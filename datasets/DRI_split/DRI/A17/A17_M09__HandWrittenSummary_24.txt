This paper presents a method for synthesizing streams of motions based on a corpus of captured movement while preserving the quality of the original data. Given a set of motion capture data, a structure called a motion graph is compiled in order to encode how the captured clips may be re-assembled in different ways. The motion graph is a directed graph wherein edges contain either pieces of original motion data or automatically generated transitions, and nodes serve as choice points where these small bits of motion join seamlessly. The whole process is divided into three steps. Firstly, a set of candidate transition points is detected by comparing the similarity of the frames according to the root position, joint angle and rotational velocity. Secondly, these candidate transitions are selected by searching the local minimum in the distance function. If the similarity is under a threshold, the transition is selected and created to blend the two sequences. Finally, the graph is pruned to eliminate problematic edges. When generating a new sequence, a standard graph algorithm is used to find a path which minimize the error metric. The limitations of this work include the computational bottleneck in graph construction, manual setting of the transition thresholds. Future work include applying the motion graph to crowd simulation and the incorporation of a parameterizable motion.