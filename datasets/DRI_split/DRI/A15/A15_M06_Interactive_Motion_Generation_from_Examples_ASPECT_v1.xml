<?xml version="1.0" encoding="UTF-8" standalone="no"?>
<Document xmlns:gate="http://www.gate.ac.uk" name="A15_M06_Interactive_Motion_Generation_from_Examples_ASPECT_v1.xml">


  
    3315e831b4f59b30e8bdad883c77df9ed5f301dbb0e70be6b8443d0ad5d2b311
    3vtl
    http://dx.doi.org/10.1145/566570.566606
  
  
    
      To appear in the ACM SIGGRAPH conference proceedings
      
        <Title>Interactive Motion Generation from Examples</Title>
      
      
        
          Okan Arikan
        
      
      University of California, Berkeley
      <Abstract>
<Sentence aspectClass="NONE" inAbstract="true">There are many applications that demand large quantities of natural looking motion.</Sentence> <Sentence aspectClass="NONE" inAbstract="true">It is difficult to synthesize motion that looks natural, particularly when it is people who must move.</Sentence> <Sentence aspectClass="NONE" inAbstract="true">In this paper, we present a framework that generates human motions by cutting and pasting motion capture data.</Sentence> <Sentence aspectClass="NONE" inAbstract="true">Selecting a collection of clips that yields an acceptable motion is a combinatorial problem that we manage as a randomized search of a hierarchy of graphs.</Sentence> <Sentence aspectClass="NONE" inAbstract="true">This approach can generate motion sequences that satisfy a variety of constraints automatically.</Sentence> <Sentence aspectClass="NONE" inAbstract="true">The motions are smooth and human-looking.</Sentence> <Sentence aspectClass="NONE" inAbstract="true">They are generated in real time so that we can author complex motions interactively.</Sentence> <Sentence aspectClass="NONE" inAbstract="true">The algorithm generates multiple motions that satisfy a given set of constraints, allowing a variety of choices for the animator.</Sentence> <Sentence aspectClass="NONE" inAbstract="true">It can easily synthesize multiple motions that interact with each other using constraints.</Sentence> <Sentence aspectClass="NONE" inAbstract="true">This framework allows the extensive re-use of motion capture data for new purposes.</Sentence>
</Abstract>
	  CR Categories: I.2.7 [Artificial Intelligence]: Problem Solving, Control Methods and Search—Graph and tree search strategies I.3.7 [COMPUTER GRAPHICS ]: Three-Dimensional Graphics and Realism—Animation Keywords: Motion Capture, Motion Synthesis, Human motion, Graph Search, Clustering, Animation with Constraints
      
        
          D. A. Forsyth
        
      
    
    
      
        <H1>1 Introduction</H1>
      
      <Sentence aspectClass="COMMON_PRACTICE" inAbstract="false">Motion is one of the most important ingredients of CG movies and computer games.</Sentence> <Sentence aspectClass="COMMON_PRACTICE" inAbstract="false">Obtaining realistic motion usually involves key framing, physically based modelling or motion capture.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">Creating natural looking motions with key framing requires lots of effort and expertise.</Sentence> <Sentence aspectClass="ADVANTAGE_DISADVANTAGE" inAbstract="false">Although physically based modelling can be applied to simple systems successfully, generating realistic motion on a computer is difficult, particularly for human motion.</Sentence> <Sentence aspectClass="COMMON_PRACTICE" inAbstract="false">A standard solution is motion capture: motion data for an approximate skeletal hierarchy of the subject is recorded and then used to drive a reconstruction on the computer.</Sentence> <Sentence aspectClass="ADVANTAGE" inAbstract="false">This allows other CG characters to be animated with the same motions, leading to realistic, “human looking” motions for use in movies or games.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">The biggest drawbacks of motion capture are:
      1.</Sentence> <Sentence aspectClass="DISADVANTAGE" inAbstract="false">Most motion capture systems are very expensive to use, because the process is time consuming for actors and technicians and motion data tends not to be re-used.</Sentence>
      2. <Sentence aspectClass="DISADVANTAGE" inAbstract="false">It is very hard to obtain motions that do exactly what the animator wants.</Sentence> <Sentence aspectClass="DISADVANTAGE" inAbstract="false">Satisfying complex timed constraints is difficult and may involve many motion capture iterations.</Sentence> <Sentence aspectClass="DISADVANTAGE" inAbstract="false">Examples include being at a particular position at a particular time accurately or synchronizing movement to a background action that had been shot before.</Sentence>
      <Sentence aspectClass="NONE" inAbstract="false">In order to make motion capture widely available, the motion data needs to be made re-usable.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">This may mean using previous motion capture data to generate new motions so that certain requirements are met, transferring motions from one skeletal configuration to another so that we can animate multiple figures with the same motion without it looking “funny”, or changing the style of the motion so that the directors can have higher level control over the motion.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">There are three natural stages of motion synthesis:
      1.</Sentence> <Sentence aspectClass="COMMON_PRACTICE" inAbstract="false">Obtaining motion demands involves specifying constraints on the motion, such as the length of the motion, where the body or individual joints should be or what the body needs to be doing at particular times.</Sentence> <Sentence aspectClass="COMMON_PRACTICE" inAbstract="false">These constraints can come from an interactive editing system used by animators, or from a computer game engine itself.</Sentence> 2. <Sentence aspectClass="COMMON_PRACTICE" inAbstract="false">Generating motion involves obtaining a rough motion that satisfies the demands.</Sentence> <Sentence aspectClass="NOVELTY" inAbstract="false">In this paper, we describe a technique that cuts and pastes bits and pieces of example motions together to create such a motion.</Sentence> 3. <Sentence aspectClass="COMMON_PRACTICE" inAbstract="false">Post processing involves fixing small scale offensive artifacts.</Sentence> <Sentence aspectClass="COMMON_PRACTICE" inAbstract="false">An example would involve fixing the feet so that they do not penetrate or slide on the ground, lengthening or shortening strides and fixing constraint violations.</Sentence>
      <Sentence aspectClass="NOVELTY" inAbstract="false">In this paper, we present a framework that allows synthesis of new motion data meeting a wide variety of constraints.</Sentence> <Sentence aspectClass="ADVANTAGE" inAbstract="false">The synthesized motion is created from example motions at interactive speeds.</Sentence>
      
        <H1>2 Related Work</H1>
      
      <Sentence aspectClass="COMMON_PRACTICE" inAbstract="false">In the movie industry, motion demands are usually generated by animators.</Sentence> <Sentence aspectClass="COMMON_PRACTICE" inAbstract="false">However, automatic generation of motion demands is required for autonomous intelligent robots and characters <CitSpan>[Funge et al. 1999]</CitSpan>.</Sentence> <Sentence aspectClass="COMMON_PRACTICE" inAbstract="false">An overview of the automatic motion planning can be found in <CitSpan>[Latombe 1999; O’Rourke 1998]</CitSpan>.</Sentence> <Sentence aspectClass="COMMON_PRACTICE" inAbstract="false">Generating motion largely follows two threads: using examples and using controllers.</Sentence> <Sentence aspectClass="COMMON_PRACTICE" inAbstract="false">Example based motion synthesis draws on an analogy with texture synthesis where a new texture (or motion) that looks like an example texture (or motion example) needs to be synthesized <CitSpan>[Efros and Leung 1999; Heeger and Bergen 1995]</CitSpan>.</Sentence> <Sentence aspectClass="COMMON_PRACTICE" inAbstract="false">Pullen and Bregler used this approach to create cyclic motions by sampling motion signals in a “signal pyramid” [2000].</Sentence> <Sentence aspectClass="COMMON_PRACTICE" inAbstract="false">They also used a similar approach to fetch missing degrees of freedom in a motion from a motion capture database <CitSpan>[Pullen and Bregler 2002]</CitSpan>.</Sentence> <Sentence aspectClass="COMMON_PRACTICE" inAbstract="false">The sampling can also be done in the motion domain to pick clips of motions to establish certain simple constraints <CitSpan>[Lamouret and van de Panne 1996; Schodl et al. 2000]</CitSpan>.</Sentence> <Sentence aspectClass="COMMON_PRACTICE" inAbstract="false">A roadmap of all the motion examples can be constructed and searched to obtain a desired motion <CitSpan>[Choi et al. 2000; Lee et al. 2002; Kovar et al. 2002]</CitSpan>.</Sentence> <Sentence aspectClass="COMMON_PRACTICE" inAbstract="false">The clips in this roadmap can also be parameterized for randomly sampling different motion sequences <CitSpan>[Li et al. 2002]</CitSpan>.</Sentence> <Sentence aspectClass="COMMON_PRACTICE" inAbstract="false">The motion signals can also be clustered.</Sentence> <Sentence aspectClass="COMMON_PRACTICE" inAbstract="false">The resulting Markov chain can be searched using dynamic programming to find a motion that connects two keyframes <CitSpan>[Molina-Tanco and Hilton 2000]</CitSpan> or used in a variable length Markov model to infer behaviors <CitSpan>[Galata et al. 2001]</CitSpan> or directly sampled from to create new motions <CitSpan>[Bowden 2000]</CitSpan>.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">This is similar to our work.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">However, our clustering method does not operate on body configurations and our probabilistic search strategy is more effective than dynamic programming as it will be explained below.</Sentence> <Sentence aspectClass="COMMON_PRACTICE" inAbstract="false">Types of probabilistic search algorithms have also been used in physically based animation synthesis <CitSpan>[Chenney and Forsyth 2000]</CitSpan> and rendering <CitSpan>[Veach and Guibas 1997]</CitSpan>.</Sentence> <Sentence aspectClass="COMMON_PRACTICE" inAbstract="false">Controller based approaches use physical models of systems and controllers that produce outputs usually in the form of forces and torques as a function of the state of the body.</Sentence> <Sentence aspectClass="COMMON_PRACTICE" inAbstract="false">These controllers can be designed specifically to accomplish particular tasks <CitSpan>[Brogan et al. 1998; Hodgins et al. 1995]</CitSpan> or they can be learned automatically using statistical tools <CitSpan>[Grzeszczuk and Terzopoulos 1995; Grzeszczuk et al. 1998; Mataric 2000]</CitSpan>.</Sentence> <Sentence aspectClass="COMMON_PRACTICE" inAbstract="false">The motion data can also be post processed to fix problems such as feet sliding on the ground or some constraints not being satisfied <CitSpan>[Gleicher 1998; Lee and Shin 1999; Popovic 1999; Rose et al. 1996]</CitSpan>.</Sentence> <Sentence aspectClass="COMMON_PRACTICE" inAbstract="false">This usually involves optimization of a suitable displacement function on the motion signal.</Sentence> <Sentence aspectClass="COMMON_PRACTICE" inAbstract="false">Different body sizes move according to different time scales, meaning that motion cannot simply be transferred from one body size to another; modifying motions appropriately is an interesting research problem <CitSpan>[Hodgins and Pollard 1997]</CitSpan>.</Sentence>
      1
      To appear in the ACM SIGGRAPH conference proceedings
      
        <H1>3 Synthesis as Graph Search</H1>
        <Sentence aspectClass="COMMON_PRACTICE" inAbstract="false">We assume there is a set of N motion sequences forming our dataset, each belonging to the same skeletal configuration.</Sentence> <Sentence aspectClass="COMMON_PRACTICE" inAbstract="false">Every motion is discretely represented as a sequence of frames each of which has the same M degrees of freedom.</Sentence> <Sentence aspectClass="COMMON_PRACTICE" inAbstract="false">This is required to be able to compare two motions and to be able to put clips from different motion sequences together.</Sentence> <Sentence aspectClass="COMMON_PRACTICE" inAbstract="false">We write the i’th frame of s’th motion as s i .</Sentence>
        
          <H2>3.1 Motion Graph</H2>
          <Sentence aspectClass="COMMON_PRACTICE" inAbstract="false">The collection of motion sequences could be represented as a directed graph.</Sentence> <Sentence aspectClass="COMMON_PRACTICE" inAbstract="false">Each frame would be a node.</Sentence> <Sentence aspectClass="COMMON_PRACTICE" inAbstract="false">There would be an edge from every frame to every frame that could follow it in an acceptable splice.</Sentence> <Sentence aspectClass="COMMON_PRACTICE" inAbstract="false">In this graph, there would be (at least) an edge from the k’th frame to the k + 1’th frame in each sequence.</Sentence> <Sentence aspectClass="DISADVANTAGE" inAbstract="false">This graph is not a particularly helpful representation because it is extremely large — we can easily have tens of thousands of nodes and hundreds of thousands of edges — and it obscures the structure of the sequences.</Sentence> <Sentence aspectClass="NOVELTY" inAbstract="false">Instead, we collapse all the nodes (frames) belonging to the same motion sequence together.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">This yields a graph G where the nodes of G are individual motion sequences and there is an edge from s to t for every pair of frames where we can cut from s to t.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">Since edges connect frames, they are labelled with the frames in the incident nodes (motion sequences) that they originate from and they point to.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">We also assume that the edges in G are attached a cost value which tells us the cost of connecting the incident frames.</Sentence> <Sentence aspectClass="COMMON_PRACTICE" inAbstract="false">If cutting from one sequence to another along an edge introduces a discontinuous motion, then the cost attached to the edge is high.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">Appendix A introduces the cost function that we used.</Sentence> <Sentence aspectClass="COMMON_PRACTICE" inAbstract="false">The collapsed graph still has the same number of edges.</Sentence> <Sentence aspectClass="COMMON_PRACTICE" inAbstract="false">For an edge e from s i to t j , let f romMotion(e) = s, toMotion(e) = t, f romFrame(e) = i, toFrame(e) = j and cost(e) be the cost associated with the edge (defined in Appendix A).</Sentence> <Sentence aspectClass="COMMON_PRACTICE" inAbstract="false">In this setting, any sequence of edges e 1 · · · e n where toMotion(e i ) = f romMotion(e i+1 ) and toFrame(e i ) &lt; f romFrame(e i+1 ), ∀i, 1≤i &lt; n is a valid path and defines a legal sequence of splices.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">(figure 1).</Sentence>
          Path Edge 1 Edge 5 Edge 2 Edge 4 Edge 3 Edge 1 Sequences Edge 2 Edge 4 Edge 3 Motion Edge 5 Corresponding Motion Time
          
            Figure 1: We wish to synthesize human motions by splicing together pieces of existing motion capture data. This can be done by representing the collection of motion sequences by a directed graph (top). Each sequence becomes a node; there is an edge between nodes for every frame in one sequence that can be spliced to a frame in another sequence or itself. A valid path in this graph represents a collection of splices between sequences, as the middle shows. We now synthesize constrained motion sequences by searching appropriate paths in this graph using a randomized search method.
          
        
        
          <H2>3.2 Constraints</H2>
          <Sentence aspectClass="COMMON_PRACTICE" inAbstract="false">We wish to construct paths in the motion graph that satisfy constraints.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">Many constraints cannot be satisfied exactly.</Sentence> <Sentence aspectClass="COMMON_PRACTICE" inAbstract="false">For example, given two positions, there may not be any sequence of frames in the collection that will get us from the first position to the second position exactly.</Sentence> <Sentence aspectClass="COMMON_PRACTICE" inAbstract="false">We define hard constraints to be those that can (and must) be satisfied exactly.</Sentence> <Sentence aspectClass="COMMON_PRACTICE" inAbstract="false">Typically, a hard constraint involves using a particular frame in a particular time slot.</Sentence> <Sentence aspectClass="COMMON_PRACTICE" inAbstract="false">For example, instead of considering all valid paths, we can restrict ourselves to valid paths that pass through particular nodes at particular times.</Sentence> <Sentence aspectClass="ADVANTAGE" inAbstract="false">This way, we can constrain the moving figure to be at a specific pose at a specific time.</Sentence> <Sentence aspectClass="ADVANTAGE" inAbstract="false">This enables us to search for motions such as jumping, falling, or pushing a button at a particular time.</Sentence> <Sentence aspectClass="COMMON_PRACTICE" inAbstract="false">A soft constraint cannot generally be met exactly.</Sentence> <Sentence aspectClass="COMMON_PRACTICE" inAbstract="false">Instead we score sequences using an objective function that reflects how well the constraint has been met and attempt to find extremal sequences.</Sentence> <Sentence aspectClass="COMMON_PRACTICE" inAbstract="false">One example is the squared distance between the position of the constraint and the actual position of the body at the time of the constraint.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">Example soft constraints include:
          1.</Sentence> <Sentence aspectClass="COMMON_PRACTICE" inAbstract="false">The total number of frames should be a particular number.</Sentence>
          2
          To appear in the ACM SIGGRAPH conference proceedings
          2. <Sentence aspectClass="COMMON_PRACTICE" inAbstract="false">The motion should not penetrate any objects in the environment.</Sentence> 3. <Sentence aspectClass="COMMON_PRACTICE" inAbstract="false">The body should be at a particular position and orientation at a particular time.</Sentence> 4. <Sentence aspectClass="COMMON_PRACTICE" inAbstract="false">A particular joint should be at a particular position (and maybe having a specific velocity) at a specific time.</Sentence> 5. <Sentence aspectClass="COMMON_PRACTICE" inAbstract="false">The motion should have a specified style (such as happy or energetic) at a particular time.</Sentence>
          <Sentence aspectClass="COMMON_PRACTICE" inAbstract="false">Finding paths in the motion graph that satisfy the hard constraints and optimize soft constraints involves a graph search.</Sentence> <Sentence aspectClass="DISADVANTAGE" inAbstract="false">Unfortunately, for even a small collection of motions, the graph G has a large number of edges and straightforward search of this graph is computationally prohibitive.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">The main reason is the need to enumerate many paths.</Sentence> <Sentence aspectClass="COMMON_PRACTICE" inAbstract="false">There are, in general, many perfectly satisfactory motions that satisfy the constraints equally well.</Sentence> <Sentence aspectClass="COMMON_PRACTICE" inAbstract="false">For example, if we require only that the person be at one end of a room at frame 0 and near the other end at frame 5000, unless the room is very large, there are many motions that satisfy these constraints.</Sentence>
        
      
      
        <H1>4 Randomized Search</H1>
        <Sentence aspectClass="NONE" inAbstract="false">The motion graph is too hard to search with dynamic programming as there are many valid paths that satisfy the constraints equally well.</Sentence> <Sentence aspectClass="COMMON_PRACTICE" inAbstract="false">There may be substantial differences between equally valid paths — in the example above, whether you dawdle at one side of the room or the other is of no significance.</Sentence> <Sentence aspectClass="COMMON_PRACTICE" inAbstract="false">This suggests summarizing the graph to a higher level and coarser presentation that is easier to search.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">Branch and bound algorithms are of no help here, because very little pruning is possible.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">In order to search the graph G in practical times, we need to do the search at a variety of levels where we do the large scale motion construction first and then “tweak” the details so that the motion is continuous and satisfies the constraints as well as possible.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">Coarser levels should have less complexity while allowing us to explore substantially different portions of the path space.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">In such a representation, every level is a summary of the one finer level.</Sentence> <Sentence aspectClass="COMMON_PRACTICE" inAbstract="false">Let G ← G ← G ← · · · ← G n ← G be such a hierarchical representation where G is the coarsest level and G is the finest.</Sentence> <Sentence aspectClass="COMMON_PRACTICE" inAbstract="false">We will first find a path in G and then push it down the hierarchy to a path in G for synthesis.</Sentence>
        
          <H2>4.1 Summarizing the Graph</H2>
          <Sentence aspectClass="COMMON_PRACTICE" inAbstract="false">All the edges between two nodes s and t can be represented in a matrix P st .</Sentence> <Sentence aspectClass="COMMON_PRACTICE" inAbstract="false">The (i, j)’th entry of P st contains the weight of the edge connecting s i to t j and infinity if there is no such edge.</Sentence> <Sentence aspectClass="COMMON_PRACTICE" inAbstract="false">In the appendix A, we give one natural cost function C(s i ,t j ) for edge weights.</Sentence> <Sentence aspectClass="COMMON_PRACTICE" inAbstract="false">We now have: (P st ) i j = C(s ∞ i ,t j ) otherwise.</Sentence> <Sentence aspectClass="COMMON_PRACTICE" inAbstract="false">if there is an edge from s i to t j The cost function explained in section A causes the P matrices to have non-infinite entries to form nearly elliptical groups ( figure 2 ).</Sentence> <Sentence aspectClass="COMMON_PRACTICE" inAbstract="false">This is due to the fact that if two frames are similar, most probably their preceding and succeeding frames also look similar.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">In order to summarize the graph, we cluster the edges of G. We now have G , whose nodes are the same as the nodes of G, and whose edges represent clusters of edges of G in terms of their f romFrame and toFrame labels.</Sentence> <Sentence aspectClass="COMMON_PRACTICE" inAbstract="false">We require that, if there is a cut between two sequences represented by an edge between two nodes in G, there be at least one edge between the corresponding nodes in G .</Sentence> <Sentence aspectClass="ADVANTAGE" inAbstract="false">If this were not the case, our summary would rule out potential paths.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">In order to insure that this condition holds and because the graph is very large, we cluster edges connecting every pair of nodes in G separately.</Sentence> <Sentence aspectClass="COMMON_PRACTICE" inAbstract="false">We cluster unconnected edge groups of G from the P matrices (defined between every pair of nodes) using k-means ma joraxislength <CitSpan>[Bishop 1995]</CitSpan>.</Sentence> <Sentence aspectClass="COMMON_PRACTICE" inAbstract="false">The number of clusters is chosen as minoraxislength for each group where the axis lengths refer to the ellipse that fits to the cluster (obtained through Principal Component Analysis).</Sentence> <Sentence aspectClass="NONE" inAbstract="false">The nodes of G are the same as the nodes of G. The edges connecting nodes in G are cluster centers for clusters of edges connecting corresponding nodes in G. The centers are computed by taking the average of the edges in terms of f romFrame, toFrame and cost values.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">At this point, every edge in G represents many edges in G. We would like to have a tree of graph representations whose root is G , and whose leaves are G. We use k-means clustering to split each cluster of edges in half at each intermediate level and obtain a hierarchical representation G ← G ← G ← · · · ← G n ← G for the original graph G. This is an instance of Tree-Structured Vector Quantization <CitSpan>[Gersho and Gray 1992]</CitSpan>.</Sentence> <Sentence aspectClass="COMMON_PRACTICE" inAbstract="false">Thus, in our summarized graph G , each edge is the root of a binary tree and represents all the edges in close neighborhood in terms of the edge labels.</Sentence> <Sentence aspectClass="COMMON_PRACTICE" inAbstract="false">Note that the leaf edges are the edges in the original graph and intermediate edges are the averages of all the leaf edges beneath them.</Sentence> <Sentence aspectClass="ADVANTAGE" inAbstract="false">A path in G represents a sequence of clips; so does a path in G , but now the positions of the clip boundaries are quantized, so there are fewer paths.</Sentence>
          Frame i Frame j Walking Running Walking , frame i
          Clustering
          j frame Running,
          
            
            
            Figure 2: Every edge between two nodes representing different motion clips can be represented as a matrix where the entries correspond to edges. Typically, if there is one edge between two nodes in our graph, there will be several, because if it is legal to cut from one frame in the first sequence to another in the second, it will usually also be legal to cut between neighbors of these frames. This means that, for each pair of nodes in the graph, there is a matrix representing the weights of edges between the nodes. The i, j’th entry in this matrix represents the weight for a cut from the i’th frame in the first sequence to the j’th frame in the second sequence. The weight matrix for the whole graph is composed as a collection of blocks of this form. Summarizing the graph involves compressing these blocks using clustering.
          
        
        
          <H2>4.2 Searching the Summaries</H2>
          <Sentence aspectClass="NONE" inAbstract="false">While searching this graph, we would like to be able to generate different alternative motions that achieve the same set of constraints.</Sentence> <Sentence aspectClass="COMMON_PRACTICE" inAbstract="false">During the search, we need to find paths close to optimal solutions but do not require exact extrema, because they are too hard to find.</Sentence> <Sentence aspectClass="COMMON_PRACTICE" inAbstract="false">This motivates a random search.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">We used the following search strategy:</Sentence>
          3
          To appear in the ACM SIGGRAPH conference proceedings
          1. <Sentence aspectClass="COMMON_PRACTICE" inAbstract="false">Start with a set of n valid random “seed” paths in the graph G 2.</Sentence> <Sentence aspectClass="COMMON_PRACTICE" inAbstract="false">Score each path and score all possible mutations 3.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">Where possible mutations are: (a) Delete some portion of the path and replace it with 0 or 1 hops.</Sentence> <Sentence aspectClass="COMMON_PRACTICE" inAbstract="false">(b) Delete some edges of the path and replace them with their children 4.</Sentence> <Sentence aspectClass="COMMON_PRACTICE" inAbstract="false">Accept the mutations that are better than the original paths 5.</Sentence> <Sentence aspectClass="COMMON_PRACTICE" inAbstract="false">Include a few new valid random “seed” paths 6.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">Repeat until no better path can be generated through mutations
          Intuitively the first mutation strategy replaces a clip with a (hopefully) better one and the second mutation strategy adjusts the detailed position of cut boundaries.</Sentence> <Sentence aspectClass="ADVANTAGE" inAbstract="false">Since we start new random “seed” paths at every iteration, the algorithm does not get stuck at a local optimum forever.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">Section 4.2.2 explains these mutations in more detail.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">Hard constraints are easily dealt with; we restrict our search to paths that meet these constraints.</Sentence> <Sentence aspectClass="COMMON_PRACTICE" inAbstract="false">Typically hard constraints specify the frame (in a particular node) to be used at a particular time.</Sentence> <Sentence aspectClass="COMMON_PRACTICE" inAbstract="false">We do this by ensuring that “seed” paths meet these constraints, and mutations do not violate them.</Sentence> <Sentence aspectClass="COMMON_PRACTICE" inAbstract="false">This involves starting to sample the random paths from the hard constraint nodes and greedily adding sequences that get us to the next hard constraint if any.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">Since the path is sampled at the coarse level, a graph search can also be performed between the constraint nodes.</Sentence> <Sentence aspectClass="COMMON_PRACTICE" inAbstract="false">At every iteration we check if the proposed mutation deletes a motion piece that has a hard constraint in it.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">Such mutations are rejected immediately.</Sentence> <Sentence aspectClass="COMMON_PRACTICE" inAbstract="false">Note that here we assume the underlying motion graph is connected.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">Section 4.2.1 explains the constraints that we used in more detail.</Sentence> <Sentence aspectClass="COMMON_PRACTICE" inAbstract="false">Notice that this algorithm is similar to MCMC search (a good broad reference to application of MCMC is <CitSpan>[Gilks et al. 1996]</CitSpan>).</Sentence> <Sentence aspectClass="DISADVANTAGE" inAbstract="false">However, it is difficult to compute proposal probabilities for the mutations we use, which are strikingly successful in practice.</Sentence> <Sentence aspectClass="ADVANTAGE" inAbstract="false">This is an online algorithm which can be stopped at anytime.</Sentence> <Sentence aspectClass="NOVELTY" inAbstract="false">This is due to the fact that edges in intermediate graphs G · · · G n also represent connections and are valid edges.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">Thus we do not have to reach the leaf graph G to be able to create a path (motion sequence).</Sentence> <Sentence aspectClass="NOVELTY" inAbstract="false">We can stop the search iteration, take the best path found so far, and create a motion sequence.</Sentence> <Sentence aspectClass="NOVELTY" inAbstract="false">If the sequence is not good enough, we can resume the search from where we left off to get better paths through mutations and inclusion of random paths.</Sentence> <Sentence aspectClass="ADVANTAGE" inAbstract="false">This allows an intuitive computation cost vs. quality tradeoff.</Sentence>
          
            <H3>4.2.1 Evaluating a Path</H3>
            <Sentence aspectClass="NONE" inAbstract="false">Since during the search all the paths live in a subspace implied by the hard constraints, these constraints are always satisfied.</Sentence> <Sentence aspectClass="COMMON_PRACTICE" inAbstract="false">Given a sequence of edges e 1 · · · e n , we score the path using the imposed soft constraints.</Sentence> <Sentence aspectClass="COMMON_PRACTICE" inAbstract="false">For each constraint, we compute a cost where the cost is indicative of the satisfaction of the constraint.</Sentence> <Sentence aspectClass="COMMON_PRACTICE" inAbstract="false">Based on the scores for each of the constraints, we weight and sum them to create a final score for the path (The S function in equation 1).</Sentence> <Sentence aspectClass="COMMON_PRACTICE" inAbstract="false">We also add the sum of the costs of the edges along the path to make sure we push the search towards paths that are continuous.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">The weights can be manipulated to increase/decrease the influence of a particular soft constraint.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">We now have an expression of the form:</Sentence>
            n
          
          
            <H3>4.2.2 Mutating a Path S(e · · · e ) = w ∗ ∑ cost(e ) + w ∗ F + w ∗ B + w ∗ J <CitSpan>(1)</CitSpan>
</H3>
            
              1
              1 n c i f b j
            
            i=1
            
              Figure 3: The two mutations are: deleting some portion of the path (top-left, crossed out in red) and replacing that part with another set of edges (top-right), and deleting some edges in the path (bottomleft) and replacing deleted edges with their children in our hierarchy (bottom-right)
            
            <Sentence aspectClass="NONE" inAbstract="false">Where w c ,w f ,w b and w j are weights for the quality (continuity) of the motion, how well the length of the motion is satisfied, how well the body constraints are satisfied and how well the joints constraints are defined.</Sentence> <Sentence aspectClass="COMMON_PRACTICE" inAbstract="false">We selected these weights such that an error of 10 frames increases the total score the same amount as an error of 30 centimeters in position and 10 degrees in orientation.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">The scores F, B and J are defined as:
            1.</Sentence> <Sentence aspectClass="COMMON_PRACTICE" inAbstract="false">F: For the number of frame constraints, we compute the squared difference between the actual number of frames in the path and the required number of frames.</Sentence> 2. <Sentence aspectClass="COMMON_PRACTICE" inAbstract="false">B: For body constraints, we compute the distance between the position and orientation of the constraint versus the actual position and orientation of the torso at the time of the constraint and sum the squared distances.</Sentence> <Sentence aspectClass="COMMON_PRACTICE" inAbstract="false">The position and orientation of the body at the constraint times are found by putting the motion pieces implied by the subsequent edges together ( figure 1 ).</Sentence> <Sentence aspectClass="COMMON_PRACTICE" inAbstract="false">This involves taking all the frames of motion toMotion(e i ) between frames f romFrame(e i+1 ) and toFrame(e i ) and putting the sequence of frames starting from where the last subsequence ends or from the first body constraint if there is no previous subsequence.</Sentence> <Sentence aspectClass="COMMON_PRACTICE" inAbstract="false">Note that we require that we have at least two body constraints enforcing the position/orientation of the body at the beginning of the synthesized motion (so that we know where to start putting the frames down) and at the end of the synthesized motion.</Sentence> <Sentence aspectClass="COMMON_PRACTICE" inAbstract="false">The first body constraint is always satisfied, because we always start putting the motions together from the first body constraint.</Sentence> 3. <Sentence aspectClass="COMMON_PRACTICE" inAbstract="false">J: For joint constraints, we compute the squared distance between the position of the constraint and the position of the constrained joint at the time of the constraint and sum the squared distance between the two.</Sentence> <Sentence aspectClass="COMMON_PRACTICE" inAbstract="false">To determine the configuration of the body at the time at which the constraint applies, we must assemble the motion sequence up to the time of the constraint; in fact, most of the required information such as the required transformation between start and end of each cut is already available in the dataset.</Sentence>
            <Sentence aspectClass="NOVELTY" inAbstract="false">We implemented two types of mutations which can be performed quickly on an active path.</Sentence>
            4
            To appear in the ACM SIGGRAPH conference proceedings
            Domain of smoothing Discontinuity Magnitude
            Smoothed Signal
            
              
              Figure 4: In the synthesized motion, discontinuities in orientation are inevitable. We deal with these discontinuities using a form of localized smoothing. At the top left, a discontinuous orientation signal, with its discontinuity shown at the top right. We now construct an interpolant to this discontinuity, shown on the bottom right and add it back to the original signal to get the continuous version shown on the bottom left. Typically, discontinuities in orientation are sufficiently small that no more complex strategy is necessary.
            
            1. <Sentence aspectClass="COMMON_PRACTICE" inAbstract="false">Replace a sequence by selecting two edges e i and e i+ j where 0 ≤ j ≤ n − i, deleting all the edges between them in the path and connecting the unconnected pieces of the path using one or two edges in the top level graph G (if possible).</Sentence> <Sentence aspectClass="ADVANTAGE" inAbstract="false">Since in the summarized graph, there are relatively fewer edges, we can quickly find edges that connect the two unconnected nodes by checking all the edges that go out from toMotion(e i ), and enumerating all the edges that reach to f romMotion(e i+ j ) and generate a valid path.</Sentence> <Sentence aspectClass="COMMON_PRACTICE" inAbstract="false">Note that we enumerate only 0 or 1 hop edges (1 edge or 2 edge connections respectively).</Sentence> 2. <Sentence aspectClass="COMMON_PRACTICE" inAbstract="false">Demoting two edges to their children and replacing them with one of their children if they can generate a valid path.</Sentence> <Sentence aspectClass="ADVANTAGE" inAbstract="false">Doing this mutation on two edges simultaneously allows us to compensate for the errors that would happen if only one of them was demoted.</Sentence>
            <Sentence aspectClass="COMMON_PRACTICE" inAbstract="false">We check every possible mutation, evaluate them and take the best few.</Sentence> <Sentence aspectClass="ADVANTAGE" inAbstract="false">Since the summary has significantly fewer edges than the original graph, this step is not very expensive.</Sentence> <Sentence aspectClass="COMMON_PRACTICE" inAbstract="false">If a motion sequence cannot generate a mutation whose score is lower that itself, we decide that the current path is a local minimum in the valid path space and record it as a potential motion.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">This way, we can obtain multiple motions that satisfy the same set of constraints.</Sentence>
          
          
            <H3>4.2.3 Creating and Smoothing the Final Path</H3>
            <Sentence aspectClass="NONE" inAbstract="false">We create the final motion by taking the frames between toFrame(e i ) and f romFrame(e i+1 ) from each motion toMotion(e i ) where 1 ≤ i &lt; n ( figure 1 ).</Sentence> <Sentence aspectClass="COMMON_PRACTICE" inAbstract="false">This is done by rotating and translating every motion sequence so that each piece starts from where the previous one ended.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">In general, at the frames corresponding to the edges in the path, we will have C 0 discontinuities, because of the finite number of motions sampling an infinite space.</Sentence> <Sentence aspectClass="COMMON_PRACTICE" inAbstract="false">In practice these discontinuities are small and we can distribute them within a smoothing window around the discontinuity.</Sentence> <Sentence aspectClass="COMMON_PRACTICE" inAbstract="false">We do this by multiplying the magnitude of the discontinuity by a smoothing function and adding the result back to the signal ( figure 4 ).</Sentence> <Sentence aspectClass="COMMON_PRACTICE" inAbstract="false">We choose the smoothing domain to be ±30 frames (or one second of animation) around the discontinuity and</Sentence>
            
              Figure 5: Body constraints allow us to put “checkpoints” on the motion: in the figure, the arrow on the right denotes the required starting position and orientation and the arrow on the left is the required ending position and orientation. All constraints are also time stamped forcing the body to be at the constraint at the time stamp. For these two body constraints, we can generate many motions that satisfy the constraints in real-time.
            
            
              Figure 6: We can use multiple “checkpoints” in a motion. In this figure, the motion is required to pass through the arrow (body constraint) in the middle on the way from the right arrow to the left.
            
            <Sentence aspectClass="NONE" inAbstract="false"> y( f ) =       0 − 0 2 1 ∗ 2 1 ( ∗ f ( −d+s f s −d+s s ) 2 ) 2 + 2 ∗ ( f −d+s s ) − 2 d d f f − ≤ &gt; &lt; s d d f ≤ + − ≤ f s s d &lt; + d s
            as the smoothing function that gives the amount of displacement for every frame f , where d is the frame of the discontinuity and s if the smoothing window size (in our case 30).</Sentence> <Sentence aspectClass="COMMON_PRACTICE" inAbstract="false">To make sure that we interpolate the body constraints (i.e. having a particular position/orientation at a particular frame), we take the difference between the desired constraint state, subtract the state at the time of the constraint and distribute this difference uniformly over the portion of the motion before the time of the constraint.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">Note that these “smoothing” steps can cause artifacts like feet penetrating or sliding on the ground.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">However, usually the errors made in terms of constraints and the discontinuities are so small that they are unnoticeable.</Sentence>
          
        
        
          <H2>4.3 Authoring Human Motions</H2>
          <Sentence aspectClass="NONE" inAbstract="false">Using iterative improvements of random paths, we are able to synthesize human looking motions interactively.</Sentence> <Sentence aspectClass="ADVANTAGE" inAbstract="false">This allows interactive manipulation of the constraints.</Sentence> <Sentence aspectClass="ADVANTAGE" inAbstract="false">This is important, because motion synthesis is inherently ambiguous as there may be multiple motions that satisfy the same set of constraints.</Sentence> <Sentence aspectClass="ADVANTAGE" inAbstract="false">The algorithm can find these “local minimum” motions that adhere to the same constraints.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">The animator can choose between them or all the different motions can be used to create a variety in the environment.</Sentence> <Sentence aspectClass="ADVANTAGE" inAbstract="false">Since the algorithm is interactive, the animator can also see the ambiguity and guide the search by putting extra constraints ( figure 6 ).</Sentence> <Sentence aspectClass="NONE" inAbstract="false">Currently, we can constrain the length of the motion, the body’s position and orientation at a particular frame ( figure 5 ,6), a joint (e.g. head, hand) to a particular state at a particular frame ( figure 7 ), or constrain the entire body’s pose at a particular frame (figure 8).</Sentence> <Sentence aspectClass="NONE" inAbstract="false">Notice that we can synthesize multiple interacting motions independently using hard constraints ( figure 9 ); we simply select the poses, position and orientation at which the figures interact and this framework fills in the missing motion, in a sense, interpolating the constraints.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">These are only a few of the constraints that can be implemented.</Sentence> <Sentence aspectClass="ADVANTAGE" inAbstract="false">As long as the user specifies a cost function that evaluates a motion and attaches a score that is indicative of the animator’s satisfaction with the path, many more constraints can be implemented.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">For example, if the motions in our database are marked with their individual stylistic attributes, we can also constrain the style of the desired motion by penalizing motions that do not have the particular style.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">In a computer game environment, we can constrain the synthesized motion to avoid obstacles in the environment.</Sentence> <Sentence aspectClass="COMMON_PRACTICE" inAbstract="false">In such a case, body position/orientation constraints can also come from an underlying path planner.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">Thus, given high level goals (such as going from point A to point B, say) human looking motions can be generated automatically.</Sentence>
          5
          To appear in the ACM SIGGRAPH conference proceedings
          
            Figure 7: In addition to body constraints, joint constraints can be used to further assign “checkpoints” to individual joints. In this figure, the head of the figure is also constrained to be high (indicated by the blue line), leading to a jumping motion.
          
        
      
      
        <H1>5 Results</H1>
        <Sentence aspectClass="NOVELTY" inAbstract="false">We have presented a framework that allows interactive synthesis of natural looking motions that adhere to user specified constraints.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">We assess our results using four criteria.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">Firstly, the motion looks human.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">Secondly, the motions generated by the method do not have unnatural artifacts such as slipping feet on the ground or jerky movement.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">Third, the user specified constraints are satisfied, i.e. the motion passes through the required spot at the required time, or the character falls to a particular position ( figure 8 ).</Sentence> <Sentence aspectClass="NONE" inAbstract="false">Finally, motions are generated interactively — typically depending on the quality of the path desired, an acceptable 300 frame motion is found in between 3 and 10 seconds on an average PC (Pentium III at 800 Mhz).</Sentence> <Sentence aspectClass="ADVANTAGE" inAbstract="false">This speed allows interactive motion authoring.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">For example, we generated the real-time screen captures in the attached video using a dataset of 60-80 unorganized, short (below 300 frames each) motion capture fragments.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">The average precomputation time required for this many motions (computing the motion graph) is 5 hours on the same computer.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">On average, the results shown in the video contain 3-30 motion pieces cut from the original motions.</Sentence> <Sentence aspectClass="ADVANTAGE" inAbstract="false">This framework is completely automatic.</Sentence> <Sentence aspectClass="ADVANTAGE" inAbstract="false">Once the input motions are selected, the computation of the hierarchic motion graph does not require any user intervention and the resulting representation is searched in real-time.</Sentence> <Sentence aspectClass="COMMON_PRACTICE" inAbstract="false">For many kinds of constraints the motion synthesis problem is underconstrained; there are many possible combinations of motion pieces that achieve the same set of constraints.</Sentence> <Sentence aspectClass="ADVANTAGE" inAbstract="false">Randomized search is well suited to find many different motions that satisfy the constraints.</Sentence> <Sentence aspectClass="COMMON_PRACTICE" inAbstract="false">On the other hand, some constraints, may not be met by any motion.</Sentence> <Sentence aspectClass="COMMON_PRACTICE" inAbstract="false">In this case, randomized search will try to minimize our objective motion and find the “closest” motion.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">For example, if the user asks for 100 meters in 5 seconds, the algorithm will tend to put fast running motions together but not necessarily satisfying the constraints.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">Similarly, if the set of motions to begin with do not form a connected graph, the algorithm will perform searches confined to the unconnected graphs.</Sentence> <Sentence aspectClass="LIMITATION" inAbstract="false">If there are hard constraints in different unconnected components, we will not even be able to find starting seed paths.</Sentence> <Sentence aspectClass="COMMON_PRACTICE" inAbstract="false">From this perspective, the selection of the database to work with is important.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">In our system, we used 60-100 football motions that have a strong bias towards motions that run forward.</Sentence> <Sentence aspectClass="ADVANTAGE" inAbstract="false">However, as the attached video suggest, the randomized search has no problem finding rare motions that turn back to satisfy the constraints.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">The motion databases that we used were unorganized except that we excluded football warming up and tackling motions unless they were desired ( figure 9 ).</Sentence> <Sentence aspectClass="ADVANTAGE" inAbstract="false">The randomized search scales linearly as a function of the database size with a very small constant.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">We have tried datasets of 50-100 motions without a noticeable change in the running time of the algorithm.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">The linearity in the running time comes from the linear increase in the number of alternative mutations at every step.</Sentence> <Sentence aspectClass="LIMITATION" inAbstract="false">Note that as the database size gets larger, the constant τ (Appendix A) that is used to create the edges can get lower since more motions mean that we expect to find better connections between motions, decreasing the number of edges.</Sentence> <Sentence aspectClass="LIMITATION" inAbstract="false">This will lead to a sublinear increase in the running time.</Sentence> <Sentence aspectClass="ADVANTAGE" inAbstract="false">The framework can work on any motion dataset: it can be created by traditional key framing, physically based modelling or motion capture.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">For example, we can take the motion data for “Woody” – who may well have been key-framed, from “Toy Story” and create new “Woody” motions automatically.</Sentence> <Sentence aspectClass="ADVANTAGE" inAbstract="false">The framework is also appli- cable to non-human motion synthesis.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">For example, this framework can be used to generate control signals for robots to achieve a particular task by generating the motion graph for previously known motion-control signal pairs.</Sentence> <Sentence aspectClass="ADVANTAGE" inAbstract="false">During the synthesis we can not only synthesize the final robot motion but also the associated control signals that achieve specific goals.</Sentence> <Sentence aspectClass="ADVANTAGE" inAbstract="false">Since the generated motions are obtained by putting pieces of motions in the dataset, the resulting motions will also carry the underlying style of the data.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">This way, we can take the motion data for one character, and produce more motions with the intrinsic style of the character.</Sentence>
        
          Figure 8: Using hard constraints, we can force the figure to perform specific activities. Here, we constrain the end of the motion to be lying flat on the ground at a particular position/orientation and time. Our framework generates the required tipping and tumbling motion in real-time.
        
        6
        To appear in the ACM SIGGRAPH conference proceedings
      
      
        <H1>6 Future Work</H1>
        <Sentence aspectClass="COMMON_PRACTICE" inAbstract="false">During the construction of the final motion, better ways of smoothing between adjacent motions could be used to improve realism <CitSpan>[Popovic 1999]</CitSpan>.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">Using better post processing, motions could also be synthesized on non-uniform surfaces which the current framework cannot handle.</Sentence> <Sentence aspectClass="COMMON_PRACTICE" inAbstract="false">Additional post processing may involve physically based modelling to make sure the synthesized motions are also physically correct.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">Automatic integration of higher level stylistic constraints could be incorporated into the framework, avoiding the arduous job of labelling every motion with the intrinsic style by hand.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">By analyzing patterns in the motion dataset, we might also infer these styles or obtain higher level descriptions <CitSpan>[Brand and Hertzmann 2001]</CitSpan>.</Sentence> <Sentence aspectClass="LIMITATION" inAbstract="false">The synthesized motions are strictly bound to the motions that were available in the original dataset.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">However, it is conceivable that the motions that are very close to the dataset could also be incorporated in the synthesizable motions using learned stylistic variations.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">The integrity of the original dataset directly effects the quality of the synthesized motion.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">For example, if the incoming motion dataset does not contain any “turning left” motions, we will not be able to synthesize motions that involve “turning left”.</Sentence> <Sentence aspectClass="LIMITATION" inAbstract="false">An automatic way of summarizing the portions of the “possible human motions” space that have not been explored well enough by the dataset could improve the data gathering and eventually the synthesized motions.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">This could also serve as a palette for artists: some portions of the precomputed motion graph can be paged in and out of memory depending on the required motion.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">For example, the animator could interactively select the motions that need to be used during the synthesis, and only the portion of the motion graph involving the desired motions could be loaded.</Sentence> <Sentence aspectClass="ADVANTAGE" inAbstract="false">This would give animators a tool whereby they can select the set of motions to work with in advance and the new motions will be created only from the artist selected set.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">Furthermore this encourages comprehensive re-use of motion data.</Sentence>
      
      
        <H1>7 Acknowledgements</H1>
        <Sentence aspectClass="NONE" inAbstract="false">This research was supported by Office of Naval Research grant no.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">N00014-01-1-0890, as part of the MURI program.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">We would like to thank Electronic Arts for supplying us with the motion data.</Sentence>
      
      
        <H1>A Appendix: Similarity Metric</H1>
        <Sentence aspectClass="COMMON_PRACTICE" inAbstract="false">We define the torso coordinate frame to be the one where the body stands centered at origin on the xz plane and looks towards the positive z axis.</Sentence> <Sentence aspectClass="COMMON_PRACTICE" inAbstract="false">Any point p in the torso coordinate frame can be transformed to the global coordinate frame by T (s i ) + R(s i ) · p , where T (s i ) is the 3 × 1 translation of the torso and R(s i ) is the 3 × 1 rotation of the torso and R(s i ) represents the rotation matrix associated with the rotation.</Sentence> <Sentence aspectClass="COMMON_PRACTICE" inAbstract="false">We wish to have a weight on edges of the motion graph (section 3.1) that encodes the extent to which two frames can follow each other.</Sentence> <Sentence aspectClass="COMMON_PRACTICE" inAbstract="false">If the weight of an edge is too high, it is dropped from the graph.</Sentence> <Sentence aspectClass="COMMON_PRACTICE" inAbstract="false">To compute the weight of an edge, we use the difference between joint positions and velocities and the difference between the torso velocities and accelerations in the torso coordinate frame.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">Let P(s i ) be a 3 × n matrix of positions of n joints for s i in torso coordinate frame.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">Equation 2 gives us the difference in joint position and body velocity.</Sentence>
        
          2
          D s i ,t j = [(P(s i ) − P(t j )) (|T (s i )| − |T (t j )|) (|R(s i )| − |R(t j )|) ]
        
        <Sentence aspectClass="NONE" inAbstract="false">We then define the normalizing matrices O and L in equation 3 and 4.</Sentence>
        
          3
          O = max s,i (|D s T i ,s i D s i ,s i+1 |)
        
        
          4
          L = max s,i (|D s T i ,s i D s i ,s i+1 |)
        
        <Sentence aspectClass="NONE" inAbstract="false">Then the cost function function in equation 5 is used to relate s i to t j .</Sentence>
        
          5
          C(s i ,t j ) = trace(D s i ,t j MO −1 D s T i ,t j + D s i ,t j T L −1 D s T i ,t j )
        
        <Sentence aspectClass="NONE" inAbstract="false">Where diagonal (n + 2) × (n + 2) matrices M and T are used to weight different joints differently.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">For example, position differences in feet are much more noticeable than position differences of hands because the ground provides a comparison frame.</Sentence> <Sentence aspectClass="COMMON_PRACTICE" inAbstract="false">We have found M and T matrices empirically by trying different choices.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">Unfortunately, defining a universal cost metric is a hard problem.</Sentence> <Sentence aspectClass="ADVANTAGE" inAbstract="false">The metric defined above produces visually acceptable results.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">Using this cost metric, we create edges from s i to t j where C(s i ,t j ) &lt; τ .</Sentence> <Sentence aspectClass="NONE" inAbstract="false">For an edge e from s i to t j , we set cost(e) = C(s i ,t j ).</Sentence> <Sentence aspectClass="NONE" inAbstract="false">τ is a user specified quality parameter that influences the number of edges in G. We have fixed this value so that cuts created between motions along the edges do not have visible artifacts.</Sentence> <Sentence aspectClass="COMMON_PRACTICE" inAbstract="false">Note that an error that is visible on a short person may not be visible on an extremely large person.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">Thus, in theory, the weights must be adjusted from person to person.</Sentence> <Sentence aspectClass="ADVANTAGE" inAbstract="false">However, in practice, possible size variation of adult people is small enough that we used the same weights for different people without creating a visible effect.</Sentence>
      
      
        <H1>References</H1>
                
          BISHOP, C. M. 1995. Neural Networks for Pattern Recognition. Clarendon Press, Oxford. BOWDEN, R., 2000. Learning statistical models of human motion.
          BRAND, M., AND HERTZMANN, A. 2001. Style machines. In Proceedings of SIGGRAPH 2000, 15–22.
          BROGAN, D. C., METOYER, R. A., AND HODGINS, J. K. 1998. Dynamically simulated characters in virtual environments. IEEE Computer Graphics &amp; Applications 18, 5, 58–69.
          CHENNEY, S., AND FORSYTH, D. A. 2000. Sampling plausible solutions to multibody constraint problems. In Proceedings of SIGGRAPH 2000, 219–228.
          CHOI, M. G., LEE, J., AND SHIN, S. Y. 2000. A probabilistic approach to planning biped locomotion with prescribed motions. Tech. rep., Computer Science Department, KAIST.
          DEMPSTER, W., AND GAUGHRAN, G. 1965. Properties of body segments based on size and weight. In American Journal of Anatomy, vol. 120, 33–54.
          EFROS, A. A., AND LEUNG, T. K. 1999. Texture synthesis by non-parametric sampling. In ICCV (2), 1033–1038.
          six-year-old children. In Research Quarterly for Exercise and Sport, vol. 54(2),126–135.
          FORTNEY, V. 1983. The kinematics and kinetics of the running pattern of two-, four and
          FUNGE, J., TU, X., AND TERZOPOULOS, D. 1999. Cognitive modeling: Knowledge, reasoning and planning for intelligent characters. In Proceedings of SIGGRAPH1999, 29– 38.
          GALATA, A., JOHNSON, N., AND HOGG, D. 2001. Learning variable length markov
          models of behaviour. In Computer Vision and Image Understanding (CVIU) Journal, vol. 81, 398–413.
          GERSHO, A., AND GRAY, R. 1992. Vector Quantization and signal compression. Kluwer Academic Publishers. GILKS, W., RICHARDSON, S., AND SPIEGELHALTER, D. 1996. Markov Chain Monte Carlo in Practice. Chapman and Hall.
          GLEICHER, M. 1998. Retargetting motion to new characters. In Proceedings of
          SIGGRAPH 1998, vol. 32, 33–42. GRZESZCZUK, R., AND TERZOPOULOS, D. 1995.
          Automated learning of muscleactuated locomotion through control abstraction. In Proceedings of SIGGRAPH 1995, 63–70.
          GRZESZCZUK, R., TERZOPOULOS, D., AND HINTON, G. 1998. Neuroanimator: Fast neural network emulation and control of physics based models. In Proceedings of SIGGRAPH 1998, 9–20.
          HEEGER, D. J., AND BERGEN, J. R. 1995. Pyramid-Based texture analysis/synthesis. In Proceedings of SIGGRAPH 1995, 229–238.
          HODGINS, J. K., AND POLLARD, N. S. 1997. Adapting simulated behaviors for new characters. In Proceedings of SIGGRAPH 1997, vol. 31, 153–162. HODGINS, J., WOOTEN, W., BROGAN, D., AND O’BRIEN, J., 1995. Animated human athletics.
          KOVAR, L., GLEICHER, M., AND PIGHIN, F. 2002. Motion graphs. In Proceedings of SIGGRAPH 2002.
          LAMOURET, A., AND VAN DE PANNE, M. 1996. Motion synthesis by example. In Eurographics Computer Animation and Simulation ’96, 199–212.
          LATOMBE, J. P. 1999. Motion planning: A journey of robots, molecules, digital actors, and other artifacts. In International Journal of Robotics Research, vol. 18, 1119–1128.
          LEE, J., AND SHIN, S. Y. 1999. A hierarchical approach to interactive motion editing for human-likefigures. In Proceedings of SIGGRAPH 1999, 39–48.
          LEE, J., CHAI, J., REITSMA, P., HODGINS, J., AND POLLARD, N. 2002. Interactive control of avatars animated with human motion data. In Proceedings of SIGGRAPH 2002.
          LI, Y., WANG, T., AND SHUM, H. Y. 2002. Motion texture: A two-level statistical model for character motion synthesis. In Proceedings of SIGGRAPH 2002.
          MATARIC, M. J. 2000. Getting humanoids to move and imitate. In IEEE Intelligent Systems, IEEE, 18–24.
          MCMAHON, T. 1984. Muscles, Reflexes and Locomotion. PhD thesis, Princeton University Press.
          MOLINA-TANCO, L., AND HILTON, A. 2000. Realistic synthesis of novel human movements from a database of motion capture examples. In Workshop on Human Motion (HUMO’00), 137–142.
          NELSON, R., BROOKS, C., AND N.PIKE. 1977. Biomechanical comparison of male and female distance runners. In Annals of the NY Academy of Sciences, vol. 301, 793–807. O’ROURKE, J. 1998. Computational Geometry in C. Cambridge University Press.
          POPOVIC, Z. 1999. Motion Transformation by Physically Based Spacetime Optimization. PhD thesis, Carnegie Mellon University Department of Computer Science.
          PULLEN, K., AND BREGLER, C. 2000. Animating by multi-level sampling. In Computer Animation 2000, 36–42. ISBN 0-7695-0683-6.
          PULLEN, K., AND BREGLER, C. 2002. Motion capture assisted animation: Texturing and synthesis. In Proceedings of SIGGRAPH 2002.
          ROSE, C., GUENTER, B., BODENHEIMER, B., AND COHEN, M. F. 1996. Efficient generation of motion transitions using spacetime constraints. In Proceedings of
          SIGGRAPH 1996, vol. 30, 147–154.
          SCHODL, A., SZELISKI, R., SALESIN, D., AND ESSA, I. 2000. Video textures. In Proceedings of SIGGRAPH 2000, 489–498.
          VEACH, E., AND GUIBAS, L. J. 1997. Metropolis light transport. In Proceedings of SIGGRAPH 1997, vol. 31, 65–76.
          WITKIN, A., AND POPOVIC, Z. 1995. Motion warping. In Proceedings of SIGGRAPH 1995, 105–108.

        
        7
        To appear in the ACM SIGGRAPH conference proceedings
        
          Figure 9: Using combinations of constraints, we can generate multiple motions interacting with each other. Here, the skeletons are constrained to be tackling each other (using hard constraints) at specified times and specified positions/orientations. We can then generate the motion that connects the sequence of tackles.
        
        8
      
    
  

</Document>
