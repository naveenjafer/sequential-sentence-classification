<?xml version="1.0" encoding="UTF-8" standalone="no"?>
<Document xmlns:gate="http://www.gate.ac.uk" name="A16_M07_Momentum-based_Parameterization_of_Dynamic_Character_Motion_ASPECT_v1.xml">


  
    386ca8d7b7c53aecc8e5cf78fb6ae5b9e541682119594cbc0fdbe24b71074b46
    3vtd
    http://dx.doi.org/10.1145/1028523.1028546
  
  
    
      Eurographics/ACM SIGGRAPH <CitSpan>Symposium on Computer Animation (2004)</CitSpan> R. Boulic, D. K. Pai (Editors)
      
        <Title>Momentum-based Parameterization of Dynamic Character Motion</Title>
      
      
        
          Yeuhi Abe C. Karen Liu Zoran Popović
        
      
      University of Washington
      <Abstract>
<Sentence aspectClass="NONE" inAbstract="true">This paper presents a system for rapid editing of highly dynamic motion capture data.</Sentence> <Sentence aspectClass="NONE" inAbstract="true">At the heart of this system is an optimization algorithm that can transform the captured motion so that it satisfies high-level user constraints while enforcing that the linear and angular momentum of the motion remain physically plausible.</Sentence> <Sentence aspectClass="NONE" inAbstract="true">Unlike most previous approaches to motion editing, our algorithm does not require pose specification or model reduction, and the user only need specify high-level changes to the input motion.</Sentence> <Sentence aspectClass="NONE" inAbstract="true">To preserve the dynamic behavior of the input motion, we introduce a spline-based parameterization that matches the linear and angular momentum patterns of the motion capture data.</Sentence> <Sentence aspectClass="NONE" inAbstract="true">Because our algorithm enables rapid convergence by presenting a good initial state of the optimization, the user can efficiently generate a large number of realistic motions from a single input motion.</Sentence> <Sentence aspectClass="NONE" inAbstract="true">The algorithm can then populate the dynamic space of motions by simple interpolation, effectively parameterizing the space of realistic motions.</Sentence> <Sentence aspectClass="NONE" inAbstract="true">We show how this framework can be used to produce an effective interface for rapid creation of dynamic animations, as well as to drive the dynamic motion of a character in real-time.</Sentence>
</Abstract>
	Categories and Subject Descriptors (according to ACM CCS) : I.3.7 [Computer Graphics]: Three-Dimensional Graphics and Realism-Animation  
    
    
      
        <H1>1. Introduction</H1>
      
      <Sentence aspectClass="NONE" inAbstract="false">Despite great advances in recent years, creating effective tools for synthesis of realistic human motion remains an open problem in computer animation.</Sentence> <Sentence aspectClass="COMMON_PRACTICE" inAbstract="false">This is particularly true for synthesis of highly dynamic character motion such as running, leaping, jumping and other athletic and acrobatic maneuvers that frequently occur in feature special effects and video games.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">Synthesizing such motions can be challenging because any physical inaccuracies in these motions are particularly noticeable.</Sentence> <Sentence aspectClass="COMMON_PRACTICE" inAbstract="false">Both spacetime optimization and controller synthesis approaches have been proposed for direct synthesis of dynamic character motion.</Sentence> <Sentence aspectClass="ADVANTAGE_DISADVANTAGE" inAbstract="false">Although these methods do satisfy physical laws, they tend to appear overly smooth and at times robotic.</Sentence> <Sentence aspectClass="DISADVANTAGE" inAbstract="false">Furthermore, these methods do not provide interactive control, often requiring considerable offline processing time before the animation sequence is generated.</Sentence> <Sentence aspectClass="DISADVANTAGE" inAbstract="false">In addition, it is difficult to achieve a graceful degradation of realism for the purpose of greater control.</Sentence> <Sentence aspectClass="ADVANTAGE" inAbstract="false">In contrast to direct synthesis, methods based on adaptation of motion capture data produce highly realistic motion, especially in the neighborhood of captured motion samples.</Sentence> <Sentence aspectClass="ADVANTAGE" inAbstract="false">They also run at interactive speeds, as they employ data interpolation techniques.</Sentence> <Sentence aspectClass="DISADVANTAGE" inAbstract="false">Unfortunately, these methods require a large number of motion samples.</Sentence> <Sentence aspectClass="DISADVANTAGE" inAbstract="false">If the animator wants to interactively control a specific parameter of the animation such as the landing foot position in a particular acrobatic stunt, the need for a large dataset is particularly pronounced: the interpolation techniques would require an already existing family of motion sequences where the only difference in motion is the landing foot position.</Sentence> <Sentence aspectClass="DISADVANTAGE" inAbstract="false">Gathering such a datataset is not only laborious, but it also requires that the captured family of motions is similar in all other respects (e.g. other landing points, initial and final state, overall style) — an aspect that is quite hard to reproduce by real actors.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">In fact, the process of generating such parameterized motions is the most challenging aspect of data acquisition for video game production [Buc].</Sentence> <Sentence aspectClass="DISADVANTAGE" inAbstract="false">In addition, the animators often wish to create non-realistic motions that defy the laws of physics, a space where motion capture simply fails to provide any samples.</Sentence> <Sentence aspectClass="NOVELTY" inAbstract="false">We take the approach to acquiring similar motions is to adapt a single motion sequence several times to synthesize a family of motions that preserve physics constraints.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">Motions created in this manner can satisfy an animator’s exact specifications with a minimum of deviation from the initial motion sequence.</Sentence> <Sentence aspectClass="NOVELTY" inAbstract="false">Ideally, we would like to use a minimal source of motion data, perhaps a single captured movement, to create a wide range of additional motions.</Sentence> <Sentence aspectClass="COMMON_PRACTICE" inAbstract="false">Recently a number of dynamic motion adaptation methods have been proposed <CitSpan>[PW99, ZH99, TSK02, SP04, SHP04]</CitSpan>, and the work presented in this paper falls into this category.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">In this paper, we describe the momentum-based motion editing technique.</Sentence> <Sentence aspectClass="NOVELTY" inAbstract="false">In contrast to the existing methods, our proposed framework is particularly robust to large-scale motion modifications.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">For example, we can adapt a forward leaping movement, to a collection of leaping movement in different directions including a backward leap, or a 360 ◦ leaping spin.</Sentence> <Sentence aspectClass="ADVANTAGE" inAbstract="false">Using our motion editing framework, we show how a family of dynamic movements can be synthesized based on the animator’s needs for interactive control.</Sentence> <Sentence aspectClass="ADVANTAGE" inAbstract="false">Because our family of motions samples the space widely, satisfies exact constraints, and otherwise deviates minimally from the original source sequence, we can use simple interpolation techniques to allow real-time exploration of this synthetic motion space.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">We describe a number of real-time animation tools that can be constructed using these synthetic motion families, such as interactive displacement of constraints (e.g. varying foot landing position), as well as inverse control examples such as the determination of the natural volleyball spike that would hit the ball arriving at a specific position in space.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">In addition, we describe how the same synthetic sampling/interpolation approach can be used to develop realtime controllers for leaping character motion, all synthesized from a single motion-captured leap.</Sentence>
      c The Eurographics Association 2004.
      Yeuhi Abe, C. Karen Liu, &amp; Zoran Popović / Momentum-based Parameterization of Dynamic Character Motion
      
        <H1>2. Related work</H1>
        <Sentence aspectClass="COMMON_PRACTICE" inAbstract="false">Recent research in computer animation focused on techniques for remapping existing data to given specifications of a new scenario.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">In this paper, we build on the research in both physicsand interpolation-based motion editing methods.</Sentence>
      
      
        <H2>2.1. Physics-based motion editing</H2>
        <Sentence aspectClass="ADVANTAGE" inAbstract="false">Optimal trajectory methods introduced by Witkin and Kass <CitSpan>[WK88]</CitSpan> provide a powerful framework for enforcing dynamic constraints while searching for the most favorable motion judged by the objective function.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">Extending physicsbased optimization to a full human figure, however, has presented a significant challenge mainly due to the nonlinearity of the dynamic constraints, and sensitivity to the starting point of the optimization.</Sentence> <Sentence aspectClass="COMMON_PRACTICE" inAbstract="false">The dependency on the initial point has been somewhat alleviated by starting out with the captured motion sequence.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">Popović and Witkin in 1999 developed a first method that transforms motion capture data while preserving physical properties <CitSpan>[PW99]</CitSpan>.</Sentence> <Sentence aspectClass="ADVANTAGE" inAbstract="false">They found solutions by performing optimizations on the reduced character model.</Sentence> <Sentence aspectClass="COMMON_PRACTICE" inAbstract="false">More recently, editing motion capture data based on spacetime optimization has become a popular strategy for producing realistic character animations [RGBC96, SP04, SHP04].</Sentence> <Sentence aspectClass="COMMON_PRACTICE" inAbstract="false">These methods provide control for modifying data while retaining physically plausible properties of captured motion by restricting the optimization space with additional kinematic constraints (e.g. [RGBC96]), or by solving within the PCA-reduced space of motions <CitSpan>[SHP04]</CitSpan>.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">It has recently been shown that relying on simplifications of dynamic constraints is not necessary if proper scaling and estimation of joint angles, torques, and Lagrange multipliers are provided <CitSpan>[SP04]</CitSpan>.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">Our work uses a similar spacetime optimization framework.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">In contrast to other approaches, we formulate significantly simpler momentum constraints on a complex character model, without solving for muscle forces explicitly, similar to <CitSpan>[LP02]</CitSpan>.</Sentence> <Sentence aspectClass="ADVANTAGE" inAbstract="false">Since we do not compute internal torques for joints, scaling and convergence issues are less critical in our optimization framework.</Sentence> <Sentence aspectClass="COMMON_PRACTICE" inAbstract="false">Our physics-based motion editing approach is based on the momentum constraints introduced by Liu and Popović <CitSpan>[LP02]</CitSpan>.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">In that work, momentum constraints were used for synthesis of highly dynamic motion from simple animations that did not contain sufficient information to synthesize the full motion.</Sentence> <Sentence aspectClass="COMMON_PRACTICE" inAbstract="false">As a result, transition poses had to be introduced to further restrict the optimization space.</Sentence> <Sentence aspectClass="ADVANTAGE" inAbstract="false">There are two main advantages of momentum constraints over the full dynamics constraints.</Sentence> <Sentence aspectClass="ADVANTAGE" inAbstract="false">First, since dynamic constraints are reduced to only global momentum patterns, we are solving for a much smaller set of unknowns, and over a much “better behaved” set of constraints.</Sentence> <Sentence aspectClass="ADVANTAGE" inAbstract="false">This allows us to find solutions quickly.</Sentence> <Sentence aspectClass="ADVANTAGE" inAbstract="false">Also, in our experience, these constraints do not suffer from many local minima, thus enabling us to find solutions significantly further away from the original motion.</Sentence> <Sentence aspectClass="ADVANTAGE" inAbstract="false">The second advantage of momentum constraints is that they encode more about the natural motion than just physical correctness.</Sentence> <Sentence aspectClass="ADVANTAGE" inAbstract="false">For example in natural motion, passive elements such as tendons and ligaments store and release energy during ballistic motion.</Sentence> <Sentence aspectClass="COMMON_PRACTICE" inAbstract="false">To model this with a full dynamic system, one would have to include a complex muscle model.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">Momentum constraints effectively record the aggregate effect of the natural torque usage and energy storage/release in a specific momentum pattern.</Sentence> <Sentence aspectClass="ADVANTAGE" inAbstract="false">This additional information embedded within the momentum constraints ensures that adapted motion is not just physically correct, but that it also constrains the motion within the momentum exchange patterns observed in nature.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">In contrast to the original paper that introduced momentum constraints, our method applies momentum constraints directly on the motion capture data.</Sentence> <Sentence aspectClass="ADVANTAGE" inAbstract="false">Our algorithm does not require any additional pose constraints at the transition points between flight and ground phases.</Sentence> <Sentence aspectClass="NOVELTY" inAbstract="false">Furthermore, we introduce a novel spline-based representation for the momentum patterns that can be used to intrinsically enforce the similarity between the resultant motion and the input motion.</Sentence> <Sentence aspectClass="ADVANTAGE" inAbstract="false">Instead of formulating a physics-based optimization, dynamic filtering is an efficient alternative for motion editing of smaller amplitude.</Sentence> <Sentence aspectClass="ADVANTAGE" inAbstract="false">Per-frame based frameworks largely reduce the computation time, providing an interactive editing interface to the user <CitSpan>[TSK02, SKG03]</CitSpan>.</Sentence> <Sentence aspectClass="DISADVANTAGE" inAbstract="false">Unfortunately, the per-frame approach means that animators can modify the spatial position of constraints, but not their position in time.</Sentence> <Sentence aspectClass="COMMON_PRACTICE" inAbstract="false">Tak et al. applied Kalman filter to estimate an optimal pose for the current frame subject to the given constraints.</Sentence> <Sentence aspectClass="COMMON_PRACTICE" inAbstract="false">The result of the estimation is then rectified by least-square-fit to ensure a physically sound motion <CitSpan>[TSK02]</CitSpan>.</Sentence> <Sentence aspectClass="COMMON_PRACTICE" inAbstract="false">Shin et al. approximated the adjustment made to the original motion capture data by correcting the momentum of the character during flight and using the balance constraints on the ground <CitSpan>[SKG03]</CitSpan>.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">In general, these methods are geared toward the local modification compared to the overall motion, such as improving the balance, whereas our approach is able to handle global changes of the motion such as transforming a forward jump to a 360 ◦ backward spin jump.</Sentence> <Sentence aspectClass="COMMON_PRACTICE" inAbstract="false">Another branch of dynamic filtering employs dynamic tracking <CitSpan>[ZH99, PR01]</CitSpan>.</Sentence> <Sentence aspectClass="ADVANTAGE" inAbstract="false">These methods combine motion capture data and dynamic simulation to retain human-like details from the data while presenting interaction with the environment.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">These methods produce motions that do not deviate significantly from the input motion, relying on the existence of captured motion that is similar to what the user intends to do.</Sentence>
        c The Eurographics Association 2004.
        Yeuhi Abe, C. Karen Liu, &amp; Zoran Popović / Momentum-based Parameterization of Dynamic Character Motion
      
      
        <H2>2.2. Interpolation-based motion editing</H2>
        <Sentence aspectClass="DISADVANTAGE" inAbstract="false">Straightforward interpolation of joint angles usually fails to preserve physical realism from the original data.</Sentence> <Sentence aspectClass="ADVANTAGE" inAbstract="false">However, many methods have shown that small modification of the motion can be easily done by linear interpolation of joint angles <CitSpan>[BW95, WP95, WH97]</CitSpan>.</Sentence> <Sentence aspectClass="COMMON_PRACTICE" inAbstract="false">Combining interpolation with kinematics constraints, Gleicher adapted original motion to a new character while maintaining environmental constraints such as foot contacts on the floor <CitSpan>[Gle98]</CitSpan>.</Sentence> <Sentence aspectClass="COMMON_PRACTICE" inAbstract="false">A more sophisticated interpolation was presented using radial basis functions to blend motion sequences with various inverse-kinematic goals <CitSpan>[RSC01]</CitSpan> or different style <CitSpan>[RCB98]</CitSpan>.</Sentence> <Sentence aspectClass="DISADVANTAGE" inAbstract="false">Unfortunately, data acquisition and post-processing for these methods present a significant challenge since motion sequences need to be carefully crafted so that they contain the same content yet different in style.</Sentence> <Sentence aspectClass="ADVANTAGE" inAbstract="false">Our approach only requires one single motion capture sequence as the seed.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">This seed is used to generate a family of motion sequences that parameterize the dynamic space.</Sentence> <Sentence aspectClass="COMMON_PRACTICE" inAbstract="false">Lee and Shin presented a multi-level B-spline representation by which they transform existing motion to satisfy desired constraints adaptively through direct manipulation <CitSpan>[LS99]</CitSpan>.</Sentence> <Sentence aspectClass="ADVANTAGE" inAbstract="false">Using B-spline representation, the motion edits can be limited to user-specified frequency bands, providing a more effective optimization framework.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">Our work adapts the idea of using spline-based representation to constrain the search of the optimization.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">We model the momentum curves by a B-spline representation which are fitted to the original motion so that the search space in the optimization is limited to solutions that have similar dynamic behavior of the original motion.</Sentence>
        Mocap Data Momentum Curve Pre-fitting Spacetime User specification Optimization Optimized Optimized Optimized motion motion motion Linear Interpolation Interpolated ..... Interpolated ..... Interpolated motion motion motion
        
          Figure 1: System overview
        
      
      
        <H1>3. Overview</H1>
        <Sentence aspectClass="NOVELTY" inAbstract="false">Our system is based on an optimization algorithm that can transform the captured motion to satisfy high-level user constraints while preserving physical realism.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">As input, the system takes a single motion capture sequence and the userspecified modification.</Sentence> <Sentence aspectClass="NOVELTY" inAbstract="false">We describe the algorithm in three separate components: Motion pre-fitting, optimization, and interpolation (see Figure 1 ).</Sentence> <Sentence aspectClass="NOVELTY" inAbstract="false">The pre-fitting optimizes a set of coefficients used to model momentum curves so that they are constrained to the similar shapes of the original motion.</Sentence> <Sentence aspectClass="NOVELTY" inAbstract="false">The system then formulates a spacetime optimization that solves for a new motion, where both high-level physical constraints and the user specification are met.</Sentence> <Sentence aspectClass="NOVELTY" inAbstract="false">With a family of such optimized motions that parameterize certain dynamic space, we can apply a simple linear interpolation to generate arbitrary new motion within the dynamic space in real-time.</Sentence>
      
      
        <H1>4. Motion editing with momentum constraints</H1>
        <Sentence aspectClass="NONE" inAbstract="false">Our algorithm adapts the momentum-based constraints <CitSpan>[LP02]</CitSpan> for the task of motion editing.</Sentence> <Sentence aspectClass="COMMON_PRACTICE" inAbstract="false">Instead of filling in missing data, motion editing must solve the converse problem of preserving the original data while still satisfying animator-imposed constraints.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">There is no need for keyframing of any kind because the motion already starts in a good initial state.</Sentence> <Sentence aspectClass="LIMITATION" inAbstract="false">Any underlying physical model employed by the system must be flexible enough to precisely describe the initial state of the motion and, at the same time, rigid enough to maintain a semblance of the original motion throughout the editing process.</Sentence>
        c The Eurographics Association 2004.
        Yeuhi Abe, C. Karen Liu, &amp; Zoran Popović / Momentum-based Parameterization of Dynamic Character Motion
      
      
        <H2>4.1. Motion pre-fitting</H2>
        <Sentence aspectClass="NOVELTY" inAbstract="false">At the heart of our algorithm is a set of full-body angular and linear momentum curves.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">These curves constrain the edited motion to the realm of physical realism without the need to simulate expensive dynamical properties such as joint torques and contact forces.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">The momentum curves are parameterized by a set of coefficients that are pre-solved to closely match the input motion.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">The advantage of this approach is twofold.</Sentence> <Sentence aspectClass="ADVANTAGE" inAbstract="false">First, a good initial state of the momentum coefficients results in rapid convergence of the optimization.</Sentence> <Sentence aspectClass="ADVANTAGE" inAbstract="false">Second, the coefficients that control the shape of the curves can be fixed throughout the editing process, effectively performing a biased search for similar motions in the momentum space.</Sentence> <Sentence aspectClass="COMMON_PRACTICE" inAbstract="false">After the motion is captured using an optical system and processed to fit the character’s skeletal structure, we employ the constraint detection technique described in <CitSpan>[LP02]</CitSpan> to partition the motion into ground-contact and flight stages.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">Since the the animator may at times wish to produce physically impossible jumps that are not constrained to the earth’s gravity, and because the sampling rate varies for each input motion sequence, we also need to determine the time interval between two animation frames.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">Gravity and time step are directly related because we can equivalently choose to find the right gravitational constant that makes the motion realistic for a given unit time step.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">During free-fall stages, the linear momentum is only affected by gravity and the angular momentum remains constant.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">By observing that the center of mass (COM) of the model must follow a parabolic trajectory, p(t), we can compute the gravitational constant, g, by solving a system of equations = 1/2gt 2 + 0 t + 0</Sentence>
      
      
        p(t) v C p(t n C n p(t n/2 C n/2
        ) = ) =
        <Sentence aspectClass="NONE" inAbstract="false">where t 0..</Sentence>
<Sentence aspectClass="NONE" inAbstract="false">n are time steps in the free-fall stage, C 0..</Sentence>
<Sentence aspectClass="NONE" inAbstract="false">n are corresponding values of the COM, and v 0 is the unknown initial velocity of the COM.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">When the body is in contact with external forces, the momentum curves can no longer be represented by a simple set of linear equations.</Sentence> <Sentence aspectClass="NOVELTY" inAbstract="false">Instead, we represent the momentum curves with a 3rd-order non-uniform B-splines for their flexibility and convenient knot based parameterization.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">In our spline representation, the first and last knots have duplicity 4 to ensure interpolation of the end points (see [FvDFH92]).</Sentence> <Sentence aspectClass="NONE" inAbstract="false">A defining characteristic of motion is the shape and magnitude of its momentum curve (see Figure 2 ).</Sentence> <Sentence aspectClass="NONE" inAbstract="false">In the case of our spline representation, the control points determine the magnitude of the curve and the spacing of the knots influence the shape.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">We note that this formulation can capture a greater variability of momentum patterns than the previously used hardwired patterns <CitSpan>[LP02]</CitSpan>.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">This is especially important when dealing with motion capture data due to wide range of different maneuvers possible in the real world.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">To find a set of control points, {c i |i ∈ 1..</Sentence>
<Sentence aspectClass="NONE" inAbstract="false">k}, and knots, {u i |i ∈ 1..</Sentence>
<Sentence aspectClass="NONE" inAbstract="false">k + 4}, that closely match the momentum pattern of the input motion, we solve the following constrained optimization problem for each momentum spline 0..</Sentence>k , 0..k+4 ):
      
      
        S(t, c u
        n
      
      
        S<CitSpan>(0)</CitSpan> m S(n) m
        = 0 =
        <Sentence aspectClass="NONE" inAbstract="false">min S i=0 ∑ (m i − S(t i )) 2 subject u i − u to i−1 &lt; ε,        for S(n) S<CitSpan>(0)</CitSpan>  ̇  ̇ i ∈ = = 1..</Sentence>
<Sentence aspectClass="NONE" inAbstract="false">k v v n 0 + n 4 where m i is the momentum of the input motion at time step i, and v i = gM, where g is the gravitational constant in the adjacent flight stage and M is the body mass of the character.</Sentence> <Sentence aspectClass="COMMON_PRACTICE" inAbstract="false">In other words, we perform a least-squares regression over the momentum curve in the ground stage, while maintaining C 1 continuity through the transitions to the flight stages.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">There are few exceptions to the problem described above.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">When there is no adjacent flight stage, we remove the constraint corresponding to v i from the statement of the problem.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">Also, the constraint corresponding to v 0 is entirely removed when pre-fitting the vertical linear momentum curve since the transition from a free-fall stage to a ground stage is typically dominated by impulsive forces, which are not C 1 continuous in the vertical momentum component.</Sentence>
      
      
        <H2>4.2. Motion editing and optimization</H2>
        <Sentence aspectClass="NONE" inAbstract="false">In this section we discuss the process of editing motions using our system.</Sentence> <Sentence aspectClass="COMMON_PRACTICE" inAbstract="false">As in <CitSpan>[LP02]</CitSpan> we model motion as an optimal dynamic process with a set of realistic constraints.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">In general terms, our condition for optimality is that the output motion be both as smooth, and as similar, to the original motion as possible.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">Constraints on the solution ensure that the character’s limb do not bend unnaturally, that the character’s feet do not pass through the ground, and that the character’s full-body momentum curve follows the path of the pre-fit momentum splines.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">The degrees of freedom to be optimized are contained in Q G, where Q is the set of joint angles through time describing the motion and G is the set of the control points controlling the momentum splines.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">In the initial state of the optimization, Q is a good initial guess at the target motion formed by linearly interpolating the original motion between user specified translations and orientations, and G contains the pre-fit momentum coefficients.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">In addition to the constraints and objectives used in <CitSpan>[LP02]</CitSpan>, we also introduce a similarity objective and a pseudo balance objective as described in the following sections.</Sentence>
        c The Eurographics Association 2004.
        Yeuhi Abe, C. Karen Liu, &amp; Zoran Popović / Momentum-based Parameterization of Dynamic Character Motion
        20 8 19 20 8 19 8 24 40 56 72 88 8 24 40 56 72 88
        
          Figure 2: Linear momentum of a jumping motion in vertical direction. The gray area indicates the flight stage. Left: The control points {c i |i ∈ 1..k}, visible as red circles, determine the magnitude of the curve. The spacing of the knots {u i |i ∈ 1..k + 4}, visible as blue triangles, influence the shape. Pre-fitting phase solves for a set of control points and knots that closely match the momentum pattern of the input motion (shown as green squares). Right: During the spacetime optimization, u i is held fixed while c i is part of free variables. In this example, the optimized control points c i result in a more energetic jumping motion.
        
      
      
        <H3>4.2.1. Similarity objective</H3>
        <Sentence aspectClass="NONE" inAbstract="false">The similarity objective is intended to keep the optimized motion as similar to the original as possible.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">We formulate this objective as the squared distance between the original vector of DOFs, Q init , and the solution vector, Q. Each joint DOF is scaled by its natural bound.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">The energy function we wish to minimize is then, E s (Q) = (Q init − Q) 2</Sentence>
      
      
        <H3>4.2.2. Pseudo balance objective</H3>
        <Sentence aspectClass="NONE" inAbstract="false">Since we do not model the specific human preference to stay out of extreme leaning movements that in real life can often cause foot slipping on the ground, there are some instances when the resulting motion would leave the character unnaturally leaning without a means of support.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">To pull the optimized solution away from these unstable regions, we include a pseudo balance objective.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">The objective we use attempts to minimize the squared distance between the COM, C(t) of model in the first time-step, t 0 , and last timestep, t f , of the initial and final ground stages of the motion.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">For interior ground stages, we instead minimize the distance between the COM of the model in the middle frame of the stage, C(t m ), and the COM of the linearly interpolated input motion, C orig (t m ), in the same frame.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">In other words, we introduce an additional objective function term, E b (Q) = (C(t 0 ) − )) 2 , for the initial and final ground</Sentence>
      
      
        C(t
        f
        <Sentence aspectClass="NONE" inAbstract="false">stage, and E b (Q) = (C orig (t m ) − C(t m )) 2 for each interior ground stages.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">We find that the correct weight of these objectives do not vary much from motion to motion and, in fact, as long as the weight is well scaled w.r.t.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">other parts of the objective function, one value tends to “fit all”.</Sentence>
      
      
        <H3>4.2.3. Spacetime optimization</H3>
        <Sentence aspectClass="NONE" inAbstract="false">To summarize, the unknowns of our system, Q and G, are the character DOFs and the control points for the momentum splines.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">Note that spline knots are omitted to maintain the similar momentum pattern of the original motion.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">The optimization enforces two types of constraints: environment constraints, K e , such as feet positions on the ground, and momentum constraints, K m .</Sentence> <Sentence aspectClass="NONE" inAbstract="false">The following spacetime formulation finds the unknowns Q and G that minimize the objective function while satisfying all the constraints: min Q,G E s (Q) + E b (Q) subject to K K e m (Q) (Q, G) = = 0 0</Sentence>
      
      
        <H3>4.2.4. User interface</H3>
        <Sentence aspectClass="ADVANTAGE" inAbstract="false">Our system provides several high level motion specification tools so that the animator never has to think of editing in terms of constrained optimization.</Sentence> <Sentence aspectClass="COMMON_PRACTICE" inAbstract="false">First, motions are automatically partitioned into alternating flight and ground stages.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">Alternatively, the user can manually adjust the partitioning to make corrections.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">Next, the user manipulates ground stages with the mouse to translate their position and turns a dial to change the orientations as desired.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">The system treats these specifications as offsets from the original state of a ground stage.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">In other words, given the original translation, q T , and original orientation, θ, of the ground stage, the user specifies offsets ∆q T and ∆θ.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">The new translation and rotation of the ground stage is then altered to be q T + ∆q T and θ + ∆θ, respectively.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">To form a good initial guess at the solution for the frames of the flight stages, the system linearly interpolates the offsets of the adjacent ground stages over each time step of the flight stage.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">The resulting motion is a crude approximation of the final result, but provides a good initial state for the spacetime optimization.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">The animator can also change the height of the trajectory in a flight stage by interactively shaping a visualization of the trajectory.</Sentence> <Sentence aspectClass="ADVANTAGE" inAbstract="false">This is particularly useful when creating non-realistic motion that defies gravity, as will be explained below.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">Once the user is satisfied with the edits, the optimization process takes between 1 to 5 minutes per motion.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">Alternatively, several motions can be generated together in a batch mode.</Sentence>
      
      
        <H2>4.3. Populating the dynamic space of motions</H2>
        <Sentence aspectClass="NOVELTY" inAbstract="false">In this section we describe a technique for generating a continuous ranges of physically plausible motions from a single motion capture sequence.</Sentence> <Sentence aspectClass="NOVELTY" inAbstract="false">The technique constructs an output motion in real-time by performing a simple weighted average over the DOFs values from a set of sample motions.</Sentence> <Sentence aspectClass="NOVELTY" inAbstract="false">A family of motions can be populated from the input motion by systematically varying the position and orientation of one or more ground stages and then performing a sequence of similar optimization.</Sentence>
        c The Eurographics Association 2004.
        Yeuhi Abe, C. Karen Liu, &amp; Zoran Popović / Momentum-based Parameterization of Dynamic Character Motion
        
          Figure 3: Left: Line motion family that varies the translation of a ground stage along a line. Middle: Grid motion family that varies the translation of the ground stage along a 2 dimensional grid. Right: Circle motion family that varies both the translation and orientation of the ground stage along a semi-circle such that the orientation of the character is always aligned with the normal vector on the arc.
        
      
      
        <H3>4.3.1. Motion families</H3>
        <Sentence aspectClass="NONE" inAbstract="false">We provide a user interface for the three most useful types of motion families(see Figure 3 ).</Sentence> <Sentence aspectClass="NONE" inAbstract="false">The first type varies the translation of a ground stage along a line, the second type varies the translation of the ground stage along a 2 dimensional grid, and the third type varies both the translation and orientation of the ground stage along a semi-circle such that the orientation of the character is consistently aligned along the normal vector of the arc.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">The size of the sample space as well as the density at which it is sampled can both be adjusted as necessary.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">Other types of motion families can be easily added.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">Once a motion family is populated, we are able to generate arbitrary intermediary motions by blending the nearest 2 n samples, where n is the number of dimensions in the parameterized space.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">We chose to use a simple linear blending method for several reasons.</Sentence> <Sentence aspectClass="ADVANTAGE" inAbstract="false">First and foremost, the algorithm is very fast and well suited to any application where the output motion must be generated “on the fly”.</Sentence> <Sentence aspectClass="ADVANTAGE" inAbstract="false">Since motion families are produced offline, they can be as densely populated as necessary to increase the accuracy of the interpolation.</Sentence> <Sentence aspectClass="ADVANTAGE" inAbstract="false">Second, since the members of a motion family are produced by the same optimization setup, varying only in specific dimensions (e.g. landing positions, height, orientation, etc), it is often the case that they blend very well and need not be sampled very densely at all.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">In our results section, 9 samples is the most we ever required to adequately sample the dynamic space of a motion.</Sentence>
      
      
        <H3>4.3.2. Foot glide</H3>
        <Sentence aspectClass="DISADVANTAGE_ADVANTAGE" inAbstract="false">Although foot glide is among the most troublesome artifacts for most motion blending techniques, we find that it is imperceptible for both the line and grid motion families.</Sentence> <Sentence aspectClass="DISADVANTAGE" inAbstract="false">However, when the global orientation and the translation of the motion are interpolated simultaneously, as is the case in the circle motion family, a very miniscule amount of foot glide becomes perceptible.</Sentence> <Sentence aspectClass="COMMON_PRACTICE" inAbstract="false">A simple fix is to apply a per-frame inverse kinematic (IK) solver to slightly adjust the lower body to satisfy the positional constraints on each foot.</Sentence> <Sentence aspectClass="ADVANTAGE" inAbstract="false">Solving IK on the lower body not only has the effect of planting the foot firmly on the ground without changing the overall looks of the motion, but is also light-weight enough to converge in real-time, as the motion is being displayed.</Sentence>
      
      
        <H3>4.3.3. Inverse control</H3>
        <Sentence aspectClass="NONE" inAbstract="false">So far we have shown how to populate the space of dynamic motion by interpolating between samples.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">Here we will discuss a more intuitive way of controlling these animations.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">In many applications the most important aspect to control is the position and time at which the character makes contact with an object in the environment.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">Consider the example of a soccer header motion, where it is required that the character’s head always makes contact with the soccer ball at the correct moment in time.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">Starting from a single input motion we can generate an arbitrary header by creating a grid motion family that varies the translation of the landing stage.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">The joint configuration at each time-step in the output motion is then defined as a vector function q(x, y,t) of the landing position, (x, y), and the time-step, t.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">If we denote the position of the character’s head by the function h(q), the problem of finding the motion that constrains the characters head to ball position p c at time t c , is reduced to that of finding values (x, y) such that p c = h(q(x, y,t c )).</Sentence> <Sentence aspectClass="NONE" inAbstract="false">This is, in turn, analogous to minimizing the energy function E(x, y) = (p c − h(q(x, y,t c ))) 2 , which can be solved efficiently by a simple gradient descent method.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">The gradients are computed using finite differences.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">One caveat is that q is actually a piecewise function that performs a bi-linear interpolation of the 4 nearest sample motions.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">When one sample motion is replaced by another in the set of 4, q ceases to be C 1 continuous, causing convergence problems with the gradient descent method.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">A simple solution is to replace the linear blending functions f (x) = x and g(x) = (x − 1) with smooth in/out functions such as f (x) = sin 2 (x) and g(x) = cos 2 (x), thereby maintaining C 1 continuity through the transitions.</Sentence>
      
      
        <H2>4.4. Interactive control</H2>
        <Sentence aspectClass="ADVANTAGE" inAbstract="false">One advantage of our motion generation algorithm is that it provides for a wide range of physically plausible animations in real-time.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">To demonstrate the full benefit of this approach, we have created a video game interface where the user controls the trajectory of a jumping character with a multi-directional control pad (see Figure 6 ).</Sentence> <Sentence aspectClass="NONE" inAbstract="false">We start with a motion capture sequence of a character making two consecutive jumps.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">The interesting aspect of this motion is that the character must exhibit foresight in the motion of the first jump, so that the correct contact forces can be generate in the intermediate ground stage, to create the necessary momentum for the second jump.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">The spacetime approach is</Sentence>
        c The Eurographics Association 2004.
        Yeuhi Abe, C. Karen Liu, &amp; Zoran Popović / Momentum-based Parameterization of Dynamic Character Motion
        p c p c = h(q(x,y,t c )) (x, y) (x, y)
        
          Figure 4: In the example of the soccer header motion, the user specifies the contact point of the head and the soccer ball p c at timestep t c . Inverse control mechanism is able to immediately determine the four nearest neighbors among the
        
        <Sentence aspectClass="NONE" inAbstract="false">sampled motions as well as their weights that interpolate the desired motion.</Sentence> <Sentence aspectClass="ADVANTAGE" inAbstract="false">An efficient gradient descent method solves for the landing position (x, y) by optimizing E(x, y) = (p c − y,t c ))) 2 .</Sentence>
      
      
        <Sentence aspectClass="NONE" inAbstract="false">h(q(x,
        ideal for editing such a motion because of the way it intrinsically models the interdependencies between different stages of a motion.</Sentence> <Sentence aspectClass="ADVANTAGE" inAbstract="false">Our approach inherits the same key benefit from spacetime, but allow us generate motions in realtime.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">In this demonstration we wish to control the horizontal translation vectors of the first and second jumps, d 1 and d 2 , respectively.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">First we generate a motion family by varying both the first and last ground stages along a 3x3 grid.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">The entire motion family then consists of 81 optimal motions resulting from permuting the 9 possible starting positions with 9 possible ending positions.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">This is necessary in order to sample the entire range of possible ground stage transitions between the two jumps.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">We are then able to populate the space between sampled motions by linearly interpolating the nearest neighbor optimal solutions.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">In this case, we have 4 dimensions in our sample space corresponding to the values of d 1 and d 2 , making for a total of 2 4 (or 16) nearest neighbor motions.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">Therefore, we can express the output motion as vector function q(d 1 , d 2 ), whenever d 1 and d 2 are within the bounds of the sample space.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">To make our demonstration even more interesting, we chain our jumping motion end to end, such that it continuously loops upon itself.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">This is done by blending the second flight stage of the first motion, q a (d a1 , d a2 ), into the first flight stage of the second motion,q b (d b1 , d b2 ).</Sentence> <Sentence aspectClass="NONE" inAbstract="false">In order to make the blending work, we simply require that d a2 = d b1 .</Sentence> <Sentence aspectClass="NONE" inAbstract="false">In order words, we require the length and direction of the blended jumps be the same.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">The end result is an interactive jumping simulation where the user controls the direction that the character jumps and then sees the motion carried out in a physically plausible manner.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">Due to the foresight discussed earlier, the character must always have prior knowledge of the next two directions it will jump.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">This causes some lag time between when the user specifies a direction and when that motion will occur, but this is only natural given the deterministic nature of the ballistic motion.</Sentence>
        
          
            
              
                
                   Motion
                   Sequences
                   Frames
                   Time
                
                
                   Forward jumps
                   1
                   46
                   2 min
                
              
              
                
                   Two-step hop
                   1
                   49
                   3.5 min
                
                
                   360 degree spin
                   1
                   79
                   3.5 min
                
                
                   Volleyball slam
                   9
                   44
                   17 min
                
                
                   Interactive controller
                   81
                   56
                   4.5 h
                
              
            
          
          Motion Sequences Frames Time Forward jumps 1 46 2 min Two-step hop 1 49 3.5 min 360 degree spin 1 79 3.5 min Volleyball slam 9 44 17 min Interactive controller 81 56 4.5 h
          Table 1: Computation time for optimizations
        
      
      
        <H1>5. Results</H1>
        <Sentence aspectClass="NONE" inAbstract="false">The motion sequences in our demonstration were captured at 120 frames per second using an optical motion capture system.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">The character is composed of 18 rigid links and 43 degrees of freedom.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">S0<CitSpan>(3)</CitSpan> rotations are expressed in exponential map representation.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">The mass distribution of the model is an appropriately scaled version of the population average as obtained from <CitSpan>[dL96]</CitSpan>.</Sentence> <Sentence aspectClass="COMMON_PRACTICE" inAbstract="false">We used SNOPT <CitSpan>[GSM96]</CitSpan>, a nonlinearly-constrained optimization package, for solving spacetime optimization, as well as for pre-fitting the momentum curves.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">Most edits shown in the accompanying video clips were done in less than 1 minute.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">The optimization process for each motion took on the order of 2 to 4 minutes to fully converge on a 2Ghz Pentium 4 machine (see Table 1 ).</Sentence>
      
      
        <H2>5.1. Motion editing</H2>
        <Sentence aspectClass="NONE" inAbstract="false">Our system provides a set of UI tools to help the user rapidly specify modifications to existing motions.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">In a hopping example, the animator interactively manipulates the position, height, and orientation of each ground stage.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">The character must cover a longer distance, reach a greater height and assume a new orientation in the modified hopping motion, so she must lower her center of mass, lean farther to the right, and pivot slightly in preparation for the take-off.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">Despite these changes, the resultant motion remains stylistically similar to the original.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">To show that our system is capable of making drastic changes from the original motion, we edited the same hopping motion to exhibit a 360 ◦ spin followed by a 180 ◦ spin in the opposite direction(see Figure 5 ).</Sentence>
      
      
        <H2>5.2. Real-time interpolation</H2>
        <Sentence aspectClass="NONE" inAbstract="false">In order to demonstrate real-time motion interpolation we modified a motion with two consecutive leaps.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">We let the user control the landing and take-off positions along an evenly spaced grid to generate a set of parameterized motions.</Sentence> <Sentence aspectClass="ADVANTAGE" inAbstract="false">Since the interpolation can be performed in real-time, we are able to generate a jumping motion with arbitrary takeoff and landing positions within the parameterized space in an interactive fashion.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">Another example shows a soccer header motion observed to miss its target.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">First, we correct the motion by increasing the height of the jump to meet the ball at the point of contact.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">Next, we use our editing algorithm to generate a motion family parameterized over the space of the landing position of the motion.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">By interpolating between the optimal motions, we are able to generate arbitrary intermediary motions where the character contacts the ball at any location within the sampled space, in real-time.</Sentence>
        c The Eurographics Association 2004.
        Yeuhi Abe, C. Karen Liu, &amp; Zoran Popović / Momentum-based Parameterization of Dynamic Character Motion
      
      
        <H2>5.3. Inverse control</H2>
        <Sentence aspectClass="COMMON_PRACTICE" inAbstract="false">A more intuitive way to edit motion capture data with arbitrary positional constraints is to use our real-time inverse control mechanism.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">In the volleyball slam example, the user interactively specifies the position of the character’s hand in mid-flight.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">Our system immediately determined the correct linear interpolation of 4 nearest neighbor samples to meet the positional constraint on the hand.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">The brightness of the sample motions on the floor indicates the weights associated with each sample.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">We used 9 sampled motions which are all edits of the same input sequence.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">The demonstration shows various slam motions being generated in real-time by using the trajectory of the volleyball to guide the character’s motion.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">(see Figure 6 ).</Sentence>
      
      
        <H2>5.4. Non-realistic motion</H2>
        <Sentence aspectClass="NOVELTY" inAbstract="false">Our system can also be used to create a class of nonrealistic motions that allow the character to exhibit superhuman strength and to defy the laws of physics.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">Consider an example where we wish to edit a jumping motion to reach a higher mid-point in the same time span as the the original motion.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">The first observation to make is that this is physically impossible without altering the gravitational constant, which dictates the maximum rate at which the character returns to the ground from the height of the jump.</Sentence> <Sentence aspectClass="ADVANTAGE" inAbstract="false">In our system it is easy to alter the gravitational constant in one or more ground stages.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">Still, the character must gain the momentum required to achieve the specified height on takeoff and, subsequently, absorb the same amount of momentum on landing.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">This requires a super-human muscle strength, but since we do not directly model muscle forces, and we place no limits on their magnitude, our system can easily handle these imaginary circumstances.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">From the animators perspective, editing non-realistic motion is the same as editing any other motion.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">To increase the height of a flight stage, the animator simply manipulates a visualization of the trajectory of the motion in the flight stage to the required height, and then specifies whether the system should change gravity or, alternatively, the total time in the flight stage.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">If the animator chooses to leave the gravity unaltered, the system increases the length of the time-step in each frame of the flight stage and then continues the editing process as normal.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">In one example, we edited a forward jump into a 2-meter-long backward jump (see Figure 7 ).</Sentence>
      
      
        <H1>6. Conclusion</H1>
        <Sentence aspectClass="NONE" inAbstract="false">This work builds on the research in both physics-based motion synthesis and interpolation-based motion editing approaches.</Sentence> <Sentence aspectClass="NOVELTY" inAbstract="false">In this paper we suggest that using physics-based adaptation to create motion samples for the purpose of data interpolation is perhaps a "sweetspot" between these two approaches.</Sentence> <Sentence aspectClass="NOVELTY" inAbstract="false">Once the dataset is created, this paradigm allows animators to interactively edit the realistic dynamic motion.</Sentence> <Sentence aspectClass="NOVELTY" inAbstract="false">The primary contribution of this work is a new momentum-based method for adaptation of ballistic character movement.</Sentence> <Sentence aspectClass="ADVANTAGE" inAbstract="false">In contrast to previous dynamic-based adaptation methods, our framework can produce an wide range of motions that are significantly different from the original motion.</Sentence> <Sentence aspectClass="ADVANTAGE" inAbstract="false">Our method does not require model reduction, or a reduced motion space.</Sentence> <Sentence aspectClass="ADVANTAGE" inAbstract="false">Because we do not solve for the generalized forces for each joint angle, our method is also significantly faster than other physics-based transformation methods.</Sentence> <Sentence aspectClass="ADVANTAGE" inAbstract="false">This speed allows us to create a large number of motions within a reasonable time.</Sentence> <Sentence aspectClass="NOVELTY" inAbstract="false">Once the family of parameterized motion samples has been generated, we describe an interactive framework where the animator can explore the space of realistic motions.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">We also show how the same framework can be adapted for inverse control.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">Finally, we show how real-time data-driven controllers for realistic human motion can be constructed from a single motion capture sequence.</Sentence> <Sentence aspectClass="LIMITATION" inAbstract="false">Naturally, our framework does not handle all realistic character motions.</Sentence> <Sentence aspectClass="LIMITATION" inAbstract="false">It specifically applies to highly-dynamic motions with ballistic stages.</Sentence> <Sentence aspectClass="LIMITATION" inAbstract="false">We suspect that momentumbased approach would not be well suited for less energetic motions such as walking.</Sentence> <Sentence aspectClass="LIMITATION" inAbstract="false">Furthermore, the number of samples required is exponentially proportional to the number of dimensions, thus the current framework is hindered by the offline computation of a large dataset.</Sentence> <Sentence aspectClass="COMMON_PRACTICE" inAbstract="false">There are several ways to facilitate the computation by taking advantage of the fact that we are solving a sequence of very similar problems.</Sentence> <Sentence aspectClass="COMMON_PRACTICE" inAbstract="false">A more intelligent sampling strategy is essential for generalizing our approach to a multi-dimensional dynamic space.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">Because our model does not account for realistic muscle strength, and friction during ground contact there are some extreme cases which do not produce realistic motion.</Sentence> <Sentence aspectClass="COMMON_PRACTICE" inAbstract="false">Adding heuristics such as balance during contact can to a large extent eliminate these problems.</Sentence>
      
      
        <H1>7. Acknowledgments</H1>
        <Sentence aspectClass="NONE" inAbstract="false">Special thanks go to Mira Doncheva for her assistance with creating videos.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">We also thank Keith Grochow for his help with processing motion capture data.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">This work was supported by the UW Animation Research Labs, NSF grants CCR-0092970, ITR grants IIS-0113007, EIA-0121326, NSF REU grant, Alfred P. Sloan Fellowship, Electronic Arts Corporation, Sony and Microsoft Research.</Sentence>
        c The Eurographics Association 2004.
        Yeuhi Abe, C. Karen Liu, &amp; Zoran Popović / Momentum-based Parameterization of Dynamic Character Motion
        
          
          Figure 5: A forward hopping motion (shown in yellow) is modified to make a 360 degree spin in the clockwise direction followed by a 180 degree spin in the opposite direction (shown in blue).
        
        
          
          Figure 6: Left: For a volleyball slam motion, the user interactively specifies the position of the character’s hand in mid-flight. The system then determines the correct linear interpolation of the sampled motions to meet the positional constraint on the hand. Middle: The volleyball motion in profile. Right: The user interactively controls the direction the character jumps with a multi-directional control pad.
        
        
          Figure 7: The timeline of this animation goes from left to right. To demonstrate a motion that is impossible to achieve in the real world, the animator altered a forward jump to a 2-meter-long backward jump.
        
        c The Eurographics Association 2004.
        Yeuhi Abe, C. Karen Liu, &amp; Zoran Popović / Momentum-based Parameterization of Dynamic Character Motion
      
      
        <H1>References</H1>
        
          [Buc] B UCHANAN J.: Personal communication. Electronic Arts.
          [BW95] B RUDERLIN A., W ILLIAMS L.: Motion signal processing. In Computer Graphics (SIGGRAPH 95 Proceedings) (Aug. 1995), pp. 97– 104.
          [dL96] DE L EVA P.: Adjustments to ZatsiorskySeluyanov’s segment inertia parameters. J. of Biomechanics 29, 9 (1996), 1223–1230.
          [FvDFH92] F OLEY J., VAN D AM A., F EINER S. K., H UGHES J.: Computer Graphics: Principles and Practice. Adidison Wesley, 1992.
          [Gle98] G LEICHER M.: Retargeting motion to new characters. In Computer Graphics (SIGGRAPH 98 Proceedings) (July 1998), pp. 33– 42.
          [GSM96] G ILL P., S AUNDERS M., M URRAY W.: SNOPT: An SQP algorithm for large-scale constrained optimization. Tech. Rep. NA 96-2, University of California, San Diego, 1996.
          [LP02] L IU C. K., P OPOVI C  ́ Z.: Synthesis of complex dynamic character motion from simple animations. In Proceedings of the 29th annual conference on Computer graphics and interactive techniques (2002), ACM Press, pp. 408–416.
          [LS99] L EE J., S HIN S. Y.: A hierarchical approach to interactive motion editing for human-like figures. In Computer Graphics (SIGGRAPH 99 Proceedings) (Aug. 1999).
          [PR01] P OLLARD N. S., R EITSMA P. S. A.: Animation of humanlike characters: Dynamic motion filtering with a physically plausible contact model. In Yale Workshop on Adaptive and Learning Systems (2001).
          [PW99] P OPOVI C  ́ Z., W ITKIN A. P.: Physically based motion transformation. In Computer Graphics (SIGGRAPH 99 Proceedings) (Aug. 1999), pp. 11–20.
          [RCB98] R OSE C., C OHEN M. F., B ODENHEIMER B.: Verbs and adverbs: Multidimensional motion interpolation. IEEE Computer Graphics &amp; Applications 18, 5 (Sept. – Oct. 1998).
          [RGBC96] R OSE C., G UENTER B., B ODENHEIMER B., C OHEN M.: Efficient generation of motion transitions using spacetime constraints. In Computer Graphics (SIGGRAPH 96 Proceedings) (1996), pp. 147–154.
          [RSC01] R OSE C. F., S LOAN P.-P. J., C OHEN M. F.:  Artist-directed inverse-kinematics using radial basis function interpolation. In EG 2001 Proceedings, Chalmers A., Rhyne T.-M., (Eds.), vol. 20(3) of Computer Graphics Forum. Blackwell Publishing, 2001, pp. 239–250.
          [SHP04] S AFONOVA A., H ODGINS J., P OLLARD N.: Synthesizing physically realistic human motion in low-dimensional, behavior-specific spaces. In Proceedings of the 31st annual conference on Computer graphics and interactive techniques (2004), ACM Press.
          [SKG03] S HIN H. J., K OVAR L., G LEICHER M.: Physical touch-up of human motions. In Pacific Graphics 2003 (Oct. 2003).
          [SP04] S ULEJMANPASIC A., P OPOVI C  ́ J.: Adaptation of performed ballistic motion. ACM Transactions on Graphics (2004).
          [TSK02] T AK S., S ONG O.-Y., K O H.-S.: Spacetime sweeping: An interactive dynamic constraints solver. In Proceedings of the Computer Animation 2002 (2002).
          [WH97] W ILEY D. J., H AHN J. K.: Interpolation synthesis of articulated figure motion. IEEE Computer Graphics and Applications 17, 6 (Nov./ Dec. 1997), 39–45.
          [WK88] W ITKIN A., K ASS M.: Spacetime constraints. In Computer Graphics (SIGGRAPH 88 Proceedings) (1988), pp. 159–168.
          [WP95] W ITKIN A., P OPOVI C  ́ Z.: Motion warping. In Computer Graphics (SIGGRAPH 95 Proceedings) (Aug. 1995), pp. 105–108.
          [ZH99] Z ORDAN V. B., H ODGINS J. K.: Tracking and modifying upper-body human motion data with dynamic simulation. In Computer Animation and Simulation ’99 (Milano, Italy, September 1999), Eurographics. ISBN 3-21183392-7.
        
        c The Eurographics Association 2004.
      
    
  

</Document>
