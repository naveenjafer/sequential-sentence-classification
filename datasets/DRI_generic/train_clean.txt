Problem	Local mass conservation prevents small scale details of the free surface from disappearing, a problem that plagues many previous approaches, while global mass conservation ensures that the total volume of the liquid does not decrease over time.
Result	Our method handles moving solid boundaries as well as cells that are partially filled with solids.
Result	Due to its stability, it allows the use of large time steps which makes it suitable for both off-line and real-time applications.
Method	We achieve this by using density based surface tracking with a novel, unconditionally stable, conservative advection scheme and a novel interface sharpening method.
Method	While our approach conserves mass, volume loss is still possible but only temporarily.
Method	With constant mass, local volume loss causes a local increase of the density used for surface tracking which we detect and correct over time.
Result	We also propose a density post-processing method to reveal sub-grid details of the liquid surface.
Result	We show the effectiveness of the proposed method in several practical examples all running either at interactive rates or in real-time.
Problem	Tracking the free surface of a liquid is an important and challenging problem.
Background	For an overview of existing methods we recommend the class notes of Wojtan et al. [WMFB11].
Background	The most popular approach is to advect a scalar field with the fluid and define the liquid surface to be one of the isosurfaces.
Background	The main advantage of this class of methods is that they handle topological changes implicitly in contrast to mesh-based tracking methods.
Background	Until recently, the level set method was the method of choice in graphics.
Background	Here, the signed distance field is used as the scalar field with the zeroiso-surface as the liquid surface.
Problem	A well known drawback of the level set method is that volume is lost both globally and locally.
Problem	With global volume loss the water level decreases over time while local volume loss causes small detail such as thin sheets and droplets to disappear.
Problem	A way to alleviate this problem is to introduce Lagrangian components such as particles [FF01], [EMF02] or triangle meshes [BGOS05].
Problem	Even though these methods reduce volume loss, they cannot guarantee complete volume conservation.
Problem	Moreover, Lagrangian components add significant run-time cost and complicate the implementation significantly, especially for GPUs.
Background	As an alternative to the signed distance field, [MMTD07] in- troduced the idea of using a density field as the scalar field for surface tracking with the liquid surface being the 0.5 isosurface.
Background	This density field is not to be mistaken for the density field of the liquid.
Background	In incompressible fluid simulations, the fluid-density is 1 everywhere and therefore not stored.
Method	So in what follows, we use the symbol ρ for the surface density.
Method	We chose to use surface density instead of the signed distance field because there are advection methods that strictly conserve quantities like density such as the one proposed by [LAF11].
Method	Their advection method is unconditionally stable and fully conservative.
Method	With this approach, the overall mass defined by the surface density is conserved.
Method	Since the surface density can deviate from 1 temporarily, the overall volume may vary over time though.
Method	However, in contrast to the level set method where such variations go unnoticed, volume deviations are reflected in the density field.
Result	In this paper we propose several methods to preserve volume both globally and locally using the information stored in the density field.
Problem	Ideally, the surface density has the form of a step function at the liquid-air interface.
Problem	Over time, however, the initially sharp boundary blurs out due to numerical diffusion.
Background	Therefore, [MMTD07] apply a sharpening filter at each time step which conserves mass globally but not locally.
Result	We propose a new sharpening method which conserves mass both locally and globally.
Background	3D Eulerian liquid simulation was introduced to computer graphics by Foster and Metaxas [FM96] who used a finite difference approach to solve the governing equations.
Background	Later Foster and Fedkiw [FF01] employed the semi-Lagrangian method introduced by Stam [Sta99] to solve the advection term and the level set method and particles to track liquid surface.
Background	Enright et al. [EMF02] devised the Particle Level Set (PLS) method which uses particles on both sides of liquid-air interface to reduce volume loss.
Background	Since then, many methods have been proposed to further improve the accuracy of Eulerian surface tracking.
Background	Various approaches have been proposed to track the liquid domain more faithfully.
Background	[BGOS05] used a triangle mesh representation in connection with a level set grid, [HK10] augmented the level set grid with quadrature points.
Background	Grid-less methods work with Lagrangian elements only such as particles [ZB05], [APKG07] or [YT10], triangles meshes [M 09],  ̈ [BB09] and [WTGT10].
Problem	In this paper we focus on fluid mass and volume conservation.
Background	A popular way to compensate volume gain or loss is to modify the divergence of the velocity field as proposed in [FOA03].
Background	This technique was extended and used for con∗ serving volume of bubbles [KLL 07], highly deformable objects [ISF07] and liquids [MMTD07].
Background	The problem of loss of liquid mass and momentum has also been addressed by proposing elaborate advection methods such as BFECC [KLLR05], modified MacCormack ∗ [SFK 08], derivatives advection [KSK08] and conservative semi-Lagrangian advection [LGF11], [LAF11].
Background	As an alternative to level-set, the fluid domain can be tracked with a Volume-of-Fluid (VOF) approach [HN81] where the volume fraction of fluid in each cell is evolved over time.
Background	With proper care, VOF can be made mass conserving.
Problem	However, despite several improvements in subsequent works such [PP04], [AGDJ08], reconstructing surface normal and curvature from VOF is still difficult.
Background	Sussman and Puckett [SP00] proposes coupled Level Set and Volume-ofFluid (CLVOF) which track the fluid interface with both representations, where VOF is used for re-initializing the Level Set.
Background	The surface can then be extracted from the Level Set.
Background	CLVOF is extended to handle multiple interfaces in [KPyNS10].
Background	The downside of CLVOF is the need to use two representations which can be quite computationally intensive.
Background	An alternative to VOF is to track a smeared-out surface density and keep it relatively sharp with a sharpening operation.
Background	This method was introduced to computer graphics by Mullen et al. [MMTD07].
Method	Our fluid domain tracking approach builds upon this work and make it conserve mass both locally and globally.
Background	Apart from the Eulerian formulation we use, there are many alternative models to simulate 3D liquids such as the LatticeBoltzmann method [TR04] and [TR09], approaches based on the discrete sin-cosine transform [LR09] or particle based ∗ methods such as [MCG03], [PTB 03], [APKG07], [SP09], and [SG11].
Method	The equations are solved in the domain specified by a surface density field ρ [MMTD07], in the region where ρ > 0.5.
Method	The interaction of the liquid with the environment is handled by considering the appropriate Dirichlet and Neumann boundary conditions.
Method	We discretize the simulation domain using a regular staggered grid [HW65].
Method	The x, y and z components of fluid velocity u = (u, v, w) are stored at the center of the faces perpendicular to the x, y and z axis, respectively.
Method	The scalar pressure p and the density ρ are stored at cell centers following [MMTD07].
Method	Our time integration scheme is summarized in Algorithm 1.
Method	The overall structure is the same as the one proposed in [MMTD07] with our novel modifications to the advection, sharpening and pressure incompressibility enforcement steps.
Method	Then, we advect the surface density field and sharpen it.
Method	After this we advect the velocity field and take external forces into account.
Method	Finally, we enforce incompressibility by making the velocity field divergence free.
Method	To extrapolate the velocities from inside the liquid into the surrounding air we use the scheme described in [CM11b], i.e. we apply the method of [JRW07] to derive the velocities a few grid cells away from the interface and then extrapolate based on a hierarchy of grids to obtain velocities far away from the surface.
Method	We advect ρ using our unconditionally stable conservative advection method which we derived from the method proposed by Lentine et al. in [LGF11] and [LAF11] and improved in terms of computational cost.
Background	Lentine et al. [LGF11] modified the semi-Lagrangian advection scheme to conserve mass by ensuring that each cell distributes all its mass of the current time step among some cells at the next time step.
Method	Let A be the matrix of the discretized advection operator such that ρ n+1 = Aρ n , where ρ n and ρ n+1 are the density in the current and the next time step respectively.
Method	Let w ij − (and w + ij ) represent the fraction of value that cell i gives to cell j which is found by backward (and forward) tracing and computing the tri-linear interpolation weights.
Method	The entries of A in the standard semi-Lagrangian advection is hence A i j = w − ji .
Method	Then, β j = ∑ i A i j is the fraction of mass from cell j that gets advected.
Method	To ensure that mass is conserved, A needs to be modified such that all the β j are 1.
Background	Lentine et al. [LGF11] achieve this by first iterating through all cells j with β j > 1 and re-scaling all A i j to A i j /β j .
Background	In a second step they iterate through all cells j with β j < 1 and forward trace the velocity field to adding the weights (1 − β j ) by distributing them among the A k j , where k are the cells reached by forward tracing and tri-linear interpolation.
Background	At this point, all the β j are 1, i.e. A is mass conserving.
Background	This method works well for compressible flow on fine grids.
Background	However, as discussed in [LAF11], the scheme produces artifacts when used for incompressible flow on coarser grids.
Method	The problem is due to the clamping of the β j by re-scaling which limits the amount of density that reaches certain cells.
Method	An indicator of this amount are the γ i = ∑ j A i j .
Background	The traditional semi-Lagrangian method ensures that all the γ i are 1 while the β j are arbitrary.
Background	In contrast, the scheme described above ensures that all the β j are 1, while the γ i are arbitrary.
Background	Lentine et al. [LAF11] propose a method to ensure the β j are all 1 while the γ i stay close to 1.
Background	To this end they keep track of the cumulative γ i over time as separate variables.
Method	The matrix A is computed by performing multiple forward and backward traces as follows: 1.
Method	Advect γ i using the backward semi-Lagrangian method (set to 1 in the first time step).
Method	Compute A by performing a backward tracing step as before, i.e. A i j = w − ji .
Method	Scale A by the γ i , i.e. A i j A i j /γ i .
Method	Compute the β j from A. 5.
Method	Forward trace the velocity field to add the weights (1 − β j ) to A for all cells j where β j < 1 by distributing them among the A k j , where k are the cells reached by forward tracing and tri-linear interpolation as before, i.e. A k j += (1 − β j )w + jk .
Method	Compute the new γ i from the updated matrix A. 7.
Method	Scale A by the γ i , i.e. A i j ← A i j /γ i .
Method	Re-compute the β j from the updated matrix A. 9.
Method	Clamp the β j to 1 by re-scaling A i j ← A i j /β j .
Method	Re-compute the γ i from the updated A. 11.
Method	Evaluate ρ n+1 = Aρ n .
Method	At this point, all the β j are 1 but the γ i might still deviate from 1.
Background	To bring them even closer to 1 Lentine et al. apply a diffusion step on ρ n+1 and the γ i .
Background	They iterate through all the cells dimension-by-dimension.
Method	If, for two neighboring cells i and j, γ j > γ i , they move ρ j (γ j − γ i )/2γ j from cell j to cell i and set both γ j and γ i to γ j +γ 2 i .
Method	If γ j < γ i , the flow happens in the opposite direction.
Method	This process is repeated 1 to 7 times per time step.
Method	Note that these diffusion iterations do not affect the β j , so they remain 1.
Method	Implementing the method described above on a GPU would require 5 scatter passes per iteration in steps 4, 6, 8, 10, and 11.
Method	Scattering is expensive on GPU’s because it either requires atomic operations or a prefix-scan.
Method	We propose a modification of this method.
Method	The basic idea is to reorder the forward tracing and the re-scaling steps to simplify the calculations.
Method	The resulting discrete conservative advection operator is not the same as the one computed with the original scheme.
Method	However, both are just approximations to the doubly-stochastic matrix (all rowand column sums are one) closest to the original discrete advection operator.
Method	While the visual results are of similar quality as shown in Figure 2 and the accompanying video, our simplification reduces the number of scatter passes from 5 to 3.
Method	Another advantage of our new scheme is that A does not need to be stored explicitly because the order of the operations allow for updating ρ n+1 , β and γ directly.
Method	Not storing A explicitly is possible in the original scheme as well but it would complicate the process considerably and would require even more scatter operations.
Method	Here is our modified scheme: 1.
Method	Advect γ i using the semi-Lagrangian method (set to 1 in the first time step).
Method	Initialize β ← 0.
Method	Add the weights γ i to β by distributing them among the β l , where l are the cells reached by backward tracing and tri-linear interpolation, i.e. β l += w − li γ i .
Method	Evaluate ρ n+1 from ρ n and γ from γ by backward tracing and tri-linear interpolation from cells l but this time scale the weights by max(1,β γ i l ) , i.e. ρ n+1 i += ∑ l max(1,β γ i l ) w − li ρ n l ) 5.
Method	γ ← γ .
Method	(This can be done in-place during the previous step).
Method	For each cell j whose β j < 1, add ρ n j (1 − β j ) to ρ n+1 by distributing the value among the ρ n+1 k , where k are the cells reached by the forward tracing and tri-linear interpolation, i.e. ρ k n+1 += ρ n j (1 − β j )w + jk .
Method	Similarly, for each cell j whose β j < 1, add (1 − β j ) to γ by distributing the value among the γ k , where k are the cells reached by the forward tracing and tri-linear interpolation, i.e. γ k n+1 += γ n j (1 − β j )w + jk .
Method	These two steps can be done concurrently.
Method	Apply diffusion as in the original approach.
Method	This modified method only requires 3 scatter passes in the steps 3, 6, and 7.
Method	As demonstrated in Table 1 , our method keeps γ in a similar range to that of [LAF11], while [LGF11] has a much larger range, resulting in visible compressibility artifacts.
Method	The technique above guarantees that mass is conserved.
Method	However, the density field smooths out over time blurring the 0.5 iso-contour with the effect that we can no longer track the movement of the liquid surface accurately.
Method	We solve this problem by manipulating ρ to sharpen the interface.
Method	The parameter τ controls the maximum difference in density between two adjacent cells, which we set to 0.4 as in [MMTD07].
Method	This yields the following density correction:
Method	This update sharpens the interface.
Method	However, it does not conserve mass.
Background	Mullen et al. [MMTD07] modify it to conserve mass by summing up the mass change due to this update across all cells.
Background	Then they distribute a fraction of the total mass change back to each cell based on a local area measure.
Background	This successfully conserves mass globally.
Background	One artifact of this approach is that mass moves far, potentially across the entire simulation domain.
Background	This problem can be reduced by re-distributing mass only within connected regions as pro∗ posed by [KLL 07].
Background	However, even with this technique, local mass loss can still occur due to moving mass away from small features resulting in the disappearance of small surface details.
Background	The mass conserving sharpening method of [MMTD07] transfers the mass from the liquid balls to the pool causing them to disappear mid-air.
Method	We propose a novel method to conserve mass during the sharpening phase that conserves mass both locally and globally.
Method	In the first line we make sure that ρ ≥ 0 at the next time step.
Method	We also clamp small positive densities to zero so that we do not have to apply the sharpening operator to this cell at the next time step, thus reducing computation cost.
Method	In the second line we make sure that cells with ρ > 0.5 are not modified.
Method	This way mass only moves from the air side to the liquid side.
Method	Then we update ρ i using this modified ∆ρ i in Equation 16.
Method	We then add back −∆ρ i by using Algorithm 2.
Method	TraceAlongField determines where to put the lost mass.
Method	It starts from the cell center and follows the gradient field of the density ρ until it reaches the 0.5 iso-contour.
Method	The tracing stops if a predefined distance D∆x is reached or if it crosses a solid boundary.
Method	This is done using multiple forward Euler sub-steps.
Method	ScatterValue deposits −∆ρ i to nearby grid points using tri-linear weights.
Method	If a grid point is in a solid we set the corresponding weight to zero and re-normalize the weights.
Method	We use values of D between 1.1 to 3.1 in all of our examples.
Method	So far, the method does not take solid fraction and solid velocity into account.
Method	We use u s = (u s , v s , w s ) for the solid velocity and V i for the fraction of non-solid matter, i.e. fluid and f f f air in cell i.
Method	The scalars V i+( 1 ,0,0) , V i+(0, 1 ,0) , and V i+(0,0, 1 ) 2 2 2 represent the fraction of non-solid area of the positive x, y, and z faces respectively.
Method	During the simulation, the value of ρ i can become larger than V i in some cells which is a non-valid state.
Method	We handle the situation differently depending on whether the cell is partially solid (V i < 1) or completely non-solid (V i = 1).
Method	If the cell is partially solid, we first compute the excess density d = ρ i − V i .
Method	When then follow the gradient of the solid signed distance function away from the solid for a distance of S∆x and scatter d to nearby grid points.
Method	After this we subtract d from ρ i .
Method	This method keeps ρ i ≤ V i in most cells near solid boundary and guarantees ρ i = 0 inside the solid.
Method	We use S = 1 in all of our examples.
Method	With this choice excess density gets removed from solid quickly enough to not cause visual artifacts.
Method	The case where V i = 1 is handled in the incompressibility enforcement step described in the next section.
Method	To enforce incompressibility, we first compute the pressure using a variational framework [BBB07] and then use the pressure gradient to make velocity field divergence free.
Method	The tricky part in our case is to determine the fraction of liquid in each cell.
Method	This fraction is used to decide whether a cell is included in the linear pressure solve.
Method	It is also needed in the ghost fluid method [ENGF03] to accurately handle the liquid-air boundary.
Method	However, we cannot directly use ρ because a cell with V < 0.5 will likely have ρ < 0.5 causing the solver to treat it erroneously as air.
Method	Notice that cells that are completely solid (V = 0) have ρ = 0.
Method	We then extrapolate ρ from cells that have V > 0 to adjacent cells with V = 0 so they are included in the linear system.
Method	For the ghost fluid method, we also need a signed distance function near the free surface.
Method	We approximate this field by defining φ i = −(ρ i − 0.5)∆x and use the method of [CM11a] to compute the coefficients of linear system for pressure projection.
Method	To handle the cells with ρ i > 1 (whether or not V = 1 or V < 1), we add min(λ(ρ i −1),η) to the divergence, where we ∆x use λ = 0.5 and η = 1 in all our examples.
Method	This artificial divergence pushes the excess density away from the cells whose ρ > 1.
Background	Mullen et al. [MMTD07] also added this term to the divergence but with λ = 1 and η = ∞ which can cause stability problems when ρ is much larger than 1.
Method	A scenario in which this happens is when liquid flows very fast towards a solid boundary and gets reflected due to our method for removing excess density from the solid.
Method	Adding additional divergence is important because in our case, ρ > 1 results in visual volume loss.
Method	With the method described above, this problem gets gradually corrected over time.
Method	We solve for the pressure p with the multigrid method of [CM11a] which enforces separating solid boundary conditions.
Method	Finally, we use the pressure field to make the velocity field divergence free.
Method	For rendering, we extract the triangle mesh of the 0.5 isocontour of ρ using the marching cubes method [LC87].
Background	This approach is typically used in level-set based liquid simulations as well to extract the zero contour of the signed distance field [EMF02].
Method	The surface density ρ contains small scale details that are not captured by the 0.5 iso-contour.
Method	Here, the regions where 0 < ρ < 0.5 represent features such as small splashes and thin sheets that are too small to be captured with the grid resolution used.
Method	In the level-set approach, these features are destroyed by the redistancing step.
Method	To bring out these small scale details in surface rendering, we propose a post processing method.
Method	An important observation is that regions in which 0 < ρ < 0.5 do not necessarily represent small scale features.
Method	They also exist on the air side of the surface of large liquid regions.
Method	In the latter case, we want to leave ρ unchanged but in the former we want to scale up ρ so that the features appear in the 0.5 iso-surface.
Method	To this end, we define an additional function γ i = 2 min(ρ i , 0.5) and define the regions in which ρ needs to be scaled up as the regions where γ ≤ 0.5.
Method	So far, the two cases above are not distinguished.
Method	However, this can be achieved by applying a Gaussian blur filter to γ.
Method	Now, since γ > 0.5 inside liquid, those values spread across the interface and cause γ to raise toward 1.
Method	In contrast, since γ < 0.5 everywhere inside small scale features, blurring will still result in γ being small.
Method	We then define ρ i = min(max(γ ρ i i ,θ),1) and extract the liquid surface as the 0.5 iso-surface of this modified density field.
Method	We used σ = 2∆x for the Gaussian blur filter and θ = 0.01 in this example.
Future Work	A way to improve the results further would be to apply thinning to the parts of the surface that come from region with ρ < 0.5 in order to compensate for the density up-scaling.
Future Work	This is part of our future work.
Method	We implemented our method using CUDA and ran the simulations on an NVIDIA GTX 680.
Method	For all the examples we used a time step size of 1/30s, ∆x = 0.05m, gravity 10m/s 2 and D = 2.1.
Method	Density post-processing was turned off unless otherwise stated.
Method	Our code run at interactive rates in all examples.
Result	Parameter tuning to get visually appealing results did not take much time.
Method	We compared our method with the particle level set (PLS) approach [EMF02].
Result	Our method conserves the liquid’s mass as expected and prevents the water level from decreasing.
Result	In contrast, with PLS, most of the liquid disappears in the course of the simulation due to the large time step size used.
Method	We used the PLS implementation of [MF] and set the number of particles per cell to 64.
Result	The jet has a very fast flow rate and generates fast moving liquid splashes and sheets.
Result	These are difficult cases for level set approaches while our method handles them without any problem.
Result	With our approach we were able to create, for the first time, a 3d water demo that is both simulated and ray-traced in real time.
Result	We achieved a frame rate of over 30fps with two GPUs, one for simulation and one for ray-tracing.
Result	These examples demonstrate the ability of our method to simulate liquid in a non-axis aligned moving container.
Result	One way coupling with fast moving solids is shown in Figure 11 and the accompanying video.
Result	Several solid objects move at high speed across the tank sloshing the liquid up to the air.
Result	Our method conserves mass and prevents volume loss in this difficult case as well.
Method	We computed the mass and the volume enclosed by the 0.5 iso-contour of the liquid over time in various examples.
Method	The total mass is computed by integrating ρ over the whole simulation grid.
Method	To measure the volume we used marching cubes to extract the 0.5 contour triangle mesh of ρ and determined the enclosed volume.
Result	Our method conserves mass in all examples and generally keeps the volume close to the true liquid volume.
Result	However, there are several situations where our method loses volume visually.
Result	One such case is when a liquid ball hits the ground and spreads out until it becomes thinner than the grid spacing.
Result	Even though the density values are nonzero, marching cubes does not generate surface meshes in those regions.
Result	Another case is when the ratio of surface area to volume is large.
Result	In this case, there are large regions with ρ < 0.5 that do not contribute to the volume because the 0.5 iso-contour is empty.
Result	However, in contrast to PLS, when such features join the main body of water again, they correctly contribute to its volume so that the global level remains constant.
Result	We proposed a method for simulating liquids that conserves mass and is effective in keeping the volume defined by the 0.5 iso-contour close to constant.
Result	We have demonstrated the strength of our technique in various scenarios.
Result	The method has its limitations as well.
Result	First, although our sharpening scheme ensures that the ρ = 0.5 interface is sharp, it does not modify regions where ρ > 0.5.
Result	It could theoretically be possible that the region with ρ slightly above 0.5 expands so that the volume defined by the 0.5 iso-contour grows by a factor of two while keeping its original mass.
Future Work	An alternative to our sharpening method is to perform antidiffusion step [SHA11], which is an interesting avenue for future work.
Result	Another limitation is the possibility of losing local volume temporarily as discussed in the previous section.
Result	The density post processing method we proposed is an effective way to alleviate this effect.
Result	Even though our method cannot guarantee complete volume conservation at all times, it reduces this problem significantly in comparison to all the previous methods we have investigated.

Result	This paper describes a technique for animating the behavior of viscoelastic fluids, such as mucus, liquid soap, pudding, toothpaste, or clay, that exhibit a combination of both fluid and solid characteristics.
Method	The technique builds upon prior Eulerian methods for animating incompressible fluids with free surfaces by including additional elastic terms in the basic Navier-Stokes equations.
Method	The elastic terms are computed by integrating and advecting strain-rate throughout the fluid.
Method	Transition from elastic resistance to viscous flow is controlled by von Mises’s yield condition, and subsequent behavior is then governed by a quasi-linear plasticity model.
Background	Often referred to as viscoelastic fluids, these materials initially respond to strain elastically like a solid, but when subjected to increasingly large stresses they flow like a fluid.
Background	A tremendous variety of materials exhibit this type of behavior, and a few common examples include: mucus, egg white, dough, gelatin, unset cement, liquid acrylic, toothpaste, gels, clay, and liquid soap.
Background	Like a solid, these materials can bounce and jiggle, but they will also flow like a fluid.
Background	For some of these materials, such as egg white or clay, the combination of elastic and fluid behavior is quite apparent.
Background	For others, such as liquid soap, the elastic behavior manifests less obviously as predominately fluid behavior that differs subtly from that of a simply viscous fluid.
Method	The technique we present builds on prior Eulerian methods for animating incompressible fluids with free surfaces.
Background	As evidenced by their widespread use, these methods can efficiently produce results that are realistic enough for applications in the demanding visual effects industry.
Method	Our method computes viscoelastic fluid behavior by supplementing the basic Navier-Stokes equations with additional terms for elastic body forces.
Method	These elastic terms require computing the material strain throughout the fluid.
Method	Because the fluid simulations do not make use of an explicit reference configuration, strain is computed by integrating strain-rate and advecting the results.
Background	The transition from elastic resistance to viscous flow is controlled by von Mises’s yield condition, and subsequent behavior is then governed by a quasi-linear plasticity model.
Background	While the mechanics describing the behaviors exhibited by solids and fluids may seem distinct, they are actually quite similar.
Background	First, both resist changes to their volume.
Background	The physical reasons for why they conserve volume may differ, but the mathematical expressions capturing the behaviors are essentially the same.
Background	Furthermore, many fluid methods assume incompressibility and most solid methods assume that volume changes will be negligible.
Background	Second, the internal damping force for a solid and the viscous force for a fluid are not just similar, they are identical.
Problem	The key difference between an ideal solid and an ideal fluid is the presence or absence of an elastic term that attempts to restore the material to its original shape.
Background	The continuous variable that spans the space between solid and fluid materials is this limit on how much stress can be tolerated before flow occurs.
Background	Other properties such as damping/viscosity, density, and elastic stiffness are largely orthogonal.
Background	When the elastic limit is set to a high value, the material behaves like a solid, when it is zero the material behaves like a fluid, and intermediate values correspond to materials like mucus, liquid soap, toothpaste, or clay.
Background	These intermediate materials are often referred to as viscoelastic fluids or as elastoplastic solids, depending on whether their behavior is closer to that of an ideal fluid or ideal solid.
Background	In the field of computer graphics, the technique described in [Carlson et al., 2002] is perhaps closest in intent to the method we describe here.
Background	Like us, they were interested in modeling materials with properties intermediate between solids and fluids using an Eulerian grid-based fluid simulation method.
Background	However, they opt to map the continuum between fluids and solids to varying viscosity.
Background	In their system a solid is simply a fluid with very high viscosity.
Background	This approach ignores the elastic behavior demonstrated by many materials.
Background	Nevertheless, they do generate nice results for highly viscous fluids, and they describe an implicit integration method for coping with stability issues arising from very high viscosities.
Background	Other graphics researchers have used particle-based methods for modeling highly viscous fluids and for modeling fluids with some form of elasticity.
Background	In [Terzopoulos et al., 1989] the authors modeled melting thermoelastic materials.
Background	The particles exerted cohesive, viscous, and volume-preserving forces on their neighbors.
Background	While solid, each particle was connected to a fixed set of neighbors using elastic springs.
Background	As the material would become more fluid-like, the springs would weaken, and eventually disappear.
Background	By varying the elastic properties of the materials, this method could model a range of behaviors, but without plasticity, it could not model materials, like clay, that flow into a new configuration and then resist changes from that configuration.
Background	Similar approaches using different particle formulations have appeared in [Desbrun and Gascuel, 1995], [Desbrun and Cani, 1996], [Cani and Desbrun, 1997], and [Stora et al., 1999].
Background	The method appearing in [Desbrun and Gascuel, 1995] used elastic forces with dynamically determined neighbors to allow behavior that is similar to plastic flow.
Background	Perhaps the greatest limitation on the level of realism achievable by these particle methods was the relatively small number of particles used.
Background	However, as processor speeds have increased, particle-based methods have been able to achieve increasingly impressive results.
Background	Compelling real-time results for modestly sized systems appear in [Müller et al., 2003], and [Premo ze et al., 2003] demonstrates off-line results that are comparable to the current best grid-based methods.
Background	Although both of these recent methods focus on strictly liquid behavior, they could be extended along lines similar to what we propose here.
Background	Some methods for modeling solids have dealt with limited amounts of plastic flow.
Background	Both [Terzopoulos and Fleischer, 1988a] and [Terzopoulos and Fleischer, 1988b] describe transition to plastic flow based on von Mises’s yield condition, and [O’Brien et al., 2002] used a similar plasticity model for ductile fracture behavior.
Method	We use the same yield condition of von Mises, but we do not assume that plastic flow occurs instantaneously.
Method	Instead we use a more complex model that accommodates phenomena such as creep.
Background	Additionally, these prior methods used Lagrangian meshes with largely fixed topology, and so they would have encountered “tangling” difficulties, such as inverting elements, for large amounts of plastic flow.
Background	Another, rather interesting, approach to combining solid and fluid behaviors appears in [Nixon and Lobb, 2002].
Background	They surround a fluid simulation with an elastic membrane.
Background	The result is an object that behaves somewhat like a water balloon.
Method	Our work builds directly on previous grid-based, Eulerian methods for animating fluids with free surfaces.
Background	Details on these methods can be found in [Foster and Metaxas, 1996], [Stam, 1999], [Foster and Fedkiw, 2001], and [Enright et al., 2002].
Method	In particular, our work essentially extends [Enright et al., 2002] to include the behavior of viscoelastic fluids.
Background	Outside the graphics field, viscoelastic materials have been studied extensively.
Background	We refer the reader to the texts [Fung, 1965], [Han and Reddy, 1999], and [ Bird et al., 1987 ] for detailed descriptions of several different models for viscoelastic and elastoplastic materials.
Method	The general approaches we use for introducing elastic forces into the Navier-Stokes equations, and integrating and advecting strain are not completely novel.
Background	Some recent examples of fluid simulation outside the graphics literature that involve elastic forces include [Gerritsma, 1996], [Tomé et al., 2002], and [ Bonito et al., 2003 ].
Background	A detailed analysis of two-dimensional simulations of viscoelastic fluids on staggered rectilinear grids appears in [Gerritsma, 1996].
Background	The three-dimensional method we use for storing rank-two tensor quantities on a staggered grid is a generalization of their two-dimensional method.
Background	In [ Bonito et al., 2003 ] a combination of rectilinear grids and finite elements are used with a volume-of-fluid method to model three-dimensional fluids with elastic properties.
Background	They do not include plasticity and they store all quantities at cell centers.
Background	The marker-andcell based method in [Tomé et al., 2002] is another example solving viscoelastic free-surface flows.
Background	They address issues relating to elastic-stress based boundary conditions at rigidbody and free-surfaces.
Background	Although they use a staggered grid for the velocity field, they still store their tensor values at cell centers.
Method	The framework we use for fluid simulation is based on the method described in [Enright et al., 2002].
Method	This framework consists of two primary components which work together to produce useful results.
Method	The first is a rectilinear grid that stores the values that define the fluid’s state.
Method	The values on the grid change as forces act on the fluid, and they also change as the fluid moves through the space delineated by the grid.
Method	The second component is a function whose levelset at zero locates the boundaries of the fluid.
Method	The function is represented using a combination of particles and values defined on a second rectilinear grid.
Method	The particles and grid values evolve based on the motion of the fluid.
Method	A full description of this type of system is beyond the scope of this paper, so we focus on the changes we make to accommodate viscoelastic behavior.
Background	We suggest the following references for a more complete description of this simulation methodology: [Foster and Metaxas, 1996], [Stam, 1999], [Foster and Fedkiw, 2001], and [Enright et al., 2002].
Method	Behavior of the viscoelastic fluid is governed by a modified version of the Navier-Stokes equations that includes an additional term for elastic stress.
Method	The symbol denotes the vector of difT ferential operators = [∂/∂x, ∂/∂y, ∂/∂z] , and we have implicitly assumed that μ v and μ e are constant throughout the material.
Method	By omitting elastic and viscous terms relating to dilation, we have also assumed that the fluid is incompressible.
Method	This condition is enforced by adjusting the pressure field at each integration step.
Method	Additionally, we do not use the first term of Equation (1) (the advection term) directly.
Method	Instead, we use a semi-Lagrangian method to advect field values.
Background	We refer the reader to [Stam, 1999] and [Foster and Fedkiw, 2001] for a discussion on efficiently modeling the above equations.
Method	The fourth term of Equation (1) computes acceleration due to elastic forces and it requires knowing the elastic strain throughout the fluid.
Method	If we had an explicit deformation function then we could use its spatial derivatives to compute strain.
Method	However, with the Eulerian formulation we are using there is no deformation function available.
Method	Furthermore, the large deformation and flow experienced by the material makes tracking deformation impractical.
Method	Instead we compute strain by integrating strain-rate.
Method	Because we do not wish to model a perfectly elastic material, we also require rules concerning how the elastic strain changes due to plastic yielding.
Method	We first separate the total strain into an elastic and a plastic component so that          Tot Elc Plc = + .
Method	(Outside this section we denote elastic strain as simply .
Method	Similarly, the plastic strain is given by integrating plastic flow.
Method	We use von Mises’s criterion for determining when plastic flow should occur.
Method	So long as the magnitude (Frobenius norm) of the strain deviation remains below the yield point, γ, no plastic flow occurs.
Method	When the limit is exceeded, flow occurs at a rate proportional to the amount the limit has been exceeded by.
Method	Note that Equation (9) does not take into account the movement of the material through space.
Method	Like velocity or any other fluid property, the elastic strain must be advected with the fluid.
Method	We use the same semi-Lagrangian advection scheme that we use for the fluid velocities, and we update the elastic strain using Equation (9) after our advection step.
Method	However in addition to scalars (e.g. pressure) and rank-one tensors (e.g. velocity), we also need to store the elastic strain, a rank-two tensor, on the simulation grid.
Method	Just as velocity components are stored separately on faces, the different components of the strain tensor are stored at different locations.
Method	The diagonal entries are stored at the cell centers.
Method	The off-diagonal entries are stored at the center of edges perpendicular to the component directions.
Method	For example, the xy components are stored on the edges parallel to the z axis.
Method	This approach is a generalization of the 2D method described in [Gerritsma, 1996], and they describe its merits in detail.
Method	We use a particle-level-set method for tracking the fluid’s free surface as described in [Enright et al., 2002], but with the substantially faster, though less accurate, method detailed in [Enright et al., 2004].
Method	The authors note that the method is susceptible to volume loss, and we found this behavior to be problematic for some of our examples that involve fixed, small amounts of fluid.
Method	We were able to ameliorate this problem somewhat by using a level-set grid with twice the fluid grid’s resolution, and that is staggered with respect to the fluid grid.
Method	This scheme places level-set grid centers on the cell centers, face centers, edge centers, and nodes of the fluid grid.
Method	In addition to helping to prevent volume loss by locating level-set values where velocity boundary constraints are enforced, the higher resolution also benefits the rendered surfaces.
Method	We have implemented this method for modeling viscoelastic behavior and used it to generate several example animations.
Method	Most of these examples were selected to illustrate some interesting aspect of viscoelastic fluid behavior.
Result	The motion of the pure fluid example differs substantially from the viscoelastic examples.
Result	Additionally, the surfaces of the viscoelastic examples retain evidence of the impact even after motion has stopped.
Result	Again, the behavior of simple and viscoelastic fluids differ substantially.
Result	A simply viscous fluid would merely flow out to fill the container.
Result	The examples with high yield strain, i.e. large γ, behave like deformable solids and bounce.
Result	When the spheres collide, their level-set surfaces merge so that they adhere.
Result	The fluid retains its momentum, generating the resulting spinning and stretching motion.
Result	Close examination shows that the spheres slightly anticipate their collision.
Result	This error occurs because the surfaces begin to interact through shared ghost cells.
Method	All of the images were rendered with a standard Newtoniteration based ray marching algorithm implemented in the open source renderer Pixie developed by Okan Arikan.
Future Work	While ray marching produces nice results we think they might be improved using the method described in [Heckbert, 1987].
Result	Some of our examples suffer from noticeable volume loss.
Result	This occurs because, while the particle level-set method does a nice job modeling moderately thick volumes of fluids, very thin surfaces, or strands, still have a tendency to vanish.
Result	These effects are particularly noticeable visually when the fluid is moving in orderly fashion, as opposed to splashing about chaotically.
Result	It is difficult to say if this behavior is a deficiency in our implementation or a limitation of the surface tracking method.
Result	The speed of this simulation method is approximately the same with and without the addition of elastic forces.
Result	For example, one of the falling cube examples on a 40 3 grid requires about half an hour of computation per second of animation on a single 3 GHz Pentium 4 processor.
Method	We are using an explicit integration method for the viscous and elastic forces, so very high viscous or elastic coefficients would probably cause stability problems and force smaller time steps.
Future Work	If it became an issue, that difficulty could be ameliorated somewhat with an implicit integration scheme.
Result	The material can be made to adhere to or slip off of boundary surfaces by adjusting the velocity or pressure constraints enforced along closed boundaries.
Result	However, in our current implementation all fluids will stick to each other because different surface components merge when they collide.
Result	For the fluids we show in our examples, this behavior is a desirable feature.
Result	However, for non-sticky materials, like cold gelatin, it would be undesirable.
Future Work	To a large extent, our method for incorporating elastoplastic terms does not depend on the underlying fluid simulation method, and one could easily adapt the method to other fluid simulation techniques such as smoothed-particle hydrodynamics.
Result	Furthermore, we found that once we already had a working fluid simulation, adding the elastoplastic terms was fairly easy.
Result	Finally, we note that while the method we present can model a wide range of phenomena, many real materials can demonstrate behaviors not captured by this model.
Background	Biological fluids, such as blood, can exhibit many interesting effects that arise from their microscopic structure.
Result	Even relatively simple polymer suspensions can demonstrate behavior that can only be roughly captured with this model.

Background	Progress in cloth simulation for computer animation and apparel design has led to a multitude of deformation models, each with its own way of relating geometry, deformation, and forces.
Problem	As simulators improve, differences between these models become more important, but it is difficult to choose a model and a set of parameters to match a given real material simply by looking at simulation results.
Result	This paper provides measurement and fitting methods that allow nonlinear models to be fit to the observed deformation of a particular cloth sample.
Method	Unlike standard textile testing, our system measures complex 3D deformations of a sheet of cloth, not just one-dimensional force–displacement curves, so it works under a wider range of deformation conditions.
Method	The fitted models are then evaluated by comparison to measured deformations with motions very different from those used for fitting.
Background	Today’s cloth simulators for animation, visual effects, games, and apparel design can mimic real cloth to a high degree of fidelity.
Problem	But to fully exploit their capabilities, the constitutive models for cloth deformation must be tuned with great care.
Problem	During this tuning process it is difficult to tell which models and which parameters are giving results more like the real material.
Problem	This paper aims to solve this problem by introducing new techniques to measure complete cloth behavior under controlled conditions and to estimate cloth deformation models from these measurements.
Background	Most methods for testing cloth move the sample into a state of near-uniform strain, exercising one or at most two components of strain at once: pure stretching, pure shearing, or pure bending.
Background	One or two forces are measured to quantify the cloth’s resistance to deformation, and the resulting forcedisplacement curves are valuable in studying the differences between materials.
Problem	However, this approach has certain limitations.
Problem	The inevitable deviations from uniform strain create modeling error that cannot be quantified without knowing the actual strain variation; and force-displacement curves can be used directly to tune a cloth model, but do not provide any way to validate the resulting fit.
Result	The contributions of this paper are, first, a new, general system for observing cloth properties that measures more complete data than previous work in cloth capture or textile testing, and second, a new method for fitting parametric models to this type of data.
Result	Finally we show results that illustrate the performance of several widely used cloth models.
Method	Our measurement system applies forces to a sample of cloth using actuators and force sensors that let us know the complete applied force, in 3D.
Method	The resulting deformation is tracked by a stereo computer vision system that captures the complete deformation, also in 3D.
Result	Having deformation and force information makes our data well suited to model validation—the experiment measures the complete answer that should be predicted by a cloth simulator.
Method	Also, we do not need uniform strain, and in this paper we illustrate a range of tests, some that mimic traditional tests and some with more complex deformations.
Method	Our approach to model estimation is to numerically optimize nonlinear stress-strain curves to minimize errors in force and position compared to the measurement.
Method	We have designed a general fitting method, suited for the vast majority of existing cloth models, that leverages equilibrium conditions to guide the iteration.
Method	By estimating model parameters under a sequence of deformations of increasing complexity, we alleviate problems with convergence in the presence of abundant local minima.
Method	We have used our system to fit three membrane models and two bending models from the graphics literature, each based on a different strain measure, and to evaluate the resulting models against more complex motions.
Background	Cloth simulation has a comparatively long history in computer graphics.
Background	Since the first physics-based approach by Terzopoulos et al. [ TPBF87 ] a multitude of different cloth models have emerged, ranging from simple mass-spring systems [ Pro95 , CK02 ] over general particle systems [ BHW94 , BW98 , EWS96 ] to elaborate models derived from continuum mechanics [ EKS03 , VMTF09 ] or even the discrete yarn structure [ KJM08 ].
Problem	Considering the number of existing models, it is very hard to clearly identify or even quantify the advantages of individual approaches.
Problem	Our goal is to define a platform for comparing cloth models to the observed behavior of real cloth.
Background	As a central component of any cloth model, material models describe the relation between deformation and resulting forces.
Background	Continuum-based approaches can accurately describe the directional variation of material properties, but regardless of the cloth model, a single set of material coefficients for the entire deformation range is not sufficient to faithfully capture the nonlinear response of typical fabrics.
Background	Bi-phasic models, typically implemented as strain limiting methods [Pro95, BFA02, Mül08, TPS09, WOR10], improve on this by splitting the material behavior into an initial, weakly elastic range and a stiff, quasi-inextensible limit.
Background	At the extreme, the elastic range can be replaced altogether by inextensibil∗ ity constraints [GHF 07, EB08].
Background	A better approximation to the true material response can be obtained by making the material parameters functions of the deformation, rather than constants, and by fitting these functions to measured data.
Background	To this end, previous work [BHW94,EWS96, VMTF09 ] has mainly relied on the Kawabata Evaluation System (KES) [Kaw80 ] and corresponding machinery.
Background	While the KES covers a comprehensive set of experiments, other devices have been used in more specific context such as the Picture Frame test [ Cul79 ] for measuring shear properties and the Cantilever test [ CPGE90 ] for measuring bending properties (see also Pabst et al. [ PKST08 ]).
Background	These measurement-based approaches establish a valuable link between simulation and real-world behavior, but they rely on experiments that isolate individual deforma∗ tion modes.
Background	As an alternative, Bhat et al. [ BTH 03 ] (and recently Kunitomo et al. [ KNM10 ]) aim at avoiding the need for controlled conditions and try to extract parameters from casually captured videos of cloth.
Background	This approach appeals through a simple and inexpensive acquisition process, but it is not possible to accurately separate internal (i.e. material-specific) and external (e.g. friction, air drag) parameters.
Background	In a similar spirit, capture technology can be used to record time-varying geometry of complex cloth mo∗ ∗ tions [WCF07,BPS 08,SGdA 10].
Background	But while capturing can provide accurate deformation data, parameter fitting remains very difficult without explicit control over boundary conditions, in particular loading forces.
Background	Closer to our work is the recent approach of Wang et al. [WRO11], who propose a data-driven piecewise linear elastic cloth model comprising 39 material parameters.
Background	These parameters are fitted to experimentally acquired data obtained from planar and bending deformations.
Result	Their capture setup is appealingly simple, but ours is more general and powerful: it produces a 3D surface, rather than a 2D deformation, and it measures all forces applied to the cloth as they change during a range of different deformations.
Method	Like other cloth testing systems, we focus primarily on tensile forces, because it is hard to repeatably produce and measure compression forces in a sheet that is inclined to buckle.
Method	Tests are performed on 100 mm square cloth samples using two kinds of plastic clips: small, rounded clips that grab a localized area, and long clips that grip one whole side of the sample.
Method	We measure the weights of all cloth samples as well as the clips (see Table 1 ) and use these values in the optimization process.
Method	Forces are applied to the clips by fine wire cords that are pulled to defined displacements by eight linear actuators, and the tension in the cords is monitored by miniature load cells located at the actuator ends (see Figure 2).
Method	The location and orientation of the cords attached to the clips (which reveal the direction of the applied force) are also tracked.
Method	The magnitudes are determined by the tension measurements, and the directions are determined by the observed directions of the cords.
Method	Note that the actuator positions themselves are not part of the output, since they are superseded by the displacements measured at the clips.
Method	This prevents stretching of the cord, or other factors affecting the distance between the clip and the actuator, from affecting displacement accuracy.
Method	Our vision system recovers the space-time geometry of the deforming cloth and attached rigid clips, as well as the directions of the forces applied to the clips.
Method	The cloth sample starts flat on a table and we capture the rest pose without applied tensile forces.
Method	This initial frame serves to compute the geometry of the cloth without any occlusion from clips.
Method	We then attach the clips, and the measurement process continues automatically, following a defined script of actuations, and recording images and forces.
Method	We typically deform the cloth by moving the actuators at 0.5 mm/sec and capture a frame every 2 seconds.
Method	The raw data for a single deformation consists of 20 to 200 individual measurement frames, with a set of camera images and simultaneous force sensor readings for each frame.
Method	We compute the per-frame geometry using a state-ofthe-art stereo reconstruction technique [ BBH08 ], which was specifically tailored for reconstructing cloth geome∗ try [ BPS 08 ].
Method	If the inherent texture of the cloth is not sufficiently random, it is printed with a wavelet noise pat∗ tern [ AIH 08 ] to provide texture that can be used for stereo reconstruction and tracking.
Method	The pattern is printed with a flatbed inkjet printer and does not have a noticeable effect on the material behavior.
Method	To represent inter-frame correspondence, we use optical flow to obtain a single triangle mesh that deforms over time, akin to the human face tracking method of Bradley et al. [BHPS10].
Method	To start, the cloth vertices in the rest pose frame (frame 0) are projected onto the input images, where optical flow predicts the projection of each vertex at the next time step.
Method	Back-projecting onto the reconstructed geometry for the next frame gives new position estimates for the cloth vertices.
Method	The process is then repeated using the result from frame n to obtain frame n + 1.
Method	As with all sequential tracking methods, very small errors can accumulate over time and cause temporal drift in the reconstruction.
Method	To avoid drift, we subsequently match each frame independently back to the rest pose frame using the approach described in Bradley et al. [BHPS10].
Method	The final solution is smoothed using Laplacian regularization to remove noise.
Method	In order to measure the complete answer that a simulator should predict, we need to determine the interaction between the rigid clips, the cloth, and the cords.
Method	The clips are produced, using rapid prototyping, with embedded codes [Fia05] that allow us to determine their identity, position, and orientation automatically.
Method	The area of cloth occluded by the clips is used to automatically determine which cloth vertices are clamped by each clip and will therefore be constrained to it in the simulator.
Method	The vision system also finds the cords in the images and triangulates a 3D line for each cord.
Method	A few user scribbles on an input image indicate which cords are affecting each clip.
Method	The forces are rendered as red vectors with lengths proportional to the force magnitudes.
Method	The set of deformations to measure is motivated by the goals of the parameter fitting stage (Section 5): to fit model parameters for stretch, shear and bending that best describe the cloth, and to validate the parameter fits by comparing against other measurements.
Method	To reduce the risk of falling into local minima during parameter fits, we have designed deformation sequences that produce near-isolated strains, and allow estimating stretch, shear and bending properties in a separate and incremental manner.
Method	However, unlike standard textile evaluation practices [Kaw80], and thanks to our full 3D deformation capture solution, we relax the requirement of uniform strains.
Method	To isolate stretching we perform a uni-axial tension experiment, with forces applied to two long bar clips attached to either side of the cloth (see Figure 4 , 2nd column).
Method	The cloth is slowly stretched until a maximum force is reached and then slowly released back.
Method	The process is repeated three times, in both weft and warp directions separately.
Method	Shearing is captured using an approximate picture-frame experiment [Cul79], where four long clips fix the cloth boundaries and shear stress is applied as the cords pull on opposite corners ( Figure 4 , 3rd column).
Method	To isolate bending deformation we slowly push the flat cloth sample off the edge of a table and measure its shape as it bends under its own weight ( Figure 4 , 4th column), for both weft and warp directions.
Method	Thus we have a total of five measurements per cloth sample that will be used for parameter fitting (two stretch, one shear, and two bending).
Method	We also capture two sequences with more complex deformation ( Figure 5 ) for validation after parameter fitting.
Method	In the first test, opposite edges of the cloth are pulled in opposite directions, causing shearing and buckling ( Figure 5 , top).
Method	The second is a four-corner pulling test, where opposite pairs of corners are pulled in alternation, resulting in diagonal wrinkles ( Figure 5 , bottom).
Result	To our knowledge, our method presents the first system able to record such extensive information about the behavior of a cloth sample.
Result	In the vision system, the camera calibration accuracy is within 0.3 pixels, or about 0.075 millimeters at the distance of the cloth.
Background	The multi-view stereo algorithm of Bradley et al. [BBH08] is among the most accurate available according to the Middlebury evaluation benchmark.
Result	It is difficult to quantify the accuracy of the temporal flow computation, but it can be visualized by compositing the reconstructed deformation on top of the input images (see accompanying video).
Method	The raw repeatability of our force sensors is about 3 millinewtons (RMS).
Method	The largest source of error in measuring the force indirectly through the cord is the internal friction in the cord as it bends around the pulleys, which introduces an artificial hysteresis of about 0.1 N.
Problem	Our goal is to study the fidelity of constitutive models of cloth—models that predict the forces produced in the cloth in response to deformations.
Method	The input of such a model is the positions of the vertices x 1 , . . . , x n ∈ IR 3 that define the deformation state of the sheet (analogous to strain in continuum mechanics) and the output is the forces that act between those vertices in response (analogous to stress).
Method	Although some of the models we look at are discrete in nature, we will use the convenient terms stress and strain to describe them.
Background	Most elastic cloth models separate membrane (i.e., stretch and shear) and bending deformation energies.
Method	In both cases, deformation energy density can be described by the product of strain (ε) and stress (σ), i.e., W = 2 1 σ · ε.
Background	Furthermore, most of these models define separable scalar stress components as linear functions of individual scalar strain metrics.
Method	In that case, the energy density of each deformation component i can be written as W i = 1 2 k i ε 2 i , where k i ε i = σ i and k i is the stiffness coefficient corresponding to the deformation component ε i .
Background	The force density due to each ε i follows as F i = − W i = −σ i ε i = −k i ε i ε i .
Method	We have evaluated three models for membrane deformation that fit this description (spring systems, the soft constraint model by Baraff and Witkin [BW98] and the diagonalized St.Venant-Kirchhoff (StVK) model by Volino et al. [VMTF09]), and two bending models (spring systems and the edge-based bending model in Discrete Shells [GHDS03]).
Method	Considering possible anisotropic behavior, we distinguish six different strain components on regularly triangulated cloth: weft-stretch (ε s,u ), warp-stretch (ε s,v ), shear (ε s,uv ), weft-bend (ε b,u ), warp-bend (ε b,v ), and diagonalbend (ε b,uv ).
Method	Next, we describe in detail the strain metrics for the individual deformation components in the selected models.
Method	Note that not all force models define the quantities below explicitly as strains, as they often rely on the resolution of the discretization, or they differ simply by scale factors that can be embedded in the stiffness k i .
Method	We use continuum strain definitions in all cases to fit them in a common formulation that allows us to easily compare the models.
Method	All deformation components are modeled based on springs, with weft and warp ring-1 springs for stretch, and diagonal ring-1 springs for shear.
Method	The membrane deformation is defined using the Green-Lagrange strain tensor, a formulation introduced to computer graphics by Terzopoulos et al. [TPBF87].
Method	Given a per-triangle mapping function w from the undeformed 2D configuration (x a,0 , x b,0 , x c,0 ) to the deformed        3D configuration (x a , x b , x c ), the deformation gradient can be computed as −1 (w u w v ) = (x b − x a x c − x a ) x b,0 − x a,0 x c,0 − x a,0 .
Background	Volino et al. [VMTF09] approximate the standard StVK model zeroing out off-diagonal terms in the matrix that relates strain and stress, σ = Eε.
Background	Then, in the diagonalized StVK, each membrane stress component depends only on its corresponding strain component, σ s,i (ε s,i ).
Method	Weftand warp-stretch are measured through a subtle modification of the Green-Lagrange strain tensor, defining terms that are quadratic in positions instead of quartic:
Method	The deformation is measured based on weft and warp ring-2 springs for weftand warp-bend, and diagonal ring-2 springs for diagonal-bend.
Method	Same as for membrane deformation, strain is measured as the relative change of edge length (1).
Background	Grinspun et al. [GHDS03] and Bridson et al. [BMF03] discovered concurrently the appropriate weighting of the angle change in order to model homogeneous bending on irregular triangle meshes with a homogeneous stiffness.
Background	Grinspun et al. define h 0 as a third of the average of the heights of the two triangles incident to the edge.
Background	This definition implies that bending energy density is integrated over edgecentered rectangles of size l 0 × h 0 .
Method	With our separation of weft-, warpand diagonal-bending to capture anisotropy, the bending models in Discrete Shells and by Baraff and Witkin [BW98] are equivalent up to a stiffness scale factor.
Method	The generic force density model F = −σ ε defined above assumes a linear stress-strain curve σ = kε.
Method	However, stressstrain curves are potentially nonlinear functions.
Method	Then, for each deformation component, we model stress as a function σ i = k i (ε i )ε i , with a strain-dependent stiffness k i encoded using Hermite splines.
Method	We enforce non-negative constraints on the stiffness values at control points.
Method	The resulting nonlinear force density function, F i = −k i (ε i )ε i ε i yields a conservative force field, but note that the elastic energy density can no longer be defined simply as 1 2 kε 2 , and would now require the integration of the stiffness function.
Method	Although only Volino et al. [VMTF09] propose a general nonlinear stress-strain relationship (though many systems use some form of strain limiting instead), the same construction can easily be built on any of our selected models.
Method	Because linear models fit the data poorly, we used the nonlinear model in all cases, resulting in a consistent set of models, parameterized by the number of spline control points, which reduces to the widely used linear models when each spline has a single control point.
Problem	The key question of how well a given model describes a particular piece of cloth is answered by fitting the model to the measurement data: adjusting its parameters to minimize the difference between the model’s predictions and the measured behavior, both in position and force.
Method	We do this by solving an optimization problem, leveraging that the cloth is at static equilibrium at the measured configurations.
Method	In principle all parameters of a cloth model can be fit to a sufficiently rich single deformation sequence, but this can result in a problem fraught with local minima.
Method	In order to achieve stable fits, we have designed an incremental optimization procedure that fits model parameters a few at a time using the isolated deformations described in Section 3.2.
Method	For each different cloth sample, we have created a simulated replica with the same mass, uniformly distributed, and the same 100mm square geometry, discretized with a regular 25 × 25-node mesh, connected either with springs or with quadrilaterals split into triangles, depending on the model.
Method	In each measurement sequence, a different set of nodes is fixed to rigid bodies representing the clips.
Method	For the bending measurement sequences (see Figure 4 ), we fix all cloth nodes above the edge of the table.
Method	The measured pulling forces of the cords are applied as point forces on the rigid bodies at known locations, with known magnitudes and orientations.
Method	Given a set of captured static deformation frames, we wish to know the (nonlinear) stress-strain curves for the deformation components of a cloth model, such that a simulated cloth matches known positions and forces as well as possible.
Method	Specifically, we minimize the weighted error of cloth positions and clip forces over a sequence of measurement frames, subject to the constraint of static equilibrium on all frames.
Method	For the formulation of the objective function, we concatenate in vectors the positions, x n , and the net forces, F n , of free cloth nodes at all frames, as well as the forces, F c , applied by the cords on the clips.
Method	Due to equilibrium, the net force on the clips, produced by cord forces, gravity, and forces from fixed cloth nodes, must be zero.
Method	We indicate with x n and F  ̃ c , respectively, the known cloth node positions and clip forces, measured as described in Section 3.
Method	We also concatenate in a vector k the (unknown) stiffness values at the control points of the nonlinear stress-strain curves for the deformation components of the cloth.
Method	Since the pieces of cloth are homogeneous, we use a single curve for each deformation component for all frames and all cloth elements.
Method	Then, the computation of model parameters based on the minimization of position and force errors subject to the static equilibrium condition can be formulated as the following nonlinear constrained least-squares problem: k = arg min μ x n (k) − x n 2 + λ F c (x n , k) − F  ̃ c 2 ,
Method	In this optimization problem, we use the measured clip positions, x c , as known boundary conditions.
Method	For stretch tests, the objective function is based only on clip forces, i.e., μ = 0, λ = 1, while for bend tests it is based only on cloth positions (since there are no measured forces), i.e., μ = 1, λ = 0.
Method	For shear tests, the objective function is based only on clip forces parallel to the direction of the clips themselves.
Method	We observed that, in situations of near-homogeneous shear, the clip-parallel forces are dominated by shear, while clip-orthogonal forces are dominated by stretch.
Method	Then, by fitting only clip-parallel forces we reduce the sensitivity to potential errors in stretch stiffness.
Method	The optimization problem contains two unknowns: the parameter vector k and cloth node positions x n .
Method	We solve the optimization in an iterative manner, refining k and x n separately on two nested loops.
Method	In an outer loop, we refine k by local minimization of the error function and, in an inner loop, we recompute x n to satisfy the equilibrium constraint.
Method	As a result, we obtain a linear expression that relates node positions to parameter values:
Method	We terminate the outer loop (and hence the overall optimization) when the residual is reduced by less than 1% between two consecutive iterations.
Method	To ensure convergence of the Newton-like iterations and to enforce non-negativity constraints on the components of k, we execute a line search from k(i) to the solution of (9) if the residual grows or if the solution violates some constraint.
Method	The solution to the linear least squares problem requires solving a system Ak = b, where the size of A is given by the number of unknown stiffness values, |k|.
Method	In our test examples, this number was always below 10, and we solved the linear systems using LDL factorization.
Method	The formulation of A, on the other hand, requires solving |k| linear systems of type ∂F n y = b, which ∂x n we did using the conjugate gradient method.
Method	Once the parameter values k(i + 1) are refined, we bring the cloth to a static equilibrium position, x n (i + 1).
Method	We do this by solving quasi-static simulations until convergence on all captured frames, starting always from the measured configuration x n and using the measured clip positions x c as boundary conditions.
Method	We consider that a piece of cloth has converged to equilibrium when F n < 10μN.
Method	The quasi-static simulations involve linear-system solves with the cloth stiffness matrix ∂F n .
Method	We found that, during inter∂x n mediate iterations, the stiffness matrix may not always be well conditioned, therefore we have solved the quasi-static equilibrium problems using additive Levenberg-Marquardt, which effectively produces a modified stiffness matrix of the form ∂F n + μI.
Method	For improved conditioning, we also use this ∂x n modified stiffness matrix in the outer loop.
Method	The nonlinearity of cloth deformation, together with the complex interplay of various deformation components in the resulting forces and positions, make the optimization problem above extremely complex in the general case, prone to falling in local minima and sensitive to initialization values.
Method	However, we largely alleviate these issues with the design of the five isolated deformation measurements described in Section 3.2, which allow us to separately fit stiffness curves for the six deformation components described in Section 4.1, following an incremental parameter fitting procedure.
Method	First, we fit in parallel the weft-stretch stiffness curve, k s,u (ε s,u ), for the weft-stretch sequence, and the warp-stretch stiffness, k s,v (ε s,v ), for the warp-stretch sequence.
Method	We ignore shear and bend parameters for stretch fits, as we have observed that they have little effect.
Method	Second, using known stretch stiffness curves, we fit the shear stiffness k s,uv (ε s,uv ), for the shear sequence.
Method	Third, we fit in parallel the weftbending stiffness k b,u (ε b,u ), for the weft-bending measurement sequence, and the warp-bending stiffness k b,v (ε b,v ), for the warp-bending sequence.
Method	Finally, we fit the diagonalbending stiffness curve k b,uv (ε b,uv ), using both weftand warp-bending measurements.
Method	To better account for crossinfluence of shear and bending, we use their estimated values as initial guesses and run another fitting iteration.
Method	To fit each stiffness curve k i (ε i ), we iteratively subdivide the Hermite spline adding more control points until the residual error function (6) is reduced by less than 1% or a speci- fied maximum number of points, usually 4 or 5, is reached.
Method	First, we evaluate the strain histogram for the corresponding measurement sequence, and we determine maximum and minimum strains after removing outliers.
Method	We initialize the stiffness curve with one control point (i.e., constant stiffness), and subsequently we subdivide the strain range with equidistant control points.
Method	We tested our system on four fabric samples, including a knit and the three common weave patterns (plain weave, twill, and satin), and three fiber types (cotton, wool, and synthetic): cotton satin (#4), rayon/spandex knit (#12), cotton denim (#14), and wool/cotton blend (#18).
Method	Each fabric was tested with seven deformations (see Section 3.2): for fitting, stretch in X and Y, simple shear, and bending in X and Y; and for evaluation, complex shearing and corner pulling.
Result	The measurement shows the typical behavior of a woven fabric: a nonlinear curve with increasing stiffness for higher strain, and large hysteresis.
Method	The test repeats three times, retracing the same loop each time after the initial extension from rest.
Method	We worked with three cloth models built from the components described in Section 4.
Method	The Springs model uses the spring membrane model with the spring bending model; the Soft Constraints model uses Baraff and Witkin’s membrane model with the Discrete Shells bending model; and the St. VK model uses the diagonalized St. Venant-Kirchoff membrane model with the Discrete Shells bending model.
Method	We fit all the models in four variants: linear (constant stiffness for each deformation mode), isotropic (identical stiffness in warp and weft), linear and isotropic (the simplest variant), and nonlinear orthotropic (the most general variant).
Result	The results are too numerous to include in the paper; we refer the reader to the supplementary material, which illustrates the behavior of the nonlinear orthotropic variant of all three models for all four fabrics, and the behavior of the variants of the Soft Constraints model for denim, a largely nonlinear and anisotropic material.
Result	For each test we show a selected frame (near maximum distortion) with renderings illustrating the captured and fitted cloth geometry and forces.
Result	To illustrate the fitting residuals more quantitatively, we show a force-displacement plot comparing a summary of the measured forces to the predictions of the fitted model and a vector-field plot illustrating the position error over the geometry of the fitted mesh (see caption for details).
Result	The four selected fabrics span a large range of possible cloth behaviors.
Result	In a nutshell, #12 is isotropic and very compliant in stretch and bending; #4 is also isotropic, very stiff in stretch but compliant in bending; #14 is stiff and quite isotropic in stretch, but extremely anisotropic in bending (with 33/1 stiffness ratio in weft and warp); and #18 is anisotropic both in stretch (with 10/1 stiffness ratio) and in bending (with 13/1 stiffness ratio).
Result	The maximum stretch stiffness for #4 is 250 times higher than for #12, while #14 is 10 times stiffer in shear than any other fabric.
Result	All four fabrics show similar hysteresis behavior, with loading-to-unloading stretch stiffness ratios ranging from 1.4/1 to 1.8/1.
Result	Sample #12 is nearly linear in the test deformation range, while all other three fabrics exhibit nonlinearity.
Result	Interestingly, nonlinearity may arise in some deformation modes but not in others, with no clear pattern.
Result	For stretching, all three cloth models fit nicely to the average of the hysteresis bands, even in highly nonlinear cases.
Result	The fitting residual is larger for stiffer fabrics, and the nonlinear orthotropic model variants fit anisotropic fabrics best, as expected, while linear and/or isotropic variants reach a reasonable compromise but are not always able to remain inside the hysteresis band.
Result	For shearing, the fitting force residual is larger for #14, the stiffest fabric.
Result	Across models, the Soft Constraints and St. VK models fit to the average of the shearing hysteresis band, while the Springs model deviates at times.
Method	For bending, no forces are available, and we evaluate the position residual as well as profiles of sample curves orthogonal to the support plane.
Result	The fitting residual is similar for all fabrics, but distinctly higher for the Springs model.
Result	Often, the residual is dominated by a difference in curl near the edge of the sample, while the overall shape is well fit.
Result	The behavior of sample #12, the most linear fabric, is predicted well in all cases, as seen in the force-displacement plots, the buckling behavior in corner pulling, and the (lower) effective shear stiffness of the sheet when allowed to buckle in the complex shear test.
Result	Visually, the mismatch is more apparent in the complex shear test, where models with underestimated stiffness exhibit wider folds than the real fabrics.
Method	We have also evaluated the fitted models on new test samples of each fabric, to validate their generality.
Method	Specifically, we have tested stretching on new samples of rayon/spandex knit (#12.2) and cotton denim (#14.2), and shearing on new samples of cotton satin (#4.2) and wool/cotton blend (#18.2).
Result	The force-displacement plots of the real cloth samples, shown in the supplementary document, indicate very similar behavior between fitting and test samples for #12 and #14, and a larger disparity for #4 and #18.
Result	The evaluation plots for the simulation models behave similar for the test and fitting cases, but the matching quality depends on the actual disparity across cloth samples.
Result	While overall force-displacement behavior is nicely matched, the actual folding shapes of simulated cloth may deviate largely from the captured cloth, because even a small change in material properties may lead to distant stable configurations in the L 2 sense.
Result	For this reason, the traditional L 2 metric is not appropriate for evaluating error in this case.
Result	The discontinuity of stable configurations is also the cause of flickering and twitches in some of our examples.
Result	The Springs model exhibits the worst fitting quality in shearing force-displacement curves, and the highest fitting residual for bending.
Result	This is probably due to the inherent coupling of stretch and bending deformation components in this model.
Result	Nevertheless, the overall deformations in complex shearing fit reasonably well.
Result	In contrast to continuum models, complex parameter tuning has often been regarded as a caveat of mass-spring models; but our results indicate that satisfactory parameter estimation is possible by incorporating anisotropy and nonlinearity into the model.
Result	The Soft Constraints and St. VK models produce results with very similar quality, which is expected as the models present only subtle differences as described in Section 4.1.
Result	At least three effects are missed by the tested models: hysteresis, Poisson effect (due to the diagonalization of the standard StVK model), and cross-modal stiffening (e.g., shear stiffening due to stretching).
Result	We indeed identified stretch stiffening in the shearing deformations, therefore we chose clip-parallel forces as objective function to minimize the effect of stretch errors on shear optimization.
Result	We conjecture that missing cross-modal stiffening may also be, to a large extent, the reason for stiffness underestimation in the corner pulling test for the Soft Constraints and St. VK models.
Future Work	An extension to the nonlinear model of Wang et al. [WRO11] could help alleviate these problems.
Result	This paper has demonstrated a novel system for observing cloth behavior, including complete information about deformation and forces, and a new method for fitting and evaluating cloth models using the measurements.
Result	Our system is different from standard textile testing systems because it captures detailed geometry information; it is different from previous cloth capture systems in that it captures complete force information and measures deformations of a 3D surface.
Result	The combination of very complete position and force information provides an unprecedented view into the complex behavior of cloth.
Result	Our measurement setup offers very accurate control over membrane deformations, but the bending tests require manual intervention and are thus less precise.
Result	Furthermore, the bending tests are most accurate for samples with straight edges, but some cloth materials (in particular knit) tend to curl up at free boundaries.
Future Work	In order to eliminate these problems, we would like to investigate alternative ways of controlling bending deformations in the future.
Result	The data from our experiments shows some of the limitations of current models.
Result	The most obvious of these is hysteresis—all widely used cloth models are elastic, but cloth is clearly far from elastic, resulting in quite large errors for any given point in the experiment.
Future Work	There are many paths for future work in measurement, including more complete exploration of strain space (including compression) and capture of dynamic properties, and in fitting, where new ways of evaluating fitting error are needed that can work when the cloth’s equilibrium state is unstable or non-deterministic.

Method	We capture the shape of moving cloth using a custom set of color markers printed on the surface of the cloth.
Result	The output is a sequence of triangle meshes with static connectivity and with detail at the scale of individual markers in both smooth and folded regions.
Method	We compute markers’ coordinates in space using correspondence across multiple synchronized video cameras.
Method	Correspondence is determined from color information in small neighborhoods and refined using a novel strain pruning process.
Method	Final correspondence does not require neighborhood information.
Method	We use a novel data driven hole-filling technique to fill occluded regions.
Result	Our results include several challenging examples: a wrinkled shirt sleeve, a dancing pair of pants, and a rag tossed onto a cup.
Result	Finally, we demonstrate that cloth capture is reusable by animating a pair of pants using human motion capture data.
Method	We capture the motion of cloth using multiple video cameras and specially tailored garments.
Result	The resulting surface meshes have an isometric parameterization and maintain static connectivity over time.
Background	Over the course of roughly half a dozen papers on cloth capture a prevailing strategy has emerged.
Problem	First, a pattern is printed on the cloth surface such that small regions of the pattern are unique.
Problem	Next, correspondence is determined by matching regions across multiple views.
Problem	The 3D location of a region is determined by intersecting rays through the corresponding observations in the image set ( figure 4 ).
Problem	Reconstruction is done independently on a frame by frame basis and the resulting data is smoothed and interpolated.
Background	Previous work, such as [Scholz et al. 2005], yields pleasing results.
Background	Little work has been done to capture garments with folds and scenes with occlusion.
Method	In this paper we use folding to refer to local phenomena such as wrinkles around a knee and occlusion to refer to large scale effects such as one limb blocking the view of another.
Problem	Folds and occlusion are common, especially when dealing with real garments such as pants where limbs block interior views and cloth collects around joints.
Problem	Both phenomena are symptoms of the same problem: views of the surface are blocked by other parts of the surface.
Problem	However, there is a distinction in scale and different methods are required to solve each problem.
Problem	When a surface is heavily folded, contiguous visible regions are often small and oddly shaped.
Problem	In these regions correspondence is essential for detailed reconstruction yet can be challenging to identify.
Method	We solve the correspondence problem both by improving the pattern printed on the surface of the cloth and by improving the method used to match regions.
Result	Our method gets more information per pixel than previous methods by drawing from the full colorspace instead of a small finite set of colors in the printed pattern.
Method	Additionally, because cloth cannot stretch much before ripping, we use strain constraints to eliminate candidates in an iterative search for correspondence.
Result	In combination, these two modifications eliminate the need for neighborhood information in the final iteration of our algorithm.
Result	As a result, we determine correspondence using regions that are 25 times smaller than in previous work ( figure 6 ).
Problem	Many regions on the surface are impossible to observe due to occlusion.
Method	We fill these holes using reconstructions of the same surface region taken from other points in time.
Method	We found that MeshIK ([Sumner et al. 2005]), a tool originally developed for mesh posing and animation, is appropriate for filling holes in cloth.
Method	In fact, MeshIK is well-suited to cloth data and we use it to bind reconstruction of our pants to motion capture data.
Method	We suggest two tools to evaluate marker-based capture systems.
Method	The first, markers per megapixel, is a measure of efficiency in capture systems.
Problem	Efficiency is important because camera resolution and bandwidth are expensive: the goal is to get more performance from the same level of equipment.
Result	This metric is designed to predict scaling as technology moves from the research lab to the professional studio.
Method	The second tool is information theory: we look at the predictive power of different cues in a capture system.
Method	By doing simple bit calculations, we direct our design efforts more appropriately.
Background	Previous work in cloth motion capture has focused on placing high density markers in correspondence between multiple views.
Problem	The primary challenge is to increase marker density while correctly assigning correspondence between markers.
Method	We suggest markers per megapixel as an appropriate metric for comparison ( figure 3 ) because it measures the method instead of the equipment.
Background	Most high density full frame-rate capture has focused on cloth, however, there has been some recent work enhancing human motion capture [Park and Hodgins 2006].
Background	These methods have far fewer markers per megapixel because they affix individual markers.
Background	When working with cloth, markers are typically painted on the surface.
Background	These markers can be broken into three categories: complex surface gradients [Pritchard and Heidrich 2003; Scholz and Magnor 2004; Hasler et al. 2006] (typically detected using SIFT descriptors [Lowe 2004]), intersecting lines [Tanie et al. 2005] and regions of constant color [Guskov and Zhukov 2002; Guskov et al. 2003; Scholz et al. 2005].
Method	Our work falls in the third category: regions of contant color.
Method	We evaluate previous work by examining the quality of the reconstructed cloth in still images and video.
Background	The most common errors are marker mismatches and are observable in reconstructions by local strain in the reconstructed surface.
Method	Overall, we observe that constant color markers perform the best.
Background	[Pritchard and Heidrich 2003] used cloth with unique line drawings as markers.
Background	Their work identifies parameterization as one of the key aspects of cloth capture.
Background	They use a stereo camera to acquire 3D and SIFT descriptors to establish correspondence.
Background	These descriptors are often mismatched and require significant pruning.
Background	They introduce a rudimentary strain metric, as measured along the surface, to rule out incorrect matches.
Background	While successful, their static reconstructions show numerous correspondence errors.
Background	The real-time system described in [Guskov et al. 2003] introduces markers of constant color, resulting in significantly fewer correspondence errors than in [Pritchard and Heidrich 2003].
Background	This system uses a Kalman smoothing filter and is heavily damped.
Background	Additionally, the complexity of the color pattern limits the method to simple geometry.
Background	[Scholz et al. 2005] improve upon [Guskov et al. 2003] by creating a non-repeating grid of color markers.
Background	Each marker has five possible colors and all three by three groups are unique.
Background	This allows substantially larger sections of cloth and virtually eliminates correspondence errors.
Background	Results include a human wearing a shirt and a skirt captured using eight 1K x 1K cameras.
Background	However, the range of motion is limited to avoid occlusion (e.g., arms are always held at 90 degrees to the torso).
Background	They use thin-plate splines to fill holes.
Background	[White et al. 2005] introduce a combined strain reduction/bundle adjustment that improves the quality of the reconstruction by minimizing strain while reconstructing the 3D location of the points on the surface of the cloth.
Background	[White et al. 2006] introduce the use of silhoutte cues to improve reconstruction of difficult to observe regions.
Result	We make three main contributions: we improve the color pattern and matching procedure to get more information per marker, we introduce strain constraints to simplify correspondence and we create a data driven hole filling technique that splices previously captured cloth into the mesh.
Result	As a result, our system is capable of capturing a full range of motion with folding and occlusion.
Method	To acquire a 3D point cloud of the cloth surface, we print a colored pattern on the cloth, sew it together, and record its motion using multiple synchronized cameras.
Method	We then reconstruct the 3D location of surface points by detecting corresponding points in multiple views ( figure 4 ).
Problem	Our goal is high marker density in the 3D reconstruction – especially in regions with high curvature.
Method	To achieve this, we need markers that are both small in scale and highly discriminative.
Method	These two goals are in tension: small markers are less discriminative.
Method	In addition, we cannot increase camera resolution without bound because camera bandwidth becomes very expensive.
Method	As a result, we opt for the smallest markers that we can reliably detect and we make small markers more distinctive.
Method	We combine information from three cues to establish correspondence: marker color, neighboring markers and strain constraints in the reconstruction.
Method	Marker color and strain constraints are more useful than neighboring markers because they place fewer requirements on local cloth geometry.
Method	Specifically, neighboring markers are observed only when the cloth is relatively flat.
Method	When the surface is heavily curved only small portions of the surface are visible before the cloth curves out of view.
Method	In subsequent sections we adopt the following strategy: maximize information obtained from marker color and eliminate the information needed from neighbors.
Method	We optimize our correspondence technique by analyzing the information provided by different cues.
Method	In this framework we can accurately minimize the number of neighbors required for correspondence and observe folds better.
Method	We can compare our work to previous methods using this framework ( figure 6 ).
Method	It takes log 2 M bits to determine the identity of each observed marker on a garment with M total markers.
Method	Because independent information adds linearly, we can compute the information needed to meet this threshold by adding information from the different cues: color, neighbors and strain.
Method	However, structural ambiguities in the pattern subtract information lost to determine which neighbor is which.
Method	This neighbor is one of four possible neighbors – thus it takes two bits to specify which neighbor we found (A = 2).
Method	However, larger marker regions have the disadvantage that curvature can cause local occlusions and prevent observation of the entire region.
Method	Our best efforts are to improve C – the number of bits from each marker observation.
Method	We do this by picking marker color from the full colorspace instead of a small discrete set of colors.
Method	We print a random colored pattern on the surface of cloth in an attempt to maximize the information available per pixel.
Method	While our pattern is composed of tesselated triangles ( figure 5 ), any shape that tiles the plane will work (squares and hexagons are also natural choices).
Method	To maximize the density of reconstructed points, we print the smallest markers that we can reliably detect.
Method	To maximize the information contained in the color of each marker, we print colors that span the gamut of the printer-camera response, then use a gaussian color model (section 4.1).
Method	From a system view, the printer-camera response is a sequence of lossy steps: we generate a color image on a computer, send the image to the printer, pose the cloth, and capture it with a camera.
Result	Our experiments suggest that loss is largely attributable to camera response because larger markers produced substantially more information.
Problem	Illumination is also problematic and takes two forms: direct illumination on a lambertian surface and indirect illumination.
Method	To correct for variations in direct illumination, we remove the luminosity component from our color modelling.
Method	We do not correct for indirect illumination.
Method	Each marker in the printed pattern has a randomly chosen color, subject to the constraint that neighboring marker colors must be dissimilar.
Method	In the recognition stage, we detect markers by comparing colors to a known color.
Method	These comparisons must be made in the proper color space: we photograph the surface of the printed cloth with our video cameras to minimize the effect of non-linearities in the printing process.
Method	The goal of our acquisition pipeline is to compute correspondence using minimal neighborhoods.
Method	We accomplish this through an iterative algorithm where we alternate between computing correspondence and pruning bad matches based on those correspondences.
Method	After each iteration we shrink the size of the neighborhood used to match.
Method	We start with N = 3 and end with N = 0.
Method	In the final iteration, markers are matched using color and strain alone.
Method	This iterative approach allows us to match without neighborhoods.
Method	This is better than label propagation methods.
Background	As shown in figure 5 , occluding contours are both common and difficult to detect.
Method	In contrast, our iterative approach relies on strain constraints – which require computing the distance between a point and a line, and color detection – which requires averaging color within a marker.
Method	Both of these computations are easier than detecting occluding contours.
Method	Our gaussian noise model has a single free parameter, the variance, which must be computed empirically for each recording setup.
Method	This variance determines the color response for the entire setup — smaller variances mean more bits from color.
Method	At this stage, we compute color information for each marker and eliminate hypothetical correspondences from further consideration that have large color differences.
Method	The size of the neighborhood is chosen so that we get more than enough bits to meet our information budget (log 2 M bits – typically 11 to 13).
Result	Because the identity of the marker is overspecified, there are few mistakes.
Method	This approach works from flat regions in the first iteration to foldy regions in the later iterations.
Method	In the first iteration, we require three neighbors to make a match.
Method	In heavily folded regions, often neighboring markers on the image do not neighbor on the surface of the cloth.
Method	As such, these regions are not going to match.
Method	In contrast, in the last iteration, no neighbors are necessary.
Method	Occluding contours, which are common in heavily folded regions, no longer disrupt the matching procedure.
Method	We use reprojection error to prune bad matches (reprojection errors average 0.3 pixels and we discard points with errors larger than 2 pixels).
Method	The first discards reconstructed points that cause physically unrealistic strain on the surface of the mesh and the second constrains our search for correspondence.
Method	Our strain constraint is based on the work of [Provot 1995] who noted that strain in cloth does not exceed 20% in practice.
Method	Relaxing the constraint to distances in 3D (surface distance is always more than the distance in 3D), we can use strain to exclude possible correspondences.
Method	Strain naturally fits in to our information theory framework: if strain excludes 87.5% of the possible correspondences, then strain has added 3 bits (because log 2 (1 − 0.875) = −3).
Method	To find correspondence, we match each image marker to a marker in the parametric domain.
Method	To do this, we define affinities a i, j between image marker i and parametric marker j.
Method	Each affinity is a product over different cues.
Method	Initially, we learned this threshold from labelled data, but we found that changing it by several orders of magnitude had little effect on our results.
Method	Subsequently, we use the value 10 −5(N+1) where N is the number of neighbors.
Problem	In the acquisition process, occlusion inevitably creates holes in the reconstructed mesh ( figure 8 ).
Problem	One would like to fill these holes with real cloth.
Result	One of our major contributions is a data driven approach to hole filling: we fill holes with previously observed sections of cloth.
Method	Our work differs from [Anguelov et al. 2005] because our hole filling procedure does not assume a skeleton that drives the surface and our procedure estimates a single coefficient per example.
Method	This hole filling procedure has a number of requirements: the missing section needs to be replaced by a section with the same topology; the new section needs to obey a number of point constraints around the edge of the hole, and the splicing method should respect properties of cloth (specifically strain).
Method	We select a reconstruction technique based on deformation gradients [Sumner and Popovic 2004].
Method	In this approach, we fit deformation gradients for the missing section to a combination of deformation gradients in other observed sections.
Method	Then, we reconstruct the point locations from the deformation gradients.
Method	This procedure has a number of advantages.
Method	First, deformation gradients naturally yield cloth like properties.
Method	Deformation gradients are the transformation matrix between triangles in two poses of the mesh.
Method	By penalizing elements that deviate in this matrix, we have a fairly direct penalty on large changes in scale or strain.
Background	In contrast, methods based on the Laplacian of the mesh ([Sorkine et al. 2004]) do little to penalize these strains and can show many artifacts around the edge of the mesh.
Method	Second, deformation gradients can be converted into vertex locations by inverting a linear system, allowing us to specify vertex locations as constraints.
Background	Methods such as [Lipman et al. 2005] don’t allow vertex constraints.
Method	We produce a mesh by forming equilateral triangles for sections of cloth that are printed with a contiguous pattern by referencing the triangle stucture of markers on the cloth.
Method	Our recovered markers are at the center of each triangle – so we average points to get out the vertices and subsequently the original mesh.
Method	We insert artificial points where two pieces of fabric come together.
Method	These points are created once per garment by hand clicking on photos of the each seam.
Method	The 3D locations of these points are recreated in each frame by averaging points near the seam.
Method	We use occlusion free meshes from other frames to automatically interpolate holes.
Method	For each hole in each frame, we cut out the missing region plus a ring of two triangles around the region.
Method	We select a set of examples of the enlarged region, then use MeshIK ([Sumner et al. 2005]) to reconstruct the surface.
Background	MeshIK works by choosing a combination of deformation gradients from the examples and then solving for the missing point locations.
Method	We use the points from the ring of known triangles around the hole as constriants in MeshIK.
Method	The most restrictive aspect of MeshIK is that it requires example meshes without holes.
Method	In practice, we never observe complete ex- ample meshes – each mesh is missing some triangles.
Method	These holes appear in different places in different meshes and we create complete meshes in an iterative method.
Method	First, we fill all holes with a naive linear algorithm (specifically, we triangulate across gaps and use barycentric coordinates to place the missing points – this gets the job done, but works poorly).
Method	Then, we do another pass through all the data, where we replace the linear sections with sections created using MeshIK on the linearly filled data.
Method	To downweight the linear data, we select the examples with the highest percentage of viewed points in the missing section.
Method	These frames are then used as examples in MeshIK to hole fill in the rest of the sequence.
Method	For the pants capture, we iteratively refine a set of 27 extreme poses which were captured specifically for filling holes.
Method	The advantage of this apporach is that the example poses are chosen to capture the relevant degrees of freedom – yielding better results.
Method	For the cloth toss sequence, we chose the simpler approach: iteratively refine the entire sequence.
Method	We introduce flexibility preserving smoothing – a method similar to anisotropic diffusion [Perona and Malik 1990] that smoothes near-rigid movement without effecting flexible deformation.
Problem	Typical temporal smoothing is dangerous because fast non-rigid movements can easily become physically implausible when blurred over time.
Problem	However, because fast non-rigid regions of the cloth are complex, small temporal errors are often difficult to notice.
Problem	In contrast, small errors in regions of the cloth that move rigidly are typically easy to observe.
Method	As a result we use flexibility preserving smoothing, a procedure that smoothes rigid movement more heavily than non-rigid movement.
Method	To do this, we take a local region around each vertex in the mesh (typically 25 points) and compute a rigid transformation to previous and subsequent frames.
Method	Aligning the regions with this transformation, we compute the movement of the vertices in this reference frame as a proxy for rigidity.
Method	Large variations in location indicate non-rigid movement and consequently receive little smoothing.
Method	Smaller variations indicates rigid movement and benefit from more substantial smoothing.
Method	We use a size adjusted gaussian to smooth in this reference frame.
Method	Our video sequences were taken with synchronized firewire cameras (Foculus FO214C) with a capture resolution of 640 x 480 and a capture rate of 24 frames per second.
Method	Our still captures were taken using a digital SLR camera and then downsampled to approximate available video resolutions.
Method	We use the automated calibration technique in [White and Forsyth 2005], but any standard calibration will work ([Zhang 2002] and [Bouguet 2005] are good choices).
Method	In the pants sequences, we used seven lights totalling 1550 Watts to illuminate the scene.
Method	Adequate lighting is critical: from our experience fewer lights degrade performance due to harsh shadows and dim lighting causes motion blur through slower shutter speeds.
Method	Our cloth was printed by a digital mail order fabric printing service.
Method	On a P4 2.4 GHz machine, acquisition takes roughly 6 minutes and mesh processing 2 minutes per frame.
Method	Code is written in MATLAB.
Result	Our capture results are best evaluated by looking at our video and figures 1,12,13.
Result	Much of the cloth is in contact with the floor and unobservable – yielding fewer bits of strain.
Result	In addition, the camera images were not output in a linear color space, reducing the number of color bits.
Result	As a result, we terminated the correspondence algorithm at N = 2.
Result	Our pants animation is by far the most challenging, and we analyze some of the details a little more closely.
Result	With an average of 2405 observed markers, there were 979 3D markers per megapixel.
Result	If we factor out the pixels lost to background, we get 3500 3D markers per foreground megapixel or 282 foreground pixels per recovered 3D marker.
Result	Our marker observations average 56 pixels per marker per image.
Result	This approach covers a reasonably large range of motion, but ignores cloth dynamics.
Method	The largest challenge is that captured cloth meshes contain only points on the cloth surface, so we do not know joint locations.
Method	Instead, we insert proxy points for knee and hip joints in each of our basis meshes.
Method	These points are then connected to a small set of nearby triangles in the original mesh.
Method	For each frame of animation we set the proxy points’ locations according to joint angles in the skeletal mocap data.
Method	The resulting transformed joints are used as constraint points in MeshIK, which produces the final output meshes.
Result	Using our MATLAB implementation of MeshIK, this process takes around 5-10 seconds per frame.
Method	We use the same 27 bases poses for MeshIK based reconstruction.
Method	In order for a small basis to adequately express a full range of motion, each basis pose must be an extreme configuration.
Method	For simple objects such as a cylinder, a small bend (for example) is sufficient to extrapolate to a larger bend [Sumner et al. 2005].
Method	However, for pants the relationship is more complex: the fact that no folding occurs in a small bend does not imply that folding will be absent in a larger bend.
Method	Conversely, if a decent amount of folding occurs in a small bend, we do not expect extreme folds in a corresponding larger bend.
Result	As a result, MeshIK is most useful when a basis is carefully chosen to prevent extrapolation artifacts.
Result	One drawback to our approach is the loss of secondary kinematic motion, such as the sway of loose cloth.
Result	Because MeshIK does not use velocity information, the resulting animation appears damped.
Result	We have brought cloth capture from constrained laboratory examples to real settings by providing robust methods for dealing with occlusion and folding.
Result	Like human motion capture, this tool requires significant engineering effort.
Result	Camera setup and calibration are time consuming and the equipment is costly.
Result	However, once these obstacles have been overcome, capturing large amounts of data is relatively easy.
Result	So that other researchers can benefit from our work, we are releasing our capture data at http://www.ryanmwhite.com/data.
Result	In our video, we show some of the uses of this data, including editing using [Kircher and Garland 2006] and posing using [Sumner et al. 2005].
Future Work	Future work in cloth capture should involve more cameras, higher resolution (leading to smaller denser markers), different garments and different materials.
Future Work	We plan to pursue more tools to edit and repurpose captured data.
Background	Simulation and image based rendering both provide methods to generate animation of cloth (a limited simulation list includes [House and Breen 2000; Terzopoulos et al. 1987; Choi and Ko 2002; Bridson et al. 2003; Baraff et al. 2003] and a limited image based rendering list includes [Bradley et al. 2005; White and Forsyth 2006; Lin and Liu 2006; Scholz and Magnor 2006]).
Background	These methods have several advantages: simulation gives significant user control and produces higher resolution meshes while image based rendering techniques produce more accurate illumination.
Problem	However, capturing large amounts of data is far easier than simulating large amounts of data and provides more control than image based rendering.
Problem	Common simulation complaints include long computation times, significant parameter tweaking and tangling.
Result	In contrast, capture is relatively quick (our code is 8 minutes per frame in MATLAB); parameters are set by selecting the type of cloth [Bhat et al. 2003] and tangling is relatively uncommon.
Result	Cloth capture makes it easy to capture large amounts of cloth, including fast light cloths that create instabilities in simulation.
Result	An added attraction of cloth capture is that complex interaction between the cloth and the body is recorded without complicated human models.
Method	We do some pre-processing to get marker locations and connectivity from raw images.
Background	We recommend readers unfamiliar with these techniques refer to [Forsyth and Ponce 2002].
Method	We start by converting each image to HSV, disregarding the luminosity (V) and using polar coordinates to compute distances in hue and saturation.
Method	To detect markers, our code looks for uniformly colored blobs in two stages: first regions are built by growing neighborhoods based on similarity between pixels.
Method	This method is sensitive to image noise and can produce oversized regions when the color boundaries are smoothed.
Method	The second stage takes the center of mass of each blob from the first stage, computes the mean color and grows a region based on distance to the mean color (it is computationally intractable to use this as the first stage of the blob detection).
Method	The process is iterated for increasing thresholds on the affinity value in the first stage, using the portions of the image where detection failed in previous stages.
Method	Finally, blobs are thresholded based on size.
Method	Next, we need to determine the neighborhood relationships.
Method	For each marker, we construct a covariate neighborhood (a fitted ellipse) and vote for links to the three closest markers with similar covariate neighborhoods.
Method	This measures distances appropriately in parts of the scene where the cloth is receding from view and discourages links between markers with wildly different tilts.
Method	All links that receive two votes (one from either side) are kept while the rest are discarded.
Method	Links that bridge markers with conflicting color information are also discarded (typically on internal silhouettes).
Background	For more reading on information theory, consult [Cover and Thomas 1991].
Method	Our analysis is based on the information entropy definition: H(X) = − ∑ n i=1 p(x i ) · log 2 x i .
Background	For [Scholz et al. 2005], the equation in section 3.1 is reduced to I = 9 ∗ C − A because they use 8 neighbors and no strain constraints.
Background	They use 5 colors which, without errors, yields C = log 2 5 bits per marker.
Background	They cite an error rate of five to ten percent.
Background	As a result, they recover anywhere from 1.65 to 2.04 bits per marker.
Method	In our comparison, we use C = 1.93 bits for color information from their method (five percent error, with equal probabilities for all remaining choices).
Method	Note that this is effectively less than four colors!
Method	Second, we compute structural ambiguities in their method which account for uncertainty in observations.
Method	The orientation of the surface is unknown, yielding four possible directions, or two bits of structural ambiguity.
Background	Second, in their paper, they say that oblique views cause another bit of uncertainty.
Background	As a result A = 3 bits.
Method	For our work, C is an empirical observation.
Result	Depending on the lighting and camera configuration, we get anywhere from 5 to 7 bits.
Method	We use the conservative estimate of C = 5 bits per marker.
Method	Second, our mesh is triangular and there are three possible neighborhood rotations, yielding A = log 2 3 = 1.59 bits of structural ambiguity.
Method	When neighborhoods are not used, there is no structural ambiguity.
Result	Strain information is difficult to compute and depends on the geometry of the surface and the orientation of the camera.
Result	In most cases, we observe more than 9 bits of strain information.

Background	Back and Forth Error Compensation and Correction (BFECC) was recently developed for interface computation by using the level set method.
Problem	We show that it can be applied to reduce dissipation and diffusion encountered in various advection steps in fluid simulation such as velocity, smoke density and image advections.
Result	BFECC can be implemented easily on top of the first order upwinding or semi-Lagrangian integration of advection equations, while providing second order accuracy both in space and time.
Result	When applied to level set evolution, BFECC reduces volume loss significantly.
Method	We combine these techniques with variable density projection and show that they yield a realistic animations of two-phase flows.
Result	We demonstrate the benefits of this approach on the image advection and on the simulation of smoke, of bubbles in water, and of a highly dynamic interaction between water, a solid, and air.
Problem	Simulation of incompressible fluid involves several computation steps including diffusion, advection and pressure projection.
Background	Advection steps transport some quantities from one region to another along the fluid’s velocity field.
Problem	In this paper, we explore four forms of advection encountered in fluid simulation: velocity, smoke density, image and level set advections.
Problem	Velocity advection transports the velocity field along the velocity itself.
Method	This step is always needed in nonsteady flow simulation based on Navier-Stokes equation.
Problem	Smoke density advection transports smoke along the velocity field.
Problem	Sometimes, we may want to advect a colored image, which may be considered as colored smoke.
Method	We call this process image advection.
Problem	When one uses a level set method [OS88] to simulate a free surface or a two-phase flow, for example a water surface simulation, the level set must be transported as well.
Method	We call it level set advection.
Problem	Those advection steps can be computed by an upwind or a semi-Lagrangian method.
Background	The latter is often preferred due to its stability for large time step.
Background	The first order semi-Lagrangian method is popular in computer animation because of its simplicity.
Background	However, the first order semiLagrangian contains a significant amount of numerical diffusion and dissipation.
Background	In velocity advection, it yields damped fluid motion.
Background	In smoke density advection, it leads to a premature dilution of smoke, and is not able to simulate pure advec- tion.
Background	Therefore, higher order schemes, such as WENO or CIP [ TFK ∗ 03 ], are desired.
Result	We show that the implementation complexity of these schemes may be easily avoided by adding a very simple Back and Forth Error Compensation and Correction (BFECC) to an existing first order semiLagrangian schemes, thus improving its space and time accuracy to second order.
Result	We show that this approach reduces velocity damping and smoke density dilution and demonstrate its benefits on the four forms of advections discussed previously.
Background	BFECC was recently proposed in [DL03, DL04] as a level set interface computation method.
Background	As is mentioned in [ELF05], high order methods may not prevent volume loss much.
Background	However, the authors of [DL03] combined BFECC with their simple redistancing technique and applied it to the Zalesak’s problem, showing significantly reduced the volume loss.
Method	We, however, use BFECC and the simple redistancing for level set advection of various fluid simulations and show that sufficiently realistic fluid animation can be obtained.
Method	It would be interesting to apply this to the level set advection part of the particle level set method [ELF05] for more demanding simulation.
Background	The stability problems in the earlier works such as [ FM96 ] were successfully remedied in [ Sta99 ] by introducing the pressure projection scheme to enforce incompressibility of the fluid and the semi-Lagrangian treatment of the advection term in the Navier-Stoke equation.
Background	This solution is popular for the simulation of incompressible Fluids, such as smoke [ FSJ01 ] and also for more challenging free surface flows [ FF01 , EMF02 ].
Background	The semi-Lagrangian velocity advection [Sta99] comes with built-in dissipation, i.e., the velocity is dissipated quickly since the linear interpolation in the first order semiLagrangian produces large error.
Background	While higher order interpolation can solve the problem, it involves more neighboring grid point values and increases the complexity, particularly when non-uniform mesh structures are used.
Background	In [FSJ01], vorticity is added to generate small scale fluid rolling motion.
Background	Recently, [ SSK05 ] addressed this built-in dissipation by enhancing advection itself.
Background	They adopted the CIP [ TFK ∗ 03 ] method that increases the order of accuracy in space by introducing the derivatives of velocity to build a sub-cell velocity profile.
Background	A nice feature of this CIP method is that it is local in the sense that only the grid point values of one cell are used in order to update a point value.
Background	However, in this CIP method, all components of velocity and their partial derivatives should be advected, increasing the implementation complexity and computation time, especially in 3D.
Background	It is also worth noting that CIP has higher order accuracy in space only.
Background	Therefore high order integration of characteristics is also necessary.
Background	In contrast, BFECC is easier to implement and exhibits second order accuracy both in space and time and is local during each of its operational steps.
Background	Song et al [ SSK05 ] focused on applying CIP to generate more dynamic water surface behavior.
Background	However, we believe that having less dissipative and diffusive advection provides significant benefits in smoke simulations as well.
Background	In contrast, when BFECC is used, the smoke keeps full brightness throughout the simulation as is shown in the last five images.
Background	The introduction of the level set method to fluid animation in [ FF01 ] allowed realistic simulation of fluids with complex free surfaces.
Background	The problem left here was the volume loss in the level set method and the solution, known as the particle level set method, proposed subsequently in [ EMF02 ], turned out to be very successful in volume preservation.
Background	The two phase fluid solver using variable density projection has been broadly studied in mathematics and fluid mechanics [ SSO94 , OKBG00 , HKLS04 ].
Background	It has been used in graphics applications by [ HK03 ], where the authors simulated air bubbles rising and merging and by [TFK ∗ 03, SSK05], where splash style interactions between water surface and air are studied.
Method	We follow the operator splitting steps proposed in [Sta99] except for the advection step, where we use BFECC and for the projection step for which we use the variable density pressure projection.
Method	We use the standard staggered grid [FSJ01].
Method	Suppose all terms in (1) except for − ρ 1 ∇P are treated and let the velocity obtained so far be u.
Method	̃ The final step is applying the variable density pressure projection step to enforce the continuity equation ∇ · u = 0, i.e, solving the equation ∇ · ∆t ρ ∇P = ∇ · u.
Method	̃ Its first order discretization is ∆x ∆t 2 P i, ρ j − i− P 2 1 i−1, , j j + P i, ρ j − i+ P 1 2 i+1, , j j + P i, ρ j − i, j− P i, 2 1 j−1 + P i, ρ j − i, j+ P i, 2 1 j+1 1 = ∆x u  ̃ i+ 2 1 , j − u  ̃ i− 2 1 , j + v  ̃ i, j+ 1 2 − v  ̃ i, j− 1 2 .
Method	(2) We assume ∆x = ∆y here and through the rest of the presentation.
Method	The extension to 3D is straightforward and hence omitted.
Method	This first order approximation is identical to [ SSK05 ] and higher order formulations can be found in [ ABS96 , SAB ∗ 99 ].
Method	Obviously, if ρ is constant, we have the pressure projection ∆t ρ ∇ 2 P = ∇ · u introduced in [ Sta99 ].
Method	We also include a simple implementation of surface tension similar to [ SAB ∗ 99 ].
Method	Since we want to apply it to various advections, we use φ to denote a quantity that is advected and reserve the symbol φ for the level set function through the presentation of this paper.
Method	If the advection step L(·, ·) is exact, the first two forward and backward steps should return the value exactly the same as the original one, i.e., φ n = φ  ̄ .
Method	Then the first two forward and backward steps will produce error 2e, i.e., φ  ̄ = φ n + 2e.
Method	Therefore, the error can be computed as e = − 1 2 ( φ n − φ  ̄ ).
Method	We subtract this error e before the final forward advection step.
Method	Then the equation (5) becomes φ n+1 = L(u, φ n − e).
Method	This step will add an additional e, which will be cancelled by the subtracted amount −e.
Method	This method is proven to be second order accurate both in space and time [DL03, DL04].
Method	First let the function SingleStep(u, v, φ n , φ n+1 ) implement upwind or semiLagrangian integration of the scalar field φ , which can be the velocity components u,v,w, the smoke density, RGB colors of an image or the level set function φ .
Method	Then BFECC is implemented as:        SingleStep(u, v, φ n , φ  ̃ ) SingleStep(−u, −v, φ  ̃ , φ  ̄ ) φ  ̃ := φ n + ( φ n − φ  ̄ )/2 SingleStep(u, v, φ  ̃ , φ n+1 )
Method	We can use (5) to implement the velocity advection step in solving the Navier-Stokes Equation.
Method	In this case, φ becomes u, v and w.
Result	We show that BFECC can improve the damping in the first order semi-Lagrangian implementation of velocity advection, which is a well known drawback of [Sta99].
Method	For multiphase flow, this BFECC needs to be turned off near the interface to prevent velocities of different fluids with different densities from being mixed, which creates momentum changes.
Method	We simply turn BFECC off, i.e., use the first order semi-Lagrangian, for the grid points where | φ | < 5∆x.
Method	We also turn it off near the boundary.
Method	Notice that reducing velocity dissipation is equally important in the entire fluid domain, not only near the interface.
Method	In other words, turning BFECC off near the interface has little effect since it is still turned on in most of the fluid domain.
Result	As is shown in Fig. 2 , applying BFECC adds details in smoke motion.
Method	Notice that these details cannot be obtained from the vorticity confinement method [FSJ01], which only adds small scale rolling motions.
Method	We also performed the same test in a coarser grid of 100×40.
Result	In this case, the flow did not fluctuate at all around the obstacles with the first order semi-Lagrangian advection.
Result	However, when BFECC was added, the flow fluctuated as in the refined grid.
Result	We conclude that BFECC creates a physically correct fluctuations in a coarser grid.
Result	Velocity advection can also be important when rigid bodies are involved.
Method	We also apply BFECC to the advection of smoke density for the smoke simulation.
Method	As is shown in [DL03], BFECC is linearly stable in l 2 sense, i.e., ||a|| l 2 = ∑ |a i j | 2 is bounded, when the velocity field is constant, where a is the smoke density.
Method	However, density values a i j can become negative or greater than 1.0 for some grid points.
Method	In our simulation, this problem was not significant and we simply clamped those values to stay in [0, 1].
Method	To measure the diffusion/dissipation amount, we design a test problem similar to Zalesak’s problem.
Method	Instead of the notched disk, we place a color image and rotate it 360 degree and then compare it with the original image as is shown in Fig. 5 .
Result	As is shown in (d), the dissipation of the color is significantly reduced with BFECC.
Result	During the advection, the image is also diffused to neighboring region, even though it is not visible.
Method	To visualize the diffusion amount, we plot background pixels as blue to show the region where the image has been diffused into.
Result	As is shown in (d), the color of the object is little diffused into neighboring region when BFECC is used.
Result	Also notice that the size of the image looks smaller and its position is noticeably different from the original location in (c), which is again fixed in (d) where BFECC is used.
Result	The computation time was 0.156 sec (without BFECC) and 0.36 sec (with BFECC) per frame on a 3GHz Pentuim4.
Background	Advection is often used for scientific visualization, especially for various forms of flow visualization.
Background	For example, [JEH02] uses semi-Lagrangian advection of dye to visualize the vector field.
Background	[Wei04] applied level set method to advect dye without diffusion.
Background	Only one dye color is allowed and the dye cannot be diffused at all.
Background	Also level set implementation is needed.
Method	In contrast, BFECC is trivial to implement and provides advection of fully colored pattern of dye, if necessary.
Result	As is shown in Fig. 3 , the dissipation/diffusion is very small.
Future Work	Thus, we believe that it can be used in flow visualization as well.
Future Work	This remains as a future work.
Method	Even though, BFECC still has some volume loss in fluid simulation, especially for small droplets or thin filaments, it is still interesting to show how BFECC performs in the fluid simulation since it is trivial to implement and fast.
Method	When we use the BFECC for level set advection, i.e., φ = φ , redistancing is needed to keep the level set function as a signed distance function.
Method	This equation can be solved by applying first order upwinding in discretizing the term w · ∇φ .
Method	An alternative is the semi-Lagrangian style integration, i.e., φ n+1 = φ n (x − w∆ τ ) + sgn( φ n )∆ τ , where x is the location of each grid point.
Method	Hence, φ n (x − w∆ τ ) is the φ value of previous location.
Method	When these integration formulae for (6) are combined with BFECC, the redistancing tends to spoil good φ values computed from the second order accurate BFECC.
Method	This leads to the idea of turning redistancing off near the interface to keep good φ values there.
Method	The conditions to turn off redistancing is provided in [DL03], where the significant enhancement were shown for the Zalesak’s problem.
Method	This simple redistancing is crucial in preserving volume [DL03].
Method	It is also easy to implement since it simply requires to perform redistancing at the points where at least one of the following two conditions are met.
Method	• When the grid point is not close to the interface, i.e., when φ i, j has the same sign with its eight neighbors.
Method	• When the slope is sufficiently high, i.e., when | φ i, j − φ i±1, j | or | φ i, j − φ i, j±1 | ≥ 1.1∆x.
Method	We test BFECC in different fluid simulations.
Method	We simulate air-water and olive oil-air interactions.
Method	Water is rendered as bluish surface and olive oil is rendered in yellowish color.
Method	We use PovRay ( http://povray.org ) to render images.
Method	The cup is released upside down near the water surface.
Result	Due to its weight, the cup sinks deep into water but it soon rise again because of the air in it.
Result	However, in the top, we turned BFECC off for velocity advection and hence the water became dissipative, preventing the cup from tumbling.
Result	In the bottom, we use BFECC for velocity advection, where the velocity dissipation is small and hence the cup can tumble 180 degree.
Result	This example indicates that reducing velocity dissipation could be important in simulating fluid and rigid body interaction.
Method	We implement the rigid fluid method [CMT04] to simulate rigid body and fluid interaction in Fig. 1 and 7.
Method	We use multiple pressure projections to address the seeping problem mentioned in [CMT04].
Result	The computation time varies in situations such as the complexity of fluid motions.
Result	In simple bubble rising situation without rigid body, it took a few seconds per time step using a 50 3 mesh.
Result	The cup example in Fig. 7 has multiple pressure projections and it took about 30 to 130 seconds per time step on a 70 3 grid.
Result	We have shown that the BFECC scheme can be used to improve the simulation of fluids.
Result	Once the simple first order upwinding or semi-Lagrangian steps for velocity, smoke density, image or level set advections are implemented, BFECC can be added with a trivial amount of code.
Result	We show that this simple extension yields significant enhancements in reducing diffusion and dissipation in velocity, smoke, image advection and in preserving volume under various situations including two-phase flows and rigid bodies.

Problem	In this article, we present a semi-Lagrangian surface tracking method for use with fluid simulations.
Method	Our method maintains an explicit polygonal mesh that defines the surface, and an octree data structure that provides both a spatial index for the mesh and a means for efficiently approximating the signed distance to the surface.
Method	At each timestep, a new surface is constructed by extracting the zero set of an advected signed-distance function.
Method	Semi-Lagrangian backward path tracing is used to advect the signed-distance function.
Result	One of the primary advantages of this formulation is that it enables tracking of surface characteristics, such as color or texture coordinates, at negligible additional cost.
Result	We include several examples demonstrating that the method can be effectively used as part of a fluid simulation to animate complex and interesting fluid behaviors.
Problem	The fundamental problem of tracking a surface as it is advected by some velocity field arises frequently in applications such as surface reconstruction, image segmentation, and fluid simulation.
Problem	Unfortunately, the na ̈ ive approach of simply advecting the vertices of a polygonal mesh, or other explicit representation of the surface, quickly encounters problems such as tangling and self-intersection.
Background	Instead, a family of methods, known as level-set methods, has been developed for surface tracking.
Background	These methods represent the surface implicitly as the zero set of a scalar field defined over the problem domain.
Background	The methods are widely used, and the texts by Sethian [1999] and Osher and Fedkiw [2003], and Osher and Sethian’s [1988] seminal article, provide an excellent introduction to the topic.
Background	One of the key issues that distinguishes various level-set and similar approaches is the representation of the scalar field, which must capture whatever surface properties are important to a given application.
Problem	In this article we present a surface tracking method that explicitly represents the surface as a set of polygons.
Method	A new polygonal surface is generated by contouring or extracting the zero set of ψ.
Method	The value of ψ at a point x, at current time t, is obtained by first tracing backward through the flow field to find the previous location x at time t − t, and then returning the signed distance of x from the previous surface.
Method	Using adaptive octree data structures, we can efficiently and reliably construct the new surface and corresponding signed-distance function.
Method	The theoretical framework for this method comes from a series of articles by Strain [1999b, 1999c, 1999a, 2000, 2001] that described and analyzed a method for contour tracking in two dimensions.
Method	While the semi-Lagrangian procedure for backward advection does not change significantly when going from twoto three-dimensional problems, significant surface tracking issues arise when moving to three dimensions.
Problem	This article discusses these issues, as well as the general method, and demonstrates how semi-Lagrangian surface contouring can be useful for animating the complex and interesting behavior of fluids.
Result	One of the primary advantages of this method is that it enables tracking surface characteristics, such as color or texture coordinates.
Result	These properties can be easily stored directly on the polygonal mesh and efficiently mapped onto the new surface during semi-Lagrangian advection.
Result	The explicit surface representation also facilitates other common operations, such as rendering, while reconstruction from a scalar function allows operations that rely on an implicit representation.
Result	Finally, the method produces detailed, well-defined surfaces that are suitable for realistic animation and that do not jitter or exhibit other undesirable behaviors.
Method	Our method pulls together solutions to a number of well-studied problems to arrive at a method for tracking surfaces.
Background	Because surface tracking arises in a variety of contexts, the topic has received a significant amount of attention.
Background	Even in the limited context of fluid animation, there has been a great deal of excellent work on simulating fluids with free surfaces, including Foster and Metaxas [1996], Foster and Fedkiw [2001], Enright et al. [2002b], Carlson et al. [2002, 2004], Losasso et al. [2004], Goktekin et al. [2004], Hong and Kim [2005], Wang et al. [2005], Guendelman et al. [2005], and Zhu and Bridson [2005].
Background	The methods available for tracking free surfaces of liquids can be roughly sorted into four categories: level-set methods, particle-based methods, particle level-set methods, and semi-Lagrangian contouring.
Background	Many of the most successful solutions to the surface tracking problem are based on level-set methods, which were originally introduced by Osher and Sethian [1988].
Background	A complete review of level-set methods is beyond the scope of this article, and we recommend the excellent surveys by Sethian [1999] and Osher and Fedkiw [2003].
Background	Level-set methods represent a surface as the zero set of a scalar function which is updated over time by solving a partial differential equation, known as the level-set equation.
Background	This equation relates change of the scalar function to an underlying velocity field.
Background	By using this implicit representation, level-set methods avoid dealing with complex topological changes.
Background	However, the scalar function is defined and maintained in the embedding three-dimensional space, rather than just on the two-dimensional surface.
Background	In practice, scalar function values need only be accurately maintained very near the surface, resulting in a cost that is roughly linear in the complexity of the surface.
Background	One difficulty with level-set methods is that they generally require very high-order conservation-law solvers, though fast semi-Lagrangian methods have been shown to work in some cases [Strain 1999b; Enright et al. 2005].
Background	The most significant drawback to using level-set methods to track liquid surfaces is their tendency to lose volume in underresolved, high-curvature regions.
Background	See Enright et al. [2002a] for an excellent discussion of the reasons for this volume loss.
Background	Bærentzen and Christensen [2002] built a sculpting system using a level-set surface representation which could be manipulated by a user with a variety of sculpting tools.
Background	Like us, they used adaptive grid structures to store the scalar field.
Background	However, they used a two-level structure rather than a full octree.
Background	They also used semi-Lagrangian methods to update their level-set function.
Background	However, when evaluating the distance function after the semi-Lagrangian path tracing, they interpolated distance values stored on a regular grid, while our explicit surface representation allows us to compute exact distances near the surface.
Background	Sussman and Puckett [2000] coupled volume-of-fluid and level-set methods to model droplet dynamics in ink-jet devices.
Background	Volume-of-fluid [Hirt and Nichols 1981] techniques represent the surface by storing, in each voxel, a volume fraction—the proportion of the voxel filled with liquid.
Background	Any cell whose fraction is not one or zero contains surface.
Background	Unfortunately, this representation does not admit accurate curvature estimates, which are essential to surface tension computations.
Background	However, accurate curvature estimates are easily computed from level-set representations.
Background	Thus, the authors combined volume-of-fluid and level-set representations to model surface tension in ink droplets.
Background	Some volume-of-fluid methods build an explicit surface representation from the volume fractions stored in each voxel.
Method	The key difference between our method and volume-of-fluid methods is that we never compute volume fractions.
Method	Instead, our explicit representation is generated by contouring an advected signed-distance function.
Background	A number of researchers [Terzopoulos et al. 1989; Desbrun and Gascuel 1995; Foster and Metaxas 1996; Desbrun and Cani 1996; Cani and Desbrun 1997; Stora et al. 1999; M uller  ̈ et al. 2003, 2004; Premo ze et al. 2003; Zhu and Bridson 2005; Pauly et al. 2005] have used particles to track surfaces.
Background	In many of these methods, the simulation elements are particles, which are already being tracked throughout the volume of the deforming liquid or solid.
Background	The surface can then be implicitly defined as the boundary between where the particles are and where they aren’t.
Background	The particles can be visualized directly, or can be used to define an implicit representation using blobbies or moving least-squares methods.
Background	Premo ze et al. [2003] went a step further and used particle positions and velocities to guide a level-set solution.
Background	Mueller et al. [2004] and Pauly et al. [2005] used special particles, called surfels, to represent the surface.
Background	Surfels store a surface normal as well as position and there are generally many more surfels than simulation particles.
Background	The principal drawback of these methods is that generating high-quality time-coherent surfaces can be difficult: directly visualizing the particles is insufficient for high-quality animations, methods which convert the particles to some other representation on a per-frame basis often lack temporal coherence, and methods which must run sequentially through the frames or run during the simulation are often quite costly.
Background	Additional difficulties arise when trying to ensure a good sampling of the surface.
Background	To address the volume loss of level-set methods, Enright and his colleagues [2002a, 2002b, 2005] built on the work of Foster and Fedkiw [2001] to develop particle level-set methods.
Background	These methods track the characteristics of the fluid flow with Lagrangian particles, which are then used to fix the level-set solution, essentially increasing the effective resolution of the method.
Background	Recently, these methods have been extended to work with octrees [Enright et al. 2005; Losasso et al. 2004], allowing for very high-resolution surface tracking.
Background	These methods represent the current state of the art on tracking liquid surfaces for animation, but do have some drawbacks.
Background	In particular, the published particle correction rules choose a single particle to provide the signed-distance value.
Background	Since there is no guarantee that the same particle will be chosen at subsequent timesteps, the method is extremely susceptible to high-frequency temporally incoherent perturbations of the surface.
Background	The artifacts are most noticeable when the surface thins out below the grid resolution and particles happen to be near some of the sample points, but not others.
Background	Also, the method has a large number of parameters and rules, such as the number of particles per cell and the reseeding strategy, which need to be decided, often in an application-specific way.
Background	Finally, the method tends to produce very smooth surfaces with very little detail, which is desirable in some, but not all, applications.
Background	Despite these drawbacks, the particle level-set methods have been very successful and represent a significant step forward in the area of surface tracking for liquid simulations.
Background	Recently, Strain [1999b, 1999c, 1999a, 2000, 2001] has written a series of articles building a theoretical framework culminating in the formulation of surface tracking as a contouring problem.
Background	He demonstrated his semi-Lagrangian contouring method on a variety of two-dimensional examples.
Method	Our method is based on the method presented by Strain [2001], but with variations and extensions to deal with problems that arise in three-dimensional computer animation.
Method	While our method bears a number of similarities to level-set methods and takes advantage of many techniques developed for those methods, we are not directly solving the level-set equation.
Method	By formulating surface tracking as a contouring problem, we avoid many of the issues that complicate level-set methods.
Method	In particular, we do not have the same volume loss issues which prompted the particle levelset methods: while we do not explicitly conserve volume, our semi-Lagrangian path tracing tends to conserve volume in the same way as the Lagrangian particles in the particle level-set method.
Method	The octree structure we use to build and index the polygonal mesh is quite similar to adaptively sampled distance fields [Frisken et al. 2000].
Background	These structures adaptively sample distance fields according to local detail and store samples in a spatial hierarchy.
Method	The key difference between adaptively sampled distance fields and our surface representation is that we store a polygon mesh in addition to distance samples.
Method	This polygon mesh is used for exact evaluation of the distance function near the surface.
Method	Additionally, our splitting criterion is different from that presented by Frisken et al. [2000].
Background	An alternative structure for storing narrow-band level-set functions is the dynamic tubular grid of Nielsen and Museth [2006].
Background	This structure can be combined with run-length encoding schemes [Houston et al. 2006], providing extremely compact, high-resolution representations of level-set functions.
Background	While the asymptotic times for their structure match ours, they are able to exploit cache coherence to provide extremely fast run times for most level-set operations.
Future Work	Integrating the methods presented here with this data structure is a promising area for future work.
Method	As our title suggests, we formulate surface tracking as a contouring problem.
Background	The contouring problem has been well studied in computer graphics and a number of approaches have been suggested.
Background	The oldest and most widely used is marching cubes, which was first presented by Wyvill et al. [1986], and later named and popularized by Lorensen and Cline [1987].
Background	Marching cubes suffers from a tendency to create ill-shaped triangles.
Background	This problem is fixed to some degree by dual contouring [Ju et al. 2002], which also provides adaptive contouring and an elegant means of preserving sharp boundaries.
Background	Dual contouring depends on normal estimates at edge crossings and is very sensitive to inaccuracies in these normal estimates.
Method	Unfortunately, in our method we do not have accurate normal information until after the contouring step, when we have the triangle mesh.
Background	More recently, Boissonnat and Oudot [2003] presented a contouring technique which uses Delaunay triangulation methods to generate provably good triangulations.
Background	However, this method appears to be prohibitively expensive for something which must run at every timestep.
Background	Yet another alternative is marching triangles [Hilton et al. 1996], which takes a surface-based rather than volume-based approach to contouring.
Background	Marching triangles requires significantly less computation time and fewer triangles, and produces higher-quality triangles than marching cubes.
Background	Unfortunately, marching triangles is not guaranteed to produce closed, manifold meshes in the presence of sharp or thin features.
Background	Semi-Lagrangian methods have been widely used in computer graphics since they were introduced by Stam [1999] to solve the nonlinear advection term of the Navier-Stokes equations.
Method	These methods provide the foundation for our surface tracking method.
Method	Consequently, we briefly discuss the mathematical foundation of semi-Lagrangian methods.
Method	Our discussion follows that of Strain [1999b].
Method	Thus we can find φ values at any time t by finding the characteristic curve passing through (x, t), following it backward to some previous point (x 0 , t 0 ) where the value of φ is known, and setting φ(x, t) = φ(x 0 , t 0 ).
Background	This observation forms the basis of the backward characteristic or CIR scheme developed by Courant, Isaacson, and Rees [1952], which is the simplest semi-Lagrangian scheme.
Method	Then φ(x, t n+1 ) is set equal to the interpolated value, φ(s(t n ), t n ).
Method	For linear PDEs, such as Equation (1), the Lax-Richtmyer equivalence theorem [LeVeque 1990] guarantees that CIR will converge to the exact solution as t, x → 0 if it is stable and consistent.
Method	The stability properties of the CIR scheme are excellent.
Method	Each new value φ(x, t n+1 ) is a single interpolated value of φ at time t n , so unconditional stability is guaranteed in any norm where the interpolation does not increase norms.
Method	For example, CIR with linear interpolation is unconditionally stable in the 2-norm.
Method	In general, semi-Lagrangian schemes satisfy the CFL condition by shifting the stencil, rather than restricting the timestep.
Method	Thus information propagates over long distances in one timestep.
Method	Consistency (loosely speaking, the local accuracy of the method), however, is conditional.
Method	Thus CIR is consistent to O( t) if a condition t ≥ O( x) is satisfied, contrary to the usual hyperbolic condition t ≤ C x.
Method	This condition is extremely convenient, because t = O( x) balances time and space resolution in this first-order accurate scheme.
Method	For nonlinear PDEs, CIR still converges when the solution is smooth.
Method	But nonsmooth shock solutions of conservation laws move at the wrong speed because CIR is not in conservative form.
Method	Since level-set solutions have no shocks, CIR is a natural scheme for moving interfaces.
Problem	The surface tracking problem can be phrased as: given a surface representation and a velocity field at time t, build a representation of the surface at time t + t.
Method	We begin with a triangle mesh and an octree annotated with signed-distance field samples.
Method	We could try to advect the mesh points through the flow field, but would quickly encounter significant topological difficulties.
Method	Instead, we avoid topological issues by updating the surface using an implicit representation.
Method	The implicit representation is then used to construct a new mesh at the current timestep.
Method	More specifically, we define a scalar-valued function which relates the surface at the current timestep to the surface at the previous timestep.
Method	Next, we extract the zero set of this function using a contouring algorithm.
Method	Finally, a new signed-distance field is computed through a process known as redistancing (see Figure 1 ).
Method	One of the key differences between our method and other surface tracking methods is that we build an explicit representation of the surface at every timestep.
Method	This explicit representation is a closed, manifold triangle mesh, which is stored as an array of vertices and an array of triangles.
Method	The vertices are shared between triangles, allowing for easy computation of smooth vertex normals and other common mesh operations.
Method	The distance tree (see Section 6) provides a spatial index for the mesh.
Method	The explicit representation provides our method with several advantages.
Method	First, it allows us to compute exact signeddistance values near the mesh.
Method	Second, it allows us to store properties on mesh vertices, rather than at points near the mesh.
Method	Finally, it allows us to take advantage of the many tools and algorithms which have been developed in computer graphics for manipulating and rendering triangle meshes.
Method	To avoid the topological difficulties of directly updating an explicit surface representation, we update the surface in time through an implicit representation (see Figure 2 ).
Method	We define a scalar-valued field function, ψ(x), which relates the surface at the current timestep to the surface at the previous timestep.
Method	For a point x at the current timestep, the function, ψ, first uses backward path tracing, a semiLagrangian integration technique, to find the point x at the previous timestep which flows to x.
Method	It then returns the distance from x to the surface, S n−1 , at the previous timestep.
Method	Essentially, we are advecting the signed-distance function through the velocity field given by the fluid simulator.
Method	In solving this advection term, our method differs from the simple CIR scheme discussed earlier in two ways.
Method	It is important to note that, while this method traces back through the velocity field with second-order accuracy, the velocity field is frozen over the course of the timestep, leading to first-order accuracy in time.
Method	The second difference is that, when evaluating φ at points near the surface, we do not interpolate values stored on a grid.
Method	Instead, we compute exact distance values.
Result	These changes only improve the accuracy (consistency) of our method and do not affect the unconditional stability.
Method	To compute the exact distance from a point x , we compute the distances d i to all the nearby triangles.
Method	The distance to the surface is min i d i .
Background	Schneider and Eberly [2002] detailed a method for computing the distance from a point to a triangle.
Background	This operation is relatively expensive, but many triangles can be pruned, especially when x is very close to the surface, by using standard bounding-box techniques and our octree data structure (see Section 6).
Method	Signing the distance values turns out to be somewhat difficult near sharp corners.
Method	Let y and n(y) denote the closest point on the surface to x and its normal, respectively.
Method	However, if the nearest point in the mesh lies on more than one triangle (i.e., on an edge or vertex of the mesh), the triangles do not always agree on the sign.
Method	These situations can be resolved by computing an angle-weighted pseudonormal for each edge and vertex of the mesh and using these pseudonormals to determine the sign when the nearest point is on an edge or vertex of the mesh.
Background	Bærentzen and Aanæs [2002] provided a proof that this procedure results in accurate signing (in exact arithmetic).
Method	The ability to compute exact distances is one of the chief advantages of having an explicit surface representation.
Method	Interpolation can produce substantial errors (see Figure 3 ) which are compounded over time.
Method	In fact, this interpolation error is one of the most significant drawbacks to semi-Lagrangian methods in general.
Background	When used for velocity advection, interpolation produces such significant smoothing that researchers have proposed a number of methods to add detail back to the flow [Fedkiw et al. 2001] or avoid semi-Lagrangian advection altogether [Zhu and Bridson 2005].
Result	In this work, we are able to leverage the advantages of semi-Lagrangian advection, without incurring the interpolation error that would otherwise undesireably smooth surface detail.
Method	Our implementation makes heavy use of a structure we call the distance tree.
Method	The distance tree is a balanced octree subdivision of the spatial domain.
Method	The octree vertices are annotated with signeddistance values and each cell of the octree contains a list of the triangles with which it intersects.
Method	(2) It provides a fast, approximate signed-distance function, which is sufficient when evaluating the signed distance far from the surface.
Method	(3) It guides the contouring algorithm, quickly identifying cells which have vertices of different sign and, thus, contain triangles.
Method	When computing the signed distance from a point x to a surface, S, we first find the smallest octree cell, C, containing x .
Method	If C is at the finest level of the octree, then x may be near the surface and all the triangles in the up to 27 cells in the concentric triple 1 of C are considered when computing the minimum distance to the surface.
Method	By storing the nearest distance seen so far and using standard bounding-box techniques, many of these triangles can be pruned before computing distances, especially when x is very near the surface.
Method	If the computed distance is less than C’s edge length, then the distance is guaranteed to be exact.
Method	Otherwise, the computed distance is a very good estimate but may be slightly larger than the actual distance.
Method	Contrariwise, if C is not at the finest level of the octree or if there are no triangles in the concentric triple of C, then x is not near the surface and we do not require an exact distance.
Method	An approximation with the correct sign is sufficient.
Method	In this case, we use trilinear interpolation of the distance values stored at the vertices of C.
Method	We make use of two different methods for building distance trees in this work.
Method	Most often, we wish to build a distance tree to resolve the zero set of our field function ψ.
Method	However, it is also useful to build a distance tree from an existing triangle mesh.
Method	Our octrees are always built in a top-down manner where each cell is split based on some variation of the following splitting criterion:
Method	Splitting ends when the tree reaches a predetermined maximum depth.
Method	Criterion (11) results in a three-color octree, as described by Samet [1990], where each cell of the octree has one of three types: interior, exterior, and boundary (see Figure 4 ).
Method	—A cell’s size is proportional to its distance to the surface.
Method	—If φ is the signed distance to the surface at vertices and we extend φ into each cell by trilinear interpolation, then, because cells vary in size, φ will be discontinuous.
Method	However, the jumps in φ decrease in size in cells near the surface because of the triangle inequality.
Method	Thus the interpolated φ is nearly continuous near the surface.
Method	—Cells coarsen very rapidly away from the surface: if there are N childless cells touching the surface, then the entire tree contains only O(N log N ) cells.
Method	Hence the surface is resolved accurately at minimal cost.
Method	The octree is built recursively from the root cell C 0 by the following splitting criterion:
Method	Thus we apply Criterion (13) as if ψ n+1 were a distance function.
Method	Thus in the limit, t = O( x) → 0, Criterion (13) reduces to (11), yielding the properties noted above.
Method	In practice, we use the value of φ at the cell’s center to determine whether we should split the cell.
Method	To deal with the fact that ψ n+1 is not a distance function and that the value at the cell’s center may not be the minimum over the cell, we multiply the edge length by some constant before doing the comparison.
Method	We have found that 1/3 works well in practice—always dividing near the surface, without spuriously dividing too many cells.
Method	Notice that we can vary this constant to achieve high-resolution bands of varying width around the surface.
Method	When building an octree from a triangle mesh (either in initialization, or after some geometric operation has been applied to the triangle mesh) we use the following splitting criterion:
Method	This test is efficiently implemented using Green and Hatch’s [1995] cube/triangle intersection test.
Method	Once we have resolved ψ on our distance tree, we need to create an explicit representation of our surface at the new timestep.
Method	Creating this explicit representation amounts to extracting the zero set of ψ and is an instance of the contouring problem, which has been well studied in computer graphics.
Method	For its simplicity, robustness, and speed, we choose to use a marching-cubes method in our implementation.
Method	Our implementation is based on Bloomenthal’s [1994].
Method	Our cubes are the leaf cells in the distance tree which have vertices of differing sign.
Method	We divide each cube into six tetrahedra to simplify the implementation.
Method	Additionally, when finding the zero crossing along any edge (which will eventually be a vertex in the triangle mesh), we use a secant method to speed up convergence and evaluate our full composite field function, including exact evaluation of the previous signed-distance function.
Method	Consequently, the vertices of our polygon mesh are guaranteed to lie on the implicit surface (within an tolerance).
Method	In fact, each vertex in our polygon mesh can be mapped to some point on some triangle in the mesh at the previous timestep.
Method	We take advantage of this fact when advecting surface properties.
Method	The marching-cubes algorithm works well for our purposes because each triangle generated by marching cubes sits strictly inside a single cell of the distance tree, making the distance tree an especially effective spatial index.
Method	Furthermore, we use the distance tree we have already built to guide the marching cubes, avoiding the need to build a second structure to determine the topology of the new mesh.
Method	Near the surface, our distance tree is refined to the maximum level and looks like a uniform grid.
Method	Consequently, we need not worry about patching the marching-cubes solution.
Result	Our choice of contouring algorithm does result in some limitations.
Result	In addition to creating poorly shaped triangles, marching cubes is nonadaptive.
Result	That is, the sampling is as dense in flat regions as in regions of high curvature.
Method	Unfortunately, the nonadaptive nature of marching cubes limits the resolution we can achieve in high-curvature areas, but is necessary to ensure compatibility.
Background	To address this lack of resolution in high-curvature areas, Strain [2001] split line segments whose centers were far from the surface, yielding arbitrarily high accuracy.
Background	Unfortunately, this splitting technique is not easily extended to three dimensions as splitting a triangle either creates an incompatible triangulation or produces even more poorly shaped triangles.
Method	It is also very difficult to guarantee that we will still have a manifold when the inserted vertices are moved to the surface.
Background	Alternatively, several adaptive contouring methods [Shu et al. 1995; Shekhar et al. 1996; Poston et al. 1998] seek to use adaptive grids and regain compatibility through various crack-patching techniques.
Future Work	Such methods could easily be used here and we plan to explore adaptive methods in future work.
Method	Although we did not find it necessary, after the contouring step the mesh can be processed in any way that preserves the closed-manifold invariant.
Method	This optional processing might include smoothing the surface, improving the shape of the triangles, or any other operation that returns a closed manifold.
Method	A new distance tree can then be built from this modified mesh using Criterion (15).
Method	A new distance must be built only if the mesh is modified.
Method	By taking advantage of the details of our method, we can very efficiently achieve limited smoothing in two ways.
Method	First, we can define a second composite function to be the combination of path tracing backward in time followed by the evaluation of a high-order polynomial interpolant of the distances at the vertices of the octree.
Method	This function is quite similar to the functions used in semi-Lagrangian level-set methods [Strain 1999b; Enright et al. 2005].
Method	When marching cubes encounters an edge whose vertices have different signs, we find a point which evaluates to zero for each composite function.
Method	The final mesh vertex is an average of these two points.
Method	By constraining the mesh vertex to be on the edge of the marching-cubes grid, we still guarantee a consistent, closed, manifold triangulation.
Method	While this smoothing technique may be quite useful in some applications, we did not use this method for any of the results in this article.
Method	Second, repeatedly using the same grid for contouring can produce grid artifacts.
Method	For example, a sphere of fluid falling under gravity will develop creases along the coordinate axes.
Method	Such artifacts are a form of aliasing and can be reduced by jittering the grid each timestep.
Method	Most of the examples in this article used grids which were slightly larger than the simulation domain.
Method	These grids were then randomly perturbed so that grids at adjacent timesteps were slightly offset from one another.
Method	This jittering limits the reusability of our octrees, but since we build new octrees every timestep, this limitation is not significant.
Method	After the triangle mesh at the current timestep has been extracted, we must assign true distance values to the vertices of our octree.
Background	This problem, referred to as redistancing, has been well studied by the level-set community and a number of methods have been suggested.
Background	Strain [1999a] suggested redistancing by performing an exact evaluation at every vertex of the octree.
Background	This method is relatively efficient since the tree coarsens rapidly away from the surface and works well in two dimensions.
Method	However, in three dimensions, we have found it to be prohibitively expensive and unnecessary.
Method	Instead, we perform exact evaluation at all vertices of the cells that contain triangles, but then run a fast marching method [Sethian 1996; Losasso et al. 2004] over the remaining vertices.
Method	In our method, there may be some parts of the domain where the octree was refined but did not result in any triangles, such as when the surface becomes thinner than the resolution of the tree.
Method	Consequently, our octree, unlike those used by Losasso et al. [2004], does not necessarily coarsen away from the surface.
Method	To address this problem, we coarsen parts of the tree which have been refined but did not generate surface.
Method	We do this coarsening in two steps.
Method	First, we propagate the triangle lists up the tree so that the triangle list of a cell is the union of the triangle lists of a cell’s descendants.
Method	Second, we remove all the children of any cell whose concentric triple does not contain any triangles.
Method	Our redistancing method comprises three steps: —coarsen the octree; —compute exact distances at vertices of cells which contain triangles; —run a fast marching method over the remaining vertices.
Result	One of the primary advantages of our method is the ability to track surface properties, such as color, texture coordinates, or even simulation variables, accurately at negligible additional cost.
Method	As pointed out earlier, every vertex in a polygon mesh corresponds to some point on some triangle in the previous mesh.
Method	Thus, semi-Lagrangian advection provides a mapping between surfaces at adjacent timesteps.
Method	If vertex v in the current mesh maps to point p in the old mesh and some surface property was stored at p, this property can be copied to v.
Method	In this way we can track surface properties on the actual surface as we build the surface, so we do not incur any significant additional cost.
Background	Previous methods, such as the one proposed by Rassmussen et al. [2004], have been limited to tracking properties in the volume near the surface and interpolating them to the surface.
Background	Such methods incur significant cost, introduce substantial smoothing, and blur properties between nearby surfaces.
Method	In many cases it is sufficient to use barycentric interpolation to compute a value at p and copy this interpolated value to v.
Method	However, for some applications this interpolation can produce unwanted smoothing.
Method	Essentially, we are having trouble because we are resampling the surface at every timestep.
Method	However, if we know something about the property we are tracking, we may be able to “clean up” the blurred signal.
Method	For example, in our examples with checkerboard textures, we tracked reference coordinates which were passed to a simple function to determine color.
Method	Since we know that the tracked value should always be a point on the initial surface we could find the point on the initial mesh which was closest to the value the tracking method supplied.
Method	In this way, we ensured that, at every timestep, every vertex in the mesh mapped back to some point on the initial surface.
Method	Once we had this mapping we could copy any property stored on the initial surface, whether it be the reference coordinates, texture coordinates, or color values.
Method	Thus, if image textures were preferred over procedural textures, texture coordinates could be copied instead of reference coordinates.
Result	There are still plenty of open problems in the area of texturing liquid surfaces.
Result	In particular, it is difficult to deal with large discontinuities in surface properties, which occur when two surfaces merge, or a surface splits.
Result	Creating detail where a surface stretches is also an open problem.
Method	We have tested this surface tracking method coupled with a fluid simulation on several examples such as the ones shown in Figures 5 and 6.
Method	We also tested it in the spiraling analytical test field from Enright et al. [2002a].
Result	The sphere was restored to a nearly identical shape (see Figure 8 ), while the bunny exhibited a small amount of smoothing.
Method	At each timestep, the morphogens were advected along with the surface and then allowed to react.
Method	All of our fluid examples used a standard regular-grid Eulerian fluid simulator with the elasticity model of Goktekin et al. [2004].
Method	The fluid simulator and the surface tracking module were only very loosely coupled: the fluid simulator provided the surface tracker with a velocity function and, in turn, the surface tracker provided the simulator with the signed-distance function.
Method	Because our fluid simulator has a regular grid its resolution is notably coarser than the surface tracker, which uses an octree.
Background	The idea of using different resolutions for the fluid and surface is not new; Foster and Fedkiw [2001] used different timesteps for their fluid and surface calculations and Goktekin et al. [2004] found that increasing the spatial resolution of the surface tracking grid dramatically reduced volume loss.
Background	As noted by Losasso et al. [2004], using different spatial resolutions can produce artifacts.
Background	For example, pieces of surface could appear connected when the simulator thinks they are disconnected and vice versa.
Background	Additionally, surface features may be maintained when a more detailed fluid simulator would smooth them away.
Result	In general, we found the increased surface resolution to be worth these artifacts.
Method	Ideally we would use a multiresolution fluid simulation, like the octree method of Losasso et al. [2004].
Future Work	We plan to incorporate a multiresolution fluid simulator as part of our future work.
Result	For most of our examples the surface tracking module took roughly 1 min/timestep at an effective resolution of 512 3 .
Result	The fluid simulation also required about 1 min/timestep.
Result	Both the fluid simulator and the surface tracking module took 11 timesteps per frame.
Result	Thus it took about 2 days to simulate 10 s of animation, with roughly half the time spent solving for the velocity field and half the time updating the surface.
Result	It is important to note that, given a perfect semi-Lagrangian path tracer, the method could take arbitrarily large timesteps.
Future Work	Decoupling the timesteps of the fluid simulator and surface tracker, so that the surface tracker runs only once per frame, is an interesting area of future work.
Method	This surface is textured by advecting reference coordinates along with the flow and applying a procedural checkerboard texture.
Result	The motion of the spots on the surface occurs both from the motion of the surface and from the reactiondiffusion system seeking equilibrium on the moving surface.
Result	As the streams oscillate from side-to-side, they collide and produce a thin, web-like surface between them.
Result	The motion of the two streams causes this thin surface to form a spiral shape as the streams separate.
Result	Similar effects can be seen in real-world footage.
Method	All of our images were rendered with the open-source renderer Pixie [Arikan 2005].
Method	Many of our examples were rendered with a matte shader so that the surface detail can be seen.
Method	A number of our examples were also rendered with a glass shader (using water’s index of refraction) for comparison to previous methods and real fluids, and to demonstrate how the method can be used to generate realistic results.
Result	Our colored and textured examples illustrate how easily a variety of properties may be attached to the surface.
Result	In practice, we believe that advected properties could be used effectively with standard shading techniques to generate a wide range of interesting effects.
Result	Semi-Lagrangian contouring offers an elegant and effective means for surface tracking and has a number of advantages over competing methods.
Result	First, we have an explicit representation.
Result	In addition to enabling exact evaluation, this explicit representation also allows us to leverage 30 years of computer graphics technology which has been optimized for polygonal meshes.
Result	Rendering, texture mapping, and a variety of other applications are all very straightforward.
Result	Second, we have an implicit representation.
Result	This implicit representation allows us to update the surface without explicitly addressing any of the difficult topological issues which plague other approaches.
Result	Third, semi-Lagrangian advection gives us a mapping between surfaces at adjacent timesteps.
Result	This mapping allows us to accurately track surface properties on the actual surface at negligible complexity and cost.
Result	Fourth, our method does not have any ad hoc rules or parameters to tune.
Result	In fact, the only parameters to our system are the upper and lower corners of the domain, the maximum depth of the octree (a resolution parameter), and some resolution tolerances.
Result	Finally, and most importantly, we are able to produce detailed, flicker-free animations of complex fluid motions.

Result	We present a new collision resolution scheme for cloth collisions.
Problem	Our main concern is to find dynamically convincing resolutions, i.e. positions and velocities of cloth elements, for any kinds of collisions occuring in cloth simulation (cloth-cloth, cloth-rigid, and cloth-cloth-rigid).
Method	We define our cloth surface as connected faces of mass particles where each particle is controlled by its internal energy functions.
Method	Our collision resolution method finds appropriate next positions and velocities of particles by conserving the particles’ momentums as accurately as possible.
Problem	Cloth-cloth collision resolution is a special case of deformable N-body collision resolution.
Method	So to solve deformable N-body collision resolutions, we propose a new collision resolution method, which groups cloth particles into parts and resolves collisions between parts using the law of momentum conservation.
Method	To resolve collisions, we solve a system of linear equations derived from the collision relationships.
Method	A system of linear equations is built using a scheme adapted from the simultaneous resolution method for rigid N-body collisions [ 1 ].
Method	For the special case where we can find cyclic relationships in collisions, we solve a system of linear inequalities derived from the collision relationships.
Background	Collision handling in Computer Graphics has two phases.
Background	One is to detect collisions and the other is to resolve collisions.
Background	In cloth collision detection, the computation time to detect collisions is not negligible because the number of geometrical entities (nodes, faces, edges) the collision detection algorithm has to handle is considerable (over 10,000 particles for regular attire).
Background	For this reason, several approaches have tried to expedite the collision detection processes [ 16 , 3 ].
Background	Collision resolution is to find the correct next positions and velocities of colliding objects.
Background	Cloth resolution methods so far have found non-penetrating positions, velocities and accelerations of cloth surface particles [ 14 , 3 , 15 ].
Background	This scheme works fine for cloth-rigid collisions and for the special case of cloth-cloth collisions where the dynamic interactions between cloth surfaces in cloth-cloth collisions do not have to be noticeable.
Background	Volino et. al. [ 15 ] applied the conjugate gradient method to find the actual particles’ positions where a group of particles are colliding into each other.
Background	By preserving barycentric relationships of collision entities, their method resolves collisions where numerous cloth surfaces are colliding together as a group, which is a novel way to resolve multiple collisions at once.
Background	However it does not conserve the momentum of cloth surfaces in cloth-cloth collisions.
Background	Another method for cloth-cloth collisions has been proposed by Provot [ 12 ], which resolves collisions by giving an average velocity to all the particles of collisions.
Background	Provot’s method is easy to implement but it cannot give proper visual effect of collisions since we cannot get dynamic interactions between particles once the particles collide into each other.
Background	Cloth-cloth collision resolution is a special case of deformable N-body collision resolution.
Result	To solve deformable N-body collision resolutions, we propose a new collision resolution method which gives a visually reasonable response by ensuring the conservation of N-body momentums.
Method	Our cloth system is particle-based, as many systems are in other cloth research groups [ 14 , 6 , 12 , 3 ].
Method	To resolve collisions, we first divide the colliding particles into parts and build a system of linear equations based on the collision relationships between these parts.
Method	Then we solve the whole system using the law of N-body momentum conservation.
Method	The system of equalities is based on the scheme adapted from the simultaneous resolution method for rigid N-body collisions proposed by Baraff [ 1 ].
Background	However his original inequality relationships between relative velocities before and after collisions are purely heuristic, which may not be physically correct.
Background	Though this physical inaccuracy has been an inherent problem of simultaneous collision resolutions, it appears to give graphically agreeable results.
Result	Hence with the help of the law of N-body momentum conservation, we found the results of our resolutions are visually acceptable.
Background	A swept volume is a volume made by two sets of positional entities of a face one at time t and one at time t + t .
Method	Connecting these old and new positions of all particles in a face gives us a volume.
Background	Any collision happening within an integration time step always can be detected by this swept volume method, unless the motions of faces are highly rotational.
Method	An interesting case is where the faces are not actually intersecting but two swept volumes report a intersection anyway.
Method	Though this case is not an actual collision, it happens only when two faces are very close.
Method	Hence we resort to the collision report of this case, since we consider this case as a violation of the proximity law.
Method	We use classical edge-polygon detection algorithms to detect collisions among swept volumes.
Method	We use this swept volume approach for cloth and the dynamic rigid body alike, but for the non-moving rigid body only the surface faces are used for collision detection.
Method	In addition, we add proximity regions to the normal directions of faces of a swept volume to add proximity violation regions.
Problem	Though detected collisions are reported as pairs of face-face, we cannot respond to each collision individually since these individual responses may introduce another new collision or one face may possibly be related to several other collisions.
Method	So we save all detected collisions in a data structure, i.e. a set of zones of impact [ 12 ] during the collision detection phase.
Method	All stored detected collisions will be resolved comprehensively by the rule described in the next section.
Background	Originally a zone of impact (IZ) is an area where multiple self-collisions occur [ 12 ].
Method	We extend Provot’s definition of an IZ to an area where collisions happen, including collisions against bodies and self-collisions.
Method	An object O is a set of particles, faces, and edges, where faces and edges are defined based on the positions of particles by the rule comprising cloth surface.
Method	An area A is a subset of O such that all the particles and edges constituting a face in A are members of A .
Method	An area A is called separable when, for all faces 2 A , does not collide with any face in A .
Method	An area A is called colliding when, for all faces 2 A , collides with at least one face in A .
Method	An IZ is a separable colliding area.
Method	An area A is called visitable when, for all particles P 2 A , P can be encountered by traversing from any other particle in A using edges in A .
Method	Otherwise, the area A is non-visitable.
Method	We call a visitable subset area of an IZ a collision cluster (CC).
Method	When a face-face collision is detected, the entities of each colliding face (the particle and the edges of , and itself) are inserted into a CC, where the CC can be encountered by traversing from the particles in using only edges in .
Method	When there is no such CC, becomes a CC.
Method	When two or more such CCs are found, these CCs are merged into one CC connected by .
Background	A widely used method for detecting cloth collisions is to put small repellent proximity forces between the cloth surface and the rigid or cloth surface [ 4 , 14 , 3 ] while the actual collisions are tested with pairs of particle-face or face-face of the current positions.
Background	When objects are moving fast, however, these preventive proximity forces cannot prevent collisions since a particle can pass through the proximity violation region during one integration time step.
Background	This problem can be negligible when the integration time step is very small, so we rarely have those pass-through cases.
Background	Numerous approaches [ 14 , 12 , 3 , 15 ] have been introduced for cloth collision resolution: the correct next positions and velocities of colliding cloth particles.
Background	So far, however, no cloth collision resolution method which considers cloth-cloth momentum conservation has been introduced, while we cannot achieve realistic cloth interactions in cloth animation without conserving cloth-cloth momentums.
Background	Having this characteristic is visually distinctive when cloth surfaces are moving fast and interact with each other.
Background	For rigid N-body collisions by graphics and robotics groups [ 11 , 1 , 10 , 9 ] and for flexible-rigid collision resolution [ 2 ], several approaches have been suggested.
Problem	But they are not directly applicable for deformable N-body collision resolutions, which is the case cloth requires.
Background	Cloth resolution methods so far compute non-penetrating positions, velocities or accelerations of particles [ 14 , 3 , 15 ], which work fine for the collisions against fixed bodies.
Problem	Using these methods, however, we cannot achieve visually satisfying dynamics of cloth-cloth collisions.
Background	Adjusting particle orientations after collision resolution as suggested by [ 14 ] to sustain the geometrical consistency of colliding faces also does not warrant reasonable dynamic movements of cloth-cloth collisions.
Background	Handling collisions in an IZ as a bundle, proposed by Provot [ 12 ], also does not give a proper visual effect.
Result	We propose our cloth collision resolution method which resolves simultaneous collisions while ensuring conservation of momentum as accurately as possible.
Method	Since simultaneous resolution does not blindly resolve a collision without considering neighboring collisions within an IZ, we do not introduce any new collisions while resolving a collision.
Method	After we handle each IZ separately, we check whether any new collisions between IZs are introduced by collision resolutions, and handle them if there are any.
Method	In an IZ, we first check whether it has CCs from rigid bodies.
Method	In case we do not find any CCs from rigid bodies, the collisions in that IZ are categorized as cloth-cloth collisions.
Method	If we find CCs from rigid bodies in an IZ, we extract them temporarily from the IZ so that only cloth-cloth collisions remain in the IZ.
Method	After resolving these cloth-cloth collisions, we take care of cloth collisions against rigid bodies so that the resolutions against rigid bodies will be done on top of the result of self-collision resolutions.
Method	This sequence of resolutions is chosen to avoid the case where self-collisions are ignored while collisions against rigid bodies are handled.
Method	For some cases, an IZ has only one CC (for example, in the case of extreme bending).
Method	When an IZ has only one CC, we cannot handle the particles in that CC as a bundle as usual.
Method	Since the particles in that CC will stick together after resolution, the movements of cloth would not be natural and satisfactory.
Method	Hence we divide one CC into parts so that we can find proper collision responses within these parts.
Method	Segmenting one CC into parts is performed by identifying border edges.
Method	A border edge is an edge where we identify a “significant” bending between two faces adjoining in that edge.
Method	When an IZ has three or more CCs, we reduce the total number of CCs by merging closely located CCs.
Method	This merger is performed to prevent undesirable collision resolution.
Method	If CCs are closely located, it means the cloth patches represented by these CCs are closely located.
Method	We do not want to handle closely located CCs separately since it might instantly introduce instabilities to the system by allowing closely located CCs to have different velocities.
Method	However, there is an exception.
Method	When we find a significant bending between these closely located CCs, we have to resolve collisions between these CCs by handling them separately.
Method	Bending between CCs is considered significant in the same way as in the case of bending between faces.
Method	We do not want to handle closely located CCs separately except for the case where the bending is significant (CCs are considered to be closely located heuristically when they can be connected using at most two edges which are not members of both CCs).
Method	Hence the candidates of the CC merger are the CCs closely located, where we do not witness any significant bending between the CCs.
Method	After merging, we still possibly have more than two CCs.
Method	By definition, an IZ is a set of CCs.
Method	Since we pre-processed a single CC IZ previously, we assume an IZ always has two or more CCs.
Method	The important part of the collision resolution of these multiple CCs is to find the proper directions of collisions.
Method	Collision direction is a direction to which two CCs collide into each other.
Method	Since the velocities of CCs after collision are computed based on this collision direction, finding the correct collision direction is important to achieve proper visual effect of collisions.
Method	In the case of the two billiard ball collision, the collision direction is computed by connecting the two ball centers of mass.
Method	But in cloth-cloth collisions, connecting two centers of CC masses is not a proper way to decide the collision direction.
Method	We choose the collision direction to be the average direction of the two face normals of colliding CCs.
Method	To have the proper average direction, the CC face normals, N 1 and N 2 , have to be properly signed as N 1 N 2 0 .
Method	The face normal of a CC is the average normal of all faces in the CC.
Method	We handle a CC as a sphere mass where the diameter of the sphere reflects the minimum proximity region.
Method	This approach serves us well empirically.
Method	The velocity of a CC is defined as the average velocity of all particles in that CC.
Method	When we have collisions of three or more CCs in an IZ, it is not straightforward to resolve the collisions.
Method	As has been discussed in multiple collisions of rigid bodies, we can think of two ways to solve this multiple cloth collision problem.
Background	One way of resolving these multiple collisions is to handle them as staggered collisions [ 11 , 10 ]; the other way is to handle them as simultaneous collisions [ 1 ].
Background	The staggered collision approach handles multiple collisions as a series of single collisions [ 11 ] or desynchronized groups of collisions [ 10 ].
Background	The simultaneous collision approach treats multiple collisions as simultaneous collisions within a time-step.
Method	The staggered collision approach gives us a more physically correct solution than the other.
Method	In the synchronized staggered collision method, we have to find the first collision among multiple collisions.
Method	After we resolve it, we march the time step until we find the next collision.
Method	Then we repeat the same procedure.
Method	This whole process is not only computationally expensive but also we have to consider the possibility that the resolution of a collision can create new multiple collisions, which we have to employ another strategy to resolve.
Method	In the desynchronized staggered collision method, we identify groups of collisions, and redefine the integration front-end by allowing time desynchronization.
Method	In addition to the substantial computational expense and complexity, the visual advantage of those staggered methods is not considered significant compared to that of the simultaneous collision method.
Background	The simultaneous collision handling method, proposed by Baraff [ 1 ], resolves multiple rigid body collisions by solving a system of linear inequalities, where the system of linear inequalities is based on the colliding relationships between rigid objects.
Method	When CC bodies are considered as vertices, an edge exists between two vertices where the bodies represented by those two vertices collide.
Method	We call the resultant graph a collision graph.
Method	When the collision graph of an IZ has a loop, we call the collisions in the IZ cyclic.
Method	However a problem arises when collision resolutions of an IZ create new collisions against objects around the IZ.
Method	This happens when objects do not move fast enough to penetrate objects outside an IZ, but just fast enough to make the result of collision resolutions penetrate the proximity region of objects outside the IZ.
Method	To our relief, this case appears to be very rare.
Method	However we can resolve this case by maintaining the barycentric relationship between cloth surfaces and the newly introduced colliding entities.
Method	Apparently, in the worst case, this involves repetitious processes as we may introduce other new collisions when we resolve the current collisions.
Method	For the special case where we observe cyclic collisions in an IZ, we build a system of linear inequalities based on the collision rela- tionships between grouped particle parts.
Method	We find the feasible solution of the linear inequality system, while trying to minimize the energy we introduce into the simulation artificially.
Method	This inequality relationship between the relative velocities before and after collision is an artificial relationship set up heuristically, not based on physics.
Method	This inequality relationship, first used for rigid body multiple collisions [ 1 ], appears to serve the graphical purpose well.
Method	The system of inequalities with an objective function can be solved using a Linear Programming Method.
Method	If an IZ has CCs from rigid bodies (rigid CCs) along with CCs from cloth (cloth CCs), the collision resolutions against rigid bodies are performed after cloth-cloth collisions are resolved.
Method	When an IZ has rigid CCs, collision responses are different based on whether rigid CCs are moving or fixed or a mixture of both.
Method	If the rigid CCs in an IZ are all fixed, we handle particles in that IZ individually.
Method	Where N face is the normal of a rigid face, V is a particle velocity, V normal and V tangential are the normal and tangential components of V with respect to the rigid face, particles are considered separating if V normal N face 0 .
Method	Particles are ignored if they are not in the vicinity of a face in fixed rigid CCs, where the size of vicinity is the thickness of cloth.
Method	Furthermore, particles separating from the rigid bodies are also ignored.
Method	The new particle velocity V new is , C e V normal + C f V tangential , where C e is an elastic coefficient and C f is a frictional coefficient.
Method	If the rigid CCs in an IZ are all moving, we handle particles as a bundle as long as particles are in the vicinity of moving rigid CCs.
Method	We find the x and the velocity V rigid of a moving rigid CC, where V rigid is defined as the translational velocity of the center of mass of the moving rigid CC.
Method	Then the positions of all particles we have to handle will be incremented by x and the velocities of the particles will be updated as V rigid .
Method	If an IZ has both moving and fixed rigid CCs along with cloth CCs, collision resolutions against rigid bodies are done based on the proximities of particles to the rigid CCs.
Method	Cloth collision resolutions against rigid CCs will be computed based on the closest rigid CC.
Method	Collisions between rigid bodies (rigid-rigid) have to be handled independently from cloth collisions.
Method	All our simulations were done on SGI Octane with R10000 CPU and R10010 FPU.
Method	For numerical integration, we used the CG method proposed by Baraff [ 3 ].

Problem	In this paper we show how to incorporate effects of wind fields in cloth animations.
Method	We discuss two different approaches to model force fields describing air motion and show how these models can be augmented to exhibit interaction with deformable thin objects such as textiles.
Method	The first model is based on the Navier-Stokes equations, while the second method extends simple particle tracing methods by the effect of lee.
Result	In each case, we present a method for simulating the interaction of cloth movements with the wind field.
Result	Both methods have been integrated in an existing cloth simulation system, and we compare their respective advantages and disadvantages.
Problem	While the simulation of wind is an area of vast interest in aerodynamic engineering, computational fluid dynamics (CFD), and animation/visualisation of fluids in computer graphics, it has been a rather abandoned subject in simulation of deformable objects such as cloth simulation.
Problem	This is mostly due to the fact that conventional CFD applications require enormous computational power.
Problem	However, aerodynamic effects are obviously capable of enhancing the realism of an animated scene and thus are an important part of a cloth simulation system.
Problem	For example, air resistance is a vital component which cannot be neglected if realistic animation is desired [ BTH + 03 ].
Problem	In this work we discuss two different approaches to      model force fields describing air motion and show how these forces can be applied to generate aerodynamic effects on textiles.
Problem	The first method is based on modelling air flows with the Navier-Stokes equations.
Method	With this model, the effect of wind fields on smoke has already been investigated [FSJ01], and in this paper we extend this approach to wind effects on textiles.
Problem	However, the solution of the sophisticated NavierStokes equations is not desired and not necessary in all situations where wind effects shall be integrated into cloth simulations.
Result	For this case, we present a much simpler model based on tracing wind particles that move along a global force field.
Method	During the simulation, the wind field is evaluated for each wind particle at its current position.
Method	The so determined flow field is used to compute the wind force which is added to the forces that act on the textiles.
Method	By detecting collisions between the wind particles and objects in the scene, we are able to simulate the important effect of lee even with this straightforward method.
Problem	Of course, both approaches have different characteristics and aim at different applications for wind simulation.
Result	In this work, we compare the models’ advantages and disadvantages and show practical results of the described methods.
Background	Models for fluid dynamics can be essentially subdivided into two categories.
Background	Simple models which are commonly used in most computer graphics applications describe the wind flow by predefined flow functions.
Background	Here, global functions are defined to model the velocity of wind.
Background	Either special flow primitives can be combined [ WH91 ; LDG96 ; Li00 ] or visually pleasing functions introducing random turbulence [ SF92 ; SF93 ; Sta97 ] are taken into account to model even complex wind scenes.
Background	Many models use this method to move objects in the wind field through the scene [ Ree83 ; Sim90 ; WH91; BLM95 ].
Background	In addition, physically based fluid dynamics solving equations of motions with particle methods were presented recently [ IK03 ].
Background	However, fixed flow functions lack interaction with the user or objects in the scene.
Background	Hence, with increasing computer power, computer graphics concentrates on physically more accurate simulations.
Background	In many fields the Navier-Stokes equations are the standard mathematical formulation to model fluid dynamics.
Background	A vast literature exists on how to solve these equations numerically.
Background	CFD are applied in this field for engineering tasks with a high degree of quality requirements.
Background	Unfortunately, it is quite difficult to apply these algorithms in computer graphics due to enormous calculation times.
Background	Hence, faster fluid solvers were investigated for computer graphics applications.
Background	Kajiya et al. [ KvH84 ], Yaeger et al. [ YU86 ], and Gamito et al. [ GLG95 ] worked on fluid dynamics solvers in two dimensions, and many improvements and variants followed [ CdVLHM97 ; KM90 ].
Background	Foster and Metaxas [ FM96 ; FM97 ], and Griebel et al. [ GDN98 ] presented a solver for the fully three dimensional Navier-Stokes equations.
Background	Due to explicit integration methods very small step sizes had to be used.
Background	To enable faster simulations, a solution with an unconditionally stable solver was introduced by Stam [Sta99 ] and further extended in [ FSJ01 ; Sta01 ; Sta03 ].
Background	Modelling interaction of fluids with solid objects has been investigated by Takahashi et al. [ TFK + 03 ] and Génevaux et al. [ GHD03 ].
Background	Recently, Wei et al. [ WZF + 03 ] presented an interesting approach to simulate lightweight objects like soap bubbles and feathers in a wind flow using a Lattice Boltzmann Model extended with a subgrid model.
Background	For interaction of highly deformable objects and especially cloth-like objects only few models have been investigated.
Background	Simple models consist in the calculation of lift and drag forces from the surrounding velocity field [SF92; Pro95; KCC + 00; KCCL01].
Background	More complex interaction models calculate the wind force by a panel method [LDG96; Li00] introducing local vortices.
Result	In this work, we show how recent results in fluid dynamics for computer graphics can be exploited to simulate interaction of wind flows with textiles.
Result	Moreover, we extend the more straightforward approach of global wind field functions by the effect of lee.
Method	To incorporate wind effects in a physically based animation we have to apply additional external forces in the dynamical model of the deformable objects.
Method	Hence, given a wind flow represented by a velocity field in the scene we calculate the forces which are exerted on the simulated objects.
Method	The wind force acting on objects in an air stream is decomposed into two components: the lift force F L and the drag force F D (see figure 1 ).
Method	The direction of the drag force F D is diametral to the relative velocity v rel = v object − u, where v object is the object’s velocity and u is the velocity field of the wind.
Method	Note that in the case of a windless situation, i.e. u = 0, we still have air resistance for moving objects.
Method	The drag force per face is then given by F i,D = 2 1 C D ρ|v i,rel | 2 A · ( n i · v i,rel ) · (− v i,rel ) ,        where C D is the specific air resistance coefficient, ρ the density of air, A is the area of the corresponding face, and v i,rel the unit relative velocity vector of the face.
Method	The direction of the lift force, which is perpendicular to v i,rel and lies in the plane spanned by v i,rel and n i , is given by u i = ( n i × v i,rel ) × v i,rel .
Method	Then the lift force is calculated as F i,L = 1 2 C L ρ|v i,rel | 2 A cos θ · u i , where C L is the lift force coefficient, and θ is the angle between v i,rel and the actual face.
Method	The first model is based on the work of Stam [Sta97] and calculates the numerical solution of the Navier-Stokes equation with a semi-Lagrangian approach.
Method	This model is extended to interaction of the wind flow with textiles.
Method	The second model employs precomputed wind flows and particle tracing methods.
Method	This approach is much easier to implement and can be added to existing simulation modules without additional computational cost.
Problem	The numerical algorithms used in CFD to solve these equations are designed for physical accuracy for engineering applications and are expensive in computation.
Method	But in our case where this precision is not necessary simplifications can be made which greatly reduce the computation costs as described by Stam [Sta03].
Method	Since the arising wind velocities are clearly below the speed of sound, compressibility effects are negligible, and the wind is modelled as an incompressible constant density fluid.
Method	Here, u describes the (three-dimensional) velocity field, ν is the kinematic viscosity of the fluid, ρ its density, p the pressure in the wind field, and f accounts for external forces.
Method	The first equation states that the velocity field should be incompressible while the second one describes the evolution of a velocity field over time.
Method	The first term on the right hand side reflects the change of velocity due to advection, while the second expression accounts for any external force f and acceleration caused by the local pressure gradient ∇p and by viscous drag depending on ν.
Method	To solve these equations numerically they first have to be discretised.
Method	For this, the computational domain is diced up into equally sized cubes forming a grid as described in section 4.2.2, and sample values of velocity and pressure are defined at the cell centres.
Background	Foster and Metaxas [FM96] use a finite difference approximation for the discretisation of the operators in equation (4.2).
Background	Then they update the cell’s velocities according to the divergence value computed in each direction, respectively, using an explicit integration scheme.
Method	Since time steps in explicit computations usually need to be very small, we follow Stam [Sta99] who proposes an implicit integration scheme, which allows stable simulations with large time steps.
Method	While the linear terms in equation (4.2) are straightforward to solve implicitly, the term −(u · ∇)u is nonlinear and deserves special attention.
Method	Here, a different approach based on the method of characteristics is used to solve the advection equation.
Method	Equation (4.2) does not provide a divergent-free velocity field.
Method	Therefore, the divergence of each cell in the grid has to be projected to zero using the Helmholtz-Hodge decomposition [Sta03].
Background	The major advantage of Navier-Stokes based approaches consists in the fact that the evolution of the wind flow over time is calculated.
Method	It enables us to model global effects like convection and diffusion on a physical basis.
Result	We present a model to exploit these wind models for calculating the interaction of deformable objects with the air flow by a boundary condition method.
Background	As already stated by Stam [Sta03] “a velocity field of its own isn’t really visually interesting until it starts moving objects [...
Background	That means in particular that all objects in the scene interact with the fluid present in it, i.e. in our case clothes with the wind.
Background	On the one hand the wind deforms the objects which on the other hand change the wind flow.
Method	To describe the above situation by a physical model we require the Neumann boundary condition ∂u =0 ∂n to be satisfied for the wind flow u at any boundary point of an object with normal n.
Background	Rigid objects like walls will influence the fluid field but will not be affected by fluid forces themselves.
Background	Deformable objects like cloth are supposed to both experience fluid forces and itself influence the fluid flow.
Method	This in fact is a major difficulty.
Method	Consider a point p b on the boundary of a deformable object in the scene.
Method	Let u(p b ) be the corresponding wind velocity at that point and n be its normal.
Method	On the one hand, we want the Neumann boundary condition u(p b ) · n = 0 to be satisfied.
Method	On the other hand, the wind velocity orthogonal to the object’s surface is just what causes the aerodynamic forces.
Method	Without further remedial action setting the boundary according to the Neumann condition would mean that the fluid will not exert forces on the objects.
Method	Here we propose a method which meets both requirements.
Method	For every deformable object the velocity value of the surrounding wind field for every vertex of the representing mesh is tracked.
Method	The wind velocity at the vertex positions of the object is recorded.
Method	Additionally, the normals of these vertices are stored.
Method	Then, the aerodynamic forces as described in section 3 are calculated.
Method	Finally, for every marked cell in the scene the previously stored normals are averaged in one space cell which are used to update the velocity at the cell to satisfy the Neumann boundary condition.
Method	Thus, the boundary conditions are met and yet aerodynamic forces are obtained.
Method	A different issue is how to deal with the inside of (rigid) objects.
Method	The method to set boundary conditions as described above does not account for the interior of objects.
Method	Thus, a nonzero velocity could be mistakenly assigned to cells lying inside an object.
Method	To avoid this situation, the path of the wind flow is checked for object intersection, whereby the collision detection of the cloth simulation system provides a simple method to deal with this issue [MKE03].
Method	To define a wind scene we first built up the air flow by simple primitives such as parallel directed wind fields, vortices, etc.
Method	We then use a par- ticle tracing method in the defined wind field to determine the effect of lee by detecting windless areas.
Result	This method is very easy to implement and yields very plausible and nicely looking results.
Method	A simple approach to generate complex air flows is to define a wind field by mathematical functions which assign to each point in space a unique velocity value.
Method	One drawback of this model is that it cannot handle objects exhibiting complex boundaries.
Background	The approach to model solid objects in the scene taken by Wejchert et al. consists in placing a wind source using a mirror principle in order to extinguish the air flow at the boundary of the object.
Background	While this works for simple objects this approach is not feasible at all with deformable objects like textiles.
Method	Another more serious drawback of this model for our application consists in the lack of interaction with objects.
Method	The wind flow defined by the primitives will not react on objects in the scene which means for example that tissues in the lee of other objects will be affected by the wind flow as well.
Method	However, this method can be combined with the aerodynamic model described in section 3 to give nice and fast results as will be shown in section 5.
Method	To solve the described problems we propose a model which combines the simple global wind flow techniques with a particle tracing method.
Method	Here, particles are moved along the wind field to determine the effect of objects in the scene.
Method	This model divides the scene into parallelepiped cells.
Background	There are two common approaches to discretising the continuous velocity field defined in space: one can either choose the midpoint of a cell [Sta99] or its six faces [FM96] to define the field.
Method	As usual, values between the defining points of the grid are interpolated using trilinear functions.
Method	The basic idea of the particle tracing method is to trace wind particles through a field w = i w i defined by linear superposition of wind sources corresponding to flow primitives with respective velocity fields w i .
Method	The field w does not account for lee effects caused by objects in the flow.
Method	Therefore we compute the wind field u containing these effects as follows.
Method	The wind particles are emitted into the velocity field w i of the corresponding wind source which is defined on a grid.
Method	The specific emission intervals and amounts depend on the properties of the flow sources.
Method	In every time step each particle in a wind gust moves along its velocity field w i defined by the corresponding wind source.
Background	Notice that the movement of the particles in a wind gust is only affected by the wind source they belong to.
Background	The global superposition of all wind sources has no effect on these particles.
Method	To calculate the wind particles’ positions we used the explicit Euler integration scheme.
Method	For a wind particle at position p t and time t this results in a path s(p t , p t+∆t ), where p t+∆t denotes the position after time step ∆t according to p t+∆t = p t + w i (p t , ∆t) .
Method	As a particle moves along its path in space, all grid cells colliding with the path are updated with the velocity of the associated wind source with respect to the position of the particle.
Method	The particle might cross several grid cells on its way during a single time step.
Method	If this is the case, the path of the particle has to be subdivided into parts not exceeding the size of a grid cell.
Method	This path is then tested for collisions with the objects in the scene.
Method	The velocity field u is then computed as for each grid cell separately, where w i are all those wind sources whose particles have reached the cell.
Method	The wind force effective on objects in the scene is then computed from the velocity field u.
Method	Since u is determined using the wind particles, every point p that could not be reached by any wind particle will hold zero velocity even if w may hold a nonzero velocity.
Method	Thus, this method solves the problems described in section 4.2.1.
Method	Note that the somewhat tempting simplification of tagging each cell to either have wind in it or not is not valid.
Method	Imagine the simple scene in which there are two directional wind sources with opposite wind directions.
Method	Let them further have equal velocity magnitude and no distance attenuation.
Method	If we now place a solid object in between these two sources a rather undesired effect would occur using this simplification: on both sides of the solid object all cells would be tagged as having wind.
Method	But evaluating the wind field at every cell we would obtain a zero velocity.
Method	This is due to the extinguishing effect of the superposition of the two wind sources.
Method	Therefore, it is crucial for the particles to have the associated velocity of their wind source and not just the velocity resulting from the global superposition of all wind sources.
Result	For physically accurate simulations based on the common method in fluid dynamics the model introduced by Stam produces realistic effects which global wind field models can never achieve.
Result	It produces nice swirls and vortices derived from dynamical characteristics of the fluid.
Result	However implementing the fluid solver is quite complex and using a high grid resolution is computationally expensive.
Result	Hence, the global wind field model is better suited for an easy to implement tool which is easy to adapt to specific situations.
Background	Particle systems are very common in the simulation engines and most functionality can be adapted to integrate the proposed wind model.
Result	Even with this straightforward approach, nice, realistic looking results can be achieved which is illustrated in the next section.
Method	We implemented the wind models described in sections 4.1 and 4.2 in a cloth animation system that employs a fast finite element method to simulate the drape of textiles with measured material properties [EKS03].
Method	For collision detection (between deformable objects, rigid objects, and wind particles) we use k-DOP hierarchies as described in [MKE03].
Method	We used the particle tracing method described in section 4.2 to model the effects of a directional wind field on the flag.
Method	Two flags are exposed to a wind field, but the wind is blocked by a wall, so one of the flags is not affected by the wind.
Method	To show the improved realism when simulating lee effects, we let the the wind act on all polygons of the shirt on the right (no lee effect).
Result	For the shirt on the left we used the Particle Tracing Method to simulate lee effects which, we think, gives more realistic results (see also the accompanying video).
Result	We presented two models for including advanced wind effects into cloth simulation systems.
Method	The first concentrates on physically accurate computations using a semi-Lagrangian approach to solve the Navier-Stokes equations, the second model incorporates a particle tracing method for global wind fields.
Result	As illustrated in the previous section both methods produce realistic looking results which are capable of enhancing the realism of computer animations.
Result	While the first model has a wider range of applications, the second one provides an easy method which still delivers realistic effects such as air resistance and lee.
Result	All methods described in this work should be easy to extend to three-dimensional deformable objects.
Result	All the methods apply the same except for simple changes.
Result	Since three-dimensional objects define an inner and outer part, the adaption of the face normals in equation (3.1) is not necessary.
Result	Moreover, in the wind field computation care has to be taken that no wind field is present in the object.
Result	Here, the same method as described for rigid objects (section 4.2.2) can be applied.

Result	We propose a layered framework for incorporating example-based skinning algorithms such as Pose Space Deformation or Shape-by-Example into an existing character animation system.
Problem	The challenge in implementing example-based skinning in an existing system lies in the fact that it is generally believed that the interpolation of the examples is best performed before doing other skinning deformations (although there has been no analysis as to why this is the case), whereas the examples are specified by the user after the other deformations are performed.
Problem	It is therefore necessary to invert the operation of these skinning and deformation operators.
Background	Existing systems typically allow layering of both basic skinning methods such as Skeleton Subspace Deformation (SSD) and other deformations such as lattices, etc., and commercial systems may further allow additional proprietary deformation algorithms as part of the character skinning.
Problem	Unfortunately, understanding and accessing their various parameters can be laborious at best, and we do not have access to the algorithms in the case of commercial packages.
Background	With the help of modelling tools or capture devices, complicated 3D character models are widely used in fields of entertainment, virtual reality, medicine etc.
Background	The range of breathtaking realistic 3D models is only limited by the creativity of artists and resolution of devices.
Background	Driving 3D models in a natural and believable manner is not trivial, especially when the model is very detailed and playback of animation becomes quite heavy and time consuming.
Problem	Each time when a frame goes wrong, a production cannot afford major revisions such as resculpting models or re-rigging skeletons.
Problem	Therefore, providing a flexible and efficient solution to animation remains an open problem.
Background	Articulated character animation is a process of deforming the skin surface by manipulating influencing objects such as skeletons, IK, wire frames and Nurbs curves etc.
Background	Skeleton Subspace Deformation (SSD) is the predominant approach to character skinning at present.
Background	A nice review of SSD is given in [ 1 ].
Background	SSD is widely used in games, virtual reality and other realtime applications due to its ease of implementation and low cost of computing.
Background	It provides the relation between characters and their underlying skeletons.
Background	Normally this relation is defined in the rest pose, and determines how characters move according to their skeletons thereafter.
Background	Sometimes, artists will edit the geometry of characters in the rest pose to fine-tune animations.
Background	This approach is not commonly applied, however, since editing in the rest pose will influence most other poses.
Background	On the other hand SSD is also notorious for artifacts at rotating elbows and extreme poses.
Background	For those applications that require visual fidelity, such as movies, SSD serves only as a basic framework, on which lots of more complicated deformation approaches are built as a compensation.
Background	Example based skinning methods such as Pose Space Deformation (PSD) are candidates for correcting SSD limitations.
Background	Example geometric models paired with underlying skeletons in different poses are provided by artists with carefully sculpting and posing.
Background	PSD smoothly interpolates these meshes in pose space and produces visually attractive animations.
Problem	However, although PSD may be used as a compensation to the underlying SSD, and the animator specifies the PSD examples after the SSD has been performed, it is generally believed that the examples are best interpolated in the rest pose, before the SSD has been applied.
Problem	Therefore the action of the SSD and any other deformations must be “inverted” in order to push the example compensation before these operations.
Problem	Besides SSD, other skinning approaches such as rigid skinning, Free Form Deformation etc. can also be applied.
Problem	Our goal is to incorporate examplebased skinning into a system having a variety of other skinning and deformation operations, and to be able to invert these operations regardless of their nature.
Method	Since SSD is the most representative in the family of basic skinning, we will discuss how it performs in the inverse operation of PSD scheme.
Result	For a simplified condition where only one joint rotation and two example poses are considered, we demonstrate this inverse strategy has a better performance than the same framework without it.
Background	Besides the geometric solutions mentioned in the previous section, physical modelling and animation is another field providing realistic character simulations.
Background	Given physical principles, this category can generate more believable animation effects compared to its geometric counterpart.
Background	But they are seldom applied to interactive applications because of the high cost of computing and complicated algorithms.
Problem	This paper is mainly dedicated to geometric solutions.
Background	Pose Space Deformation [ 1 ] combines shape blending and Skeleton Subspace Deformation by formulating a scattered data interpolation problem over sculpted (or otherwise obtained) example poses.
Background	Character geometries in problematic poses will be re-sculpted by animators and then resulting displacement (referred as delta values in this paper) from the original geometries will be stored as “scattered data” for interpolation phase.
Background	The interpolation is performed in the pose space which consists of skeleton joints, or other potentially abstract controllers.
Background	Their values such as rotation degrees can be chosen as coordinates of the abstract pose space.
Background	After a model is posed and resculpted in different example poses, a multidimensional linear system is built by implementing an interpolation scheme using Radial Basis Functions (RBF), and the output of this system is the weights of each example pose.
Background	The final animation can be synthesized by linearly blending RBF functions with the solved weights.
Background	Related research efforts have improved the speed and power of example-based skinning.
Background	[ 2 ] incorporate linear elements into RBF to produce constant changes between examples.
Background	[ 3 ] precompute principal components of the deformation influences for individual kinematic joints instead of storing displacements for key poses, thereby enabling realtime rendering large nonlinear finite element models of human hands.
Background	[ 4 ] introduce weighted pose space deformation for deforming realistic models of human hand.
Background	The latest work [ 5 ] identifies statistically relevant bones and approximates bone transforms from example mesh animations.
Background	Using established terminology from statistical modeling, these example-based approaches can be considered as non-parametric skin deformation methods.
Background	The data needed for these methods grows with the number of examples, but arbitrary deformations can be approximated as a result.
Background	Simpler parametric skinning approaches (of which SSD is the prototype) have a fixed number of parameters; these have also seen some development in recent years [ 6 ], [ 7 ].
Background	Skinning using free form lattices [ 8 ], [ 9 ] or NURBS curves [ 10 ] instead of skeletons to drive character surface are also common practices in the entertainment production.
Method	Our framework implements existing PSD theory and the distinction is that we insert an optimization module into the PSD pipeline by applying a unified inverse approach assuming the knowledge of basic skinning is unavailable.
Result	We provide detailed reasons why and how the inverse operation can improve the results.
Result	For a simplified case, we show that the direction of deformed vertices from inverse skinning is a linear function of joint rotation, while in the forward approach, that direction is kept as a constant.
Result	This demonstration provides for the first time a clear theoretical reason why inverse operation is required.
Result	We formulate editing geometry in rest pose as an optimization problem and propose a unified framework which can be implemented on high-end commercial packages while allowing any proprietary skinning operators to be incorporated.
Background	Skeleton Subspace Deformation (SSD) is a basic algorithm that is used to define how the character surface deforms following movements of its underlying skeletons.
Background	The main idea is introduced by [ 11 ], and is also known as soft skinning, linear blending or Single Weight Enveloping (SWE).
Background	Due to its simplicity and efficiency, SSD is widely applied to interactive applications such as games and virtual reality, and it is implemented in most commercial animation packages.
Background	A skeleton should be rigged to a character surface beforehand, roughly based on the anatomy of the character and kinetic rules.
Background	The pose in which the skeleton is rigged normally is referred to as the rest pose.
Background	The basic relationship between surfaces and skeletons is defined at the rest pose, and all motions of the character will be influenced thereafter.
Method	If SSD is adopted to define this relation, each vertex or control point of the character surface is provided with a list of joints, that will influence it, along with the weight indicating the amount of influence.
Method	When the character is animated, the position of a vertex in the animated pose is the result of weighted linear blending of its transformation by each associated joint.
Method	For a vertex in rest pose v , its transformed position in pose p is v p .
Background	T pk means the kth joint’s transformation from rest pose to pose p. Readers can find details on how to compute T pk in [ 1 ].
Method	ω k is the corresponding weight.
Method	This weight is usually a function of distance between v r and its associated joints, and is defined when we apply SSD to the rigged character.
Method	Rectangles represent animated sections in each of two frames and the curve shows the blended result of both frames.
Background	Since vertex transformations can be easily implemented in the graphic card, SSD is very popular in circumstances that require animating a number of characters in real time.
Method	Some opportunities for control are provided to the animators.
Method	When a character goes wrong in some pose, animators can adjust joint influence weights.
Method	But the domain of adjusting one vertex in this way is strictly limited to the linear subspace formed by the vertex as transformed by joints influencing this vertex.
Background	The famous SSD problem of “collapsed elbow” is recognized in [ 1 ] as being due to the fact that deforming is limited to a linear subspace.
Background	Because of this limitation SSD cannot synthesize many parts of a character skin involving complicated joint structures.
Background	Built on the SSD scheme, the Pose Space Deformation (PSD) is proposed by [ 1 ] as a combination of SSD and shape blending providing nice solution to above mentioned problems.
Method	In our proposed framework, this step will be replaced by an optimization routine.
Method	We add this delta to the original character surface and then let SSD or any other skinning scheme finish the final transformation.
Method	For a vertex v, if sculpted in N example poses, then there are N delta d i , i = 0, . . . , N − 1 corresponding to each pose x i , i = 0, . . . , N − 1.
Method	These are converted to rest pose displacements using d i r = SSD −1 (d i ).
Method	We adopt Gaussian Radial Basis functions to interpolate d i r .
Method	First a N ∗ N matrix Φ is built with the (i, j)th element as φ ( x i − x j ), where x i − x j means the Euclidean distance between pose x i and pose x j , then we have a linear system:
Method	Here W and D r are column vectors with ith element ω i and d i r respectively.
Method	In the synthesis phase, for an intermediate pose x, we can obtain the delta d for this vertex by:
Method	For the Gaussian function φ (x) = e − σ x 2 2 , σ is used to control the “fall-off”.
Method	, we use Gaussian Radial Basis functions to interpolate 3 points.
Method	The blue and green curve represent σ = 1.0 and σ = 2.0 respectively.
Method	Other basis functions also can be candidates.
Method	Although PSD and improved example-based schemes have been discussed in many publications [ 2 ], [ 3 ], [ 4 ], the reason why the inverse should be performed is still ambiguous.
Method	We still study SSD as the underlying skinning, since an explicit form of basic skinning can help to simplify our task of explanation.
Method	We call the PSD scheme without the inverse operation as “forward PSD”, and comparison to it will be used to demonstrate the superiority of the inverse method.
Method	For N examples, a vertex v is first transformed from rest pose by SSD to positions v i , i = 0, . . . , N − 1, then animators move it to example positions to obtain delta values d i , i = 0, . . . , N − 1.
Method	The final positions of v in example poses are v i + d i , i = 0, . . . , N − 1, and we call them target positions vt i .
Method	The “forward PSD” approach then concludes by interpolating d i as a function of pose.
Method	In the inverse approach we instead apply the inverse of SSD i (∗) to v i t to obtain a modified rest pose vertex v r i .
Method	The difference of vr i and vr produces new delta value d i r , which will be the input of linear system (equation 2) introduced in the previous section.
Method	In this step we need implement the inverse skinning operator SSD −1 .
Method	Since SSD is a 3D transformation, SSD −1 simply is the inverse transformation matrix generated by SSD.
Method	For the situation where other unknown skinning operations are adopted, we propose a unified framework which will be discussed in the following section.
Method	Next we build a new delta vector Dr with ith element as d i r , and replace D in equation 2 with d i r to get a new weight vector W r .
Method	v x represents the final position of vertex v in pose x.
Method	Given two examples as shown in Figure 2 (a) and (b) respectively, vertex v with the position v r in the rest pose ( 0 degrees ) is sculpted to a “target position” v ti in an example pose (90 degrees).
Method	The delta value in the first pose is zero.
Method	Then we apply forward and inverse PSD respectively to interpolate these two poses.
Method	For an intermediate pose x, we have two distinct deforming vertices resulting from two algorithms, as illustrated in Figure 3 , v ssd x , v x p , v x I p are the deformed positions from SSD, forward and inverse PSD in an intermediate pose x.
Method	We use two angles α p and α I p to analyze how directions of a deformed vertex change with the pose.
Method	In the forward case, α p is formed by the vector (v ssd x , v x p ) and the line y = Y v ssd x , where Y v x ssd is the y coordinate of v x ssd .
Method	For two examples shown in Figure 2 (a) and (b), we have delta values d 1 = [d 1x , d 1y ] and d 2 = [d 2x , d 2y ].
Method	Taking the model in rest pose as an example is a common practice when applying shape interpolation, since interpolating effects from other examples should not change the original model in rest pose.
Method	Therefore, by solving above equation we have: ω 1x = φ 11 −1 d 1x + φ 12 −1 d 2x = φ 12 −1 d 2x ω 2x = φ 21 −1 d 1x + φ 22 −1 d 2x = φ 22 −1 d 2x = d 2x ω 1y = φ 11 −1 d 1y + φ 12 −1 d 2y = φ 12 −1 d 2y ω 2y = φ 21 −1 d 1y + φ 22 −1 d 2y = φ 22 −1 d 2y = d 2y where φ i −1 j is the (i, j)th element of Φ −1 , and if i = j, φ i −1 j = 1.
Method	Then in an intermediate pose x for α p , we have tan α p = d d x y .
Method	d y and d x are delta values in x, y coordinates computed from equation 3.
Method	Then we take a look at α I p in the inverse case.
Method	We transform two examples to rest pose to obtain delta values: d 1 r = [d 1x , d 1y ] = [0, 0] and d r 2 = [d 2x , d 2y ].
Method	Then for the vertex v r = [v 0x , v 0y ], SSD θ (v r ) transforms v from rest pose to [v SSD x , v SSD y ] = [v 0x cos θ − v 0y sin θ , v 0x sin θ + v 0y cos θ ].
Method	In an intermediate pose x, we have its corresponding rest position as v r x = [v 0x + d x , v 0y + d y ], and here the [d x , d y ] are interpolated result computing from equation 3.
Method	We just apply the simplified SSD to v x r to obtain v I x p : v Inp x = (v 0x + d x ) cos θ − (v 0y + d y ) sin θ and v Inp y = (v 0x + d x ) sin θ + (v 0y + d y ) cos θ .
Method	Similarly, we compute the tangent of α I p : tan α I p = − v v Inp Inp x y − − v v SSD SSD x y = − d x sin θ + d y cos θ = − tan( β + θ ) d x cos θ − d y sin θ where tan β = d y = d 2y .
Method	Then we can see α I p = d x d 2x −( θ + β ), which is linearly proportional to the pose rotation θ .
Method	And now we take a look at a real cylinder model with one vertex sculpted in the second pose, shown in the Figure 4 .
Method	Forward PSD and the corresponding inverse PSD in the same poses (30, 45 and 60 degree of one rotated joint ) are illustrated respectively in Figure 5 .
Result	We can see that in forward case, the direction of deformed vertex always keeps the same with the example cylinder ( figure 4 ).
Result	For inverse PSD however, that direction is changed along with the rotation of the joint.
Result	The case described above is quite common in practice when animating shoulder, elbow, knee, hip-bone, neck, etc.
Result	All these parts would rotate from the rest pose with some angle to other poses.
Method	On the other hand, as a matter of experience, PSD is supposed to be a method as “local” correction, which means pose space should not be extended to a whole space that has to incorporate all influenced objects.
Method	Otherwise, large amount of unnecessary works of building examples will be required, and the distance between different poses is also meaningless.
Method	For example how to measure the distance between differing poses such as “lying down” and “pitching”?
Method	The above discussions assume that the basic skinning algorithm is SSD, but in many circumstances, other deformation schemes will be adopted [ 9 ], [ 10 ], most of which have been implemented in most animation packages.
Problem	Therefore we propose a unified framework in which no explicit inverse operation is necessitated.
Method	Given a basic skinning method supported by animation packages we can deform the original character model from rest pose to another specific pose.
Method	To find delta d i in the rest pose: v i = SKINNING i (v r ) + d i = SKINNING i (v r + d i ) we can setup a minimization problem to minimize the function:
Method	This function can be given to Powell’s method to find d i at the minimum of f (d ).
Method	For each example pose P i , we have a d i , then we can apply radial basis function to d i (i = 0 . . . n − 1) in pose space to obtain ω i (i = 0 . . . n − 1).
Method	In synthesis phase, a d x in an intermediate pose x can be computed by equation 3 based on its position x in pose space d x = ∑ n−1 i=0 ω i φ (||x − x i ||).
Method	Then we have the final synthesis result:
Background	For a minimization problem, there are many candidate algorithms according to the form of function, knowledge of the derivative, computing capacity, and requirements for the rate of convergence, etc.
Problem	In our situation, the function form is not explicit, and the computing burden increases with the number of example poses increases.
Method	We will adopt Powell’s method as the solution to this minimization problem.
Background	One advantage of Powell’s classic method is that it does not need explicit computation of the function’s gradient [ 12 ].
Method	Because we are treating the skinning operations as a “black box”, their gradient is not available, so Powell’s method is suitable.
Method	Minimizing the function f (d ) in a particular direction is actually minimization problem of one variable, which is also called line minimization.
Background	Powell’s idea is trying to find each minimum of function f (d ) in different direction until f (d ) stops decreasing.
Background	How to choose the next direction is the main concern of Powell’s method, and it has been proved that after repeated cycles of M line minimizations on conjugate directions, the optimization will in due course converge to the minimum [ 12 ].
Method	M is the dimensionality of the function f ().
Method	We implement this unified approach as a Maya plug-in.
Background	In Maya, “tweaking” is a procedure adding delta values to original surface vertices before any deformations.
Background	It is actu- ally Maya’s form of rest-pose editing for their built-in deformation operators.
Method	As presented in Figure 6 , the whole system is divided into two phases.
Method	The first phase is to find each delta in the rest pose corresponding to each example pose.
Method	Basic skinning provided by Maya is called in the loop of minimization scheme.
Method	The output of the first phase, the delta in the rest pose, is input to into the second phase that is a linear system performing RBF interpolation to obtain the PSD weights.
Method	In the synthesis process, for an intermediate pose x, a delta d x ( or d x r ) is synthesized by equation 7.
Method	The final deformed vertex is computed by Maya skinning as in equation 10.
Method	If the SSD transformation in equation 1 is singular, some types of inverse PSD deformation will not be possible, because any component of the desired deformation that lies in the null space of the SSD matrix will be ignored.
Method	Although singular cases are rare (one example is a joint with 180 o rotation and equal 2 1 , 2 1 weights on the two joint frames, which is an unrealistic case of selfintersection), it is possible to handle these cases with a small rearrangement of the inverse PSD approach.
Method	We reformulate the problem as f (y i ) = v i + w i − SKINNING i (v r + d i ) 2 + λ w i 2 where y i is a concatenated vector y i = [d i , w i ] and λ is an arbitrary small number.
Method	The final synthesis is then v x = SKINNING(v r + d x ) + w x where w x is interpolated after SKINNING by applying the same RBF scheme as used for d x (thus, only minimal code changed are required).
Method	The idea here is that, since w i is being minimized, it will be generally be zero, and will be non-zero only if it is not possible to obtain the desired deformation v i using SKINNING i (v r + d i ).
Method	In the case where the SSD transform is nearsingular, the solved d i can be much large than other d k , which can result in poorly posed interpolation.
Method	To address this case, we further modify the objective function as        f (y i ) = v i +w i −SKINNING i (v r +d i ) 2 + λ w i 2 + μ d i 2 where 0.0001 is a sufficient value for both λ and μ .
Result	Inverse skinning integrates SSD and shape interpolation more firmly than its forward rival.
Result	We demonstrate the direction of deformed vertex in inverse skinning is linearly proportional to joint rotations in a simplified example, while the forward PSD does not incorporate the direction information.
Result	Therefore the inverse approach presents better performance and more consistent interpolation ( Figure 7 to Figure 10 ).
Result	By formulating the inverse process as a minimization problem we propose a unified model not only for SSD but also for other skinning schemes, into which shape interpolation can be incorporated.
Result	But the minimizing process will introduce more cost.
Result	This cost depends on the size of deformed character, parameters of minimization methods (Powell) such as convergence precision, and the number of example poses.
Result	In addition the cost of the animation software must be considered (for example, the Maya API implements a run-time type interpretation system on all operations).
Result	The cost of the inverse operation is not critical, however, since it is a one time “setup” cost, and the compute time is insignificant compared to the human time required to sculpt the desired deformations.
Result	Once the linear system is solved, the synthesis is potentially realtime since no extra computing is involved in this process compared to the forward PSD.
Result	We implement this unified example-based approach as a Maya plugin.
Result	It interoperates with their closed-source “Smooth Skinning” deformation.

Problem	This paper presents a method to retarget the motion of a character to another in real-time.
Method	The technique is based on inverse rate control, which computes the changes in joint angles corresponding to the changes in end-effector position.
Method	While tracking the multiple end-effector trajectories of the original subject or character, our on-line motion retargetting also minimizes the joint angle differences by exploiting the kinematic redundancies of the animated model.
Result	This method can generalize a captured motion for another anthropometry to perform slightly different motion, while preserving the original motion characteristics.
Result	Because the above is done in on-line, a real-time performance can be mapped to other characters.
Result	Moreover, if the method is used interactively during motion capture session, the feedback of retargetted motion on the screen provides more chances to get satisfactory results.
Result	As a by-product, our algorithm can be used to reduce measurement errors in restoring captured motion.
Result	The data enhancement improves the accuracy in both joint angles and end-effector positions.
Result	Experiments prove that our retargetting algorithm preserves the high frequency details of the original motion quite accurately.
Problem	The dream of animating complex living creatures with pure computation (such as inverse kinematics, or dynamic control) proved impractical.
Problem	Even though creatures are not free from physics, their motion is not a direct consequence of physics.
Background	Dynamic control can provide solutions based on simplified assumptions about human motion.
Problem	However, the result tends to look quite mechanical.
Background	If a high quality character animation has to be produced during a short period of time, motion capture might be a most reasonable choice these days.
Problem	The captured data itself is for a specific person in performing specific motion.
Problem	Whenever the data needs to be reused, it has to be retar- getted to account for the differences in the anthropometry and motion.
Problem	Therefore motion retargetting is emerging as an important technique in recent character animation.
Problem	If the original motion characteristics are severely lost during motion retargetting, the technique loses its merit over the above pure computation approaches.
Problem	The problem we try to solve in this paper can be summarized as: ( 1 ) finding in real-time the motion retargetted to a new character that has different anthropometric proportions, and ( 2 ) at the same time, preserving the features of the original motion during the retargetting.
Problem	( 3 ) As a by-product, it is possible to use the above retargetting algorithm for enhancing motion capture data so that the errors in joint angles and end-effector positions are reduced.
Method	On-line motion retargetting presented in this paper is based on inverse rate control [17] (or resolved motion rate control), which is a way to implement inverse kinematics based on Jacobian.
Method	It computes the changes in joint angles corresponding to the changes in end-effector position.
Method	While tracking the multiple end-effector trajectories of the original subject or character, our on-line motion retargetting imitates the joint motion of the original character by exploiting the kinematic redundancies of the animated model.
Method	Moreover, jerky motion is prevented since the next configuration is dependent on the previous configuration in inverse rate control.
Result	As will be shown in later experiments, the high frequency details of the original motion, which carries important characteristics of the motion, are also well preserved by our algorithm.
Method	The input is a stream of joint angle vectors   src of the measured subject in the source motion and another stream of the reference (or desired) end-effector positions x 1 of the animated character at discrete time ticks.
Method	The output is a stream of joint angle vectors   des of the animated character during the destination motion at corresponding time ticks.
Method	It explains why it is called on-line.
Method	If the retargetting can be done in on-line, real-time performance can be mapped to another character, or the feedback of the retargetted animation can facilitate motion capture session so that satisfactory results can be obtained with fewer trials.
Method	Since the memory required for on-line retargetting does not increase with time, our algorithm can handle an infinitely long sequence of motion.
Method	For example, when there is a bat-swing motion, we can obtain different swing motions aiming at different hit positions by specifying x 1 t appropriately.
Result	As a by-product, our OMR algorithm can be used to reduce measurement errors in restoring captured motion.
Method	For this data enhancement, we use captured position data for x 1 t even though it can be calculated from   src t by forward kinematic positioning, to recover from possible measurement errors in joint angles.
Method	If the positioning of the pose is done from joint angles alone, the errors can accumulate as the forward kinematic positioning propagates toward the end-effector.
Method	The end-effector position data x 1 t can be utilized to limit the above error accumulation within a certain range.
Background	Several techniques have been proposed for reusing or altering existing motions.
Background	Witkin et al’s motion warping [19] and Bruderlin et al’s motion displacement mapping [4] discuss motion editing technique based on direct manipulation of data curves.
Background	Bruderlin et al [4] and Unuma et al [11] utilized signal processing techniques for motion editing.
Background	Wiley et al [18] proposed the interpolation synthesis algorithm that chooses and combines most relevant motions from the database to produce animation with a specific positional goals.
Background	Though some of the techniques above can be used for motion retargetting problem with user’s extra efforts, they don’t specifically address the motion retargetting problem.
Background	In [3], Boulic and Thalmann presented the combined direct and inverse kinematic control technique for motion editing.
Background	The concept called coach-trainee metaphor is very similar to the motion retargetting problem formulation.
Background	The fundamental idea is to consider the joint motion of coach as a reference input to trainee motion for the secondary task exploiting the null space of the Jacobian when solving inverse kinematics.
Background	The inverse kinematic constraint is given by half-space such as plane, cylinder, or sphere.
Background	Although their approach shares the technique of utilizing the redundancy in inverse kinematic control with ours, the problem they solved is not the motion retargetting but is rather a motion correction technique since the end-effector constraint specified by half-spaces is not general to solve the motion retargetting problem.
Background	A method which is devoted to the motion retargetting problem was proposed by Gleicher [6].
Background	He used the spacetime constraint method that minimizes an objective function g x subject to the constrains of the form f x = c .
Background	The constraints can represent the ranges of parameters, or various kinds of spatial-temporal relationship among the body segments and the environment.
Background	The objective function is the time integral of the signal displacement between the source and destination motion.
Background	The global method as above can correlate frames back and forth within the whole duration and thus generally produces more smooth results compared to the local method such as our OMR technique.
Background	But the look-ahead property of the global method is effective when the constraints are imposed only at sparse key frames.
Method	Our OMR takes continuous trajectories of constraints as input, so that it produces globally coherent motion in spite of local computation.
Method	The global coherence is also achieved from the effort to exploit the redundancy of the system in resembling the original motion.
Method	The local coherence of the motion comes from the fact that the adjacent frames are inter-related by the inverse rate control.
Result	Therefore, without significant degradation of quality, our algorithm provides much faster and interactive way of motion retargetting.
Background	Bindiganavale and Badler [2] presented a method to abstract and edit motion capture data.
Background	Their algorithm detects significant events and abstracts constraints from the motion, and imposes those constraints to other character.
Background	The constraints abstracted from the motion is solved by inverse kinematics at significant frames and then those frames are interpolated.
Background	Although the constraint abstraction is an improvement compared to the other techniques, the interpolation technique might fail to preserve the high frequency details if the key frames are sparsely spaced.
Method	m can be 12 or 18 if we want to impose multiple end-effector constraints.
Method	J 1 is called Jacobian and is an m n matrix that linearly relates the end effector velocity and joint angle velocity at the moment.
Method	Given the end effector velocity, we can get joint angle velocity by inverting the Jacobian.
Method	However, most articulated figures have kinematic redundancy and thus the inverse of Jacobian is not unique.
Method	Some criteria can be specified to pick one that best fits for our purpose.
Method	One of popular criteria is called the minimal norm solution         ( 4 )        where J 1 + = J 1 T J 1 J 1 T , 1 is the pseudo inverse 1 of J 1 .
Method	Another way to utilize the redundancy of the system is to set y to the gradient , r g of a criterion function g   in Equation 5.
Method	Then integration of Equation 5 tries to reduce the value of g   while the end-effector is made to track the given trajectory [9].
Background	Balestrino et al [1], Tsai and Orin [15], and Sciavicco and Siciliano [14, 13] proposed the closed-loop inverse kinematics (CLIK) scheme based on Jacobian pseudoinverse.
Method	CLIK leads to zero steady state error which means that the error is exponentially convergent to zero for a fixed target position.
Method	It can be easily shown that as the smallest eigen value of K 1 becomes large, the convergence rate increases accordingly since the error dynamics is governed by the relation e 1 + K 1 e 1 =0 .
Method	In a continuous time formulation such as Equation 7, a large value of K 1 is desirable.
Method	However, as will be shown below an arbitrarily large K 1 doesn’t guarantee convergence in implementing the discrete version of Equation 7.
Method	Therefore, e 1 n should be estimated.
Method	Below we show that any estimation based on the old values (at n , 1 , n , 2 , : : : ) requires K 1 to be I for the best tracking performance.
Method	Suppose that we estimated e 1 n simply with e 1 n , 1 .
Method	) But in practice, we found that instability rarely occurs at a usual sampling rate ( 30 60 Hz) in dealing with human motion.
Method	x des 2 is the actual result of the secondary task that tries to realize the given goal x 2 .
Method	It is proven that e 2 is ultimately bounded within a certain range and the tracking error for the primary task is not affected by the second term of Equation 15 [13].
Method	But again, arbitrarily large K 2 is not allowed in discrete implementation.
Method	We found that the estimation rule described below gives satisfactory results.
Background	The serial chain is not suitable for modeling creatures since underlying articulated structures contain branches.
Method	An illustrative example is taken from human upper body, and is shown in Figure 2 .
Method	The model consists of spine and two arms.
Method	The waist is the root of the kinematic tree structure, and the two arms are branching at the top of the spine.
Method	If both hands have their own goals to reach, and if inverse kinematics is solved for these cases separately, then the spine angles will differ in the solutions.
Background	In [22], Zhao and Balder solved this problem by a weighted sum of independently obtained gradients, each of which directs its corresponding end-effector to a goal position.
Background	However, the effects of different weights are not easily predictable.
Background	Depending on the weight assignment, their algorithm can fail to find an inverse kinematic solution even if all the constraints can be actually met.
Method	Intrinsically, the problem of finding inverse kinematic solution of multiple constraints doesn’t require any weight or priority assignment: if all the end-effector constraints can be met, then it should be possible without considering weights or assigning priorities to each end-effector constraint.
Method	Compared with Zhao and Badler’s algorithm, Jacobian based inverse rate control gives a quite simple and intuitive solution to the problem.
Method	The only thing we have to do in order to incorporate multiple end-effector constraints is concatenating the end-effector vectors and composing the Jacobian appropriately.
Method	Of course, the Jacobian will have many zeroes where the joint angle and the end-effector have no relation such as left elbow joint and right hand.
Method	In inverse rate control, the above conflict of the spine angles is resolved during the computation of the pseudo inverse of the Jacobian.
Method	In general, we can formulate the motion retargetting problem with the following task set, and can solve for   des .
Method	Since joint angle trajectories contain important characteristics of a motion, and since the end-effector movements are already tracked by the primary task, an obvious and useful choice for the secondary task might be to imitate the joint motion of the source character.
Method	Reasonable choices for K 1 and K 2 are I ’s in discrete implementation as stated before.
Method	But K 1 , K 2 can be adjusted based on the dexterity measure to get consistent motion near the kinematic singularities.
Method	A popular dexterity measure is min = max , where min and max are the minimum and maximum, respectively, among the singular values of the Jacobian.
Method	In this case, smaller K 1 and K 2 should be used if the dexterity measure turns out to be small.
Method	The adaptive scheme can be also useful if we apply the OMR algorithm to motion transition.
Method	Smaller gain (e.g. K 1 = K 2 = 0 : 1 I ) will produce sluggish tracking, but produces smooth motion.
Method	Therefore, if the animated model switches to another motion and there exists a large discrepancy at the motion boundary, smooth transition can be obtained by adjusting the gain matrix K 1 and K 2 appropriately.
Method	Therefore another provision for enforcing stability might be to clamp the value that goes into the box of J 1 + in Figure 4 whenever it is over a certain threshold.
Method	The provision might be effective when there is an excessively large acceleration, or when the model is fully stretched and almost no manipulative redundancy is left in the system.
Method	(In dealing with the human motion, however, the above provision was almost never needed.
Method	When we capture a motion, we often measure the joint angles and use forward kinematics to reconstruct the motion.
Problem	But the method can introduce large end-effector position errors since the joint angle error near the base is amplified when it comes to the end-effector, and joint angle errors are accumulated as the forward kinematic positioning propagates toward the end-effector.
Background	Choi et al’s interpolation/regression method [5], applies inverse kinematics at sparse keyframes and the resulting joint angles are interpolated with cubic spline curves.
Background	The interpolation is combined with least square fitting so that the characteristics of the original joint angle data is preserved in the resulting motion.
Method	The OMR algorithm described in the previous section can be used to reduce measurement errors in restoring the captured motion.
Result	The new method is an improvement over the above interpolation/regression method in three aspects: ( 1 ) inverse kinematics is done at every frame, which promises much closer end-effector tracking, ( 2 ) the joint angle imitation is done by exploiting redundant degrees of freedom rather than depending on the least square fit, and ( 3 ) the high frequency component of the original motion is preserved much better in the new method.
Method	For the enhancement, we measure both joint angle and end-effector trajectories during the motion capture session.
Method	The measured trajectories are supplied to our motion retargetting algorithm: the end-effector trajectories are supplied for x 1 , and the joint angle trajectories are supplied for   src .
Method	Of course, the destination character has to be same with the source character, if pure data enhancement needs to be done.
Result	In general, our algorithm also reduces the errors in joint angle measurements.
Result	While the joint angle errors can accumulate in forward kinematic reconstruction, once it is processed by our OMR, the total amount of accumulated error is limited by the amount of end-effector position error.
Result	Moreover, the joint angle error due to the end-effector position error is distributed among all the joints.
Result	Therefore unless the amount of end-effector position error is excessively larger than that of joint angle errors, our OMR produces more accurate result than the unprocessed data.
Method	Note that the above does not mean the retargetting and data enhancement should be done separately.
Method	If a different destination character is used, the two things are actually achieved at the same time.
Result	This is especially useful when a real-time performance is retargetted.
Method	In the first experiment, we show a retargetting example in which our OMR is applied to retarget a walking motion, to demonstrate that our OMR based on inverse rate control is not inferior in the quality to the retargetting based on spacetime constraints.
Method	Major error analysis of the algorithm is given in this example.
Method	In the second experiment, we show the retargetting of bat-swing motion.
Method	In this experiment, the source motion (refer to the video clip #1) is a curved path walking motion which was procedurally generated by Ko’s locomotion algorithm [8].
Method	The walker took 13 steps and produced a total of 390 frames.
Method	The kinematic structure of the characters used for walking motion is shown in Figure 5 .
Method	Since the lower body motion is far more important than the upper body motion in walking example, we retargetted only the lower body motion.
Method	As shown in Figure 5 the lower body consists of pelvis, upper leg, lower leg, foot, and toes, and they are connected at the hip, knee, ankle, and ball joints.
Method	The total degree of freedom of the lower body is 8 3 + 6 = 30 .
Method	(All the joints were modeled by 3-DOF joints, and the base has extra 6 DOFs.
Method	) The destination character was about 60% scaled down from the source character with non-uniform proportions.
Method	In the retargetting, the secondary task was set to   src =   des .
Method	To specify the primary task, we set the toe-tip of the stance leg as the base and the toe-tip of the swing leg as the end-effector.
Method	The source character’s toe-tip trajectory was used for x 1 without any modification.
Method	Therefore the destination character had to take relatively bigger steps considering his body size.
Method	At the boundaries of steps the base and end-effector were switched.
Method	It implies that there can be discontinuities at the boundary if the tracking error is large.
Result	The retargetted motion with the above task set is shown in the video clip #2.
Result	The tracking error of the swing foot was negligible and thus the produced motion was smooth at the step boundaries.
Result	But the pelvis motion showed non-uniform speed along the direction of progression (anterior-posterior), which wasn’t observable in the source motion.
Method	So we constrained the transverse plane motion of the pelvis.
Method	i.e. the pelvis was designated as another end-effector, and the x; z component of the source character’s pelvis movement was tracked in the destination motion.
Method	(Note that the pelvis motion along y -axis should be adapted to account for the height difference).
Result	After adding the constraint, we could obtain a satisfactory result as shown in the video clips #3 and #4.
Result	Even with the extra constraints, the end-effector trajectories of the source and the destination made an accurate match.
Result	The comparison is shown in Figure 7 .
Result	The dotted curves for the source motion are not visible because they overlap exactly with the solid curves, the end-effector trajectories of the destination motion.
Method	To show the tracking error microscopically, the area indicated with a small box near the 150th frame in Figure 7 was magnified in Figure 8 .
Result	The trajectories in the figure show that the tracking error is kept small where the velocity is nearly constant, but the error increases when the velocity makes sudden changes.
Result	The maximum error (1.0464 cm) occurred at the 128th frame where the y -coordinate (height) of the toe-tip reached its peak acceleration and this error was reduced to a negligible level at around the 135th frame as the acceleration decreased.
Method	The step boundary was taken from low-acceleration points so that the base to end-effector switch makes a smooth transition.
Result	The joint angle trajectories of the left leg during the original and retargetted motion are plotted in Figure 10 .
Result	Only the angles around the sideways direction (medial-lateral) axes are presented in the graphs.
Result	The comparison shows that the amplitude of the hip angle is increased in the destination motion to cover the given step length with the relatively smaller body.
Result	Other than that the original joint angle pattern was quite well preserved.
Result	3 At the end of every step, the ball joint of the source character showed an abrupt change from a large negative value to zero.
Result	It corresponds to the toe-off moment when the toes take off the ground.
Result	After the retargetting, the sharp corner of the trajectory was well preserved.
Result	In general, our OMR preserves the high frequency content of the motion quite well, since inverse rate control is directed by Jacobian values.
Result	Big mountains or valleys are never missed.
Result	To recover tiny fluctuations as well, however, a high sampling rate is needed to avoid aliasing.
Result	If the sharp corners are undesirable, they can be prevented by adjusting the gain matrix K 2 or clamping some of the control input as stated in Section 4.
Result	The adjustment of K 2 does not affect the end-effector tracking performance.
Method	In this experiment, actual performance of a bat swing motion was processed by our OMR to produce the destination motion of three different characters shown in Figure 9 .
Method	The anthropometry of Character B is about the average.
Method	Character A has a longer torso but shorter limbs than average, and Character C has a shorter torso but longer limbs.
Method	Their kinematic structures are same as Figure 5 except that the torso is segmented to 5 parts and the feet are excluded.
Method	To set the primary task, the base and end-effectors should be specified as before.
Method	In this experiment, the pelvis was chosen as the base and two hands were chosen as the endeffectors.
Method	Three 6-DOF sensors were used to capture those positions and orientations.
Method	The end-effector motion was directly supplied for x 1 t without any modification.
Method	Since all the torso segments can not be measured due to the limited number of sensors, we measured only the topmost segment.
Method	Therefore, the five joints from the waist to the top-most torso segment had to be generated from the orientation difference between the pelvis and the top-most torso segment.
Method	For this, the measured orientation of the topmost torso segment was added to the primary task, and zero angles for the unmeasured joints were added to the secondary task, expecting the primary task can be met with minimal joint angles along the torso.
Method	The other sensors were used to measure the joint angles.
Method	(Because we had only 13 sensors available, we had to give up capturing the foot motion.
Method	) In this experiment only the upper body motion was adapted by OMR.
Method	The lower body motion was reconstructed by applying the measured joint angles directly.
Result	The retargetting of the source motion to Characters A, B, C are shown in the video clips #5 ̃6, #7 ̃8, and #9 ̃10, respectively.
Result	The small green boxes in the video indicate the position of the end-effectors and base.
Result	In the video we can observe that end-effector positions are accurately tracked.
Result	Since the body dimensions of Character B and the real performer are similar, the retargetted motion does not contain any noticeable difference from the source motion.
Result	In the case of Character A, however, we can see the waist is bent to lower the hit position, and the torso is shifted forward to account for the shorter arms.
Result	In the case of Character C, the torso is bent backward and makes a bigger twist to account for the longer arms and shorter torso.
Result	Snap shots were taken during the retargetted motions to clearly demonstrate the above adaptation for the anthropometric differences and shown in Figure 11 .
Method	Since we had no privilege to install our program to the platform equipped with a motion capture system, we had to emulate the real-time motion capture.
Method	That is, the motion data captured at 30Hz was fed to the OMR system with the same sampling rate using a timer.
Result	At this sampling rate, not a single frame was lost even with the visualization included.
Method	We used an Intergraph GX1 system (dual P-III 550, wildcat 4000) for the experiments.
Result	The code was not fully optimized and so the performance can be potentially improved further.
Result	The slower rate of the bat swing motion is due to the bigger size of the Jacobian matrix compared to the walking motion (8 30 vs. 9 42).
Result	As shown in the table, the OMR is fast enough to process motion capture data collected at a usual sampling rate (30 90Hz) in real-time for the models of reasonable complexity.
Result	This paper presented the on-line motion retargetting technique based on inverse rate control.
Result	The method is an improvement over the off-line retargetting based on spacetime constraints since real-time performances can be retargetted without degradation of retargetting quality.
Result	The OMR technique greatly helps to get more satisfactory results in motion capturing with fewer trials by giving the real-time feedback to the performer.
Result	Furthermore, the captured data are enhanced in both end-effector positions and joint angles by going through our OMR filter.
Result	One minor unsolved problem is that there is no easy way to guarantee full-proof stability of the system due to the non-linearity.
Result	We observed that at a very low sampling rate, and if the model goes near the kinematic singularity and thus very little manipulative redundancy is left, then the system can became unstable.
Result	However, experiments proved that the system never become unstable at 30Hz or higher sampling rate.
Result	If the source motion is available only at a low sampling rate, two remedies are recommended: ( 1 ) by interpolating the source motion curves, first produce more samples, and then use them as the input to the OMR filter, or ( 2 ) scale down the end-effector trajectory to avoid the singular configuration, or use both of ( 1 ) and ( 2 ).
Result	The above remedies are for an excessively bad situation.
Result	Our on-line motion retargetting produces satisfactory results in retargetting most human or creature motion.
Result	If the technique is well utilized, it can be very useful to people in character animation and game industries.

Problem	We present a technique which allows subtle nonlinear quasi-static deformations of articulated characters to be compactly approximated by data-dependent eigenbases which are optimized for real time rendering on commodity graphics hardware.
Result	The method extends the common Skeletal-Subspace Deformation (SSD) technique to provide efficient approximations of the complex deformation behaviours exhibited in simulated, measured, and artist-drawn characters.
Method	Instead of storing displacements for key poses (which may be numerous), we precompute principal components of the deformation influences for individual kinematic joints, and so construct error-optimal eigenbases describing each joint’s deformation subspace.
Method	Pose-dependent deformations are then expressed in terms of these reduced eigenbases, allowing precomputed coefficients of the eigenbasis to be interpolated at run time.
Method	Vertex program hardware can then efficiently render nonlinear skin deformations using a small number of eigendisplacements stored in graphics hardware.
Result	We refer to the final resulting character skinning construct as the model’s EigenSkin.
Result	Animation results are presented for a very large nonlinear finite element model of a human hand rendered in real time at minimal cost to the main CPU.
Background	Significant work has occurred in graphics for deforming articulated characters using geometric methods [Magnenat-Thalmann et al. 1988; Singh and Kokkevis 2000; Lewis et al. 2000] and physicallybased methods [Wilhelms and van Gelder 1997; Scheepers et al. 1997; Gourret et al. 1989].
Background	Despite this, most character animation in interactive applications, such as video games, is based on a geometric skeletal deformation technique commonly referred to as linear blending, or matrix palette skinning, or Skeletal-Subspace Deformation (SSD), in which vertex locations are weighted averages of points in several coordinate frames (see [Magnenat-Thalmann et al. 1988; Magnenat-Thalmann and Thalmann 1991]).
Background	One alternative is to store a large database of character poses, and interpolate between them [Maestri 1999].
Background	While these approaches give animators great control over character deformation, they have the disadvantage of requiring a potentially very large number of poses for animation, and also lack an underlying kinematic model.
Background	Nevertheless, such approaches are common, especially for facial animation [Parke et al. 1996].
Background	A hybrid approach which effectively combines SSD and morphing, is the work of Lewis et al. who introduced “Pose Space Deformations” (PSD) [Lewis et al. 2000] to overcome the limitations of linear transform blending while retaining a kinematic approach.
Background	Starting with a (simple) SSD model, they then store vertex displacement offsets between the SSD surface and various character poses.
Background	At run time, the character may be simulated by mapping interpolated displacements onto the underlying SSD character model, thereby providing a kinematic deformation model which also has artist-drawn poses.
Background	While this is a big improvement over character morphing, and sufficiently interactive for animators, storing surface displacements for each pose in a large pose space is a memory inefficient approach for hardware applications.
Background	Similar to PSD, Sloan et al. show a more efficient method of interpolating an articulated figure using example shapes scattered in an abstract space [Sloan et al. 2001].
Background	The abstract space consists of dimensions describing global properties of the shape, such as age and gender, but also includes dimensions used to describe configuration, such as the amount of bend at an elbow.
Background	Like our method, interpolation occurs in the rest pose before SSD is applied, however, the interpolation involves blending over all of the example shapes for every vertex.
Background	This becomes inefficient and difficult to map to hardware with the large number of examples required for a highly articulated figure since the independence of abstract space dimensions is not taken into account (e.g., bend in left elbow and bend in right elbow).
Problem	In addition to character poses created by 3D artists, we also wish to efficiently render deformation behaviour computed using physically-based and reality-based deformable models.
Background	Such models have been widely used [Terzopoulos and Fleischer 1988; Terzopoulos and Witkin 1988; Metaxas and Terzopoulos 1992; CaniGascuel 1998; O’Brien and Hodgins 1999; Pai et al. 2001; Allen et al. 2002], although most approaches are not intended for real time (hardware) rendering.
Background	Recently, approaches for fast simulation of physical dynamic volumetric deformations have appeared [Zhuang and Canny 1999; Debunne et al. 2001; Picinbono et al. 2001] for interactive applications, such as surgical simulation.
Background	Our interest is more closely related to quasi-static deformation, for which fast deformation techniques also exist [Cotin et al. 1999; James and Pai 1999] but are unfortunately restricted to small deformations unlike those associated with articulated characters (although see [James and Pai 2002b]).
Background	More closely related to character animation is anatomically based modeling of physical deformable models [Wilhelms and van Gelder 1997]; examples include musculature [Chen and Zeltzer 1992; Scheepers et al. 1997] and faces [Lee et al. 1995].
Background	We note that a large class of pose-dependent quasi-static deformations can be described using the EigenSkin approach, largely independent of their origin, whether artist-drawn, measured, or anatomically based physical models.
Background	For example, pose-space parameterization of nonhysteretic cloth on articulated characters has recently been considered [Herman 2001], and could be optimized for hardware rendering using the techniques presented herein.
Background	Finally, the use of reduced eigenbasis representations for highdimensional models has a long history in science, with foundations on Principal Component Analysis and Karhunen-Loeve theory [Jolliffe 1986; Hyvarinen et al. 2001].
Background	Related deformation topics include a morphable model for face synthesis [Blanz and Vetter 1999], modal analysis for dynamic vibrations [Pentland and Williams July 1989 ; James and Pai 2002a], decomposition of static deformations [Bookstein 1989], and recognition applications in computer vision, e.g., face recognition [Turk and Pentland 1991].
Result	We introduce a method for extending SSD that enhances its range of modeling capabilities at very little cost, and in a manner optimized for real time graphics hardware.
Result	EigenSkin constitutes an error-optimal set of eigenbases for approximating the original deformation model, for a given amount of per-vertex displacement memory.
Result	We illustrate our method by rendering a very large finite element model (which took several hundred hours to compute) at interactive rates on a PC with negligible cost to the main CPU.
Result	Using commodity graphics hardware, EigenSkin enables the simulation of subtle nonlinear surface deformations of geometrically complex models at little more than the cost of rendering.
Problem	Rendering of complex physical deformation models for character animation remains a significant hurdle for interactive applications, but one that has been largely overcome for off-line animation.
Background	Currently, most real time character animation, e.g., for video games, is done using a very common linear transform blending technique called (among other things) Skeletal-Subspace Deformation (SSD) [Magnenat-Thalmann et al. 1988].
Background	It is extremely popular for its simplicity and plausibility, and is also widely supported by graphics hardware accelerators.
Background	While methods have been proposed to address this and have been effectively employed by the motion picture industry [Lewis et al. 2000], due to memory and graphics hardware constraints nearly all video game character animation is still done using traditional SSD.
Problem	In this paper, we present a practical technique which overcomes all aforementioned SSD problems, and can be achieved using a memory-efficient linear correction to the traditional SSD method.
Result	The resulting EigenSkin construct allows subtle character deformations for skin and clothing, such as those derived from highly realistic artist-drawn poses, measurements from the real world, or laboriously computed anatomically and physically-based models.
Result	The deformations can be compactly represented in an efficient datadependent basis and rendered in real time using vertex shaders in commodity graphics hardware, e.g., see [Lindholm et al. 2001].
Method	Our approach is to start with an artist’s SSD approximation of the character in question, as well as with geometry corresponding to particular key poses not well approximated by SSD.
Method	Vertex displacements between a given pose and the SSD model are mapped back to the neutral character pose, providing a displacement field pose correction.
Method	Instead of storing these displacement fields for each key pose and then interpolating between them at runtime, as in Pose Space Deformation (PSD) [Lewis et al. 2000], we use Principal Component Analysis (PCA) to construct an error-optimal eigendisplacement basis for representing this potentially large set of pose corrections.
Method	However, we do not simply use PCA on the displacement field defined over the entire surface, since this would lead to a large number of important basis functions and be inefficient for hardware rendering.
Method	Instead, we decompose the model into locally supported domains learned from the influence of individual joints on the displacement fields (described in detail in Section 2.2).
Result	The resulting memory sensitive set of locally supported eigendisplacement basis functions constitutes the EigenSkin approximation, and is well suited to rendering in graphics hardware.
Method	Although the process is shown for displacements, it applies similarly to the construction of linear normal corrections, allowing EigenSkin to correct SSD for both shape and shading.
Method	We compute our SSD bone weights as a function of vertex bone distances in the neutral pose.
Method	This yields reasonable bone weights which change smoothly over the mesh.
Method	Filtering may be required to force each bone’s weights to zero at the edges of its influence to prevent discontinuities.
Future Work	In principle, the weights can be computed to optimize the quality of the EigenSkin correction, and this is a topic of future research.
Method	Let P be the set of indices of observed poses with 0 ∈ P representing the rest pose and let the observed vertex positions and bone transforms for pose p ∈ P be denoted as v p and T p , respectively.
Method	If the deformations vary smoothly over pose space, then interpolated displacements provide a good approximation of deformations at configurations between observations.
Method	To make our hardware implementation possible, we exploit the observation that localized changes to the configuration of an articulated character often result in local deformations.
Background	This independence occurs in most articulated characters, and certainly exists in realistic human hands.
Background	Bending a single joint in one finger, though difficult without bending any other joints, does not cause noticeable deformations in the other fingers.
Method	Likewise, bending one finger of our finite element hand model does not cause noticeable deformations in the others (see Figure 4 ).
Method	Although the finite element model deformations resulting from a change to a single joint are global, the displacement magnitudes are imperceptible at vertices that are far from the joint.
Method	We refer to the set of vertices significantly affected by a joint motion as the joint support.
Method	Note that the joint supports depend on the SSD weights and in general they do not correspond to the sets of vertices influenced by bone transforms.
Method	To find the support of a joint we compute the deformations that result from moving the joint to different positions in its full range of motion while keeping all other joints fixed to the rest pose position.
Method	The set of vertices having a displacement larger than a given threshold in any of these computed poses then becomes the support of this joint.
Method	For example, in our case we used four percent of the maximum observed displacement (we will see that memory constraints also play a large part).
Method	Note that we consider only single joint perturbations due to the high dimensionality of our hand model’s configuration space.
Method	Nevertheless, we can still approximate linear coupling effects since we let the joint supports overlap.
Method	For notational convenience, suppose the articulated figure has a tree structure, i.e., does not have loops, such as for humanoids, and joints are denoted by the index of the adjacent bone furthest from the root of the hierarchy.
Method	Denoting 0 ∈ B as the root, joints have nonzero index.
Method	Let P j ⊂ P be the set of pose indices used to compute the support for joint j and let S j be the set of vertex indices in the joint support.
Method	Furthermore, let J i be the set of joints whose supports contain vertex i.
Method	That is, J i = { j|i ∈ S j } ⊂ B\{0}.
Background	Although the pose displacements computed for independently perturbed joints may be used as a basis for describing displacements of new configurations, significant redundancy exists in the pose displacements, e.g., skin bulging in similar directions.
Method	Principal Component Analysis (PCA) of joint support displacements yields an orthogonal displacement basis, which we term eigendisplacements.
Method	As guaranteed by PCA, adding successive corrections with the eigendisplacement basis provides approximations which are better in a formal, least squares, sense [Golub and van Loan 1996].
Method	Computing principal components with the Euclidean norm is equivalent to computing the singular value decomposition (in the case of a square symmetric matrix it is equivalent to eigenanalysis).
Method	For each joint j we construct a rectangular matrix, A j , of size 3|S j | × |P j |, whose columns consist of the x,y, and z components of the vertex displacements on the joint support.
Method	In the singular value decomposition, A j = U j D j V T j , the matrix U j has the same size as A j and consists of columns of eigendisplacements for support j in the same block column format that was used to build A j .
Method	The singular values, in the diagonal matrix D j , identify the importance that each eigendisplacement has in reproducing the observed poses (they relate to the proportion of variation explained by each principal component).
Method	Note that the matrix V j and the singular values combine to gives the coordinates of our observed displacements in the eigendisplacement basis.
Method	We denote u ˆ jk the eigendisplacement i of vertex i in the basis of support j with importance k where k goes from 1 (the principal component) up to |P j |.
Method	At this point we can truncate each eigendisplacement basis expansion knowing that the error will be minimized in the least squares sense.
Method	The hardware limits the size of each truncated basis set as there is a limited amount of per vertex data memory in which we can send the eigendisplacements to the EigenSkin vertex program (see Section 2.5).
Method	Letting n j < |P j | be the size of the truncated basis set of joint support j, this constraint can be written as max n j |J i | ≤ maximum possible displacements.
Method	i Instead of choosing each n j individually, we take an equal number of eigendisplacements from each support.
Method	These coordinates are computed to interpolate between observed displacements, as shown below.
Method	Note that Equation 2 provides a powerful model for shape deformation (see, in particular, [James and Pai 2002a]).
Method	As an articulated character moves between observed configurations, its shape should interpolate the observed poses.
Method	To do this we interpolate the eigendisplacement coordinates of the observed configurations.
Method	For the truncated set of eigendisplacements at each support, we need the coordinates in the truncated basis which give displacements closest to the observed displacements.
Method	Conveniently, the least squares solution for any number of eigendisplacements, n j , is available from the singular value decomposition computed in Section 2.3.
Method	This leads us to the problem of computing the eigendisplacement coordinates for arbitrary configurations.
Background	Radial basis functions [Powell 1987] (RBF) are a common choice for interpolating scattered data, and have been used by Lewis et al. [Lewis et al. 2000] for pose space deformation and by Sloan et al. [Sloan et al. 2001] for shape interpolation with articulated figures.
Method	Our interpolation is one dimensional since all our observations involved perturbations of individual joints.
Method	Although we could use a simpler interpolant, we also choose RBFs because they extend easily to the higher dimensional domains needed to let EigenSkin capture nonlinear multi-joint coupling effects (a subject of future work).
Method	We use Gaussian interpolation shape functions, φ (r) = exp(−r/r 0 ).
Method	In our one dimensional case, the α jk only depend on the distance of joint j from its settings in poses P j .
Method	For revolute joints, we can easily compute the distance, r, by comparing the joint angles directly.
Method	For joints with more than one rotational degree of freedom, we compute distance as the angle in the axis-angle representation of the joint’s rotation matrix.
Method	Ideally, with a large number of observed joint perturbations per support we would interpolate using fewer interpolation basis functions ( φ ) than observations.
Method	In the case of our hand model, however, we only have approximately half a dozen pose perturbations for each joint degree of freedom (for a total of approximately 120 poses).
Method	This justifies our use of interpolation basis functions since the total cost of constructing and evaluating the RBF interpolant for half a dozen poses is negligible.
Background	Modern vertex programming hardware (e.g., [Lindholm et al. 2001]) is ideally suited to performing the per-vertex weighted linear superposition of eigendisplacements (contained in the large brackets of Equation 2) performed prior to the SSD weighted transformation.
Background	Depending on the number of eigendisplacements used, the weighted eigendisplacement vector accumulations are about as costly as the weighted transform matrix-vector multiplyaccumulate operations.
Background	Current vertex programs limit per vertex data to 16 4-tuples of floats.
Method	In our implementation we impose a limit of 10 eigendisplacements per vertex (or 5 eigendisplacements and 5 normal corrections), which still leaves room for texture coordinates after specifying the vertex position, normal, colour, and bone weights.
Method	Notice that this limit is not hard since careful choices and packing of per vertex data permit more than 10 of the 16 available tuples to be allocated for EigenSkin data.
Method	If a vertex is in many supports then the number of eigendisplacements renderable by current hardware may be too severely restricted.
Method	In this case it is useful to smoothly mask the support groups to smaller regions, otherwise fewer eigendisplacements must be used.
Method	To illustrate our EigenSkin method, we have constructed a finite element model of the human hand (see Figure 6 ) which exhibits subtle nonlinear skin deformations.
Method	The surface skin model and matching skeleton are based on Loop subdivision [Loop 1987] of a hand mesh exported from Curious Labs Poser [Curious Labs Inc.
Method	A finite element mesh containing 11,171 high-order 10-node tetrahedral elements was generated using NETGEN [Schoberl 1997] (and subsequent simplification).
Method	The hand was moved into various poses by applying position constraints to vertices adjacent to the rigid bones, and computing the resulting tissue deformation using geometrically nonlinear static finite element analyses [Zienkiewicz 1977] with (a modified version of) the CalculiX program [Dhondt and Wittig].
Method	Approximately half a dozen poses were computed for each joint degree of freedom to estimate the locally supported joint eigendisplacements, and 25 additional poses were computed for validation.
Method	Finite element analyses were performed on a cluster of modern workstations and consumed several hundred CPU hours.
Result	Despite these limitations, the model reasonably describes bulk tissue deformations and was sufficient to illustrate our method.
Result	As shown in Figure 7 , the eigendisplacement approximations of the hand model produce a clear improvement over the traditional SSD algorithm.
Result	Even with only five leading eigendisplacements, the EigenSkin approximation is essentially indistinguishable from the original FEM model.
Method	Our interactive simulation uses a CyberGlove [Immersion Corporation] input device to interactively drive our EigenSkin hand model, while graphical feedback is rendered using OpenGL and a GeForce3 graphics card.
Method	Radial basis function interpolation of the pose-space data is performed on the main CPU, with eigendisplacement amplitudes and bone transforms set as input parameters to the EigenSkin vertex programs which are compiled as static display lists.
Result	Currently, our unoptimized implementation renders the EigenSkinned hand model only slightly slower than the traditional SSD model.
Result	A large 55,904 triangle hand model renders at 47 frames per second (FPS), while a coarser 13,976 triangle model achieves 181 FPS.
Result	Our results confirm that the EigenSkin method is an effective tool for character skinning when compressed hardware renderable approximations are required for an articulated character’s nonlinear quasi-static deformations.
Result	EigenSkin works best when SSD corrections are localized, providing independence between different parts of the mesh, and are stable (i.e., corrections vary slowly over posespace), allowing accurate and efficient interpolation.
Result	We assume that an initial SSD model is provided and then show how the EigenSkin corrections are beneficial.
Future Work	However, an alternate approach involves optimizing bone weights to allow better EigenSkin approximations of the displacements and normals.
Future Work	While good eigendisplacement bases can often be constructed using displacements resulting from single joint motions, in practice it is desirable to allow general pose sets and to recover nonlinear joint-joint coupling phenomena.

Result	A data-driven approach for real-time processing of clothes, particularly suitable for simulating dresses worn by virtual characters, is proposed.
Method	It starts, prior to realtime simulation, by analyzing cloth behavior in relation to the underlying skeleton movement from a pre-simulated sequence of the cloth obtained using any high quality offline simulators.
Problem	The idea is to use this analysis to find an optimal combination of physics-based simulation and geometric approximation of the simulator; potentially colliding regions are defined on the cloth such that they will hold true for the skeleton movement that closely matches that of pre-simulated sequence.
Result	At runtime, using these analyses, our simulation process provides both visually pleasing results and performance, as long as the motion of the character remains sufficiently close to the original sequence used for the pre-computation.
Result	The key contributions of this paper are (1) efficient collision handling that prunes out potentially colliding objects by using the off-line simulation sequence as examples; (2) data-driven fix-up process for the coarse mesh simulation that deduces the gross behavior of the cloth; and (3) geometric approximation of the fine mesh deformation, responsible for details in the shape of the cloth such as wrinkles.
Background	The problem of simulating the behavior of clothes is one subject the graphics community has been grappling with since almost two decades ago [19] [21].
Problem	Relatively little emphasis has been placed on the separate problem of how to achieve real-time performance in simulating cloth.
Background	A number of strategies have been suggested, such as using simplifying assumptions for the physics model and/or collision detection [ 7 ] [12].
Background	A recent work by James et al. [10] suggests a different approach by adopting a data-driven method.
Background	These techniques do not suffice, however, when simulating fully dressed virtual characters in real-time, leaving the topic unexplored.
Result	We present a data-driven method for simulating clothes worn by 3D characters in real-time.
Method	To effectively optimize the physics-based deformation, which is the bottleneck of the simulation, we use a coarse representation of the cloth mesh to drive the gross behavior in simulation.
Problem	We consider that the gross cloth behavior is driven mainly by two separable contributions: the skeleton-driven movement of the character and the mechanical properties of the cloth.
Background	This consideration was partly inspired by the hybrid real-time simulation method proposed in Cordier et al. [ 5 ], where a hybrid deformation method is used to combine dynamic surfaces with Skeleton-Driven Deformation (SDD).
Result	Unlike that method, however, our method exhibits significantly more efficient and realistic behavior.
Method	This effect is achieved by focusing on the analysis of cloth movements in relation to its associated skin surface, and adopting a learning strategy.
Method	The idea is to use the analysis of the presimulated sequence to identify the region largely explained by joint movement and to replace the physics based simulation with geometric methods wherever possible.
Method	Second, we use the pre-simulated sequence to approximate the dynamic behavior of the coarse mesh geometrically wherever possible.
Method	Finally, fine details such as wrinkles are also simulated in a data-driven manner, by using the pre-simulated cloth sequence as examples.
Result	Subsequently, real-time animation of fully dressed human could be generated, which would be suitable for applications such as games where visual plausibility is more important than accuracy.
Background	Probably the most common technique for simulating the physical properties of clothes is the particle system.
Background	Simulation process is broken down into calculating the internal forces and solving the system of Partial Differential Equations (PDE).
Background	The latter point has attracted much interest in the field of real-time applications, since it requires high computation power.
Background	The explicit Euler method [ 2 ] has been one of the first numerical solvers.
Background	Unfortunately, this method is notorious for its instability when using large time steps and stiff equations.
Background	Several improvements have been proposed to reduce instability, such as the Verlet integration [11] and the explicit Euler combined with inverse dynamics [17] [20].
Background	Unfortunately, the simulation quality is sacrificed in favor of computation speed, due to the approximations employed in these models.
Background	The implicit Euler method presented by Baraff et al. [ 2 ] performs the computation not by using the derivative at the current time, but the predicted derivative at the next time step.
Background	Unlike explicit Euler integration, the implicit Euler method offers higher stability while using large time-steps and clothes with stiff mechanical properties.
Background	Desbrun et al [ 7 ] proposed solving the linear system with a precomputed inverse matrix.
Background	Kang et al. [12] proposed further optimization with a direct update formula for the positions and velocities of the cloth vertices.
Background	As indicated by the authors, these methods are not intended to provide a physically-correct cloth animation.
Method	Our approach to that problem is a data-driven mass-spring system: the simulation is corrected with a set of functions built from the pre-simulated animation.
Method	By doing so, we bring the deformation of the mass-spring system closer to the original cloth behavior.
Background	Another approach to fast garment deformations is the hybrid approach.
Background	They aim for a neat combination of physically based deformation and geometric deformation.
Background	Cordier et al. [ 5 ] proposed to segment the cloth into pieces and simulate these by different algorithms, depending on how they lie on the body surface and whether they adhere to it or flow over it.
Background	Others have noted that wrinkle deformation is geometric in nature and therefore can be computed with a geometric method.
Background	Wrinkles can be generated either by tessellating the cloth mesh [12] or rendering details on texture using bump mapping [9].
Problem	The main difficulty is defining a fold function that can simulate all kinds of wrinkle patterns.
Problem	Moreover, determining the location and shape of wrinkles is left to CG artists.
Result	One of our contributions is a geometric wrinkling method that is “trained” by using a pre-simulated cloth sequence, rather than relying on users.
Problem	Collision detection is usually one of the bottlenecks in real-time animation.
Problem	The problem is particularly acute in the case of clothes because these objects are highly deformable.
Background	Several algorithms have been proposed to process robustly collisions in cloth simulation [21] [22] without reaching real-time performance.
Background	Some other methods exploit graphics hardware to compute collisions on bump maps [20]; others use implicit surfaces to check collisions on the body [18], or voxel trees, which partition the space hierarchically [14].
Background	Using frame coherency to reduce computation cost has been explored by Zhang et al [23].
Method	In this work, we propose a data-driven collision detection method; we use the pre-simulated sequence to localize the collision checks to neighboring cloth regions that have high probability to collide.
Background	The idea of building an interpolator from examples or pre-simulated data has proven to be a valuable tool in a variety of areas of CG, e.g. for modeling a variety of human body shapes and for motion synthesis.
Background	The basic idea is to build an interpolation space filled with a set of pairs of input parameters and the targeted graphical objects.
Problem	Cloth animation depends on a high number of parameters and therefore a data-driven approach is difficult to adapt.
Background	Very recently, James et al. [10] resented such an approach, where physics-based deformation and collision detection are both handled in a unified framework.
Background	By blending of pre-computed orbits rather than using a mass-spring system, previous unseen results could be achieved, such as garments with stiff mechanical properties in real-time.
Background	However, they show little degrees of freedom (DoF) to the clothes under simulation; Instead of resorting to a data-driven approach for the entire simulation, we seek a neat combination of a data-driven approach with the mass-spring system.
Result	Unlike previous works, our simulator allows a much higher degree of interaction, as it is often needed in animating clothes on moving characters.
Background	The history of research on real-time cloth is relatively recent.
Background	Researchers have concentrated mainly on two aspects of real-time cloth animation: simulating the physical properties of garments and collision handling.
Problem	The primary focus of this paper is the development of a fast cloth simulator for real-time applications.
Problem	Dynamic simulation of complex deformable models, however, can easily involve thousands of degrees of freedom.
Problem	For example, a physics-based simulator would require several minutes to compute one frame of a cloth model worn by a character.
Problem	Simulating large models directly would therefore be computationally impractical.
Method	Our simulator is based on two levels of deformation: the first deduces the gross cloth behavior by working on a coarse mesh with a physics-based approach whereas the second generates wrinkles on a fine mesh with a geometric method.
Method	The coarse mesh is generated by simplifying the original cloth mesh through segmentation.
Method	The reason for this choice is to lower the computation time; geometric methods are in general much faster than physically-based ones [9].
Problem	When observing the behavior of garment worn by a character, there are considerable correlations between the body motion and the movement of the garment.
Problem	These correlations are especially clear for some clothes like tight shirts and trousers.
Method	In our method we take advantage of these relationships to reduce the computation load on the mass-spring system and collision detection.
Method	We first construct the cloth-to-joint relation by analyzing a presimulated sequence of the cloth to be animated.
Method	We then reduce the number of vertices to be physically simulated by identifying the garment regions in which the shape follows that of the underlying skin.
Method	The cloth-to-joint relation enables us also to optimize collision detection by restricting the collision check to a small area around each vertex of the coarse mesh.
Method	Finally, we use the cloth shape of a pre-simulated cloth sequence to correct the physicsbased simulation of the coarse mesh in order to match the original cloth behavior more closely.
Method	The pre-processing stage involves generating the coarse mesh, computing the cloth-to-joint relation, and constructing the collision hulls and the interpolation functions for data-driven coarse mesh deformation and wrinkle animation.
Method	Collisions are handled by collision hulls the position of which is computed by our SDD.
Method	The final mesh is then obtained using the winkle shape interpolator and the computed geometry of the coarse mesh.
Background	The skeleton-driven deformation (SDD), a classical method for the basic skin deformation is perhaps the most widely used technique in 3D character animation.
Background	This method works first by assigning a set of joints with weights to each vertex in the character.
Background	The location of a vertex is then calculated by a weighted combination of the transformation of the influencing joints.
Method	Although developing a new SDD method is not our main goal, the way the skin deforms is important in our framework since natural looking cloth shape also requires natural skin shape.
Method	There are two requirements which the method should fulfill for this particular use: first, it must overcome the undesirable effect of vertex collapse as shown in Figure 3(a) .
Method	Second, the method must provide an easy way to compute the local coordinate system for each skin vertex.
Method	This is necessary as we want to compute the deformation of the cloth surface in relation to the skin surface.
Method	We found that the classical SDD can be greatly improved by replacing the linear combination of the matrices by the matrix operator defined by Alexa [ 1 ].
Method	Note that the operator is not continuous.
Method	It is not defined for a rotation of 2π radians between the matrices to be blended.
Method	In practice, such case is rare; in general, the largest angle range does not exceed π radians.
Method	Due to the computational expenses of solving the full numerical system of the physics-based deformation, we seek simplifications by constructing a coarse mesh representation of the garment.
Method	The coarse mesh is used to deduce the gross behavior of the cloth in a data-driven manner, based on the input pre-simulated sequence.
Method	We begin by constructing a coarse representation of the given cloth model that will drive the gross behavior of the simulated garment.
Method	(2) A coarse mesh representation is obtained by combining a set of vertices in a patch into a single mass point located at the center.
Method	The generation of a patch starts by finding a vertex that has not yet been attributed to a patch that is already generated.
Method	The patch is then grown by adding neighboring vertices one after the other.
Method	To select a new vertex into the current patch, we evaluate each neighboring vertex that has not been already assigned to a patch, using a penalty function.
Method	To enforce the regularity of coarse mesh, which is one condition for obtaining efficient deformation with the mass-spring system [21], we consider two following components.
Method	• Minimizing the "shape factor": Square Root (Surface Area)/Contour Length.
Method	The objective is to obtain "well-shaped patches", patches that have a circular shape.
Method	This component gives a cost that increases with the surface area of the patch.
Method	By modifying the significance of this component, we can easily control the number of vertices to be simulated with the physically-based deformation (see Figure 4 ).
Method	The vertex with the lowest cost is selected.
Method	When the lowest cost exceeds a threshold, the construction of the patch is completed.
Method	We proceed until no vertices can be found to start a new patch.
Method	Deciding a good granularity in the coarse mesh is hand-tuned, so that a neat compromise between the simulation quality and the computation load is found.
Method	We have found that best simulations are obtained when patch area covers one or two cloth wrinkles.
Method	Note that that each patch is associated with a vertex on the coarse mesh.
Method	We denote the vector position of a vertex P as XP, and the vector position of its neighbors as X N R 3n (n: number of neighbors of P).
Method	Next we carry out cloth-to-skin (or body) attachment through skin fitting, by which the skinning data on the cloth mesh are approximated in such a way that the skinning-driven cloth shape best fits the simulated cloth shape throughout the whole pre-simulated sequence.
Method	The basic idea is to use the pre-simulated results as examples and find the error-minimizing skin data through optimization.
Method	An optimization approach, such as the one presented by Mohr et al [15], could be adopted here.
Method	In our case, however, our SDD method is non-linear and therefore the linear regression as adopted by Mohr et al is not beneficial.
Method	Function minimization techniques such as Powell’s method [16] can deal with non-linear functions.
Background	Performance is slightly slower, but only pre-processing performance is affected and not runtime performance.
Method	Notably, the floating regions (colored in red in Figure 5(d) ) are attached to the root of the character, as shown in Figure 5(b) ; this is contributable to the fact that these regions are large in volume and they rarely collide with limbs during the walk motion.
Result	The residual values of the fitting provide useful information on how the garments behave in relation to the body.
Method	Intuitively, floating garments such as a skirt, cloth patches may collide with several joints; collisions need to be computed on these regions.
Method	On the other hand, the local movements of some cloth patches (like underwear) are negligible and these patches can be considered as being attached rigidly to the skeleton.
Method	In our approach, three regions are identified from the residual values of the skin fitting process ( Figure 5(d) ): those that potentially interact with several joints, those that are loosely attached to the skeleton and those that are rigidly attached to the skeleton.
Method	The threshold values are chosen in a way that the coarse mesh deformation remains sufficiently close to the pre-simulated sequence.
Method	For example, a false assignment of loose region into tight region would produce elongated deformations instead of slipping garment over the skin, and therefore generate an overly deformed coarse mesh, which is beyond the training data of the wrinkle generator.
Method	Similarly, a false assignment of region 3 into region 2 would result in the garment crossing the legs.
Method	In practice, values of 0.5 cm and 4.0 cm are used to identify tight regions and floating regions, respectively.
Method	The deformation of tight regions is directly computed with the SDD (line 2 and 6 on Figure 6 ).
Method	The use of SDD for these regions makes it possible to reduce the number of mass points even further.
Method	Therefore, an additional collision check is required to handle the interaction of the clothes with the whole body skeleton.
Method	A list of potentially colliding body patches is defined by selecting those that approach within a certain distance of the floating regions during the pre-simulated cloth sequence.
Method	Apart from the position, our SDD computes the local transformation matrix of the vertices, the simulator to be optimized at least for the two following points: limiting collision checks to a small area around the vertices, and the geometric wrinkling which is processed in the SDD local coordinate system.
Method	At each frame of the simulation, we compute the coarse mesh by a mass-spring system with the implicit Euler numerical solver [ 2 ].
Method	The simulation run on the coarse mesh hardly reproduces the gross movement of the original cloth because the initial mesh has been significantly simplified (from 4000 to a few dozen vertices) and the topology has been modified.
Method	Moreover, unlike the simulator used for the pre-simulated cloth sequence, the simplified mass-spring model does not accurately simulate the bending and shearing properties of the fabrics [21].
Method	We approach the problem by modifying the behavior of the mass-spring system through a fix-up process (similar to [14]) where the position and velocity of the coarse mesh vertices are modified in order to maintain the cloth shape as close as possible to the original one ( Figure 7 ).
Method	Ideally, the local shape (e.g. position of the vertices in relation to their neighbors) should be a blend of those of the pre-simulated animation.
Method	This is achieved by constructing a set of functions of local shape deformation.
Method	Post-correction is accomplished with a function that evaluates the "ideal" position of the vertex given the position of its neighbors connected by the edges.
Method	For each vertex, we construct an interpolating function F Post by using a set of (X N,Pre-simulated , X P,Pre-simulated ) pairs extracted from each frame of the pre-simulated sequence, where X N ∈R 3 (n: number of neighbors of P) denotes the position of the neighbors and X N ∈R 3n the position of the vertex in question.
Method	Given a position of neighbors X N,Input as input, the interpolation computes the corresponding X P by a weighted summation of the X P,pre-simulated values, each weight being computed from the Euclidian distance between X N,Input and all the X N,Presimulated values.
Result	The computation cost of this interpolator grows as the number of pre-simulated frames increases.
Method	We wish to keep the computation cost constant regardless of the duration of the pre-simulated sequence.
Method	A common solution is to construct a lookup table filled with values pre-simulated by the interpolator on grid sampling.
Method	In order to reduce the memory usage of the lookup table, the dimension of XN,Pre-simulated was reduced prior to the construction of the interpolator, by Principal Component Analysis [16].
Method	The first three principal components, which describe 95 % of the average variability of the data, are used.
Method	The positions of the vertices are corrected after every simulation loop.
Method	The velocity is updated as well.
Method	Its new value is set to the sum of the original velocity and the velocity due to the modification of the vertex position (line 11 on Figure 9 ).
Method	To prune unnecessary collision tests, we pre-compute what we term “collision hulls” that exploit the skin-tocloth relation obtained from the pre-simulated sequence.
Method	These are built once at the beginning of the simulation (prior to the runtime simulation) after the SDD has been computed on the coarse mesh, using the pre-simulated sequence.
Method	At each pre-simulated frame, we calculate the difference between the SDD motion model and the presimulated cloth model in the local coordinate system of the SDD.
Method	After a sweep, we get a set of points that cover the path a patch takes during the simulation.
Method	The smallest convex hull that contains all these points is generated for every patch using the “Quickhull” algorithm presented by Barber et al [ 3 ].
Method	Given enough variation and range of character motion, we expect these hulls to cover the allowable positions of corresponding cloth patches during the runtime simulation.
Method	By using collision hulls, collision tests are restricted to a small area around the patch; the overall computation can be significantly reduced in comparison to classical collision detection methods in which collisions are computed between the whole skin and cloth surface.
Method	Note that the collision hulls are generated for loose and floating garment regions only.
Method	The collision hulls of tight regions are small enough to be approximated by a single point.
Method	Collision handling at runtime consists of correcting the position of coarse mesh vertices after every simulation step so that they remain inside their respective hulls.
Method	We used constrained dynamics [22] to handle the collision response (i.e. modification of position and velocity in response to collision detection) at line 15.
Method	The real-time computation of global cloth movements is obtained with a mass-spring system together with the collision response and post-correction described above.
Problem	Again, the main challenge here is obtaining the highest possible realism while maintaining acceptable computation load, in order to meet the real-time requirements.
Background	As recognized in earlier works [9] [13], wrinkles can be efficiently animated with a geometric method as they are geometric in nature.
Method	Unlike previous methods, however, our wrinkling function is not hand-drawn, nor geometrically approximated, but rather trained from on the analysis of the pre-simulated sequence.
Method	In this work, we choose to represent the wrinkle displacement in the local coordinate system used for SDD.
Method	This makes our wrinkle parameterization invariant of all joints of higher hierarchy than the currently influencing joint.
Background	Several techniques exist for shape interpolation using examples, such as Radial Basis Functions or parametric interpolation.
Method	We have used linear interpolation in which coefficients are defined by multi-linear regression on the pre-simulated animation, since it provides satisfactory results at a very low computation cost.
Method	For every vertex x in a patch, the interpolator function takes the associated mass point in the coarse mesh, and its neighbors as input.
Method	The values α, α P and α N are the interpolation coefficients.
Method	They are defined by multi-linear regression on a set of pairs (positions of coarse mesh vertices, fine mesh vertices) extracted from the pre-simulated cloth sequence.
Method	X P and X N are respectively the position of the vertex x and its neighbors; they are all expressed in the SDD coordinate system of x.
Method	Despite its simplicity, linear interpolation works fairly well provided a sufficient number of pre-simulated frames for the multi-linear regression.
Method	A condition of a good working interpolator is that the input (i.e. position of the coarse mesh vertices) should be within the range of the pre-simulated data.
Method	In other word, the wrinkle interpolator can only work for the input range for which it has been trained.
Method	This condition is maintained thank to the data-driven post-correction (see Section 5.3).
Method	This also keeps the smoothness of the boundaries between patches.
Method	We measure and validate the proposed real-time cloth simulation method along three criteria: the variety of clothes to be simulated, the computation speed and the range of body motion in the pre-simulated cloth sequence.
Method	Pre-simulated sequences obtained by the cloth simulator of Volino et al [21] were used in our preprocessing.
Method	We used our framework to different types of clothes, as shown on the demonstration video.
Method	• The “evening” dress ( Figure 14 ) is chosen to demonstrate our wrinkle interpolator on large garment regions.
Method	• The “cocktail” dress ( Figure 18 ) is a relatively complex model; the bottom is composed of two layers of tissues and has folds made of large number of vertices, inducing many self collisions.
Method	• The “Jeans” outfit is a good example of a model where the SDD based geometric approximation can reduce the number of mass points substantially by simulating only a few regions that contribute significantly to the dynamic behavior.
Result	Our simulator behaves fairly well on a wide variety of clothes, including those with highly stiff mechanical properties.
Result	Moreover, performance will increase due to the fact that the smallest number of triangles will be processed for the real-time rendering.
Result	However, the method may introduce flaws in simulation for some tight clothes, due to the approximate handling of collision detection.
Result	For some body movements, the skin surface may slightly intersect the cloth surface.
Result	Similarly, the same problem may arise for self-collisions on clothes.
Method	The deletion of the skin triangles covered by the garment surface can partially correct this drawback.
Result	Note that the cloth simulation is also restricted to clothes worn on bodies.
Result	While offering high computation speed, the cloth simulator cannot handle some cloth movements such as those appearing during dressing or undressing.
Result	More generally, the clothes are unable to interact with objects other than those that have been taken into consideration during the pre-processing phase.
Method	The list of objects that can potentially interact with clothes and the way these objects interact are defined at the preprocessing stage and cannot be changed during the realtime simulation.
Future Work	Finding a method to update the list of possible interacting objects automatically could be a subject for future research.
Result	The pre-processing of all the cloth models took less than 10 minutes.
Result	All examples run in real-time at approximately 25 to 50 frames per second (fps), with the coarse mesh deformation process taking about 75 % of the total CPU time.
Result	As expected, the duration of the pre- simulated sequence is not a factor of the runtime computation speed.
Result	In practice, the performance lowers down at a low rate as the complexity of the collision hulls increases, which tends to be governed by the number of pre-simulated frames (see Section 5.3).
Result	As expected, the quality of the simulation depends on the number and variety of examples – the pre-simulated sequence in our case.
Method	To show that the simulator faithfully recreates the cloth movement used for training, we compared the real-time simulation with the presimulated one in the first video.
Result	The character walks at a normal pace without any fast movements.
Result	In the second video, different body movements from those of the training were supplied as input to our realtime simulator and the results are compared with the ones generated with a high quality simulator.
Result	To measure the simulation quality, we compared our simulation results with the pre-simulated sequence, using a deformation metric.
Result	It measures the still shape and movement by the sum of edge length difference and the mass velocity difference over the cloth mesh.
Result	The best quality is achieved when the range of the body motion in the presimulated sequence is approximately 30 % larger than the one used in the real-time simulation.
Result	Our simulator works well for interpolation (i.e. joint angles within the range of those of the pre-simulated sequence) but often fails for extrapolation.
Result	The main reason for this limitation is collision detection, which does not allow the clothes to have different locations on the body from those calculated in the pre-simulated sequence; this makes the clothes being attached rigidly to the skeleton.
Result	With less than 70 pre-simulated frames, the real-time simulation loses its quality.
Background	The recent advent of cloth simulation techniques has matured enough to produce highly realistic cloth movements on animated characters.
Problem	However, real-time simulation has been largely unexplored until now.
Result	This paper presents the first report of a practical and efficient method for handling real-time simulation almost automatically.
Result	We used our framework to produce visually pleasing motion of a wide range of clothes.
Method	Both the mass-spring system and collision detection have been rewritten to take advantage of the pre-simulated sequence of the clothes to be animated.
Result	Consequently, our cloth simulator is able to construct a model for real-time animation without user intervention and can deal with different types of clothes from tight to floating with low computation consumption.
Future Work	There are many interesting avenues for future work.
Future Work	First, the approach could be extended to simulating other physics-based models such as hair and fluid.
Future Work	We also believe that the work on collision hulls is promising.
Future Work	The current mesh model of collision hulls could be replaced by implicit surfaces or voxel maps.
Future Work	Therefore, for a cloth vertex, it could be possible to compute several collisions hulls in relation to different objects in the scene and to compute their intersection for real-time collision detection.
Future Work	By doing so, it may be possible to process collisions on a higher number of objects while maintaining low computation cost.
Future Work	We also believe that the precision of the collision detection could be improved by replacing the convex shape by a surface to follows more closely the trajectories of the vertices.

Problem	An ambitious goal in the area of physics-based computer animation is the creation of virtual actors that autonomously synthesize realistic human motions and possess a broad repertoire of lifelike motor skills.
Problem	To this end, the control of dynamic, anthropomorphic figures subject to gravity and contact forces remains a difficult open problem.
Problem	We propose a framework for composing controllers in order to enhance the motor abilities of such figures.
Result	A key contribution of our composition framework is an explicit model of the “pre-conditions” under which motor controllers are expected to function properly.
Method	We demonstrate controller composition with pre-conditions determined not only manually, but also automatically based on Support Vector Machine (SVM) learning theory.
Method	We evaluate our composition framework using a family of controllers capable of synthesizing basic actions such as balance, protective stepping when balance is disturbed, protective arm reactions when falling, and multiple ways of standing up after a fall.
Result	We furthermore demonstrate these basic controllers working in conjunction with more dynamic motor skills within a prototype virtual stuntperson.
Result	Our composition framework promises to enable the community of physics-based animation practitioners to easily exchange motor controllers and integrate them into dynamic characters.
Problem	Despite the considerable history of progress in animating virtual humans [ 3 , 7 ], physics-based animated characters with a large repertoire of motor skills have so far been elusive.
Background	This may seem surprising in view of the recent successes in implementing a slew of specialist controllers capable of realistically synthesizing the complex dynamics of running, diving, and various gymnastic maneuvers [ 16 ].
Background	While a divide-and-conquer strategy is clearly prudent in coping with the enormous variety of controlled motions that humans and other animals may perform, little effort has been directed at how the resulting control solutions may be integrated to yield composite controllers with significantly broader functionalities.
Problem	For example, if researcher A creates a walking controller for a dynamic character while researcher B creates a running controller for the same articulated model, it would be beneficial if they could share their controllers (perhaps through an e-mail exchange) and easily create a composite controller enabling the character to both walk and run.
Problem	This is a difficult problem, but its resolution would help pave the way towards controller libraries for dynamic animation which communities of practitioners could utilize and to which they could contribute.
Problem	In this paper, we propose a simple yet effective framework for composing specialist controllers into more general and capable control systems for dynamic characters.
Method	In our framework, individual controllers are black boxes encapsulating control knowledge that is possibly gleaned from the biomechanics literature, derived from the robotics control literature, or developed specifically for animation control.
Method	Individual controllers must be able to determine two things: (1) a controller should be able to determine whether or not it can take the dynamic character from its current state to some desired goal state, and (2) an active controller should be able to determine whether it is operating nominally, whether it has succeeded, or whether it has failed.
Method	Any controller that can answer these queries may be added to a pool of controllers managed by a supervisor controller whose goal is to resolve more complex control tasks.
Result	An important technical contribution within our controller composition framework is an explicit model of pre-conditions.
Method	Preconditions characterize those regions of the dynamic figure’s state space within which an individual controller is able to successfully carry out its mission.
Method	Initially, we demonstrate the successful composition of controllers based on manually determined pre-conditions.
Method	We then proceed to investigate the question of whether pre-conditions can be determined automatically.
Method	We devise a promising solution which employs Support Vector Machine (SVM) learning theory.
Method	Our novel application of this technique learns appropriate pre-conditions through the repeated sampling of individual controller behavior in operation.
Method	As a testbed of our techniques, we are developing a physicallysimulated animated character capable of a large repertoire of motor skills.
Result	An obvious application of such a character is the creation of a virtual stuntperson: the dynamic nature of typical stunts makes them dangerous to perform, but also makes them an attractive candidate for the use of physics-based animation.
Problem	The open challenge here lies in developing appropriate control strategies for specific actions and ways of integrating them into a coherent whole.
Problem	In this paper, we demonstrate families of composable controllers for articulated skeletons whose physical parameters reflect anthropometric data consistent with a fully-fleshed adult male.
Method	One family of controllers is for a 37 degree-of-freedom (DOF) 3D articulated skeleton, while a second family of controllers has been developed for a comparable 16 DOF 2D articulated skeleton.
Method	While the 3D skeleton illustrates the ultimate promise of the technique, the easier control associated with the 2D skeleton allows for more rapid prototyping of larger families of controllers and more careful analysis of their operation.
Problem	As has been recognized in the robotics literature, the control of broad skilled repertoires of motion remains very much an open problem even for 2D articulated figures.
Result	The upright balancing dynamic figure is pushed backwards by an external force; its arms react protectively to cushion the impact with the ground; the figure comes to rest in a supine position; it rolls over to a prone position, pushes itself up on all fours, and rises to its feet; finally it balances upright once again.
Result	A subsequent disturbance will elicit similar though by no means identical autonomous behavior, because the initial conditions and external forces will usually not be exactly the same.
Result	Control sequences of such intricacy for fully dynamic articulated figures are unprecedented in the physics-based animation literature.
Problem	The simulation and animation of human characters is a challenging problem in many respects.
Problem	Comprehensive solutions must aspire to distill and integrate knowledge from biomechanics, robotics, control, and animation.
Problem	Models for human motion must also meet a particularly high standard, given our familiarity with what the results should look like.
Problem	Not surprisingly, a divide-and-conquer strategy is evident in most approaches, focusing efforts on reproducing particular motions in order to yield a tractable problem and to allow for comparative analysis.
Background	The biomechanics literature is a useful source of predictive models for specific motions, typically based on experimental data supplemented by careful analysis.
Background	These models target applications such as medical diagnosis, the understanding and treatment of motor control problems, the analysis of accidents and disabilities, and high-performance athletics.
Background	Computer simulation is becoming an increasingly useful tool in this domain as the motion models evolve to become more complex and comprehensive [ 26 , 27 , 29 ].
Background	Given the challenge of achieving high-fidelity motion models for individual motions, there have been fewer efforts towards integrated solutions applicable to multiple motions.
Background	Reference [ 26 ] is one such example.
Background	Robotics research has made remarkable progress in the successful design of a variety of legged robots [ 28 ] and, more recently, bipedal robots with anthropomorphic aspirations [ 23 ].
Background	Despite their limited motion repertoires and rather deliberate movements, these robotic systems are truly engineering marvels.
Background	The work in [ 1 ] provides a good summary of behavioral architectures explored in the context of robotics.
Background	A 3 DOF ball-juggling robot is described in [ 6 ] which uses a theory of behavior composition, although the practicality of extending the method to high-DOF dynamic models of human motions is unclear.
Background	Computer animation is to a large extent unencumbered by the exacting fidelity requirements of biomechanical models and the mechanical limitations of robotic systems.
Background	This has spawned a great variety of kinematic and dynamic models for character motion [ 3 , 4 , 7 ].
Background	While motion capture solutions based on blending and warping techniques may give satisfactory results for such tasks in the short term, controller based approaches reveal more about the physics, planning, and control of such motions and they therefore serve as a basis for more general solutions.
Background	Dynamically simulated characters were first proposed over 15 years ago [ 2 , 34 ] and since then have progressed in sophistication in a variety of directions.
Background	Controllers have been successfully designed for specific human motions such as walking, running, vaulting, cycling, etc. [ 16 , 22 , 35 ].
Problem	Dynamically simulated articulated characters equipped with an integrated, wide-ranging repertoire of motor skills currently remain an unachieved goal.
Background	Some positive steps in this direction are evident, however.
Background	Examples include an integrated repertoire of motor controllers for biomechanically animated fish [ 30 ], a methodology for controller design and integration applicable to simple figures [ 32 ], a demonstration of successful integration for selected diving and gymnastic motions [ 35 ], and adapting a controller designed for one character to work on another character [ 17 ].
Background	The work of Wooten [ 35 ] is the most relevant as an example of a sequence of successive transitions between several controllers for human motions such as leaping, tumbling, landing, and balancing.
Background	Transitions are realized by including the end state of some controllers in the starting states of other controllers.
Background	This currently remains ambitious work in progress.
Problem	Our work is aimed at creating dynamic human characters with broadly integrated action repertoires.
Method	Unlike previous work focusing on specific athletic movements, our methodology is to begin with a core set of simple actions, including balancing, small steps, falling reactions, recovery from falls, standing up from a chair, and others.
Method	In the present paper, we do not cover in any appreciable detail the design of individual controllers to effect such basic actions.
Result	1 Rather, our contribution here is a framework for composing individual controllers, however they may be designed, into more capable control systems for dynamic characters.
Result	Our pre-condition learning algorithm adds to the growing body of learning algorithms that have been successfully applied in the context of computer animation in recent years [ 14 , 15 ].
Method	In our controller composition framework, we consider individual controllers as black boxes which are managed by a simple supervisor controller.
Method	When no controller is active, the supervisor polls the pool of controllers, querying each whether it can handle the transition of the dynamic character from its current state to the desired goal state.
Method	Individual controllers return an integer confidence/suitability score when queried in order to bid on becoming the active controller.
Method	In our implementation, controllers that can perform a sensible action given the current state of the character return an integer in the range 1⁄2 1⁄21⁄4 , while those that can handle the current state as well as guarantee a transition to the desired state, return an integer in the range 1⁄21⁄4 3⁄41⁄4 .
Method	Lastly, a value of 1⁄4 means that a controller is unsuited for the current state.
Method	The controller that returns the highest score becomes active.
Method	While this scoring scheme potentially allows for a nuanced evaluation of the controller suitability in terms of criteria such as probability of success or energy used, our current controllers resort to a simpler scheme.
Method	This consists of a binary success/failure evaluation multiplied by a weighting factor assigned to each controller that serves to establish a relative preference ordering.
Method	It does not appreciably burden the controller design task.
Method	Each controller can be as primitive or as sophisticated as its designer wishes.
Method	A controller within the pool of available controllers can be as simple as a constant force, or as complex as a structured hierarchy of multiple levels of control abstraction.
Method	For example, as more controllers are added to the system, we may wish to group all the walking and running controllers together into a cluster that can be treated as one encapsulated controller.
Method	Regardless of the encapsulation, our composition method requires controllers to define pre-conditions, post-conditions and expected performance.
Method	Pre-conditions are a set of conditions over the state of the character and the environment.
Method	If these conditions are met then the controller can operate and possibly enable the character to satisfy the post-conditions.
Method	Assuming that the pre-conditions were met, the post-conditions define a range of states for the final state of the character after the execution of the controller.
Method	In other words the controller realizes a mapping between a domain of input states to a range of output states for the character.
Method	Because of unexpected changes in the environment, this mapping may not always succeed, which motivates the notion of expected performance.
Method	The controller should be able to evaluate its performance in order to detect failure at any point during its operation.
Method	To do this, the controller must at all times have knowledge of the current and expected state of the character or the environment.
Method	Defining the pre-conditions, post-conditions, and expected performance for complex characters, motions, and environments is not a straightforward task.
Method	However, we believe that the effort required to generate these specifications is a fair and necessary price to pay to achieve the benefits of composability.
Method	Controllers that adhere to these specifications can form a pool of available controllers managed by the supervising controller.
Method	The position and velocity of the center of mass are denoted as and respectively.
Method	The base of support of a figure (often called the support polygon) is denoted as Ë .
Method	It is represented by a polygon that surrounds the foot or feet that are in contact with the ground at any given time.
Method	In general, pre-conditions are relationships and constraints involving several different parameters.
Method	Most of our controllers can operate within a small region of the state space which we denote Ê  ́ Õ μ .
Method	These include the contact points between the character and the ground, as well as the normal of the ground and the amount of friction at the contact points.
Method	Usually, this is indicated by the relative position and velocity between the figure’s center of mass and the base of support.
Method	Typically, if the projection of along the gravity vector does not intersect the base of support Ë , the figure is considered to be unbalanced.
Method	We denote the balance conditions as  ́ Ë μ .
Method	Successful operation of a controller brings the character from an initial state, as defined by the pre-conditions, to a desired state or a desired region Ê  ́ Õ Ó μ in the state space.
Method	In general, however, the post-conditions are different from the pre-conditions.
Method	For example, while a pre-condition for a falling controller requires that the center of mass be moving, the postconditions require that the center of mass be at rest.
Method	Our framework permits the automatic selection of the appropriate controller based on the information provided by the controllers themselves.
Method	Only the individual controllers can detect whether they are operating normally or whether failure is imminent.
Method	Failure in our case means that the controller cannot meet its post-conditions Ç .
Method	The controller may fail because of a sudden change in the environment or because of badly designed pre-conditions.
Method	The sooner a controller can detect failure the sooner another more appropriate controller can take over.
Method	This is important for making a character behave naturally.
Method	For example, the character should not attempt to continue a walking gait if it has lost its balance and it is falling.
Method	In our implementation, the expected performance consists of expressions similar to those of the pre-conditions È .
Method	In particular if the controller successfully completes its task in the time interval Ø 1⁄2 , Ø 3⁄4 , then  ́ Ø 1⁄2 μ 3⁄4È and  ́ Ø 3⁄4 μ 3⁄4Ç .
Method	Transitions between controllers are not explicitly modeled as they would be in a finite state machine.
Method	They occur implicitly in response to the evolution of the motion over time, as the system state traverses the “regions-of-competency” of the various controllers.
Method	Nevertheless, given that most controllers are designed for specific situations, typical patterns of controller activation occur.
Method	For example, the controllers and transitions used in achieving the motion shown in Fig. 1 is given by balance fall default rollover prone-tostanding balance.
Method	For example, the prone-to-standing fall transition can occur if the figure is given a sufficiently strong push while rising.
Method	Most of the transitions which are not shown but are still practically feasible are of this nature, dealing with falling behaviors.
Method	Note that the fall controller always responds to the specific direction of the current fall.
Method	Any transition involves one controller being deactivated and another being activated.
Method	A controller can become deactivated (and thereby elicit a transition) for one of three reasons.
Method	First, it may relinquish control by declaring success upon reaching its postcondition, as is the case for a standup controller which has successfully returned the character to a standing position.
Method	Second, user intervention may elicit a transition.
Method	The controllers designed for sitting or balanced standing will retain control until intervention by a user (or by a higher level planner) forces a desired transition.
Method	Thus, when the 2D character is balanced a user-driven process must choose among the next plausible actions, namely one of sit, walk, or dive (see Fig. 4 ).
Method	Third, a controller may detect failure, as will be the case for unpredictable events such as a push or an unforeseen obstacle causing the character to trip.
Method	The transitions in Figs. 3 and 4 are labelled according to the type of controller deactivations which typically elicit the given transition patterns.
Method	We note that our framework is designed to work in interactive settings.
Method	As such, controllers typically start with slightly different initial conditions each time they are invoked, the user can interact with the character at any time, and generally there are no guarantees that the controller will reach the same end state each time it operates.
Method	As a result, the transition graph is dynamic in structure.
Problem	For controllers associated with complex dynamic characters, determining the exact region of the state space and the general conditions that determine success or failure of the controller is in general a non-trivial matter.
Method	The manual approach allows designers to incorporate their knowledge within controllers, whereas the automatic approach is based on machine learning techniques.
Background	For certain cases, suitable pre-conditions for specific controllers may be found in the biomechanics literature [ 8 , 25 ].
Background	For example Pai and Patton [ 25 ] present a comprehensive study of balance in the sagittal plane and identify the conditions under which a human can compensate for postural disturbances and maintain balance without stepping.
Background	For certain other cases, the pre-conditions are trivially defined by the desired motion itself.
Background	Certain controllers function as intermediate stages between other controllers.
Problem	In any case, the designer of a controller presumably understands the way the controller operates, and thus is able to provide high level conditions on its success or failure.
Problem	For example, the designer of a walking controller knows if the controller can operate when the walking surface has minimal friction properties.
Problem	Also, human motion is shaped by notions such as comfort, and only the designer can take this into account.
Problem	For example, if a person is pushed while standing he/she might take a protective step because it may be more comfortable to do so instead of maintaining an inverted pendulum balancing strategy.
Background	Similarly, the way people react to slipping and imbalance and the protective behaviors they employ are largely age dependent.
Method	In this section, we introduce an automatic, machine learning approach to determining pre-conditions, which is based on systematically sampling the performance of controllers.
Method	Our method uses a machine learning algorithm attributed to Vapnik [ 33 ] known as Support Vector Machines (SVMs), which has recently attracted much attention, since in most cases the performance of SVMs matches or exceeds that of competing methods.
Background	SVMs are a method for fitting functions to sets of labeled training data.
Background	The functions can be general regression functions or they can be classification functions.
Method	In our application, we use simple classification functions with binary outputs which encode the success or failure of a controller.
Background	Burges [ 5 ] provides an excellent tutorial on SVMs.
Method	Mathematically, we are given Ð observations, each consisting of an dimensional vector Ü 3⁄4 1⁄2 Ð and the associated “truth” Ý 3⁄4   1⁄2 1⁄2 provided by a trusted source.
Method	Here, Ý 1⁄2 labels a positive example—in our application, the observed success of a controller applied when the dynamic figure is in state Ü — while Ý   1⁄2 labels a negative example—the failure of the controller applied to state Ü .
Method	The set of observations Ü Ý is called the training set.
Method	The SVM is a machine whose task is to learn the mapping Ü Ý from a training set.
Method	The SVM is defined by functional mappings of the form Ü  ́ Ü « μ , where « are parameters.
Method	A particular choice of « generates a “trained” SVM.
Method	In a trained SVM, the sign of the decision function  ́ Ü μ represents the class assigned to a test data point Ü .
Method	In our application, a properly trained SVM predicts if a controller will succeed (  ́ Ü μ 1⁄4 ) or fail (  ́ Ü μ 1⁄4 ) on a given state Ü of the dynamic character.
Method	How does one train an SVM?
Method	In the simplest case of a linear SVM with separable training data, there exists a decision boundary separating positive from negative examples which takes the form of a “separating hyperplane” in .
Method	The SVM training algorithm computes the separating hyperplane with the largest margin · ·   , where · (   ) is the shortest distance from the separating hyperplane to the closest positive (negative) example.
Method	SVM training requires the solution of a quadratic programming optimization problem involving a Lagrange multiplier « for every datapoint in the training set.
Method	Those datapoints in the solution with corresponding « 1⁄4 are called support vectors.
Method	The support vectors are critical elements of the training set.
Method	They lie closest to the separating hyperplane.
Method	If other observations in the training set are moved (subject to certain restrictions) or removed and SVM training is repeated, the same separating hyperplane will result.
Method	To use a trained SVM, we simply determine on which side of the decision boundary a given test data point Ü lies and assign the corresponding class label to that point.
Method	The linear SVM is easily generalized to nonseparable training data.
Method	Furthermore, it is straightforward to generalize the theory to encompass nonlinear SVMs for which the decision boundaries are no longer hyperplanes (i.e., the decision function are no longer linear functions of the data).
Method	The trick, in principle, is to map the data to some higher (possibly infinite) dimensional space in which the linear theory can be applied.
Method	This is easily done by introducing kernel functions Ã  ́ Ü Ü μ , such as the polynomial kernel Ã (RBF)  ́ Ü Ý kernel μ  ́ Ü Ã ¡  ́ Ü Ý · Ý μ 1⁄2μ Ô , ÜÔ ́ or the   Ü Gaussian   Ý 3⁄4 3⁄4 or 3⁄4 μ radial .
Method	To apply the SVM technique to the problem of determining controller pre-conditions, we train a nonlinear SVM classifier to predict the success or failure of a controller for an arbitrary starting state.
Method	Thus, the trained SVM demarcates the boundary of regions in the figure’s state space wherein the controller can successfully do its job.
Method	Training sets comprising examples Ü Ý are generated by repeatedly starting the dynamic figure at a stochasticallygenerated initial state Ü , numerically simulating the dynamics of the figure under the influence of the controller in question, and setting Ý ·1⁄2 if the controller succeeds or Ý   1⁄2 if it fails.
Method	The distribution of the stochastically-generated initial states is of some importance.
Method	The sample points should ideally be located close to the boundaries which demarcate the acceptable precondition region of state-space.
Method	However, these boundaries are in fact the unknowns we wish to determine and thus we must resort to a more uniform sampling strategy.
Method	Unfortunately, the high dimensionality of the state-space precludes regular sampling.
Method	A shortduration simulation (typically 0.3s) is then carried out from this initial state while a randomized perturbation process is executed.
Method	This currently consists of applying an external force of random (but bounded) magnitude and random direction to the center-of-mass of the pelvis.
Method	Simultaneously, the character’s joints are perturbed in a stochastic fashion by setting randomized offset target angles for the joints and using the character’s PD joint controllers to drive the joints towards these perturbed positions.
Method	While the perturbation strategy is admittedly ad-hoc, we have found it to be effective in sampling the pre-condition space, as is validated by the online use of the learned pre-condition models.
Method	We employ T. Joachims’ SVM Ð Ø software which is available on the WWW [ 21 ].
Method	The software can accommodate large training sets comprising tens of thousands of observations and it efficiently handles many thousands of support vectors.
Method	It includes standard kernel functions and permits the definition of new ones.
Method	It incorporates a fast training algorithm which proceeds by solving a sequence of optimization problems lower-bounding the solution using a form of local search.
Method	It includes two efficient estimation methods for error rate and precision/recall.
Method	The SVM training phase can take hours in our application, but this is done off-line.
Method	For example, on a 733 MHz PIII computer, the SVM training time for a training set of 8,013 observations is 2,789 seconds using the polynomial kernel, 2,109 seconds using the linear kernel, and 211 seconds using the radial kernel.
Method	For a training set of 11,020 observations, the training time is 8,676 seconds using the polynomial kernel, 3,593 seconds using the linear kernel, and 486 seconds using the radial kernel.
Method	Once trained, the SVM classifier can provide answers on-line in milliseconds.
Method	We compared the performance of the SVM algorithm to that of a nearest neighbor (NN) classifier [ 9 ].
Result	Given a training set, the nearest neighbor classifier returns for an arbitrary state Ü the same succeed/fail label as the label for that observation in the training set that is closest to Ü .
Result	NN classifiers should perform particularly well in cases where the feasible area in the state space is highly fragmented and localized.
Result	Note that the NN method requires zero training time, but that it provides an answer in Ç  ́ Ò μ time where Ò is size of the training set.
Method	To compute accuracy rates, we trained the SVM and NN pre-condition learning algorithms using randomly sampled observations collected from each of the controllers.
Method	Then we generated test sets of novel observations and compared their true success/fail status against that predicted by the trained NN and SVM pre-conditions to obtain the accuracy percentages listed in the rightmost two columns of the table.
Result	The results show that the SVM algorithm consistently outperforms the NN classifier.
Method	For the results shown in the table, the SVM algorithm employed polynomial kernel functions.
Result	We ran a similar set of experiments using Gaussian RBF kernel functions, but the accuracies were consistently lower than those obtained with polynomial kernel functions.
Method	Our control composition framework is implemented within DANCE , a portable, extensible object-oriented modeling and animation system [ 24 ].
Background	2 DANCE provides a platform that researchers can use to implement animation and control techniques with minimal design and implementation overhead.
Background	The core of the system supports four base classes, Systems, Simulators, Actuators and Geometries which are loadable as plug-ins in accordance with simple APIs.
Background	Articulated objects are a System subclass that support skeleton hierarchies.
Background	They have kinematic properties and, usually, fully dynamic physical properties as well.
Method	Our virtual actors, which will be described shortly, are dynamic articulated objects implemented as Systems within DANCE .
Method	An actuator is a generic concept that includes anything that can exert forces or, in general, interact in any way with systems or other actuators.
Method	For example, gravity, the ground, the collision mechanism, the supervisor controller and individual controllers are implemented as actuators.
Background	DANCE places no restrictions on the complexity of the controllers.
Background	Simulators compute the equations of motion of all the dynamic characters and other systems in DANCE .
Background	DANCE offers built in support for SD/FAST, a commercial system which produces optimized simulation code [ 18 ].
Method	Our simulators are automatically produced by SD/FAST from description files.
Method	They use Kane’s method for computing articulated dynamics and a fourth order explicit Runge-Kutta time integrator for numerically simulating the motions.
Method	Actuators and simulators are implemented as DANCE plug-ins.
Method	This allows the user to dynamically load controllers and simulators at runtime.
Method	In addition, researchers can exchange, simulators, and controllers in the form of dynamically linked pieces of code.
Method	Object collisions (including self collisions) are handled by the Collision actuator.
Method	This actuator works on pairs of objects.
Method	The DANCE API allows it to work with objects that have different simulators.
Method	Collision detection is based on a library that uses oriented bounding boxes [ 13 ].
Method	Collision resolution uses a penalty method that corrects geometry interpenetration using spring-and-damper forces.
Method	As with all penalty methods, it can make the system stiff, but it has performed well in our experiments to date.
Method	The red arrows indicate the joint positions and axes of rotational degrees of freedom (DOFs) which are also presented in the table.
Method	The 3D skeleton model has 37 DOFs, six of which correspond to the global translation and rotation parameters.
Method	The dynamic properties of both models, such as mass and moments of inertia, are taken from the biomechanics literature and correspond to a fullyfleshed adult male.
Method	The models are equipped with natural limits both on the motion of the joints and the strength of their muscles.
Method	However, DANCE has no built in muscle model and does not enforce the limits automatically.
Method	Users can implement the model they prefer and include code to enforce the limits of the model.
Method	Our plug-in control scheme uses rotational spring-and-damper forces for control and enforces the limits on the joints with exponential springs.
Method	Most of the controllers for our virtual stuntperson are based on pose control, which has often been used both for articulated objects [ 31 ] and soft objects [ 11 ].
Background	Pose control is based on cyclic or acyclic finite state machines with time transitions between the states.
Background	Each state of the controller can be static or depend on feedback parameters.
Method	For some of our controllers, we use continuous control, in the sense that the control parameters are tightly coupled with some of the feedback sensors.
Method	The balance controllers are an example of this.
Method	We designed several controllers based in part on experimental studies of how humans detect loss of balance [ 25 ] and analysis of protective and falling behaviors [ 8 ].
Method	The resulting parameterized controllers have been enhanced with appropriate pre-conditions, post-conditions, and expected performance and have been integrated using an arbitration-based supervising controller.
Method	Each controller has full access to the internal data structures of DANCE including all the information associated with any character or object in the system.
Method	This allows the controllers to define arbitrary sensors that keep track of necessary information such as state parameters for feedback loops and the state of the environment.
Method	For efficiency, the supervisor controller calculates a number of common sensor values that are available to all the controllers.
Method	Many controller transitions in the control framework happen autonomously, such as taking a protective step in response to losing balance.
Method	However, other actions are initiated in a voluntary fashion.
Method	For example, a standing character can do any of (1) remain standing using the balance controller, (2) sit-down, (3) walk, and (4) dive.
Method	Currently, the user directs these voluntary motions by interactively entering command strings to the supervisor controller which, in turn, directly increases the suitability score of the designated controller and forces the arbitration process to be invoked to select a new active controller.
Method	The control of voluntary motions could equivalently be delegated to a high-level planner, although this kind of planning is beyond the scope of our work at present.
Result	At the heart of our prototype system is a composite controller that is capable of handling a large number of everyday tasks, such as walking, balancing, bending, falling, and sitting.
Method	In addition, we present brief descriptions of the controllers involved in producing several stunt actions.
Result	While the given controller descriptions are for the 3D character, the equivalent 2D controllers are very similar.
Method	We began our implementation with the simple tasks of standing, recovering balance when pushed, and falling.
Method	An autonomous human agent should be able to balance, standing naturally in place.
Method	Should loss of balance occur, the character ought to react naturally either with a restoring motion or with a protective falling behavior depending on which action is appropriate in each case.
Result	Affording a dynamic articulated figure with natural reactions to loss of balance or impending falls is an essential step towards believable autonomous characters.
Method	A balance controller is responsible for maintaining a natural standing posture.
Method	This controller is based on an inverted pendulum model [ 12 ], using the ankles to control the body sway.
Result	Despite the fact that the body of the character is not as rigid as the inverted pendulum hypothesis suggests, the approximation works well in practice.
Method	An animated character should attempt to maintain balance in response to external disturbances by shifting its weight, taking a step or bending at the waist.
Method	If the character cannot maintain balance, it must then resort to a falling behavior.
Background	The manner in which people fall depends on a number of factors such as their physique, their age and their training.
Background	For example, the work in [ 19 ] shows that, during a fall, the elderly are more likely to impact their hip first as compared to younger adults falling under the same conditions.
Method	Our fall controller is designed with the average adult in mind.
Method	Its main action is thus to absorb the shock of the impact using mostly the hands.
Method	The pre-conditions of the fall controller are defined in accordance with those of the balance controller.
Method	Situations that are beyond the capabilities of the latter should be handled by the fall controller.
Result	Our implementation of the fall controller can handle falls in any direction, responding in different ways to falls in different directions.
Background	Sitting down in a chair and rising from a chair are common everyday tasks.
Method	We have implemented a controller that can do both depending on the instructions of the animator.
Method	Apart from the command string supplied by the user, the pre-conditions are either a balanced upright posture or a balanced sitting posture.
Method	The postconditions are similarly defined.
Background	Getting up off the ground is a surprisingly difficult motion to simulate.
Background	It involves rapid changes of the contact points and significant shifting of the figure’s weight.
Background	In addition, the frictional properties of the ground model can influence the motion.
Method	The pre-conditions for this controller are straightforward.
Method	The character must be lying with its back flat on the ground, within some tolerance.
Method	The post-conditions are that the character should be on its feet with its center of mass within the support polygon.
Method	Then it would be up to another controller to take over and bring the character from a crouching position to a standing one.
Background	When lying on their back, some people may choose to roll-over to a prone position before attempting to stand.
Method	We have implemented a roll-over controller that can emulate this action.
Method	The pre-conditions of the roll-over controller require a supine posture, and no movement of the center of mass.
Method	The postconditions of the roll controller are fairly simple and they include any prone position for which the character is extended and fairly straight; i.e., no crossing of legs or arms, etc.
Method	When lying face-down, the pre-conditions can be fairly relaxed.
Method	Our controller assumes that is has the time to change the state of the character to one from which it knows how to rise.
Method	As long as the figure is not lying on its arms and the ground is relatively flat it will attempt to get up.
Method	The post-conditions are chosen such that they satisfy the pre-conditions of the balance controller.
Method	Apart from everyday actions, we want our dynamic character to be able to do a variety of other voluntary actions dictated by the animator.
Method	Such actions can potentially include vigorous and/or physically dangerous actions.
Problem	It is our hope that if a large number of researchers contribute controllers the character can eventually be used as a virtual stuntperson.
Background	The kip is an athletic motion often seen in martial arts films and is depicted in Fig. 9 .
Method	The controller is based on a pose controller whose pre-conditions include a variation of supine positions.
Method	As before, the first part of the controller makes sure that the character assumes a position suitable for performing the kip.
Method	The larger part of the motion is ballistic, which focuses the control mainly at the kick off and landing phases.
Method	The last part of the controller applies continuous control to bring the stuntman to an erect position from which the balance controller can take over.
Method	The character can be instructed to lunge forward and upward at a takeoff angle controlled by the user.
Method	When the hands contact the ground a front-roll is attempted.
Method	The pre-conditions of this controller are defined be an upright position and little movement of the center of mass.
Method	We have also experimented with a multiple character scenario, with one character tackling another, Fig. 11 .
Method	While the timing of the tackle is scripted, it illustrates the capability of the system to cope with a pair of interacting characters, each equipped with its own supervisory controller.
Result	We have produced two relatively long animation sequences that demonstrate the potential of the our framework.
Method	The sequence for the 3D skeleton model presented in Fig. 1 involves controllers whose pre-conditions are provided analytically by the designer.
Method	Such conditions tend to define square regions within the space defined by the parameters involved.
Result	Despite their simple form, such pre-conditions can generally work well as is demonstrated by the intricacy of the animation produced.
Future Work	We expect to investigate the application of SVM-learned pre-conditions to the 3D model in the future.
Method	A second animation sequence with the 2D terminator model (see Fig. 12 ) makes use of a set of controllers having a mix of analytic and learned pre-conditions.
Method	The sequence of controllers that generated the animation was: balance sit lean-forward rise balance walk step-to-stand balance dive default kneel kneel to stand balance step-forward step-tostand balance step-back step-to-stand balance fall default.
Method	The analytical pre-conditions prune large parts of the state space and the svm-classifier provides a more accurate success/failure prediction within the remaining region.
Result	During the animation sequence, the svm-classifier correctly refined the analytical answer in several cases.
Method	Most of the computational burden in our approach lies in the numerical simulation of the equations of motion.
Result	The computations associated with the controllers and our composition framework are negligible in comparison.
Result	In general, the 2D model simulates in real time, while the 3D model runs between 5 and 9 times slower than real time on a 733 MHz Pentium III system.
Problem	The challenges of physics-based controller design plus the technical obstacles that researchers face when attempting to share their algorithms has hindered progress in the important area of physicsbased character animation.
Result	This paper has presented a methodology for ameliorating the problem with a framework which facilitates the exchange and composition of controllers.
Result	Our framework has been implemented within a freely available system for modeling and animating articulated characters.
Result	To our knowledge, our system is the first to demonstrate a dynamic anthoropomorphic character with controlled reactions to disturbances or falls in any direction, as well as the ability to pick itself up off the ground in several ways, among other controlled motions.
Result	We hope that our system will foster collective efforts among numerous practitioners that will eventually result in complex composite controllers capable of synthesizing a full spectrum of human-like motor behaviors.
Future Work	Given the enormous challenge of building controllers capable of large repertoires of dynamic human-like motion, it is inevitable that the work presented in this paper is incomplete in many ways.
Future Work	Published control methods for 3D walking, running, and stair climbing make obvious candidates for integration into our system.
Future Work	Coping with variable terrain and dynamic environments are dimensions of added complexity that should provide work for years to come.
Future Work	Automatic parameterization of controllers to variations in character dimensions and mass is a necessary step for having solutions adaptable to a variety of characters.
Future Work	Deriving controllers from motion-capture data is an exciting but difficult prospect, although some progress is already being made in this area.
Future Work	Other methods of “teaching” skills to a dynamic character also warrant investigation.
Future Work	Finally, intelligently integrating controllers which affect only subsets of DOFs needs to be addressed in order to allow for the parallel execution of controllers.
Method	The articulated body must be in a balanced upright position, the velocity and acceleration of the center of mass should not exceed certain threshold values as explained in [ 25 ], and both feet must maintain contact with the ground at all times.
Method	The controller can tolerate small perturbations of the posture and the velocity/acceleration of the center of mass by stiffening the ankle joints.
Method	For larger accelerations of the center of mass, the controller actively actuates the ankle joint to reduce the acceleration of the center of mass.
Method	The post-conditions are similar to the pre-conditions.

Problem	While such vertex-parallel computation is often done on the GPU vertex processors, further parallelism can potentially be obtained by using the fragment processors.
Problem	In this paper, we develop a parallel deformation method using the GPU fragment processors.
Method	Joint weights for each vertex are automatically calculated from sample poses, thereby reducing manual effort and enhancing the quality of WPSD as well as SSD (Skeletal Subspace Deformation).
Result	We show sufficient speed-up of SSD, PSD (Pose Space Deformation) and WPSD to make them suitable for real-time applications.
Background	Skinning is an important part of realistic articulated body animation and is an important topic of computer graphics and animation.
Background	Generally, skinning can be categorized into algorithmic, physically-based, and example-based methods.
Problem	Although widely used, simple algorithmic skinning schemes cannot capture the complexity and subtlety of real skin deformation, and revised approaches will be required to increase character animation realism.
Background	Physically-based skinning is based on the biomechanics of skin deformation arising from the motions of muscles and tendons.
Problem	Although this approach can generate physically accurate simulations of each layer, it is not at present suitable for real time applications such as gaming due to the large computation required.
Background	Example-based methods capture some of the complexity of real skin deformation by interpolating scanned or sculpted examples of the desired skin shape in various poses.
Background	Al-      though this requires gathering a sufficient number of samples and some pre-calculation, example-based methods can potentially be used in real-time applications due to their relatively simple real-time computation.
Background	Weighted pose space deformation (WPSD) is an example based skinning method that generates high quality skinning with a limited number of sample poses [KM04].
Background	Although it can generate an accurate skinning, it requires more computation than the original pose space deformation (PSD) [LCF00], since joint distances are computed independently for each vertex.
Background	As such, this method has not been suitable for real-time applications.
Background	Furthermore, both WPSD and SSD require joint weights for each vertex, and accurate joint weights are required to achieve good results.
Problem	However, the weights are usually manually generated by artists, which requires effort and great skill in the case of a complex skeletal system such as the human hand.
Problem	In this paper, we present a parallel WPSD algorithm (including automatic determination of joint weights) suitable for SIMD architectures such as current GPUs.
Method	The joint
Method	This can enhance the skinning quality not only of SSD but also WPSD, since both methods require accurate joint weight values.
Method	The deformation required in WPSD and SSD is independent for each vertex and this per-vertex computation can be parallelized in a SIMD architecture.
Background	The GPU is a general SIMD architecture having one-sided (unidirectional) communication to texture memory.
Method	We demonstrate our parallel WPSD method using GPU fragment processors.
Method	In our experiments, we can speed up SSD, PSD, as well as WPSD to around 20 times faster than on the CPU (from 1.2FPS to 25FPS speed-up of WPSD on a detailed model having 22836 triangles with 11574 vertices) using a modern graphics card, thus making WPSD a feasible real-time skinning solution for various applications including games, virtual reality, and other real-time simulations.
Background	Many commercial software packages generate skin deformation arising from joint movement using a method known as (linear blend) skinning, Skeletal Subspace Deformation (SSD), enveloping, etc., based in part on work published by Thalmann et al. [MTLT88].
Background	SSD is based on the weighted blending of affine transformations of each joint and used in many real-time applications due to its simple and fast computation.
Background	However, it also exhibits some well known artifacts such as skin that collapses around the joints at increasing bend angles, and a variety of solutions for these problems have been published [Web00, WP02, MTG03, KZ05].
Background	Recently, example-based methods [LCF00, SRC01, ACP02, KJP02, KM04] have permitted more complex skinning effects such as muscle bulges and major wrinkles, while also addressing the artifacts of simple algorithmic schemes.
Background	In these methods, a number of provided (scanned or sculpted) samples of the desired skin shape are simply interpolated based on the creature’s pose (and possibly additional abstract control “dimensions”).
Background	These example-based methods can also be considered as a non-parametric approach to skin deformation.
Background	In common with non-parametric sampling methods in texture synthesis (and more generally in statistical regression), the amount of memory for these methods grows with the number of training samples, but arbitrary distributions can be approximated.
Background	Some of the most impressive example-based results to date are those of Kurihara and Miyata’s hand model derived from medical images [KM04].
Background	Since acquiring 3D medical images is relatively expensive, they developed weighted pose space deformation (WPSD) to generate proper skinning from a limited number of pose samples.
Background	They modify the distance between poses using the joint weights of each vertex to provide a more appropriate distance measure for skinning.
Background	Although the joint weights for each vertex are important data for SSD and WPSD calculations, they have traditionally been manually generated by skilled artists.
Background	Least-squares based vertex weight estimation was shown in the skinning methods [WP02, MTG03].
Background	James et al. describe mesh based skinning including estimation of bone parameters and vertex weights for each bone [JT05].
Background	In their paper, the vertex weights of each joint are calculated by NNLS (non-negative least squares) and we derive a similar approach to calculate weights for SSD and WPSD.
Background	In recent years, since the performance of GPUs has been improving more rapidly than that of CPUs, and GPUs have many processing units serving as a SIMD parallel architecture, many algorithms have been accelerated by GPU programming [LHK ∗ 04, PF05, GPG].
Background	Deformation and skinning algorithms can also be enhanced by GPUs and several papers have profited from this [JP02, KJP02, BK05, JT05].
Background	However, in previous research, since vertex information cannot be accessed in the fragment program, GPU-based vertex deformation is usually performed by vertex programs.
Problem	In this paper, we develop a parallel WPSD method using the fragment processors to gain greater parallelism and performance.
Background	Person-specific data modeling and its deformation is also an interesting topic in realistic articulated body simulation.
Background	Rhee et al. described human hand modeling from surface anatomy of the person [RNL06].
Background	Anguelov et al. developed shape completion and animation of people, derived from the set of range scan data and example based deformation in pose and shape space [ASK ∗ 05].
Background	Physically inspired skinning should be also recognized as another important area of articulated body animation.
Background	However, we entrust the review of the subject to the recent related papers [AHS03, CBC ∗ 05, PCLS05, SNF05].
Method	In skeletal subspace deformation the displacement D(p a ) is omitted and the target surface is calculated by SSD as a blend of affine transforms of v 0 [section 3.1].
Method	Skinning methods related to PSD use the displacement of an arbitrary pose D(p a ), calculated by interpolation in pose space [section 3.2].
Method	SSD [MTLT88] is based on the weighted blending of an affine transformation of each joint by equation 2.
Method	The weight w j can be assigned by the artist to control deformation and usually ∑ n j=1 joint (w j ) = 1.0.
Background	This simple algorithm is used in many commercial graphics packages and real-time rendering applications but shows several limitations, because the deformation of this method is restricted to the subspace of the affine transformation of the joints [LCF00].
Method	If we have a sufficient set of examples to describe the movement of an articulated object, we can interpolate displacement in “pose space” [LCF00].
Method	Each sample pose consists of sample skin geometry and the related joint skeleton, and a vector containing the joint angles represents the pose.
Method	Note that the inverse here is of the weighted sum of affine transforms.
Method	After defining the displacement of each pose, the displacement at an arbitrary pose can be calculated by RBF (Radial Basis Function) [LCF00] or normalized radial basis function [KM04] interpolation of the example poses’ displacements.
Method	The weight r k (p a ) is calculated using normalized RBFs and is used in equation 4 to calculate the displacement d a of a vertex in an arbitrary pose p a :
Background	WPSD is developed by Kurihara et al. [KM04] to deform their example-based human hand model derived from medical images.
Method	In equation 7, since the γ k is the difference of n joint dimensional joint vectors of related poses, every vertex in the pose p k has same distance γ k resulting in the same weight r k (p a ) in every vertex of the pose p k .
Method	Furthermore, because each element of the joint vector equally contributes to the distance calculation, two vectors having a same value but different order generate same pose distance.
Method	For example, three different joint vectors p 1 = (θ, 0, 0), p 2 = (0, θ, 0), p 3 = (0, 0, θ) have same distance between them and it can cause unexpected results in PSD.
Background	In WPSD [KM04], Kurihara et al. modify the distance definition between poses using joint weight of each vertex i to give proper weight to each element of a joint vector,
Method	From this definition, a more accurate pose distance is obtained and it generates better skinning in arbitrary poses, especially when the poses are far from the examples.
Background	The joint weights of each vertex are important to generate accurate skinning in SSD (equation 2) as well as in WPSD (equation 8).
Background	In many applications, the weights are manually generated by skilled artists and it is hard to generate accurate values when a number of joints are involved in deforming a region.
Method	In this paper, we automatically calculate the joint weights of each vertex from the sample poses to enhance the accuracy of the weight value.
Result	This results in better skinning and reduces the elaborate manual work required to create weight maps.
Method	>From equation 11, we can calculate w from the given value of v and A to reduce the error of this equation.
Method	We use the non-negative least square (NNLS) method to solve this problem and it determines positive weight values minimizing error in equation 10.
Method	The calculated weight vector w is normalized to satisfy ∑ n j=1 joint w j = 1.0.
Method	In order to avoid a singular matrix A, the number of poses should be greater or equal to the number of overall DOF (Degree Of Freedom) of the joint vector (each joint has 3 DOF), and the sample poses should be sufficiently different.
Method	James et al. used a similar approach to estimate vertex weights in each joint [JT05] and we demonstrate their efforts in our skinning method.
Background	Skinning deformations vary across vertices.
Background	In SSD and WPSD, this per-vertex computation is independent for each vertex and can be parallelized by a SIMD parallel architecture.
Result	We developed a parallel skinning algorithm for SSD and WPSD that is suitable to GPUs having a SIMD architecture with one-side communication to texture memory.
Method	The computation cost of the SSD skinning algorithm is O(n vertex × n joint ) from equations 1, 2, PSD is O(n vertex × n joint × n pose ) from equations 1, 2, 4, and WPSD is O(n vertex × n joint × n pose × n pose × n pose ) from equations 1, 2, 4, 5, 6.
Method	Where, computation cost of original PSD is defined by equation 1, 2, 4, since r i is same in all vertices and d i can be pre-calculated.
Method	The number of joints n joint and poses n pose can be reduced to the smaller numbers using the method developed by Kry et al. [KJP02], as will be discussed in section 5.2.1 with efforts to reduce texture memory space.
Background	In previous research, the Eigenskin method based on PSD was developed using GPU vertex programming [KJP02].
Method	The vertex program uses a relatively small number of slow processing units compared with the fragment processors, and the per-vertex computation cost of the original PSD is O(n joint × n pose ).
Result	Therefore WPSD, having higher pervertex computation cost O(n joint × n pose × n pose × n pose ), can clearly benefit from parallel computation on fragment processors.
Method	We developed parallel skinning using the GPU fragment processors and demonstrate our method using three rendering passes.
Method	In order to minimize real-time computation, we separate possible pre-calculation steps and save the results into texture memory using texture maps.
Method	Because the value in the texture memory is not changed in the successive deformation, it can be pre-computed and stored in the read-only texture memory.
Method	In the first and second pass, per-vertex deformation is calculated in the fragment program and the results are stored in texture maps using the FBO (Frame Buffer Object) extension [Gre05].
Method	These texture maps are bound to the geometry of the rest pose with their texture coordinates.
Method	In the third pass, each vertex in the rest pose is changed by the deformed vertex stored in the output texture generated in the first and second passes using vertex texture fetch.
Background	The fragment processors cannot access vertex information.
Method	Instead, we can use texture memory to send data to the fragment program.
Method	Information needed in the fragment program is packed into texture maps and stored into texture memory.
Method	Geometry information from the rest pose is stored into two RGB texture maps, a vertex texture T v and normal texture T n ; each has size n vertex × 3.
Method	These textures represent parameter v 0 in equation 2 and each 3D element (x, y, z) is stored into the (r, g, b) value of a texel [ Figure 2 ].
Background	In general, the distribution of skinning effects in an articulated body is local to several joints [MMT97,KJP02], even in a region as complicated as a hand.
Background	For example, deformations arising from the PIP (Proximal Interphalangeal) joint of index finger do not propagate to the other fingers, and deformation on the middle phalanx of index finger is only affected by the movement of PIP and DIP(Distal phalanx) joints.
Method	From this observation, we can reduce joint weight storage from the actual number of joint n joint to a smaller number of “principal joints” n  ̃ joint selected by sorting on the weight value.
Method	We threshold n  ̃ joint at four in our tests with an additional four elements to hold the related joint index.
Method	As a result, we can save the joint weights of entire geometry in two RGBA textures T w1 , T w2 each with size n vertex × 4(rgba) and store the entire information required for SSD [equation 2] in four textures T v , T n , T w1 , and T w2 .
Method	The displacement values calculated by equation 3 can be stored in n pose displacement textures; n pose is the number of sample poses.
Method	In case of complex joint structures and a large DOF model, we need many sample poses to calculate accurate joint weights and PSD deformation.
Method	However, since the joint weights can be pre-calculated, we can reduce the number of sample poses needed in real-time PSD computation.
Background	PCA (Principal Component Analysis) of pose space can yield an orthogonal basis called “ Eigendisplacement ” [KJP02].
Method	If we reduce the size of pose space from n pose to n  ̃ pose “principal poses” ( n  ̃ pose < n pose ), we can reduce the number of displacement textures.
Method	In our paper, we set n  ̃ pose as eight in our experiment and save displacements of all poses into a RGB texture T d having size n vertex × 8( n  ̃ pose ) × 3(rgb).
Method	Therefore, from the two important observations of “principal joints” and “principal poses”, the original computation cost for SSD, PSD, and WPSD discussed in section 5.1 can be reduced using n  ̃ joint and n  ̃ pose rather than n joint and n pose .
Method	In the original PSD, since the weight r i in equation 4 is the same at every vertex, we do not need to calculate this value in the GPU.
Method	Since the size of this value is just n  ̃ pose , we can simply pass them to the GPU as parameters without generating a texture map.
Method	Therefore, we store all the information needed to calculate the original PSD at this point.
Method	In order to reduce real-time computation, we pre-calculate T j in equation 2 and λ in equation 5 and store them into another one channel texture T x having size n  ̃ pose × ( n  ̃ pose + n  ̃ joint × 3(x, y, z)).
Method	As a result, we store all the variables required to calculate WPSD, PSD, and SSD in six texture maps: T v , T n , T w1 , T w2 , T d , and T x .
Method	The values in the texture maps are stored in the texture memory at setup time, since they are not changed during the deformation process.
Background	In current graphic card architectures, data transfer from CPU to GPU is slow compared with memory access within the GPU.
Result	Although, we cannot access vertex data in the fragment program, the efficiency of parallel computation on a fragment program is higher, since the fragment processor has more processing units and each of them has more computation power than a vertex processor.
Method	The fragment processing system is a general SIMD architecture using fragment streams as input data; each fragment is assigned to a fragment processor to calculate its final color value independently and in parallel.
Method	We developed a parallel WPSD algorithms using the fragment processors to enhance the extent of parallel computation.
Method	Geometry information like vertex positions and normals are stored in texture maps T v and T n as described in section 5.2.1 and the vertex information is referred in the fragment processors to calculate final color values.
Method	In order to assign each vertex value stored in a texture map to a fragment, we bind the geometry texture T v or T n to a quad and render it using an orthographic camera having the same width and height as the quad.
Method	Furthermore, since the viewport is set to the same resolution as the textures, each fragment is exactly matched with each texel holding the vertex information, and we can access each vertex using the texture coordinates of the fragment; vertex weights and displacements stored in the texture maps can also be accessed by similar methods.
Background	A similar idea was developed in [PBMH02] to calculate ray tracing in a fragment program and is used in GPGPU (General Purpose computation on GPUs) applications [GPG, LHK ∗ 04, PF05].
Background	The FBO (Frame Buffer Object) extension [Gre05] supports rendering into an attached texture.
Background	This saves memory and time, since there is no copy operation from frame buffer to texture buffer.
Method	We implemented our WPSD algorithm using the fragment program with the FBO extension to store the result directly into texture maps accessed by vertex program in the next pass.
Method	We implemented GPU deformation using three rendering passes, and the basic architecture is described in figure 3 .
Method	In the first pass, we parallelize per-vertex deformation using GPU fragment processors.
Method	The data required to calculate this deformation is stored in the textures as described in section 5.2.1 and the deformation for each vertex is calculated in a fragment processor.
Method	In a given arbitrary pose defined by a joint vector, SSD is computed by equation 2 using texture maps T v , T w1 , T w2 and T x ; refer to the texture map notation in section 5.2.1.
Method	PSD is computed by equation 4 using T d , T x , after calculating r k (p a ) by equation 6.
Method	In the second pass we calculate and store normal deformation with a similar method as in the first pass, and the results are stored in the texture map T n ′ .
Method	In the third pass, using a vertex program, each vertex of the rest pose is transformed to the final deformed position using the information from the texture maps computed in the previous two passes.
Method	In order to access related texture information in each vertex, we created texture coordinates of each texel in pre-processing and used them in the vertex program.
Method	Specifically, the two texture maps, T v ′ and T n ′ that are generated in the first and second passes are accessed in the vertex program using the texture coordinate of the current vertex.
Method	Alternatively, multiple render targets (MRTs) can combine the first and second pass, and vertex buffer objects (VBOs) could be used to render the deformed results back to the vertex array [OPE, GPG, LHK ∗ 04].
Method	We tested our methods using upper arm models consisting of four joints (collar, shoulder, elbow, and wrist).
Method	Each has three DOF and the wrist is the end joint having no DOF.
Method	Three different resolution meshes are used to test the performance of GPU parallel computation: the high-resolution model has 91460 triangles with 46036 vertices, the midresolution model has 22836 triangles with 11574 vertices, and the low-resolution model has 5762 triangles with 2972 vertices [ Figure 4 ].
Method	Note that these models are considerably more detailed than those used in current games, so the reported frame rates would be much higher if typical gameresolution models were used.
Result	On the other hand, with the expected growth of GPU processing power, models such as these will be in wide use in a few years, and algorithms such as WPSD will be required to produce realistic deformations at this level of resolution.
Method	Eight sample poses were created by Poser [Cur] and the joints weights and displacements of each sample were derived from these models [ Figure 5 ].
Method	Our parallel algorithm is based on three pass GPU computation.
Method	The fragment program for the 1st and 2nd pass, and the vertex program for the 3rd pass are implemented in the Cg language [FK03].
Method	For accuracy the GPU computation is performed by 32bit floating point operations with 32bit floating point texture maps.
Method	Note that the maximum required memory space for the highest resolution model is just 6.8 Mbytes; the size of the output texture T v ′ and T n ′ is the same as the size of T v and T n .
Result	The results of GPU-based deformation for SSD, PSD, and WPSD are shown in Figure 1 and 6, and the experiment is performed in a GeForce 6800 Ultra GPU and a 3.4Ghz Pentium 4 CPU.
Result	The timing results of each algorithm on the CPU and GPU are summarized in table 1 .
Result	On average, our GPU-based deformation shows around 20 times speed-up compared with CPU-based deformation.
Result	GPU-based WPSD has roughly the same speed as CPUbased SSD.
Result	Therefore, real-time applications using SSD can substitute WPSD running on the GPU without loosing their real-time performance.
Result	Since our algorithm shows speed-up for SSD and PSD as well as WPSD, applications can choose the most appropriate skinning method according to the required deformation and detail.
Result	In this paper, we present a parallel skinning algorithm suitable for SIMD architectures such as GPUs.
Method	The joint weights of each vertex are automatically computed by NNLS and used in the skinning computation for SSD and WPSD.
Method	Independent per-vertex deformation is parallelized on the GPU using three rendering passes.
Method	In the first and second passes, per-vertex deformation is calculated by the fragment processors and the results are stored in texture maps using FBO.
Method	In the third pass, using vertex processors, each vertex of the rest pose is changed by the deformed vertex stored in the textures generated by the first and second passes.
Result	Articulated body skinning using SSD, PSD, and WPSD are efficiently parallelized by our GPU-based method, and on a detailed model, we obtain around 20 times speed-up compared with CPU-based computation.
Result	Principal component compression of the examples and careful analysis of joint distributions can reduce the domain of computation [KJP02] and other algorithms based on the SSD, PSD, and shape interpolation may be parallelized on GPU using our approach.

Problem	Optimization is a promising way to generate new animations from a minimal amount of input data.
Problem	Physically based optimization techniques, however, are difficult to scale to complex animated characters, in part because evaluating and differentiating physical quantities becomes prohibitively slow.
Background	Traditional approaches often require optimizing or constraining parameters involving joint torques; obtaining first derivatives for these parameters is generally an O(D 2 ) process, where D is the number of degrees of freedom of the character.
Method	In this paper, we describe a set of objective functions and constraints that lead to linear time analytical first derivatives.
Result	The surprising finding is that this set includes constraints on physical validity, such as ground contact constraints.
Result	Considering only constraints and objective functions that lead to linear time first derivatives results in fast per-iteration computation times and an optimization problem that appears to scale well to more complex characters.
Result	We show that qualities such as squash-and-stretch that are expected from physically based optimization result from our approach.
Result	Our animation system is particularly useful for synthesizing highly dynamic motions, and we show examples of swinging and leaping motions for characters having from 7 to 22 degrees of freedom.
Background	One appealing vision in animation is that the animator should be able to create and edit motion by defining and adjusting a small number of keyframes and constraints—and that the resulting motion should remain optimal in some way.
Background	An optimization approach to animation has proven useful for editing human motion capture data, refining a “sketched” version of an animation, and for creating entirely new motions for simple characters or short segments.
Problem	Several challenges remain, however, to achieving fast, flexible, and realistic optimization of human motion.
Problem	One challenge is incorporating physics into an interactive animation system.
Problem	Physical validity is important, however, in situations such as those shown in Figure 1 .
Problem	Kinematic optimization alone is unlikely to capture the coordination of different parts of the body that is required to perform this task, such as the preparatory back swing, the tuck, or the motion of the legs to drive the character upward that is shown in the bottom row of the figure.
Result	This paper presents an approach to physically based optimization that is efficient and appears to scale well to more complex characters.
Method	We use a standard problem formulation—iteratively adjust character motion to meet animator constraints and minimize an objective function.
Method	Our approach is based on restricting the definition of this optimization problem to constraints and objective functions that can be differentiated in time linear in the degrees of freedom of the character.
Method	The motivation for this approach is that solution techniques for nonlinear constrained optimization problems (e.g. SQP) typically require either analytical or numerical derivatives.
Method	Obtaining these derivatives is a computational bottleneck, and complex derivatives can lead to poor optimization performance and problems with local minima.
Background	Kinematic optimization [Gleicher 1997], which has been shown to be successful for complex characters, depends on constraints and objective functions for which first derivatives can be computed in linear time.
Result	We have found that constraints on physics that can be derived from the aggregate force and torque applied to the character can also be differentiated in linear time.
Result	This set includes most common constraints required for physically correct animation, such as conserving linear and angular momentum during flight, ensuring that ground contact forces can be explained by foot placement, constraining torque applied about an axis (e.g. the high bar in Figure 1 ), and limiting the coefficient of friction at any contact with the environment.
Background	Linear time derivatives for physics constraints do not result from direct differentiation of the equations of motion in either the Newton-Euler or the Lagrangian formulation; in either case, symbolic differentiation would result in a quadratic time algorithm.
Result	In this paper, we describe how the Newton-Euler equations of motion can be rewritten to allow first derivatives of aggregate forces and torques to be computed in linear time.
Result	We note that it is not possible to compute derivatives for torques at all of the characters joints in linear time.
Problem	Intuitively, quadratic time is required because motion at any joint affects torque at all joints.
Method	As a result, typical objective functions such as minimizing the sum of squared joint torques are excluded from our restricted problem setup.
Result	Our results suggest, however, that physics constraints and a kinematic measure of smooth motion such as minimizing the sum of squared joint accelerations are sufficient to capture dynamic effects such as squashand-stretch and tucking for faster rotation, as shown in Figure 1 .
Method	While animator constraints such as key poses or an objective based on proximity to a reference motion can easily be incorporated into the system, no motion capture data is used in our examples, and user-supplied constraints are minimal (e.g., see Figure 7 ).
Result	The characteristics of the final motions fall out of the requirements of physical validity, a simple kinematic optimization function, and timing values selected for each phase of the motion.
Background	Constrained optimization techniques were introduced to the graphics community by Witkin and Kass [1988], who created a variety of animations involving a jumping Luxo lamp from simple descriptions including start pose, end pose, and a physically based objective function.
Background	Optimization approaches with physically based objective functions have proven difficult to extend to complex articulated characters, however, and much research has been focused on this problem.
Background	Cohen and his colleagues [Cohen 1992] [Liu et al. 1994] introduced techniques to give the user more control, including an ability to focus on windows in time, and employed a hierarchical wavelet description to allow incremental changes to affect the motion at different time scales.
Background	In his dissertation, Liu [1996] also describes how symbolic differentiation of the equations of motion can be made efficient (although still quadratic time) by cleverly aggregating terms.
Background	Grzeszczuk, Terzopoulos, and Hinton [1998] developed a neural network approximation of dynamics so that gradient search could be performed on this neural network, resulting in faster convergence to a solution.
Background	The mix of animator control and physics present in Witkin and Kass [1988] has been expanded upon in interactive techniques developed to control physical simulations of rigid bodies [Popović et al. 2000], and a number of researchers have shown that the freefall portion of a dive can be efficiently optimized for a simplified character [Liu and Cohen 1994][Crawford 1998][Albro et al. 2000], as can motions such as weight lifting and pushups [Lo and Metaxas 1999].
Background	Optimal control techniques, introduced to the graphics community by Brotman and Netravali [1988], have been used with success by Pandy and Anderson [2000] for simulating human lower body motions such as optimal height jumping and walking.
Background	Running times were far from interactive, but show that optimization techniques can produce realistic motion for systems of human-level complexity.
Background	Preexisting motion data can simplify the optimization process.
Background	Full scale human motion can be optimized when closely spaced keyframes are available [Liu and Cohen 1995] or when only transitions between existing motion segments are required [Rose et al. 1996].
Background	Popović and Witkin [1999] have shown that significant changes to motion capture data can be made by optimizing with a physically based objective function when the character is reduced to the degrees of freedom most important for the task.
Background	When physics does not dominate the motion, kinematic techniques can give the animator interactive control for motion editing (e.g., [Gleicher 1997] [Lee and Shin 1999] [Arikan and Forsyth 2002]).
Background	The idea of physically valid motion has appeared in both graphics and robotics.
Background	Dynamic filters have been developed for processing motion capture data for physical correctness [Yamane and Nakamura 2000] [Dasgupta and Nakamura 1999] [Pollard and Reitsma 2001].
Background	Physics constraints have been used to plan biped walking motions, exploiting the idea that dynamic equilibrium can be maintained by ensuring that the zero moment point (ZMP)—the point on the ground at which ground reaction moments about horizontal axes are zero—lies within the support polygon of the feet [Vukobratović 1970] [Takanishi et al. 1985] [Nagasaka et al. 1999].
Background	Similar ideas have also been developed in graphics by [Ko and Badler 1996], who bend the torso of a character to reduce torques at the desired ZMP, and [van de Panne 1997] who ensure that reasonable forces are available to accelerate the center of mass without creating angular acceleration.
Background	Liu and Popović [2002] show that some dynamic effects can be preserved by enforcing patterns of linear and angular momentum, which does not require computation of dynamic parameters such as contact forces and joint torques.
Result	We add to this body of work the insight that it is possible to incorporate constraints on physics as efficiently as constraints on kinematic parameters and an O(D) algorithm for computing first derivatives of a broad range of physics constraints for improved performance in a optimization context.
Background	Constrained optimization has been shown to be a very powerful approach for obtaining appealing dynamic motions from a minimal amount of input information.
Background	The user adjusts the problem description in the form of keyframes, constraints, and objectives; an optimizer computes an optimal animation given this problem description; and the process repeats until the user obtains a final animation ( Figure 2 ).
Method	We use cubic B-splines as basis functions and follow the standard approach of enforcing constraints at a fixed set of points in time (t i ).
Method	Enforcing physics constraints or minimizing a dynamic property such as sum squared joint torques requires an inverse dynamics computation at each time t i .
Background	Although the inverse dynamics computation is relatively expensive, many efficient algorithms exist, and the process is well known to require time linear in the number of degrees of freedom of the character.
Method	However, typical choices for the numerical optimizer in Figure 2 also require derivatives of the constraints and objective function.
Background	For example, the sequential quadratic programming algorithm used in [Witkin and Kass 1988] makes use of first derivatives of the constraints (the constraint Jacobian) and both first and second derivatives of the objective function (the Jacobian and the Hessian).
Method	This paper describes how a broad range of physics constraints can be expressed based on aggregate forces and torques applied to the character, and how expressing physics constraints in this way allows us to compute the constraint Jacobian in linear time (Section 4).
Method	We used an objective function that enforces smooth motion, with a linear time Jacobian computation and a constant Hessian.
Result	With this objective function and our linear time algorithm for computing the constraint Jacobian, we are able to show that physically based optimization can be performed for a 22 degree of freedom character at interactive speeds.
Method	Constraints that enforce physical validity can be formulated as linear equality or inequality constraints on aggregate force.
Method	The aggregate force is a representation of all external forces and torques (excluding gravity) that would have to be applied to the character root to explain the character’s motion.
Method	We classify the physics constraints for the motions in our examples into the categories of flight, bar contact, and ground contact.
Method	One way of enforcing correct physics during flight is to ensure that the aggregate momentum of the body remains constant throughout the flight phase.
Method	Unfortunately, the constraint Jacobian that results from constraining momenta is denser than necessary as the control points that determine take-off affect all constraint equations governing the flight phase.
Method	A more elegant solution is to restrict illegal forces during flight.
Method	During flight, no forces, with the exception of gravity, may be derived from the environment.
Method	Let the aggregate force be denoted by f 0 .
Method	(In the spatial notation used here, f 0 contains both linear forces and torques.
Method	) The flight constraint is thus f 0 = 0.
Method	When the character is swinging on a high bar or monkey bars, the amount of torque that can be applied about the bar axis is constrained.
Method	Aggregate force is translated to a constraint point c as follows:
Background	During ground contact, the feet can only push, not pull on the ground, contact forces should not require an unreasonable amount of friction, and the center of pressure must fall within the support polygon of the feet.
Method	These effects can be modeled with equations that constrain the linear and angular forces separately.
Method	We constrain the linear force using Coulomb’s contact model.
Background	Coulomb’s model dictates that the linear reaction force must fall within a friction cone oriented along the contact normal with angular half-width tan −1 μ , where μ is the coefficient of friction.
Method	The magnitude of the normal force can be constrained as follows:
Method	Contact torques are constrained by geometrically confining the center of pressure to the support area.
Method	Let T x and T y be orthogonal vectors spanning the rectangular support, and let δ x and δ y be the distances from c to the edge of the support along along T x and T y respectively.
Method	The torques about T x and T y may be constrained as:
Method	Once all physics constraints have been expressed as constraints on aggregate force, computing derivatives on the physics constraints becomes a problem of differentiating aggregate force with respect to the free parameters of the problem.
Method	At any time t, character position q, velocity q,  ̇ and acceleration q  ̈ are known.
Method	The derivative of interest can be expressed in terms of q, q,  ̇ and q  ̈ using the chain rule:
Method	The term ∂ f 0 / ∂ q, which we will refer to as the force Jacobian, is the most difficult term in this expression.
Method	The main point of the paragraphs below is to show how the force Jacobian can be computed efficiently.
Result	1 We show that straightforward analytical computation of the force Jacobian would require time quadratic in the number of degrees of freedom of the character.
Method	However, if joint torques are not required, then this value and first derivatives for constraints based on this value can be computed in linear time.
Result	To our knowledge, our paper is the first to present a linear time algorithm for computing the force Jacobian for an articulated character or robot.
Method	Our argument and implementation is constructed around a NewtonEuler formulation of inverse dynamics.
Method	We use spatial notation as in Featherstone [1987] for conciseness.
Method	Spatial notation involves 6-dimensional vectors, 6x6 coordinate transformations, and 6x6 inertia tensors.
Method	It combines linear and angular quantities such as force and torque or linear and angular velocity into single vectors, as shown in Equations 1 through 3.
Method	Efficiently computing ∂ f 0 / ∂ q, the force Jacobian, requires efficiently computing ∂ p 0 / ∂ q, the momentum Jacobian, because aggregate force f 0 is the time derivative of aggregate momentum p 0 .
Method	We begin with a discussion of the momentum equations and present an argument that the momentum Jacobian can be computed in linear time.
Method	The usual way to compute aggregate momentum is to formulate the following recursion:
Method	Velocities v i are propagated from base to leaf, and momentum p i is propagated from leaf to base.
Method	Parameter q i appears in the coordinate transforms X i i+1 and X i+1 i , and so every v j for j > i depends on q i , and every p j for j ≥ 0 depends on q i .
Method	Unrolling the recursion to collect terms for ∂ p 0 / ∂ q i requires O(D) time.
Method	There are D terms q i , and this approach will lead to an O(D 2 ) computation for the momentum Jacobian.
Method	There is no clever way to simplify the calculation by aggregating terms when it is presented in this form.
Method	We observe that rewriting the recursion solves this dilemma:
Method	The key thing to notice here is that p ∗ i is expressed as a function of v i , which is a local variable at link i.
Method	As a result, only propagation from leaf to base is required, and each parameter q j does not affect terms computed for joints j + 1 and beyond ( Figure 4 ).
Method	Also note that p ∗ i is in general not equal to p i if i = 0.
Method	A term superscripted with an asterix should be treated only as an intermediary quantity, unless its subscript is zero in which case it is the desired aggregate result.
Method	A linear time expression for the momentum Jacobian can be derived in a straightforward manner based on this form of the recursion.
Method	Aggregate momentum p 0 and the momentum Jacobian are exactly the same in both formulations.
Method	This equation has the properties we are looking for.
Method	Velocity v i and acceleration a i are local to link i, and terms are propagated from leaf to base only.
Method	Note that as with aggregate momentum, f ∗ i is in general different from the actual joint force f i if i = 0.
Method	Numerically the partial derivatives are identical.
Method	The articulated model is a serial chain ranging from 3 to 50 links.
Method	As expected, the proposed method is linear in the degrees of freedom, while direct differentiation shows quadratic growth.
Method	It is also observed that despite overheads in computing aggregate intermediate terms, the linear time method shows a computational advantage with as few as 5 degrees of freedom.
Problem	One possible reason is that there is a cost to this approach that may be higher for robotics applications than for graphics applications.
Method	In a standard Newton-Euler formulation, force parameter f i (Equation 17) contains all of the joint force information for joint i, in particular forces in the actuated directions of motion (joint torques).
Background	In robotics, this information must be computed because it corresponds to signals sent to the motors of the robot.
Background	It must in general also be part of optimization routines, because en- ergy consumption and joint torque limits are of particular concern when operating a robot, and none of the joints can be ignored.
Method	In contrast, we argue that for animation of human motion, many of the effects we expect to see in physically based optimization do not depend on joint torques.
Problem	We believe that physical correctness and optimization functions enforcing smooth motion are sufficient to obtain many natural characteristics of human motion.
Problem	If some torques (e.g. torques at the hip joints) are found to be important, it seems quite certain that many others (e.g. torques at the fingers) can be ignored for many motions.
Method	If a subset of K torques are required, it is straightforward to extend our approach to measure torques at these joints in O(KD) time.
Method	One traditional approach is to use the integral of the sum of squared joint torques to produce a motion that approximately minimizes energy expenditure:
Method	This function is expensive because computing its gradient requires O(D 2 ) work.
Method	Adopting this function would negate our effort in constructing efficient physics constraints.
Method	An objective function that we have found to work well is to minimize the integral of the sum of squared, weighted joint accelerations:
Method	For example, the weight for the left-knee during a left-legged support is the entire body mass minus the left lowerleg.
Method	Parameters q  ̈ i do not include translational or rotational acceleration of the character root.
Method	Note that the analytical Hessian for this objective function is constant, symmetric, positive definite, and band-diagonal.
Method	Where a reference motion q R (t) is available, a simple objective function with low cost is to simply minimize the distance from the reference motion:
Method	This objective function is similar to the one used in Gleicher [1997].
Method	Other objective functions we have attempted include an integral of squared contact forces:
Method	The Jacobian of this function is computable in linear time; our physics constraints are based upon it.
Method	Gaits generated using this function have a certain ‘tip-toe’ quality to them, as the function minimizes the amount of reaction force derived from the contacts.
Method	Minimizing contact jerk (the time derivative of force) can be achieved using forward differences:
Result	Note the looser tuck and the higher flight trajectory in the 0.8s motion.
Result	The initial motion (shown in the top row of Figure 6) appears very unstable at landing.
Result	The character would fall over.
Result	This effect is eliminated in the optimization by enforcing the physics constraints of ground contact.
Result	Details of the optimization setup are in Figure 7 .
Result	All timing information is for a 750 MHz Pentium 3 computer.
Result	No touch-up was done on the results.
Result	In particular, the geometry of the monkey bars and the pegs was not modeled.
Result	In these examples, notice the swinging of the legs and arms, as well as body roll, pitch, and yaw.
Result	All of these effects are obtained as a result of the optimization process.
Result	In these examples, the initial motion is rigid translation of the entire character.
Problem	Our goal was to require a minimal amount of information from the animator.
Method	To set up these examples, we used 15-30 control points per degree of freedom.
Result	We found that a number of time slices (for constraint evaluation) equal to the number of control points produced good results and did not need to adjust this value for individual motions.
Result	Finer time slices would overly constrain the system, and sparser time slices allowed too much freedom for error.
Method	Each motion was set up using a constraint configuration file containing the information listed in the tables.
Method	In general, the initial motion was determined directly from constraints, with no additional user input, using linear interpolation between constrained poses.
Method	The exception was initial control points for the character root in the first example, which were set to create the overall body rotation required for the backflip.
Method	To automatically compute initial motion in a constrained pose, all joints are set at zero angle, the character is in a vertical posture, and the relevant end effector is placed at a user-specified point (e.g. hand at a specific point on the monkey bars).
Method	The vertical ”zero posture” had arms up for the bar swings, legs out for the monkey bars, and arms down for the ground motions.
Method	The high bar final pose was the only pose provided as a constraint in these examples.
Method	To empirically test the advantage of our method for fast derivative computation, we ran the peg example (bottom row of Figure 6) 5 times, each time with the identical setup except that a different technique was used to compute all required first derivatives.
Method	Two implementation issues were especially important for achieving the results described in this paper.
Method	First, we note that if the basis functions have local influence, the vector and matrix quantities computed during optimization are very sparse.
Method	We use the publicly-available Lancelot optimization package [Conn et al. 1992] where sparsity is accounted for by groupseparability.
Method	Second, we outline the issue of rerooting.
Method	Implementing any inverse dynamics algorithm requires selecting a character root.
Method	An ability to move the effective root to different parts of the character is very convenient.
Method	In the swing example of Figure 1 , it may be convenient to root the character at the hands for the swing, at the center of mass for flight, and at the feet for landing.
Background	In a Newton-Euler inverse dynamics formulation, rerooting is typically done by changing parent / child relationships, which requires inverting joint angles and transforms at each joint and altering the flow of dynamic terms from leaves to root.
Method	Both of these changes complicate the problem description presented to the optimizer.
Method	The effective root can be relocated more easily, however, by leaving the actual root and the flow of the dynamics computation fixed and computing velocities and accelerations at the root to maintain the desired constraint.
Result	This paper contributes to physically based optimization by defining and exploring a restricted class of optimization problems where physics constraints are included and first derivatives of constraints and objective functions can be computed in linear time.
Result	The fact that first derivatives can be computed in linear time instead of quadratic time suggests that our problem is simpler than previous physically based approaches and similar in complexity to very successful kinematic approaches such as minimizing distance to a reference motion.
Result	We suspect that our solution landscape will be smoother than previous physically based optimization approaches, making it feasible to handle more complex characters.
Result	When the optimization does not converge, we can usually trace it back to the problem setup.
Result	Sometimes it is due to overconstrained equations (setup error).
Result	But often it is due to overly restrictive parameters, such as friction coefficients, joint limits, poor selection of timings, etc.
Method	At present, timings are set by the user and their values need to be reasonable (e.g., the character cannot leap too far in too short a time).
Result	Any optimization technique that makes use of local derivatives has potential problems with local minima.
Result	Our experience, however, was that as long as an expected motion sequence could be thought of as motion about some neutral position, then when the character was started in that neutral position there was no problem descending toward the expected minimum.
Result	We were able to create a jumping Luxo and highly dynamic human motions with good success.
Result	For less dynamic activities, our system would require additional input; physics constraints plus smooth motion would not in general produce the desired results.
Result	” Given this problem definition, our system would identify a static pose near the initial guess where the projection of the center of mass is in support area.
Method	Additional information would be required to fill in the details of the standing motion.
Method	For activities where joint torque limits are important, this torque information must be taken into account to produce good results.
Result	An extreme example of this situation is the passive swing of a multilink chain.
Result	Minimizing accelerations while maintaining physics constraints would produce a result that was valid for the body as a whole but would require non-zero torques at the joints—no whipping motion would be seen.
Result	Minimizing sum squared torques would produce the desired results.
Result	(Of course, truly passive motion can be created much more easily using forward dynamic simulation.
Result	) More commonly, a limited set of torques or energy terms may be important.
Result	For example, the peg running motion appears very athletic because it would require high torques at the knee and hip joints.
Result	When physical parameters at certain joints are identified as important, our method can be extended to provide and differentiate these parameters for any K joints with running times of O(KD), reaching the expected bound of O(D 2 ) when all joint torques are required.
Future Work	An interesting research problem is to determine automatically when torques at a given joint should be considered.
Result	Running on flat ground shows a combination of difficulties.
Future Work	To make this motion appear more natural, we would need to consider proper timing for the running stride, a more accurate foot model, torques at some of the joints, and perhaps also aspects of style that are not driven by physics or energy.
Result	Complexity in the number of degrees of freedom of the character is not the only concern in physically based optimization.
Result	The number of free parameters of the optimization problem also grows linearly with total time allotted for the animation.
Background	We have not yet attempted any long motion sequences, but we note that Liu, Gortler, and Cohen [Liu et al. 1994] have shown that time complexity can be effectively managed in an optimization context, in part because the influence of any one parameter is localized in time.
Method	It is interesting to compare our approach to that of Liu and Popović [2002].
Background	Their paper describes the power of patterns (e.g., momentum patterns) in creating desirable animation effects, and their approach could be adapted easily to obtain linear time performance by rewriting the momentum equations as described in Section 4.2 of this paper.
Future Work	The idea of dynamic patterns is an exciting one.
Future Work	However, relying on momentum patterns without computing interaction forces between the character and the environment may result in problems with certain types of physics constraints (e.g., keeping forces within a friction cone) when the initial motion is not favorable.
Result	In the present paper, we show that it is possible to optimize motion with physics constraints in an efficient manner, so that reasonable friction conditions, for example, can be easily enforced.
Result	We believe the combination of correct physics and knowledge of natural dynamic patterns of human motion such as momentum or movement of the center of pressure in the roll of the foot on the ground could be very powerful.
Result	Finally, we would like to emphasize that the main advantage of our approach may be as part of a more complete animation system.
Result	Our vision is that the ability to enforce physics constraints efficiently should be just one of the tools available to the animator.
Future Work	Details of the desired motion could be fleshed out using motion capture data, procedural techniques, keyframes, and/or objective functions appropriate to the specific task.
Result	We have shown that physics constraints can be enforced in an efficient manner.
Future Work	Incorporating physics constraints into traditionally kinematic animation approaches is one direction of future work.
Method	For rotational joints, joint axis s i is represented as follows:
Method	Both terms are expressed in the body i local frame, and the superscript on s i indicates that the spatial vector is expressed in body i local frame coordinates.
Method	We represent multiple degree of freedom joints as sequences of single degree of freedom joints, connected by massless and inertialess bodies.
Method	Spatial force also combines linear and angular quantities:
Method	Spatial transform X i j takes spatial quantities from frame i to frame j:
Method	Spatial inertia represents both body mass and rotational inertia:
Method	Where superscripted with an asterix (e.g., I ∗ i ) the quantity represents aggregated information accumulated from L to i.
Method	The equations of motion of a serial multibody chain are compactly expressed in recursive form as follows:
Method	The Newton-Euler equations propagate quantities in two directions.
Method	Compute:
Method	I ∗ 0 and p ∗ 0 are the aggregate inertia and momentum of the entire body, and p ∗ 0 is equal to p 0 computed from the previous NewtonEuler recursive equations.
Method	However, p ∗ i is in general not equal to p i where i = 0 and should only be used as an intermediary quantity in computing the aggregates.
Method	As before, f ∗ i is in general not equal to f i where i = 0.
Method	The Jacobian may be constructed in time linear in the number of degrees of freedom as follows.
Method	All partial derivatives are expressed in frame i.
Method	Suppose we wish to place the effective root of the character at the point on body i that is located at point r in body i coordinates.
Method	We wish this point to have linear velocity b r,des and linear acceleration b  ̇ r,des , expressed in the world coordinate frame.
Method	The current velocity of body i in the body i frame is v i .
Method	In Equation 51, v b r is the linear velocity of the effective root expressed in world coordinates.
Method	This velocity should be b r,des .
Method	To obtain the correct velocity at the effective root, simply add the desired correction (b r,des − v b r ) to the reference frame velocity:
Method	The adjustment to a 0 is derived using similar reasoning.
Method	When these changes are made, the actual character root can remain at the pelvis, for example, while the effective root is moved from hand to pelvis to foot or other bodies as needed.
Method	The effective root can even be set to the center of mass to obtain correct ballistic motion during flight.
Method	Derivatives of all equations with respect to parameters describing the motion can be computed in O(D) time.

Problem	Choosing the adequate method should be done with full knowledge of the advantages and weaknesses of the main techniques.
Result	This paper presents a quantitative comparison of the efficiency of the most common integration techniques used for cloth simulation, and raises the key considerations for optimal implementations depending on the practical kind of simulation problematic.
Problem	The correct choice of the simulation method and its implementation is a very important issue in the design of an efficient cloth simulation system.
Background	Among the available methods, there are finite elements methods [ EIS 96 ], continuum mechanics [ TER 87 ] or particle systems [ BRE 94 ].
Method	We will focus on the latter, which has shown to bring the best compromise between accuracy and speed for highly deformable objects such as cloth [ VOL 95 ] [ VOL 97 ].
Background	A particle system represents the mechanical system as a set of punctual masses.
Background	The cloth surface shape is represented by the geometry between neighboring particles.
Background	The mechanical behavior is represented as interaction forces between the particles, which depend on the relative position and speed of the particles, measuring deformation and deformation speed.
Background	Various models exist for this representation, which rank from the simple spring-mass representation (spring forces between particle couples depending on the distance between the particles) to accurate surface or volume models (involving complex interactions between several neighboring particles).
Background	The laws ruling these interactions also rank from linear to highly nonlinear involving discontinuities and hysteretic curves.
Background	The evolution of the system is computed numerically from these equations that form a large and sparse ordinary differential equation system, which, through adequate modeling, is also first-order.
Background	This numerical system has to be integrated numerically, for finally obtaining the evolution of the mechanical system along time, usually as a sequence of successive positions of the object along regular time intervals.
Problem	The aim of this study is not to describe the implementation of these methods, which has already been carried out extensively in [ EBE 96 ] [ VOL 97 ] [ BAR 98 ] [ VOL 00 ], and with some adaptations in [ DES 99 ] [ EBE 00 ] [ KAN 00 ].
Problem	It rather intends to evaluate quantitatively the performance of the main integration methods in terms of speed and accuracy.
Method	Using a “typical” cloth object made of a common fabric material, we compare the computation speed and accuracy of each integration methods depending several simulation contexts, giving the reader an overview of the performance he can expect from each method.
Problem	The choice of the adequate integration method has to be carried out using various considerations related to the kind of problem to be simulated.
Background	The literature is abundant about various integration methods which aim to solve linear systems of first-order ordinary differential equations [ PRE 92 ].
Problem	One can easily turn the second-order systems relating dynamical mechanical systems into first-order systems by constructing a state vector defined by the concatenation of position and speed states of the system, such as to fit the requirements of any of these algorithms.
Method	We shall restrict our consideration to three different methods which explore the range of these classes, and which seem to fit the best the requirements set for cloth simulation problems, in terms of implementation simplicity and efficiency for particle systems using large numbers of particles that interact sparsely and with a constant topology.
Background	It requires two mechanical derivations per iteration and returns a second-order accurate solution relative to the time step.
Background	It also requires two storages of the state vector.
Method	We preferred this method to the still simpler first-order Euler method, because of the obvious gains of accuracy and stability which, despite the additional mechanical evaluation, makes it largely more efficient.
Method	We implemented this method for garment simulation in [ VOL 95 ].
Background	It requires five mechanical derivations per iteration, as well as five storages of the state vector.
Background	This method is supposed to provide high accuracy, which increases significantly as the time step is reduced.
Background	This method was experimented in [ EBE 96 ] and [ VOL 97 ].
Background	It requires one mechanical evaluation and the resolution of a sparse linear system per iteration, as well as one storage of the system state additionally to those required for the system resolution algorithm.
Background	This method is supposed to provide approximate results that are not subject to numerical instability as the time step is increased.
Method	We implemented this method combined with a Conjugate Gradient algorithm using linear system matrix products computed on the fly, as described in [ VOL 00 ], and thus able to take into account the anisotropy and nonlinearities of the mechanical model as the actual Hessian matric is used for each current state of the mechanical system.
Background	No initial matrix setup is required, suppressing also the need of separating linear and nonlinear components as discussed in [ EBE 00 ].
Method	We have also carried out some preliminary tests with the Rosenbrook method, which is an implicit implementation of a fourth-order Runge-Kutta method.
Background	It is supposed to combine the stability of implicit methods with the accuracy of high-order methods.
Result	We implemented this method using the algorithm described in [ PRE 92 ], but preliminary experiments have shown very deceptive results, and the gain of accuracy did not compensate the large calculations required for each iteration, whereas increased instability problems did not allow time steps much larger than those used for good accuracy with backward Euler.
Method	We did not consider in our tests the methods aimed toward simplifications which might highly approximate and degrade the dynamic behavior of deformable models, such as implicit integration with precomputed inverse matrices [ DES 99 ] which involves high simplification and linrarization of the Hessian matrix and which also becomes very unpractical for large matrix sizes (the inverse of a sparse matrix is not necessarily sparse).
Result	We simulated such algorithm using accurate resolution on an accordingly approximated constant matrix, and we found that these approximations produced more simulation errors (on dynamic behavior of wrinkles and motion damping particularly) than producing a quick and rough linear system solution using a reduced number of Conjugate Gradient iterations with an accurate matrix.
Background	Even more drastic simplifications [ KAN 00 ] reduce the matrices to their diagonal component.
Method	Bending is also implemented, but not taken into account in this study.
Method	The base element of this simulation is a triangle of the mesh describing the surface, and the elasticity laws are computed as interactions between the three vertices of a triangle reflecting all the mechanical behavior curves which, for this study, are restricted to be linear.
Method	This model is one of the simplest that a cloth simulation application would use.
Method	The implementation also supports collision detection and response, which were disabled for these tests.
Method	An object-oriented framework written in C++ integrate all these technologies into a single application allowing simulation of cloth objects of any shape with specified parameters.
Method	The application is run on a SGI Octane having a 200 MHz R100000 processor, and enough memory for working without swapping.
Method	Performance timings are done on the mechanical computation only, and do not take into account display and data structure management.
Background	Performance is a key issue in choosing the adequate integration method, as cloth simulation usually involves very large mechanical systems described by a huge number of variables, and the numerical resolution of the system is therefore critical to the total computation time.
Method	This depends on the complexity of the method, and also related to the number of times the forces of the system have to de derived from the system state using the laws of mechanics.
Method	Accuracy increases along with time step reduction as better as the method is high-order.
Method	These factors describe our investigation field in the following sections.
Background	The total computation time is the time required for computing one iteration times the number of iterations.
Method	Our first investigation is to evaluate the iteration computation time for each of these methods.
Method	For these measurements, we have simulated a square of fabric with a given discretization both with the accurate and simplified models, using the Midpoint, the RungeKutta and the Backward Euler methods, with 1, 2, 4, 8 iterations in the Conjugate Gradient algorithm for the latter, and measured computation time (Fig.1).
Result	With one iteration only, it is barely worse than the very simple explicit Midpoint method.
Method	Our implementation, described in [ VOL 00 ] does not explicitly construct the matrix of the system to be resolved by the Conjugate Gradient, but computes “on the fly” the product of this matrix with vectors when needed by the Conjugate Gradient algorithm.
Result	This gives a very efficient implementation when using a low number of Conjugate Gradient iterations (no heavy preprocessing for building the matrix), which is often sufficient for most applications.
Method	These tests will help us to choose the method that gives the best compromise between accuracy and computation speed, as discussed in the next section.
Method	For measuring accuracy and numerical stability of the algorithms, we need to set up a “standard” material on which the experiments are carried out, as well as the rules allowing to extrapolate the results to any material of different size and parameters.
Method	In the scope of our study, we restrict the experimentation to linear metric elasticity of an isotropic cloth material, described by a Young modulus E and a surface density d.
Method	For the simulation, the surface square is discretized into elements which roughly have the length l, and the computation is carried out with time steps of size t.
Method	We checked experimentally with our implementation that any scaling of a simulation along distance, time and mass which leaves K unchanged does not change anything to the simulation result.
Method	A typical cloth simulation problem could involve a cotton fabric cloth surface, which typically have a density d = 0.1 kg.m -2 and a Young modulus E = 2 0 N .
Method	Given a discretization into elements averaging one centimeter and a simulation time step of ten milliseconds, the condition coefficient of the problem computed with (1) is K = 2 0 0 .
Method	It is possible to define similar coefficients related to bending and viscosity modulus.
Method	The corresponding K coefficients are respectively multiplied by additional l -2 and t factors.
Method	In simulations that consider simultaneously all these forms of mechanical behaviors, the dominant K coefficient rules the “numerical difficulty” of the problem.
Method	In such kind of simulation, the interest is to reproduce exactly the motion of a cloth object along time, the accuracy of its evolution being the key of the realism of an animation involving simulated cloth.
Method	When using implicit methods, we perform a preconditioning of the system state variables of the linear system to be resolved using the inverse square root of the mass of the corresponding particle.
Method	This allows the iterations of the Conjugate Gradient algorithm to distribute the resolution numerical errors as evenly as possible between the particles, so that to obtain for instance a fall speed that does not depend on the mass of the particle.
Method	We measure the time it takes for this fabric piece to fall a height of 1 m .
Method	Without any additional external forces considered (no aerodynamic interactions), we expect this to happen in a constant time of 0.45 s.
Result	Several interesting facts arise from this experiment.
Result	As a matter of numerical stability, the Midpoint method supports K values up to almost 3 whereas the RungeKutta method supports K values up to almost 100.
Result	This indicates that with Runge-Kutta, it is possible to use simulation time steps which are almost six times larger than with Midpoint.
Result	Given the fact that a Runge-Kutta iteration takes only three times more computation than a Midpoint iteration (Fig.1), the Runge-Kutta method seems to be computationally two times more efficient than the Midpoint method.
Result	As a matter of simulation accuracy, both Midpoint and Runge-Kutta seem to preserve accuracy correctly within their range of numerical stability.
Result	While the implicit Euler method seems stable for any K value, its accuracy is however very degraded by high K values and reduced numbers of Conjugate Gradient iterations.
Result	More precisely, we see that accuracy is well preserved with one Conjugate Gradient iteration up to a K value of 4, and increasing the iteration number n times also increases the K value n 2 times for the same accuracy.
Result	From this, we can see that the Inverse Euler method needs at least four Conjugate Gradient iterations to reach the accuracy of the Runge-Kutta method.
Result	We also see that similar requirement of accuracy bring the two methods in parity in terms of computation time (Fig.1).
Method	However, it should be noted that the experiment was carried out using a uniformly discretized mesh, and uniform mechanical parameters.
Result	Real-world simulations do not have this regularity, and numerical instability with explicit methods occur in the stiffest regions of the mesh, which, even if they are marginal in the whole mechanical system, may totally “explode” and destroy the simulation and therefore will rule the size of the largest time step possible.
Method	With implicit methods, the resulting inaccuracies may be unnoticed when taking a time step adapted to the average stiffness.
Result	Anyhow, this experiment shows clearly that when accurate reproduction of dynamic motion is required, it is not possible to increase the time step of implicit methods as much as desired, as this cause very noticeable inaccuracy as weak forces will be “neglected” relatively to stiff forces.
Result	While this is not an issue for draping problems where only the final state is desired, this aspect has to be taken into account when accurate reproduction of the whole evolution is wanted.
Method	Considering a simulation involving elements n times smaller, maintaining accuracy and stability (preserving K constant in formula (1)) would require a time step n times smaller, and therefore n times as many iterations for simulating the mechanical system along a constant duration.
Method	Given the fact that there are also n 2 times more elements to handle, the total computation time is finally multiplied by a drastic n 3 (even n 4 if curvature stiffness rule the simulation accuracy).
Result	While this factor is what cause explicit methods to become so inefficient with refined discretizations as this scaling has to be strictly observed for preventing instability, implicit methods are a bit more tolerant if only “visual” accuracy matters, accuracy which is not related to the size of the elements.
Background	Draping is another context of simulation, where only the final static equilibrium state of the mechanical system is to be computed.
Method	Here, the interest is to converge to the equilibrium state as quickly as possible, with minimum computation charge.
Method	As the full evolution of the cloth along time is not an interest, accuracy can be traded away for computation speed.
Method	From the dynamic study described above, implicit methods should be quite strong on this point, as they do not suffer from numerical instability, and allow large time steps to be used at the expense of dynamic accuracy which can here be neglected.
Method	Without any damping, we expect that in its first oscillation, the fabric reach a roughly vertical position after slightly more than half a second.
Method	Our purpose is here to find the computation time necessary to obtain the fabric in its vertical position.
Method	For this, we count the number of computation iterations necessary for obtaining the fabric in its vertical position in its first oscillation, not being interested by the realism of this motion (Fig.5).
Result	Our first finding is that the explicit methods seem quite not adapted for draping.
Result	The backward Euler method is robust enough to handle the problem without instability for any time step.
Result	However, we see that larger time steps do not proportionally translate into fewer steps for performing the draping.
Result	As the time step becomes larger, and as the corresponding K coefficient exceeds the theoretical limit observed in the previous section, we quickly observe a “saturation” of the number of iterations to a constant which seems to be inversely proportional to the number of Conjugate Gradient iterations that were performed.
Result	From this it is clear that when K exceeds the dynamic accuracy limit of a given implicit integration method, the time step does not really reflect a time interval anymore.
Method	In such case, the implicit method will only evaluate an approximation of the rest state of the mechanical system by linear extrapolation from the Hessian matrix, whose accuracy depends on the number of Conjugate Gradient iterations that were used to resolve the corresponding linear system.
Background	Most mechanical simulations work with numerical equations that are not linear.
Background	For instance, the strain-stress relation describing elasticity may actually be complex curves, which furthermore may take into account timedependent and hysteretic behaviors.
Background	* During the simulation, the orientation of the mechanical elements change, and this modifies the expressions of the mechanical laws in the world coordinates.
Background	While rarely causing numeric “explosions” as with explicit methods, nonlinearity may disrupt the stability of simulations integrated with implicit models with large disturbing vibrations, particularly when using large time steps that cause iterations to converge to the equilibrium state of the mechanical objects rather than simulating accurately their mechanical behavior.
Background	This can for instance be observed when simulating stretched flat surfaces without curvature forces.
Background	The reason for that is that the hypothetical equilibrium state is derived from the knowledge of the Hessian matrix, which relates the firstorder evolution of the forces as the deformations change.
Method	Nonlinearity causes this matrix to change between the successive iterations, and this evaluation to be inaccurate, despite high system resolution accuracy that can be reached with numerous Conjugate Gradient iterations.
Method	The solution for this is to approximate the Hessian matrix for taking into account the changes that may be observed from the change of the system state between successive iterations.
Method	While an underestimation of de derivatives may lead to an equilibrium state valuation too far from the current state, and by this cause instability, an overestimation of the derivatives will place this evaluation nearer to the current state, therefore stabilizing the simulation, at the expense of extra numerical damping and slow convergence.
Method	This is particularly true for drastic linearisations as for example used in [ DES 99 ].
Method	Knowledge of the expected state changes between successive time steps are required to perform this approximation correctly.
Method	With nonlinear mechanical behavior, one solution is to take the steepest parts of the curves as derivatives, whereas for the element orientation problem, isotropic derivatives considering force evolution equally in any directions may be considered.
Result	However, the more drastic these approximations are, the less accurate the simulation will be for dynamic simulations, and the slower the simulation will converge for draping problems.
Background	A nice solution described in [ EBE 00 ], which makes sense when efficiency relies on the use of a constant Hessian matrix, is to perform the implicit resolution on a linear constant approximation, and to simulate the nonlinear and variable component, unlikely to cause stiffness problems, using an explicit method.
Method	In order to test the efficiency of our model in the context of garment animation, the algorithms have been integrated in a 3D design framework allowing the management of complex garment objects in interaction with animated virtual characters.
Method	This integration has been carried out in the form of a 3DStudio Max plugin (Fig.6), running on a 500 MHz PentiumIII PC.
Method	We have simulated a 2000 Polygon garment made of the cotton material described in Section 3.
Method	The mesh elements are roughly five centimeters in size, and therefore the resulting condition coefficient K is roughly 8 with a simulation time step of 10 milliseconds.
Method	This is a draping problem involving to obtain a rest position of the garment as quickly as possible.
Method	The dynamical motion of the cloth is important here.
Result	The garment assembly and seaming operations could be performed almost four times faster with the Backward Euler (2 minutes) than with Runge-Kutta (8 minutes), knowing that collision detection and response account for more than the half of the computation time, and actually limits the time step size when contact starts between the cloth and the body.
Result	For the dynamical animation, comparable accuracy could be obtained between Runge-Kutta and Backward Euler using eight iterations of the Conjugate Gradient, which gave similar computation times.
Background	Recent literature has emphasized on the relevance of implicit methods for cloth simulation.
Result	The implicit Euler method seems effectively a good candidate for most situations involving cloth simulation, because of the robustness resulting from not being prone to numerical instability.
Method	This is particularly true when simulating very heterogeneous mechanical systems (elements of various sizes and various mechanical properties) where, using explicit models, the most critical elements would rule the time step size for all the simulation.
Result	Contrary the perception of the implicit model iteration being slow because of the linear system resolution it involves, the inverse Euler iteration often proves to be faster than the explicit Runge-Kutta method of higher order, if an adequate approximate linear system resolution is implemented.
Method	A limited number of Conjugate Gradient iterations seems suitable for this.
Result	Furthermore, while increasing the time step seems not limited by instability with implicit methods, it should be kept in mind that this is still done at the expense of accuracy of the whole simulation.
Result	The number of iterations should also be set sensitively to the stiffness of the mechanical problem, for limiting the potential inaccuracies that become particularly visible when an accurate simulation of a dynamical system is wanted.
Result	There is an obvious advantage of using implicit methods, and particularly the inverse Euler method, for draping problems where quick convergence to a rest position is required quickly.
Result	Our test have shown that the inverse Euler method allow to perform a draping problem almost ten times as fast as with the Runge-Kutta method.
Result	While not exactly reproducing real mechanical behavior, the simulation with large time steps provides a quite efficient convergence to equilibrium, and the numerical errors quite often act as extra damping, removing the need of adding them explicitly to the model.
Result	For dynamic problems where accurate evolution of the mechanical system along time is needed, the advantage of implicit methods is less obvious.
Result	Their stability gives a false sense of efficiency, allowing obtaining quickly a result by “cheating” on the time step size.
Result	These artifacts are still augmented by the approximations made to the Hessian matrix, possibly in the purpose of reducing instability, while excessive reduction of the Conjugate Gradient iterations produce additional inaccuracy and slow convergence.
Result	It seems that there is still some benefit in using the Backward Euler method than any other explicit method for dynamic simulations thanks to the reduced time it takes to compute one iteration, which also only requires one derivation of the particle forces from the state of the system.
Result	Our tests have shown a roughly doubled speed for the accuracy corresponding to the limit of stability of the Runge-Kutta method.
Result	We got substantial improvements through the implementation of the implicit Midpoint method [ VOL 00 ], which however had the drawback of increasing the numerical instability problem, forcing additional use of isotropic force gradients, at the expense of accuracy.
Result	The explicit methods have still their interest, and should be reserved for simulations requiring high accuracy and particularly those where involving low mechanical damping and where mechanical energy conservation is important.
Result	Instability concerns will force parameters and time step size to ensure good accuracy for the simulation of all particles of the discrete mechanical representation, and therefore for the entire mechanical object.
Result	This may however require prohibitive computation times for very stiff and discretized models.
Result	The 5th-order Runge-Kutta method das proven to be a good solution [ EBE 96 ] [ VOL 97 ], because of its high accuracy, and because it furthermore provides integration error evaluation, which is a very good hint to the very sensitive problem of optimal time step size determination.
Result	The simpler Midpoint method may have some interest only in very particular cases involving very loose materials with rough discretization, or when numerous fast iterations with small time steps are required for other reasons (high motion sampling, collision detection, very discontinuous models).
Result	All these considerations should be carefully taken into account when designing a mechanical simulation engine, as they are the keys to efficient simulation, and therefore complex models that, for garment simulation, express fully visual experience of real fashion models.
Future Work	We intend to pursue our investigations for dealing with damping in a more accurate way.
Future Work	This still remains an important issue to dynamic realism of cloth simulation models, which has to take into account viscosity, the dissipative effect of hysteretic behavior, as well as collision damping and friction.
Future Work	The integration methods have to be tuned to take precisely these effects into account.

Problem	The bottle-neck in most cloth simulation systems is that time steps must be small to avoid numerical instability.
Result	This paper describes a cloth simulation system that can stably take large time steps.
Method	The simulation system couples a new technique for enforcing constraints on individual cloth particles with an implicit integration method.
Method	The simulator models cloth as a triangular mesh, with internal cloth forces derived using a simple continuum formulation that supports modeling operations such as local anisotropic stretch or compression; a unified treatment of damping forces is included as well.
Method	The implicit integration method generates a large, unbanded sparse linear system at each time step which is solved using a modified conjugate gradient method that simultaneously enforces particles’ constraints.
Method	The constraints are always maintained exactly, independent of the number of conjugate gradient iterations, which is typically small.
Result	The resulting simulation system is significantly faster than previous accounts of cloth simulation systems in the literature.
Problem	Physically-based cloth animation has been a problem of interest to the graphics community for more than a decade.
Background	Early work by Terzopoulos et al. [ 17 ] and Terzopoulos and Fleischer [ 15 , 16 ] on deformable models correctly characterized cloth simulation as a problem in deformable surfaces, and applied techniques from the mechanical engineering and finite element communities to the problem.
Background	Since then, other research groups (notably Carignan et al. [ 4 ] and Volino et al. [ 20 , 21 ]; Breen et al. [ 3 ]; and Eberhardt et al. [ 5 ]) have taken up the challenge of cloth.
Background	Although specific details vary (underlying representations, numerical solution methods, collision detection and constraint methods, etc.), there is a deep commonality amongst all the approaches: physically-based cloth simulation is formulated as a time-varying partial differential equation which, after discretization, is numerically solved as an ordinary differential equation
Result	In this paper, we describe a cloth simulation system that is much faster than previously reported simulation systems.
Method	Our system’s faster performance begins with the choice of an implicit numerical integration method to solve equation (1).
Background	The reader should note that the use of implicit integration methods in cloth simulation is far from novel: initial work by Terzopoulos et al. [ 15 , 16 , 17 ] applied such methods to the problem.
Background	1 Since this time though, research on cloth simulation has generally relied on explicit numerical integration (such as Euler’s method or Runge-Kutta methods) to advance the simulation, or, in the case of of energy minimization, analogous methods such as steepest-descent [ 3 , 10 ].
Background	This is unfortunate.
Problem	Cloth strongly resists stretching motions while being comparatively permissive in allowing bending or shearing motions.
Problem	This results in a “stiff” underlying differential equation of motion [ 12 ].
Problem	Explicit methods are ill-suited to solving stiff equations because they require many small steps to stably advance the simulation forward in time.
Problem	2 In practice, the computational cost of an explicit method greatly limits the realizable resolution of the cloth.
Background	For some applications, the required spatial resolution—that is, the dimension n of the state vector x—can be quite low: a resolution of only a few hundred particles (or nodal points, depending on your formulation/terminology) can be sufficient when it comes to modeling flags or tablecloths.
Problem	To animate clothing, which is our main concern, requires much higher spatial resolution to adequately represent realistic (or even semi-realistic) wrinkling and folding configurations.
Result	In this paper, we demonstrate that implicit methods for cloth overcome the performance limits inherent in explicit simulation methods.
Result	We describe a simulation system that uses a triangular mesh for cloth surfaces, eliminating topological restrictions of rectangular meshes, and a simple but versatile formulation of the internal cloth energy forces.
Method	(Unlike previous metric-tensor-based formulations [ 15 , 16 , 17 , 4 ] which model some deformation energies as quartic functions of positions, we model deformation energies only as quadratic functions with suitably large scaling.
Result	Quadratic energy models mesh well with implicit integration’s numerical properties.
Result	) We also introduce a simple, unified treatment of damping forces, a subject which has been largely ignored thus far.
Method	A key step in our simulation process is the solution of an O(n) × O(n) sparse linear system, which arises from the implicit integration method.
Background	An ADI method generates a series of tightly banded (and thus quickly solved) linear systems rather than one large sparse system.
Background	(The price, however, is that some of the forces in the system—notably between diagonally-adjacent and non-adjacent nodes involved in self-collisions—are treated explicitly, not implicitly.
Result	) The speed (and ease) with which our sparse linear systems can be robustly solved—even for systems involving 25,000 variables or more—has convinced us that there is no benefit to be gained from using an ADI method instead (even if ADI methods could be applied to irregular triangular meshes).
Method	Thus, regardless of simulation size, we treat all forces as part of the implicit formulation.
Result	Even for extremely stiff systems, numerical stability has not been an issue for our simulator.
Method	Much of the performance of our system stems from the development of an implicit integration formulation that handles contact and geometric constraints in a direct fashion.
Method	) Our formulation for directly imposing and maintaining constraints is harmonious with the use of an extremely fast iterative solution algorithm—a modified version of the conjugate gradient (CG) method—to solve the O(n) × O(n) linear system generated by the implicit integrator.
Method	Iterative methods do not in general solve linear systems exactly—they are run until the solution error drops below some tolerance threshold.
Method	A property of our approach, however, is that the constraints are maintained exactly, regardless of the number of iterations taken by the linear solver.
Method	Additionally, we introduce a simple method, tailored to cloth simulation, for dynamically adapting the size of time steps over the course of a simulation.
Method	The combination of implicit integration and direct constraint satisfaction is very powerful, because this approach almost always allows us to take large steps forward.
Result	In general, most of our simulations require on average from two to three time steps per frame of 30 Hz animation, even for (relatively) fast moving cloth.
Result	The large step sizes complement the fact that the CG solver requires relatively few iterations to converge.
Result	For example, in simulating a 6, 000 node system, the solver takes only 50–100 iterations to solve the 18, 000 × 18, 000 linear system formed at each step.
Method	Additionally, the running time of our simulator is remarkably insensitive to the cloth’s material properties (quite the opposite behavior of explicit methods).
Result	All of the above advantages translate directly into a fast running time.
Result	For example, we demonstrate results similar to those in Breen et al. [ 3 ] and Eberhardt et al. [ 5 ] (draping of a 2,600 node cloth) with a running time just over 2 seconds per frame on an SGI Octane R10000 195 Mhz processor.
Result	Similarly, we show garments (shirts, pants, skirts) exhibiting complex wrinkling and folding behavior on both key-framed and motion-captured characters.
Result	Representative running times include a long skirt with 4,530 nodes (8,844 triangles) on a dancing character at a cost of 10 seconds per frame, and a shirt with 6,450 nodes (12,654 triangles) with a cost varying between 8 to 14 seconds per frame, depending on the underlying character’s motion.
Background	Terzopoulos et al. [ 15 , 17 ] discretized cloth as a rectangular mesh.
Background	Energy functions were derived using a continuum formulation.
Background	This work recognized the need for damping forces; however, only a simple viscous drag force −k x was used.
Background	The linear systems result- ing from the use of implicit integration techniques were solved, for small systems, by direct methods such as Choleski factorization, or using iterative techniques such as Gauss-Seidel relaxation or conjugate gradients.
Background	(For a square √ system of n nodes, the resulting linear system has bandwidth n.
Background	In this case, banded Choleski factorization [ 6 ] requires time O(n 2 ).
Background	) As previously discussed, Terzopoulos et al. made use of an ADI method for larger cloth simulations.
Background	Carignan et al. recognized the need for damping functions which do not penalize rigidbody motions of the cloth (as simple viscous damping does) and they added a force which damps cloth stretch and shear (but not bend).
Background	Later work by the same group includes Volino et al. [ 20 ], which focuses mainly on collision detection/response and uses a triangular mesh; no mention is made of damping forces.
Background	The system uses the midpoint method (an explicit method) to advance the simulation.
Background	Thus far, the accumulated work by this group (see Volino et al. [ 21 ] for an overview) gives the only published results we know of for simulated garments on moving characters.
Background	Reported resolutions of the garments are approximately two thousand triangles per garment (roughly 1,000 nodal points) [ 21 ] with running times of several minutes per frame for each garment on an SGI R4400 150 Mhz processor.
Background	Breen et al. [ 3 ] depart completely from continuum formulations of the energy function, and describe what they call a “particlebased” approach to the problem.
Background	By making use of real-world cloth material properties (the Kawabata measuring system) they produced highly realistic static images of draped rectangular cloth meshes with reported resolutions of up to 51 × 51 nodes.
Background	The focus of this work is on static poses for cloth, as opposed to animation: thus, their simulation process is best described as energy minimization, although methods analogous to explicit methods are used.
Background	Speed was of secondary concern in this work.
Background	Refinements by Eberhardt et al. [ 5 ]—notably, the use of higher-order explicit integration methods and Maple-optimized code, as well as a dynamic, not static treatment of the problem—obtain similarly realistic results, while dropping the computational cost to approximately 20–30 minutes per frame on an SGI R8000 processor.
Background	No mention is made of damping terms.
Background	Provot [ 13 ] focuses on improving the performance of explicit methods by a post-step modification of nodal positions.
Background	He iteratively adjusts nodal positions to eliminate unwanted stretch; the convergence properties of this method are unclear.
Background	A more comprehensive discussion on cloth research can be found in the survey paper by Ng and Grimsdale [ 9 ].
Method	Our simulator models cloth as a triangular mesh of particles.
Method	Given a mesh of n particles, the position in world-space of the ith particle is x i ∈ IR 3 .
Method	The geometric state of all the particles is simply x ∈ IR 3n .
Method	The same component notation applies to forces: a force f ∈ IR 3n acting on the cloth exerts a force f i on the ith particle.
Method	Real-world cloth is cut from flat sheets of material and tends to resist deformations away from this initial flat state (creases and pleats not withstanding).
Method	We capture the rest state of cloth by assigning each particle an unchanging coordinate (u i , v i ) in the plane.
Method	Collisions between cloth and solid objects are handled by preventing cloth particles from interpenetrating solid objects.
Method	Our current implementation models solid objects as triangularly faced polyhedra.
Method	Each face has an associated thickness and an orientation; particles found to be sufficiently near a face, and on the wrong side, are deemed to have collided with that face, and become subject to a contact constraint.
Method	(If relative velocities are extremely high, this simple test may miss some collisions.
Method	In this case, analytically checking for intersection between previous and current positions can guarantee that no collisions are missed.
Method	) For cloth/cloth collisions, we detect both face-vertex collisions between cloth particles and triangles, as well as edge/edge collisions between portions of the cloth.
Method	As in the case of solids, close proximity or actual intersection of cloth with itself initiates contact handling.
Background	The most critical forces in the system are the internal cloth forces which impart much of the cloth’s characteristic behavior.
Background	Breen et al. [ 3 ] describes the use of the Kawabata system of measurement for realistic determination of the in-plane shearing and out-of-plane bending forces in cloth.
Method	We call these two forces the shear and bend forces.
Method	We formulate the shear force on a per triangle basis, while the bend force is formulated on a per edge basis—between pairs of adjacent triangles.
Method	The strongest internal force—which we call the stretch force— resists in-plane stretching or compression, and is also formulated per triangle.
Background	Under normal conditions, cloth does not stretch appreciably under its own weight.
Method	This requires the stretch force to have a high coefficient of stiffness, and in fact, it is the stretch force that is most responsible for the stiffness of equation (1).
Background	A common practice in explicitly integrated cloth systems is to improve running time by decreasing the strength of the stretch force; however, this leads to “rubbery” or “bouncy” cloth.
Method	Our system uses a very stiff stretch force to combat this problem, without any detrimental effects on the run-time performance.
Method	While the shear and bend force stiffness coefficients depend on the material being simulated, the stretch coefficient is essentially the same (large) value for all simulations.
Method	(Of course, if stretchy cloth is specifically called for, the stretch coefficient can be made smaller.
Method	) Complementing the above three internal forces are three damping forces.
Method	The damping forces do not dissipate energy due to other modes of motion.
Method	Additional forces include air-drag, gravity, and user-generated generated mouse-forces (for interactive simulations).
Method	Cloth/cloth contacts generate strong repulsive linear-spring forces between cloth particles.
Method	Combining all forces into a net force vector f, the acceleration ẍ i of the ith particle is simply ẍ i = f i /m i , where m i is the ith particle’s mass.
Method	(A triangle’s mass is the product of the cloth’s density and the triangle’s fixed area in the uv coordinate system.
Method	The use of an implicit integration method, described in the next section, generates large unbanded sparse linear systems.
Method	We solve these systems through a modified conjugate gradient (CG) iterative method, described in section 5.
Method	CG methods exploit sparsity quite easily, since they are based solely on matrix-vector multiplies, and require only rudimentary sparse storage techniques.
Method	The sparsity of the matrix generated by the implicit integrator is best represented in block-fashion: for a system with n particles, we deal with an n × n matrix, whose non-zero entries are represented as dense 3 × 3 matrices of scalars.
Method	The matrix is represented as an array of n rows; each row is a linked list of the non-zero elements of that row, to accommodate possible run-time changes in the sparsity pattern, due to cloth/cloth contact.
Method	The (dense) vectors that are multiplied against this matrix are stored simply as n element arrays of threecomponent vectors.
Method	The overall implementation of sparsity is completely straightforward.
Method	An individual particle’s position and velocity can be completely controlled in either one, two, or three dimensions.
Method	Particles can thus be attached to a fixed or moving point in space, or constrained to a fixed or moving surface or curve.
Method	Constraints are either user-defined (the time period that a constraint is active is user-controlled) or automatically generated, in the case of contact constraints between cloth and solids.
Method	During cloth/solid contacts, the particle may be attached to the surface, depending on the magnitudes of the frictional forces required; otherwise, the particle is constrained to remain on the surface, with sliding allowed.
Method	The constraint techniques we use on individual particles work just as well for collections of particles; thus, we could handle cloth/cloth intersections using the technique described in section 5, but the cost is potentially large.
Method	For that reason, we have chosen to deal with cloth/cloth contacts using penalty forces: whenever a particle is near a cloth triangle or is detected to have passed through a cloth triangle, we add a stiff spring with damping to pull the particle back to the correct side of the triangle.
Method	The implicit solver easily tolerates these stiff forces.
Method	Given the known position x(t 0 ) and velocity x(t 0 ) of the system at time t 0 , our goal is to determine a new position x(t 0 + h) and velocity x(t 0 + h) at time t 0 + h.
Method	To compute the new state and velocity using an implicit technique, we must first transform equation (2) into a first-order differential equation.
Method	To simplify notation, we will define x 0 = x(t 0 ) and v 0 = v(t 0 ).
Method	We also define x = x(t 0 + h) − x(t 0 ) and v = v(t 0 + h) − v(t 0 ).
Method	As previously discussed, the step size h must be quite small to ensure stability when using this method.
Method	The difference in the two methods is that the forward method’s step is based solely on conditions at time t 0 while the backward method’s step is written in terms of conditions at the terminus of the step itself.
Method	4 The forward method requires only an evaluation of the function f but the backward method requires that we solve for values of x and v that satisfy equation (4).
Method	Equation (4) is a nonlinear equation: rather than solve this equation exactly (which would require iteration) we apply a Taylor series expansion to f and make the firstorder approximation ∂f ∂f f(x 0 + x, v 0 + v) = f 0 + ∂x x + ∂v v.
Method	In this equation, the derivative ∂f/∂x is evaluated for the state (x 0 , v 0 ) and similarly for ∂f/∂v.
Method	Substituting this approximation into equation (4) yields the linear system
Method	Taking the bottom row of equation (5) and substituting x = h(v 0 + v) yields v = hM −1 f 0 + ∂x ∂f h(v 0 + v) + ∂v ∂f v .
Method	Given v, we trivially compute x = h(v 0 + v).
Method	Thus, the backward Euler step consists of evaluating f 0 , ∂f/∂x and ∂f/∂v; forming the system in equation (6); solving the system for v; and then updating x and v.
Method	We use the sparse data structures described in section 2.3 to store the linear system.
Background	Cloth’s material behavior is customarily described in terms of a scalar potential energy function E(x); the force f arising from this energy is f = −∂E/∂x.
Method	Equation (6) requires both the vector f and the matrix ∂f/∂x.
Method	Expressing the energy E as a single monolithic function—encompassing all aspects of the cloth’s internal behavior—and then taking derivatives is impractical, from a bookkeeping point of view.
Method	A better approach is decompose E into a sum of sparse energy functions; that is, to write E(x) = α E α (x) where each E α depends on as few elements of x—as few particles—as possible.
Method	However, even decomposing E into sparse energy functions is not enough.
Method	Energy functions are an undesirable starting point because sensible damping functions cannot be derived from energy functions.
Method	Instead, we define internal behavior by formulating a vector condition C(x) which we want to be zero, and then defining the associated energy as k C(x) T C(x) where k is a stiffness constant.
Method	An added bonus is that starting from this vector-based energy description tends to result in a simpler, more compact, and more easily coded formulation for ∂f/∂x than proceeding from an energy function in which the structure of C has been lost.
Method	Given a condition C(x) which we want to be zero, we associate an energy function E C with C by writing E C (x) = k 2 C(x) T C(x) where k is a stiffness constant of our choice.
Method	Assuming that C depends on only a few particle, C gives rise to a sparse force vector f.
Method	Recall from section 2.1 that we view the vector f in block form; each element f i is a vector in IR 3 .
Method	Similarly, the derivative of f is also sparse.
Method	Defining the derivative matrix K = ∂f/∂x, the nonzero entries of K are K ij for all pairs of particles i and j that C depends on.
Method	Again, we treat K in block fashion: K ∈ IR 3n×3n , so an element K ij is a 3 × 3 matrix.
Method	Additionally, since K ij is a second derivative—that is, K ij = ∂f i /∂x j = ∂ 2 E/∂x i ∂x j —we have K ij = K T ji so K is symmetric.
Method	Note that since C does not depend on v, the matrix ∂f/∂v is zero.
Method	We can now easily describe the internal forces acting on the cloth, by just writing condition functions.
Method	Forces and their derivatives are easily derived using equations (7) and (8).
Method	Recall that every cloth particle has a changing position x i in world space, and a fixed plane coordinate (u i , v i ).
Method	Even though our cloth is modeled as a discrete set of points, grouped into triangles, it will be convenient to pretend momentarily that we have a single continuous function w(u, v) that maps from plane coordinates to world space.
Method	Stretch can be measured at any point in the cloth surface by examining the derivatives w u = ∂w/∂u and w v = ∂w/∂v at that point.
Method	The magnitude of w u describes the stretch or compression in the u direction; the material is unstretched wherever w u = 1.
Method	Stretch in the v direction is measured by w v .
Background	(Some previous continuum formulations have modeled stretch energy along an axis as essentially (w u T w u − 1) 2 , which is a quartic function of position [ 15 , 16 , 17 , 4 ].
Method	We find this to be needlessly stiff; worse, near the rest state, the force gradient—a quadratic function of position—is quite small, which partially negates the advantage implicit integration has in exploiting knowledge of the force gradient.
Method	A quadratic model for energy is, numerically, a better choice.
Method	) We apply this stretch/compression measure to a triangle as follows.
Method	Let us consider a triangle whose vertices are particles i, j and k.
Method	Define x 1 = x j − x i and x 2 = x k − x i .
Method	Also, let u 1 = u j − u i , while u 2 = u k − u i and similarly for v 1 and v 2 .
Method	We approximate w(u, v) as a linear function over each triangle; this is equivalent to saying that w u and w v are constant over each triangle.
Method	This lets us write x 1 = w u u 1 + w v v 1 and x 2 = w u u 2 + w v v 2 .
Method	Note that x 1 and x 2 vary during the simulation but the matrix in the above equation does not.
Method	We can treat w u and w v as functions of x, realizing that they depend only on x i , x j and x k and using equation (9) to obtain derivatives.
Method	Usually, we set b u = b v = 1, though we need not always do so.
Method	In particular, if we want to slightly lengthen a garment (for example, a sleeve) in the u direction, we can increase b u , which causes w u to seek a larger value, and tends to induce wrinkles across the u direction.
Method	Likewise, we might decrease b v near the end of a sleeve, inducing a tight cuff, as on a sweatshirt.
Method	We have found the ability to control shrink/stretch anisotropically to be an indispensable modeling tool.
Method	Cloth likewise resists shearing in the plane.
Method	We can measure the extent to which cloth has sheared in a triangle by considering the inner product w u T w v .
Method	In its rest state, this product is zero.
Method	Since the stretch term prevents the magnitudes of w u and w v from changing overly much, we need not normalize.
Method	By the small angle approximation, the product w u T w v is a reasonable approximation to the shear angle.
Method	The condition for shearing is simply C(x) = aw u (x) T w v (x) with a the triangle’s area in the uv plane.
Method	We measure bend between pairs of adjacent triangles.
Method	The condition we write for the bend energy depends upon the four particles defining the two adjoining triangles.
Method	If we let n 1 and n 2 denote the unit normals of the two triangles and let e be a unit vector parallel to the common edge, the angle θ between the two faces is defined by the relations sin θ = (n 1 × n 2 ) · e and cos θ = n 1 · n 2 .
Method	We define a condition for bending by writing simply C(x) = θ which results in a force that counters bending.
Method	This makes differentiating θ with respect to x a manageable task.
Method	Rectangular meshes make it simple to treat bending anisotropically.
Method	The uv coordinates associated with particles make this possible for triangular meshes as well.
Method	Given material for which bending in the u and v directions are weighted by stiffnesses k u and k v , we can emulate this anisotropy as follows.
Method	Let the edge between the triangles be between particles i and j, and define u = u i − u j and v = v i − v j .
Method	The stiffness weighting for this edge should simply be k u ( u) 2 + k v ( v) 2 .
Method	To the above forces we also add easily implemented forces such as gravity and air-drag (which is formulated on a per-triangle basis, and opposes velocities along the triangle’s normal direction).
Method	When the simulation is fast enough to interact with, we add user-controlled “mouse” forces.
Method	These forces and their gradients are easily derived.
Method	The energies we have just described are functions of position only.
Method	Robust dynamic cloth simulation, however, is critically dependent on well-chosen damping forces that are a function of both position and velocity.
Method	For example, the strong stretch force must be accompanied by a suitably strong damping force if we are to prevent anomalous in-plane oscillations from arising between connected particles.
Method	However, this strong damping force must confine itself solely to damping in-plane stretching/compressing motions: stretch damping should not arise due to motions that are not causing stretch or compression.
Background	Terzopoulos et al.’s [ 16 , 17 ] treatment of cloth used a simple viscous damping function which dissipated kinetic energy, independent of the type of motion.
Background	Carignan et al. [ 4 ] improved upon this somewhat, borrowing a formulation due to Platt and Barr [ 11 ]; however, their damping function—a linear function of velocity—does not match the quartic energy functions of their continuum formulation.
Method	At an equilibrium point of E, the gradient ∂E/∂x vanishes.
Method	Since E  ̇ = (∂E/∂x) T x, we find that E  ̇ is zero when E is at its minimum, regardless of the system’s velocity x = v.
Method	In general, E  ̇ is always too small near the system’s rest state.
Method	Clearly, basing the damping force on E  ̇ is not what we want to do.
Method	We believe that the damping function should be defined not in terms of the energy E, but in terms of the condition C(x) we have been using to define energies.
Method	The force f arising from the energy acts only in the direction ∂C(x)/∂x, and so should the damping force.
Method	Additionally, the damping force should depend on the component of the system’s velocity in the ∂C(x)/∂x direction; in other words, the damping strength should depend on (∂C(x)/∂x) T x = C(x).
Method	As before, d i is nonzero only for those particles that C depends on, and ∂d/∂x has the same sparsity pattern as ∂f/∂x.
Method	Note that ∂d/∂x is not a second derivative of some function as was the case in equation (8) so we cannot expect ∂d/∂x to be symmetrical.
Method	In equation (12), it is the term (∂C(x)/∂x i )(∂ C(x)/∂x  ̇ j ) T which breaks the symmetry.
Method	Anticipating section 5.2, we find it expedient simply to leave this term out, thereby restoring symmetry.
Method	This simplification is clearly not physically justifiable, but we have not observed any ill effects from this omission.
Method	(Omitting all of equation (12), however, causes serious problems.
Method	) Finally, equation (6) requires the derivative ∂d/∂v.
Method	In this case, the result is symmetrical without dropping any terms.
Method	The constraints we discuss in this section are either automatically determined by the user (such as geometric attachment constraints on a particle) or are contact constraints (generated by the system) between a solid object and a particle.
Result	The techniques we describe in this section could be used for multi-particle constraints; however, constraints that share particle would need to be merged.
Method	Thus, a set of four-particle constraints (such as vertex/triangle or edge/edge contacts in the cloth) might merge to form a single constraint on arbitrarily many particles, which would be expensive to maintain.
Method	Because of this, we handle cloth/cloth contacts with strong springs (easily dealt with, given the simulator’s underlying implicit integration base) and “position alteration,” a technique described in section 6.
Method	At any given step of the simulation, a cloth particle is either completely unconstrained (though subject to forces), or the particle may be constrained in either one, two or three dimensions.
Method	Given the differential nature of our formulation, it is the particle’s acceleration, or equivalently, the change in the particle’s velocity, that is constrained.
Method	If the particle is constrained in all three dimensions, then we are explicitly setting the particle’s velocity (at the next step).
Method	If the constraint is in two or one dimensions, we are constraining the particle’s velocity along either two or one mutually orthogonal axes.
Method	An obvious and quite exact method for constraining a particle is to reduce the number of coordinates describing the particle’s position and velocity.
Method	A completely constrained particle would have no coordinates, while a particle with one dimension of constraint would have two coordinates.
Method	This is possible—but it complicates the system immensely.
Method	If we change the number of coordinates per particle, we alter the size of the derivative matrices in equation (6), as well as the sparsity pattern (this happens when a particle changes from having no coordinates to some coordinates, or vice versa).
Method	Given the transient nature of contact constraints between cloth and solids, this is most unappealing.
Method	The computation of the derivative matrices’ entries is also greatly complicated, because we must now introduce extra Jacobian matrices that relate a particle’s reduced coordinates to its motion in world-space.
Method	Finally, correct constraint-release behavior between cloth and solid objects is difficult to achieve using a reduced coordinate formulation.
Method	Considering all of this, we immediately rejected this method of constraints.
Method	We could constrain particles through the use of strong energy functions—essentially, stiff springs that attempt to prevent illegal particle motions.
Method	Since our entire formulation is geared to handle stiffness, the usual objections to enforcing constraints with springs—very stiff equations—do not carry as much weight.
Method	We tried this for a time, and found it to be a not unreasonable constraint enforcement mechanism.
Method	However, penalty methods do not enforce constraints exactly, and they do add some additional stiffness to the system.
Method	Since the mechanism we describe enforces constraints exactly, and adds no extra stiffness, we turned away from penalty methods except in the case of cloth/cloth interactions.
Method	We could introduce additional constraint forces—that is, Lagrange multipliers—into our system to satisfy the constraints.
Method	This involves augmenting the linear system of equation (6) with extra variables (the multipliers) and extra equations (the constraint conditions).
Method	Unfortunately, this turns a positive definite system into an indefinite system, which means that iterative methods such as CG will need to square the system first, thereby doubling the running time and degrading the numerical conditionining of the linear system.
Method	Additionally, an iterative method will generally not enforce the constraints exactly without a large number of iterations.
Method	(A direct method for solving the augmented system would, however, avoid this problem.
Method	) Again, the constraint method we describe steps past these difficulties, so we turned away from using Lagrange multipliers.
Method	The idea behind our constraint enforcement mechanism is described quite simply, although the actual implementation is somewhat more complicated, to maximize performance.
Method	A dynamic simulation usually requires knowledge of the inverse mass of objects; for example, note the appearance of M −1 , and not M in equation (6).
Method	In the case of a single particle, we write x  ̈ i = m 1 i f i to describe a particle’s acceleration.
Method	When inverse mass is used, it becomes trivial to enforce constraints by altering the mass.
Method	Suppose for example that we want to keep particle i’s velocity from changing.
Method	If we take 1/m i to be zero, we give the particle an infinite mass, making it ignore all forces exerted on it.
Method	Complete control over a particle’s acceleration is thus taken care of by storing a value of zero for the particle’s inverse mass.
Method	What if we wish to constrain the particle’s acceleration in only one or two dimensions?
Method	Although we normally think of a particle’s mass as a scalar, we need not always do so.
Method	Suppose we write ẍ i = 1/m 0 i 1/m 0 i 0 0 f i .
Method	Now ẍ i 0 0 0 must lie in the xy plane; no acceleration in the z direction is possible.
Method	Note than an unconstrained particle can be considered to have the 3 × 3 inverse mass matrix 1 I, with I the identity matrix.
Method	More generally, given a unit vector p ∈ IR 3 , a particle is prevented from accelerating along p by using an inverse mass matrix 1 (I − m i pp T ); this follows from the fact that (I − pp T )p = 0.
Method	Similarly, given two mutually orthogonal unit vectors p and q, we prevent a particle from accelerating in either the p or q direction by using the inverse mass matrix 1 (I − pp T − qq T ).
Method	We will create a modified version W of M −1 ; W will be a block-diagonal matrix, with off-diagonal blocks being zero, and diagonal blocks defined as follows: let ndof(i) indicate the number of degrees of freedom particle i has, and let particle i’s prohibited directions be p i (if ndof(i) = 2) or p i and q i (if ndof(i) = 1) with p i and q i mutually orthogonal unit vectors.
Method	We are not limited to constraining particles to have zero accelerations in certain directions; rather, we control exactly what the change in velocity is along the constrained directions.
Method	For every particle i, let z i be the change in velocity we wish to enforce in the particle’s constrained direction(s).
Method	(This implies we can choose any value of z i for a completely constrained particle, since all directions are constrained; an unconstrained particle must have z i = 0 since it has no constrained directions.
Method	) Using W and z, we rewrite equation (6) to directly enforce constraints.
Method	Completely constrained particles will have v i = z i , while partially constrained particles will have a v i whose component in the constrained direction(s) is equal to z i .
Method	We initially implemented constraints using equation (14) and found that it worked exactly as advertised.
Method	For very small test systems, we solved equation (14) using a direct method (Gaussian elimination) without any problems.
Method	For larger systems, we planned to use the iterative, sparsity-exploiting CG method, which immediately presents us with a problem: equation (14) is not a symmetric linear system.
Method	(For that matter, neither is equation (6) unless all particles have the same mass.
Background	) CG methods, however, require symmetric matrices.
Method	6 We could apply a CG method to the unsymmetric matrix of equation (14) by use of the “normal equations”; but this involves multiplying the matrix of equation (14) with its transpose which doubles the cost of each iteration while squaring the condition number of the system [ 14 ]—a less than desirable plan.
Method	We decided that using a CG method to solve the unsymmetric problem was not acceptable.
Method	Unfortunately, we cannot apply the same transformation to equation (14), because W is singular—the filtering blocks in equation (13) are rank deficient—so we cannot multiply through by W −1 .
Method	The solution to the problem of asymmetry is to modify the CG method so that it can operate on equation (15), while procedurally applying the constraints inherent in the matrix W at each iteration.
Method	The modified method will need to know about the particles’ constraints and the vector z.
Method	• For each particle i, the component of v i in the particle’s constrained direction(s) will be exactly z i (no matter how many iterations are taken).
Method	Note that these two conditions imply that unconstrained particles have r i close to zero, while completely constrained particles have v i = z i .
Method	Thus in the case when no particles are constrained, our modified CG method should produce the same result as the regular CG method.
Method	The CG method (technically, the preconditioned CG method) takes a symmetric positive semi-definite matrix A, a symmetric positive definite preconditioning matrix P of the same dimension as A, a vector b and iteratively solves A v = b.
Method	The iteration stops when b − A v is less than b where is a user-defined tolerance value.
Method	We derive our modified conjugate gradient method by observing that the effect of the matrix W in equation (14) is to filter out velocity changes in the constrained directions.
Method	Our idea then is to define an invariant— for all i, the component of v i in the constrained direction(s) of particle i is equal to z i —and then establish and maintain the invariant at each iteration, by defining a filtering procedure filter.
Method	Lines 5 and 15 maintain the invariant by filtering c before adding it to v.
Method	The unmodified conjugate gradient method establishes a stopping criterion based on b T Pb.
Method	Since our constrained formulation ignores certain components of b, our stopping criterion should as well, so we add filtering to line 3.
Method	The vector r measures the solution error b − A v, and should not include error due to the constraints; hence we add filtering at lines 4 and 8.
Method	(Note that removing the calls to filter and changing line 2 to v = 0 yields the standard preconditioned conjugate gradient method.
Method	) We use a simple preconditioner P by making P be a diagonal matrix with P ii = 1/A ii so products involving P −1 are trivially computed.
Method	More elaborate preconditioners could be used, though we doubt there is a large speedup to be gained.
Method	Matrix-vector products with A are of course implemented in sparse matrix-vector fashion, using the data structures defined in section 2.3.
Result	” Proofs about CG methods are difficult in general; in practice, our method always converges, which answers the first question.
Method	Prior to implementing modified-pcg, we used a penalty method and applied the standard CG method to equation (15).
Method	When we began using procedure modified-pcg, we did not notice any substantial change in the number of iterations required by the method.
Result	Empirically, we conclude that the two methods have similar convergence behavior.
Method	For contact constraints (between cloth and solid objects) we need to know what the actual force of constraint is, in order to determine when to terminate a constraint.
Method	Additionally, we need to know the constraint force actually exerted in order to model frictional forces properly.
Method	Fortunately, it is easy to add one more step to modified-pcg to determine the constraint force.
Method	When modified-pcg terminates, the residual error e = A v − b has the property that e i need not be close to zero if particle i is constrained.
Method	In fact, e i is exactly the extra constraint force that must have been supplied to enforce the constraint.
Method	Thus, we can compute constraint forces at the end of modified-pcg by performing one last matrixvector product to compute A v − b.
Method	(The vector r in modified-pcg is equal to filter(A v − b), so the extra matrix-vector product to compute e really is necessary.
Method	) The particles’ accelerations are inherently dependent on one another through the matrix A of equation (16).
Method	This means that the correct approach to determing constraint release is combinatoric, as in Baraff [ 2 ].
Result	In practice, this has proven to work well.
Method	Friction presents a similar problem.
Method	When cloth contacts a solid, we lock the particle onto the surface, if the relative tangential velocity is low.
Method	We monitor the constraint force, and if the tangential force exceeds some fraction of the normal force, we allow the particle to slide on the surface.
Method	For high sliding velocities, we apply a dissipative tangential force, opposite the relative sliding direction, proportional to the normal force.
Background	Much has been written about collision detection for cloth; we have nothing substantial to add to the subject of collision detection per se.
Background	Cloth/cloth collisions are detected by checking pairs ( p, t) and (e 1 , e 2 ) for intersections, where p and t are a cloth particle and a cloth triangle respectively, and e 1 and e 2 are edges of cloth triangles.
Method	Given a previous known legal state of the cloth, we postulate a linear motion for the cloth particles to the current (possibly illegal) state and check for either particle/triangle or edge/edge crossings.
Method	To avoid O(n 2 ) comparisons, we use a coherency-based boundingbox approach [ 1 ] to cull out the majority of pairs.
Method	When collisions between a cloth vertex and triangle, or two cloth edges are detected, we insert a strong damped spring force to push the cloth apart.
Method	A dissipative force tangent to the contact is also applied, countering any sliding motion.
Method	The force is not, strictly speaking, a frictional force: rather it is proportional to the slip velocity, so it is in actuality a damping force, although it reasonably emulates dynamic friction.
Method	Applying static friction forces to cloth contacts is far more difficult, and is a problem we have not solved yet.
Method	The forces, and their derivatives with respect to position and velocity, are of course included in equation (15).
Method	Our system detects collisions between cloth particles and solid objects by testing each individual cloth particle against the faces of each solid object.
Method	A solid object’s faces are grouped in a hierarchical bounding box tree, with the leaves of the tree being individual faces of the solid.
Method	The tree is created by a simple recursive splitting along coordinate axes.
Method	Both cloth/cloth and cloth/solid collisions give rise to the same problem whenever two contacts form.
Method	For both types of collisions, our detection algorithm reports an intersection, and then takes action to remedy the situation: either by enforcing a constraint (cloth/solid collisions) or by adding a penalty force (cloth/cloth) collisions.
Method	However, since our simulator proceeds in discrete steps, collisions resulting in a reasonably substantial interpenetration depth can occur between one step and the next.
Method	Clearly, this situation needs to be remedied.
Method	For cloth/cloth collisions, this would not appear to be a problem: the spring forces that are added work to counter the colliding velocities and then push the cloth apart.
Method	For cloth/solid collisions, however, the situation is more complicated.
Method	If we simply enforce a constraint which causes the colliding cloth particle to have a velocity consistent with the solid object’s velocity, and continue to enforce that constraint, the cloth particle will continue to remain embedded somewhere below the solid object’s surface.
Method	This is unacceptable.
Method	One solution is to use Baumgarte stabilization [ 18 ], which schedules the particle’s acceleration so that the position and velocity error of the particle with respect to the surface decay asymptotically to zero.
Method	We experimented with this technique, but found it lacking.
Method	In particular, a fast rise to the surface was prone to noise and “jumpiness”; this could be eliminated, but at the cost of decreasing the step size.
Method	A slower rise to the surface caused visual artifacts.
Method	We tried a simpler solution: when intersections occurred, rather than wait for a scheduled constraint or a penalty force to eliminate the intersection, we simply altered the positions of the cloth particles, effecting an instantaneous (and discontinuous) change in position.
Method	While this would be problematic when using a multi-step differential equation solver which expects continuity (such as a RungeKutta method), it should not interfere with a one-step solver such as the backward Euler method.
Method	Unfortunately, simply changing particle positions produced disastrous results.
Method	The stretch energy term in a cloth system is extremely strong, and altering particle positions arbitrarily introduced excessively large deformation energies in an altered particle’s neighborhood.
Method	This resulted in visibly “jumpy” behavior of the cloth in localized regions.
Method	Despite its initial failure, the ability to make arbitrary small changes in a particle’s position continued to attract our attention.
Method	The entire process of implicit integration can be considered to be a filtering process [ 7 ], and we postulated that a mechanism for filtering energy changes caused by displacing particles might make position alteration a viable technique.
Method	We considered that perhaps some sort of extra implicit step could be used as a filter, but forming and solving an additional linear system at each step seemed too expensive.
Method	Happily, we can make use of the filtering effect of implicit integration without any extra work.
Method	Consider a particle that has collided with a solid object.
Method	The particle’s change in velocity at each step is under our control, using the constraint techniques described in section 5.
Method	Meanwhile, the particle’s position at the next step follows from equation (4): x i = h(v 0i + v i ) (recall that v 0i is the particle’s current velocity).
Method	The reason that changing positions after a step has been taken doesn’t work is because the particle’s neighbors receive no advance notification of the change in position: they are confronted with the alteration at the beginning of the next step.
Method	Having modified the top row of equation (4), we must follow this change through: using equation (17) and repeating the derivation of section 3 and the symmetric transform from section 5 yields the modified symmetric system
Method	This modification gives us complete control over both the position and velocity of a constrained particle in just one step, without any extra computational cost.
Method	We use this technique to bring particles quickly and stably to the surface of solid objects without creating visual artifacts or limiting the allowable step size.
Method	We can also add correction terms to particles involved in cloth/cloth collisions.
Method	Without a constraint on those particles’ velocities there is no guarantee that they will go exactly where we want in one step, but the ability to induce sizeable jumps in position without excessively stiff spring forces adds greatly to the stability of the simulation.
Result	The methods introduced in all of the previous sections usually allow us to take sizeable steps forward, without loss of stability.
Method	Even so, there are still times when the step size must be reduced to avoid divergence.
Background	There are a large number of methods for altering the size of a time step, for both explicit and implicit integrators, but these methods tend to concentrate on the accuracy of the simulation, and not the stability.
Problem	Our goal is animation, not engineering; thus visually pleasing results, meaning a numerically stable solution, rather than overall accuracy, is the deciding voice.
Method	The trick is to recognize instability before you see it on your screen—by then it’s too late.
Method	Stiffness, and thus any potential instability, arises almost completely from the strong stretch forces in the cloth.
Method	After each implicit step, we treat the resulting x as a proposed change in the cloth’s state, and examine the stretch terms (section 4.2) for each triangle in the newly proposed state.
Method	If any triangle undergoes a drastic change in its stretch (in either the u or v direction) we discard the proposed state, reduce the step size, and try again.
Method	Subtlety is not required: we find that an unstable step invariably results in stretch changes that are quite large, and are thus easily detected.
Method	Our simulation is run with a parameter that indicates the maximum allowable step size: this parameter is set by the user, and is always less than or equal to one frame.
Method	(Most of our simulations involving human motions use a step size of 0.02 seconds.
Method	) Whenever the simulator reduces the step size, after two successes with the reduced step size the simulator tries to increase the step size.
Method	If the simulator fails at the larger step size, it reduces the size again, and waits for a longer period of time before retrying to increase the step size.
Method	At its limit, the simulator will try increasing the step size every 40 steps; thus, if the user chooses too large a step, the simulator settles down to wasting only one out of every 40 steps in attempting too large a step.
Result	This method, though simple, has served us well.
Result	Unaccounted overhead of the simulation (typically about 5%) includes tasks such as geometry transformations, memory allocation, etc.
Method	The clothes in figures 3–6 were modeled as discrete planar panels, and then topologically seamed.
Method	The simulator was used to relax the clothing from an initial deformed state, that got the clothes around the characters, to a well-fitting state on the characters.
Method	The b u and b v parameters (see equation (10)) were then made smaller in certain regions to produce cuffs and waistbands, or strategically increased to induce wrinkling behavior in other regions.
Method	We also ran the simulation in figure 1 with a range of stiffnesses for the bend term.
Method	Using the stiffness parameters in figure 1 as a reference, we ran the simulation with those bend stiffnesses multiplied by 0.1, 1.0, 10, 100 and 1,000 (for a total range of 10,000 in the stiffness).
Result	The variance in the running times was under 5%.
Result	We doubt that simulators based on explicit integration methods could make a similar claim.
Method	Finally, we tried to estimate our simulator’s performance as a function of n, the number of cloth particles.
Method	We ran the simulation in figure 1 with cloth resolutions of 500, 899, 2,602 (shown in figure 1 ) and 7,359 particles.
Result	The running times were, respectively, 0.23 seconds/frame, 0.46 seconds/frame, 2.23 seconds/frame, and 10.3 seconds/frame.
Result	This is slightly better than O(n 1.5 ) performance, which is in line with the convergence rates of the conjugate gradient method [ 14 ] for systems such as equation (18).

Result	We present an algorithm for the simulation of incompressible fluid phenomena that is computationally efficient and leads to visually convincing simulations with far fewer degrees of freedom than existing approaches.
Method	Rather than using an Eulerian grid or Lagrangian elements, we represent vorticity and velocity using a basis of global functions defined over the entire simulation domain.
Result	We show that choosing Laplacian eigenfunctions for this basis provides benefits, including correspondence with spatial scales of vorticity and precise energy control at each scale.
Method	We perform Galerkin projection of the Navier-Stokes equations to derive a time evolution equation in the space of basis coefficients.
Result	Our method admits closed form solutions on simple domains but can also be implemented efficiently on arbitrary meshes.
Background	Fluid motion is naturally captivating.
Background	Over the years, it has piqued the imagination and curiosity of artists, mathematicians and scientists.
Background	The fascination with fluid motion is exemplified by its long history in the computer graphics literature.
Background	Early work focused on obtaining motion that is visually interesting and convincing.
Background	More recent physically based techniques rely primarily on numerical approximation of the Navier-Stokes equations.
Background	Computer simulation of a model necessitates a finite representation of its spatial quantities.
Background	Grid-based techniques are the most common approach.
Problem	However, they suffer from high computational complexity, due to the general requirement at each simulation step to solve a system of equations whose size is proportional to the number of grid elements in the domain.
Background	Lagrangian techniques, such as mass particles, removes the dependence on the simulation domain.
Problem	That said, the computation of pressure and other fluid quantities are expensive and approximations lead to noticeable violations of incompressibility.
Background	Vorticity primitives, including particles and filaments, are very effective at simulating smoke in inviscid media but have difficulties modelling diffusion and handling boundary conditions.
Background	Model reduction is a data-driven approach that exploits a precomputed set of example simulations to obtain a low dimensional representation for fluid motion.
Problem	While this technique is very efficient at run-time, it suffers from significant costs for precomputation and storage, and is dependent on the performance of an existing simulator or other mechanism to obtain ground-truth data.
Problem	We propose an algorithm for the interactive simulation of fluid motion that avoids many of the shortcomings of existing techniques.
Method	We employ a representation of fluid velocity and vorticity in a finite dimensional basis of Laplacian eigenfunctions.
Result	The resulting velocity basis fields are divergence free and respect boundary conditions, so that these constraints are enforced automatically without the need for additional computation.
Method	Our algorithm can be formulated as Galerkin projection of the vorticity form of the Navier-Stokes equations onto Laplacian eigenfunctions defined over the simulation domain.
Method	The resulting finite dimensional form of the equations describes the time evolution of the basis coefficients.
Method	We precompute the non-linear advection terms between pairs of basis functions and store the result as structure coefficients in a set of matrices.
Method	Viscosity and external forces are incorporated using linear terms, and the basis function coefficients are hence updated using a simple matrix-vector equation.
Method	Laplacian eigenfunctions form an orthogonal basis, allowing one to easily compute the energy of the fluid.
Method	Additionally, Laplacian eigenfunctions of increasing eigenvalue magnitude have a natural visual correspondence with decreasing scales of vorticity.
Method	Coupled with orthogonality, the correspondence allows precise control of a fluid’s turbulent spectrum through adjustment of basis coefficients.
Method	With Laplacian eigenfunctions the viscosity can be simulated accurately through a simple exponential decay of basis coefficients, but also allows arbitrary user-controlled or automatic adjustment of the spectrum to achieve a desired effect.
Method	For some practically important simulation domains such as a 2-D plane and 3-D rectangular cavity, Laplacian eigenfunctions have closed form expressions, allowing fully analytic simulation.
Method	In these cases, no mesh is required to store the fluid’s velocity.
Method	Instead, a velocity can be precisely evaluated at any spatial coordinate without the need for interpolation.
Method	Furthermore, closed form expressions allow symbolic evaluation of the precomputed advection operator, making this process fast and exact.
Method	However, our method is not limited to these domains, and we present a formulation on structured and irregular meshes using discrete exterior calculus, in which velocity and vorticity basis fields are eigenvectors of a discrete Laplacian operator.
Method	Additionally, our method supports the interaction of immersed moving obstacles and buoyancy through projection of forces to the velocity basis fields.
Result	Our method allows considerable flexibility in choosing the basis dimensionality.
Result	Even simulations with few degrees of freedom provide visually convincing results, avoiding the artifacts common to very low-dimensional representations in Eulerian or Lagrangian simulations.
Result	In this respect, our method provides a principled means of dimensionality reduction of the Navier-Stokes fluid equations.
Result	However, our method is not data-driven as seen in current model reduction techniques and hence avoids the need for an existing fluid simulator or pre-existing data.
Result	We believe our algorithm and choice of basis provides an exciting avenue and will be an important complement to the methods in the literature.
Background	Incompressible fluid dynamics is a vast subject.
Background	We survey some relevant work from geometric mechanics, computational fluid dynamics (CFD) and the computer graphics literature.
Background	Euler’s equations describing the dynamics of a rotating rigid body date from the 18th century.
Background	In 1901, Poincaré [1901] showed that by considering various group manifolds as the configuration space, Euler’s equation could apply generally to a class of physical systems.
Background	For example, in the case of a rotating rigid body the group is the rotation group SO(3).
Background	Arnold [1966] showed that an ideal incompressible fluid is described similarly as geodesic motion on SDiff, the Lie group of volume preserving diffeomorphisms.
Background	The notion of structure coefficients to describe the interaction of Lie algebra basis elements of these groups is directly related to the precomputed coefficient matrices used in our method.
Background	Many of these concepts are summarized by Marsden and Ratiu [1999].
Background	Representing vorticity using Laplacian eigenfunctions dates back at least to Yudovich [1963], who used this method to prove existence and uniqueness theorems for the two dimensional NavierStokes equations.
Background	More recently, Agrachev et al. [2005] used vorticity Laplacian eigenfunctions to prove theorems in the mathematical control literature.
Method	This paper was our inspiration for investigating a Laplacian eigenfunction representation of vorticity as a practical means of fluid simulation in computer graphics applications.
Background	In the 1950’s, Silberman presented a fluid simulation algorithm for the earth’s atmosphere in a basis of spherical harmonics, which are Laplacian eigenfunctions on the surface of a sphere [Silberman 1954].
Background	This basis was applied to the vorticity stream function fluid equations in two dimensions, and the advection operator was evaluated symbolically.
Background	This method has come to be known in the CFD literature as the interaction coefficient method.
Background	Outside of atmospheric sciences, it is not widely used due to poor scaling for large basis dimensionality.
Background	Such performance considerations were the motivation for the development of spectral methods as pioneered by Orszag [Orszag 1969].
Background	Spectral methods are characterized by the use of a fast transform allowing efficient calculation of advection in the spatial domain, thereby avoiding convolution sums in the spectral domain.
Background	They are often used to study homogeneous turbulence [Orszag and Patterson 1972; Rogallo et al. 1981].
Background	Fourier series or Chebyshev polynomials are commonly employed, as spectral methods are limited to bases admitting a fast transform.
Method	Our method is most analogous to the interaction coefficient method of [Silberman 1954], although we consider arbitrary domains.
Background	On arbitrary domains, Laplacian eigenfunctions do not in general admit a fast transform and hence do not share the inherent theoretical performance of a spectral method.
Background	However, Laplacian eigenfunctions have many other benefits as we describe in Section 3.
Background	Furthermore, theoretical performance scaling is less critical for the applications we consider and we show that visually detailed simulations are attainable at low cost.
Background	Divergence free finite element methods (DFFEM) employ bases of discrete divergence free velocity fields to solve fluid equations in a space that satisfies mass continuity a priori [Gustafson and Hartman 1983].
Method	Our method is similar in this respect.
Background	However, in contrast to DFFEM, for some simple domains Laplacian eigenfunctions do not require a discrete mesh.
Background	Also, to our knowledge no basis employed in DFFEM exhibits all of the advantageous proper- ties of Laplacian eigenfunctions, including orthogonality, stationarity with respect to Navier-Stokes equations, global support, and correspondence with spatial scales of vorticity.
Background	Fluid simulation methods in the computer graphics literature belong to roughly four categories: grid-based, mass particles, vortex elements and model reduction.
Background	Grid-based techniques for simulating the 3-D Navier-Stokes equations were introduced by Foster and Metaxas [1996] but were unstable due to the use of explicit integrators.
Background	Stam developed an unconditionally stable integration scheme using semi-Lagrangian advection and an implicit integrator [Stam 1999].
Background	However, the result produces artificial viscosity which dampens vortices prematurely, and requires an iterative linear solver to solve for a pressure field to enforce incompressibility.
Background	Works aimed at mitigating or minimizing artificial diffusion include vorticity confinement [Fedkiw et al. 2001] and high order advection schemes [Selle et al. 2008].
Background	To improve the performance of the iterative pressure solver, use of adaptive grids [Losasso et al. 2004] and hierarchical coarse grids for projection [Lentine et al. 2010] have been proposed.
Background	Stam [2002] used the 2-D Fourier transform of a velocity field to perform fast pressure projection, but this method is limited to simple domains and boundary conditions, and still dissipates energy.
Background	Bridson presented a simple means to generate procedural divergence free flows through the curl of a vector potential stream function [Bridson et al. 2007] but this work did not address physical dynamics.
Background	Elcott presented a method that preserves circulation on simplicial meshes, but does not preserve energy [Elcott et al. 2007].
Background	Mullen et al. developed a fluid integrator capable of perfect energy preservation or desired viscosity independent of grid-resolution [Mullen et al. 2009], but this method is complex and requires a solution to a non-linear system at each timestep.
Background	Hybrid particle-grid methods such as FLIP [Zhu and Bridson 2005] are effective in eliminating numerical diffusion, but still require a grid to enforce incompressibility.
Background	Common to all these stable grid-based techniques previously mentioned is the need to solve a system of equations at each time integration step, the size of which is proportional to the number of grid elements.
Method	In contrast, the performance of our method is independent of the domain or grid resolution.
Method	In fact, for typical domains such as a 2-D rectangle or 3-D rectangular cavity, the global basis functions we employ have closed form expressions, removing the need for a velocity grid representation entirely.
Method	Our method allows controllable viscosity, and supports general domains through a formulation on discrete meshes.
Background	Particle methods track a fluid’s mass through Lagrangian elements.
Background	Smoothed particle hydrodynamics (SPH) was introduced to graphics by Desbrun and Gascuel [1996] and used subsequently to simulate water [Müller et al. 2003; Adams et al. 2007].
Background	Enforcing incompressibility in SPH methods is computationally expensive, making them impractical for a large number of particles.
Method	Our method satisfies incompressibility automatically as it operates directly in a space of divergence free fields.
Background	Vortex methods use Lagrangian elements such as particles or filaments to track vorticity, and advect these elements through the fluid’s velocity [Gamito et al. 1995; Park and Kim 2005; Angelidis et al. 2006; Weißmann and Pinkall 2010].
Background	A formulation using vorticity guarantees incompressibility, but the reconstruction of the velocity field is computationally expensive, typically involving the Biot-Savart formula.
Method	We also use a vorticity formulation, hence requiring no explicit enforcement of the incompressibility constraint.
Method	However, we use a superposition of global basis functions allowing the representation of arbitrary vorticity fields, whereas Lagrangian elements are limited to vorticity concentrated at points or on curves.
Method	Additionally, choosing Laplacian eigenfunctions as a basis allows the velocity field to be recovered trivially, removing the need for complicated and expensive reconstruction.
Background	Gupta and Narasimhan represented fluid velocity in a basis of Legendre polynomials allowing analytic evaluation of differential operators [Gupta and Narasimhan 2007].
Background	However, only boxboundary conditions were considered and the velocity basis fields are not strictly divergence free hence requiring a pressure projection step to enforce incompressibility.
Background	Model reduction has been applied to fluid simulation by Treuille et al. [2006].
Background	This technique chooses a reduced velocity basis defined on a mesh through observation of an existing fluid simulator.
Background	The resulting run-time performance is fast, but the precomputation time and memory requirements are large.
Background	Furthermore, it is unclear how well this technique generalizes to arbitrary flows, as behavior is limited to the examples present in training.
Method	Our method can be used directly as a means of dimensionality reduction through choice of the basis dimension N , but it differs from current approaches in many respects.
Method	We choose an appropriate velocity basis a priori instead of relying on observation of an existing fluid simulator.
Background	Up to a desired scale of vorticity, Laplacian eigenfunctions form a complete basis for divergence free fields.
Background	Adding basis functions increases the coverage in a well defined way.
Background	In contrast, a data driven basis can only approximate flows that are in some sense “close” to those observed in training, and there is no guarantee that additional training data will substantially increase the span of the resulting PCA basis.
Method	Our basis has a natural correspondence with spatial scales of vorticity that is lacking in [Treuille et al. 2006].
Background	Finally, Laplacian eigenfunctions have closed form expressions for some simple domains, in which case the precomputation time and memory requirements are vastly reduced in comparison.
Method	When acting on divergence free fields, the vector Laplacian reduces to ∆ = −curl 2 .
Method	The eigenfunctions of the Laplacian operator ∆ are domain dependent.
Method	The vector fields Φ k are Laplacian eigenfunctions with eigenvalues λ k = −(k 1 2 + k 2 2 ).
Method	We will continue to use the square domain as a concrete, illustrative example throughout the text, although closed form expressions also exist for many other domains including a 3-D rectangular prism [de Witt 2010], a disc, the surface of a sphere, or a planar region with a wrap around boundary condition.
Method	For our simulation method, we also require the vorticity field ω = curl (u) and a vorticity basis {φ k } with φ k = curl Φ k .
Method	One can verify that the φ k are also Laplacian eigenfunctions of the domain.
Method	However, as u and ω are orthogonal, the vorticity basis functions have only a normal component at the boundary, and hence satisfy ∆φ k = λ k φ k
Method	We summarize some additional interesting and useful properties of our basis.
Background	In general, reconstructing a velocity field from a vorticity field is computationally expensive, typically involving the use of the Biot-Savart Law [Angelidis et al. 2006; Weißmann and Pinkall 2010].
Method	A further important observation is that due to linearity of the curl operator, the expansion of the vorticity ω in the φ i basis shares the same coefficients as the expansion of the velocity u in the Φ k basis          N N N ω = curl u = curl ω i Φ i = ω i curl Φ i = ω i φ i .
Method	i i i          This is notable since a single coefficient vector w = [ω 1 ω 2 . . . ω N ] uniquely identifies both the fluid’s velocity u and its vorticity ω.
Method	Either field can be easily reconstructed from the basis coefficients ω i .
Method	Laplacian eigenfunctions on a domain form an orthogonal set.
Method	The total energy of a signal expressed in an orthogonal basis is the sum of the squares of its coefficients by Parseval’s identity.
Method	As shown in Figure 4 , larger eigenvalues of the Laplacian correspond to fields with smaller vortices.
Method	Basis coefficients can be interpreted as a discrete spatial spectrum of the fluid with higher “frequencies” corresponding to smaller scales of vorticity.
Background	This notion has been previously applied by Stam and Fiume using a Fourier basis to generate procedural stochastic turbulence [Stam and Fiume 1993].
Method	A decomposition into a spectrum of vorticity is important for at least two reasons.
Method	First, because computations require our basis to be finite, this ordered structure provides a principle by which to select the finite set.
Method	In choosing to truncate the spectrum at some finite N , the error we incur is well defined: we lose the ability to simulate vortices smaller than a given scale.
Method	Second, combined with orthogonality, our basis delivers a means of controlling the energy at different scales of vorticity by adjusting the magnitude of the basis coefficients.
Method	We use this property in Section 4 to accurately model viscous energy decay.
Method	It could also be used to initialize or arbitrarily change a fluid’s turbulent spectrum.
Method	For some simple domains, the basis fields have closed form expressions.
Method	This allows the velocity to be evaluated at any spatial coordinate without the need for a voxelized grid or interpolation.
Method	A grid may still be used for visualization, for example to track density or subsample the velocity from the closed form expressions to accelerate particle advection.
Method	However, this grid is independent of the simulation, and its resolution may be changed without changing the performance or behavior of the underling simulation.
Method	Although the benefits of closed form expressions are limited to simple geometries, a 2-D rectangle and 3D rectangular cavity both represent typical simulation domains.
Background	A fluid’s velocity field will change continuously over time according to physical laws.
Method	In our basis representation, this can be described by the continuous change of the coefficient vector w.
Method	For notational convenience, we choose Adv(·, ·) to represent the advection term, which is defined as Adv(u, ω) := curl (ω × u).
Method	The Adv(Φ i , φ j ) terms represent the nonlinear advection of basis fields.
Method	As will be detailed in Section 6, we precompute these terms and the vorticity basis coefficients of the result are stored in a set of matrices C k .
Method	Because φ k are Laplacian eigenfunctions, the viscous term becomes ν i ∆ω k φ k = ν k λ k ω k φ k .
Method	The effect of viscosity on each basis coefficient is hence described by the linear first order differential equation ω  ̇ k = νλ k ω k which conveniently has the closed form solution ω  ̇ k (t) = ω k (0)e νλ k t .
Method	This says that the magnitude of each basis coefficient decays with a time constant equal to the eigenvalue, which is physically correct, as small vortices dissipate faster than large vortices.
Method	The contribution to ω  ̇ k is then ω  ̇ k = f k .
Background	However, for computer graphics applications speed and energy stability are important requirements.
Method	We first describe our preferred integration scheme that meets these two requirements, and then discuss other available techniques.
Method	Our basis is orthogonal allowing kinetic energy to be calculated as a sum of squared coefficients.
Method	Additionally, orthogonality implies that surfaces of constant energy in the Euclidean space of coefficients are spheres.
Method	An inviscid fluid preserves kinetic energy, and should trace out a path on such a sphere.
Method	We choose a fast explicit integrator (such as forward Euler or Runge-Kutta method) to first perform an unconstrained timestep, followed by renormalization to enforce the energy constraint as depicted in Figure 6 .
Background	Renormalizing to preserve the kinetic energy is a technique available in any fluid simulation method and is not particular to our approach.
Background	However, when employing grid based velocity fields it is often undesirable as it can lead to visual artifacts.
Method	We have not observed such artifacts, possibly because our basis fields are globally supported and energy is never dissipated locally through a pressure projection step as for example in [Stam 1999].
Method	The effect of viscosity and projected forces will change the kinetic energy, so these terms are integrated following the energy renormalization.
Method	Physical viscosity is achieved by decaying each coefficient exponentially as described in Section 4.
Method	Computation is dominated by the evaluation of matrix vector products, making the run time complexity O(z), where z is the total number of non-zero entries in all the {C k } combined.
Method	In general, {C k } are dense and z is O(N 3 ), leading to a computational complexity similar to that of [Treuille et al. 2006].
Method	Differentiating this expression produces closed form expressions for time derivatives of arbitrary order.
Method	These can be useful for alternate integration schemes to improve accuracy or allow time reversibility.
Method	However, considering that stability has already been enforced it may not be a concern for graphics applications.
Method	Greater accuracy could also be easily achieved through high order explicit schemes using a small timestep.
Method	A final integration scheme that is theoretically interesting involves the calculation of an N dimensional rotation matrix R, which, when applied to the coefficient vector w, constrains its motion exactly to the constant energy N -sphere.
Method	This approximates the true geodesic motion of the Euler fluid equations near the current state.
Method	The position vector ω and the tangent vector ω  ̇ span an N −1 dimensional rotation plane that uniquely identifies an N ×N skew symmetric matrix ξ.
Method	This matrix g is an element of so(N ), the Lie algebra of the N -dimensional rotation group SO(N ).
Method	Multiplying by ∆t and exponentiating the matrix yields the N × N rotation matrix R = exp(∆tξ).
Method	This method is more expensive than explicit integration with renormalization, and we have found that in comparison it offers very little gain in accuracy for small timesteps.
Method	However, it is of interest because it preserves the geometric viewpoint of a fluid as a high dimensional rotation group, and provides a more rigorous way of enforcing energy preservation compared to the renormalization correction step.
Method	The operator Adv(u, ω) := curl (ω × u) represents the advection of a fluid’s vorticity by its velocity field.
Method	It has many equivalent expressions, including the the Lie derivative L u ω, or the JacobiLie bracket of vector fields −[u, ω], Adv(Φ i , φ j ) := L Φ i φ j = −[Φ i , φ j ] = curl (φ j × Φ i ).
Method	In our context, all the preceding expressions are equivalent, and any can be used to evaluate the advection of pairs of basis fields.
Method	For discrete domains, it can be approximated numerically on a mesh as described in Section 8.
Method	For every pair of basis functions we evaluate the advection operator and express the result in the finite φ k basis.
Method	The basis coefficients of this projection are the structure coefficients that form the {C k } matrices and satisfy Adv(Φ i , φ j ) = C k [i, j]φ k .
Method	k The Laplacian eigenfunction basis is closed under the Jacobi-Lie bracket.
Method	Hence, we expect the result to factor perfectly into a linear combination of vorticity basis functions.
Method	For simulation, our basis must necessarily be finite dimensional.
Method	Despite closure, the advection operator may produce coefficients beyond the chosen finite bandlimit N which cannot be stored.
Method	This is unavoidable, as the nonlinear advection operator necessitates products of functions.
Method	Considering for example the Fourier basis, the multiplication of two N bandlimited functions is in general bandlimited by 2N .
Method	Physically this represents the cascading of energy to ever higher scales of turbulence.
Method	Projecting the result of the advection operator to our finite dimensional basis amounts to truncating the coefficients beyond the bandlimit N .
Method	However, this truncation is physically motivated, since in a real fluid the vortices will eventually reach a small enough scale and dissipate quickly through viscosity.
Method	A pseudo-code listing of the precomputation procedure is shown in Algorithm 2.
Method	Because the Jacobi-Lie bracket and vector cross product are anti-symmetric operators, the structure coefficient matrices have the property 1 1 C k [i, j] = − C k [j, i].
Method	λ i λ j The antisymmetry reflects an important property of the our basis functions.
Method	The self advection Adv(Φ k , φ k ) of a vorticity basis field φ k by its velocity Φ k is identically zero, and hence u  ̇ = 0, meaning that each velocity basis field is a stationary flow.
Method	This is analogous to the stable rotation of a rigid body about a principal axis [Arnold 1966].
Method	To illustrate the preceding discussion, the evaluation of the structure coefficients in closed form for a 2-D rectangle is provided in Appendix A as an example.
Method	As discussed in Section 4, external forces can be incorporated by projecting f to the velocity basis basis f i = f , Φ i .
Method	The inner product for vector valued f and Φ i is defined by the summation of dot product of vectors at every point x within the domain f , Φ i = f (x) · Φ i (x).
Method	x We make use of external forces to allow immersed moving obstacles and to incorporate a simple buoyancy model.
Method	The eigenfunctions of the Laplacian operator are defined by their domain and boundary conditions, making the velocity and vorticity basis fields domain dependent.
Method	Static irregular boundaries and obstacles are supported in our method through precomputation on general meshes as will be discussed in Section 8.
Method	However, moving obstacles change the shape and boundary conditions of the domain dynamically, and hence require special consideration.
Method	Our goal is to satisfy the internal boundary conditions of immersed objects at all times.
Method	This requirement can be simply stated: in addition to remaining divergence free, the fluid velocity at an object’s boundary should be equal to the normal component of the boundary’s velocity.
Method	This satisfies the free-slip condition when the object is at rest, and equates normal components of the fluid and boundary velocity when the object is in motion.
Method	Our solution is as follows.
Method	At each time-step we project the difference from the desired normal component onto the velocity basis Φ k and subtract the result from the current state vector w.
Method	The result is a divergence free field that best satisfies the desired boundary conditions.
Method	Note that this method is not perfect, as the projected forces only approximate the desired forces to the extent that the basis fields can resolve them.
Method	In other words, to handle obstacles with small spatial features, one must increase N to use basis functions of a sufficiently high spatial frequency.
Result	However, for coarse objects, we have found this method to provide reasonable accuracy, and it is efficient enough to perform interactively without requiring precomputation.
Background	Treuille et al. [2006] also correct the normal velocity component through projection to a divergence free field, and our technique is similar in this respect.
Background	However, in their case an additional set of fields they name the boundary basis are employed that are chosen based on the object’s geometry to best correct for normal velocity components.
Background	The boundary basis allows the free-slip constraint to be more accurately enforced in the vicinity of the boundary, but adds substantially to memory and precomputation expense.
Background	It also does nothing to improve the quality of object-fluid interaction since the underlying simulation basis, to which the boundary basis must be numerically projected, remains unchanged.
Method	In contrast, our basis fields exhibit a spectrum of spatial scales (akin to a Fourier Series) allowing some guarantee of resolving obstacle features with similar length scales.
Method	Although our method does not perfectly resolve the boundary, it avoids the use of multiple bases for simulation and boundaries as well as the associated expensive precomputation and memory requirements.
Method	In some of our examples we incorporate a simple buoyancy model.
Method	Smoke density or particle density are subsampled onto a grid.
Method	Buoyancy forces at each grid centre are calculated through the Boussinesq approximation.
Method	These forces are projected to the velocity basis through pointwise multiplication.
Background	Simple geometries admit basis fields with closed form expressions.
Method	However, our method also supports discrete domains defined on a mesh.
Method	For this, we require a set of basis fields defined on the mesh that are eigenfunctions of a discrete Laplacian operator, as well as a means to precompute their advection numerically.
Background	Discrete exterior calculus (DEC) provides a principled means of describing operators and quantities on simplicial meshes [Desbrun et al. 2005].
Background	It has been applied to fluid simulation in previous work, and we use a discrete formulation on tetrahedral meshes analogous to [Mullen et al. 2009; Elcott et al. 2007].
Method	Regular voxel meshes are also supported as a special case of this discretization.
Method	Through DEC we define the discrete Laplacian operator ∆ = −curl 2 = −d ∗ d∗ which has a representation as a sparse, symmetric matrix.
Method	We compute the eigendecomposition of this matrix to produce the discrete velocity and vorticity basis fields.
Method	The velocity basis fields satisfy a free slip boundary condition and are divergence free, due to constraints imposed implicitly through the Laplacian operator matrix.
Method	For example, to enforce a free-slip velocity boundary condition, we omit (set to zero) the rows of the discrete Laplacian ∆ that calculate velocity flux on boundary faces.
Method	Defined as above, ∆ admits only divergence free solutions in its eigendecomposition.
Method	Examples of basis fields for a tetrahedral mesh are shown in Figure 9 .
Method	We also employ DEC to approximate the advection operator Adv(·, ·) using appropriate discretizations.
Method	This evaluation is similar to that employed in [Mullen et al. 2009].
Method	Other than the discrete representation and computations described above, the rest of our fluid simulation method remains the same.
Method	The operation and performance of the time integration scheme described in Section 5 does not change, since it operates only with the basis coefficients.
Method	However, additional expenses in the case of meshed domains include the storage of discrete basis fields, and the reconstruction of the velocity field through summation.
Result	As we show in Section 9, these costs are reasonable for typical operating parameters, but can become large for simulations employing very fine meshes and large basis dimensionality.
Method	All experiments were performed on a single CPU core.
Method	Time integration was performed using an explicit fourth order Runge Kutta method.
Result	Closed form domains are limited in their boundaries, but have notable advantages in terms of runtimes, precomputation and memory requirements.
Result	For examples including external forces (such as buoyancy or moving obstacles), the cost of projecting the forces on to the basis is noted.
Result	This cost is proportional to the mesh resolution and the number of basis fields.
Method	In the case of the bunny, a subsampled 16 3 density grid is used for the buoyancy force calculations.
Method	For discrete meshes, velocity field reconstruction requires summation of stored basis fields.
Method	This is proportional to the mesh resolution and the dimension of the basis.
Method	On closed form domains, there are two alternatives for velocity reconstruction.
Method	The basis fields may be pre-evaluated on a mesh and stored, just as in the discrete case.
Method	Alternatively, they may be computed on demand.
Method	Closed form evaluation is proportional to the number of basis functions and the number of advected quantities.
Result	Each alternative has its strengths.
Result	Caching the basis fields uses memory, but saves computation when many quantities are being advected through the field (density or millions of particles).
Result	If only a few particles need to be advected (leaves in wind, for example), then evaluating closed form expressions is accurate and fast and does not have additional memory requirements.
Result	A comparison to the stable fluids algorithm is included as a rough qualitative validation.
Result	We demonstrate flow on some simple tetrahedral meshes; however we chose a structured voxelized grid for the bunny example only to facilitate implementation.
Result	A robust tetrahedral mesh implementation would have similar performance characteristics and alleviate the boundary “stair case” artifacts.
Result	The effects of basis dimensionality are illustrated through the bunny example.
Result	Modes with small eigenvalue capture the low frequency motion of the fluid.
Result	Notably, the bunny’s ears do not begin to be resolved until after the 64th mode.
Method	In addition to using the bottom of the spectrum to capture the large scale motion, one may choose additional modes from much higher parts of the spectrum to incorporate smaller scales.
Result	This demonstrates the benefit of a basis that exhibits a spectrum of scales.
Result	Note that these high frequency modes interact and decay physically, in contrast to other post-processing turbulence models.
Result	Our method is most applicable to gaseous phenomena and situations when the domain is entirely filled by fluid.
Result	Currently it is not readily adaptable to typical liquid simulations that require a constantly changing fluid domain with a free surface.
Result	We have shown that interesting dynamics can be captured in a reasonably sized basis dimension and simulated interactively.
Result	However, various issues prevent it from scaling well to very large basis dimension or grid resolutions.
Result	For irregular domains, the runtime is in general O(N 3 ).
Result	For discrete meshes, the cost of reconstructing the velocity field and projecting external forces grows linearly with the basis dimension and mesh resolution.
Result	Many of these issues are not present for domains with closed form expressions.
Result	However, in this case the shape of the boundary is limited.
Result	Also, when advecting many particles or projecting many forces the velocity basis fields must still be cached as the cost of closed form evaluations become prohibitive.
Result	We believe our method has potential to be exploited for the expressive control of fluid phenomena.
Result	We have shown how to continuously change the basis coefficients to simulate the physical motion of a fluid.
Result	However, any smooth curve through coefficient space, physical or not, may be perceived as “fluid-like” as it represents a continuously changing volume preserving flow that respects all boundary conditions.
Result	In addition to constructing completely arbitrary flows, perturbing existing physical paths offers a means to deviate from physics while quantifying this deviation.
Result	Due to orthogonality of the basis and its correspondence with vorticity of varying scales, we have a unique mechanism for spectral energy control.
Future Work	This could be used to implement timevarying filters to amplify or attenuate parts of the spectrum, such as achieving crescendos of turbulence or gradual calming.
Result	Again, we have a means of quantifying the deviation from non-physical energy behavior, as we have shown how to decay the spectrum according to physical viscosity.
Background	Space-time control for fluids has been attempted previously in [Treuille et al. 2003; McNamara et al. 2004; Fattal and Lischinski 2004].
Background	Many of these methods can be expensive because the optimization scales sharply with the size of the grid, making them impractical for interesting domains.
Background	A low dimensional basis offers a good setting to implement control policies that would be intractable in higher dimensions as demonstrated for example by Barbi c et al. [Barbi c et al. 2009].
Future Work	Our method’s availability of closed form expressions for time derivatives could also prove useful in optimization algorithms.
Result	Our method is fast enough to be interactive, and is very memory efficient and well formulated on rectangular domains due to the available closed form expressions.
Future Work	This makes it particularly attractive for use in image based settings such as painting applications that simulate fluid phenomena, as we briefly demonstrate in the video.
Future Work	Additional potential uses in this vein include texture synthesis and non-photorealistic rendering.
Future Work	Boundaries of moving obstacles are handled only approximately and could benefit from alternate methods.
Future Work	We have presented a fast and stable integration scheme; however, additional time integrators could be explored, particularly symmetric integrators to allow time reversibility as was achieved in [Mullen et al. 2009].
Future Work	Time reversibility could prove useful in fluid control applications, as was demonstrated for rigid bodies by Twigg and James [2008].
Result	We have evaluated the advection operator symbolically for closed form expressions on rectangular 2-D and 3-D domains.
Future Work	The same could be done for additional geometries, such as a 2-D disk or a spherical surface.
Future Work	Also, different boundary conditions (for example, a wrap-around boundary condition) remain to be considered, which could prove useful for tilings of fluid simulation domains [Wicke et al. 2009].
Result	Divergence free fields have many potential uses besides simulating natural phenomena.
Background	Fluid motion describes the optimal transport in an incompressible medium, and can be used to quantify volume preserving deformations.
Result	This has uses in image analysis and shape deformation.
Future Work	We plan to consider how the unique properties of our method could be exploited in these fields.
Future Work	In particular, the elegant formulation on rectangular domains could make it useful for medical image registration.
Future Work	Additionally, the availability of closed form expressions and flexibility in choosing the basis dimension make it an accurate and tractable model for optimization methods.
Future Work	This could be useful for the inverse modelling of real fluid flows for the purpose of parameter estimation, for example to estimate viscosity from sampled velocity measurements.
Result	We have presented a fluid simulation method that uses eigenfunctions of the vector Laplacian as bases.
Result	We have described many of its unique properties and its use as a practical means of fluid simulation for computer graphics.
Result	The orthogonality of the basis functions and their correspondence to a spectrum of vorticity scales enables energy control at varying turbulent scales.
Result	We have used this property to enforce stability of integrators and simulate physical viscosity.
Result	Flexibility in choosing basis dimensionality and the ability to integrate directly in a space of basis coefficients permits computational efficiency, enabling interactive performance.
Result	The existence of closed form solutions for simple domains allows symbolic evaluation of the advection operator and the ability to sparsely evaluate velocities on demand.
Result	We have demonstrated some of the useful properties of our method, but many exciting avenues remain to be explored.
Future Work	We plan to investigate its use for the the expressive control of fluid motion, such as spectral energy control and space time optimization.
Future Work	We also believe there is potential for our method to be exploited in other research areas such as medical imaging and inverse flow modelling.
Method	We evaluate Adv(Φ i , φ j ) = curl (φ j × Φ i ) recalling that i, j are vector wave numbers i = (i 1 , i 2 ), j = (j 1 , j 2 ) and the eigenvalues λ i = −(i 2 1 + i 2 2 ).
Method	This simplifies to 1 Adv(Φ i , φ j ) = i 1 j 2 cos(i 1 x) cos(j 2 y) sin(j 1 x) sin(i 2 y) λ i 1 − i 2 j 1 cos(j 1 x) cos(i 2 y) sin(i 1 x) sin(j 2 y) a z .
Method	The resulting coefficients are stored in the {C k } matrices 1 C i 1 +j 1 ,i 2 +j 2 [i, j] = − 4(i 1 2 + i 2 2 ) (i 1 j 2 − i 2 j 1 ) 1 C i 1 +j 1 ,i 2 −j 2 [i, j] = 4(i 1 2 + i 2 2 ) (i 1 j 2 + i 2 j 1 ) 1 C i 1 −j 1 ,i 2 +j 2 [i, j] = − 4(i 1 2 + i 2 2 ) (i 1 j 2 + i 2 j 1 ) 1 C i 1 −j 1 ,i 2 −j 2 [i, j] = 4(i 1 2 − i 2 2 ) (i 1 j 2 − i 2 j 1 ).
Method	This result demonstrates closure of the advection operator.
Method	The indices i, j are meant figuratively, as they represent tuples of integers.
Method	A suitable re-mapping from (i 1 , i 2 ) and (j 1 , j 2 ) to positive integers is necessary in an implementation.
Method	When outside of the storable finite range, they are discarded as described previously.
Method	Note the sums of indices i 1 + j 1 and i 2 + j 2 , which reflect the doubling in bandlimit due to multiplication of sinusoidal functions.

Background	The most widely used skeletal animation algorithm, linear blend skinning, is also known as skeleton subspace deformation, vertex blending, or enveloping.
Problem	It runs in real-time even on a low-end hardware but it is also notorious for its failures, such as the collapsing-joints artifacts.
Result	We present a new algorithm which removes these shortcomings while maintaining almost the same time and memory complexity as the linear blend skinning.
Result	Unlike other approaches, our method works with exactly the same input data as the popular linear version.
Result	This minimizes the cost of upgrade from linear to spherical blend skinning in many existing applications: the data structures and models need no change at all.
Problem	The paper discusses also theoretical properties of rotation interpolation, essential to spherical blend skinning.
Problem	Real-time animation of deformable objects is always a compromise between visual fidelity and computation complexity.
Problem	Other aspects are quite important as well, for example the amount of artists work necessary to design the model.
Background	Therefore, there exist many algorithms for modeling deformable objects in the literature.
Background	They differ by the intended area of application and generality of allowed models.
Method	We focus on the real-time animation systems in this paper.
Background	Its most popular representative, known generally as the skeletal animation, is based on simple but versatile structure.
Background	It consists of joints, given by their position and orientation.
Background	The segments connecting the joints are conveniently interpreted as bones.
Background	The skeleton is, formally speaking, a tree whose nodes are identified with the joints and edges with the bones.
Background	The only displayed element is a skin, a 3D polygonal mesh, usually equipped with normal and texture data.
Background	Although the terminology is adopted from the virtual humanoid modeling, the skeletal animation is not limited to character animation – it can be applied to a wide range of soft objects, including imaginary (cartoon) creatures, plants, furniture, etc.
Background	This is an apparent advantage over complex systems which rely on explicit anatomy.
Background	The skeleton simplifies the animation task considerably: instead of animating each vertex individually, it is sufficient to manipulate the skeleton, and the skin deforms automatically.
Background	The skeletal animation in general does not specify how exactly the skeleton posture should be propagated to the skin.
Background	However, there is an established standard used in majority of real-time 3D applications.
Background	It comes by many names, all relating to the same algorithm: linear blend skinning (LBS), skeleton subspace deformation, vertex blending, enveloping, or simply skinning.
Background	Basically, this algorithm blends between rigidly transformed vertices using vertex weights, which denote the amount of influence of individual joints.
Problem	Although LBS is very fast and advantageous to graphics hardware, it suffers from inherent artifacts, known as ”collapsing joints”, ”twisting elbow problem” or a ”candy-wrapper artifact”.
Problem	In general, the mesh deformed by LBS loses volume as the joint rotation increases.
Background	An early contribution concerning the animation of deformable objects is [Magnenat-Thalmann et al. 1988], which considers the movement of a human hand.
Background	First 3D characters used in numerous computer games were animated by simple, often unpublished algorithms.
Background	Later on, the basic principles of LBS were described by the game development community [Lander 1998; Lander 1999].
Background	The artifacts of LBS were discovered soon [Weber 2000].
Background	An improvement based on addition of auxiliary joints has been also proposed in [Weber 2000].
Problem	Although this reduces the artifacts, the skin to joints relationship must be re-designed after joint addition.
Background	The number and location of the additional joints remains questionable.
Problem	Another problem is how the movement of the original skeleton should be propagated into the augmented one.
Background	More formal articles consider skin deformation as an interpolation problem, such as [Lewis et al. 2000].
Background	They use radial basis functions to interpolate between example skins with different shapes.
Background	Similar method is presented in [Sloan et al. 2001] and [Kry et al. 2002].
Background	The latter de-correlates the deformation displacements using principal component analysis, which reduces the memory requirements considerably.
Background	The advantage of example based methods is that they capture the designed shape, including effects like muscle bulging.
Background	The drawback is the necessity of acquiring the example skins.
Background	An interesting generalization of LBS is called multi-weight enveloping [Wang and Phillips 2002].
Background	It introduces more parameters and therefore greater flexibility to the deformation algorithm.
Background	Instead of one weight per influence (joint) as in LBS, the multiweight enveloping uses twelve.
Background	These numerous parameters are derived from examples using the least squares optimization.
Background	The disadvantage is obvious: while the LBS models can be weighted manually by artists [Steed 2002], this is questionable with multiweight enveloping.
Background	Tools that help animators to design the vertex weights are described in [Mohr et al. 2003].
Background	This article is interesting also from the theoretical point of view, because it describes how to explore the space of all possible LBS deformations.
Background	Another deformation algorithm [Bloomenthal 2002] uses a complex auxiliary structure – a medial.
Background	An idea similar to spherical blend skinning (SBS) is bones blending proposed by [Kavan and Zára ˇ 2003].
Background	However, bones blending is limited to vertices attached to only two joints.
Background	In addition, it requires hand-tuning of special parameters.
Background	Another algorithm removes the LBS artifacts by adding additional joints, and computes the vertex weights automatically using examples [Mohr and Gleicher 2003].
Background	A recent skin deformation algorithm presented in [Magnenat-Thalmann et al. 2004] seems to give results competitive to SBS, although it is based on a different mathematical fundament [Alexa 2002].
Background	However, this method is considerably slower than LBS and therefore [Magnenat-Thalmann et al. 2004] recommends to use rather the standard LBS if the joint rotations are small.
Background	To conclude, there are many methods correcting the problems of LBS, but none of them is superior to LBS in all aspects.
Background	As a result, the linear blend skinning is still widely used in many applications, in spite of the artifacts.
Problem	We observed that the artifacts of LBS are caused by the straightforward, linear interpolation of vertex positions.
Problem	Intuitively, a linear blending is not suitable to capture deformations induced by skeleton, because their nature is rather spherical.
Method	Our basic idea is to change the interpolation domain: we interpolate transformations itself instead of transformed vertex positions.
Method	Because we consider transformations consisting of a translation and rotation, we suggest to use a quaternion representation.
Problem	The transition to non-linear interpolation domain is not elementary.
Problem	In order to achieve our goal, we cope with two main problems: determination of the center of rotation, and interpolation of multiple quaternions.
Problem	The first problem follows from the fact that the choice of the center of rotation influences the result of interpolation considerably.
Result	We show how to compute a convenient center of rotation in real-time.
Problem	The second problem is simple in the case of two quaternions [Shoemake 1985], but gets considerably harder for more than two rotations [Buss and Fillmore 2001; Park et al. 2002; Alexa 2002].
Method	Because the previous methods are not efficient enough for our purpose, we use a simple linear quaternion averaging.
Result	We justify both theoretically and experimentally that this solution is appropriate for our task (and probably for many others).
Result	Resolving those problems, we obtain a skin animation algorithm that deforms the mesh in much more plausible way then LBS.
Result	Because we change only the interpolation domain and not the input data, our program works with exactly the same models as LBS.
Result	The proposed algorithm improves a deformed shape even of models that have been designed and carefully tuned for LBS.
Result	Considering the high speed and low memory demands of SBS, it provides an attractive alternative to classic LBS.
Method	Let us denote matrices by capital letters, while vectors and quaternions by bold.
Method	Vectors are considered column vectors, therefore a multiplication of vector v by matrix M is written as Mv.
Method	We do not introduce a different notation for the R 3 vectors and their homogeneous R 4 counterparts with last coordinate equal to 1.
Method	The same convention is used for matrices.
Method	We denote the dot product of two vectors v 1 , v 2 as (v 1 , v 2 ) and the norm v 1 as a shortcut for (v 1 , v 1 ).
Background	The input to LBS consists of a polygonal mesh representing the digital skin, a skeleton, and vertex weights for every vertex of the skin.
Background	The polygonal mesh and the skeleton are designed in a reference position, e.g. virtual characters are often posed in the da Vinci posture [Steed 2002].
Method	Let us label the joints by integer numbers, assigning zero to the root.
Method	Each joint in the reference posture is associated with a homogeneous matrix, describing its position and orientation in the world coordinate system.
Method	For j-th joint, we denote this matrix by A j , like ”absolute” (or reference) position.
Method	This matrix is computed by multiplying all the transformations of individual joints in the chain from root to joint j.
Method	To compute the shape of the deformed skin, we need yet another set of matrices, describing the position and orientation of joints in the actual, animated posture.
Method	We call them F j , standing for the ”final” placement of joint j.
Method	Matrices F j are computed in a similar way as the absolute matrices, but including the actual rotation of each joint in the chain (we do not consider translating and scaling joints).
Method	The most simple skin deformation algorithm computes v = F j A −1 j v where v is a vertex in the reference skin associated with joint j and v is its position in the deformed mesh.
Method	The interpretation is following: the first matrix A −1 j transforms v to the position with joint j’s coordinate system aligned to the world coordinate system.
Method	The following transformation F j returns the vertex to its current position induced by the animated skeleton.
Method	Because these transformations usually occur together, we define the ”complete” matrix C j = F j A −1 j .
Background	Some older computer games animated characters in this way, even though it does not produce nice, smooth deformations.
Method	The linear blend skinning allows assignment of one vertex to multiple bones.
Method	Assume that vertex v is attached to joints j 1 , . . . , j n with weights w 1 , . . . , w n .
Method	The weights are coefficients of a convex combination, i.e. non-negative and ∑ n i=1 w i = 1.
Method	The weight w i represents the amount of influence of joint j i .
Method	For example if n = 2 then vertex v lies on the line segment connecting C j 1 v and C j 2 v.
Method	The actual position on the segment is given by weight w 1 (or w 2 , because w 1 +w 2 = 1).
Method	As explained in the next section, the SBS works on a circular arc instead of segment, see Figure 1 .
Method	If the joint rotations are large, the LBS produces non-natural deformations.
Method	In the extremal case of rotation by 180 degrees, the skin can collapse to a single point.
Method	It is the notorious ”candy-wrapper” artifact, which is demonstrated in Figure 2 .
Method	The right shoulder of the model is twisted by 180 degrees, while the left shoulder is left in the reference pose.
Method	To understand why this undesirable effect occurs, it is sufficient to re-arrange the equation (1)
Method	This formula is less efficient, because it blends matrices instead of vectors, but gives us a valuable insight.
Method	It is well known that the component-wise interpolation of matrices produces odd results: it does not preserve the orthogonality of the rotational part of the matrix.
Method	In some situations, it does not preserve even the rank of the interpolated matrices.
Problem	This is exactly what happens in the ”candywrapper” problem: the single point the skin collapses to is a result of transformation by a singular matrix.
Problem	A similar defect is visible also in the proximity of the singular configuration.
Problem	Although the matrix is regular, it involves a non-uniform scaling and skewing, which is responsible for the loss of volume of the deformed skin even for small rotations.
Problem	Instead of trying to correct the bad results of LBS, we propose to change the interpolation method in (2).
Method	We focus on the interpolation of rotations – the linear interpolation of the translation part of C j i matrices is all right.
Method	An established interpolation of two rotations is spherical linear interpolation (SLERP) [Shoemake 1985].
Method	Its key of success is the use of quaternions to represent rotations.
Method	Unfortunately, it is not possible to simply replace matrices C j i in (2) with corresponding pairs quaternion-translation.
Method	One of the problems is that the linear interpolation of quaternions is not equivalent to SLERP.
Method	However, this is not the most serious difficulty, and we address it in section 4.1.
Problem	The more important problem is to compute a convenient center of the interpolated rotations.
Problem	We show that this is really an important problem on an example of human arm.
Method	Consider that the arm geometry is influenced by two joints j 1 and j 2 , such that j 1 is a parent of j 2 , as in Figure 1 .
Method	The transformation of the whole mesh by C j 1 is illustrated in the top row of Figure 3 and the transformation of the same geometry by C j 2 in the bottom row (note that the results are identical in both columns of these rows).
Method	The rows in the middle show the progress of interpolation between C j 1 to C j 2 .
Method	The only difference between the two columns in Figure 3 is in the choice of the center of rotation.
Method	In the left column, the rotation center r c is set to the translation part of matrix A j 2 (the position of joint j 2 in the reference posture).
Method	Note that C j 1 r c = C j 2 r c , therefore also the transformed rotation center is constant during the interpolation.
Method	In the right column of the figure, the rotation center r c is set to the translation part of A j 1 .
Method	Because C j 1 r c = C j 2 r c , the transformed rotation center is linearly interpolated from C j 1 r c to C j 2 r c .
Method	By comparison with the starting mesh (drawn gray in each frame), it is obvious that the center of rotation choice in the left column is much more advantageous.
Method	In this case, the interpolation of every single point is a circular arc (as in Figure 1), whereas a disturbing drift is inherent to any other choice of rotation center (such as r c ).
Method	Unfortunately, the condition of zero translation cannot be always satisfied, typically for more than two influencing joints.
Method	But even if the vertex is attached to only two joints k and l that are not neighbours of each other, some translation may be inevitable.
Method	For example consider that there is no relative rotation between C k and C l , but there is a relative translation induced by the joints in the chain between k and l.
Method	Clearly no choice of the center of rotation can avoid this translation, because the rotation is identity.
Method	Anyway, it is possible to define the rotation center as the point whose transformations by associated matrices are as close as possible.
Method	This minimizes the drift and works even if the vertex is assigned to n joints j 1 , . . . , j n .
Method	In general, we cannot make any assumptions about the rank of matrix D, which can vary from 0 to 3 (consider for example n = 2 and C j 1 = C j 2 ).
Method	We search the optimal solution r c in the least-squares sense.
Method	If there are multiple solutions giving the minimal Dr c − e , the r c with the minimal norm is chosen.
Method	This can be done in a robust way using the singular value decomposition (SVD), followed by computation of pseudo-inverse matrix.
Method	To perform these computations, we use the LAPACK software [Anderson et al. 1999].
Method	Even though LAPACK routines are efficient, computation of the center of rotation per each vertex would not result in a real-time algorithm.
Method	Fortunately, the center of rotation depends only on the transformations of the joints j 1 , . . . , j n and not the vertex itself.
Method	Therefore, if we encounter another vertex assigned to the same set of joints j 1 , . . . , j n , we can re-use the center of rotation computed formerly (cached).
Method	Moreover, if there is only one, or two neighboring joints that influence the vertex, we can determine the center of rotation precisely (as indicated in the beginning of this section) and omit the SVD computation at all.
Method	It turns out that the number of different non-trivial joint sets, and therefore the number of running the SVD, is surprisingly small for common models – about several tens.
Method	This enables the real-time performance.
Background	As mentioned in the introduction, the interpolation of multiple rotations has already received some attention [Buss and Fillmore 2001; Park et al. 2002] as well as interpolation of multiple general transformations [Alexa 2002].
Background	Unfortunately, all these methods are substantially slower then the simple linear interpolation used in LBS.
Problem	Since our goal is an algorithm with comparable time complexity as LBS, we propose an approximate but fast linear quaternion blending.
Method	For the case of two rotations, we compare our method with the established SLERP.
Method	Recall that a rotation around axis a (unit length vector) with angle 2 α corresponds to quaternion q = cos α + a sin α .
Method	However, this correspondence is not unique, because both quaternions q and −q represent the same rotation.
Method	The SLERP of two unit quaternions p, q assumes that their dot product (p, q) ≥ 0.
Method	If the dot product (p, q) < 0, we use −p instead of p, which is possible because both p and −p represent the same rotation.
Method	The SLERP of p, q with interpolation parameter t ∈ 0, 1 is given by the following formula, see for example [Eberly 2001].
Method	The difference to SLERP is obvious: QLERP interpolates along the shortest segment, and then projects to arc, which does not result in the uniform interpolation of the arc.
Method	In spite of this, we claim that QLERP is sufficient for our task.
Method	In order to justify this statement, we face an interesting question by itself: how big can be the difference between QLERP and SLERP for the same input rotations?
Method	For SLERP, we denote this quaternion as r s (t).
Method	The quaternion 1 represents the identity (zero angle rotation).
Method	From the definition of quaternion multiplication it can be seen that the real part of p ∗ q equals (p, q) = cos θ .
Method	Since p ∗ q is a unit quaternion, we can express it as p ∗ q = cos θ + u sin θ for some axis of rotation u.
Method	If we substitute this into equation (5), we obtain sin((1 − t) θ ) + sin(t θ ) cos θ r s (t) = sin θ + u sin(t θ ) which means that the direction of the axis u is independent on t.
Method	Let us examine the rotation r l (t) following p in QLERP: r l (t) = p ∗ l(t; p, q) = (1 (1 − − t)1 t)p + + tp tq ∗ q = (1 − t + t cos θ ) t sin θ = + u (1 − t)p + tq (1 − t)p + tq which shows that the axis of rotation has the same direction.
Method	We can conclude with an important property: the SLERP can be written as pr s (t) and QLERP as pr l (t), where the rotations r s (t) and r l (t) have the same axis.
Method	Moreover, this axis is constant, i.e. independent on the interpolation parameter t.
Method	It follows that the only difference between QLERP and SLERP is in the angle of rotations r s (t) and r l (t).
Method	Note that both r s (t) and r l (t) have a form of linear combination of quaternions 1 and p ∗ q.
Method	It means that the results of both r s (t) and r l (t) always end up in certain 2D subspace of R 4 .
Method	We can restrict our attention to this subspace (the linear hull of 1 and p ∗ q).
Method	Since SLERP assumes cos θ = (p, q) ≥ 0, the angle θ cannot exceed π /2.
Method	To obtain an upper bound of the maximal difference in the angle, we consider the extremal case with θ = π /2, depicted in Figure 4 .
Method	The angle α (t) on the picture can be computed by atan, and β (t) by simple linear interpolation of the right angle, which yields the difference function t π d(t) = α (t) − β (t) = atan − t 1 − t 2 It remains to find the extremes of d(t) on the interval 0, 1 .
Method	The elementary mathematical analysis discovers the global extremes in points 1/2 ± (1/ π − 1/4).
Method	The absolute value of d(t) in these points is approximately 0.071 radians (4.07 degrees).
Method	As mentioned in the introduction of this section the angle of rotation is twice the angle inclined by quaternions.
Method	To conclude: both SLERP and QLERP interpolate by multiplying the first quaternion with a rotation with the same, fixed axis.
Method	The difference between SLERP and QLERP is only in the angle of this rotation, and is strictly less then 0.143 radians (8.15 degrees) for any interpolation parameter t ∈ 0, 1 .
Method	This is an upper bound; practical results are much smaller and could hardly cause an observable defect in the deformed skin.
Method	The big advantage of QLERP is that it can be easily generalized to interpolate multiple rotations – it suffices to make a convex combination and re-normalization of multiple quaternions.
Method	Now we have prepared all the ingredients to describe how the SBS algorithm works.
Method	The task is to transform a vertex v influenced by joints j 1 , . . . , j n with convex weights W = (w 1 , . . . , w n ) to its position v in the animated skin.
Method	In order to obtain an appealing deformation, it is necessary to respect the computed center of rotation r c .
Method	To achieve this, we extend the QLERP scheme to homogeneous matrices C j i .
Method	First, the rotation submatrices C rot j i are converted to quaternions q j i .
Method	One of them, for example q j 1 , is chosen as pivot.
Method	If (q j 1 , q j i ) < 0 for any i = 2, . . . , n, we replace q j i with −q j i (by analogy to SLERP).
Method	In order to change the center of rotation from the origin to r c , we define a homogeneous matrix        T = 0 I T r 1 c (7)        where I is a 3 × 3 identity matrix.
Method	Note that the shift of the center of rotation does not influence the interpolated rotation – it manifests only in the translation part.
Method	The desired transformation of vertex v is v = T q(W ; T −1 C j 1 T, . . . , T −1 C j n T )T −1 v
Method	The equation (9) has to be evaluated once per each vertex, and therefore should be as efficient as possible.
Method	The basic optimization is to pre-compute the quaternions q j i , because they do not depend on the actual vertex – only on the joint’s transformation, similarly as the rotation centers r c .
Method	Nonetheless, QLERP has to be executed for each vertex, since weights w 1 , . . . , w n can vary.
Method	In order to challenge the speed of LBS, we apply a following trick.
Method	The vertex v can be represented by a quaternion with zero real part.
Method	In this representation, its rotation by quaternion q can be expressed as q vq ∗ , which is a quaternion with zero real part as well [Eberly 2001].
Method	Therefore, we can compute the Q matrix from (9) as Q = (s,s) Q and save the sqrt operation.
Method	Some attention must be paid because standard routines for quaternion to matrix conversion assume a unit-length quaternion.
Method	First, if we substitute r c in place of v, no rotation occurs, which means that r c is indeed a center of rotation.
Method	Second, if n = 2 and C j 1 r c = C j 2 r c (as in the beginning of section 4), the translation part becomes w 1 C j 1 r c + w 2 C j 2 r c = (w 1 + w 2 )C j 1 r c = C j 1 r c which is independent of interpolation parameters (weights), i.e. the translation during interpolation is constant indeed.
Method	Third, the equation (9) is nothing but a generalization of LBS to an arbitrary method of rotation interpolation.
Method	The choice of QLERP is not important for (9), the matrix Q can be replaced by matrix resulting from any other interpolation scheme, such as [Buss and Fillmore 2001].
Method	If we substitute Q = ∑ w i C rot j i , i.e. a simple linear combination of rotation matrices, we obtain v = Q(v − r c ) + ∑ w i C j i r c = ∑ w i C rot j i v − ∑ w i C rot j i r c + ∑ w i C rot j i r c + ∑ w i C tr j i = ∑ w i C rot j i v + ∑ w i C tr j i = ∑ w i C j i v which is exactly the LBS equation (1).
Method	This also shows that LBS is a special case, which is independent of the center of rotation.
Method	The whole algorithm can be summarized in the following steps:
Method	We tested the SBS algorithm on three models, see Figure 5 and Table 1.
Method	We compare the shape of the deformed skin on the model of woman, because human eye is most sensitive to the deformations of human body.
Result	Another example has been presented already in Figure 2 .
Result	For small deformations, both algorithms produce similar results, as in the second row of Figure 6 (although a small loss of volume is noticeable even there).
Result	It is remarkable that the results of SBS are better even though the models have been optimised to work with the LBS algorithm.
Result	The performance of both algorithms is compared in Table 2 .
Result	The measured value is an average time in milliseconds necessary to deform one model on a 2.5GHz Athlon PC (rendering time not included).
Result	Put in another way, it is exactly the number of singular-value decompositions performed by the SBS algorithm.
Result	This number participates considerably on the difference between times for LBS and SBS.
Result	Theoretically, the number of different non-trivial joint sets could be very high.
Result	Fortunately, this number is surprisingly small in practice, because the joint influences tend to be local (e.g. it is unlikely to find vertices influenced by both left and right wrist).
Result	The additional memory needed for SBS is dominated by caching the computed centers of rotation.
Result	However, this amount of memory is negligible, considering the number of different non-trivial joint sets.
Method	In order to test the accuracy of QLERP, we experimented with spherical weighted averages presented in [Buss and Fillmore 2001].
Result	The algorithm proposed in [Buss and Fillmore 2001] behaves like SLERP for the case of two rotations (in contrast to QLERP, which only approximates SLERP results).
Result	On the one hand, the difference in the deformed skin was barely observable, according to the results from section 4.1.
Result	On the other hand, the increase in the execution time was quite substantial.
Result	For the woman model, the time increased from original 4.54ms to 22.74ms.
Result	This only confirmed our choice of QLERP.
Result	The proposed skin deformation system is by no means perfect; it cannot compete with complex, layered models.
Result	However, the SBS algorithm offers reasonable price for elimination of the notorious LBS artifacts.
Result	The time and memory complexity of both algorithms is comparable.
Result	The overhead of replacing an existing LBS implementation by SBS is minimal, because the input data, as well as the internal data structures, are the same.
Result	In contrast to other methods, the SBS does not need any additional information, such as the example skins.
Future Work	The presented algorithm opens many questions and suggests several directions of future work.
Result	First of all, we worked only with vertex weights optimised for LBS.
Result	These weights are designed to suppress the LBS artifacts, even though they cannot remove them.
Future Work	It would be interesting to find out how much can be the SBS results improved by a set of weights especially designed for SBS.
Future Work	In order to accomplish this, a tool to explore the space of SBS deformations would help considerably.
Future Work	This tool has been presented for LBS in [Mohr et al. 2003], but the situation of SBS is somewhat more complex, because our interpolation method is non-linear.
Future Work	Similarly, it would be possible to estimate the SBS vertex weights from examples, as was done for LBS in [Mohr and Gleicher 2003].
Future Work	This could also cover additional effects like muscle bulging.
Method	In this appendix we derive the formula (9), which describes the interpolation of rotations with respect to r c – a custom center of rotation.
Method	Let us denote by K the coordinate system with origin in r c and identical basis vectors as the world coordinate system.
Method	Then        the matrix T (7) can be interpreted as a transformation from K to the world coordinate system.
Method	We can express this matrix with respect to the world coordinate system easily T q(W ; T −1 C j 1 T, . . . , T −1 C j n T )T −1 which is exactly the formula (8).
Method	Recall that the matrix C j i has structure C j i = C 0 rot j T i C 1 tr j i        which enables us to write out T −1 C j i T = C 0 rot j T i C j i r c 1 − r c        as can be simply verified.
Method	Please note that the change of the coordinate system did not influence the rotation part C rot j i at all.
Method	Therefore the result of QLERP will be, according to equation (6)        q(W ; T −1 C j 1 T, . . . , T −1 C j n T ) = 0 Q T −r c + ∑ i=1 n 1 w i C j i r c        where Q stands for the interpolation of pure rotations, computed as indicated in section 4.2.
Method	Using T −1 v = v − r c and T x = x + r c , we see that v = T q(W ; T −1 C j 1 T, . . . , T −1 C j n T )T −1 v = T 0 Q T −r c + ∑ i=1 n 1 w i C j i r c v − 1 r c n = Q(v − r c ) + ∑ w i C j i r c i=1        is true for any vector v.
Method	This is exactly the equation (9).

Result	Pose space deformation generalizes and improves upon both shape interpolation and common skeleton-driven deformation techniques.
Problem	This deformation approach proceeds from the observation that several types of deformation can be uniformly represented as mappings from a pose space, defined by either an underlying skeleton or a more abstract system of parameters, to displacements in the object local coordinate frames.
Method	Once this uniform representation is identified, previously disparate deformation types can be accomplished within a single unified approach.
Result	The advantages of this algorithm include improved expressive power and direct manipulation of the desired shapes yet the performance associated with traditional shape interpolation is achievable.
Result	Appropriate applications include animation of facial and body deformation for entertainment, telepresence, computer gaming, and other applications where direct sculpting of deformations is desired or where real-time synthesis of a deforming model is required.
Background	Free form deformation has been approached from several distinct perspectives.
Background	As an abstract and general problem, good methods have been obtained both using the well known technique that bears this name [ 32 , 12 , 17 ] and other kinematic surface deformation techniques, and with physical models that simulate the time evolution of a membrane or solid.
Background	The animation of human and creature skin deformation is arguably the most common and important application of free form deformation in computer graphics.
Background	While such creature animation can be considered a special case of general free form deformation, its importance and difficulty have lead researchers to propose a number of domain-specific algorithms that will be reviewed in Section 2.
Problem	The problem of realistic facial animation is being actively and successfully addressed by image-based and hybrid techniques.
Problem	These techniques are not yet suitable for all applications, however: while a purely image-based approach can achieve very realistic images, this advantage may be lost if one needs to introduce geometry and surface reflectance in order to re-light characters to match preexisting or dynamically computed environments.
Problem	Film and entertainment applications require fanciful creatures that fall outside the scope of image-based approaches.
Background	Some of the most impressive examples of geometry-based (as opposed to image-based) human and creature animation have been obtained in the entertainment industry.
Background	These efforts traditionally use shape interpolation for facial animation and a standard but variously-named algorithm that we will term skeleton subspace deformation (SSD) for basic body deformation [ 25 , 9 ].
Problem	While shape interpolation is well-liked by production animators, it is not suitable for skeleton-driven deformation.
Problem	On the other hand SSD produces characteristic defects and is notoriously difficult to control.
Problem	These issues, which will be detailed in the next section, lead us to look for a more general approach to surface deformation.
Problem	New creature topologies should be accommodated without programming or considerable setup efforts.
Problem	• It should be possible to specify arbitrary desired deformations at arbitrary points in the parameter space, with smooth interpolation of the deformation between these points.
Problem	• The system should allow direct manipulation of the desired deformations [ 33 ].
Problem	• The locality of deformation should be controllable, both spatially and in the skeleton’s configuration space (pose space).
Problem	• In addition, we target a conventional animator-controlled work process rather than an approach based on automatic simulation.
Problem	As such we require that animators be able to visualize the interaction of a reasonably high-resolution model with an environment in real time (with ‘high resolution’ defined in accord with current expectations).
Problem	Real time synthesis is also required for applications such as avatars and computer games.
Result	Our solution, termed pose space deformation, provides a uniform and expressive approach to both facial skin deformation and skeleton-driven deformation.
Result	It addresses the previously mentioned drawbacks of shape interpolation and SSD while retaining the simplicity and performance associated with these techniques.
Background	Recent research has delivered significant improvements in many areas of character animation, including surface representation, model capture, performance capture, and hybrid (partially image-based) rendering approaches.
Background	Continuous deformation of a character skin was first addressed in Parke’s pioneering facial animation work [ 26 ].
Background	In this work, control vertices were deformed by custom algorithmic implementation of carefully selected high-level parameters (‘raise-upper-lip’, etc.).
Background	Komatsu [ 13 ] and Magnenat-Thalmann et. al. [ 23 ] demonstrated human body deformation driven by an underlying skeleton.
Background	The region and shape of deformation is algorithmically defined in each of these approaches.
Background	Magnenat-Thalmann et. al. developed algorithms for each of the various joints in the hand.
Background	The discussion in Komatsu focuses on the elbow and shows how the skin crease on the acute side can be obtained by a suitable algorithmic manipulation of the surface control vertices.
Background	The algorithms in this early work do not suffer the ‘collapsing elbow’ characteristic of the SSD algorithm (below).
Background	On the other hand, the algorithms are specific to particular types of joints and are perhaps too simple to portray the complexity and individual variability of real anatomy.
Background	The short film Tony de Peltrie [ 3 ] popularized the use of shape interpolation for facial animation.
Background	Forsey [ 11 ] describes a characteroriented deformation scheme in which the bending of a smooth surface can be controlled by anchoring levels of a multi-resolution spline surface to the underlying skeleton.
Background	These efforts are distinguished from the previous purely algorithmic approaches in giving the modeler control of and responsibility for the deformation.
Background	The specification and animation of surface deformation remains an active area of investigation [ 17 , 10 ].
Background	The Wires technique [ 22 ] is one interesting recent contribution; this approach is notable in providing a direct manipulation interface in a form immediately familiar to sculptors (armatures).
Background	Chadwick, Haumann, and Parent [ 7 ] introduced a multi-layered and physically inspired approach to skin deformation.
Background	In their model a free-form deformation abstractly represents underlying body tissues and mediates skin movement.
Background	Chadwick et. al. demonstrated expressive three-dimensional cartoon characters but deformation of a realistic character was not shown.
Background	Other researchers have investigated modeling the underlying body tissues in greater depth [ 27 , 24 , 8 , 35 ].
Background	Most recently, several groups have undertaken ambitious efforts to produce anatomically inspired multi-layered models of animals and humans with considerable verisimilitude.
Background	Nedel and Thalmann [ 19 ] simulate the surface deformation of muscles using spring mesh dynamics; a modeled skin cross section is reshaped by a ray-casting procedure that finds the maximum displacement of the underlying tissue.
Background	Several papers by Wilhelms and coworkers have shown anatomically representative human and animal models.
Background	In Wilhelms and Van Gelder [ 36 ] several classes of muscles are algorithmically modeled with attention to volume conservation; skin is a spring mesh anchored to underlying tissue or bone in appropriate areas.
Background	Scheepers et. al. [ 31 ] produced convincing representations of muscles as well as preliminary but promising skin deformation.
Background	In recent years character animation has moved beyond being a research topic and sophisticated deforming characters routinely appear in films and on television.
Background	Arguably the most common practice in character animation (as reflected in commercial software, animation books and courses, and some custom software) is founded on the twin techniques of shape interpolation and SSD [ 18 , 9 ].
Background	Shape interpolation (also called shape blending and multi-target morphing) is probably the most widely used approach to skin deformation for facial animation [ 3 , 18 , 9 ].
Background	Surface control vertices are simply an animated linear combination (not necessarily convex, i.e., individual weights can be greater than one or less than zero) of the corresponding vertices on a number of key shapes S k : k=0 w k S k
Background	A variation of this technique uses a single base shape S 0 and a number of delta shapes, S 0 + k=1 w k (S k − S 0 ).
Background	By writing the delta shape form as (1 − 1 w k )S 0 + 1 w k S k it is clear that the space of achievable shapes is identical in both variations.
Background	1 An attractive feature of shape interpolation is that the desired expressions can be directly specified by sculpting.
Problem	Given the popularity and effectiveness of this simple approach, it would be desirable to employ it on regions of the body other than the face.
Problem	The blending of rigid shapes is inconsistent with regions of the body that are bending under the action of an underlying skeleton, however.
Problem	Of course the key shapes could be deformed to the moving articulated figure using some other algorithm, but this defeats the purpose of proposing shape interpolation as the means of obtaining the deformation in question.
Problem	Shape interpolation also has some drawbacks for its intended role of facial animation.
Problem	For one, the interpolation is not always smooth.
Problem	Consider interpolating from a smile (shape A) to a neutral pose (B) and then to a frown (C).
Background	In practice animators object to the linear nature of the interpolation [ 34 ] and have sometimes compensated by sculpting new key shapes as often as every three to five frames [ 38 ].
Background	This simple algorithm has been repeatedly conceived and appears in commercial software packages under several rather uninformative names such as skinning, enveloping, etc.
Background	The algorithm is unpublished but is subsumed by more general published schemes such as [ 23 ].
Method	The position of a control vertex p on the deforming surface of an articulated object lies in the subspace defined by the rigid transformations of that point by some number of relevant skeletal coordinate frames ( Figure 1 ).
Method	This may be notated          p = w k L k (p) p (in more detail) p = w k L δ k L k 0 −1 L p 0 p          where L p 0 is the transform from the surface containing p to the world coordinate system, L 0 k is the transform from the stationary skeletal frame k to the world system (L 0 k −1 L 0 p together represent p in the coordinate system of skeletal frame k), and L δ k expresses the moving skeletal frame k in the world system.
Method	The deformation is controlled by the user through the weights w k .
Background	SSD is fairly versatile.
Background	For example, secondary animation effects such as muscle bulging and swelling of the chest can be achieved by variably weighting the surface to an abstract “bone” whose translation or scale is manually animated.
Background	The first major shortcoming of SSD results directly from the fact that the deformation is restricted to the indicated subspace.
Problem	In common situations such as shoulders and elbows the desired deformation does not lie in this subspace, hence no amount of adjusting the algorithm weights will produce good results.
Problem	This fact leads to considerable frustration by users of the algorithm – the character of the deformation changes as the weights are changed, sometimes sustaining the incorrect assumption that some combination of weights will produce good results.
Problem	In fact, the SSD algorithm can be easily identified in animations by its characteristic ‘collapsing joint’ defect (Figures 1, 2).
Problem	This problem is extreme in the case of simulating the twist of a human forearm (the pose taken in turning a door handle, Figure 3).
Problem	In this case the subspace basis consists of surface points rigidly transformed by the forearm frame (no axis rotation) and the wrist frame (axis rotation).
Problem	With a rotation of 180 degrees this line crosses the axis of the arm, i.e., the forearm collapses entirely as the SSD weights transition at some point from the forearm to wrist frames.
Problem	A second difficulty with SSD is that, unlike shape interpolation, it does not permit direct manipulation; artists instead directly or indirectly edit the meshes of weights w k (for each control vertex on a surface there is one weight per skeletal frame that affects the vertex).
Problem	SSD algorithms consequently have the reputation for being tedious and difficult to control.
Problem	Artists with a poor understanding of the underlying algorithm have difficulty distinguishing between results that can be further improved by adjusting weights and results that cannot be improved since the desired result lies outside the achievable subspace, resulting in the impression of unpredictability (“sometimes adjusting the weights helps, sometimes it doesn’t”).
Background	In some cases the SSD defects can be manually corrected using FFDs and other techniques, and one could consider a scheme whereby these fixes are procedurally invoked as the skeleton articulates.
Problem	But although FFDs work well (and have a direct manipulation algorithm [ 12 ]) the layered FFDs do not reduce the difficulty in adjusting the underlying SSD.
Result	The algorithm introduced in the subsequent sections removes the need for such layered fix-it approaches and permits direct specification of the desired deformations.
Background	Several published algorithms and commercial packages combine aspects of skeleton-driven deformation and shape interpolation in ways that anticipate our approach.
Background	In the pioneering work of Burtnyk and Wein, two dimensional characters were animated using a polygonal rubber sheet that afforded both skeletal and local deformation control [ 6 ].
Background	Van Overveld described a two-dimensional animation system in which animation is controlled by a skeleton and character deformation is driven from this skeleton through a scattered interpolation [ 20 ].
Background	This work is similar in spirit to ours but differs in that it used the image plane as a global interpolation domain rather than introducing a pose space.
Background	Litwinowicz and Williams’s system [ 16 ] is also a precedent and introduced sophisticated scattered interpolation (again in the image domain).
Background	Several papers consider animation (and indeed image synthesis in general) as a special case of neural net learning and interpolation/extrapolation [ 14 , 15 , 21 ].
Background	While this viewpoint is valid, in practice it is perhaps excessively general, for example, a skeleton is merely learned rather than being an intrinsic part of the model.
Background	While employed at Industrial Light and Magic the first author of the present paper developed a system that attempted to blend shape interpolation and SSD algorithms; a small portion of it remains in use in their well known Caricature animation system.
Background	Drawbacks of this work included both a complicated dependence on the details of SSD and its overall conception as a “correction” to SSD.
Background	Some commercial packages allow blending between two sculpted deformations as a function of a single-joint rotation, thereby combining shape interpolation and skeleton-driven deformation in a limited but useful setting.
Background	The depth of simulation is a prevalent issue in computer graphics, albeit one that is not always consciously considered.
Background	Early approaches to animation were purely kinematic; an emphasis on physically based modeling appeared in the literature later.
Background	Recent sophisticated approaches allow a hybrid of animator-controlled and physically governed animation as needed.
Background	In rendering we perhaps see the opposite trend – much of the literature a decade ago focused on ever deeper simulations of reality, whereas ‘shallower’ imagebased approaches are attracting attention at present.
Background	Similarly, in character deformation both deep and shallow approaches have their place.
Background	Deep models promise universally accurate simulation, and the importance of representing humans justifies the needed effort.
Background	The authors of these approaches acknowledge that producing anatomically plausible models is a daunting task, however.
Background	Pose space deformation is a shallow, purely kinematic approach to deformation (i.e. without reference to underlying forces, mass, volume), and it has consequent disadvantages.
Background	In particular, accuracy is reliant on the modeler/animator rather than being guaranteed by the simulation.
Result	On the other hand, our algorithm has clear advantages with respect to simplicity and generality, direct manipulation, real-time synthesis, and other criteria listed in the introduction.
Problem	We also wish to directly sculpt the desired deformation at various points in the parameter space, rather than working in a more abstract space such as the coefficients on various coordinate frames as required by the SSD algorithm.
Method	A scattered data interpolation method is required because deformations will be sculpted at arbitrary (rather than regularly spaced) poses.
Method	Since this interpolation is central to our application (the results of the interpolation will be directly visible in the animating deformation), we will consider the available scattered interpolation approaches before settling on a candidate.
Background	Shepard’s method [ 1 , 2 ] is a frequently employed scattered data interpolation scheme in computer graphics.
Background	(This is singular at the data points x k and should computed as (||x − x k + ) −p ).
Method	With p > 1 the interpolation surface is once differentiable.
Background	Unfortunately this simple scheme has some potentially undesirable properties.
Background	Far from the data the weights will be approximately the same, d(∞) ˆ = w ∞ d k /w ∞ 1 = d k /N , i.e. the interpolated surface converges to the average of the data values.
Background	A serious drawback for some applications is that the derivative of the surface is zero at the data points ( Figure 4 ).
Background	Radial basis functions [ 28 , 29 ] have become a popular choice for scattered interpolation.
Background	The interpolant is a linear combination of nonlinear functions of distance from the data points:
Background	If N values of d are available then the weights can be easily solved by a linear system; this can be derived either by least squares fit or by subspace projection.
Method	Taking the latter approach, we reconsider the available data points as a single point d in an N dimensional space, and consider φ k () = φ( x j − x k ) as the kth basis vector.
Method	Any nonlinear function φ() will interpolate the data, including odd choices such as φ(x) = x (which is nonlinear since x = x − x k is the argument), provided that the columns of Φ are independent.
Method	On the other hand a smooth φ() will result in a smooth interpolant (a weighted sum of continuous functions is continuous).
Background	In fact radial basis functions have a universal convergence property similar to Fourier series, though the convergence definition is different.
Method	The preceding description maps a k-dimensional input space (arbitrary k) to a one dimensional range, i.e., it is the k-dimensional version of a height field.
Method	Surfaces can of course be interpolated by allowing different combinations of the same basis functions in different dimensions, i.e., vector valued w k .
Method	The distance can be generalized to Mahalanobis distance (effectively rotating and stretching the basis function) [ 4 ].
Background	Various visual reconstruction schemes can be adapted for scattered data interpolation.
Method	In these schemes the interpolated or approximated surface is found as the minimum of a functional such as where the first term penalizes deviation of the surface d ˆ from the available data d and the second regularizing term votes for surface smoothness e.g. by integrating the squared second derivative of the surface.
Method	With small λ many of these schemes can serve as scattered data interpolants; reference [ 5 ] is a good introduction to these approaches.
Method	In some of the most powerful formulations of scattered interpolation the regularizer is considered to hold everywhere except at an unknown set of edges – this is the piecewise-smooth prior desirable in image reconstruction.
Method	Since the unknown edges may exist (or not exist) at any location in the domain, all combinations of possible edge locations must be considered and the interpolation cost is prima facie exponential in the surface resolution.
Method	The crux of our approach is the identification of an appropriate space for defining deformations.
Method	As discussed above, the interpolation domain is (a subset of) the pose space of an articulated character, or equivalently the space defined by some set of parameters such as facial controls.
Method	In concept the range of the interpolation function could simply be the desired movement of the surface control vertices.
Method	To make the job easier for the interpolation we instead interpolate the desired deviation of a surface vertex (expressed in the local frame) from its initially computed position (the rigidly transformed position in the case of an articulated model).
Method	Thus the deforming surface is defined by p + δ with p moved rigidly by the skeleton or other underlying system, and where configuration is the configuration of the set of joints or parameters controlled by the animator.
Method	Our scheme can be bootstrapped on top of an existing software system: the model is posed as desired and the desired surface at that pose is sculpted.
Method	Our algorithm computes the difference between the initial and resculpted model at that pose.
Method	This ‘deformation’ is associated with the joints or other parameters that have moved from their default positions to create the particular pose.
Method	One or more deformations will then be interpolated in this subspace using a scattered data approach.
Method	We now have enough criteria to select a particular interpolation scheme.
Method	Although it would be desirable to allow deformations to change both continuously and discontinuously with respect to the pose space, creature deformations that are discontinuous with respect to pose seem unlikely.
Method	As such the expensive energy functional and non-convex schemes are not necessary.
Method	In addition we want δ to approach zero away from the data, and the width of this falloff should be selectable.
Method	Together these comments support φ k (x) = exp( −( x−x 2σ 2 k ) 2 ) as one possible choice of radial basis ( Figure 5 ).
Method	Gaussian radial basis functions are reputed to be well behaved and our experience supports this judgement.
Background	Gaussian radial basis functions with adjustable placement and σ are discussed in the neural net literature and optimizing over these parameters is possible.
Method	This issue does not arise in our application, however, since the animator decides where in the parameter space to sculpt a pose (effectively deciding the basis function placement).
Method	The falloff σ is also specified explicitly by the animator, as described below.
Method	A pose is defined as the configuration of any pose controls (joints or abstract manipulators) that have changed from their default values.
Method	An abstract manipulator is a UI control or arbitrary piece of geometry whose movement will control the interpolation of some deformation, such as a muscle bulge or a desired facial attribute such as “happiness.
Method	” A self-relative configuration of the controls is actually considered, for example, an elbow involves two skeletal frames but only one joint angle.
Method	The pose space is the space spanned by the variations of these controls.
Method	If n = 2 pose controls are active and each has three degrees of freedom then a 3(n − 1) pose space is defined, and the particular position of the controls defines a point in that space.
Method	The artist first positions some set of pose controls and then sculpts a deformation for that pose.
Method	The artist also assigns a falloff (Gaussian σ), either as a symmetric radius across all controls or to each control individually (axis stretched falloff).
Method	Any control vertices that have moved from their rest position are found.
Method	This is done in the local coordinate frame, i.e., rigid body articulated motion results in zero δ.
Method	The δ values for the deformed vertices are computed (again in the local coordinate system) and they are saved in a database together with their corresponding location in a pose space.
Method	(At the boundary of several surface patches there may be shared vertices that need to be coincident to maintain surface continuity.
Method	Unlike some SSD implementations interpolation in pose space by definition cannot separate such vertices).
Method	When several such deformations have been saved (or when the artist is ready to try animating) it is necessary to solve the interpolation problem.
Method	For each control vertex that was moved during sculpting there are now one or more δ values at points in the pose space.
Method	Note that the dimension of the pose space can vary across vertices, for example, a particular vertex might be modified in three sculpted deformations but a neighboring vertex might have been modified in only two deformations.
Method	The interpolation is done independently for each control vertex (but see additional details below); in our experience using patch surfaces this has not been problematic.
Method	Singular Φ T Φ is interpreted as a user error; in practice this has turned out to be the result of saving new deformations without moving any pose controls rather than a result of actual numerical problems.
Method	The model is now moved to an arbitrary pose.
Method	The location in pose space is determined from the concatenated relative degrees of freedom of the pose controls (simply interpreted as independent dimensions).
Method	At this point the model interpolates through the previously defined deformation(s).
Method	The most recently defined deformation may extend too far (or not far enough) in pose space, however.
Background	There is a rich literature of schemes for optimizing radial basis parameters including σ [ 4 ].
Background	On the other hand, animators consider detailed control of the animation to be part of their craft and are quite happy to have interpolation parameters exposed to them.
Method	We have found that this potentially abstract parameter is comprehensible so long as it is possible to explore the effect of different values.
Method	At a minimum axis-aligned scaling of the falloff should be available; we have not experimented with Mahalanobis rotation of the basis.
Method	Based on the evaluation the artist may decide to sculpt additional poses as needed to achieve the desired motion.
Method	A detail that was omitted previously will now be mentioned: when a deformed vertex is found the associated pose space is determined as described above.
Method	If there are previous deformations of this vertex in the same pose space then the new deformation is simply another point to interpolate.
Method	The new deformation’s pose space may, however, be different from the previous spaces associated with the vertex!
Method	In such a case a new pose space is started, and the δ is computed as a delta from the previous layered PSD synthesis rather than from the base model.
Method	This ensures that the previous deformations are interpolated while allowing the artist complete freedom in determining the extent of the deformation and the associated pose controls.
Method	While there is an issue of commutativity, in our experience artists consider this iterative layered refinement to be a natural process.
Method	This is a well known issue; well behaved transformations are fundamental and are hopefully addressed early in the development of any character animation system.
Method	With n poses three matrices of size n must be inverted for each surface control vertex.
Result	Typically n will be between 1 and 10, say, so this cost is small.
Result	Also it is incurred at a convenient time – during setup (as a pose is saved) rather than during synthesis.
Method	For synthesis, the basis function φ(x) can be implemented by interpolated table lookup and the sqrt required in the Euclidean distance can be composed with φ(x) in the table.
Problem	An articulated model such as a human will typically have a number of different deformation subspaces, each with one or several deformations; the deformations in different subspaces may overlap spatially e.g. to simulate the influence of different muscles.
Method	The deformations needed for an elbow, for example, will be interpolated in the one-dimensional subspace defined by the elbow joint angle.
Method	Deformations in a shoulder area will need to consider two or more degrees of freedom.
Method	The neck/chest/leg blend area of many quadrupeds is a more complex case – the motion of the skin surface in these regions may depend on the relative configuration of several leg bones as well as the rib cage and possibly the neck region of the spine.
Result	PSD handles all these cases simply and uniformly.
Result	The application of PSD to facial animation is best described by comparison with shape interpolation (SI).
Result	• In both approaches a set of key shapes (or delta shapes) are sculpted.
Result	The same set of shapes can be used in both approaches.
Result	• Whereas shape interpolation is (despite the name) a superposition of a set of shapes, PSD interpolates among these shapes.
Result	• The animator’s task in PSD is to choose the interpolation path (and adjust interpolation parameters such as falloff if desired).
Result	In practice this has been considered the major difficulty in applying SI when high quality animation demands large numbers of basis shapes [ 38 ].
Result	• In shape interpolation the key shapes and the animation parameter space are one and the same – the keys define the axes of the animation parameter space.
Result	In PSD the key shapes are positioned as desired in a space of desired dimensionality.
Result	One can assign each shape in PSD to a separate dimension, exactly as with SI.
Result	On the other hand, PSD allows one to sculpt intermediate expressions (half-smile) and situate them half-way along the relevant (full-smile) axis.
Result	Similarly a sculpted pose that represents the simultaneous activation of several parameters (e.g. happy but surprised, or smiling with a wink) can simply be saved at the appropriate location in the pose space.
Result	Psychological research has shown that human facial expressions are largely described by two “emotional” axes [ 30 ] ( Figure 6 ); this two-dimensional space would be a convenient high-level pose space for controlling facial animation.
Result	• The PSD interpolation is smooth if so desired.
Result	To illustrate these comments consider Figure 7 , which abstractly represents both SI and PSD with an identical set of expressions (neutral, half-smile, full-smile, frown).
Result	In the SI side of the diagram expressions are arranged as independent (but not orthogonal) dimensions as required by SI.
Result	In the PSD diagram the expressions are situated in an expression space having a happy-unhappy axis; a second axis (arousal) and an expression (delighted) on that axis are added to show a multidimensional space.
Result	As illustrated, a PSD path from neutral to half-smile to full-smile is monotonic, as might be expected; the motion of a surface point over this interpolation is also smooth.
Method	Additional “dimensions” of deformation can be added at any time by adding a new parameter and associating additional poses with the movement of this parameter.
Method	For example, a limb can be modeled in a particular pose both in an unloaded state and with muscles sculpted to express carrying a heavy load.
Method	The ‘heavy’ pose can be associated with the ‘on’ state of an abstract parameter (e.g. an isolated bone moved into the vertical position); light and heavy loads can then be controlled by flipping this switch.
Method	Similarly one can imagine setting up a dial that causes the character to morph; this would of course require a significant set of additional deformation poses.
Result	Pose space deformation is not the last word in surface deformation for character animation; high quality anatomically based models are certainly preferable.
Result	Nevertheless both anatomically based and purely kinematic models have their place.
Background	In the current computer animation culture animators generally practice their craft by direct and exhaustive specification of the desired motion combined with quick evaluation using real-time playback.
Background	Deeper simulation approaches intrinsically take away some of this control, and animators often argue (rightly or not) that automated processes are inferior or will not produce a human feel.
Problem	The performance of current anatomically based models prohibits animation preview and other real-time applications such as telepresence and gaming (one published result is several orders of magnitude slower than real time), and the effort needed to produce an anatomically accurate model is not always justified, nor even appropriate if the model is of a fanciful creature whose surface appearance may be inconsistent with any plausible internal anatomy in any case.
Result	PSD unifies and improves upon two techniques that have been common graphics practice for more than a decade.
Result	This relatively simple algorithm uniformly handles a variety of deformation situations ranging from a simple elbow to secondary animation.
Result	The setup cost of the algorithm is insignificant, and the synthesis cost is only slightly more than that of shape interpolation, so real-time synthesis is possible at effective resolutions on current hardware.
Result	We expect that this algorithm will be a useful complement to current techniques.

Problem	We introduce an Eulerian liquid simulation framework based on the Voronoi diagram of a potentially unorganized collection of pressure samples.
Method	Constructing the simulation mesh in this way allows us to place samples anywhere in the computational domain; we exploit this by choosing samples that accurately capture the geometry and topology of the liquid surface.
Result	When combined with highresolution explicit surface tracking this allows us to simulate nearly arbitrarily thin features, while eliminating noise and other artifacts that arise when there is a resolution mismatch between the simulation and the surface—and allowing a precise inclusion of surface tension based directly on and at the same resolution as the surface mesh.
Problem	One of the most visually compelling aspects of liquids is the variety of complex thin sheets and droplets that arise during splashing.
Problem	However, these remain among the most difficult features to simulate plausibly and accurately with existing techniques.
Problem	Such detailed behaviour is extremely computationally expensive to resolve because of the tremendous grid resolution required for both the fluid solver and the surface tracking mechanism.
Background	Recent advances in explicit surface tracking with triangle meshes [Wojtan et al. 2009; Brochu and Bridson 2009; Müller 2009] have made feasible the geometric representation and manipulation of small features, without the loss of detail exhibited by implicit surface methods.
Problem	However, when the surface is coupled to a standard Eulerian simulator, the liquid volume must first be resampled onto the simulation mesh or grid to provide geometric information for boundary conditions.
Problem	As this resampling process typically destroys small details, they are invisible to the fluid solver and cannot be advanced appropriately.
Problem	This can lead to a variety of visible artifacts including lingering surface noise, liquid behaving as if it were connected when it is not (and vice versa), and thin features simply halting in mid-air because the simulator fails to see them [Bargteil et al. 2006; Kim et al. 2009].
Problem	When combined with surface tension forces, noisy sub-mesh details can also severely hamper stability if they are not artificially smoothed out.
Problem	We will address these problems by constructing a simulator that “sees” every detail in the explicit liquid surface.
Method	We carefully generate pressure sample points near the liquid surface, build a Voronoi simulation mesh from these points and a background lattice, and apply a ghost fluid/finite volume pressure discretization which captures the precise position of the liquid interface.
Method	We couple this with a semi-Lagrangian advection scheme and a new approach to surface tension, arriving at a complete liquid simulator.
Result	In summary, our key contribution is coupling an explicit surface tracker to a Voronoi-based liquid simulator with: • a pressure sample placement strategy that captures the complete liquid surface geometry, • an accurate surface tension model combining mesh-based curvature estimates and ghost fluid boundary conditions, • embedded free surface and solid boundary conditions adapted to Voronoi cells, avoiding the need for more onerous conforming tetrahedral mesh generation, • and a new velocity interpolant over unstructured meshes.
Result	The practical benefits of such a system include: • improved animation of detailed liquid features, including very thin sheets, tendrils and droplets, • elimination of noise in explicit surface tracking without nonphysical smoothing, • more detailed and less damped surface tension effects, • and faster semi-Lagrangian advection on unstructured meshes without increased dissipation.
Background	Unstructured and semi-structured meshes have a long history in computational fluid dynamics, and have gained traction in computer animation as well.
Background	An important reason for their popularity is that careful control of mesh geometry can simplify the discretization or improve accuracy.
Background	For example, conforming the simulation mesh to solid walls makes the no-flow boundary condition trivial, and adaptivity can be easily introduced by grading mesh elements as desired.
Background	Past work in graphics has extensively explored finite volume methods for tetrahedral meshes [Feldman et al. 2005a; Feldman et al. 2005b; Klingner et al. 2006; Chentanez et al. 2006; Elcott et al. 2007; Wendt et al. 2007; Chentanez et al. 2007], and now many of the features of standard grid-based solvers are supported on tetrahedra, including free surfaces and implicit coupling to dynamic solids.
Background	Batty et al. [2010] augmented this approach with embedded boundaries [Enright et al. 2003; Batty et al. 2007], improving free surface accuracy and reducing remeshing complexity.
Method	Our method extends these advantages to Voronoi meshes.
Background	In a related approach, Sin et al. [2009] developed a particle method which solves a finite volume pressure projection on the Voronoi diagram of the liquid particles.
Background	An advantage of this approach is that the pressure degrees of freedom are directly tied to the number of particles, so there can never be a resolution mismatch between surface geometry and simulator.
Method	This idea motivates our work.
Background	Franklin & Lee [2010] subdivide polyhedra into tetrahedra for interpolation similar to our method, but our method is simpler due to use of the Voronoi diagram.
Background	Implicit surfaces have long been used to capture liquid geometry in animation; this family of schemes includes level set (LS) methods [Enright et al. 2002a], volume-of-fluid (VOF) [Mihalef et al. 2006; Mullen et al. 2007], and semi-Lagrangian contouring (SLC) [Bargteil et al. 2006].
Background	Implicit approaches naturally yield smooth surfaces and seamlessly handle topological change.
Background	However, the resolution of the underlying grid imposes a severe limit on the smallest representable feature, beyond which geometry either vanishes (LS, SLC) or artificially coalesces into grid-scale “flotsam and jetsam” (VOF).
Background	Ensuring temporal coherence and avoiding visual artifacts due to the use of regular grids can also be problematic.
Background	The shortcomings of implicit schemes have spurred interest in explicit methods, i.e. “front tracking” [Glimm et al. 1998].
Background	Here the surface is represented explicitly as a triangle mesh, whose vertices are moved with the fluid velocity field.
Background	The greatest challenge is handling topological change, due to mesh tangling that may occur during merging and splitting.
Background	One solution is to determine problematic regions, switch to an implicit surface to repair the tangles there, then stitch back in a new consistent mesh patch [Du et al. 2006; Wojtan et al. 2009].
Background	Müller [2009] takes a similar grid-based approach to untangling, rebuilding a consistent mesh using marching-cubeslike stencils.
Background	Unfortunately these methods still are subject, in complex regions, to a resolution limited by the voxel grid.
Background	Another approach is to work strictly on the triangle mesh itself, using “mesh surgery” for repairs.
Background	While this is difficult in general, Brochu & Bridson [2009] recently showed that the problem can be simplified using ideas from cloth animation, enforcing the invariant that the surface remain intersection-free.
Background	Topological operations are only allowed when safe, while robust collision processing is used as a last resort to avoid tangles, i.e. the surface is minimally perturbed to avoid problems.
Method	We use this method in the presented examples, though note that other front tracking methods could easily be used instead—for example, recent work by Campen & Kobbelt [2010] suggests that the need for collision processing could be obviated with exact Boolean operations.
Method	A prime focus of our work is matching the surface mesh resolution to that of the liquid solver.
Background	Most level set-based solvers use one level set sample per pressure grid cell, conservatively avoiding resolution inconsistencies (e.g. [Foster and Fedkiw 2001; Enright et al. 2002b]).
Background	Goktekin et al. [2004] experimented with a doubleresolution level set, trading better volume conservation for other artifacts.
Background	Bargteil et al. [2006] similarly coupled an octree contouring method to a uniform grid fluid solver and explicitly discussed potential artifacts due to resolution mismatch, such as erroneously preserving surface noise and the solver interpreting disconnected fluid regions as connected.
Background	Kim et al. [2009] coupled a high resolution particle level set to a low resolution ghost fluid-based liquid solver, but ensured that pressure projection captured all liquid geometry by resampling an inflated level set at the pressure grid resolution—however, this can exacerbate other artifacts, since liquid components behave as if half a cell-width larger than they appear.
Background	Kim et al. also introduced extra surface smoothing to prevent retention of small-scale noise.
Background	Mismatched resolutions have been found useful for deformable solids, particularly as surface details are expected to generally persist, unlike in liquids.
Background	For example, Wojtan & Turk [2008] used a surface mesh coupled to a lower resolution finite element solver; forcing the simulation mesh to have the same topology, if not resolution, as the embedded surface mesh may improve realism [Teran et al. 2005; Nesme et al. 2009].
Background	Approaches to surface tension generally fall into two categories: those which apply surface tension as a body force in a region around the interface via smeared delta functions [Brackbill et al. 1992; Hong and Kim 2003; Zheng et al. 2006; Wojtan et al. 2009], and those which apply surface tension discontinuously at the interface, typically as a boundary condition in the pressure projection step.
Background	The latter is exemplified by the ghost fluid method and related approaches [Enright et al. 2003; Hong and Kim 2005; Hong et al. 2007], and has been shown to provide more realistic results.
Background	Surface tension models can also be compared in terms of how the force itself is approximated.
Background	In level set schemes, finite differences are often used to estimate mean curvature, though this can be quite inaccurate without careful modification (e.g. [Shin 2007]) and cannot capture small details.
Background	If a surface mesh is available, a more accurate approach is either to use mesh-based curvature operators (e.g. [Meyer et al. 2002b]), or as proposed recently, to model a physical tension directly in the surface mesh geometry [Perot and Nallapati 2003; Brochu 2006; Wojtan and Turk 2008].
Method	We take the best of each, computing an accurate force from the surface mesh and incorporating it precisely at the surface with the ghost fluid method.
Method	We also remedy a shortcoming of existing mesh-based approaches: that surface details below the simulation resolution add energy but cannot be correctly evolved by the solver; without correct feedback from the physics this noise tends to worsen and destroy stability.
Background	Wojtan & Turk [2008] handle this with Laplacian smoothing to eliminate small features: note, however, this non-physical operation is dissipative rather than conservative.
Method	By instead combining our surface tension model with a geometry-aware sampling, we ensure all relevant details are properly resolved.
Result	This yields accurate and comparatively stable surface tension effects without artificial smoothing.
Method	We simulate inviscid liquids with semi-Lagrangian advection and an embedded-boundary finite volume pressure projection.
Method	We generally follow the tetrahedral scheme of Batty et al. [2010] with modifications to use specially designed Voronoi meshes instead.
Method	Like Sin et al. [2009], we place pressure samples on the vertices of a Delaunay tetrahedral mesh, corresponding to the sites of the dual Voronoi diagram (figures 3(a) and 3(b)).
Method	Normal components of velocity lie on the faces of the Voronoi cells, so that the velocity sample is parallel to the line segment connecting the pressure samples in the Delaunay mesh.
Method	This configuration requires a slightly different velocity reconstruction compared to previous methods, but semi-Lagrangian advection is otherwise straightforward.
Method	For front tracking, we used Brochu & Bridson’s El Topo code [2009], in particular using its triangle mesh surface to determine the location of pressure samples for our Voronoi simulation mesh.
Background	Purely explicit front tracking algorithms generally use mesh refinement and coarsening to maintain a high quality discretization as the surface deforms.
Background	El Topo uses a sequence of edge subdivision, collapse and flipping operations, combined with null-space Laplacian smoothing.
Method	While these operations change mesh connectivity, they are designed to be geometry-preserving.
Method	For example, the smoothing moves vertices only in the null space of the local quadric metric tensor [Garland and Heckbert 1997], as suggested by Jiao [2007].
Method	If the vertex lies on a locally smooth patch it is moved in the plane tangent to the surface, but if on a ridge or corner it is moved only along this line.
Method	Therefore, sharp features are preserved, allowing the present paper’s algorithm to handle them physically.
Method	The solver runs through the following stages each time step: 1.
Method	Advect the explicit surface with 2.
Method	Generate a new simulation mesh as the Voronoi diagram of a lattice with extra samples near the liquid surface (section 5).
Method	Advect velocities onto the new mesh with semi-Lagrangian advection (section 6).
Method	Add external forces—typically just gravity.
Method	Solve for the embedded-boundary pressure projection on the Voronoi mesh, including surface tension forces (section 4).
Method	We use finite volumes on a Voronoi mesh for the pressure projection step, similar to Sin et al. [2009].
Method	However, rather than applying boundary conditions as they describe, we adapt the embedded boundary methods of Batty et al. [2010] to Voronoi meshes.
Method	Conveniently, the duality/orthogonality relationship between Voronoi and Delaunay meshes lets the accuracy benefits of the method carry over.
Method	We solve the resulting symmetric positive definite linear system using incomplete Cholesky-preconditioned conjugate gradients.
Method	To enforce embedded solid boundary conditions, we need to estimate the partial unobstructed area of each element face ( figure 3(d) ).
Background	Batty et al. [2010] used marching triangles cases for computing tetrahedra face fractions from signed distance values on the vertices.
Background	However, in the Voronoi setting, the faces are arbitrary convex planar polygons rather than triangles.
Method	To handle this, we temporarily place an extra vertex at the face centroid, and use it to triangulate the face.
Method	We then use signed distance estimates at the vertices to compute each sub-triangle’s partial area, and sum them to determine the partial area for the complete face.
Method	The embedded (ghost fluid) free surface condition uses signed distance estimates at pressure samples to estimate the surface position; these are now located at Voronoi sites rather than tetrahedra circumcenters, but the method is otherwise unchanged ( figure 3(c) ).
Method	A slight improvement can be achieved by casting rays to find the exact position of the surface mesh between pressure samples.
Method	In some cases this is much more accurate than the estimate derived from signed distances, but in practice we found it made minimal visual difference.
Method	To actually compute the liquid signed distance field on the tetrahedral mesh, we compute exact geometric distance for a narrow band of tetrahedra near the surface, then use a graph- based propagation of closest triangle indices to roughly fill in the rest of the mesh.
Method	This family of redistancing schemes is described by Bridson [2008], and is easily adapted to tetrahedra.
Method	To incorporate surface tension, we follow Enright et al. [2003] in setting the free surface pressure p fs = p air + γκ fs , where p air is the constant air pressure, γ is the surface tension coefficient and κ fs is the mean curvature of the surface.
Method	Rather than using level set finite differences, we compute curvature directly from the surface mesh to accurately capture high-frequency features.
Method	We chose the operator of Meyer et al. [2002b] because it provides high quality estimates using just the one-ring of triangles surrounding each vertex, but others could work too.
Method	Curvature is evaluated at the intersection point between the the triangle mesh surface and the line joining an interior pressure sample to an exterior one.
Method	Often this intersection point will coincide with a surface mesh vertex due to our choice of sampling scheme; where it does not, we use simple linear interpolation between the vertices of the surface triangle mesh.
Method	This method appears highly accurate, and leads to much less damping than that of Wojtan et al. [2009].
Background	An advantage of a Voronoi-based discretization is the freedom to explicitly choose pressure sample locations, which is critical for accurate ghost fluid free surface conditions as the signed distance at these samples communicate the surface geometry to the solver.
Method	We can visualize the solver’s “knowledge” by contouring this level set: figures 5 and 6 illustrate how uniform sampling may fail.
Method	Careful pressure sample placement with respect to the surface helps in three important ways.
Method	First, we can inform the solver of all local geometric extrema, allowing the physics to act upon them correctly.
Method	This eliminates the accumulation of erroneous surface noise without requiring non-physical smoothing; this is especially vital for surface tension where spurious noise affects the curvature estimates and induces disastrously large yet futile compensating velocities that destabilize the simulation.
Method	Second, we can ensure that the solver sees the correct surface topology so that the physics responds to merging or splitting only when the surface mesh itself merges or splits.
Method	Lastly, grid-scale features often disappear and reappear in regular grid sampling, from the perspective of the solver, as the surface translates through the grid.
Method	By specifically placing points inside such small features, we ensure they cannot be missed.
Background	However, this scales poorly since many of the extra samples yield little benefit, while incurring memory and computational overhead.
Background	Furthermore, there remains no guarantee that features below the smallest grid cell size will be captured.
Method	By choosing sample points to precisely capture the geometry rather than naıvely increasing sample density, we can guarantee sampling of features which would require potentially orders of magnitude more samples with pure adaptive lattices.
Method	This is considerably more difficult than non-conforming Delaunay tetrahedralization, and generally requires more Steiner points, worse-shaped tetrahedra, and/or the loss of the Delaunay property.
Method	Since our method uses embedded boundary conditions, we do not require conforming elements.
Background	(Note that this advantage is shared by the method of Batty et al. [2010].
Method	) Moreover, the position of pressure samples plays a more important role in free surface conditions than the position of element faces.
Method	As accuracy requires that tetrahedral schemes store pressures at circumcenters [Klingner et al. 2006; Batty et al. 2010], and since circumcenters often lie outside their associated tetrahedra, even filling a thin feature with conforming tetrahedra provides no guarantee that its interior will be sampled at all.
Method	We begin by choosing a characteristic length scale for the simulation, ∆x, and configure El Topo to try to maintain triangle edge 1 3 lengths in the range [ 2 ∆x, 2 ∆x].
Method	To resolve all surface details with our volumetric mesh, we need to place pressure samples so that they capture the surface’s local geometric extrema, i.e. around surface mesh vertices.
Method	In particular, we try to ensure that one edge of the Delaunay triangulation passes through each surface vertex, with one sample inside and one outside.
Method	Therefore we take the inward and outward normal at each surface vertex (averaged from the incident surface triangles), and attempt to place a pressure sample 1 a short distance along each.
Method	We placed outward samples at 2 ∆x 1 and inner samples at 4 ∆x, though other ratios would work as well.
Method	As a result, surface mesh normal directions will often align exactly with a velocity sample in the simulation mesh; this lends additional accuracy to the vertex’s normal motion, and to the incorporation of the normal force due to surface tension calculated at the vertex.
Method	This placement may miss very thin sheets or other fine structures: to robustly sample such features, we check line segments of length ∆x from each surface vertex in both offset directions for intersection with the rest of the surface mesh.
Method	If we find any triangle closer than ∆x, we store the distance d to the closest intersection, and use d in place of ∆x in the offset distance calculations above (see figure 7 ).
Method	We further reject new pressure samples which are too close to an existing sample by some epsilon, which would cause a very short edge in the final mesh.
Method	If the distance between the surface vertex and the first intersection 1 is below some threshold (e.g. 20 ∆x) at which we consider the two surfaces to have effectively collided, and the proposed sample is an air sample, we also discard it.
Method	This is necessary because the divergence constraint is not enforced on air cells, so they can act as liquid sinks [Losasso et al. 2006] and destroy liquid volume until the geometry finally merges.
Method	Unfortunately, merging in this scenario can often take several time steps to resolve because the interpolated velocity in the air gap still averages to zero, thereby preventing surface geometry from actually intersecting and flagging a collision.
Method	By not placing a sample point in these very small gaps, our simulator treats the two liquid bodies as merged and prevents volume loss; the geometric merge is usually then processed within a few timesteps.
Method	(With regular sampling, merging will depend on where grid points happen to fall with respect to the surface; hence the physics can respond as if merged when the surfaces are still as much as ∆x apart, as in figure 9 .
Method	This generates non-physical air bubbles which linger for many timesteps before they self-collide and are eliminated.
Method	) After placing the surface-adapted pressure samples, we complete the sampling of the domain by adding regularly-spaced points from a BCC lattice with cell size 2∆x, again rejecting samples which fall too near existing samples—of course, a graded octree or any other strategy could also be used to fill the domain.
Method	All samples are then run through a Delaunay mesh generator such as TetGen [Si 2006].
Future Work	Further experimentation with relative mesh spacing parameters could yield improved results.
Background	Velocity interpolation methods for unstructured meshes typically proceed in two steps [Klingner et al. 2006; Elcott et al. 2007; Batty et al. 2010].
Background	First, a full velocity vector is reconstructed at selected mesh locations using a least-squares fit to the nearby velocity components.
Background	Then barycentric or generalized barycentric interpolation between those locations interpolates velocity over the full domain.
Background	Given such an interpolant, advection of velocities and geometry is straightforward.
Method	We follow this general framework, with two modifications.
Background	In previous work, face normal components on tetrahedra were used to reconstruct velocities at circumcenters (Voronoi vertices).
Method	In our configuration, velocity components instead lie along the tetrahedra edges (Voronoi faces) so we perform the least squares fit on this data instead.
Method	We could then apply the usual generalized barycentric interpolant over Voronoi cells, but this is expensive [Chentanez et al. 2007] and requires special case handling to avoid degeneracies [Meyer et al. 2002a].
Method	A simple and fast alternative discussed by Klingner et al. and Chentanez et al. is to first interpolate velocities to Voronoi sites (tetrahedra vertices) and apply standard (and fast) barycentric interpolation over each tetrahedron.
Method	However, the interpolation onto tetrahedra vertices discards any local extrema at the Voronoi vertices, thereby severely over-smoothing the velocity field in practice, damping out interesting flow behavior.
Method	Rather than discard extrema at Voronoi vertices, we use a slightly refined tetrahedral mesh that includes them.
Method	We conceptually tetrahedralize the Voronoi cells themselves by placing additional vertices at Voronoi face centroids and Voronoi sites (see figure 10 ).
Method	Velocities for each of these new points need to be computed; while previous work used the generalized barycentric interpolant for this transfer step, we found that simply averaging the velocities of the surrounding ring or cell of Voronoi vertices is quicker and equally effective.
Method	For maximum fidelity at the face centroids, we also replace the normal component of the averaged full velocity with the exact normal component already stored at the face.
Method	Simple and efficient barycentric interpolations can then be applied on the resulting smaller tetrahedra.
Method	Because the sharper, more accurate velocities at the Voronoi vertices are retained and merely augmented with additional data, this is far less dissipative, yielding results that closely match generalized barycentric interpolation (see figure 11 ).
Method	Lastly, note that reconstructions should only use face velocities which were assigned valid data by the pressure projection, and thus we can only reconstruct reasonable velocities inside the fluid.
Method	We therefore extrapolate velocities outwards from the fluid using a breadth-first graph propagation: each unknown point in a layer is set by averaging all adjacent known points from previous layers, repeating until we have a sufficiently large band of velocities surrounding the surface.
Method	This simple method, suggested in the context of cloth-fluid coupling by [Guendelman et al. 2005], sufficed for all our animations.
Method	In summary, the steps of our interpolation scheme are: 1.
Method	Reconstruct full velocity vectors at Voronoi vertices using least squares.
Method	Assign full velocity vectors to Voronoi sites and faces using simple averaging from neighboring vertices.
Method	Subdivide the Voronoi cells into sub-tetrahedra using the sites and face centroids (see figure 10 ).
Method	Apply a simple graph-based extrapolation of velocities to fill in velocities near the liquid.
Method	To interpolate at a point, locate the sub-tetrahedron containing the point and apply basic barycentric interpolation from its four associated data points (i.e. one site, one face centroid, and two Voronoi vertices).
Method	One potential issue, not unique to our method, is that despite enforcing a lower bound on the distance between pressure samples, our unstructured sampling can cause sliver tetrahedra in the unmodified Delaunay tetrahedralization.
Method	While we found this posed little problem for the pressure projection, it can cause the least squares velocity reconstructions to be ill-conditioned due to nearly co-planar face normals.
Method	This can be readily resolved by requesting that the mesh generator add Steiner points to enforce fairly lax quality bounds; because our embedded pressure projection does not require the mesh generator to match boundaries, this is relatively inexpensive and effective.
Method	If mesh quality cannot be improved sufficiently, using additional nearby velocity samples in the reconstruction can ameliorate this at the cost of a smoother result.
Background	The issues that arise from regular, non-geometry-aware pressure sampling are common and consistent across Cartesian grids, octrees, Voronoi meshes, and tetrahedral meshes.
Method	We will therefore use Voronoi meshes throughout, and simply compare our geometryaware sampling against naıve regular sampling.
Result	In contrast, regular samples cannot fully capture the initial surface perturbation, so it cannot be rectified.
Result	Though the ghost fluid method on regular samples does detect some differences in surface height, this actually exacerbates the problem because noisy sub-mesh details will appear to the simulator as rapid discontinuous changes in surface position over time, inducing noisy responses in the fluid velocity.
Result	For example, a surface with two disjoint volumes of liquid may appear to the solver as one volume, resulting in a premature response.
Result	With regular sampling, the droplet begins to influence the static liquid before the surfaces are actually joined.
Result	Because our adaptively-placed samples match the topology of the surface tracker, they easily correct this spurious motion.
Result	Thin sheets rapidly develop as the fluid spreads out across the floor.
Result	With regular pressure samples, sheets of this kind often end up between samples, effectively disappearing from the solver.
Result	Our sampling ensures that almost arbitrarily thin sheets of liquid remain visible to the solver, and as such, interesting rippling and splashing motion still occurs.
Result	Our method also resolves thin sheets and small surface details generated by large splashes, as shown in figure 1 .
Method	To counteract gradual volume drift, we do add a corrective motion-in-the-normaldirection [Brochu 2006; Müller 2009], which further aids in pre- serving thin sheets.
Result	Although we are using only first-order semi-Lagrangian advection, the liquid motion remains lively and active throughout.
Result	We suspect that because our method retains sharp wave peaks and splashes rather than continually eroding them, their extra kinetic and gravitational potential energy is retained in the simulation, accounting for this reduced dissipation.
Result	All figures are averages per frame and all timings are in seconds.
Result	These simulations used no more than 320K tetrahedra each, whereas recent tetrahedra-based free surface methods used up to 4 times more tetrahedra to achieve a similar level of detail.
Result	Rather than quickly collapsing into a sphere, a cascade of detailed capillary waves propagate along the surface, causing it to oscillate rapidly.
Result	It initially inverts almost completely into an octahedron (the geometric dual of a cube), and continues to oscillate for many subsequent frames.
Method	To illustrate the benefits of our sampling approach in the context of surface tension, we launch an identical simulation using the same time steps on a regular mesh.
Result	Because this mesh cannot respond and correct high frequency sub-mesh details present in the curvature estimates, the simulation becomes unstable almost immediately.
Result	Applying an excessively strict timestep restriction only brings the simulation to a halt as the surface noise introduces increasingly sharp features.
Method	Inspired by an example from the work of Wojtan & Turk [2008], we run another zero gravity simulation on a rectangular block (see figure 11 ).
Result	Because our simulation does not use diffusive Laplacian mesh smoothing and applies accurate mesh-based surface tension forces discontinuously at the interface, we retain substantially greater detail in the resulting capillary wave motion.
Method	We revisit our surface tension block example to compare different interpolation schemes.
Result	As seen in figure 11 , our barycentric method is substantially less damped than the naıve barycentric interpolation approach, and matches the more complex generalized barycentric interpolant.
Future Work	Our implementation is not heavily optimized, and we defer various potential performance gains to future work.
Future Work	Obvious optimizations include: reducing the number of tetrahedra through smarter sampling, improving the broad phase algorithm for point-location queries, and streamlining the construction of mesh data structures.
Result	More fundamentally, our Voronoi simulator is in many ways dual to a tetrahedral scheme, and for a given mesh the number of velocity samples is identical; we believe that approximately comparable costs are therefore reasonable to expect.
Result	The main contribution of this paper is the coupling of simulation elements to an existing explicit surface tracking method, and not the explicit surface tracking itself.
Result	Therefore, not all artifacts due to surface tracking are addressed.
Result	For example, El Topo delays handling some very difficult collisions for a few timesteps until the topological operations can be safely processed, which occasionally yields visible lingering surface noise.
Result	(Reducing the time step size can help by introducing fewer and simpler collisions, and more aggressive simplification can also be enabled by tuning the volume change tolerance that El Topo uses to decide whether to accept a given simplification.
Result	) Likewise, despite the use of featurepreserving mesh improvement, some popping artifacts due to onthe-fly remeshing are still visible in our animations.
Method	We chose El Topo because its resolution is not constrained to a regular grid and it is therefore able to showcase very thin features; nevertheless our method could adapt to any of the front tracking methods mentioned in section 2.2.
Method	Surface tension was only used for examples in subsections 7.2 and 7.3.
Method	Our goal in many of the other examples was to highlight the ability to track thin sheets, whereas surface tension would break these sheets into droplets.
Result	Moreover, explicit surface tension schemes, such as the ghost-fluid-based method used in this paper, 3 suffer from a stringent O(∆x 2 ) time step restriction for stability, which is particularly costly when small scale capillary waves are not erroneously damped out.
Future Work	Pursuing a more efficient, fully implicit surface tension model is a promising future direction.
Result	We have shown that with careful placement of pressure samples, our Voronoi mesh-based fluid solver makes it possible for explicit surface tracking to achieve its full potential in capturing small scale liquid features.
Result	In addition, we adapted embedded boundary pressure projection techniques to Voronoi meshes, introduced a simple improvement to barycentric velocity interpolation for Voronoi/Delaunay meshes, and extended the ghost fluid surface tension model with mesh-based curvature in order to capture complex capillary waves with minimal damping.
Future Work	Several directions for future work remain.
Future Work	For example, it may be possible to enhance our sampling scheme in various ways, perhaps by exploiting curvature adaptivity, topological information, or measures of vorticity and velocity variation.
Future Work	Likewise, improvements to front tracking would be welcome, such as curvature-driven adaptivity, or greater robustness and efficiency.
Future Work	Lastly, many common extensions to basic inviscid liquid simulation rely on regular grids, and would need to be adapted to accomodate our approach.

Method	Given a corpus of motion capture data, we automatically construct a directed graph called a motion graph that encapsulates connections among the database.
Method	The motion graph consists both of pieces of original motion and automatically generated transitions.
Method	Motion can be generated simply by building walks on the graph.
Result	We present a general framework for extracting particular graph walks that meet a user’s specifications.
Result	We then show how this framework can be applied to the specific problem of generating different styles of locomotion along arbitrary paths.
Background	Realistic human motion is an important part of media like video games and movies.
Problem	More lifelike characters make for more immersive environments and more believable special effects.
Problem	At the same time, realistic animation of human motion is a challenging task, as people have proven to be adept at discerning the subtleties of human movement and identifying inaccuracies.
Background	One common solution to this problem is motion capture.
Background	However, while motion capture is a reliable way of acquiring realistic human motion, by itself it is a technique for reproducing motion.
Problem	Motion capture data has proven to be difficult to modify, and editing techniques are reliable only for small changes to a motion.
Problem	This limits the utility of motion capture  if the data on hand isn’t sufficiently similar to what is desired, then often there is little that can be done other than acquire more data, a time-consuming and expensive process.
Problem	This in particular is a problem for applications that require motion to be synthesized dynamically, such as interactive environments.
Problem	Our goal is to retain the realism of motion capture while also giving a user the ability to control and direct a character.
Problem	For example, we would like to be able to ask a character to walk around a room without worrying about having a piece of motion data that contains the correct number of steps and travels in the right directions.
Problem	We also need to be able to direct characters who can perform multiple actions, rather than those who are only capable of walking around.
Result	This paper presents a method for synthesizing streams of motions based on a corpus of captured movement while preserving the quality of the original data.
Method	Given a set of motion capture data, we compile a structure called a motion graph that encodes how the captured clips may be re-assembled in different ways.
Method	The motion graph is a directed graph wherein edges contain either pieces of original motion data or automatically generated transitions.
Method	The nodes then serve as choice points where these small bits of motion join seamlessly.
Method	Because our methods automatically detect and create transitions between motions, users needn’t capture motions specifically designed to connect to one another.
Method	If desired, the user can tune the high-level structure of the motion graph to produce desired degrees of connectivity among different parts.
Method	Motion graphs transform the motion synthesis problem into one of selecting sequences of nodes, or graph walks.
Method	By drawing upon algorithms from graph theory and AI planning, we can extract graph walks that satisfy certain properties, thereby giving us control over the synthesized motions.
Method	To demonstrate the potential of our approach, we introduce a simple example.
Method	We were donated 78.5 seconds of motion capture, or about 2400 frames of animation, of a performer randomly walking around with both sharp and smooth turns.
Method	Since the motion was donated, we did not carefully plan out each movement, as the literature suggests is critical to successful application of motion capture data [Washburn 2001].
Method	From this data we constructed a motion graph and used an algorithm described later in this paper to extract motions that travelled along paths sketched on the ground.
Method	Characteristic movements of the original data like sharp turns were automatically used when appropriate, as seen in Figure 1 .
Method	It is possible to place additional constraints on the desired motion.
Method	For example, we noticed that part of the motion had the character sneaking around.
Method	By labelling these frames as special, we were able to specify that at certain points along the path the character must only use sneaking movements, and at other parts of the motion it must use normal walking motions, as is also shown in Figure 1 .
Background	Much previous work with motion capture has revolved around editing individual clips of motion.
Background	Motion warping [Witkin and Popović 1995] can be used to smoothly add small changes to a motion.
Background	Retargeting [Gleicher 1998; Lee and Shin 1999] maps the motion of a performer to a character of different proportions while retaining important constraints like footplants.
Background	Various signal processing operations [Bruderlin and Williams 1995] can be applied to motion data.
Result	Our work is different from these efforts in that it involves creating continuous streams of motion, rather than modifying specific clips.
Background	One strategy for motion synthesis is to perform multi-target blends among a set of examples, yielding a continuous space of parameterized motion.
Background	Wiley and Hahn [1997] used linear interpolation to create parameterizations of walking at various inclinations and reaching to various locations.
Background	Rose et al. [1998] used radial basis functions to blend among clips representing the same motion performed in different styles.
Background	These works have a focus complementary to ours: while they are mainly concerned with generating parameterizations of individual clips, we are concerned with constructing controllable sequences of clips.
Background	Another popular approach to motion synthesis is to construct statistical models.
Background	Pullen and Bregler [2000] used kernel-based probability distributions to synthesize new motion based on the statistical properties of example motion.
Background	Coherency was added to the model by explicitly accounting for correlations between parameters.
Background	Bowden [2000], Galata et al. [2001], and Brand and Hertzmann [2000] all processed motion capture data by constructing abstract “states” which each represent entire sets of poses.
Background	Transition probabilities between states were used to drive motion synthesis.
Background	Since these statistical models synthesize motion based on abstractions of data rather than actual data, they risk losing important detail.
Result	In our work we have tighter guarantees on the quality of generated motion.
Background	Moreover, these systems did not focus on the satisfaction of high-level constraints.
Method	We generate motion by piecing together example motions from a database.
Background	Numerous other researchers have pursued similar strategies.
Background	Perlin [1995] and Perlin and Goldberg [1996] used a rulebased system and simple blends to attach procedurally generated motion into coherent streams.
Background	Faloutsos et al. [2001] used support vector machines to create motion sequences as compositions of actions generated from a set of physically based controllers.
Method	Since our system involves motion capture data, rather than procedural or physically based motion, we require different approaches to identifying and generating transitions.
Background	Also, these systems were mainly concerned with appropriately generating individual transitions, whereas we address the problem of generating entire motions (with many transitions) that meet user-specified criteria.
Background	Lamouret and van de Panne [1996] developed a system that used a database to extract motion meeting high-level constraints.
Background	However, their system was applied to a simple agent with five degrees of freedom, whereas we generate motion for a far more sophisticated character.
Background	Molina-Tanco and Hilton [2000] used a state-based statistical model similar to those mentioned in the previous paragraph to rearrange segments of original motion data.
Background	These segments were attached using linear interpolation.
Background	The user could create motion by selecting keyframe poses, which were connected with a highprobability sequence of states.
Method	Our work considers more general and sophisticated sets of constraints.
Background	Work similar to ours has been done in the gaming industry to meet the requirements of online motion generation.
Background	Many companies use move trees [Mizuguchi et al. 2001], which (like motion graphs) are graph structures representing connections in a database of motion.
Background	However, move trees are created manually — short motion clips are collected in carefully scripted capture sessions and blends are created by hand using interactive tools.
Background	Motion graphs are constructed automatically.
Background	Also, move trees are typically geared for rudimentary motion planning (“I want to turn left, so I should follow this transition”), as opposed to more complicated objectives.
Method	The generation of transitions is an important part of our approach.
Background	Early work in this area was done by Perlin [1995], who presented a simple method for smoothly interpolating between two clips to create a blend.
Background	Lee [2000] defined orientation filters that allowed these blending operations to be performed on rotational data in a more principled fashion.
Background	Rose et al. [1996] presented a more complex method for creating transitions that preserved kinematic constraints and basic dynamic properties.
Result	Our main application of motion graphs is to control a character’s locomotion.
Background	This problem is important enough to have received a great deal of prior attention.
Problem	Because a character’s path isn’t generally known in advance, synthesis is required.
Background	Procedural and physically based synthesis methods have been developed for a few activities such as walking [Multon et al. 1999; Sun and Metaxas 2001] and running [Hodgins et al. 1995; Bruderlin and Calvert 1996].
Background	While techniques such as these can generate flexible motion paths, the current range of movement styles is limited.
Background	Also, these methods do not produce the quality of motion attainable by hand animation or motion capture.
Background	While Gleicher [2001] presented a method for editing the path traversed in a clip of motion capture, it did not address the need for continuous streams of motion, nor could it choose which clip is correct to fit a path (e.g. that a turning motion is better when we have a curved path).
Method	Our basic approach — detecting transitions, constructing a graph, and using graph search techniques to find sequences satisfying user demands — has been applied previously to other problems.
Background	Schödl et al. [2000] developed a similar method for synthesizing seamless streams of video from example footage and driving these streams according to high-level user input.
Background	Since writing this paper, we have learned of similar work done concurrently by a number of research groups.
Background	Arikan and Forsythe [2002] constructed from a motion database a hierarchical graph similar to ours and used a randomized search algorithm to extract motion that meets user constraints.
Background	Lee et al. [2002] also constructed a graph and generated motion via three user interfaces: a list of choices, a sketch-based interface similar to what we use for path fitting (Section 5), and a live video feed.
Background	Pullen and Bregler [2002] keyframed a subset of a character’s degrees of freedom and matched small segments of this keyframed animation with the lower frequency bands of motion data.
Background	This resulted in sequences of short clips forming complete motions.
Background	Li et al [2002] generated a two-level statistical model of motion.
Background	At the lower level were linear dynamic systems representing characteristic movements called “textons”, and the higher level contained transition probabilities among textons.
Background	This model was used both to generate new motion based on user keyframes and to edit existing motion.
Method	A clip of motion is defined as a regular sampling of the character’s parameters, which consist of the position of the root joint and quaternions representing the orientations of each joint.
Method	A motion graph is a directed graph where all edges correspond to clips of motion.
Method	Nodes serve as choice points connecting these clips, i.e., each outgoing edge is potentially the successor to any incoming edge.
Method	A trivial motion graph can be created by placing all the initial clips from the database as arcs in the graph.
Method	This creates a disconnected graph with 2n nodes, one at the beginning and end of each clip.
Method	Similarly, an initial clip can be broken into two clips by inserting a node, since the later part of the motion is a valid successor to the earlier part (see Figure 2 ).
Method	A more interesting graph requires greater connectivity.
Method	For a node to have multiple outgoing edges, there must be multiple clips that can follow the clip(s) leading into the node.
Method	Since it is unlikely that two pieces of original data are sufficiently similar, we need to create clips expressly for this purpose.
Method	Transitions are clips designed such that they can seamlessly connect two segments of original data.
Method	By introducing nodes within the initial clips and inserting transition clips between otherwise disconnected nodes, we can create a wellconnected structure with a wide range of possible graph walks (see Figure 2 ).
Method	Unfortunately, creating transitions is a hard animation problem.
Method	Imagine, for example, creating a transition between a run and a backflip.
Method	In real life this would require several seconds for an athlete to perform, and the transition motion looks little like the motions it connects.
Method	Hence the problem of automatically creating such a transition is arguably as difficult as that of creating realistic motion in the first place.
Method	On the other hand, if two motions are “close” to each other then simple blending techniques can reliably generate a transition.
Method	In light of this, our strategy is to identify portions of the initial clips that are sufficiently similar that straightforward blending is almost certain to produce valid transitions.
Method	As in our system, motion capture data is typically represented as vectors of parameters specifying the root position and joint rotations of a skeleton on each frame.
Method	One might attempt to locate transition points by computing some vector norm to measure the difference between poses at each pair of frames.
Method	Simple vector norms fail to account for the meanings of the parameters.
Method	Specifically, in the joint angle representation some parameters have a much greater overall effect on the character than others (e.g., hip orientation vs. wrist orientation).
Method	Moreover, there is no meaningful way to assign fixed weights to these parameters, as the effect of a joint rotation on the shape of the body depends on the current configuration of the body.
Method	A motion is defined only up to a rigid 2D coordinate transformation.
Method	That is, the motion is fundamentally unchanged if we translate it along the floor plane or rotate it about the vertical axis.
Method	Hence comparing two motions requires identifying compatible coordinate systems.
Method	Smooth blends require more information than can be obtained at individual frames.
Method	A seamless transition must account not only for differences in body posture, but also in joint velocities, accelerations, and possibly higher-order derivatives.
Method	Our similarity metric incorporates each of these considerations.
Method	To motivate it, we note that the skeleton is only a means to an end.
Method	In a typical animation, a polygonal mesh is deformed according to the skeleton’s pose.
Method	This mesh is all that is seen, and hence it is a natural focus when considering how close two frames of animation are to each other.
Method	For this reason we measure the distance between two frames of animation in terms of a point cloud driven by the skeleton.
Method	Ideally this point cloud is a downsampling of the mesh defining the character.
Method	To calculate the distance D( i , ¡ j ) between two frames i and ¡ j , we consider the point clouds formed over two windows of frames of user-defined length k, one bordered at the beginning by   i and the other bordered at the end by ¡ j .
Method	That is, each point cloud is the composition of smaller point clouds representing the pose at each frame in the window.
Method	The use of windows of frames effectively incorporates derivative information into the metric, and is similar to the approach in [Schödl et al. 2000].
Method	The size of the   windows are the same as the length of the transitions, so D( i , ¡ j ) is affected by every pair of frames that form the transition.
Method	To address the problem of finding coordinate systems for these point clouds (item 2 in the above list), we calculate the minimal weighted sum of squared distances given that an arbitrary rigid 2D transformation may be applied to the second point cloud:
Method	The weights w i may be chosen both to assign more importance to certain joints (e.g., those with constraints) and to taper off towards the end of the window.
Method	This optimization has a closed-form solution:
Method	We compute the distance as defined above for every pair of frames in the database, forming a sampled 2D error function.
Method	To make our transition model more compact, we find all the local minima of this error function, thereby extracting the “sweet spots” at which transitions are locally the most opportune.
Background	This tactic was also used in [Schödl et al. 2000].
Method	These local minima are our candidate transition points.
Method	A local minimum in the distance function does not necessarily imply a high-quality transition; it only implies a transition better than its neighbors.
Method	We are specifically interested in local minima with small error values.
Method	The simplest approach is to only accept local minima below an empirically determined threshold.
Method	This can be done without user intervention.
Method	However, often users will want to set the threshold themselves to pick an acceptable tradeoff between having good transitions (low threshold) and having high connectivity (high threshold).
Method	Different kinds of motions have different fidelity requirements.
Method	For example, walking motions have very exacting requirements on the transitions — people have seen others walk nearly every day since birth and consequently have a keen sense of what a walk should look like.
Problem	On the other hand, most people are less familiar with ballet motions and would be less likely to detect inaccuracies in such motion.
Method	As a result, we allow a user to apply different thresholds to different pairs of motions; transitions among ballet motions may have a higher acceptance threshold than transitions among walking motions.
Method	If D( i , ¡ j ) meets the threshold requirements, we create a tran    sition by blending frames i to i+k−1 with frames ¡ j−k+1 to ¡ j , inclusive.
Method	The first step is to apply the appropriate aligning 2D transformation to motion .
Method	Then on frame p of the transition ¡ (0 ≤ p < k) we linearly interpolate the root positions and perform spherical linear interpolation on joint rotations:
Method	To maintain continuity we choose the blend weights α (p) according to the conditions that α (p) = 1 for p ≤ −1, α (p) = 0 for p ≥ k, and that α (p) has C 1 continuity everywhere.
Background	Other transition schemes, such as [Rose et al. 1996], may be used in place of this one.
Method	The use of linear blends means that constraints in the original motion may be violated.
Method	For example, one of the character’s feet may slide when it ought to be planted.
Method	This can be corrected by using constraint annotations in the original motions.
Method	We treat constraints as binary signals: on a given frame a particular constraint either exists or it does not.
Method	Blending these signals in analogy to equations 5   and 6 amounts to using the constraints from in the first half of the transition and the constraints from in the second half.
Method	In this ¡ manner each transition is automatically annotated with constraint information, and these constraints may later be enforced as a postprocessing step when motion is extracted form the graph.
Method	Descriptive labels attached to the motions are carried along into transitions.
Method	Specifically, if a transition frame is a blend between a frame with a set of labels L 1 and another frame with a set of labels L 2 , then it has the union of these labels L 1 ∪ L 2 .
Method	In its current state there are no guarantees that the graph can synthesize motion indefinitely, since there may be nodes (called dead ends) that are not part of any cycle (see Figure 4 ).
Method	Once such a node is entered there is a bound on how much additional motion can be generated.
Method	Other nodes (called sinks) may be part of one or more cycles but nonetheless only be able to reach a small fraction of the total number of nodes in the graph.
Method	While arbitrarily long motion may still be generated once a sink is entered, this motion is confined to a small part of the database.
Method	Finally, some nodes may have incoming edges such that no outgoing edges contain the same set of descriptive labels.
Method	This is dangerous since logical discontinuities may be forced into a motion.
Method	For example, a character currently in a “boxing” motion may have no choice but to transition to a “ballet” motion.
Method	To address these problems, we prune the graph such that, starting from any edge, it is possible to generate arbitrarily long streams of motion of the same type such that as much of the database as possible is used.
Method	This is done as follows.
Method	Every frame of original data is associated with a (possibly empty) set of labels.
Method	Say there are n unique sets.
Method	For each set, form the subgraph consisting of all edges whose frames have exactly this set of labels.
Method	Compute the strongly connected components (SCCs) of this subgraph, where an SCC is a maximal set of nodes such that there is a connecting graph walk for any ordered pair of nodes (u, v).
Method	The SCCs can be computed in O(V + E) time using an algorithm due to Tarjan.
Method	We eliminate from this subgraph (and hence the original motion graph) any edge that does not attach two nodes in the largest SCC.
Method	Once this process is completed for all n label sets, any nodes with no edges are discarded.
Method	A warning is given to the user if the largest SCC for a given set of labels contains below a threshold number of frames.
Method	Also, a warning is given if for any ordered pair of SCCs there is no way to transition from the first to the second.
Method	In either case, the user may wish to adjust the transition thresholds (Section 3.2) to give the graph greater connectivity.
Method	By this stage we have finished constructing the motion graph.
Method	After describing exactly how a graph walk can be converted into displayable motion, we will consider the general problem of extracting motion that satisfies user constraints.
Method	Our algorithm involves solving an optimization problem, and so we conclude this section with some general recommendations on how to pose the optimization.
Method	Since every edge on the motion graph is a piece of motion, a graph walk corresponds to a motion generated by placing these pieces one after another.
Method	The only issue is to place each piece in the correct location and orientation.
Method	In other words, each frame must be transformed by an appropriate 2D rigid transformation.
Method	At the start of a graph walk this transformation is the identity.
Method	Whenever we exit a transition edge, the current transformation is multiplied by the transformation that aligned the pieces of motion connected by the transition (Section 3.1).
Method	As noted in Section 3.3, the use of linear blends to create transitions can cause artifacts, the most common of which is feet that slide when they ought to be planted.
Method	However, every graph walk is automatically annotated with constraint information (such as that the foot must be planted).
Method	These constraints are either specified directly in the original motions or generated as in Section 3.3, depending on whether the frame is original data or a transition.
Method	These constraints may be satisfied using a variety of methods, such as [Gleicher 1998] or [Lee and Shin 1999].
Method	In our work we used the method described in [Kovar et al. 2002].
Method	We are now in a position to consider the problem of finding motion that satisfies user-specified requirements.
Method	It is worth first noting that only very special graph walks are likely to be useful.
Method	For example, while a random graph walk will generate a continuous stream of motion, such an algorithm has little use other than an elaborate screen saver.
Method	As a more detailed example, consider computing an all-pairs shortest graph walk table for the graph.
Method	That is, given a suitable metric — say, time elapsed or distance travelled — we can use standard graph algorithms like Floyd-Warshall to find for each pair of nodes u and v the connecting graph walk that minimizes the metric.
Method	With this in hand we could, for example, generate the motion that connects one clip to another as quickly as possible.
Method	This is less useful than it might appear at first.
Method	First, there are no guarantees that the shortest graph walk is short in an absolute sense.
Method	In our larger test graphs (between a few and several thousand nodes) the average shortest path between any two nodes was on the order of two seconds.
Method	This is not because the graphs were poorly connected.
Method	Since the transitions were about one-third of a second apiece, this means there were on average only five or six transitions separating any two of the thousands of nodes.
Method	Second, there is no control over what happens during the graph walk — we can’t specify what direction the character travels in or where she ends up.
Method	More generally, the sorts of motions that a user is likely to be interested in probably don’t involve minimizing metrics as simple as total elapsed time.
Method	However, for complicated metrics there is typically no simple way of finding the globally optimal graph walk.
Method	Hence we focus instead on local search methods that try to find a satisfactory graph walk within a reasonable amount of time.
Problem	We now present our framework for extracting graph walks that conform to a user’s specifications.
Method	We cast motion extraction as a search problem and use branch and bound to increase the efficiency of this search.
Method	The user supplies a scalar function g(w, e) that evaluates the additional error accrued by appending an edge e to the existing path w, which may be the empty path 0.
Method	We require g(w, e) to be nonnegative, which means that we can never decrease the total error by adding more edges to a graph walk.
Method	In addition to f and g, the user must also supply a halting condition indicating when no additional edges should be added to a graph walk.
Method	A graph walk satisfying the halting condition is called complete.
Method	The start of the graph walk may either be specified by the user or chosen at random.
Method	Our goal is find a complete graph walk w that minimizes f .
Method	To give the user control over what sorts of motions should be considered in the search, we allow restrictions on what edges may be appended to a given walk w.
Method	For example, the user may decide that within a particular window of time a graph walk may only contain “sneaking” edges.
Method	A naıve solution is to use depth-first search to evaluate f for all complete graph walks and then select the best one.
Method	However, the number of possible graph walks grows exponentially with the average size of a complete graph walk.
Method	To address this we use a branch and bound strategy to cull branches of the search that are incapable of yielding a minimum.
Method	Since g(w, e) by assumption never decreases, f (w) is a lower bound on f (w + v) for any v, where w + v is the graph walk composed of v appended to w.
Method	Thus we can keep track of the current best complete graph walk w opt and immediately halt any branch of the search for which the graph walk’s error exceeds f (w opt ).
Method	Also, the user may define a threshold error ε such that if f (w) < ε , then w is considered to be “good enough” and the search is halted.
Method	Branch and bound is most successful when we can attain a tight lower bound early in the search process.
Method	For this reason it is worthwhile to have a heuristic for ordering the edges we explore out of a particular node.
Method	One simple heuristic is to order the children greedily — that is, given a set of unexplored children c 1 , . . . , c n , we search the one that minimizes g(w, c i ).
Method	While branch and bound reduces the number of graph walks we have to test against f , it does not change the fact that the search process is inherently exponential — it merely lowers the effective branching factor.
Method	For this reason we generate a graph walk incrementally.
Method	At each step we use branch and bound to find an optimal graph walk of n frames.
Method	We retain the first m frames of this graph walk and use the final retained node as a starting point for another search.
Method	This process continues until a complete graph walk is generated.
Method	In our implementation we used values of n from 80 to 120 frames (2 3 2 to 4 seconds) and m from 25 to 30 frames (about one second).
Method	Sometimes it is useful to have a degree of randomness in the search process, such as when one is animating a crowd.
Method	There are a couple of easy ways to add randomness to the search process without sacrificing a good result.
Method	The first is to select a start for the search at random.
Method	The second is retain the r best graph walks at the end of each iteration of the search and randomly pick among the ones whose error is within some tolerance of the best solution.
Method	Since the motion extracted from the graph is determined by the function g, it is worth considering what sorts of functions are likely to produce desirable results.
Method	To understand the issues involved, we consider a simple example.
Method	Imagine we want to lay down two clips on the floor and create a motion that starts at the first clip and ends at the second.
Method	Both clips must end up in the specified position and orientation.
Method	What one will receive is a motion like in Figure 5 , where the initial clip is a walking motion and the final clip is a kick.
Result	The character turns around in place several times in an attempt to better line up with the target clip.
Method	While it’s conceivable that given a larger database we would have found a better motion, the problem here is with the function we passed into the search algorithm.
Method	First, it gives no guidance as to what should be done in the middle of the motion; all that matters is that the final clip be in the right position and orientation.
Method	This means the character is allowed to do whatever is possible in order to make the final fit, even if the motion is nothing that a real person would do.
Method	Second, the goal is probably more specific than necessary.
Method	If it doesn’t matter what kick the character does, then it should be allowed to choose a kick that doesn’t require such effort to aim.
Result	More generally, there are two lessons we can draw from this example.
Result	First, g should give some sort of guidance throughout the entire motion, as arbitrary motion is almost never desirable.
Result	Second, g should be no more restrictive than necessary, in order to give the search algorithm more goals to seek.
Result	Note the tradeoff here — guiding the search toward a particular result must be balanced against unduly preventing it from considering all available options.
Method	We have cast motion extraction as an optimization problem, and we have given some reasons why the formulation of this optimization can be difficult.
Method	To demonstrate that it is nonetheless possible to come up with optimization criteria that allow us to solve a real problem, we apply the preceding framework to path synthesis.
Method	This problem is simple to state: given a path P specified by the user, generate motion such that the character travels along P. In this section we present our algorithm for path synthesis, present results, and discuss applications of the technique.
Method	Given the framework in the previous section, our only tasks are to define an error function g(w, e) and appropriate halting criteria.
Method	A simple way to determine P is to project the root onto the floor at each frame, forming a piecewise linear curve 1 .
Method	Let P(s) be the point on P whose arc-length distance from the start of P is s.
Method	The i th frame of the graph walk, w i , is at some arc length s(w i ) from the start of P .
Method	We define the corresponding point on P as the point at the same arc length, P(s(w i )).
Method	For the j th frame of e, we calculate the squared distance between P (s(e j )) and P(s(e j )).
Method	g(w, e) is the sum of these errors:
Method	Note that s(e i ) depends on the total arc length of w, which is why this equation is a function of w as well as e.
Method	First, it is efficient to compute, which is important in making the search algorithm practical.
Method	Second, the character is given incentive to make definite progress along the path.
Method	If we were to have required the character to merely be near the path, then it would have no reason not to alternate between travelling forwards and backwards.
Method	Finally, this metric allows the character to travel at whatever speed is appropriate for what needs to be done.
Method	For example, a sharp turn will not cover distance at the same rate as walking straight forward.
Method	Since both actions are equally important for accurate path synthesis, it is important that one not be given undue preference over the other.
Method	One potential problem with this metric is that a character who stands still will never have an incentive to move forward, as it can accrue zero error by remaining in place.
Method	While we have not encountered this particular problem in practice, it can be countered by requiring at least a small amount of forward progress γ on each frame.
Method	More exactly, we can replace in Equation 9 the function s(e i ) with t(e i ) = max(t(e i−1 ) + s(e i ) − s(e i−1 ),t(e i−1 ) + γ ).
Method	Typically the user will want all generated motion to be of a single type, such as walking.
Method	This corresponds to confining the search to the subgraph containing the appropriate set of descriptive labels.
Method	More interestingly, one can require different types of motion on different parts of the path.
Method	For example, one might want the character to walk along the first half of the path and sneak down the rest.
Method	The necessary modifications to accomplish this are simple.
Method	We will consider the case of two different motion types; the generalization to higher numbers is trivial.
Method	We divide the original path into two smaller adjoining paths, P 1 and P 2 , based on where the transition from type T 1 to type T 2 is to occur.
Method	If the character is currently fitting P 2 , then the algorithm is identical to the single-type case.
Method	If the character is fitting P 1 , then we check to see if we are a threshold distance from the end of P 1 .
Method	If not, we continue to only consider edges of type T 1 .
Method	Otherwise we allow the search to try both edges of type T 1 and T 2 ; in the latter case we switch to fitting P 2 .
Method	Note that we only allow this switch to occur once on any given graph walk, which prevents the resulting motion from randomly switching between the two actions.
Result	While the examples shown in Figure 1 suggest that our technique is viable, it perhaps isn’t surprising that we were able to find accurate fits to the given paths.
Result	However, our algorithm is still useful when the input database is not as rich.
Method	We started with a single 12.8second clip of an actor sneaking along the indicated path.
Method	To stretch this data further, we created a mirror-image motion and then built a motion graph out of the two.
Result	From these we were able to construct the new motions shown at the bottom of the figure, both of which are themselves approximately 13 seconds in length.
Result	The first example uses walking motions and the second uses martial arts motions; the latter demonstrates that our approach works even on motions that are not obviously locomotion.
Result	For the walking motion, the total computation time was nearly the same as the length of the generated animation (58.1 seconds of calculation for 54.9 seconds animation).
Result	The martial arts motion is 87.7 seconds long and required just 15.0 seconds of computation.
Result	In general, in our test cases the duration of a generated motion was either greater than or approximately equal to the amount of time needed to produce it.
Result	Both motion graphs had approximately 3000 frames (100 seconds) of animation.
Method	In the first section of each path the character is required to walk, in the second it must sneak, and in the third it is to perform martial arts moves.
Result	Not only does the character follow the path well, but transitions between action types occur quite close to their specified locations.
Method	This example used a database of approximately 6000 frames (200 seconds).
Method	All examples were computed on a 1.3GHz Athlon.
Result	For our largest graph (about 6000 frames), approximately twenty-five minutes were needed to compute the locations of all candidate transitions points.
Result	Approximately five minutes of user time were required to select transition thresholds, and it took less than a minute to calculate blends at these transitions and prune the resulting graph.
Result	Directable locomotion is a general enough need that the preceding algorithm has many applications.
Result	We can use path synthesis techniques to give a user interactive control over a character.
Result	For example, when the user hits the left arrow key the character might start travelling east.
Method	To accomplish this, we can use the path fitting algorithm to find the sequence of edges starting from our current location on the graph that best allow the character to travel east.
Method	The first edge on the resulting graph walk is the next clip that will be played.
Method	This process may then be repeated.
Result	To make this practical, we can precompute for every node in the graph a sequence of graph walks that fit straight-line paths in a sampling of directions (0 degrees, 30 degrees, .
Method	The first edges on these paths are then stored for later use; they are the best edges to follow given the direction the character is supposed to travel in.
Method	If we want a character to perform certain actions in a specific sequence and in specific locations, we can draw a path with subsections requiring the appropriate action types.
Result	This allows us to generate complex animations without the tedium of manual keyframing.
Method	For this reason we term this process “highlevel” keyframing — the user generates an animation based on what should be happening and where.
Method	If an AI algorithm is used to determine that a character must travel along a certain path or start performing certain actions, the motion graph may be used to “dump” motion on top of the algorithm’s result.
Result	Hence motion graphs may be used as a back-end for animating non-player characters in video games and interactive environments — the paths and action types can be specified by a high-level process and the motion graph would fill in the details.
Result	While our discussion so far has focused on a single character, there’s no reason why it couldn’t be applied to several characters in parallel.
Result	Motion graphs may be used as a practical tool for crowd generation.
Result	For example, a standard collision-avoidance algorithm could be used to generate a path for each individual, and the motion graph could then generate motion that conforms to this path.
Result	Moreover, we can use the techniques described at the end of Section 4.2 to add randomness to the generated motion.
Result	In this paper we have presented a framework for generating realistic, controllable motion through a database of motion capture.
Method	Our approach involves automatically constructing a graph that encapsulates connections among different pieces of motion in the database and then searching this graph for motions that satisfy user constraints.
Result	We have applied our framework to the problem of path synthesis.
Method	As we had limited access to data, our largest examples used a database of several thousand frames of motion.
Result	While we believe this was sufficient to show the potential of our method, a character with a truly diverse set of actions might require hundreds or thousands of times more data.
Result	Hence the scalability of our framework bears discussion.
Result	The principle computational bottleneck in graph construction is locating candidate transitions (Section 3.1).
Result	This requires comparing every pair of the F frames in the database and therefore involves O(F 2 ) operations.
Result	However, this calculation is trivial to parallelize, and distances between old frames needn’t be recomputed if additions are made to the database.
Result	It is the exception rather than the rule that two pieces of motion are sufficiently similar that a transition is possible, and hence motion graphs tend to be sparse.
Result	In our experience the necessary amount of storage is approximately proportional to the size of the database.
Result	The number of edges leaving a node in general grows with the size of the graph, meaning the branching factor in our search algorithm may grow as well.
Result	However, we expect that future motion graphs will be larger mainly because the character will be able to perform more actions.
Result	That is, for example, having increasing amounts of walking motion isn’t particularly useful once one can direct a character along nearly any path.
Result	Hence the branching factor in a particular subgraph will remain stationary once that subgraph is sufficiently large.
Result	We anticipate that typical graph searches will be restricted to one or two subgraphs, and so we expect that the search will remain practical even for larger graphs.
Future Work	One limitation of our approach is that the transition thresholds must be specified by hand, since (as discussed in Section 3.2) different kinds of motions have different fidelity requirements.
Future Work	Setting thresholds in databases involving many different kinds of motions may be overly laborious, and so we are investigating methods for automating this process.
Future Work	A second area of future work is to incorporate parameterizable motions [Wiley and Hahn 1997; Rose et al. 1998] into our system, rather than having every node correspond to a static piece of motion.
Future Work	This would add flexibility to the search process and potentially allow generated motion to better satisfy user constraints.
Future Work	Finally, we are interested in applying motion graphs to problems other than path synthesis.

Problem	Good character animation requires convincing skin deformations including subtleties and details like muscle bulges.
Background	Such effects are typically created in commercial animation packages which provide very general and powerful tools.
Problem	While these systems are convenient and flexible for artists, the generality often leads to characters that are slow to compute or that require a substantial amount of memory and thus cannot be used in interactive systems.
Problem	Instead, interactive systems restrict artists to a specific character deformation model which is fast and memory efficient but is notoriously difficult to author and can suffer from many deformation artifacts.
Result	This paper presents an automated framework that allows character artists to use the full complement of tools in high-end systems to create characters for interactive systems.
Method	Our method starts with an arbitrarily rigged character in an animation system.
Method	A set of examples is exported, consisting of skeleton configurations paired with the deformed geometry as static meshes.
Method	Using these examples, we fit the parameters of a deformation model that best approximates the original data yet remains fast to compute and compact in memory.
Problem	To be believable, animated characters must deform in plausible ways as they move.
Problem	It is possible to accomplish this by having an artist sculpt an entire character mesh by hand for every frame of an animation sequence, but this is impractical.
Problem	Instead, animators typi- cally manipulate an underlying hierarchical skeleton.
Background	The character mesh geometry must then be attached to the underlying skeleton so that as the skeleton deforms, the mesh also deforms appropriately.
Background	This attachment of model geometry to an underlying skeleton is called a “skin” and can be viewed as a function that maps from the skeletal parameters to a deformation field.
Background	There are two fundamental aspects of skin creation—authoring and computation.
Background	Skin authoring refers to how artists use tool sets to describe the behavior of skin geometry as the skeleton moves.
Background	Skin computation refers to the method by which the deformed mesh geometry is evaluated for display at some skeleton configuration.
Background	For high-end applications, the authoring methods drive skin creation while for interactive systems, computation methods dominate.
Problem	For high-end applications such as film, the visual fidelity of characters is paramount, so artists require flexibility and control in skin authoring.
Background	Hence, there are many different ways to create characters using commercial tools.
Background	One technique involves modeling skin substructure such as muscles and tendons to drive the skin geometry [Wilhelms and Gelder 1997; Scheepers et al. 1997].
Background	Many deformers which drive skins by linking their control points to the skeletal parameters with custom expressions or scripts are also available.
Background	Some examples include FFD lattices [Sederberg and Parry 1986] or Wires [Singh and Fiume 1998].
Background	High-end characters often use a combination of these techniques—different tools are appropriate for different parts of the character.
Background	This generality and control means that the computation aspect of high-end characters is highly customizable, tightly coupled to authoring, and potentially unbounded.
Background	In fact, high-end tools allow authors to continually develop new skin computation models through custom scripts, expressions and complex deformers.
Background	In contrast, interactive systems require fast computation and small memory size for characters.
Background	Thus, the character computation model is fixed and artists must restrict their tool set to author characters in direct support of it.
Background	The most common skin computation model in games and interactive systems goes by many names including SSD, enveloping, smooth skinning, and linear blend skinning.
Background	This technique assigns a set of influencing joints and blending weights to each vertex in the character.
Background	The skin is computed by transforming each vertex by a weighted combination of the joints’ local coordinate frames.
Background	While fast to evaluate and compact in memory, this method is notorious not only for its authoring difficulty, but also for its undesirable deformation artifacts.
Background	However, this method is widely used since these characters can be used with arbitrary amounts of animation data and can be posed at runtime.
Background	A different character computation mechanism previously used in interactive systems is called mesh animation.
Background	Mesh animation works by storing a large number of deformed models as static meshes—one for each frame of animation.
Background	These static models are then either displayed directly or are linearly interpolated at runtime.
Background	Mesh animation is interesting since it decouples skin authoring from runtime skin computation, allowing artists to use any tools they want to author characters.
Background	Unfortunately mesh animation is only appropriate when the required animation sequences are short and are known a priori.
Background	As games and interactive applications use larger amounts of animation, storing every frame becomes prohibitive.
Background	This technique is also incapable of generating new poses at runtime; for example, to place the character’s hand exactly on a door knob or to make footfalls land precisely on stairs.
Background	Due to these limitations, mesh animation is losing popularity.
Result	In this paper, we present an automated method to build character skins that are fast to compute and compactly represented from a set of examples.
Result	This technique allows artists to use any skin authoring tools they like while producing characters that meet the performance demands and work with the computation models used in interactive systems.
Result	We present a framework for extending linear blend skinning that allows us to capture these detailed skin deformations.
Result	We show how we can fit the parameters of our skinning model using a sampling of an arbitrarily rigged character’s deformations.
Method	Building a skin with our system involves two major steps.
Method	We begin with a character rigged in an animation package such as Maya.
Method	We then sample this character’s skin deformations by exporting the character’s geometry in several poses.
Method	Next we fit the parameters of our underlying skinning model using this sampled data.
Method	We wish to obtain a good sampling of the character’s skin deformations to fit our underlying model with.
Method	To do this, we pose the character to exercise all the joints fully and include its extreme poses.
Method	This step does not require a trained animator since these poses are only intended to exercise the degrees of freedom of the character and need not correspond to a realistic motion.
Method	Once this is done, the poses are sampled regularly at k times.
Method	This sampling can be very simple to obtain from the user’s perspective—in our case, users must simply invoke a script we have implemented in Maya.
Method	Each sample consists of the skeleton configuration and the corresponding deformed skin geometry as a static mesh.
Method	We call a paired skeleton configuration and static mesh an example.
Method	Using this set of examples, our system first determines the set of joints that should influence each vertex, and then solves a bilinear least-squares problem to fit the parameters of the underlying skinning model.
Method	As mentioned earlier, the skinning model we use is an extension of the standard linear blend skinning model.
Method	Our extension adds extra joints to the character that are simply related to the existing joints.
Method	These new joints are designed in such a way to capture richer deformations than the standard linear blend skinning model.
Method	Our system is configured to add these extra joints automatically to characters, but we allow users to fine tune the specific set of extra joints if they wish.
Background	Character skin deformations are fundamental to character animation and have been addressed for some time in the literature.
Background	Catmull [1972] introduced one of the first skeleton-driven techniques—rigid skinning to a hierarchically structured articulated figure.
Background	A 2D skeletal bilinear deformation method was presented by Burtnyk and Wein [1976].
Background	An early 3D skeleton-driven technique that went beyond rigid skinning was presented by MagnenatThalmann, et al. [1988].
Background	Their technique used custom programmed algorithms to deform character meshes based on the nature of particular joints.
Background	More recently, novel skinning methods that start with a simple skin and use sparse data interpolation to correct errors between it and a set of examples have been introduced.
Background	Three examples, Pose Space Deformation, Shape by Example, and EigenSkin [Lewis et al. 2000; Sloan et al. 2001; Kry et al. 2002] use radial basis interpolation of corrections to linear blend skins.
Background	Another recent work applies these techniques to range scan data [Allen et al. 2002].
Background	These techniques are similar to ours in that they take examples as input.
Background	The results of these approaches are quite good, and unlike our technique, they can handle skin deformations that depend on abstract parameters rather than only skeleton configurations.
Background	However, these methods are not appropriate for interactive characters since they require storing potentially large amounts of example data for runtime interpolation.
Method	In contrast, our method discards all example data after the fitting process so the size of our runtime structures does not scale with the number of inputs.
Background	Other authors have used physical simulation for interactive deformations, especially secondary animation [James and Pai 2002; Capell et al. 2002].
Method	Our method cannot capture these secondary deformations directly; however, a technique such as DyRT [James and Pai 2002] can be applied to the characters we generate to add secondary animation.
Background	There has been some recent work on fitting skinning models.
Background	One method solves for joint centers and vertex weights for a scanned arm [Nebel and Sibiryakov 2002] but the Multi-Weight Enveloping technique [Wang and Phillips 2002], or MWE, is most similar to our approach.
Background	MWE extends linear blend skinning by giving each vertex one weight to each coefficient of each influencing joint’s transformation matrix instead of one weight per influencing joint.
Background	They then find these weights by solving a linear leastsquares problem using a set of examples as input.
Background	While on the surface Multi-Weight Enveloping and our technique seem very similar, they are in fact different in a fundamental way.
Method	Both MWE and our technique use an extension of linear blend skinning as an underlying deformation model.
Background	However, MWE extends linear blend skinning by adding more vertex weights to the model while in contrast, our method adds more joints.
Background	MWE uses a large number of weights per vertex (12 per influencing joint).
Background	This introduces the possibility of rank deficient matrices in the least-squares solutions [Wang and Phillips 2002], especially since the matrix coefficients are usually highly correlated.
Background	This can lead to overfitting, which MWE must take measures to avoid.
Method	In contrast, since the number of weights per vertex in one of our skins remains relatively small (1 per influencing joint) and our extra joints are explicitly designed to be very different from existing joints, our technique requires no special provisions to avoid overfitting.
Result	Even so, our method can detect and handle small amounts of overfitting if it occurs as explained in Section 5.2.
Method	Another consequence of having one weight per entry in the joint transformation matrices is that MWE skins are not as easily accelerated by graphics hardware as skins created using our method.
Method	Finally, since our skins are computed in the same manner as linear blend skins, existing software infrastructure can make use of them with little or no changes.
Background	The traditional interactive skinning model goes by many names.
Background	Lewis et. al call it Skeleton Subspace Deformation or SSD, Maya calls it “smooth skinning” and we call it linear blend skinning.
Background	This technique is widely used for interactive applications.
Background	An excellent description of this method is found in Lewis et al. [2000].
Background	The linear blend skinning algorithm works by first placing a hierarchical skeleton inside a static model of a character, typically in some neutral pose.
Background	This initial character pose is referred to as “dress pose”.
Background	Then, each vertex is assigned a set of influencing joints and a blending weight for each influence.
Background	Computing the deformation in some pose involves rigidly transforming each dress pose vertex by all of its influencing joints.
Background	Then the blending weights are used to combine these rigidly transformed positions.
Background	(Taken together, M i,d −1 v d represents the location of v d in the local coordinate frame of the ith influence.
Background	) Note that a deformed vertex position in the dress pose configuration c = d is the same as the provided dress pose vertex ( v d = v d ) if the weights are affine.
Background	This skinning algorithm is notorious for its failings.
Background	It cannot represent complex deformations and suffers from characteristic artifacts such as the “candy-wrapper” collapse effect on wrists and collapsing around bending joints as shown in Figure 2 .
Background	The artifacts occur because vertices are transformed by linearly interpolated matrices.
Background	If the interpolated matrices are dissimilar as in a rotation of nearly 180 degrees, the interpolated transformation is degenerate, so the geometry must collapse.
Background	In addition to these deformation problems, linear blend skins are very difficult to author [Lewis et al. 2000].
Background	Despite its failings, this skinning algorithm is very fast and widely supported by commercial applications so it remains popular especially in games and virtual environments.
Problem	The linear blend skinning model is not sufficient to capture deformations well as shown in Figure 3 .
Problem	The problem in this particular case is that as the twist approaches 180 degrees, the linearly blended matrix becomes degenerate and collapses the skin geometry.
Problem	Linearly blended transformations tend to collapse the more different they are.
Problem	The resulting loss of volume can also be observed around hinge joints such as the knee and elbow as shown in Figure 2 .
Problem	We observe that we can help avoid the collapse problem by avoiding blending transformations that are so dissimilar.
Method	We can accomplish this by adding extra transformations that properly interpolates without collapsing.
Method	In the case of the twisting wrists, we can add an extra joint that interpolates the rotation angle correctly and does not collapse.
Background	In fact, artists sometimes do this by hand to help avoid wrist collapses.
Method	More generally, we observe that any deformation effect could be obtained by adding joints that deform appropriately to capture that deformation effect.
Method	For example, to capture muscle bulges, we can add joints that scale up when the muscle should bulge, and scale down when the muscle relaxes.
Method	For wrinkles, we could add several joints that move and scale in concert to capture the wrinkles.
Method	Unfortunately, adding so many extra joints is impractical.
Method	First, adding such a large number of joints would severely impact the performance of our resulting skins.
Method	Worse, even if we could find these transformations for the input examples, it is unclear how to determine the general relationships of these transformations to the skeletal parameters in all poses.
Method	Without knowledge of this relationship, our scheme would only be able to reproduce the input frames and would not work well in new poses.
Method	Instead, we extend the traditional linear blend skinning model by adding a relatively small number of joints that are simply related to the original skeletal parameters and fit using them.
Method	We choose these extra joints by both examining the places where the standard linear blend model fails and by examining extra character deformations that we would like to capture.
Method	We then add joints that we believe will help resolve these artifacts.
Method	Finally, we fit the parameters of our skinning model using this extended skeleton.
Method	The key to our success is that since vertices choose weighted sums of transformations, if any linear scaling of an added joint is beneficial it may be used.
Method	Thus the additional joints need not be exact.
Method	We emphasize that this is a framework for obtaining better deformations and the joints we choose to add are based on our observations of characters.
Method	Different characters with different deformations may require a different set of additional joints.
Method	However, once some set of these joints is determined, the skin may be solved using our fitting algorithm without change.
Result	To help solve the collapsing geometry problem, our system can automatically add joints that properly interpolate rotations without collapsing.
Method	This is done by examining the rotation of a joint relative to the dress pose and computing the new joint as the halfway spherical linear interpolation [Shoemake 1985] of this rotation, located at the same position in space.
Method	More joints with evenly distributed interpolation parameters could be added to sample this rotation space even better; however, in our experience just a single interpolated rotation is sufficient.
Problem	Another type of effect not easily captured by the simple linear blend model is bulging and denting of skins caused by muscles, tendons, or other substructure.
Problem	These particular effects cannot be captured since the joints employed in animating a character do not typically scale up and down as would be necessary to approximate these effects.
Method	We have observed that for many characters, the substructure deformation effects from muscles and tendons are often simply related to the angles between joints.
Method	For example, a bicep bulge is small when the elbow is near full extension while the bugle is large when the elbow is near full flexion.
Method	The effect is similar for other muscles in the body.
Method	To capture these effects, our system can add several joints that scale up and down based on the angle between particular joints.
Method	We add these scaling joints as follows.
Method	First we choose a joint in the original skeleton that will drive the scaling parameters of the new joints.
Method	Once this driver is chosen, there are two sets of joints that we add.
Method	The first set is “upstream” of the driver and lies in the middle of the bone connecting the driver to its parent, the second set is “downstream” and lies in the middle of the bones connecting the driver to its children.
Method	All upstream joints are oriented in the same way, with one axis aligned with the bone as shown in Figure 6 .
Method	We use four upstream joints.
Method	Two of them scale up about two axes orthogonal to the bone and a corresponding pair scale down about the two axes orthogonal to the bone.
Method	The scale parameters of these joints are set based on the angle of the bone connecting the driver to its parent and the bone connecting the driver to its child.
Method	If the driver has multiple children, a vector that is the sum of the bones connecting the driver to its children is used to measure the angle.
Method	Downstream joints are similar.
Method	We use four downstream joints on each bone connecting the driver to its children that scale just as the upstream joints do.
Method	The scale parameters are computed as follows.
Method	For joints that scale up, the scale parameter s is s = 1 + k b 1 · b 2 + 1 2 b 1 b 2 where b 1 and b 2 are the bone vectors used to measure the angle at the driver joint and k is the maximum scale factor when the angle between b 1 and b 2 is zero.
Method	For joints that scale down, the scale parameter is simply s −1 .
Method	The value for k may be chosen by the user but in our experience, we have found that 8 works well for our examples.
Method	Again, since vertices may take any scaling of these new joints, a conservative large value is fine.
Method	For example, if a vertex in fact needed a joint that scaled by 2 instead of 8, it could be assigned a weight of 4 1 .
Method	Once our system has augmented the input skeleton, we use a fitting procedure to set the parameters of the underlying skinning model to match the example data well.
Method	As mentioned earlier, the input to the fitting process is a set of examples.
Method	An example is simply a static character mesh paired with a skeleton.
Method	This static mesh is deformed according to the skeleton configuration, but it is not attached to the skeleton in any way.
Method	For our results, our examples were generated by exporting rigged objects from Maya, but they could have been sculpted by hand or come from another program.
Method	A linear blend skin computes a deformed vertex as described earlier in Equation 1.
Method	Examining this skinning model, only the M i are predetermined.
Method	These are the coordinate frames associated with all the joints in the character.
Method	That means for each vertex, we are able to choose the set of influencing joints, influence weights (w i ) and the dress pose vertex position (v d ).
Method	We would like to choose the influence sets, weights and dress pose vertex positions that best approximate the examples and generalize well to new poses.
Method	We determine influence sets first for several reasons.
Method	Ideally, the influence sets would fall out naturally from the weight solving procedure (irrelevant joints would have a weight of zero) but this does not happen in practice because our samplings are necessarily not exhaustive.
Method	Also, the more joints that a vertex depends on, the slower the skin can be to compute and current hardware only supports a limited number of influences per vertex.
Method	Thus, we would like to select a small set of good influences.
Method	Also, choosing the influence sets appropriately lets us bound the size of the problems we must solve to determine the weights as discussed in Section 5.2.
Method	This makes the solving process faster.
Background	In most recent research, influence set determination has been left to users [Lewis et al. 2000; Wang and Phillips 2002; Sloan et al. 2001].
Background	The task is typically accomplished by “painting” the regions of influence for each joint over the mesh.
Background	While less difficult than painting the weights themselves [Lewis et al. 2000], it is a tedious process.
Method	In contrast, our system automatically determines the influence sets for each vertex using a heuristic algorithm.
Method	We observe that vertices in a character skin typically transform nearly rigidly with respect to some joint.
Method	For instance, vertices on the forearm roughly follow the forearm.
Method	We believe that for most characters, their skin is most heavily influenced by those joints that they are bound to.
Method	Even though a point on the bicep is not truly rigid as an arm moves (due to muscle bulge), we believe that these points remain mostly rigidly attached to the upper arm, and therefore should be influenced by it.
Method	Using this observation, we measure how rigidly a vertex transforms with every joint over all examples and use the most rigidly transforming joints for the influence set.
Method	For a single vertex, a rigidity score for a joint is computed as follows.
Method	For each example, the local coordinate position of the vertex is computed as M i,e −1 v e where M i,e is the coordinate frame associated with the ith joint in the eth example and v e is the global coordinate position of the vertex on the eth example.
Method	The collection of these local coordinate positions over all examples forms a point cloud as shown in Figure 7 .
Method	The more compact this point cloud, the more rigid we believe the vertex-joint relationship to be.
Method	We measure the compactness of this point cloud by taking its diameter (the maximum distance between any two points in the cloud).
Method	We have found that the simple O(n 2 ) algorithm that compares each point to every other to be fast enough for our purposes but this diameter may be computed more quickly.
Method	An O(n log n) time algorithm is possible.
Background	See [Malandain and Boissonnat 2002] for faster methods.
Method	Once the compactness measures for all joints are computed for a vertex, the smallest k are chosen as the influence set for that vertex.
Method	It may be tempting to use a threshold scheme to choose influence sets but we have found this problematic.
Method	It is unclear how to pick a good threshold because as the rigidity scores get larger, they become less meaningful.
Method	For instance, it may happen as an artifact of the particular input examples that points on the left shoulder move much more rigidly relative to the right leg rather than the left leg but both choices make no sense for influences.
Method	Since larger rigidity scores are not particularly meaningful, it is nearly impossible to pick a meaningful threshold value.
Method	As in other linear blend skinning systems, influence sets need only be determined conservatively [Wang and Phillips 2002] so we allow users to choose k if desired.
Method	In our experience, we have found that between three and eight influences works well, depending on the complexity of the character.
Method	Once the influence sets have been determined, only the weights and dress pose vertex positions remain (w i and v d ).
Method	We would like to find the best vertices and weights that minimize the least-squares difference between the skin and the examples at all the example skeleton configurations.
Method	That is        n 2 min ∑ v e i − v e i i=1        for all examples where v e i is the input vertex position from the ith example and v e i is the deformed vertex computed by the skinning model at the ith example configuration.
Method	We use an alternation technique to solve the optimization.
Method	This works by first fixing the first variable and solving a linear least-squares problem to find the second, then fixing the second and solving a linear leastsquares problem for the first.
Method	This process is then repeated until it converges.
Background	This technique is commonly used and is described in [Freeman and Tenenbaum 1997].
Method	We start by solving for weights since we have no good guess for them but we know that the initial dress pose vertices are ideal.
Method	Next we hold the weights fixed and solve for vertex positions.
Method	This process typically converges after one or two iterations.
Result	As mentioned in Section 2, we have found that since we are solving for a small numbers of weights using large numbers of examples, our systems are often well conditioned and do not suffer from overfitting if the input data is well sampled.
Result	Thus we do not have to take special precautions to avoid overfitting as in [Wang and Phillips 2002], although we include tests for robustness.
Method	For clarity, we present the matrices we solve via least-squares in block form.
Method	First we introduce some notation: T i,e = M i,e M i,d −1 .
Method	In order to ensure that the resulting weights are affine, we set w 1 = 1 − ∑ i=2 n w i , and solve for w 2 through w n .
Method	We solve these least-squares problems using the singular value decomposition.
Method	This lets us detect when our matrices are rank deficient, leading to overfitting.
Method	We detect this by comparing the ratio of the largest singular value to the smallest, and issuing a warning if there are any singular values below some fraction of this ratio.
Method	To recover, we zero these singular values and continue with the fitting process.
Method	If overfitting is a problem, provisions such as those taken in [Wang and Phillips 2002] could also be used.
Method	However, in all the examples in this paper, no singular values were zeroed.
Method	It is not only important for the geometry in a skin approximation to be accurate, but also important for normals to be well approximated.
Method	If they are not, lighting calculations will not produce good results.
Method	We assume that normals are specified per vertex.
Method	It may seem that just transforming a dress pose normal by the inverse transpose of the corresponding vertex’s transformation matrix would be correct.
Method	Instead we have single points that are computed independently.
Method	Computing the normals in this manner can give undesirable results when the blended transformations are not pure rotations.
Method	This alleviates the need for a general inversion operation.
Background	In EigenSkin [Kry et al. 2002], normals are treated as second skinning problem and are computed independently.
Method	In our system, we take the model used in existing systems as in Equation 2 and include normals in our optimization process.
Method	To do this, we simply add more terms to the objective function to include the differences between normal vectors.
Method	We allow users to scale normals if they wish to change their relative influence on the least-squares solution.
Problem	The simple linear blend skinning model commonly used in video games and other interactive applications is very fast and compact but cannot capture the high quality deformations that make convincing characters.
Result	Our framework for extending the linear blend model allows us to capture much more interesting deformations while retaining its efficiency.
Result	The most egregious deformation problems of linear blend skinning are solved by our approach.
Result	Collapsing and interpenetrations around hinge joints are also fixed using our method as shown in Figure 5 .
Result	In addition to solving these problems with linear blend skinning, our extension framework can capture other more subtle and detailed deformations required for convincing characters.
Result	While the particular extra joints we have chosen to add to our characters may not be capable of capturing the full deformation for any character, different extra joints that do capture the desired deformations may be added and solved using our technique.
Method	To demonstrate that our technique can be used on more than just simple arms and legs, Figure 9 shows a rigged upper body and its approximation by our system.
Result	This figure also shows this character in new poses from an animation sequence, demonstrating that our resulting skins generalize well to new poses.
Result	Our solution procedure is generally very fast.
Result	None of the examples shown here took more than five minutes to solve on a modern personal computer.
Result	The slowest was the upper body model which has more than 6000 vertices, 50 examples, and 5 influences per vertex.
Result	The computation time for each vertex depends on the number of influences and the number of examples.
Result	Also, since each vertex is solved independently, our algorithm is trivial to parallelize.
Result	The ability to generate compactly represented, fast to evaluate, high quality skin approximations from a set of examples is very useful.
Problem	Applications range from building characters for video games and virtual environments to high-end animation previewing.
Background	Many current interactive systems such as video games only support linear blend skinned characters.
Problem	Aside from the deformation problems associated with using this model, authoring these skins is notoriously difficult.
Problem	Determining the blending weights and influence sets is left to the skin author to set directly.
Problem	None of the more intuitive or useful deformer primitives provided by animation systems may be used.
Result	Using our method, character authors may use any tools they like to author characters.
Result	All our system requires is a set of examples which is used to compute the appropriate influence sets and blending weights automatically.
Result	This frees the author from setting them manually.
Result	It is important to note that since our characters are a straightforward extension to linear blend skinning, many existing interactive systems already have the software infrastructure to sup- port them.
Result	In addition, since our skins are computed in the same manner as existing linear blend skins, they are already accelerated by current graphics hardware.
Result	Another application of our system is to map a character originally attached to one skeleton onto a different underlying skeleton.
Result	We call this process skin retargeting.
Result	Skin retargeting is useful if a particular interactive system requires characters to have a specific skeleton.
Result	For instance, a video game may have an optimized engine for characters with a particular skeleton topology.
Result	Ordinarily, if a character was created for a different skeleton, the character would have to be re-rigged manually to work on the new skeleton topology.
Result	However, this can be accomplished much more easily with our system.
Result	One just exports a set of example meshes deformed by the original skeleton but paired with corresponding poses of the new skeleton.
Result	Our system sees this as any other set of data and solves for the proper influence sets and blending weights.
Result	Another application of our technique is targeted at high-end animation.
Background	High-end characters often have such complex deformations that they cannot be computed interactively.
Background	Thus, animators typically work with low fidelity versions that only roughly suggest the actual shape of the character.
Result	Using our method, interactive characters could be built that allow animators to interact with much better approximations of the deformed characters.
Result	In this paper, we have presented a method for building fast to evaluate, compact representations that produce accurate approximations of deforming characters.
Result	The characters may be rigged using any available tool since our system only requires static deformed meshes paired with skeletal configurations as input.
Result	While our technique works well for a wide variety of character skins, it has limitations.
Result	For instance, character deformations in our model are only driven by the skeleton’s joint parameters.
Result	Our method cannot capture deformations that are driven by abstract parameters such as “happiness” as in [Lewis et al. 2000; Sloan et al. 2001].
Result	Our system also cannot accurately reproduce deformations that are not representable as linear combinations of the transformations expressed in our skeletons.
Result	For instance, the scaling joints presented in this paper can only fully capture deformations that are well approximated by a scaling that is linearly related to the cosine of the angle between two bones.
Result	This assumption may be violated by a character whose muscle bulges only when its arm is fully bent.
Result	The scaling joints also assume that only the angle between joints is important, so bending the shoulder forward is treated the same as bending it up.
Result	Even though not all deformations can be captured using the extra joints presented here, new joints may be added to capture any important deformation, and our influence set and vertex weight solving framework may be applied without change.
Result	Despite these limitations, our method produces high-quality yet fast and compact skinned characters that work with existing game engines, graphics hardware and other runtime systems.

Result	This paper presents a system for rapid editing of highly dynamic motion capture data.
Result	At the heart of this system is an optimization algorithm that can transform the captured motion so that it satisfies high-level user constraints while enforcing that the linear and angular momentum of the motion remain physically plausible.
Result	Unlike most previous approaches to motion editing, our algorithm does not require pose specification or model reduction, and the user only need specify high-level changes to the input motion.
Method	To preserve the dynamic behavior of the input motion, we introduce a spline-based parameterization that matches the linear and angular momentum patterns of the motion capture data.
Method	Because our algorithm enables rapid convergence by presenting a good initial state of the optimization, the user can efficiently generate a large number of realistic motions from a single input motion.
Method	The algorithm can then populate the dynamic space of motions by simple interpolation, effectively parameterizing the space of realistic motions.
Result	We show how this framework can be used to produce an effective interface for rapid creation of dynamic animations, as well as to drive the dynamic motion of a character in real-time.
Problem	Despite great advances in recent years, creating effective tools for synthesis of realistic human motion remains an open problem in computer animation.
Problem	This is particularly true for synthesis of highly dynamic character motion such as running, leaping, jumping and other athletic and acrobatic maneuvers that frequently occur in feature special effects and video games.
Problem	Synthesizing such motions can be challenging because any physical inaccuracies in these motions are particularly noticeable.
Background	Both spacetime optimization and controller synthesis approaches have been proposed for direct synthesis of dynamic character motion.
Background	Although these methods do satisfy physical laws, they tend to appear overly smooth and at times robotic.
Problem	Furthermore, these methods do not provide interactive control, often requiring considerable offline processing time before the animation sequence is generated.
Problem	In addition, it is difficult to achieve a graceful degradation of realism for the purpose of greater control.
Background	In contrast to direct synthesis, methods based on adaptation of motion capture data produce highly realistic motion, especially in the neighborhood of captured motion samples.
Background	They also run at interactive speeds, as they employ data interpolation techniques.
Background	Unfortunately, these methods require a large number of motion samples.
Background	If the animator wants to interactively control a specific parameter of the animation such as the landing foot position in a particular acrobatic stunt, the need for a large dataset is particularly pronounced: the interpolation techniques would require an already existing family of motion sequences where the only difference in motion is the landing foot position.
Problem	Gathering such a datataset is not only laborious, but it also requires that the captured family of motions is similar in all other respects (e.g. other landing points, initial and final state, overall style) — an aspect that is quite hard to reproduce by real actors.
Problem	In fact, the process of generating such parameterized motions is the most challenging aspect of data acquisition for video game production [Buc].
Problem	In addition, the animators often wish to create non-realistic motions that defy the laws of physics, a space where motion capture simply fails to provide any samples.
Method	We take the approach to acquiring similar motions is to adapt a single motion sequence several times to synthesize a family of motions that preserve physics constraints.
Method	Motions created in this manner can satisfy an animator’s exact specifications with a minimum of deviation from the initial motion sequence.
Problem	Ideally, we would like to use a minimal source of motion data, perhaps a single captured movement, to create a wide range of additional motions.
Background	Recently a number of dynamic motion adaptation methods have been proposed [PW99, ZH99, TSK02, SP04, SHP04], and the work presented in this paper falls into this category.
Problem	In this paper, we describe the momentum-based motion editing technique.
Result	In contrast to the existing methods, our proposed framework is particularly robust to large-scale motion modifications.
Result	For example, we can adapt a forward leaping movement, to a collection of leaping movement in different directions including a backward leap, or a 360 ◦ leaping spin.
Result	Using our motion editing framework, we show how a family of dynamic movements can be synthesized based on the animator’s needs for interactive control.
Method	Because our family of motions samples the space widely, satisfies exact constraints, and otherwise deviates minimally from the original source sequence, we can use simple interpolation techniques to allow real-time exploration of this synthetic motion space.
Result	We describe a number of real-time animation tools that can be constructed using these synthetic motion families, such as interactive displacement of constraints (e.g. varying foot landing position), as well as inverse control examples such as the determination of the natural volleyball spike that would hit the ball arriving at a specific position in space.
Result	In addition, we describe how the same synthetic sampling/interpolation approach can be used to develop realtime controllers for leaping character motion, all synthesized from a single motion-captured leap.
Background	Recent research in computer animation focused on techniques for remapping existing data to given specifications of a new scenario.
Method	In this paper, we build on the research in both physicsand interpolation-based motion editing methods.
Background	Optimal trajectory methods introduced by Witkin and Kass [WK88] provide a powerful framework for enforcing dynamic constraints while searching for the most favorable motion judged by the objective function.
Background	The dependency on the initial point has been somewhat alleviated by starting out with the captured motion sequence.
Background	Popović and Witkin in 1999 developed a first method that transforms motion capture data while preserving physical properties [PW99].
Background	They found solutions by performing optimizations on the reduced character model.
Background	More recently, editing motion capture data based on spacetime optimization has become a popular strategy for producing realistic character animations [RGBC96, SP04, SHP04].
Background	These methods provide control for modifying data while retaining physically plausible properties of captured motion by restricting the optimization space with additional kinematic constraints (e.g. [RGBC96]), or by solving within the PCA-reduced space of motions [SHP04].
Background	It has recently been shown that relying on simplifications of dynamic constraints is not necessary if proper scaling and estimation of joint angles, torques, and Lagrange multipliers are provided [SP04].
Method	Our work uses a similar spacetime optimization framework.
Method	In contrast to other approaches, we formulate significantly simpler momentum constraints on a complex character model, without solving for muscle forces explicitly, similar to [LP02].
Method	Since we do not compute internal torques for joints, scaling and convergence issues are less critical in our optimization framework.
Method	Our physics-based motion editing approach is based on the momentum constraints introduced by Liu and Popović [LP02].
Background	In that work, momentum constraints were used for synthesis of highly dynamic motion from simple animations that did not contain sufficient information to synthesize the full motion.
Background	As a result, transition poses had to be introduced to further restrict the optimization space.
Background	There are two main advantages of momentum constraints over the full dynamics constraints.
Method	First, since dynamic constraints are reduced to only global momentum patterns, we are solving for a much smaller set of unknowns, and over a much “better behaved” set of constraints.
Method	This allows us to find solutions quickly.
Method	Also, in our experience, these constraints do not suffer from many local minima, thus enabling us to find solutions significantly further away from the original motion.
Background	The second advantage of momentum constraints is that they encode more about the natural motion than just physical correctness.
Background	For example in natural motion, passive elements such as tendons and ligaments store and release energy during ballistic motion.
Background	To model this with a full dynamic system, one would have to include a complex muscle model.
Background	Momentum constraints effectively record the aggregate effect of the natural torque usage and energy storage/release in a specific momentum pattern.
Background	This additional information embedded within the momentum constraints ensures that adapted motion is not just physically correct, but that it also constrains the motion within the momentum exchange patterns observed in nature.
Method	In contrast to the original paper that introduced momentum constraints, our method applies momentum constraints directly on the motion capture data.
Method	Our algorithm does not require any additional pose constraints at the transition points between flight and ground phases.
Method	Furthermore, we introduce a novel spline-based representation for the momentum patterns that can be used to intrinsically enforce the similarity between the resultant motion and the input motion.
Background	Instead of formulating a physics-based optimization, dynamic filtering is an efficient alternative for motion editing of smaller amplitude.
Background	Per-frame based frameworks largely reduce the computation time, providing an interactive editing interface to the user [TSK02, SKG03].
Background	Unfortunately, the per-frame approach means that animators can modify the spatial position of constraints, but not their position in time.
Background	Tak et al. applied Kalman filter to estimate an optimal pose for the current frame subject to the given constraints.
Background	The result of the estimation is then rectified by least-square-fit to ensure a physically sound motion [TSK02].
Background	Shin et al. approximated the adjustment made to the original motion capture data by correcting the momentum of the character during flight and using the balance constraints on the ground [SKG03].
Method	In general, these methods are geared toward the local modification compared to the overall motion, such as improving the balance, whereas our approach is able to handle global changes of the motion such as transforming a forward jump to a 360 ◦ backward spin jump.
Background	Another branch of dynamic filtering employs dynamic tracking [ZH99, PR01].
Background	These methods combine motion capture data and dynamic simulation to retain human-like details from the data while presenting interaction with the environment.
Background	These methods produce motions that do not deviate significantly from the input motion, relying on the existence of captured motion that is similar to what the user intends to do.
Background	Straightforward interpolation of joint angles usually fails to preserve physical realism from the original data.
Background	However, many methods have shown that small modification of the motion can be easily done by linear interpolation of joint angles [BW95, WP95, WH97].
Background	Combining interpolation with kinematics constraints, Gleicher adapted original motion to a new character while maintaining environmental constraints such as foot contacts on the floor [Gle98].
Background	A more sophisticated interpolation was presented using radial basis functions to blend motion sequences with various inverse-kinematic goals [RSC01] or different style [RCB98].
Background	Unfortunately, data acquisition and post-processing for these methods present a significant challenge since motion sequences need to be carefully crafted so that they contain the same content yet different in style.
Method	Our approach only requires one single motion capture sequence as the seed.
Method	This seed is used to generate a family of motion sequences that parameterize the dynamic space.
Background	Lee and Shin presented a multi-level B-spline representation by which they transform existing motion to satisfy desired constraints adaptively through direct manipulation [LS99].
Background	Using B-spline representation, the motion edits can be limited to user-specified frequency bands, providing a more effective optimization framework.
Method	Our work adapts the idea of using spline-based representation to constrain the search of the optimization.
Method	We model the momentum curves by a B-spline representation which are fitted to the original motion so that the search space in the optimization is limited to solutions that have similar dynamic behavior of the original motion.
Method	Our system is based on an optimization algorithm that can transform the captured motion to satisfy high-level user constraints while preserving physical realism.
Method	As input, the system takes a single motion capture sequence and the userspecified modification.
Method	We describe the algorithm in three separate components: Motion pre-fitting, optimization, and interpolation (see Figure 1 ).
Method	The pre-fitting optimizes a set of coefficients used to model momentum curves so that they are constrained to the similar shapes of the original motion.
Method	The system then formulates a spacetime optimization that solves for a new motion, where both high-level physical constraints and the user specification are met.
Method	With a family of such optimized motions that parameterize certain dynamic space, we can apply a simple linear interpolation to generate arbitrary new motion within the dynamic space in real-time.
Method	Our algorithm adapts the momentum-based constraints [LP02] for the task of motion editing.
Method	Instead of filling in missing data, motion editing must solve the converse problem of preserving the original data while still satisfying animator-imposed constraints.
Method	There is no need for keyframing of any kind because the motion already starts in a good initial state.
Method	Any underlying physical model employed by the system must be flexible enough to precisely describe the initial state of the motion and, at the same time, rigid enough to maintain a semblance of the original motion throughout the editing process.
Method	At the heart of our algorithm is a set of full-body angular and linear momentum curves.
Method	These curves constrain the edited motion to the realm of physical realism without the need to simulate expensive dynamical properties such as joint torques and contact forces.
Method	The momentum curves are parameterized by a set of coefficients that are pre-solved to closely match the input motion.
Method	The advantage of this approach is twofold.
Method	First, a good initial state of the momentum coefficients results in rapid convergence of the optimization.
Method	Second, the coefficients that control the shape of the curves can be fixed throughout the editing process, effectively performing a biased search for similar motions in the momentum space.
Method	After the motion is captured using an optical system and processed to fit the character’s skeletal structure, we employ the constraint detection technique described in [LP02] to partition the motion into ground-contact and flight stages.
Method	Since the the animator may at times wish to produce physically impossible jumps that are not constrained to the earth’s gravity, and because the sampling rate varies for each input motion sequence, we also need to determine the time interval between two animation frames.
Method	Gravity and time step are directly related because we can equivalently choose to find the right gravitational constant that makes the motion realistic for a given unit time step.
Method	During free-fall stages, the linear momentum is only affected by gravity and the angular momentum remains constant.
Method	When the body is in contact with external forces, the momentum curves can no longer be represented by a simple set of linear equations.
Method	Instead, we represent the momentum curves with a 3rd-order non-uniform B-splines for their flexibility and convenient knot based parameterization.
Method	In our spline representation, the first and last knots have duplicity 4 to ensure interpolation of the end points (see [FvDFH92]).
Method	A defining characteristic of motion is the shape and magnitude of its momentum curve (see Figure 2 ).
Method	In the case of our spline representation, the control points determine the magnitude of the curve and the spacing of the knots influence the shape.
Method	We note that this formulation can capture a greater variability of momentum patterns than the previously used hardwired patterns [LP02].
Method	This is especially important when dealing with motion capture data due to wide range of different maneuvers possible in the real world.
Method	In other words, we perform a least-squares regression over the momentum curve in the ground stage, while maintaining C 1 continuity through the transitions to the flight stages.
Method	There are few exceptions to the problem described above.
Method	When there is no adjacent flight stage, we remove the constraint corresponding to v i from the statement of the problem.
Method	Also, the constraint corresponding to v 0 is entirely removed when pre-fitting the vertical linear momentum curve since the transition from a free-fall stage to a ground stage is typically dominated by impulsive forces, which are not C 1 continuous in the vertical momentum component.
Method	As in [LP02] we model motion as an optimal dynamic process with a set of realistic constraints.
Method	In general terms, our condition for optimality is that the output motion be both as smooth, and as similar, to the original motion as possible.
Method	Constraints on the solution ensure that the character’s limb do not bend unnaturally, that the character’s feet do not pass through the ground, and that the character’s full-body momentum curve follows the path of the pre-fit momentum splines.
Method	The degrees of freedom to be optimized are contained in Q G, where Q is the set of joint angles through time describing the motion and G is the set of the control points controlling the momentum splines.
Method	In the initial state of the optimization, Q is a good initial guess at the target motion formed by linearly interpolating the original motion between user specified translations and orientations, and G contains the pre-fit momentum coefficients.
Method	In addition to the constraints and objectives used in [LP02], we also introduce a similarity objective and a pseudo balance objective as described in the following sections.
Method	The similarity objective is intended to keep the optimized motion as similar to the original as possible.
Method	We formulate this objective as the squared distance between the original vector of DOFs, Q init , and the solution vector, Q. Each joint DOF is scaled by its natural bound.
Method	The energy function we wish to minimize is then, E s (Q) = (Q init − Q) 2
Method	Since we do not model the specific human preference to stay out of extreme leaning movements that in real life can often cause foot slipping on the ground, there are some instances when the resulting motion would leave the character unnaturally leaning without a means of support.
Method	To pull the optimized solution away from these unstable regions, we include a pseudo balance objective.
Method	The objective we use attempts to minimize the squared distance between the COM, C(t) of model in the first time-step, t 0 , and last timestep, t f , of the initial and final ground stages of the motion.
Method	For interior ground stages, we instead minimize the distance between the COM of the model in the middle frame of the stage, C(t m ), and the COM of the linearly interpolated input motion, C orig (t m ), in the same frame.
Method	To summarize, the unknowns of our system, Q and G, are the character DOFs and the control points for the momentum splines.
Method	Note that spline knots are omitted to maintain the similar momentum pattern of the original motion.
Method	The optimization enforces two types of constraints: environment constraints, K e , such as feet positions on the ground, and momentum constraints, K m .
Method	The following spacetime formulation finds the unknowns Q and G that minimize the objective function while satisfying all the constraints: min Q,G E s (Q) + E b (Q) subject to K K e m (Q) (Q, G) = = 0 0
Method	Our system provides several high level motion specification tools so that the animator never has to think of editing in terms of constrained optimization.
Method	First, motions are automatically partitioned into alternating flight and ground stages.
Method	Alternatively, the user can manually adjust the partitioning to make corrections.
Method	Next, the user manipulates ground stages with the mouse to translate their position and turns a dial to change the orientations as desired.
Method	The system treats these specifications as offsets from the original state of a ground stage.
Method	In other words, given the original translation, q T , and original orientation, θ, of the ground stage, the user specifies offsets ∆q T and ∆θ.
Method	The new translation and rotation of the ground stage is then altered to be q T + ∆q T and θ + ∆θ, respectively.
Method	To form a good initial guess at the solution for the frames of the flight stages, the system linearly interpolates the offsets of the adjacent ground stages over each time step of the flight stage.
Result	The resulting motion is a crude approximation of the final result, but provides a good initial state for the spacetime optimization.
Method	The animator can also change the height of the trajectory in a flight stage by interactively shaping a visualization of the trajectory.
Method	This is particularly useful when creating non-realistic motion that defies gravity, as will be explained below.
Method	Once the user is satisfied with the edits, the optimization process takes between 1 to 5 minutes per motion.
Method	Alternatively, several motions can be generated together in a batch mode.
Method	The technique constructs an output motion in real-time by performing a simple weighted average over the DOFs values from a set of sample motions.
Method	A family of motions can be populated from the input motion by systematically varying the position and orientation of one or more ground stages and then performing a sequence of similar optimization.
Method	We provide a user interface for the three most useful types of motion families(see Figure 3 ).
Method	The first type varies the translation of a ground stage along a line, the second type varies the translation of the ground stage along a 2 dimensional grid, and the third type varies both the translation and orientation of the ground stage along a semi-circle such that the orientation of the character is consistently aligned along the normal vector of the arc.
Method	The size of the sample space as well as the density at which it is sampled can both be adjusted as necessary.
Method	Other types of motion families can be easily added.
Method	Once a motion family is populated, we are able to generate arbitrary intermediary motions by blending the nearest 2 n samples, where n is the number of dimensions in the parameterized space.
Method	We chose to use a simple linear blending method for several reasons.
Method	First and foremost, the algorithm is very fast and well suited to any application where the output motion must be generated “on the fly”.
Method	Since motion families are produced offline, they can be as densely populated as necessary to increase the accuracy of the interpolation.
Method	Second, since the members of a motion family are produced by the same optimization setup, varying only in specific dimensions (e.g. landing positions, height, orientation, etc), it is often the case that they blend very well and need not be sampled very densely at all.
Result	In our results section, 9 samples is the most we ever required to adequately sample the dynamic space of a motion.
Method	Although foot glide is among the most troublesome artifacts for most motion blending techniques, we find that it is imperceptible for both the line and grid motion families.
Method	However, when the global orientation and the translation of the motion are interpolated simultaneously, as is the case in the circle motion family, a very miniscule amount of foot glide becomes perceptible.
Method	A simple fix is to apply a per-frame inverse kinematic (IK) solver to slightly adjust the lower body to satisfy the positional constraints on each foot.
Method	Solving IK on the lower body not only has the effect of planting the foot firmly on the ground without changing the overall looks of the motion, but is also light-weight enough to converge in real-time, as the motion is being displayed.
Background	In many applications the most important aspect to control is the position and time at which the character makes contact with an object in the environment.
Method	Consider the example of a soccer header motion, where it is required that the character’s head always makes contact with the soccer ball at the correct moment in time.
Method	Starting from a single input motion we can generate an arbitrary header by creating a grid motion family that varies the translation of the landing stage.
Method	The joint configuration at each time-step in the output motion is then defined as a vector function q(x, y,t) of the landing position, (x, y), and the time-step, t.
Method	If we denote the position of the character’s head by the function h(q), the problem of finding the motion that constrains the characters head to ball position p c at time t c , is reduced to that of finding values (x, y) such that p c = h(q(x, y,t c )).
Method	This is, in turn, analogous to minimizing the energy function E(x, y) = (p c − h(q(x, y,t c ))) 2 , which can be solved efficiently by a simple gradient descent method.
Method	The gradients are computed using finite differences.
Method	One caveat is that q is actually a piecewise function that performs a bi-linear interpolation of the 4 nearest sample motions.
Method	When one sample motion is replaced by another in the set of 4, q ceases to be C 1 continuous, causing convergence problems with the gradient descent method.
Method	A simple solution is to replace the linear blending functions f (x) = x and g(x) = (x − 1) with smooth in/out functions such as f (x) = sin 2 (x) and g(x) = cos 2 (x), thereby maintaining C 1 continuity through the transitions.
Result	One advantage of our motion generation algorithm is that it provides for a wide range of physically plausible animations in real-time.
Method	To demonstrate the full benefit of this approach, we have created a video game interface where the user controls the trajectory of a jumping character with a multi-directional control pad (see Figure 6 ).
Method	We start with a motion capture sequence of a character making two consecutive jumps.
Method	The interesting aspect of this motion is that the character must exhibit foresight in the motion of the first jump, so that the correct contact forces can be generate in the intermediate ground stage, to create the necessary momentum for the second jump.
Method	Our approach inherits the same key benefit from spacetime, but allow us generate motions in realtime.
Method	In this demonstration we wish to control the horizontal translation vectors of the first and second jumps, d 1 and d 2 , respectively.
Method	First we generate a motion family by varying both the first and last ground stages along a 3x3 grid.
Method	The entire motion family then consists of 81 optimal motions resulting from permuting the 9 possible starting positions with 9 possible ending positions.
Method	This is necessary in order to sample the entire range of possible ground stage transitions between the two jumps.
Method	We are then able to populate the space between sampled motions by linearly interpolating the nearest neighbor optimal solutions.
Method	In this case, we have 4 dimensions in our sample space corresponding to the values of d 1 and d 2 , making for a total of 2 4 (or 16) nearest neighbor motions.
Method	Therefore, we can express the output motion as vector function q(d 1 , d 2 ), whenever d 1 and d 2 are within the bounds of the sample space.
Method	To make our demonstration even more interesting, we chain our jumping motion end to end, such that it continuously loops upon itself.
Method	This is done by blending the second flight stage of the first motion, q a (d a1 , d a2 ), into the first flight stage of the second motion,q b (d b1 , d b2 ).
Method	In order to make the blending work, we simply require that d a2 = d b1 .
Method	In order words, we require the length and direction of the blended jumps be the same.
Result	The end result is an interactive jumping simulation where the user controls the direction that the character jumps and then sees the motion carried out in a physically plausible manner.
Method	Due to the foresight discussed earlier, the character must always have prior knowledge of the next two directions it will jump.
Result	This causes some lag time between when the user specifies a direction and when that motion will occur, but this is only natural given the deterministic nature of the ballistic motion.
Method	The motion sequences in our demonstration were captured at 120 frames per second using an optical motion capture system.
Method	The character is composed of 18 rigid links and 43 degrees of freedom.
Method	S0(3) rotations are expressed in exponential map representation.
Method	The mass distribution of the model is an appropriately scaled version of the population average as obtained from [dL96].
Method	We used SNOPT [GSM96], a nonlinearly-constrained optimization package, for solving spacetime optimization, as well as for pre-fitting the momentum curves.
Method	Most edits shown in the accompanying video clips were done in less than 1 minute.
Result	The optimization process for each motion took on the order of 2 to 4 minutes to fully converge on a 2Ghz Pentium 4 machine (see Table 1 ).
Result	Our system provides a set of UI tools to help the user rapidly specify modifications to existing motions.
Method	In a hopping example, the animator interactively manipulates the position, height, and orientation of each ground stage.
Method	The character must cover a longer distance, reach a greater height and assume a new orientation in the modified hopping motion, so she must lower her center of mass, lean farther to the right, and pivot slightly in preparation for the take-off.
Result	Despite these changes, the resultant motion remains stylistically similar to the original.
Method	To show that our system is capable of making drastic changes from the original motion, we edited the same hopping motion to exhibit a 360 ◦ spin followed by a 180 ◦ spin in the opposite direction(see Figure 5 ).
Method	In order to demonstrate real-time motion interpolation we modified a motion with two consecutive leaps.
Method	We let the user control the landing and take-off positions along an evenly spaced grid to generate a set of parameterized motions.
Method	Since the interpolation can be performed in real-time, we are able to generate a jumping motion with arbitrary takeoff and landing positions within the parameterized space in an interactive fashion.
Method	Another example shows a soccer header motion observed to miss its target.
Method	First, we correct the motion by increasing the height of the jump to meet the ball at the point of contact.
Method	Next, we use our editing algorithm to generate a motion family parameterized over the space of the landing position of the motion.
Method	By interpolating between the optimal motions, we are able to generate arbitrary intermediary motions where the character contacts the ball at any location within the sampled space, in real-time.
Method	A more intuitive way to edit motion capture data with arbitrary positional constraints is to use our real-time inverse control mechanism.
Method	In the volleyball slam example, the user interactively specifies the position of the character’s hand in mid-flight.
Result	Our system immediately determined the correct linear interpolation of 4 nearest neighbor samples to meet the positional constraint on the hand.
Result	The brightness of the sample motions on the floor indicates the weights associated with each sample.
Method	We used 9 sampled motions which are all edits of the same input sequence.
Result	The demonstration shows various slam motions being generated in real-time by using the trajectory of the volleyball to guide the character’s motion.
Result	Our system can also be used to create a class of nonrealistic motions that allow the character to exhibit superhuman strength and to defy the laws of physics.
Method	Consider an example where we wish to edit a jumping motion to reach a higher mid-point in the same time span as the the original motion.
Method	The first observation to make is that this is physically impossible without altering the gravitational constant, which dictates the maximum rate at which the character returns to the ground from the height of the jump.
Method	In our system it is easy to alter the gravitational constant in one or more ground stages.
Method	Still, the character must gain the momentum required to achieve the specified height on takeoff and, subsequently, absorb the same amount of momentum on landing.
Method	This requires a super-human muscle strength, but since we do not directly model muscle forces, and we place no limits on their magnitude, our system can easily handle these imaginary circumstances.
Background	From the animators perspective, editing non-realistic motion is the same as editing any other motion.
Method	To increase the height of a flight stage, the animator simply manipulates a visualization of the trajectory of the motion in the flight stage to the required height, and then specifies whether the system should change gravity or, alternatively, the total time in the flight stage.
Method	If the animator chooses to leave the gravity unaltered, the system increases the length of the time-step in each frame of the flight stage and then continues the editing process as normal.
Result	In one example, we edited a forward jump into a 2-meter-long backward jump (see Figure 7 ).
Method	This work builds on the research in both physics-based motion synthesis and interpolation-based motion editing approaches.
Result	In this paper we suggest that using physics-based adaptation to create motion samples for the purpose of data interpolation is perhaps a "sweetspot" between these two approaches.
Result	Once the dataset is created, this paradigm allows animators to interactively edit the realistic dynamic motion.
Result	The primary contribution of this work is a new momentum-based method for adaptation of ballistic character movement.
Result	In contrast to previous dynamic-based adaptation methods, our framework can produce an wide range of motions that are significantly different from the original motion.
Result	Our method does not require model reduction, or a reduced motion space.
Result	Because we do not solve for the generalized forces for each joint angle, our method is also significantly faster than other physics-based transformation methods.
Result	This speed allows us to create a large number of motions within a reasonable time.
Result	Once the family of parameterized motion samples has been generated, we describe an interactive framework where the animator can explore the space of realistic motions.
Result	We also show how the same framework can be adapted for inverse control.
Result	Finally, we show how real-time data-driven controllers for realistic human motion can be constructed from a single motion capture sequence.
Result	Naturally, our framework does not handle all realistic character motions.
Result	It specifically applies to highly-dynamic motions with ballistic stages.
Result	We suspect that momentumbased approach would not be well suited for less energetic motions such as walking.
Result	Furthermore, the number of samples required is exponentially proportional to the number of dimensions, thus the current framework is hindered by the offline computation of a large dataset.
Result	There are several ways to facilitate the computation by taking advantage of the fact that we are solving a sequence of very similar problems.
Future Work	A more intelligent sampling strategy is essential for generalizing our approach to a multi-dimensional dynamic space.
Result	Because our model does not account for realistic muscle strength, and friction during ground contact there are some extreme cases which do not produce realistic motion.
Future Work	Adding heuristics such as balance during contact can to a large extent eliminate these problems.

Problem	In this paper, we present a technique for generating animation from a variety of user-defined constraints.
Method	We pose constraint-based motion synthesis as a maximum a posterior (MAP) problem and develop an optimization framework that generates natural motion satisfying user constraints.
Method	The system automatically learns a statistical dynamic model from motion capture data and then enforces it as a motion prior.
Result	This motion prior, together with user-defined constraints, comprises a trajectory optimization problem.
Result	Solving this problem in the low-dimensional space yields optimal natural motion that achieves the goals specified by the user.
Result	We demonstrate the effectiveness of this approach by generating whole-body and facial motion from a variety of spatial-temporal constraints.
Problem	Our objective in this paper is to design an animation system that allows users to easily create natural-looking character animation by specifying spatial-temporal constraints throughout the motion.
Problem	For      example, a naive user might use a performance animation system to control the trajectories of the end-positions of the limbs of a character.
Problem	A more skilled user might specify a small set of poses at key time instants.
Problem	The system then automatically finds a motion that best satisfies those constraints.
Problem	An ideal motion synthesis system should allow users to specify a variety of constraints either at isolated points or across the entire motion in order to accommodate users with different skill levels.
Background	One appealing solution to this problem is physically based optimization [Witkin and Kass 1988], which allows the user to specify various constraints throughout the motion and relies on optimization to compute the physically valid motion that best satisfies these constraints.
Problem	Unfortunately, correct physics does not ensure that the motion will appear natural for characters with many degrees of freedom.
Method	Like physically based optimization, we formulate the problem as a trajectory optimization and consider the entire motion simultaneously.
Method	Instead of using the physical laws to generate physically correct animation, we rely on statistical models of human motion to generate a statistically plausible motion.
Method	Our approach allows the user to generate a wide range of human body and facial animation by specifying spatial-temporal constraints throughout the motion.
Method	The system automatically learns a statistical dynamic model from motion capture data and then enforces this model as a motion prior.
Method	The statistical dynamic model plays a role similar to that played by the dynamics in physically based optimization because it constrains the motion to only part of the space of possible human motions.
Method	The statistical dynamic model, however, is usually lower dimensional than the dynamics model, making the optimization more efficient, less likely to be subject to local minima, and more likely to produce natural motion.
Result	We demonstrate the effectiveness of this approach in two domains: human body animation and facial animation.
Result	We show that the system can generate natural-looking animation from key-frame constraints, key-trajectory constraints, and a combination of these two constraints.
Method	For example, the user can generate a walking animation from a small set of key frames and foot contact constraints ( figure 1 top).
Method	The user can also specify a small set of key trajectories for the root, hands and feet positions to generate a realistic jumping motion ( figure 1 bottom).
Method	The user can fine tune the animation by incrementally modifying the constraints.
Method	For example, the user can create a slightly different jumping motion by adjusting the positions of both hands at the top of the jump.
Result	The system can generate motions for a character whose skeletal model is markedly different from those of the subjects in the database.
Result	We also show that the system can use a statistical dynamic model learned from a normal walking sequence to create new motion such as walking on a slope.
Result	The quality of the final animation produced by our system depends on the motion priors derived from the motion capture database and the number of user-defined constraints.
Method	We, therefore, evaluate how the database influences the final motion and how increasing or decreasing the number of user-defined constraints influences the final animation.
Method	We also compare alternative techniques for generating animation from user-defined constraints such as linear interpolation, trajectory-based inverse kinematics, and inverse kinematics in a PCA subspace.
Problem	In this paper, we construct statistical models from motion capture data and then combine these models with trajectory optimization to generate a motion that satisfies user-defined constraints.
Background	Consequently, we discuss related work in constraint-based trajectory optimization and data-driven animation with an emphasis on statistical models.
Background	Trajectory optimization methods, which were first introduced to the graphics community by Witkin and Kass [1988], provide a powerful framework for generating character animation from user-specified constraints, physics constraints, and an objective function that measures the performance of a generated motion.
Problem	Extending this approach to generate natural motion for a full human character has proved to be hard because the system is high dimensional, the physics constraints make it highly nonlinear, and defining an objective function that reliably measures the naturalness of human motion is difficult.
Background	Much of the difficulty in solving this problem appears to result from the physics constraints because optimization without physics is effective for editing [Gleicher 1998].
Background	Therefore, one way to make the problem tractable is to simplify the governing physical laws.
Background	Both Liu and Popović [2002] and Abe and his colleagues [2004] showed that many dynamic effects can be preserved by enforcing patterns of linear and angular momentum during the motion.
Background	Reformulating the dynamics to avoid directly computing the torques also provides a significant performance improvement [Fang and Pollard 2003].
Background	Reducing the number of degrees of freedom to be optimized can also create tractable problems.
Background	For example, Popović and Witkin [1999] showed that significant changes to motion capture data can be made by manually reducing the degrees of freedom to those most important for the task.
Background	Safonova and her colleagues [2004] demonstrated that an efficient optimization can be achieved in a behavior-specific, low-dimensional space without simplifying the dynamics.
Background	More recently, Liu and her colleagues [2005] introduced a novel optimization framework— Nonlinear Inverse Optimization—for optimizing appropriate parameters of the objective function from a small set of motion examples and then used the estimated parameters to synthesize a new locomotion.
Method	Our work also uses a trajectory optimization framework but replaces the physical dynamic model with a statistical dynamic model computed from a motion capture database.
Method	Our approach is also part of an alternative set of techniques that relies on motion data to constrain the search to natural looking motions.
Background	For example, motion graphs can be used to resequence whole-body or facial motions (see, for example, [Arikan and Forsyth 2002; Kovar et al. 2002; Lee et al. 2002; Zhang et al. 2004].
Background	These systems cannot match poses or satisfy such kinematic constraints as end effector constraints unless the motion database happens to contain a motion that satisfies those constraints.
Background	Motion interpolation, on the other hand, does allow isolated constraints to be satisfied (for example, [Rose et al. 1998; Kovar and Gleicher 2004; Mukai and Kuriyama 2005]).
Background	However, interpolation across a complete behavior does not have enough degrees of freedom to allow the specification of full pose constraints or end effector constraints across multiple frames.
Background	Recently, interpolation and motion graphs have been combined to obtain some of the advantages of each approach [Safonova and Hodgins 2007].
Background	Statistical models of human motion have also been used for motion synthesis.
Background	A number of researchers have used variants of Hidden Markov Models (HMMs) to statistically represent human motion: either full-body movements [Molina Tanco and Hilton 2000; Brand and Hertzmann 2000; Galata et al. 2001] or speechdriven facial expressions [Bregler et al. 1997; Brand 1999].
Background	HMMs learned from human motion data have been used to interpolate key frames [Molina Tanco and Hilton 2000; Galata et al. 2001], synthesize a new style of motion [Brand and Hertzmann 2000], and generate facial expressions from speech signals [Bregler et al. 1997; Brand 1999].
Background	Grzeszczuk and his colleagues[1998] developed a neural network approximation of dynamics based on simulated data and use it to animate dynamic models such as fish and lunar landers.
Background	Urtasun and her colleagues[2006] learned linear motion models from pre-aligned motion data via Principal Component Analysis (PCA) and used them to track 3D human body movements from video by performing nonlinear optimization over a small sliding temporal window.
Background	Switching linear dynamic system (SLDS) have also been used to model human motion.
Background	Pavlović and his colleagues [2000] present results for human motion synthesis, classification, and visual tracking using learned SLDS models.
Background	Li and his colleagues [2002] used SLDS to synthesize and edit disco dancing motion.
Method	Our approach is also to learn a statistical dynamic model from human motion capture data; however, the dynamic behavior of our model is controlled by a continuous control state rather than a discrete hidden state as in HMMs and SLDS.
Method	This property led us to formulate the motion synthesis problem as a trajectory optimization problem.
Method	More importantly, our system allows the user to specify a variety of spatial-temporal constraints such as end effector constraints throughout the motion, a capability that has not been demonstrated by previous approaches.
Background	A number of researchers have developed statistical models for human poses and used them to solve the inverse kinematics problem.
Background	Grochow and colleagues [2004] applied a global nonlinear dimensionality reduction technique, Gaussian Process Latent Variable Model, to human motion data and then used the learned statistical pose model to compute poses from a small set of user-defined constraints.
Background	Another solution for data-driven inverse kinematics is to interpolate a small set of preexisting examples using constraints.
Background	This idea has been used to compute human body poses [Rose et al. 2001] and facial expressions [Zhang et al. 2004] from kinematic constraints at a single frame.
Background	These models lack temporal information and therefore cannot be used to generate an animation from sparse constraints such as key frames.
Background	Local statistical models are sufficient if the user provides continuous control signals (the performance animation problem).
Background	Chai and colleagues [2003] presented a real-time vision-based performance animation system that transforms a small set of automatically tracked facial features into facial animation by interpolating examples in a database at run time.
Background	They also used a series of local statistical pose models constructed at run time to reconstruct full-body motion from continuous, low-dimensional control signals obtained from video cameras [Chai and Hodgins 2005].
Method	The statistical dynamic model used in this paper was motivated by the dynamic model used for video textures by Soatto and his colleagues [2001].
Background	They showed that a sequence of images of such moving scenes as sea-waves, smoke, and whirlwinds can be modeled by second-order linear dynamic systems.
Background	They applied the learned dynamic systems to synthesize an “infinite length” texture sequence by sampling noise from a known Gaussian distribution.
Method	We extend the model to learn an efficient and low-dimensional representation of human motion and use it to generate an animation that achieves the goal specified by the user.
Problem	The key idea behind our approach is that motion priors learned from prerecorded motion data can be used to create natural human motion that matches constraints specified by the user.
Method	The combination of the motion prior and the user’s constraints provides sufficient information to produce motion with a natural appearance.
Method	The human body motion capture database (about 15 minutes) includes data of locomotion (jumping, running, walking, and hopping) and interacting with the environment (standing up/sitting down, reaching/picking up/placing an object).
Method	The facial expression database (about 9 minutes) includes six basic facial expressions (happiness, surprise, disgust, fear, anger, sadness) and three facial movements related to everyday life (speaking, eating, and snoring).
Method	The motion was captured with a Vicon motion capture system of 12 MX-40 cameras [Vicon Systems 2004] with 41 markers for full-body movements and 92 markers for facial expressions.
Method	The motion was captured at 120Hz and then downsampled to 30Hz.
Method	In facial animation, y n is the 3D positions of all vertices on the face model.
Method	In human body animation, y n is the position and orientation of the root and the joint angles.
Method	We preprocess the motion capture data by applying Principal Component Analysis (PCA) [Bishop 1996] to the motion capture data and obtain a reduced subspace representation for y n :
Method	The matrix C is constructed from the eigenvectors corresponding to the largest eigenvalues of the covariance matrix of the data, and D is the mean of all example data, D = (Σ N n=1 y n )/N .
Method	The dimensionality of the system state, d x , can be automatically determined by choosing the d x for which the singular values drop below a threshold.
Method	The system first automatically learns a statistical dynamic model from motion capture data.
Method	This model is then used to compute the motion prior, − ln p(H).
Method	The user defines various forms of constraints, E, throughout the motion, which are then used to compute the likelihood term, − ln p(E|H).
Method	The constraints could be any kinematic constraints such as position, orientation, or the distance between two points on the character.
Method	They could be specified either at isolated points (key frames) or across the whole motion (key trajectories).
Method	The system uses trajectory optimization to automatically find an animation H ˆ that best satisfies the userspecified constraints while matching the statistical properties of the motion capture data: H ˆ = arg min H − ln p(E|H) − ln p(H).
Method	x n ∈ R d x and u n ∈ R d u are the system state and control input, and d u is the dimensionality of the control input u n .
Method	This formulation is similar to the linear time-invariant control system commonly adopted in the control community [Palm 1999].
Method	However, the matrix B is not unique because the control input u t is unknown.
Method	Therefore, any non-singular transformation of the matrix B represents the motion because BT and T −1 u n are also consistent with the dynamic model.
Method	To remove this ambiguity, we assume that the matrix B is an orthogonal matrix.
Method	However, we can perform singular value decomposition (SVD) on the data matrix Z such that Z = W SV T , and then get the best possible rank d u approximation of the data matrix, factoring it into two matrices: B ˆ = W and U ˆ = SV T , where B ˆ is a d x × d u matrix and U ˆ is a d u × (T − m) matrix.
Method	The dimensionality of the control input (d u ) can be automatically determined by choosing the d u for which the singular values drop below a threshold.
Method	Functionally, a statistical dynamic model is similar to a physical dynamic model.
Method	Therefore, the statistical dynamic model might achieve faster convergence and be less subject to local minima.
Method	The number of dimensions of the control input, d u , characterizes the complexity of our dynamic model.
Method	The walk data set is from multiple subjects and contains different styles.
Method	The facial expression data are from the same subject and contain a variety of facial expressions such as “happy” and “sad.
Method	” The average reconstruction error is the L 2 distance between the original test motion and the motion reconstructed from the linear time-invariant system and computed by cross-validation techniques.
Method	We observe that the reconstruction error of the statistical model decreases as both the order of dynamic system and the number of dimensions of the control input increases.
Method	If we choose d u as “zero” (simply dropping off the control term), our model becomes the linear dynamic model used by Soatto and colleagues [2001] and has the largest reconstruction error.
Method	If d u is equal to the number of dimensions of the system state d x , the model can be used to represent an arbitrary motion sequence with zero error.
Method	In practice, human motion is highly coordinated, and the dimensionality of the control input for accurate motion representation, d u , is often much lower than the dimensionality of the system state, d x .
Method	For the examples reported here, we set the dynamic order to three and the dimensionality of control input to four for human body animation (the reconstruction error is about 0.7 degrees/joint per frame); we set the dynamic order to two and the dimensionality of control input to one for facial movement (the reconstruction error is about 0.1 mm/vertex per frame).
Method	Finally, we discuss how to optimize motion by combining both terms: H ˆ = arg min H − ln p(E|H) − ln p(H).
Method	Like physically based optimization [Witkin and Kass 1988], we represent the system state x t and the control signal u t independently.
Method	For facial animation, the user can specify the positions or orientations of any points on the face, or the distance between any two points.
Method	For whole-body animation, the user can specify the positions or orientations of any points on the body, or joint angle values for any joints.
Method	Rather than requiring that constraints be specified in 3D, it is often more intuitive to specify where the projection of a point on the character should be located.
Method	Therefore, the system also allows the user to specify the 2D projections of any 3D point on a user-defined screen space.
Method	This approach could be used for rotoscoping a video, or for a single camera performance animation.
Method	The system allows the user to sketch out the motion in greater or lesser detail.
Method	For example, a novice user might want to control the paths of specific joints or paths over a period of time using a performance animation system while a more skilled user might prefer using key frame constraints.
Method	Spatially, the constraints could provide either an exact configuration such as a full-body pose or a small subset of the joint angles or end-positions.
Method	Temporally, the constraints could be instantaneous constraints for a particular frame, multiple-frame constraints, or continuous constraints over a period of time.
Method	User-defined constraints can be linear or nonlinear.
Method	Linear constraints can be used to define joint angle constraints in human body animation and positions in facial animation.
Method	The most common nonlinear constraints in human body animation might be end effector constraints, for example, foot contact constraints.
Method	In facial animation, nonlinear constraints can be used to specify the distance between two points on the face or 2D projections of 3D facial points.
Method	The likelihood term evaluates how well the synthesized motion matches the constraints specified by the user.
Method	A good match between the motion and the user-defined constraints results in a low energy solution.
Method	Many motions might satisfy the user-defined constraints.
Method	For example, when the user specifies a small set of key frames or key trajectories, the number of constraints is not sufficient to completely determine the whole motion sequence, x 1:T .
Method	To remove ambiguities, we would like to constrain the generated motion to lie in the space of natural human motions by imposing a prior on the generated motion:
Method	Based on the statistical dynamic equation (Equation 4), the current system state x t only depends on the previous system states x t−m:t−1 and the current control input u t .
Method	We have the corresponding energy term E prior dynamic = − ln T t=m+1 p(x t |x t−1:t−m , u t ) ∼ −α T t=m+1 x t − i=1 m A i x t−i − Bu t 2 (12) where α is a tuning parameter.
Method	Conceptually, the dynamic prior can be thought as dimensionality reduction of the motion in a spatialtemporal domain.
Method	It significantly reduces the dimensionality of the motion from the space of x 1:T to the space of the initial state x 1:m and the control input u m+1:T .
Method	The second term on the right side of Equation 11 computes the prior for the initial state, x 1:m , and control input, u m+1:T .
Method	We assume that both the initial state, x 1:m , and the control input, u t , are independent and identically distributed.
Method	The energy term for the second term on the right side of Equation 11 can be simplified as follows:
Method	We model the control input (u t ) as a mixture with K component Gaussian densities [Bishop 1996]:
Method	The function N(u t ; φ j , Λ j ) denotes the multivariate normal density function with mean φ j and covariance matrix Λ j .
Method	The parameters of the Gaussian mixture models (π k , φ k , Λ k ) are automatically estimated using an Expectation-Maximization (EM) algorithm [Bishop 1996].
Method	Note that we choose weak priors (static models) to model the priors for both initial states and control inputs so as not to restrict the type of motions the algorithm can generate.
Method	After combining the user-defined constraints and the motion prior, the constraint-based motion synthesis problem becomes the following unconstrained motion optimization problem:
Method	We follow a standard approach of representing x t and u t using cubic B-splines.
Method	We solve the optimization problem using sequential quadratic programming (SQP) [Bazaraa et al. 1993], where each iteration solves a quadratic programming subproblem.
Method	The Jacobian matrix and the Hessian matrix of the energy function are symbolically evaluated at each iteration.
Method	We choose all initial values using random values between 0 and 1 except that a linear interpolation of the user-specified keyframe constraints is used for initialization.
Method	We found that the optimization procedure always converges quickly (usually less than 100 iterations and less than 30 seconds).
Method	Typically, the objective function values decrease rapidly in the early iterations and then level off as they approach the optimal value.
Method	Our optimization framework can also be applied to the problem of generating human body motions for a character whose skeletal model is markedly different from the subjects in the database.
Method	User-defined constraints for motion retargeting can either be directly computed from the source motion or specified by the user.
Method	In our experiment, we extract foot positions from a source walking motion and then use it to generate a walking sequence for a new character.
Method	We also add one term in the objective function that measures the difference between the source motion and retargeted motion:
Method	We test our system by generating both human body animation and facial animation from various forms of user-defined constraints.
Method	We also evaluate the performance of our algorithm in terms of the motion priors and user-defined constraints.
Method	We learn the statistical model for each individual behavior and use it to generate individual behavior based on user-defined constraints.
Method	Two kinds of constraints were used to generate most of the examples in this paper: key-frame constraints and key-trajectory constraints.
Method	We can also combine these two constraints.
Method	For example, a jumping motion can be created by specifying a start pose and the positions of both feet and root throughout the motion.
Result	The accompanying video demonstrates the effectiveness of our system for generating a number of individual behaviors, including walking, running, and jumping.
Result	Our behavior-specific statistical motion model is capable of generating a rich variety of actions.
Result	For example, we can use a small set of key frames and foot contacts to generate normal walking, climbing over an obstacle, a baby walking, and mickey-mouse style walking.
Result	Our system can also synthesize motion that transitions from one behavior to another by using the statistical model learned from transition data.
Result	In the accompanying video, we demonstrate that the user can generate a transition from walking to jumping, from walking to sitting down, and from walking to picking up an object (figure 6).
Result	The accompanying video also shows that the system can generate motions for characters with skeletal dimensions different from those in the database.
Result	We also show that we can use motion priors learned from a small sequence of a normal walking motion (about 100 frames) to create walking on a slope and walking with small steps.
Method	The user can refine the animation by incrementally modifying the constraints.
Method	For example, the user can create a slightly different jumping motion by adjusting the positions of both hands at the top of the jump.
Method	The system learns a single statistical model from the whole facial motion capture database and then uses it to create facial animation with a variety of spatial-temporal constraints.
Method	The user can generate realistic facial animation by combining sparse keyframe constraints (three key frames) and sparse trajectory constraints (one trajectory).
Method	The user selects six points on the face and specifies the 2D projections on the screen space at three key instants.
Method	This type of constraint could be extracted by rotoscoping.
Method	The user can achieve detailed control over facial movement by specifying the trajectories of a small set of 3D facial points.
Method	The user can also use trajectories of a small set of high-level facial features (the mouth width and height and the openness of the eyes) to generate facial animation.
Method	The quality of the final animation depends on the motion priors and the user-defined constraints.
Method	We, therefore, have designed a number of experiments to evaluate the performance of our algorithm: The importance of the motion priors.
Method	We evaluate the importance of motion priors by comparing our method against alternative constraint-based motion synthesis methods.
Method	The first method is a simple linear interpolation of key frames.
Method	The second method is trajectory-based inverse kinematics that minimizes the velocity changes of the motion in the original configuration space, y t , without any priors.
Method	The third method is a simple data-driven inverse kinematics algorithm that minimizes the velocity changes of the motion in a reduced PCA space, x t .
Method	We compare the methods using key-frame constraints and key-trajectory constraints.
Method	We keep the constraints constant and use a cubic spline to represent the motion.
Result	Without the use of the statistical dynamic model, the system can not generate natural motions unless the user specifies a very detailed set of constraints across the entire motion.
Method	We evaluate how the database influences the final motion by keeping the user-defined constraints constant.
Method	We have experimented with both key-frame and key-trajectory constraints.
Method	For key-frame constraints, the user defined a sparse set of walking constraints and used them to generate walking motion from the priors learned from a number of different databases.
Method	We compare the results for a database of general locomotion, running, hopping, jumping and walking.
Result	The accompanying video shows that we can generate a good walking motion with a walking database.
Result	The quality of the animation becomes worse when we use a large and general locomotion database to generate walking.
Result	As would be expected, the system fails to generate a good walking motion if the motion prior is learned from running, hopping, or jumping data.
Result	We have tested the creation of jumping motion from key-trajectory jumping constraints when the prior is learned from a database of jumping, general locomotion, or walking.
Result	Similarly, the prior from a walking database fails to generate a good jumping motion because of the mismatch between the prior and the user-defined constraints.
Method	With an appropriate database, we compare the quality of motions generated by different numbers of constraints.
Method	More specifically, we take one motion sequence out of the database and use it as a testing sequence.
Method	We then compare the animations created by key frames that are spaced increasingly far apart in time.
Method	We also compare the results by decreasing the number of key trajectories.
Result	The accompanying video shows that results become worse when we decrease the number of the userdefined constraints.
Result	For example, the numerical error increases steadily (0.94, 1.06, 1.81 degrees per joint per frame) when the number of constraints is decreased (6, 4, 2 key frames).
Result	We observe a noticeable foot sliding artifact on one foot when two key trajectories (root and one foot) are used to create a walking motion.
Result	We have presented an approach for generating both full-body movement and facial expression from spatial-temporal constraints while matching the statistical properties of a database of captured motion.
Method	The system automatically learns a low-dimensional linear dynamic model from motion capture data and then enforces this as spatial-temporal priors to generate the motion.
Method	The statistical dynamic equations, together with an automatically derived objective function and user-defined constraints, comprise a trajectory optimization problem.
Method	Solving this optimization problem in the lowdimensional space yields optimal, natural motion that achieves the goals specified by the user.
Result	The system achieves a degree of generality beyond the motion capture data.
Result	For example, we have generated a motion using constraints that cannot be satisfied directly by any motion in the database and found that the quality of the reconstructed motion was acceptable.
Result	Our video also demonstrates that the system can generate motion for characters whose skeletal models differ significantly from those in the database.
Future Work	However, we have not yet attempted to assess how far the user’s constraints can stray from the motions in the database before the quality of the resulting animation declines to an unacceptable level.
Result	This statistically based optimization approach complements a physically based optimization approach and offers a few potential advantages.
Result	First, using a low-dimensional statistical dynamic model for the constrained optimization might achieve faster convergence and be less subject to local minima.
Result	Second, our approach can generate slow and even stylized motions that have proven particularly difficult for physically based optimization.
Result	Third, the optimization does not require physical models.
Result	Building anatomically accurate physical models for facial animation or whole-body motion remains challenging.
Result	There are two limitations of our approach: an appropriate database must be available and the user cannot specify such dynamic constraints as ground reaction forces or character mass.
Problem	The main focus of this paper has been an exploration of the use of prior knowledge in motion capture data to generate natural motion that best satisfies user-defined constraints.
Problem	Another important issue for building any interactive animation system is to design an intuitive interface to specify the desired motion.
Method	In our experiments, most of keyframe constraints were modified from example poses in the database.
Method	Foot contact constraints were specified by the user directly.
Method	Key trajectory constraints were extracted from a performance interface using two video cameras [Chai and Hodgins 2005].
Method	Alternatively, the user could rely on commercial animation software such as Maya to specify constraints.
Result	This process is timeconsuming even for a professional artist; it is more difficult for a naive user to specify such constraints.
Future Work	One of immediate directions for future work is, therefore, to design intuitive interfaces that allow the user to specify spatial-temporal constraints quickly and easily.

Problem	We present a technique for automatically synthesizing walking and running controllers for physically-simulated 3D humanoid characters.
Method	The sagittal hip, knee, and ankle degrees-of-freedom are actuated using a set of eight Hill-type musculotendon models in each leg, with biologically-motivated control laws.
Method	The parameters of these control laws are set by an optimization procedure that satisfies a number of locomotion task terms while minimizing a biological model of metabolic energy expenditure.
Result	We show that the use of biologically-based actuators and objectives measurably increases the realism of gaits generated by locomotion controllers that operate without the use of motion capture data, and that metabolic energy expenditure provides a simple and unifying measurement of effort that can be used for both walking and running control optimization.
Background	The development of physics-based locomotion controllers de novo, independent from stock motion data, has been a long-standing objective in computer graphics research and has seen resurgence in recent years.
Problem	Despite impressive progress, the gaits produced by existing controllers fall short of the natural appearance of human locomotion.
Problem	For example, physics-based walking controllers that do not rely on motion capture data commonly produce walking motion with exaggerated hip flexion which appears more crouched and less fluid than typical human walking.
Problem	One likely cause of these differences is the control force generation mechanism.
Background	Biological control systems output neural excitation signals, which then generate musculotendon forces that lead to joint torques.
Problem	The mapping from excitation to torque is highly complex due to variable moment arms, biarticular muscles, and the dependence of musculotendon forces on fiber length and contraction velocity [Zajac 1989].
Background	On the other hand, state-of-the-art bipedal locomotion control methods directly output joint torques, which ignore constraints and energetic costs imposed by muscle anatomy and physiology.
Problem	Consequently, to accomplish a motion task, controllers often employ torque patterns that are inefficient or even impossible for humans.
Problem	These biologically implausible torque patterns diminish the naturalness of the resulting gaits.
Problem	The goal of our work is to enhance the realism of locomotion gaits exhibited by physically-simulated humanoids without dependence on motion capture data.
Method	To this end, we augment the jointactuated humanoid model with a set of Hill-type musculotendon units (MTUs).
Method	These musculotendon units generate torques for the most important degrees-of-freedom (DOFs) during locomotion— the sagittal plane hip, knee, and ankle DOFs.
Method	To actuate these muscles, we define biologically-motivated control functions that map the current state of the body (joint angles, muscle fiber lengths, etc.) to excitation signals.
Method	The parameters of these functions are optimized to yield gaits that move the character forward without falling down.
Problem	While many sets of parameters are capable of achieving this task, the quality of the resulting motion varies significantly among them.
Method	To produce gaits that have a high degree of realism, we employ an objective based on minimization of metabolic energy expenditure, thus choosing the most effortless gait that achieves the task [Alexander 2003].
Background	In living humans and animals, metabolic energy expenditure can be estimated by oxygen consumption.
Problem	In contrast, it is less clear how metabolic energy expenditure should be modeled for simulated characters.
Background	A common substitute is the sum of squared joint torques [Schultz and Mombaur 2010], which does not account for the different effort levels required to generate torques in different joints, directions, and body configurations.
Background	More nuanced objectives can be learned from inverse optimization [Liu et al. 2005], but are dependent on training data.
Background	Our use of biologically-based actuators enables the estimation of metabolic energy expenditure based on the internal state of the MTUs [Anderson 1999].
Result	The result is a locomotion control optimization procedure that minimizes a physiologically-based objective within a parameter space restricted to biologically plausible torque patterns.
Method	We demonstrate the presented approach by optimizing locomotion controllers for a wide range of speeds.
Method	For quantitative evaluation, we collected experimental ground truth data from 20 human subjects walking and running at eight speeds on an instrumented treadmill.
Method	Much like human locomotion, our controllers utilize significant ankle torque and generate smooth torque trajectories.
Result	The resulting gaits match human ground truth to a greater extent than state-of-the-art walking controllers that do not rely on motion capture data.
Result	Furthermore, we show that by simply changing the initialization and target velocity, the same optimization procedure leads to running controllers.
Background	Animation researchers have been interested in the control of locomotion for 3D humanoid characters for almost 20 years [Hodgins et al. 1995; Laszlo et al. 1996; Faloutsos et al. 2001].
Background	One important recent contribution is SIMBICON [Yin et al. 2007], a remarkably robust 3D humanoid locomotion controller based on the balance control of Raibert and Hodgins [1991].
Background	A num- ber of projects have since focused on expanding the controller repertoire for simulated bipeds [Jain et al. 2009; Coros et al. 2010; de Lasa et al. 2010] and on locomotion in complex environments [Mordatch et al. 2010; Wu and Popović 2010].
Background	At the same time, efforts have been made to make the synthesized motions more human-like, or “natural.
Background	” As discussed by Wang et al. [2009], the original SIMBICON-style controllers tend to produce gaits lacking hip extension with a constant foot orientation.
Background	Knee angles lack flexion during swing, but lack extension at heelstrike.
Background	More recent controllers improve motions by designing better target trajectories in joint or feature space [Coros et al. 2009; Coros et al. 2010; de Lasa et al. 2010].
Background	While more human-like ankle motions have been produced, differences in the hip and knee angles persist ( Figure 6a ).
Problem	Perhaps more importantly, controllers relying on hand-tuned trajectories cannot be easily used to investigate how the control strategies change with respect to new constraints.
Problem	For example, how would the character’s motion style change given a physical disability?
Problem	Can we synthesize appropriate gaits for older or younger characters?
Background	Impressive results have also been achieved by controllers based on tracking motion capture data [da Silva et al. 2008; Muico et al. 2009; Kwon and Hodgins 2010; Lee et al. 2010; Ye and Liu 2010].
Problem	However, as with methods that tune joint trajectories or controller parameters by hand, motion capture driven controllers have a limited ability to predict changes in gait.
Background	Alternatively, de novo controller optimization has been used to capture features of human walking [Wang et al. 2009; Wang et al. 2010].
Background	While these methods were shown to produce gaits for a variety of characters and environmental conditions, they do not employ realistic effort measures or biologicallyplausible control torques.
Background	The resulting torque patterns are highly unnatural ( Figure 6b ), leading to artifacts such as excessive plantarflexion and sharp changes in kinematics ( Figure 6a ).
Method	In contrast, our approach is to actuate key DOFs using Hill-type MTUs and to measure effort based on metabolic energy expenditure.
Result	We demonstrate significantly more human-like kinematic and torque trajectories and show that the same control parameterization and effort objective produce both walking and running.
Background	While locomotion controllers discussed above all operate on joint-actuated models, musculoskeletal models have also been investigated in computer graphics.
Background	Such models have been used in facial animation [Waters 1987; Lee et al. 1995; Sifakis et al. 2005], simulation of the human hand [Sueda et al. 2008], neck [Lee and Terzopoulos 2006], torso [Zordan et al. 2006], and the complete upper body [Lee et al. 2009].
Background	Hase et al. [2003] optimize a CPG-based (central pattern generator) locomotion controller [Taga 1995] for 3D musculoskeletal models without tendon or activation dynamics, but their results were not compared to human kinematic and dynamic gait patterns.
Background	Moreover, full musculoskeletal models are significantly more difficult to construct than joint-actuated models.
Result	Our work demonstrates that measurable increase in locomotion realism can be produced by employing musculotendon actuators for a small subset of the body DOFs.
Background	In the biomechanics literature, abstract planar models have been used to study high-level principles of human locomotion.
Background	For example, energy minimization has been suggested as the criterion for humans in determining step length given walking speed [Kuo 2001], as well as in selecting between walking and running [Srinivasan and Ruina 2006].
Background	The spring-loaded inverted pendulum (SLIP) model [Blickhan 1989] has been used as a basis for predicting center-of-mass (COM) movements of human runners [Full and Koditschek 1999].
Background	However, in the absence of knee joints, these models cannot be used to simulate accurate gait pat- terns.
Background	Using a 2D model with knees and musculotendon actuators, Geyer and Herr [2010] showed that patterns of human walking can be generated by a set of simple control laws motivated by muscle reflexes, which inspired our work.
Result	We show how their basic ideas can be embedded in a 3D humanoid model and extended to running.
Background	Similar 2D models have been used for gait prediction [Ackermann and van den Bogert 2010], and to generate human-like responses to disturbances [Murai and Yamane 2011].
Background	Simulation studies on detailed 3D musculoskeletal models have been employed to understand muscle functions during locomotion tasks [Anderson and Pandy 2001; Liu et al. 2008; Hamner et al. 2010].
Background	In particular, Anderson and Pandy [2001] showed that human-like lower body motor patterns can be found by minimizing metabolic energy expenditure per distance travelled, and we adopt their proposed model of metabolic energy in our work.
Background	However, these biomechanical simulations only recovered muscle activation trajectories, and did not produce locomotion controllers that can function beyond the duration of input data.
Background	Finally, our work is complementary of the recent work of Jain and Liu [2011], who showed that simulating soft tissue deformation at contact sites could lead to more robust and realistic character motion.
Result	We demonstrate how musculotendon actuators, biologicallymotivated control laws, and a more realistic effort term can be used to produce more human-like locomotion gaits.
Method	Our 3D humanoid model has 30 joint DOFs and mass distributions approximating a 180 cm, 70 kg male [Wang et al. 2010].
Method	From the original model, we adjust the lower-body joint locations and mass distributions to better match human data [Hamner et al. 2010].
Method	We use cylinders to approximate the heel and ball of the foot, which allows for some amount of foot rolling after heel-strike.
Method	Unlike previous work, where the model is actuated by setting torques to all joints, we use a model that is partially actuated by Hill-type MTUs ( Figure 1 ).
Method	Specifically, control torques for the hip, knee, and ankle joint DOFs in the sagittal plane—key DOFs for gait analysis [Perry and Burnfield 2010]—are exclusively generated by eight MTUs in each leg.
Method	In addition, soft joint limit torques as defined by Geyer and Herr [2010] are applied to these DOFs.
Method	The hip joint is extended by the gluteal muscles (GLU) and flexed by the hip flexor muscles (HFL), while the knee joint is extended by the vasti (VAS).
Method	The tibialis anterior (TA) and the soleus (SOL) generate dorsiflexion and plantarflexion torques at the ankle, respectively.
Method	The biarticular MTUs ( Figure 1c ) supply torques to two joints simultaneously.
Method	We include the hamstring (HAM), which extends the hip and flexes the knee, the rectus femoris (RF), which flexes the hip and extends the knee, and the gastrocnemius (GAS), which flexes the knee and plantarflexes the ankle.
Method	The choice of muscles is based on the planar model proposed by Geyer and Herr [2010].
Method	We have added the rectus femoris since we found that it improves the walking knee flexion profile during swing when compared to human data.
Method	We employ a Hill-type model [Zajac 1989], where each MTU consists of three elements: contractile, parallel-elastic, and serialelastic.
Method	Conceptually, the contractile element (CE) models muscle fibers that can actively generate force (F CE ) depending on the current activation level (a).
Method	The parallel-elastic element (PE) models passive forces (F PE ) generated by the muscle fibers, while the serial-elastic element (SE) models the tendon.
Method	In particular, given the length and velocity of CE (l CE , v CE ), as well as the current muscle activation level (a), we can compute the MTU force (F MTU ) as follows: F MTU = F CE + F PE , F CE = aF 0 f l ( ̃ l CE )f v ( v CE ), where  ̃ l CE = l CE /l opt and v CE = v CE /l opt .
Method	F 0 and l opt are musclespecific maximum isometric force and optimal fiber length parameters.
Method	f l and f v are the force-length and force-velocity curves (Figure 3).
Method	The computation of F PE and the analytic forms of f l and f v are described in the supplemental material.
Method	Intuitively, f l models the fact that muscles can generate force more efficiently near l opt , and f v captures how the muscle loses its ability to generate force as the contraction velocity increases [Zajac 1989].
Method	As to be discussed in Section 4.1, the nonlinearity introduced by these relations is crucial for how simple control laws for muscle excitation can lead to complex force and torque trajectories.
Method	The controller outputs neural excitation signals (u), which are converted to muscle activations (a).
Method	The conversion does not occur instantaneously and is referred to as activation dynamics.
Method	The dynamics is modeled by a first-order differential equation [Zajac 1989; Geyer et al. 2003], which can be integrated by a t+1 = 100h(u t − a t ) + a t , where h is the stepsize (1/2400 s) and a t and u t are the muscle activation and excitation values at the t-th timestep.
Method	A step-response graph for the activation dynamics, as well as details on the l CE and v CE computations (contraction dynamics) are given in the supplemental material.
Method	The joint torques generated by a given MTU is a function of the current body configuration.
Method	A simple variable moment arm model is assumed for MTUs attached to the knee or ankle: τ = r j cos(θ − φ j M )F MTU , where θ is the current knee or ankle angle in the sagittal plane, and r j is the maximum MTU-joint moment arm, which occurs at the joint angle φ j M .
Method	MTUs attached to the hip are assumed to have a constant moment arm: τ = r j F MTU .
Method	The total lower extremity joint torques in the sagittal plane are obtained by summing over contributions from all relevant muscles:
Method	The main part of our control algorithm consists of functions that determine muscle excitation values for each of the lower body MTUs, which actuate the hip, knee, and ankle DOFs in the sagittal plane.
Method	For the upper body and the remaining DOFs in the lower body, we rely on a pose-graph controller [Yin et al. 2007].
Method	Our control laws for the actuators are based on the muscle-reflex controller introduced by Geyer and Herr [2010].
Method	Two different sets of control laws apply for each muscle, depending on whether the leg is in stance or swing phase (i.e., foot is on the ground or not).
Method	We further define a swing initiation state within the stance phase, and a stance preparation state within the swing phase, where control laws for a subset of MTUs are modified ( Figure 4 ).
Method	The control laws map time-delayed features of the body to muscle excitation signals.
Method	The time-delay (∆t) models the time for neural signal propagation, set to 5 ms for MTUs connected to the hip, 20 ms for MTUs connected to the ankle, 10 ms for the VAS and ground contact [Geyer and Herr 2010].
Method	Body features include MTU force, fiber length, joint angle, and segment orientation.
Method	Depending on the input feature, three different mappings are defined: positive force feedback, positive length feedback, and muscle-driven proportional derivative (PD) control.
Method	These mappings serve as building blocks for the control laws, and we discuss each in turn in this section.
Method	Given MTU m, the positive force feedback law is defined as u F m = G m F  ̃ m MTU (t − ∆t m ),          where F  ̃ m MTU (t − ∆t m ) is the MTU force normalized by F m 0 with a time-delay of ∆t m .
Method	The only free parameter is a positive gain constant G m , which is different for each MTU.
Method	Note that F  ̃ m MTU cannot increase indefinitely since the muscle’s force generation capacity depends nonlinearly on the length and contraction velocity of the muscle fiber.
Method	As F  ̃ m MTU starts to decrease due to muscle physiology, u F m starts to decrease as well.
Method	The force feedback is the main source of activation to the SOL, GAS, and VAS muscles during the stance phase.
Method	We can see that u GAS F produces a positive feedback during mid-stance, when the muscle activation does not produce a significant change in muscle fiber length, as the foot is planted on the ground.
Method	As the heel loses ground contact in late stance, the same muscle activation rapidly shortens the fiber length, which reduces force output and the activation through u F GAS .
Method	Positive length feedback is defined as          u m L = G m  ̃ l m CE (t − ∆t m ) − H m , + where  ̃ l m CE (t − ∆t m ) is the length of the muscle fiber normalized by the l m opt with a time-delay of ∆t m .
Method	G m and H m are free positive parameters and {} ± means only positive or negative values (0 otherwise).
Method	The positive length feedback effectively models a stretch reflex, which activates the muscle when the fiber is stretched beyond a fixed length.
Method	u L m is most useful during the swing phase, as the TA must be activated to dorsiflex so that toe-stubbing can be avoided.
Method	In addition, the HFL relies on length feedback to generate hip flexion torque during early swing, especially during running.
Method	We also define a muscle-driven PD control law with respect to an angular feature θ as where K m , D m , θ m are free parameters of the PD-controller.
Method	The braces sign is positive if torque generated by m is in the opposing direction of θ—e.g., if m is the hip extensor and θ is the hip flexion angle—and negative otherwise.
Method	Much like the standard torquebased PD-controller, the muscle-driven PD control aims to adjust θ towards the target angle θ m while damping its velocity.
Method	However, unlike the standard PD-controller, muscles can only activate after a time-delay and each muscle can only generate forces to rotate the angular DOF in one direction.
Method	The PD-control laws are employed by the hip muscles during the stance phase to maintain the global upper body orientation, as well as during stance preparation to prepare for ground contact.
Method	Each muscle has an initial constant excitation, or pre-stimulation value p m .
Method	These values are initialized close to zero, but are then optimized.
Method	The SOL and GAS both rely on positive force feedback and are the main sources of torque during walking.
Method	The TA ensures foot clearance during swing using a length feedback (u L TA ), but the activation is suppressed during stance in proportion to the current force generated from SOL.
Method	The suppression allows the generated TA activation patterns to better match human data during locomotion.
Method	The force feedback on the VAS creates a strong knee extension torque following ground contact, but excitation is suppressed when the knee flexion angle (θ k ) is extended below an offset (θ k off ) with an extension velocity ( θ  ̇ k < 0).
Method	The suppression prevents hyperextension of the knee during mid-stance.
Method	Using muscle-driven PD control laws, the HAM, GLU, and HFL are responsible for maintaining the global orientation of the upper body (Θ), defined as the vector between the COM of the upper body and the COM of the pelvis projected onto the sagittal plane.
Method	During double stance, these control laws are only active for the leading leg, denoted as u Θ m lead .
Method	Two main differences between our stance phase control laws compared to Geyer and Herr [2010] lie in how the swing initiation state functions.
Method	First, for running we found it necessary to enter into swing initiation using the d  ̃ > d  ̃ SI condition, rather than just wait for double stance.
Method	Second, we found it unnecessary to modulate the muscle-driven PD-control laws in the hip by ground reaction forces.
Method	Instead, the responsibility to maintain upper body orientation is always assigned to the lead leg.
Method	Much like in the stance phase, each muscle has an initial constant excitation value (q m ).
Method	The leg motion relies significantly on passive dynamics during the swing phase [Collins et al. 2005], as most muscles are only excited at low levels.
Method	The main exceptions are the TA, which maintains the length feedback (u L TA ) to avoid toestubbing, and the HAM, which is activated at late swing phase to prevent the knee from being overextended before landing.
Method	The HFL introduces a hip flexion torque through a length feedback, which is suppressed when the HAM is stretched in during late swing.
Method	The amount of excitation in the HFL also depends on the value of upper body lean at the beginning of the swing phase (Θ lto ): the further the upper body leans forward compared to the reference lean angle (Θ d ), the more excitation is supplied from the HFL during the swing phase.
Method	Note that Θ d is the same as the target angle in u Θ HFL .
Method	The GLU, HFL, and VAS work to guide the hip and knee joints toward a desired pose to prepare for ground contact: u VAS = q VAS + u VAS θ k , u GLU = q GLU + u θ GLU h , u HFL = q HFL + u θ HFL h .
Method	A single desired hip target angle (θ h ) is adjusted according to the SIMBICON balance feedback law [Yin et al. 2007] and is shared by both the GLU and HFL.
Method	We found the addition of the stance preparation state to be important for discovering running gaits.
Method	The balance feedback law allows robust control strategies to be found in difficult environments (e.g., being pushed by random forces).
Method	The rest of the DOFs are controlled using standard joint-space PDcontrollers with state-dependent parameters.
Method	Following Wang et al. [2010], the target features for the ankle and hip joints in the coronal plane are the global foot and pelvis orientations, respectively.
Method	The coronal swing hip target angles follow the same feedback law as θ h .
Method	Additionally, we set the toe joint to be a spring with spring constant of 30 Nm/rad, target angle 0, and no damping.
Method	Unlike in previous work, where a gait cycle is broken down into four states, only two are needed (triggered by left/right foot-strike) since DOFs with the most complex activities are actuated by muscles.
Method	Our upper body control also largely follows Wang et al. [2010], with the exception that the target feature of our back joint in the coronal plane is the global orientation of the torso instead of the local joint angle between the torso and the pelvis.
Method	This global target allows our model to better keep the head upright during locomotion.
Method	We fix the spring and damper constants for all arm joints to 30 Nm/rad and 3 Nms/rad, respectively, with target angles set to 0.
Method	We found that more human-like arm swing can be generated by relating the elbow and shoulder target angles as θ s l = α arm θ h l − θ h r + βθ e d and φ l s = γθ e d , where θ s l and φ l s are the shoulder angles in the sagittal and transverse planes, respectively; θ h l and θ h r are the current left and right sagittal hip angles; θ e d is the desired elbow angle, β, γ are constants chosen based on human motion data (see supplemental material), and α arm is a scale constant that determines the magnitude of the arm swing.
Method	This formulation captures the tendency to rotate the shoulder backwards and inwards while bending the elbow.
Method	The scale constant and the desired elbow angle are among the parameters set by optimization, as described in the next section.
Method	The control algorithm specified in Section 4 has a large number of parameters, which we set by optimization [Wang et al. 2010].
Method	More specifically, each of the u m F , u m L , and u m θ laws have one, two, and three parameters, respectively.
Method	There are 56 parameters in total (30 stance, 26 swing) for the MTU control laws.
Method	For the upper body and the non-sagittal DOFs in the lower body, we optimize the PDcontrol parameters (spring-damper constants, target angle, balance feedback) for all joints except for arms, where only a target elbow angle and a swing scale parameter are optimized (Section 4.4).
Method	When combined with 33 free parameters describing the initial state of the simulation, 124 parameters (w) fully define a simulated motion {s 1 . . . s T } over T timesteps.
Method	We optimize control parameters and the initial state using Covariance Matrix Adaptation (CMA) [Hansen 2006], with stepsize σ = 0.005 and 50 samples per iteration.
Method	The optimization aims to maximize the following return function: T R (w) = r(s t ) − w e J effort .
Method	The reward is defined as the negative sum of a number of task terms (i.e., r(s t ) = − i K i (s t )), which can be thought of as high-priority goals that the controller must satisfy while minimizing effort.
Method	In practice, these terms are weighed more heavily than the effort term.
Method	The tasks include moving the COM forward at a target velocity while not falling down for 10 seconds, and maintaining head stability and upper body orientation.
Method	The task terms are based on Wang et al. [2010] and are defined in the supplemental material.
Method	Note that unlike in previous work, we did not need to include human-like speed to step-length ratio and minimal angular momentum about the COM as task terms.
Result	The main contribution to our effort measurement is the total rate of metabolic energy expenditure ( E)  ̇ over all MTUs.
Method	To quantify E,  ̇ we implement a model described by Anderson [1999], which is later expanded by Bhargava et al. [2004].
Method	The rate of metabolic energy expenditure for a given muscle can be modeled as the sum of heat released and mechanical work done by the muscle: E  ̇ = A  ̇ + M  ̇ + S  ̇ + W,  ̇ where A  ̇ is the muscle activation heat rate, M  ̇ is the muscle maintenance heat rate, S  ̇ is the muscle shortening heat rate, and W  ̇ is the positive mechanical work rate.
Method	The muscle activation heat rate models the rate of energy that is converted to heat by a muscle given a certain level of activation, and is a function of both the mass of the muscle and the excitation signal.
Method	The maintenance heat rate similarly models the heat rate for the muscle to maintain contraction at a certain level, and depends additionally on the current fiber length.
Method	Specifically, A  ̇ = mass · f A (u) and M  ̇ = mass · g(  ̃ l CE )f M (a), where mass is the muscle mass and  ̃ l CE is the normalized muscle fiber length.
Method	The forms of f A , f M , and g are described in the supplemental material.
Method	The dependence on muscle mass captures the fact that while larger muscles are generally capable of generating more force, they are also more costly to use.
Method	The difference is that F MTU is the net force (both active and passive) produced in the MTU, while F CE is only the active force.
Method	Let E  ̇ m,t denote the rate of metabolic energy expenditure computed for MTU m at timestep t.
Method	We define the average rate of metabolic expenditure due to MTUs as where B  ̇ is the basal metabolic energy rate, set to 1.51 times body mass [Anderson 1999].
Method	M is the set of all sixteen muscles defined in the model.
Method	Additionally, torques generated by the PD-controllers in the rest of the DOFs are penalized by the average sum of torque squared objective: T 1 2 J R = τ j,t , T t=1 j∈Q r where Q r is the set of all joint DOFs except for the sagittal hips, knees, and ankles.
Method	We similarly define J L to penalize the average sum of squared soft joint limit torques for the hip, knee, and ankle joints, specified in Geyer and Herr [2010].
Method	The overall effort of a particular motion is defined as J effort = w M J M + w R J R + w L J L , a weighted sum between the terms.
Method	We empirically set w M = 100, w R = 1, and w L = 0.5 for all experiments.
Method	The simulations were implemented using Open Dynamics Engine (ODE) with a frequency of 2400 Hz.
Method	We simulate for T = 24000 timesteps (10 s) in each evaluation.
Method	The optimization is terminated after 3000 iterations, which takes approximately 10 hours using 50 compute cores on a cluster of Dell PowerEdge 1950 servers.
Method	An optimized controller can be simulated at interactive rates using standard hardware.
Method	We initialize walking parameters of the MTU control laws based on hand-tuned values for 2D walking from Geyer and Herr [2010].
Method	For running, we double the initial gain parameters of GAS and SOL, and initialize θ e d to set the elbow in a bent position.
Method	The precise initialization values are provided in the supplemental material.
Method	Human joint moment (torque) curves during locomotion can be computed from motion capture and ground reaction force data.
Result	In this work we are particularly interested in comparing our results to the mean and standard deviation curves for the sagittal hip, knee, and ankle joints for multiple subjects over multiple walking and running speeds.
Background	While such data for walking is readily available [Perry and Burnfield 2010], only scattered data are available for running [Novacheck 1998; Yokozawa et al. 2007; Hamner et al. 2010].
Method	Instead, we acquired our own ground truth data using an instrumented treadmill with 20 subjects.
Method	This data is available from http://graphics.stanford.edu/projects/bio-locomotion .
Method	We acquired kinematics and dynamics data for a range of walking and running speeds (from 1.0 m/s to 5.0 m/s).
Method	The supplemental material includes angle and moment plots for all speeds, as well as details on our data collection.
Result	Comparing the mean curves for walking speeds from 1.0 m/s to 1.75 m/s, we found that the range of hip angles in our subjects during walking increased by approx◦ imately 10 , while the location of maximum ankle plantarflexion shifted slightly earlier in the gait cycle.
Result	More pronounced differences are present between running data at different speeds.
Result	The hip ◦ angle range and maximum knee flexion both increased by 30 as running speed increased from 2.0 m/s to 5.0 m/s, while locations of both the maximum hip extension and ankle plantarflexion shifted earlier by 5% and 10%, respectively.
Result	Both the hip and ankle torque outputs increased with speed, though the ankle torque curves did not differ significantly between 4.0 m/s and 5.0 m/s.
Method	We first optimized for a normal walking controller (referred to below as nwalk) with a target velocity of 1.25 m/s, which is approx- imately the human self-selected walking speed.
Method	Initializing with the normal controller, we then optimized for a 1.0 m/s slow walk controller (swalk) and a 1.5 m/s fast walk controller (fwalk).
Method	A 1.75 m/s very fast walk controller (vfwalk) is optimized by initializing from fwalk.
Result	Supplemental figures indicate that our kinematic patterns generally agree with data over a range of speeds and especially at lower speeds.
Result	Two main discrepancies are the timing of knee flexion during stance, and ankle dorsiflexion before heel-strike.
Result	For higher speeds, the maximum knee flexion angle is lower than human data, and the location of maximum ankle plantarflexion occurs earlier in the gait cycle.
Result	All angle and moment curves shown are averaged over multiple cycles.
Result	Note that we found time-delays to be important for generating human-like motion given our control model.
Result	Optimizing without activation dynamics and with ∆t m = 0 for all MTUs results in a solution where ankle torques build up too quickly in the stance phase, leading to shorter step-lengths compared to human data.
Result	A major artifact from all of the previous works is the lack of hip extension during mid-gait, which does not occur in our result.
Background	The feature-based controller of Mordatch et al. [2010] is robust and flexible, but their basic walking gait shows an obvious crouch.
Result	Our result also exhibits a range of knee motion more similar to humans compared to previous works.
Result	However, all four controllers show excessive dorsiflexion before heel-strike.
Result	An important advantage of optimization over hand-tuning is the ability to create controllers based on high-level objectives such as walking speed.
Result	As demonstrated in supplemental material, our controllers generate more human-like gaits compared to optimized controllers from Wang et al. [2010] at faster walking speeds (Wang10f, Wang10vf ) as well.
Result	An obvious artifact of all controllers from Wang et al. [2010] is the excessive plantarflexion in the early swing phase, which is not present in our result.
Background	1 Examining differences in torque generation, we can see that the controller presented by Coros et al. [2009] does not employ a human-like torque distribution between the joints ( Figure 6b ).
Background	In particular, as was the case in SIMBICON [Yin et al. 2007], the gait is largely hip-driven, as can be seen by the large hip torques and small ankle torques compared to human data.
Background	In turn, controllers from Wang et al. [2010] generated larger amounts of ankle torque by optimizing for a human-like torque ratio, but did not come close to matching the shapes of human torque data.
Result	Note that our work does not exhibit unnatural torque spikes due to state switching that are present in the previous works.
Method	We compute the mean standard score against human data over 100 evenly spaced points on the curves.
Result	Note that our results show the lowest average standard score for all speeds.
Method	We evaluate the metabolic energy expenditure objective described in Section 5 against the simple sum of squared torques objective, by redefining where Q s is the set of sagittal hip, knee, and ankle DOFs (with w M = 5).
Method	Controllers optimized for each of the two objectives (nwalk, min torque) are demonstrated in the accompanying video.
Method	For this comparison, we use a target speed of 1.25 m/s, which is the same as nwalk.
Result	The gait resulting from torque minimization exhibits too much knee flexion during the swing phase and too much dorsiflexion before heel-strike.
Result	Since the foot is a relatively light link, the actual magnitude of the dorsiflexion torque is not large even when the TA is fully activated, therefore it does not incur a large penalty in the torque objective.
Result	In contrast, the metabolic energy objective captures the fact that activating and maintaining contraction of TA generates significant heat and should therefore be discouraged.
Result	Note that unlike dorsiflexion torques, large ankle plantarflexion torques can be generated with relative ease.
Result	Simply increasing the penalty on ankle torques does not account for the effort difference between generating torques in different directions.
Method	A simple objective that could approximate effort given a musculoskeletal model is the sum of squared muscle activations, which is commonly used in static optimization—a technique for recovering activations given motion capture and force plate data [Anderson 1999].
Result	However, as demonstrated in the accompanying video, this objective also does not lead to faithful walking kinematics.
Method	Here we define where M is the set of MTUs, and a m,t is the activation level of MTU m at timestep t (with w M = 60000).
Result	In the gait produced by the controller that minimizes this objective (min act), activations from the GAS/SOL are significantly lowered, while activations from VAS are increased.
Result	While the total amount of activations is reduced, the resulting gait walks in a crouch and relies heavily on the knee.
Result	Controllers optimized using the torque and activation objectives both exhibit large errors compared to nwalk, especially at the ankle joint.
Result	While noticeable kinematic differences are seen in the gaits produced by different objectives, the torque curves are smooth due to the muscle model and the control parameterization.
Background	The plantarflexors (GAS and SOL) are largely responsible for forward propulsion in normal walking [Liu et al. 2008].
Result	We found that weakening the GAS and SOL to a quarter of their original strength, while keeping all other objectives identical (target speed 1.25 m/s), results in a mild crouch gait characterized by excessive knee flexion (see accompanying video).
Result	Our result suggests that under the condition of weakened plantarflexors, the mild crouch gait may be metabolically efficient compared to other gait choices.
Background	The crouch gait is commonly found in cerebral palsy patients, and weakness in the plantarflexors is one of many factors thought to contribute to the gait abnormality [Steele et al. 2010].
Background	Knee hyperextension, another common gait abnormality, causes patients to vault the body forward over the extended stance limb, and can result from hamstring lengthening surgery in cerebral palsy patients [Kay et al. 2002].
Result	In the accompanying video, we show that our optimization indeed results in a mild hyperextension gait after weakening HAM to a quarter of its original strength, with a mini◦ mum knee flexion angle of 2 .
Result	Note that the same angle for the gait ◦ generated by nwalk is 9 .
Result	Another cause of knee hyperextension is weakened quadriceps, which can be simulated by weakening the VAS in our model.
Result	We found that weakening the VAS to one-tenth of its original strength leads to a motion similar to quadriceps avoidance gait, which is seen in patients with quadriceps weakness and anterior cruciate ligament (ACL) deficiency [Timoney et al. 1993].
Result	Our controller architecture and objective function is not limited or specific to walking alone.
Result	By simply changing the target velocity and initialization (changing the initial velocity from 1.3 m/s to 3.05 m/s, doubling the initial force feedback gains for GAS and SOL, and bending the elbow), the same procedure yields running controllers, without any modifications to the control parameterization.
Background	In contrast, previous optimization-based control synthesis methods required including torque ratios specific to walking as part of the objective [Wang et al. 2009] or adding spring elements for running [Wu and Popović 2010].
Method	Our unified approach to both walking and running is consistent with the view that humans select between walking and running by minimizing energy at different speeds [Srinivasan and Ruina 2006].
Method	We compare running motions generated by our controller at 4.0 m/s with human running data in Figure 7 .
Result	Our running kinematic results do not match human data as well as walking, though the basic features of the curves are still present.
Result	A main discrepancy is that our hip and knee joints both reach maximum extension earlier than human running data.
Result	Similar to our walking results, our knee joint flexes less during the stance phase compared to humans.
Result	Our maximum knee flexion is also lower than human data.
Result	Our knee extension torque reaches maximum earlier than human data, which can cause the knee to extend too quickly during the stance phase.
Result	On the other hand, our plantarflexion torques have a lower peak than human data, resulting in a strategy that relies on the knees more than the ankles.
Result	In the supplemental material and the video, we include results for running at speeds ranging from 3.0 m/s to 5.0 m/s.
Result	The faster running results are optimized sequentially in 0.5 m/s increments (e.g., 4.0 m/s initialized from 3.5 m/s).
Result	As the target velocity increases, finding a satisfactory local minimum appears more difficult.
Method	We use 100 samples per iteration and a 0.25 m/s optimization increment for speeds over 4.0 m/s.
Problem	In this work, we have chosen to focus on reproducing humanlike kinematics and torque trajectories.
Result	Likely due to our modeling of human-like torque generation and activation delays, our controllers cannot tolerate nearly as much external force as recently developed controllers for purely joint-actuated characters [Mordatch et al. 2010; Wang et al. 2010].
Result	However, we can still follow Wang et al. [2010] and optimize explicitly for controllers that can deal with external forces.
Method	In particular, we optimized controllers that can tolerate 100 N, 0.4 s pushes to the torso.
Result	These controllers chose to walk in a stiff crouch gait, with lowered COM and a constantly dorsiflexed ankle to ensure foot clearance (see accompanying video).
Result	Note that 100 N is approximately the weight of a 10 kg object, a significant push to a human.
Background	Comparatively, the corresponding 100 N controller presented by Wang et al. [2010], who did not model biological torque generation constraints, did not employ a gait that is significantly different from the undisturbed baseline controller.
Method	We also optimized for a 4.0 m/s running controller tolerant of 50 N, 0.4 s pushes, as shown in the video.
Result	We have presented a biologically-motivated control parameterization that can be used to automatically generate 3D human-like walking and running controllers of different speeds.
Method	Controllers are optimized to satisfy a set of high-level task terms while minimizing an effort term based on modeling the rate of metabolic energy expenditure.
Method	Notably, walking and running emerge from the same optimization process simply by changing the target velocity and initialization.
Result	Through comparisons to kinematic and torque data of human walking, we show that our results adopt a human-like torque generation strategy while producing kinematic data significantly closer to humans than previous work.
Result	Our work demonstrates the importance of modeling constraints on torque generation due to muscle physiology, both in restricting the space of possible torque trajectories and in providing a realistic model of effort.
Method	We chose to focus on generating human-like locomotion in a straight line and on flat ground.
Future Work	A natural extension is to investigate whether our control parameterization and effort term can be combined with the popular task-space controllers [Coros et al. 2010; de Lasa et al. 2010; Wu and Popović 2010] and higher-level planning [Coros et al. 2009; Mordatch et al. 2010] to create humanlike motions on uneven terrains [Wu and Popović 2010] or obstacle courses [Mordatch et al. 2010; Ye and Liu 2010]—scenarios that have only been addressed using purely joint-actuated characters.
Future Work	Finally, an exciting area for future work is to automatically synthesize locomotion controllers for more detailed, fully muscle-actuated human models [Weinstein et al. 2008; Lee et al. 2009].
Result	As we have touched on in Section 6.2, our approach can be used to develop predictive biomechanical models to investigate the effects of muscle and control properties on gait.
Future Work	However, more scientific validation of our simulation results is needed before we can conclude that our results apply to real humans.
Future Work	One clear aspect for improvement is to adopt a more physically-accurate simulation engine [Sherman et al. 2011], as ODE “emphasizes speed and stability over physical accuracy” [Smith 2006].
Future Work	More accurate simulations and detailed models present additional computational challenges both in simulation speed and in parameter optimization, but are crucial for potential scientific and medical applications.

Result	In this paper, we present a method for simulating the interaction of fluids with deformable solids.
Result	The method is designed for the use in interactive systems such as virtual surgery simulators where the real-time interplay of liquids and surrounding tissue is important.
Background	In computer graphics, a variety of techniques have been proposed to model liquids and deformable objects at interactive rates.
Problem	As important as the plausible animation of these substances is the fast and stable modeling of their interaction.
Problem	The method we describe in this paper models the exchange of momentum between Lagrangian particle-based fluid models and solids represented by polygonal meshes.
Method	To model the solid-fluid interaction we use virtual boundary particles.
Method	They are placed on the surface of the solid objects according to Gaussian quadrature rules allowing the computation of smooth interaction potentials that yield stable simulations.
Result	We demonstrate our approach in an interactive simulation environment for fluids and deformable solids.
Background	In these simulation environments, deformable objects play an important role.
Background	For the simulation of deformable solids, a variety of models have been proposed ranging from efficient mass-spring approaches to methods based on the physically more accurate Finite Element Method (FEM).
Background	Some of these methods allow the simulation of elastically and plastically deformable solids at interactive speed.
Background	More recently, there has been an increased interest in efficient methods for the realistic simulation of fluids.
Background	These approaches can be employed to represent blood or other liquids.
Background	Besides deformable models, they play an essential role in applications such as surgery simulation.
Background	So far, only a few interactive methods for the simulation of fluids with free surfaces have been proposed.
Problem	With the ability to simulate both, deformable solids and fluids, a new problem has been introduced, namely the mod- eling of the interaction of these structures.
Problem	An interaction model suitable for the use in interactive environments needs to be computationally efficient and the generated interaction forces must not induce any instabilities to the dynamic simulation.
Result	In this paper, we present a new technique to model interactions between particle based fluids and mesh based deformable solids which meets these constraints.
Method	We present our interaction model with fluids represented by a Smoothed Particle Hydrodynamics approach (SPH) and with deformable solids represented by a Finite Element approach.
Result	However, the general interaction model we propose works with any type of deformation technique as long as the object surface is represented by a polygonal mesh and the fluid by Lagrangian particles.
Background	The majority of publications in the area of physically based animation focuses on physical systems of one single type.
Background	Deformable objects are interesting to study in their own right.
Background	In fluid simulation, on the other hand, boundary conditions are often considered a necessary but not a central issue.
Background	They are typically derived from simple geometric primitives.
Method	Our method connects these two areas of research.
Background	In the field of computer graphics, a large number of mesh based methods for the physically based simulation of deformable objects have been proposed since the pioneering paper of Terzopoulos [ 1 ].
Background	Early techniques were mostly based on mass-spring systems, which are still popular for cloth simulation [ 2 , 3 ].
Background	More recent methods discretize continuous elasticity equations via the Boundary Element Method (BEM) [ 4 ] or the Finite Element Method (FEM) [ 5 , 6 , 7 ].
Background	Since T. Reeves [ 8 ] introduced particle systems as a technique for modeling fuzzy objects twenty years ago, a variety of special purpose, partice based fluid simulation techniques have been developed in the field of computer graphics.
Background	Desbrun and Cani [ 9 ] where among the first to use Smoothed Particle Hydrodynamics (SPH) [ 10 ] to derive interaction forces for particle systems.
Background	They added space-adaptivity in [ 11 ].
Background	Later, Stora et al. [ 12 ] used a similar particle based model to animate lava flows.
Background	In [ 13 ], Müller et al. derived inter particle forces from SPH and the Navier Stokes equation to simulate water with free surfaces at interactive rates.
Background	Recently, Premoze et al. [ 14 ] introduced the Moving-Particle SemiImplicit (MPS) method to computer graphics for the simulation of fluids.
Background	As a mesh-free method, it is closely related to SPH but in contrast to standard SPH, it allows the simulation of incompressible fluids.
Background	In all these papers, boundary conditions are not treated explicitly.
Background	The fluids typically interact with solid walls or the ground.
Background	Genevaux et al. [ 15 ] address the interaction problem explicitly.
Background	They propose a method to simulate the interaction between solids represented by mass-spring networks and an Eulerian fluid grid by applying spring forces to the mass-less marker particles in the fluid and the nodes of the mass-spring network.
Background	However, solids are typically represented by coarse meshes, especially in interactive simulations.
Background	Thus, the nodes of a mass-spring network are not very well suited for the application of interaction forces.
Background	Therefore, Monaghan, one of the founders of the SPH formalism, uses special boundary or ghost particles on fixed borders to model interactions [ 16 ].
Background	The idea of ghost particles was picked up in several following projects including our own.
Result	The key contribution of our paper is to place these ghost particles onto boundary triangles of deformable objects and to derive their locations and weights according to Gauss integration [ 17 ], which allows to model fluid-solid interactions stably at interactive rates.
Problem	In physically based animation, we are interested in the simulation of macroscopic effects at interactive speed.
Method	Therefore, we consider macroscopic models for both, solids and fluids.
Background	Materials, which are homogeneous at the macroscopic level, can mathematically be described as a continuum [ 18 ].
Method	Thereby, quantities such as the density ρ, viscosity μ, deformation u or velocity v are all mathematically expressed by continuous functions over space and time.
Method	A physical model relates these quantities to each other via partial differential equations (PDEs).
Method	The stresses σ s are functions of the displacements u.
Method	The equation is in Lagrangian form since the displacement vectors u follow the material points.
Method	Similarly, mechanical properties of incompressible Newtonian fluids can be described by the following two equations in Eulerian form where fluid quantities are observed in a fixed coordinate frame
Method	Equation (2) again states that the change of momentum equals the internal forces derived from the stresses σ f plus the externally applied body forces f .
Method	The stress tensor σ f = 2μ (v) − pI is composed of the viscosity stress and the pressure stress.
Method	Comparison of the right hand side of the two equations of motion (1) and (2) reveals, that the Eulerian description makes the additional convection term v · ∇v necessary.
Method	For fluids we focus on particle based methods such as SPH for which this term can be omitted.
Background	Materials such as fluids or solids are bounded by spatial limits.
Background	The behavior of materials at these limits is defined by boundary conditions.
Method	The boundary conditions relate the quantities of the two adjacent materials to each other at the interface.
Method	In the case of fluid-solid interaction, the geometrical domain of the interface Γ is defined as a surface between the volumetric solid continuum and the volumetric fluid continuum (see Fig. 2(a) ).
Method	We focus on three main types of boundary conditions.
Method	If the solid is considered to be impermeable, no fluid element is allowed to cross the boundary, which is described in the following equation:
Method	The equation states that the components of the velocities of the fluid and the deformable object perpendicular to Γ are equal.
Method	The no-slip condition models friction between the fluid and the solid (see Fig. 2(c) ).
Method	If both independent boundary conditions (4) and (5) hold, we simply have ∂t ∂ u = v at the boundary, i.e. both materials have the same velocity at the boundary.
Method	Newton’s Third Law demands the continuity of stresses σ s and σ f throughout the boundary (see Fig. 2(d) ).
Method	The continuous equations and boundary conditions described in the previous section need to be discretized in space and time via a numerical method before they can be used in a computer simulation.
Method	We do not go into the details of how equation (1) for elastic objects can be solved numerically.
Background	For possible solutions using the Finite Element Method (FEM) we refer the reader to [ 19 ], [ 6 ] or [ 7 ].
Method	All we require for our interaction method to work is • that the solid object is represented by a mesh and • that the displacements, velocities and forces are carried by the nodes of the mesh.
Background	Most of the methods used in computer graphics to simulate deformable objects meet these constraints including massspring systems, the Finite Volume Method (FVM) and the Boundary Element Method (BEM).
Method	In this paper we concentrate on Lagrangian methods because they allow fluids with free surfaces to move freely in space while in the Eulerian case fluid computations are restricted to a spatially fixed and bounded grid.
Method	From the fluid simulation method we require • that the fluid is represented by a set of particles and • that positions, velocities and internal forces are carried by the particles.
Method	Interaction modeling, thus, reduces to the problem of simulating the interaction between particles and triangulated surfaces.
Background	In physics, interaction potentials of two objects always depend on the distance between them.
Method	While the Euclidean distance between two points is uniquely defined, the distance between a point and a triangle or a point and a triangulated surface needs to be defined.
Method	Unfortunately, concavities as well as close disconnected meshes generate discontinuous first derivatives of the distance field.
Method	Those discontinuities lead to discontinuous derivatives in forces since the forces depend on the distance field.
Method	A force field with discontinuous first derivatives, in turn, yields artifacts such as the so called cooking of particles in concave regions and reduced stability of the simulation.
Method	One way to remove the problem is to replace the minimum by a weighted sum.
Method	Let the kernel W (d, h) ∈ C 1 be a positive smooth monotonously decreasing function which is zero for d ≥ h and has a vanishing derivative at d = h.
Method	However, as Fig. 3(b) shows, the resulting field is distorted near triangle boundaries.
Method	Unfortunately, normalization just distributes the distortions to adjacent regions of triangle interfaces as Fig. 3(c) shows.
Method	Another difficulty introduced by the weighted field method is the choice of the support radius h with respect to the size of the features of the boundary T .
Method	For large supports, small features are smoothed out while small supports reduce the interaction range of T .
Background	The problems mentioned in the previous section are well known in the field of implicit surface modeling introduced by Blinn [ 23 ].
Method	The implicit surface is defined by selecting an iso-surface of F S .
Method	By replacing the skeleton S with the triangulated surface T we get a smooth potential field around T (see Fig. 3(d) ).
Method	The problem with the weighted sum approach arises when when multiple triangles meet.
Method	In this case, all triangles contribute as a whole to the sum and generate bulges.
Method	In contrast, the convolution integral sums up infinitesimal parts of the skeleton each properly weighted (see Fig. 4 ).
Method	When the convolution integral is used, the interaction of p with the surface T is modeled as the interaction of p with all the infinitesimal points in T .
Background	Approaches to approximate this integral were proposed by Bloomenthal [ 24 ] and Sherstyuk [ 25 ].
Background	Bloomenthal uses radial Gauss kernels which can be separated with respect to different dimensions.
Background	The separation allows post evaluation of the convolution in 3D space, only considering the distance to the triangle plane.
Background	Sherstyuk discovered a special kernel which can be analytically convoluted over a triangle domain.
Method	Neither method is suitable for computing physical interactions because we are not free in the choice of the kernel.
Method	The potential function is given by physical laws.
Method	Our idea to solve the convolution integral is to use Gauss quadrature rules [ 17 ].
Method	We use the seven point rule which has convergence order O(L 6 ) with respect to the triangle size L. (see Fig. 5(a) and Tab.
Method	These sampling points can be interpreted as boundary particles, which are placed and weighted according to the chosen Gauss quadratur
Method	The weighted summation of their potentials approximates the convolution of the potential over the domain of the boundary triangle in an optimal way.
Method	Although the seven point rule yields good approximations of the convolution integral, triangles that are large in comparison to the interaction range of the surface would induce a poor sampling of the boundary field.
Method	Therefore, we subdivide the boundary triangle until a sufficient sampling rate is provided.
Method	We define a threshold for the maximal acceptable distance between boundary particles.
Method	This threshold is chosen relative to the maximal interaction radius of the fluid particles and can be regulated by the user.
Method	The boundary particles are generated by subdividing the triangle domain and by application of the Gauss quadrature rule to the resulting triangles (see Fig. 5(b) ).
Method	This has to be done at every time step, because triangles on the boundary are moved and deformed.
Method	Therefore, an efficient scheme is needed.
Method	We compute the relative vectors from the triangle nodes (shown in blue) to the boundary particles (shown in red) only once because they are the same for all subdivision triangles.
Method	These vectors are then added to the blue nodes to generate the complete set of boundary particles.
Method	Analog to positions, the velocities of boundary particles are interpolated from the velocities of the triangle nodes.
Method	Now that we have replaced the triangulated surface by a set of particles, the problem of triangle-particle interaction reduces to particle-particle interaction.
Method	We can, thus, use SPH-based approaches to approximate the boundary conditions stated in Sections 3.2, 3.3 and 3.4.
Background	Monaghan [ 16 ] uses a Lennard-Jones-like force to generate repulsive forces which approximate the no-penetration condition.
Method	We propose a Lennard-Jones-like force that models both repulsion and adhesion to the contact surface.
Method	The traction τ ra is dependent on the distance of the surface element from the particle p and has unit force per area in order to yield a force when integrated over the triangle.
Method	The traction has an order four repulsion term and an order two attraction term.
Method	It is designed to be zero for r = r 0 which is the preferred distance of fluid particles from the interface.
Method	The fact that for r = 0 the traction is finite (τ ra (0) = k) and that both, traction and first derivative vanish for r = h are important for robust real time simulations.
Method	We use the normalized kernel W visc proposed in [ 13 ] for viscosity computations.
Method	The kernel W visc is designed such that its Laplacian ∇ 2 W visc takes the linear form above, but satisfies the normalization criterion on the kernel itself.
Method	The normalization warrants second order interpolation convergence.
Method	So far, we have applied forces to fluid particles only.
Method	However, according to Newton’s Third Law, proper reaction forces need to be applied to the deformable solid as well.
Method	The force contributions of boundary particles have to be distributed among the boundary triangle vertices so they can be picked up by the simulator of the deformable object.
Background	Bridson et al. [ 26 ] solve a similar problem in the context of cloth simulation.
Background	To resolve vertex-triangle collisions, an impulse is applied to the colliding vertex.
Background	Then, a distribution scheme is used to compute the corresponding reaction impulses for the three vertices of the triangle.
Method	We use the same scheme to distribute the forces to the vertices of the triangle surface.
Background	According to [ 26 ] this distribution scheme provides continuity across triangle boundaries and introduces appropriate torques for off-center interactions.
Background	However, the scheme is not completely error free.
Method	Force magnitudes can get amplified – at most by a factor of 8/7 – at the triangle center.
Method	However, this error did not cause any artifacts or stability problems in our simulations.
Method	At every time step of the solid and fluid simulator, the following five steps are executed: 1.
Method	Processing the five phases one after the other would have a negative impact on storage requirements.
Method	Neighbor references and boundary particles for all triangles would have to be stored at the same time.
Method	If the computations of steps three to five are grouped around single triangles, only data relevant for the current triangle has to be stored at a time ( Fig. 6 ).
Result	The output of step 3 is a list, containing all fluid particles within interaction range h of a triangle t.
Method	To speed up the search for these particles we use a regular grid with spatial hashing [ 27 ].
Method	There is a trade-off between computation time for the neighbor search and the quality of the neighbor list.
Method	We extend the axes aligned bounding box (AABB) of t along all axes about the interaction range.
Method	Then, we query all grid cells intersecting the extended box.
Method	We also tested tighter queries which generate fewer neighbor candidates but their increased time complexity was not compensated by the reduced cost of interaction computations.
Method	In step 4, boundary particles are only generated for those triangles that have fluid particle neighbors.
Method	The boundary particles for a triangle t are kept only temporarily for the interaction computation.
Method	After t is processed, they are discarded.
Method	In this step, positions and velocities are interpolated from the triangle nodes for each boundary particle.
Method	To compute interaction forces in step 5 we iterate over all the boundary particles of a triangle.
Method	All experiments described in this section have been performed on an AMD Athlon 1.8 GHz PC with 512 MB RAM and a GeForce Ti 4400 graphics card with 128 MB RAM.
Method	Note that most of the simulations are recorded in a real-time interactive environment.
Method	Thus, we cannot afford several seconds or even minutes per frame for the reconstruction and rendering of the free fluid surface as in off-line simulations [ 14 , 15 ] which explains the simplistic renderings of the fluids.
Method	To demonstrate the stability of our model in connection with concave surfaces, we filled a pool composed of 800 tetrahedral elements with 2000 fluid particles (see Fig. 7(a) ).
Method	The simulation runs at 20 frames per second.
Method	By pulling the pool wall, the user indirectly influences the water.
Result	The generated waves, in turn, deform the pool walls.
Result	Deformable boxes float freely on the water surface (see Fig. 7(b) ).
Method	We dropped an additional large box into the pool (see Fig. 1 ).
Result	When it touches the water, it emits a wave that hits the pool boundary and causes it to fracture.
Result	This scene demonstrates the interplay of various physical phenomena provided by the fluid simulator, the solid simulator and the interaction model.
Result	An important application of our method is the simulation of bleeding during virtual operations.
Method	Our simulation of a blood vessel is a first step into this direction.
Method	We simulate the flow of 3000 particles through a virtual vessel, consisting of a deformable mesh composed of 560 tetrahedra.
Result	The simulation took about 70 ms per time step.
Method	The velocity of the fluid particles is color coded visualizing the friction of the fluid with the boundary.
Method	In the experiment shown in Fig. 10 , we turned on fracture of the Finite Element mesh.
Method	Now, the vessel is torn open when the elastic stresses caused by blood pressure exceed the material threshold.
Method	The free surface of the particle system is rendered using the Marching Cubes algorithm.
Result	The animation of the mesh and the particles are possible in real time at 60 ms per time step, while surface reconstruction took about half a second per frame.
Result	On today’s hardware only a limited number of fluid particles can be simulated in real-time which yields a relatively coarse fluid surface.
Result	We have presented a new method for the simulation of interactions of deformable solids with fluids.
Result	Our interaction model simulates repulsion, adhesion and friction near the fluid-solid interface.
Result	The smoothness of the force fields is important for the stability of the simulation.
Method	The core idea to get smooth interaction fields is to place boundary particles onto the surface triangles according to Gauss quadrature rules.
Result	This idea might be useful in other graphic domains as well.
Result	We mentioned the application to modeling with implicit surfaces.
Result	Character skinning is another application where bulges or knees are known problems in regions where several close bones meet.
Result	We demonstrated the usability of our method in an interactive simulation environment with several scenes.
Result	A difficulty in connection with the interactive simulation of fluids is the extraction and rendering of a plausible fluid surface in real time.
Future Work	Thus, ongoing work focusses on fast algorithms for surface reconstruction.

Problem	This paper presents a method for animating fluid using unstructured tetrahedral meshes that change at each time step.
Result	We show that meshes that conform well to changing boundaries and that focus computation in the visually important parts of the domain can be generated quickly and reliably using existing techniques.
Problem	We also describe a new approach to two-way coupling of fluid and rigid bodies that, while general, benefits from remeshing.
Result	Overall, the method provides a flexible environment for creating complex scenes involving fluid animation.
Problem	Although systems for physically based fluid animation have developed rapidly in recent years and can now reliably generate production-quality results, they still have some limitations.
Problem	Simulation domains can change substantially from step to step because of deforming boundaries, moving obstacles, and evolving fluid motion, yet current systems based on fixed grids are not ideally suited to handle these situations.
Method	When generating the mesh, we use the position and shape of boundaries as well as criteria based on the visually important parts of the fluid and velocity field to construct a sizing field that dictates the desired edge length for tetrahedra throughout the domain.
Method	We then use an efficient and reliable meshing algorithm adapted from [ Alliez et al., 2005 ] to produce a mesh that is refined according to this field.
Method	We use unstructured tetrahedral meshes because they conform to curved and irregular boundaries better than axis-aligned grids with the same number of grid elements and allow for precise control of refinement throughout the domain.
Method	We transfer the physical properties of the simulation from the old mesh to the new mesh using a generalization of the semi-Lagrangian velocity advection technique that introduces no additional smoothing.
Method	We then perform a mass conservation step that has been extended to allow a new, single-step solution of two-way coupling between fluid and rigid bodies.
Result	Overall, this approach provides a flexible framework for fluid simulation that opens the door to many features.
Result	We have implemented the system and tested it in a variety of scenarios such as the one shown in Figure 1 .
Result	We have found that the combination of unstructured tetrahedral domains and dynamic remeshing creates a versatile environment for the creation of complex and visually interesting fluid animations.
Background	The animation of fluids through physical simulation has become an important tool in the visual effects industry.
Background	One approach that has been popular in recent years makes use of a spatial discretization based on regular, fixed, hexahedral grids.
Background	Some examples of this approach can be found in [Foster and Metaxas, 1996], [Foster and Metaxas, 1997], [Stam, 1999], [Yngve et al., 2000], [Fedkiw et al., 2001], [Foster and Fedkiw, 2001], [Enright et al., 2002], [Carlson et al., 2002], [Feldman et al., 2003], and [Goktekin et al., 2004].
Background	The most commonly used storage scheme for these approaches is the “staggered grid” scheme.
Background	This method offsets storage of different quantities on the grid, and was first described by [Harlow and Welch, 1965].
Background	Efforts have been made to enhance these methods to allow for better conformance to irregular boundaries such as the free surface of liquids, complex obstacles, or irregularly shaped domains.
Background	[Losasso et al., 2004] described an octree-based method that retains many of the advantages of regular grids while allowing computational effort to be focused in particular parts of the simulation domain; this enables detailed tracking of moving boundaries such as liquid surfaces.
Background	Both [Carlson et al., 2004] and [Guendelman et al., 2005] have demonstrated methods for two-way coupling of obstacles to fluid.
Background	Unstructured tetrahedra have also been used for fluid simulation within the graphics community.
Background	Two examples of this are [Feldman et al., 2005a] and [Elcott et al., 2005].
Background	The first method uses a velocity-based approach while the second uses a vorticity-based formulation.
Background	It is a blend of ideas from these two papers, along with a generalization of the semi-Lagrangian velocity advection technique for moving meshes described in [Feldman et al., 2005b] that forms the heart of our method.
Background	The idea of moving meshes independent of a fixed or particle-centric coordinate system is not a new one; arbitrary Lagrangian-Eulerian (ALE) methods were designed for just this purpose.
Background	They have proven useful in the simulation of highly deformable elastic materials.
Background	ALE was first described in [Hirt et al., 1974], where it was used with finite differences to solve compressible fluid problems.
Background	[Donea et al., 1977] went on to apply ALE in a finite element setting.
Background	An excellent survey of the development of ALE methods appears in [Donea et al., 2004].
Background	Examples within the graphics literature that feature moving meshes without remeshing include [Shah et al., 2004] and [Rasmussen et al., 2004], both of which translate the grid to follow the visually important portion of the fluid.
Background	Another approach to handling changing domains is to dispense with the mesh altogether, instead using Lagrangian particles for simulation of fluids.
Background	A few examples of this approach are [Terzopoulos et al., 1989], [Desbrun and Cani, 1996], [Cani and Desbrun, 1997], [Stora et al., 1999], [Müller et al., 2003], [Premo ze et al., 2003], and [Müller et al., 2004].
Background	These meshless methods are particularly well suited to changing domains because points can move freely without concerns about mesh quality.
Method	Because we regenerate a new simulation mesh at each time step, the viability of our method hinges on fast, high-quality, reliable tetrahedral mesh generation.
Background	While a history of unstructured mesh generation is outside the scope of this paper, [Owen, 1998] and [Teng and Wong, 2000] provide good surveys of the field.
Method	For our mesh generator we selected the approach described in [ Alliez et al., 2005 ].
Method	This innovative method produces meshes which conform to domains of arbitrary topology quickly and reliably.
Method	Also, it allows for the local edge length of the tetrahedra to be specified arbitrarily throughout space, which allows us to easily perform adaptive mesh refinement from step to step.
Method	The meshes produced by this technique are Delaunay, which provides improved gradient estimation and allows us to significantly simplify some of the expressions that arise when interpolating velocity values stored on the mesh.
Result	The key contribution of our method is to demonstrate the freedom granted by remeshing at each simulation time step.
Method	The core of our system is based on the simple, efficient methods for discretizing the inviscid Euler equations on tetrahe- dral meshes described in [Elcott et al., 2005] and [Feldman et al., 2005a].
Method	We have made a few modifications in order to combine the best aspects of both approaches that are described below.
Method	Once we have a good discretization, we need a way to propagate information from one mesh to the next.
Background	[Feldman et al., 2005b] details a generalization of the standard semiLagrangian velocity advection technique that allows simulation state to be transferred between deforming domains without incurring additional smoothing.
Method	We demonstrate that their approach can easily be applied to transfer information between two arbitrary, topologically unrelated meshes, which is required to achieve more general evolution of the simulation domain from step to step.
Method	Finally, we need to quickly and reliably generate a new tetrahedral mesh for each time step that suits the current simulation conditions, such as conformance to boundaries and obstacles as well as any desired refinement.
Background	Although methods have long existed to mesh arbitrary domains, most are relatively slow in comparison to simulation running times or don’t reliably terminate under realistic conditions.
Background	The availability of efficient, versatile meshing algorithms such as [ Alliez et al., 2005 ] has made the generation of a new mesh at each time step practical.
Problem	Also, we describe a new, single-step method to achieve two-way coupling between obstacle and fluid motion.
Method	We use a staggered fluid state storage scheme that stores pressures at tetrahedron circumcenters and “face-normal velocities,” the component of velocity in the direction of the face normal, at the face circumcenters.
Background	Similar schemes have been used in [Botta and Hempel, 1996], [Elcott et al., 2005] and [Feldman et al., 2005a].
Background	These methods are a generalization of the staggered grid scheme originally proposed by [Harlow and Welch, 1965].
Method	This staggered method is used to discretize the inviscid Euler equations:
Method	In these equations, u is the fluid velocity, t time, p pressure, ρ density, and f any external forces.
Method	The symbol denotes T the vector of differential operators = [∂/∂x, ∂/∂y, ∂/∂z] .
Method	We account for the changes in the mesh over a time step directly during semi-Lagrangian advection (see Section 3.2).
Method	Divergence and gradient operators are needed as part of the mass conservation step.
Method	We make discrete estimates of these derivatives following the formulation presented in [Losasso et al., 2004] and [Elcott et al., 2005].
Method	The divergence of a tetrahedron is computed as an area weighted sum of the tetrahedron’s face normal velocities.
Method	The gradient at a face circumcenter in the direction of the face’s normal is computed using finite differences.
Method	The difference in circumcenter pressures adjacent to a face is divided by the distance between these circumcenters.
Method	In Delaunay meshes, the line connecting adjacent tetrahedra circumcenters passes through the circumcenter of the face between them and is in the direction of that face’s normal.
Method	This property of Delaunay meshes motivates our storage scheme at circumcenters because the gradient estimate is equivalent to the gradient of a piecewise linear function that interpolates the circumcenter values.
Method	The staggered scheme stores only the component of velocity in the face normal direction.
Method	For both the semi-Lagrangian step and to advect smoke particles for rendering, a full velocity vector must be found at arbitrary positions in the mesh.
Method	We interpolate velocity vectors from face normal velocities using the two-step method developed in [Elcott et al., 2005].
Method	First, a velocity vector, u t , is computed at each tetrahedron circumcenter, then we interpolate within Voronoi cells using u t values at the cell vertices.
Method	Velocity u t for tetrahedron t is found by solving the small linear system N t u t = z t where N t is a matrix containing 4 rows of the face normals of t and z t is a vector of the 4 face normal velocities associated with t.
Method	For a divergence-free field, this solution has the remarkable property that interpolating back to the face circumcenters exactly recovers the original face-normal velocities.
Method	Thus interpolating the u t velocities also exactly interpolates the face-normal velocity components, and does not incur the error one would otherwise expect from a twostep interpolation method.
Method	To find a velocity at an arbitrary point we interpolate within the Voronoi cell using the tetrahedra velocities associated with the cell.
Method	This interpolation is based on the method of [Warren et al., 2004], which presents a way to interpolate within a general convex polytope.
Method	Here, σ t is the set of polytope faces that intersect at node t.
Method	The denominator is the product of distances from x to the faces in σ t computed using the face normals,n f , and plane offsets, d f .
Method	|N t | is the determinant of a matrix of face normals in σ.
Method	Weights from all nodes are normalized to sum to 1 before use in the weighted sum.
Method	To simplify this computation we take advantage of two properties: 1) in a Delaunay mesh, edges are in the direction of the Voronoi cell’s face normals and 2) the volume of tetrahedron t is 1/6|E t | where E t is a matrix formed from the three vectors of edges emanating from a common node of t.
Method	A similar observation appears in [Ju et al., 2005], and we find that with it the velocity interpolation is quite efficient.
Method	All quantities appearing in Equation (4) are already stored for use in other parts of the timestep, saving the need to compute the terms in Equation (3).
Method	When advecting large numbers of particles, velocities at nodes of tetrahedra can be first be found using Equation (4) and then quickly interpolated in a linear fasion over the tetrahedra to advect the particles.
Background	The simple and stable semi-Lagrangian method has become the standard tool for advection of the velocity field for graphical applications [Stam, 1999].
Method	This method does not rely on velocities being stored at any particular place, as long as the velocity can be interpolated throughout space.
Method	We can extend this technique naturally to meshes which change arbitrarily at each time step as in [Feldman et al., 2005b].
Method	This extension does not incur any additional smoothing compared to using semi-Lagrangian advection with static meshes.
Method	Suppose at time t velocities are stored at locations x (t) (in our case, the face circumcenters), and we want to find (t) the velocity at a particular face location x i .
Method	We trace back (t) from x i through the velocity field of the previous time step to a point x i , which has no necessary correspondence to any feature of the old mesh.
Method	Then, we update the velocity at (t) x i to the value interpolated from the old velocity field at x i .
Method	Because the velocities from the previous step are stored on a different mesh, we have to trace back and interpolate using this previous mesh (see Figure 2 ).
Method	The domain boundaries, obstacles, and smoke are free to move and change from step to step of the simulation.
Method	By regenerating the mesh at each time step we can ensure that our domain conforms well to boundaries and is refined in visually important areas.
Method	We accomplish this by using the variational tetrahedral meshing algorithm presented in [ Alliez et al., 2005 ].
Method	This method allows for generation of tetrahedral meshes that conform well to an arbitrary input surface mesh, have no restrictions on topology (i.e., allow nested voids), and allow for sizing of tetrahedra throughout the domain based on arbitrary criteria.
Method	Our implementation differs from the original algorithm in a couple of details.
Method	As in the original method, refinement of the mesh is controlled by a sizing function μ(x) that, for any point x in the simulation domain, returns the desired local edge length of the tetrahedra.
Method	In this equation, k 0 is an offset value that controls the minimum value of the sizing field, and hence the minimum local edge length of tetrahedra.
Method	d(x) is the distance to the closest obstacle or boundary which demands refinement, s(x) is a function of the density of smoke particles, and ω(x) is a function of the vorticity of the velocity field.
Method	The parameters k d , k s , and k ω respectively control the weight each of these functions has on the sizing field.
Method	These three factors are the same as those used for octree refinement in [Losasso et al., 2004].
Method	The overall goal of the sizing field is to focus computational effort in the most visually important parts of the scene, that is, near closed boundaries, where the velocity field varies most, and where smoke is visible.
Method	This meshing method is iterative, so the mesh from the previous simulation time step can be used as an initial guess for the node placement in the mesh at the next simulation time step.
Method	Because there is, in general, strong temporal coherence between steps of the simulation, the sizing field does not change too much and so the nodes from the previous step are often a good initialization.
Method	Before the algorithm proceeds, the initial node placement is corrected to match the sizing field of the current step.
Method	One other modification we made to the algorithm is that, when optimizing the node positions, we move nodes to the average of the barycenters of the surrounding tetrahedra instead of the circumcenters.
Method	We have found that while this tends to slightly decrease the average quality of tetrahedra in the mesh, it often leads to substantial improvements in the quality of the worst elements of the mesh, which are of more concern for numerical simulation.
Method	Of course, remeshing takes time, so it is important to consider the impact it has on overall simulation performance.
Result	The time spent generating meshes for each simulation step varies, but generally accounts for less than a quarter of the overall simulation time.
Problem	The motion of fluid and rigid bodies that mutually effect each other can be complex and visually appealing.
Problem	The interaction occurs as a consequence of the conditions that:          1.
Problem	The velocities in the normal direction are the same at the interface of the fluid and the rigid body surface.
Problem	The fluid velocity is divergence free and the rigid body velocity is rigid.
Problem	The linear and angular momentum of the combined system is conserved.
Background	In [Carlson et al., 2004] these conditions are enforced sequentially.
Background	While for many cases this produces results that look very good, under some situations artifacts can be created because enforcing one of the conditions in general will break a previously enforced one.
Background	Examples of such artifacts might be fluid leaking through solid boundaries or poor performance in piston-like situations.
Method	Our implementation differs from [Carlson et al., 2004] in a couple of ways, but most significantly we enforce these conditions simultaneously within the mass conservation step.
Method	In general, the mass conservation step solves for pressures that accelerate the velocity field to be divergence free.
Background	In previous works, including those with two-way coupling, the mass conservation step treats faces to behave as fluid or explicitly prescribes their velocities.
Background	For fluid faces, the pressure accelerates the velocity proportional to the gradient of the pressure while for prescribed faces, the pressure does not effect the fluid.
Background	For a more complete discussion of fluid/prescribed-velocity mass conservation see [Fedkiw et al., 2001].
Method	We extend mass conservation to include a dynamic, rigid body.
Method	To do so, we solve for acceleration of the fluid and the rigid body, ignoring pressure for both.
Method	We then solve for a pressure term that satisfies boundary and incompressibility constraints to find the final accelerations.
Method	The rigid body accelerations can be computed by creating a matrix R that is multiplied by a vector of the pressures that surround a rigid body.
Method	R can be formed by a series of matrix multiplications:
Method	The rightmost matrix finds the net force-torque couple acting on a rigid body by summing up the contribution due to pressure forces acting on rigid body mesh faces.
Method	M is a diagonal matrix with the mass of the rigid body on the diagonals and I is the inertia matrix.
Method	The leftmost matrix in the multiplication returns the acceleration of the fluid-rigid faces in the direction of the face normal due to the linear and angular acceleration of the rigid body.
Method	By construction, accelerations generated by this matrix behave rigidly.
Method	Computing pressure accelerations of both the fluid and fluid-rigid faces can be expressed as a matrix A multiplied by a vector of all the pressures.
Method	A row of A that corresponds to a face with fluid on both sides contains the same entries as the standard gradient matrix multiplied by −1/ρ.
Method	With A built, mass conservation including two way coupling proceeds much in the same way as in the all-fluid case, with A replacing the role of the discrete gradient matrix.
Method	For a given vector of pressures, p, the intermediate velocity field, z ∗ , is accelerated to the end-of-step velocity, z, by z = z ∗ + ∆tAp.
Method	For the fluid faces, z ∗ is found by applying all terms of Equation (1) except the pressure term.
Method	For the fluid-rigid faces, z ∗ is found using a rigid body simulator without pressure forces applied.
Method	This linear system can be solved efficiently using PCG since the the matrix DA, which replaces the discrete Laplacian from the all fluid case, is also a positive-definite symmetric matrix.
Method	Using the same machinery, we can also interact with constrained rigid bodies.
Method	This simply requires finding an R matrix that correctly computes face accelerations due to pressure.
Method	For example, one could easily alter R such that the body was constrained to just rotate about the origin by replacing b i in Equation (6) with b i = (r i × n i ) T and using only the I −1 block for the center matrix.
Result	This idea could be extended further to include even articulated bodies.
Method	We implemented the method described above in matlab 1 and C, making use of Pyramid [Jonathan Shewchuck, personal communication] for Delaunay triangulation and pixie 2 for all renderings.
Result	Typical simulation times for meshes with 100,000 tetrahedra were about 1 minute per frame.
Result	Refinement of the simulation mesh near the paddle ensures good conformance to its curved surfaces that produce interesting vortex effects in the smoke.
Method	The blue valves on either side of the bulb prevent backflow.
Method	The motion of these valves is not scripted.
Method	Instead, they are modeled as rigid bodies constrained to rotate about an axis and their motion is caused by two-way interaction with the fluid.
Result	On the left is a lighter bunny which is tossed about by the force of the cannons and also affects the motion of the smoke.
Result	On the right is a heavier bunny that drops quickly to the ground.
Result	Although quality of the mesh elements does not suffer at this level of refinement, the proportion of time spent meshing increases to 39.3%.
Result	The motion of the smoke at the higher resolution is more lively and exhibits more fine-scale detail.
Future Work	A vorticity enhancement method, such as those in [Fedkiw et al., 2001] and [Selle et al., 2005] could be used to further enhance the fluid motion but we do not find such enhancement necessary and so have not implemented it.
Result	We have presented a system for performing fluid animation using unstructured tetrahedral domains that can change arbitrarily at each time step.
Result	Although our current implementation models completely fluid-filled domains, we believe it would be well-suited for use with surface tracking techniques for liquid simulation.

