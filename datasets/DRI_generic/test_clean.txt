Problem	We introduce a new method for efficiently simulating liquid with extreme amounts of spatial adaptivity.
Method	Next, we enable subtle free-surface phenomena by deriving novel second-order boundary conditions consistent with our discretization.
Method	We couple this discretization with a spatially adaptive Fluid-Implicit Particle (FLIP) method, enabling efficient, robust, minimally-dissipative simulations that can undergo sharp changes in spatial resolution while minimizing artifacts.
Result	Along the way, we provide a new method for generating a smooth and detailed surface from a set of particles with variable sizes.
Problem	Finally, we explore several new sizing functions for determining spatially adaptive simulation resolutions, and we show how to couple them to our simulator.
Method	We combine each of these elements to produce a simulation algorithm that is capable of creating animations at high maximum resolutions while avoiding common pitfalls like inaccurate boundary conditions and inefficient computation.
Problem	This paper aims to produce fluid simulations with a high degree of spatial adaptivity.
Problem	We desire to enable a simulator to focus its computational resources on the visually interesting regions of a fluid flow, while remaining computationally efficient and avoiding common artifacts due to a spatially adaptive pressure solve.
Background	Previous approaches have made great strides towards this goal, but they often exhibit visual artifacts, a lack of computational robustness, or an unacceptably hefty computational expense.
Background	The groundbreaking work of Losasso et al. [2004] introduced an octree for spatial adaptivity, but it suffers from spurious flows at T-junctions.
Background	Finite volume methods [Batty et al. 2010] repair these spatial artifacts at the expense of solving a significantly larger system of equations and sacrificing computational stability near poorly-shaped elements.
Problem	Furthermore, many existing methods still are not truly spatially adaptive in the sense that their computational complexity is still tied to a uniform grid or spatial parameter.
Result	We introduce a combination of techniques that successfully makes adaptive fluid simulation practical at large scales.
Method	We first reduce memory and computational costs by switching from a finite volume method to a discretization with a significantly smaller linear system for the pressure solve, which has the side effect of increasing the simulator’s robustness to poor-quality elements and effectively preventing locking artifacts.
Method	We next derive second-order Dirichlet boundary conditions consistent with our discretization to benefit from the subtle surface dynamics associated with an accurate pressure solve.
Method	We combine this robust and efficient tetrahedral meshbased fluid simulator with a spatially adaptive method for sampling particles for FLIP-based velocity advection, giving us a method free from any single spatial resolution.
Method	In addition to our adaptive FLIP simulator, we also introduce a new method for computing a surface from a distribution of particles with variable radii.
Result	We found that this method out-performs previous methods in cases of extreme spatial adaptivity by exhibiting smoother surfaces without sacrificing detail.
Result	Our fluid simulator works well with spatially adaptive tetrahedral meshes, but it is another question to decide exactly how these adaptive meshes should be generated.
Method	We investigate various methods for generating these adaptive meshes by experimenting with several sizing functions, allowing us to precisely dictate where simulation detail should occur.
Method	Some examples are a surface curvature-based metric that adds detail only where needed on the fluid surface, a turbulence metric that adds detail only where interesting fluid motion occurs, and a visibility metric that adds detail only in front of a virtual camera.
Result	Concretely, the contributions of our work are: • a novel tetrahedral discretization of the pressure projection step that is efficient to solve and robust to poor-quality elements; • an accurate treatment of second-order boundary conditions within the tetrahedral mesh; • a new technique for extracting a smooth surface from particles with varying radii; • and the inclusion of a flexible sizing function to focus computational resources on important areas of the flow with minimal overhead.
Result	These contributions work together to produce a practical fluid simulator that exhibits low computational and memory complexity, fewer visual artifacts, and a high effective simulation resolution.
Method	Our work is based on the Fluid-Implicit Particle (FLIP) method introduced to the computer graphics community by Zhu and Bridson [2005], which arguably represents the state-of the art for detailed and robust liquid simulations.
Method	The algorithm still follows the general ideas of the Stable Fluid solver [Stam 1999], and can be readily combined with second-order treatment of free surface boundary conditions [Enright et al. 2003].
Background	FLIP derives its success from the fact that it uses particles to compute an accurate, nondiffusive transport of flow quantities, in combination with a gridbased solve to accurately enforce constraints for mass conservation.
Background	The FLIP algorithm is heavily used in the special effects industry, and recent advances have introduced accurate coupling with obstacles [Batty et al. 2007], highly viscous materials [Batty and Bridson 2008], and two-phase flows [Boyd and Bridson 2012].
Background	Traditionally, Cartesian grids are very popular for fluid simulations.
Background	The Marker-And-Cell (MAC) approach [Harlow and Welch 1965], which stores velocity components at cell faces and pressure samples at cell centers, results in discretizations with good properties in terms of stability and accuracy.
Background	An inherent difficulty is that simulations on regular grids become prohibitively expensive for large resolutions.
Background	Thus, many works have proposed methods to focus the computations on regions that are of particular interest.
Background	One example are octrees, which were used by Losasso et al. [2004; 2005] to refine the computational grid in a controllable way.
Background	This approach, however, suffers from numerical diffusion and an inconsistent discretization near the tree’s T-junctions.
Background	Targeting a similar direction as our work, Hong et al. [2009] and Ando et al. [2012] have demonstrated methods to adapt the resolution of FLIP particles in a simulation.
Background	Both methods, in contrast to ours, focus on static computational grids and are restricted to smaller differences in particle size.
Background	Although Cartesian grids are widely used, they are limited in their flexibility to adapt to a simulation setup.
Background	Because of this, tetrahedral grids are popular for methods targeting adaptivity.
Background	In combination with a suitable method to discretize the problem at hand, they allow for very flexible computational grids.
Background	One example is the work of Klingner et al. [Klingner et al. 2006] which demonstrated the use of a Stable Fluids based solver for tetrahedral grids conforming to object boundaries.
Background	Another example is the non-linear fluid solver developed by Mullen et al. [2009], which leads to an energy conserving solve.
Method	Unlike these methods, we make use of a non-conforming grid with Body-Centered Cubic (BCC) lattices.
Background	These meshes were also used by Chentanez et al. [2007] and by Batty et al. [2010] for liquid simulations.
Method	We will denote this class of algorithms as Finite Volume Methods (FVM).
Method	These methods are primarily suitable for uniformly sampled particles, and we will demonstrate in Section 7 that their placement of pressure samples at tetrahedral circumcenters leads to numerical problems in combination with graded BCC meshes.
Background	Another direction of research performs fluid simulations based on arbitrary elements.
Background	Clausen et al. [2013] and Misztal et al. [2010] have proposed a method to simulate liquids with a computational grid conforming to a triangulation of a liquid surface.
Background	Both methods lead to an increased computational cost in comparison to the more efficient tetrahedral BCC meshes.
Background	Sin et al. [2009] proposed an alternative method for hybrid Lagrangian-Eulerian solvers which combines a Voronoi-based pressure solver and particles.
Background	Using this Vornoi-based approach for tetrahedral meshes would yield a pressure matrix similar to ours.
Background	Like our method, Brochu et al. [2010] used this discretization in combination with embedded second-order boundary conditions.
Background	Both of these approaches discretize velocities with per-face flux values, while we store velocity vectors at cell barycenters.
Background	Adaptive simulations have also been explored in the context of SPH simulations without Eulerian grids.
Background	The work of [Adams et al. 2007] shares similarities with our approach, as it is able to simulate a wider range of particle radii, and it proposes a surface reconstruction method in the adaptive setting.
Result	We will show in Section 5 that our surface creation method results in surfaces with fewer visual artifacts.
Background	Additionally, a robust and efficient method for adaptive SPH simulations was introduced by Solenthaler et al. [2011], but this work primarily targets the coupling of two different particle resolutions.
Background	Several other methods have been proposed to reconstruct smooth surfaces around collections of particles without orientation.
Background	One approach that is commonly used is to compute a signed distance function with averaged particle radii and centroids [Zhu and Bridson 2005].
Background	A variant of this approach, taking into account information about the spatial variance of the particle’s neighborhood was proposed by Yu et al. [2010].
Background	Both methods primarily target particles with constant radius.
Background	More recently, a level-set based method was proposed that computes a constrained optimization with bihar- monic smoothing [Bhattacharya et al. 2011].
Background	However, such an optimization would be complicated to apply in our unstructured setting.
Method	In contrast to these methods, our approach for surface creation computes the union of convex hulls around triplets of particles, which leads to a smooth and closed surface around a collection of arbitrarily sized particles.
Problem	The aim of our method is to solve the Navier-Stokes equations, which for incompressible, Newtonian, inviscid flows can be written as ρDu/Dt = − p + f , with the additional constraint · u = 0 to enforce a divergence-free velocity field.
Method	Here, u, p and f denote velocity, pressure and external forces, respectively, while D/Dt denotes the material derivative.
Method	The density ρ is constant in our case.
Method	We solve these equations using operator splitting [Stam 1999], and a level set φ(x) = 0 defines the position of the liquid-gas interface.
Method	The motion of the fluid is computed in a Lagrangian manner using particles, while the pressure projection step is computed on an Eulerian grid.
Method	We will now describe how we compute the pressure projection using a tetrahedral discretization.
Method	In the following, however, we prefer an alternate view that looks at this problem from an energy minimization perspective: we want to compute the minimal change in kinetic energy necessary to reach a divergence-free state of the flow similar to [Batty et al. 2007].
Method	Here, Ω represents the domain of the computational grid, and we choose to discretize this space using tetrahedral cells.
Method	This has the advantage of giving us a natural way to handle cells of different size, while yielding a consistent discretization of the differential operators involved.
Method	We store pressure samples at the nodes of the tetrahedral mesh, while velocities are stored at cell centers.
Method	Note that by assuming a piece-wise constant velocity and a linear change of pressure within a cell, this setup results in a constant pressure gradient per tetrahedron, by construction.
Method	In the following, we denote the number of cells with m and the number of nodes with n, and we indicate discretized quantities with caret notation.
Method	It consists of a m×n matrix, computing a per-tetrahedron gradient from nodal values.
Method	Consequently, we define the divergence operator to be the transpose of the discretized gradient.
Method	Before we go ahead to define [ ], we want to outline the rest of the steps for our pressure solve.
Method	The [ ] T [ ] matrix-matrix multiplication results in a square n × n matrix, which is symmetric and positive definite.
Method	As we assume a linear change of the pressure for each cell, we can use simple barycentric interpolation to retrieve the pressure p at a position inside a cell.
Method	In line with finite element methods using linear elements, we define the gradient based on the partial derivatives of the barycentric interpolation.
Method	In contrast to previous work, our pressure solve is a linear system that has n degrees of freedom, n being the number of nodes in the tetrahedral mesh.
Method	For our BCC mesh, n is in practice smaller than the number of tetrahedra m (by a factor of 6 on average).
Method	A direct implication of this smaller linear system is that it is faster to solve.
Method	A second, less obvious implication of the smaller linear system is that it effectively prevents artifacts known as locking.
Method	These artifacts are commonly observed in finite element methods for problems in elasticity.
Background	Different methods have been proposed to circumvent these problems, e.g., using linear elements for pressure instead of piece-wise constant ones [Irving et al. 2007].
Background	Other works explicitly smooth the pressure field to reduce locking problems [Misztal et al. 2010].
Method	In general, locking can be observed if the pressure basis can represent more, and higher-frequency, functions than the basis for the velocity.
Method	Thus, choosing a more restrictive basis for pressure, as in [Irving et al. 2007], or explicitly removing high-frequency information from the pressure [Misztal et al. 2010], reduces the chance of locking.
Method	Our method, by construction, has more degrees of freedom for representing velocity fields than pressure fields.
Method	Although we cannot prove that a local configuration over-constraining the velocities will never occur, the larger number of degrees of freedom for our velocities effectively prevents locking artifacts, and we have not encountered any in our tests.
Method	For the free surface, we have to ensure that the Dirichlet boundary condition p = 0 is satisfied at the interface position.
Method	Usually, this means computing a pressure value for nodes outside of the liquid so that a linear interpolation along an edge of a cell gives zero at the correct position [Enright et al. 2005; Lew and Buscaglia 2008].
Method	Considering two pressure samples along an edge, we’ll denote values inside the air with a G subscript, and values inside the liquid with an L subscript in the following.
Method	For a Cartesian MAC grid, the ghost pressure value p G is given by p G = p L φ G /φ L .
Method	In our case, however, this approach does not yield the desired result.
Method	The reason is that our velocity samples are not in line with the direct connections of the pressure samples – they are not locally orthogonal to each other.
Method	Instead, we have to ensure the boundary conditions result in the correct pressure value at the cell center.
Method	In the following we will show how to derive suitable free-surface boundary conditions to ensure second-order accuracy within our framework.
Method	Note that for p i that are not inside of the liquid, we set w i = 0.
Method	In line with the traditional ghost fluid method, we define p G uniquely for each tetrahedron.
Method	In order to do this we need to compute the coefficients w n .
Method	Here the θ n are a set of barycentric coordinate coefficients such that θ 1 +θ 2 +θ 3 = 1, and a tilde superscript denotes a value interpolated with the barycentric weights.
Method	That means the values w n are determined by those of the θ n coefficients, which we will compute in the following.
Method	Note that, theoretically, θ n could take any values as long as they add up to one.
Method	The computation of the ghost fluid ρ values is independent of the right-hand side b, so we will restrict the discussion to the left hand side.
Method	Assuming, without loss of generality, that the first vertex is the one outside of the liquid volume, we embed the boundary condition into        M based on the w n coefficients.
Method	We can extract two constraints for each θ n from this form, which, together with the barycentric coefficient constraint, give us a 3 × 3 matrix M that can be inverted analytically.
Method	If the quality of a tetrahedron is good, 0 < θ n < 1 is guaranteed.
Method	In this case, the resulting matrix is symmetric positivedefinite and can be easily inverted by the commonly used preconditioned conjugate gradient methods.
Method	However, positive off-diagonal terms of the matrix can result in values of θ outside of the range [0, 1], leading to an indefinite linear system.
Method	In these cases we consider the tetrahedron to have a poor quality.
Method	Effectively, this means reverting to first-order accuracy when second-order accuracy is intractable.
Method	We implement a similar step in our algorithm to overcome numerical problems resulting from badly shaped cells.
Method	We check whether the ghost fluid boundary conditions would violate diagonal dominance of an equation in our linear system.
Method	If we detect such a case, we smoothly transition to first order accuracy.
Method	Here, φ denotes a tolerance factor that we set to φ = 0.25.
Method	Note that this scaling does not break the symmetry of the resulting linear system.
Method	More specifically, for k = 1 this yields full second-order accuracy, while for badly shaped tetrahedra the resulting k = 0 means that we revert to the standard rounding strategy of a first order accurate method.
Method	With our BCC mesh, all regular BCC tetrahedra have very good quality and valid θ n values.
Method	The graded BCC tetrahedra, on the other hand, can be of lower quality and can require the use of Eq.
Method	Luckily, in our tests these tetrahedra make up only a very small fraction of the mesh.
Method	For this we need to construct a continuous velocity field based on the discrete values in our tetrahedral mesh.
Method	As we store velocities at the cell centers, the interpolation would ideally use the dual mesh consisting of the Voronoi cells of each node [Brochu et al. 2010].
Method	Unfortunately, performing interpolations within arbitrary Voronoi cells would be expensive and require a large amount of computation compared to the other steps of our simulator.
Method	Instead, we have found the following approach to yield high speed and good accuracy: we first interpolate the centered velocities to the nodes, similar to [Chentanez et al. 2007].
Method	Instead of interpolating these averaged values directly (which would result in smeared out motion), we temporarily subdivide the cells of our mesh by inserting a vertex at the center where we have an accurate velocity sample.
Method	We then perform barycentric interpolation based on these subdivided cells, ensuring a C 0 continuous velocity that retains the original velocities at cell centers.
Method	Note that these four smaller tetrahedra do not have to be stored explicitly.
Method	We construct them on the fly when a sample is requested from one of the original cells.
Method	We combat these problems by directly manipulating particle positions.
Method	During each time step, we apply the position correction algorithm of Ando et al. [2012]; this algorithm essentially pushes each particle away from its neighbors to prevent clustering.
Method	We also introduce two special behaviors when the particles are close to the liquid surface (less than a distance of six times the particle radius).
Method	First, we impose the constraint that the position correction step may only move particles near the surface tangentially to the fluid interface.
Method	Secondly, particles near the surface may leave gaps when they spread out quickly.
Method	Our method naturally fills in these gaps by slightly pulling each particle towards the fluid interface.
Method	For particles near the interface, this pulling force acts in addition to the position correction.
Method	FLIP particles that partake in splashes and sprays can pose a significant burden on computational resources, especially in an adaptive framework like ours.
Method	This inefficiency stems from the fact that water droplets undergo extremely simple ballistic motion.
Method	Theoretically, we know that such a small region with purely free-surface boundary conditions will yield zero internal forces, so we simply detect individual FLIP particles that have no neighbors within six times their radius, remove them from the pressure solve, and accelerate them with gravity instead.
Method	When these particles eventually enter the neighborhood of other particles at some point in the future, we resume treating them like fluid by returning them to the pressure solve.
Method	This decision allows us to avoid aggressively refining the tetrahedral mesh in locations where the physical motion is uninteresting.
Method	Only a small percentage of the particles are simulated in this way, e.g., 1.7% on average for Figure 6 .
Method	Our method achieves adaptivity by varying the mesh resolution over the computational domain.
Method	Our FLIP simulation performs computation on both a background volumetric mesh and on a set of particles.
Method	Given a sizing function that indicates the desired spatial level of detail, our method first creates a tetrahedral mesh with varying spatial resolution, and then it locally changes the particle density by splitting and merging operations.
Method	To compute the spatially-varying background grid, we start with the Delaunay tetrahedralization of a set of points distributed in a body-centered cubic lattice configuration.
Method	In order to make the mesh resolution change over space, we use the octree-based grading method which was proposed by Labelle and Shewchuk [2007] and later adopted in several adaptive simulation environments [Chentanez et al. 2007; Wojtan and Turk 2008; Batty et al. 2010].
Method	Similar to [Batty et al. 2010], we generate a new tetrahedral mesh every ten time steps, instead of rebuilding the mesh on every consecutive step.
Method	Also, the tetrahedral mesh is only temporarily used for the pressure solver, so no information is transferred from one time step to the next by storing it on the grid.
Method	Thus, we do not worry about re-sampling data when computing a new tetrahedral mesh.
Method	We change the size and number of particles in our simulation with splitting and merging operations.
Method	For this, we modify the strategy of Ando et al. [2012] to work within our framework: at each remeshing step, we loop through the particles and determine whether the resolution needs to be changed.
Method	If a particle is too small, then we merge it with its nearest neighboring particle, resulting in a particle whose radius is given by the combined volume of the two original particles.
Method	If a given particle is bigger than the desired size, then the particle is split in two.
Method	The two new particles are placed randomly within the original particle’s radius and redistributed with a heuristic that attempts to fill in nearby gaps: We first compute the 24 midpoints m i between this particle and its 24 nearest neighbors.
Method	Then we find the closest particle to each midpoint and store the squared distance as a weight ω i .
Method	The new particle’s position is equal to the weighted average of all nearby midpoints: x new = ω i m i / ω i .
Method	After a split or merge operation, the new particle’s velocity is computed using a volume-weighted average.
Method	Also, we must take care to ensure that particles close to the surface do not introduce interfacial bumps when they split or merge; whenever we create a new particle that is less than 1.25 times its radius away from the surface (through either a split or a merge event), we move it in the surface normal direction such that its sphere lies exactly tangent to the liquid interface.
Method	Numerical viscosity in fluid simulations is tightly coupled to the spatial resolution resolving the flow.
Method	We compensate for spatiallyvarying numerical viscosity caused by particles of various sizes in our simulation by adjusting the PIC/FLIP blending parameter in our FLIP simulation [Bridson 2008].
Method	Given quantities Q i,PIC and Q i,FLIP computed at particle i from PIC and FLIP simulations, respectively, the new quantity Q i is computed as a weighted blend between the two:
Method	We found that this strategy adequately eliminates any artifacts due to spatially varying numerical viscosity.
Method	Sizing Functions We define the level of detail in our simulations with a spatially varying sizing function S(x).
Method	We have experimented with several different sizing functions depending on factors such as distance to a camera, distance to the liquid surface, curvature of the liquid surface, measures of fluid turbulence, and arbitrary analytical number fields.
Method	Our simulator is versatile enough to cope with any of these sizing functions, resulting in efficient simulations with highly variable levels of detail.
Method	In all of the examples in this paper, the sizing function is defined as a combination of five different metrics:
Method	This has the effect that motion near the surface has higher priority than motions far inside the bulk volume of the liquid.
Method	V (x, y) is a view-dependent function that returns the value y if x is within the camera’s visible region and returns the maximum particle radius r max (representing the minimum surface resolution) otherwise.
Method	The next two metrics are designed to prioritize geometric detail of the liquid surface and of obstacles by computing a desired resolution based on cuvature.
Method	κ liquid (x) returns 0.8 divided by the extrapolated curvature of the liquid interface.
Method	Similarly, κ solid (x) returns 1.6 W smooth (d solid , r max ) divided by the extrapolated curvature of the solid interface, where W smooth (x, h) is a smooth kernel function (1 − ||x|| 2 /h 2 ) 3 and d solid is the closest distance to the solid boundary.
Method	As a last component of our sizing function we found it beneficial to invest computational resources into keeping interesting motion of the flow field alive.
Result	We also introduce a new method for computing an implicit surface from a set of particles.
Method	Given our set of FLIP particles with variable radii, we aim to implicitly represent the fluid surface by computing its signed distance function.
Background	Several useful methods for computing a surface from a collection of particles have been proposed in the past [Zhu and Bridson 2005; Adams et al. 2007; Yu and Turk 2010], but they tend to produce undesirably bumpy surfaces when considering particles of highly variable radii ( Figure 4 ).
Problem	In this section, we introduce a new strategy for computing an implicit surface from a set of particles of various sizes.
Problem	The main idea is to approximate the fluid surface with the union of the convex hulls of each triplet of nearby particles close to the surface.
Method	For each set of three FLIP particles near the surface, the convex hull forms a thickened triangle shape with rounded edges ( Figure 5 ).
Method	We only consider particles that are less than a given distance apart, with the maximum distance equal to a constant scale factor l times the sum of the two particle radii.
Method	A small l shows more surface details, while a larger l tends to fill in small concavities.
Method	We used l = 2 for most of the simulations in this paper.
Method	We ultimately represent our surface as the union of all such local convex hull shapes, and the minimum signed distance from these shapes to a point in space defines the outer part of our level set function.
Method	In practice, we compute the local convex hull by finding the two outermost planes tangent to a set of three spheres.
Method	We efficiently compute the distance to these planes by analytically solving the polynomial system: ax 1 +by 1 +cz 1 +d = r 1 , ax 2 +by 2 +cz 2 +d = r 2 , ax 3 + by 3 + cz 3 + d = r 3 , a 2 + b 2 + c 2 = 1 .
Method	a, b, c, d are the variables defining our plane with the signed distance function ax + by + cz + d = 0.
Method	Intuitively, the first three equations ensure that the plane is the right distance away from each particle with the normal facing away from them, and the final equation ensures that the plane equation is normalized to a distance function.
Method	These four equations represent the intersection of three hyperplanes and a hypercylinder in 4D {a, b, c, d} space.
Method	We solve this system analytically by first finding the line of common intersection of the first three equations, and then intersecting this line with the cylinder represented by the final equation.
Method	The system has two solutions, representing the top and bottom planes of our convex hull shape.
Method	The above calculation describes how to find the planar regions of the convex hull of a set of three spheres.
Method	By computing the conic and spherical convex hull facets ( Figure 5 , bottom right) in a similar fashion, we can easily compute the signed distance between this convex hull and a point in space.
Method	To evaluate our final level set value, we compute the minimum signed distance from a query point to all nearby convex hulls.
Method	We evaluate the level set on each of the vertices of our adaptive BCC mesh, and we extract a triangle mesh using a marching tetrahedra algorithm.
Method	We then perform a light mesh smoothing to increase the reliability of any curvature computations.
Result	The algorithm as described works perfectly for computing the level set outside of our particle surface, but it may lead to small gaps inside.
Method	To avoid the creation of holes, we temporarily reassign each particle’s radius: r i temp = max(r i , −kφ i ) where φ i is the particle’s stored level set value from the previous time step, and k is a constant set to 0.75 in our simulations.
Method	Using this temporary radius to compute the signed distance as described above will remove erroneous gaps inside the liquid.
Method	We need to compute liquid surfaces both for final visualization as well as for several calculations during the progress of our simulation.
Method	For the final visualization, we compute an especially highresolution BCC mesh from all of our particles and proceed with the algorithm above.
Method	The final surface creation is trivially parallelized, and takes around five minutes average per frame for all of our simulations.
Method	We attempt to speed up the surface creation routine used for simulation computations by computing on the moderate-resolution BCC mesh used for simulation and ignoring ballistic particles (Section 3).
Result	We compare our surface creation routine with a few existing methods in Figure 4 .
Result	Most previous algorithms perform poorly in this comparison because they were not designed for particles with varying radii.
Method	In the beginning of each step (line 2), we typically compute the level-set for the current particle configuration as described in Section 5.
Method	We require the distance to the surface in several steps of our algorithm, so we store the level set values for each particle (line 3).
Method	When enough time has passed to trigger an update of the mesh, it becomes necessary to evaluate the sizing function.
Method	At this point, additional user-defined sizing functions could be computed as well.
Method	Having the information from the sizing functions ready, we create a new BCC mesh and perform particle merging and splitting.
Result	The particle velocity update of line 12 uses barycentric interpolations as explained in Section 3.
Result	Likewise, the grid-based velocity extrapolation of line 10 uses the nodal velocities of Section 3.
Method	A time step is completed by performing the pressure projection and advecting the particles in the resulting divergence-free velocity field.
Method	To evaluate the performance and robustness of our method in comparison to previous work we have performed an extensive series of tests.
Result	One comparison that is particularly interesting is the one comparing our method to an FVM based simulation.
Result	Using a graded BCC mesh leads to problems with the latter, as the position of the circumcenter lies exactly on a face for the graded tetrahedrons.
Result	In the graded region, this can result in two pressure samples from adjacent tetrahedra being placed at the exact same position.
Background	To alleviate this problem, [Batty et al. 2010] propose to slightly offset the pressure samples from the faces.
Result	However, our implementation of their method exhibited slow convergence and the velocity artifacts despite this fix.
Result	The influence of the different components of our sizing function on the evolution of a simulation is difficult to depict with static images, so we refer to the accompanying video for a comparison.
Method	To evaluate the basis of our adaptive model without any influence of the camera dependent sizing function, we have simulated the simple geometric configuration shown in Figure 3 .
Method	For this setup, resolutions from 8 to 256 were used, resulting in 6 levels of adaptivity.
Method	For this simulation, the initial configuration consisted of 168, 161 particles, and momentarily peaked up to 1, 048, 776 during the maximal extent of the splash (settling down again to around 250 thousand in the end).
Method	Note that a full sampling of the initial configuration with a regular grid would have required approximately 6 million particles.
Result	Our measurements show that the run-time of our method has a strong linear relationship to the number of particles, and thus the visual complexity of the simulation.
Result	The per-frame time is low at the beginning and end of the simulation, but strongly peaks during the complex splash in its middle.
Result	Here the computational resources are focused on the visible region of a rotating camera, as the liquid splashes around a U-shaped corridor.
Result	Our solver efficiently resolves the complex motion near the camera, while effectively reducing the computational cost for parts that are not visible.
Method	The κ solid component of our sizing function ensures that geometrically complex regions near the obstacle are simulated with higher accuracy.
Result	In this way, we can resolve the detailed flow of liquid through the holes in the obstacle.
Result	Without adaptivity, the large open liquid surface with complex splashes in a localized region would require huge amounts of computational resources.
Result	Our method can simulate this setup very efficiently, and in a fully coupled manner with an effective high resolution.
Result	The large open region is successfully coarsened by our sizing function, resulting in subtle wave motions around the splashes.
Result	In this case, the whole simulation with 8 different octree levels and a maximum resolution of up to 1024 cells took on average only 4.6 minutes per frame to compute.
Result	Just to illustrate the amount of detail in this setup – our adaptive version initially used 1.7 million particles, while a regular sampling at the finest resolution would have required roughly 400 million.
Result	We store the pressure variables on tetrahedral vertices, and there are far fewer vertices than tetrahedra in a given mesh.
Result	Consequently, the pressure solve has fewer variables and is faster to solve.
Result	Also, by counting degrees of freedom and constraints, we can see that our discretization prevents the locking ar- tifacts which are common in other methods.
Result	However, the lower number of pressure constraints also implies that the highest frequencies of the velocity field may be unconstrained.
Method	In our case a regularization via PIC interpolation acts to diminish any highfrequency artifacts.
Method	Our method uses a FLIP scheme instead of a purely Eulerian method.
Method	We store all physical variables on the FLIP particles, so information is carried from one time step to the next in a Lagrangian manner.
Method	As a result, we are allowed to aggressively remesh the tetrahedral background grid without worrying about excessive damping or re-sampling artifacts.
Background	On the other hand, FLIP simulations have a well-known problem of creating noisy particle distributions, because there are typically several times more particles than velocity variables on the background grid.
Method	We utilize particle repositioning to improve the distribution quality, at the expense of slight inaccuracies due to displacing physical variables.
Result	We noticed that our new surface creation routine is essential for maintaining detailed simulations in the presence of accurate freesurface boundary conditions.
Result	One major benefit of our method is that it can easily create perfectly flat surfaces from a mixture of differently-sized particles.
Result	These flat surfaces represent the equilibrium state of a fluid simulation, so our animations are able to smoothly settle down as time progresses.
Result	Without a method for accurately reproducing flat surfaces, second-order boundary conditions will introduce additional forces in the locations of surface bumps, which artificially prevent a simulation from settling down.
Result	While we believe that our surface creation routine is indispensable, it is quite expensive to compute.
Future Work	In the future we would like to optimize the surface computation.
Result	Our simulations perform quite well for large differences in resolutions, but we have only been able to push them to a certain point in our current implementation.
Result	We found that using too sharp of a grading in our sizing function can place coarse and fine simulation elements too close together and potentially result in artifacts.
Result	For example, when small particles land in very coarse cells after violent splashes, these particles can get stuck in mid air.
Result	Occasionally, this can also lead to an overly strong weight for such particles during the velocity mapping, resulting in momentum artifacts.
Result	While we presented specific parameters for the sake of reproducibility, these values were not meticulously tuned and are certainly not optimal.
Future Work	The task of choosing an ideal sizing function is still an open problem that we are interested in pursuing in the future.
Future Work	In particular, we are interested in taking more temporal information into account.
Future Work	This could lead to more gradual changes in resolution, at the expense of a slightly higher particle count.
Result	We have presented a novel framework for highly adaptive liquid simulation.
Method	In our method, a novel, robust discretization works together with accurate embedded boundary conditions and a flexible sizing function to allow for aggressive adaptivity and high computational performance.
Result	In this way, we can efficiently compute tough simulation setups, such as large surfaces with very localized details.
Result	We have additionally presented a novel surface creation method that yields smooth surfaces in the presence of strongly varying particle radii, which turned out to be an important building block for our framework.
Method	We chose a BCC mesh generation because it is, to the best of our knowledge, the fastest way to generate high-quality meshes.
Result	However, despite its efficiency, mesh generation is still a bottleneck for our simulation.
Result	This is partly due to the fact that it is a mostly serial operation that is difficult to parallelize (most other steps of our algorithm parallelize easily).
Future Work	So, instead of computing the mesh from scratch each time, we are interested in exploring techniques for continuous re-meshing.
Result	Also, our choice of piece-wise constant basis functions for velocity indicates that our discretization could lead to difficulties when it is used for diffusion or viscosity solves.
Future Work	It will be interesting to see how these could be incorporated into our framework.
Future Work	Finally, we are highly interested in applying our method to other types of phenomena, such as smoke and fire simulations, or visco-elastic materials.
Future Work	It will be very interesting to leverage the benefits of our framework for extreme adaptivity in these situations.
Method	Here we describe how to compute the ghost fluid coefficients θ n given the 4 × 4 pressure matrix entries of a single tetrahedron.
Method	Note that each of the θ n has two degree of freedom, and thus each w n also has two degrees of freedom.
Method	As we know that the resulting matrix needs to be symmetric, which gives us the following constraints: a + αw 2 = a + βw 1 , b + γw 1 = b + αw 3 , and c + βw 3 = c + γw 2 .
Method	As the w n linearly depend on θ n , that means: αθ 2 = βθ 1 , γθ 1 = αθ 3 , and βθ 3 = γθ 2 .
Method	When we re-write these constraints in matrix form, and include the barycentric coordinate constraint θ 1 + θ 2 + θ 3 = 1 we get the following linear system:
Method	As the rank of top three rows of the matrix is 2, we can drop one of them.
Method	This means that for our discretization, the ghost pressure coefficients θ n are given by the tetrahedron’s matrix entries from Eq.10.
Method	More specifically, by those for the vertex that is located outside of the liquid, i.e., α, β and γ.

Problem	We present a method for animating characters automatically.
Method	Given a static character mesh and a generic skeleton, our method adapts the skeleton to the character and attaches it to the surface, allowing skeletal motion data to animate the character.
Result	Because a single skeleton can be used with a wide range of characters, our method, in conjunction with a library of motions for a few skeletons, enables a user-friendly animation system for novices and children.
Result	Our prototype implementation, called Pinocchio, typically takes under a minute to rig a character on a modern midrange PC.
Background	Modeling in 3D is becoming much easier than before.
Background	User-friendly systems such as Teddy [Igarashi et al. 1999] and Cosmic Blobs ( http://www.cosmicblobs.com/) have made the creation of 3D characters accessible to novices and children.
Problem	Bringing these static shapes to life, however, is still not easy.
Background	In a conventional skeletal animation package, the user must rig the character manually.
Background	This requires placing the skeleton joints inside the character and specifying which parts of the surface are attached to which bone.
Problem	The tedium of this process makes simple character animation more difficult than it could be.
Problem	We envision a system that eliminates this tedium to make animation more accessible for children, educators, researchers, and other non-expert animators.
Problem	For example, a child should be able to model a unicorn, click the “Quadruped Gallop” button, and watch the unicorn start galloping.
Method	To support this functionality, we need a method (as shown in Figure 1 ) that takes a character, a skeleton, and a motion of that skeleton as input, and outputs the moving character.
Background	The missing portion is the rigging: motion transfer has been addressed in prior work [Gleicher 2001].
Method	Our algorithm consists of two main steps: skeleton embedding and skin attachment.
Method	Skeleton embedding computes the joint positions of the skeleton inside the character by minimizing a penalty function.
Method	To make the optimization problem computationally feasible, we first embed the skeleton into a discretization of the character’s interior and then refine this embedding using continuous optimization.
Method	The skin attachment is computed by assigning bone weights based on the proximity of the embedded bones smoothed by a diffusion equilibrium equation over the character’s surface.
Method	Our design decisions relied on three criteria, which we also used to evaluate our system:
Problem	A key design challenge is constructing a penalty function that penalizes undesirable embeddings and generalizes well to new characters.
Method	For this, we designed a maximum-margin supervised learning method to combine a set of hand-constructed penalty functions.
Method	To ensure an honest evaluation and avoid overfitting, we tested our algorithm on 16 characters that we did not see or use during development.
Result	Our algorithm computed a good rig for all but 3 of these characters.
Result	For each of the remaining cases, one joint placement hint corrected the problem.
Method	We simplify the problem by making the following assumptions.
Method	The character mesh must be the boundary of a connected volume.
Method	The character must be given in approximately the same orientation and pose as the skeleton.
Method	Lastly, the character must be proportioned roughly like the given skeleton.
Method	• An A ∗ -like heuristic to accelerate the search for an optimal skeleton embedding over an exponential search space (Section 3.4).
Method	• Use of Laplace’s diffusion equation to generate weights for attaching mesh vertices to the skeleton using linear blend skinning (Section 4).
Method	This method could also be useful in existing 3D packages.
Result	Our prototype system, called Pinocchio, rigs the given character using our algorithm.
Result	It then transfers a motion to the character using online motion retargetting [Choi and Ko 2000] to eliminate footskate by constraining the feet trajectories of the character to the feet trajectories of the given motion.
Background	Recent exceptions include Motion Doodles [Thorne et al. 2004] as well as the work of Igarashi et al. on spatial keyframing [2005b] and as-rigid-as-possible shape manipulation [2005a].
Background	These approaches focus on simplifying animation control, rather than simplifying the definition of the articulation of the character.
Background	In particular, a spatial keyframing system expects an articulated character as input, and as-rigid-as-possible shape manipulation, besides being 2D, relies on the constraints to provide articulation information.
Background	The Motion Doodles system has the ability to infer the articulation of a 2D character, but their approach relies on very strong assumptions about how the character is presented.
Background	A few approaches to the skeleton extraction problem are representative.
Background	Teichmann and Teller [1998] extract a skeleton by simplifying the Voronoi skeleton with a small amount of user assistance.
Background	Liu et al. [2003] use repulsive force fields to find a skeleton.
Background	In their paper, Katz and Tal [2003] describe a surface partitioning algorithm and suggest skeleton extraction as an application.
Background	The technique in Wade [2000] is most similar to our own: like us, they approximate the medial surface by finding discontinuities in the distance field, but they use it to construct a skeleton tree.
Problem	For the purpose of automatically animating a character, however, skeleton embedding is much more suitable than extraction.
Problem	For example, the user may have motion data for a quadruped skeleton, but for a complicated quadruped character, the extracted skeleton is likely to have a different topology.
Background	The anatomically appropriate skeleton generation by Wade [2000] ameliorates this problem by techniques such as identifying appendages and fitting appendage templates, but the overall topology of the resulting skeleton may still vary.
Background	For example, for the character in Figure 1 , ears may be mistaken for arms.
Background	Another advantage of embedding over extraction is that the given skeleton provides information about the expected structure of the character, which may be difficult to obtain from just the geometry.
Problem	So although we could use an existing skeleton extraction algorithm and embed our skeleton into the extracted one, the results would likely be undesirable.
Problem	For example, the legs of the character in Figure 1 would be too short if a skeleton extraction algorithm were used.
Background	Most of the work has been focused on human models, making use of human anatomy specifics, e.g. [Moccozet et al. 2004].
Background	For segmenting and animating simple 3D models of characters and inanimate objects, Anderson et al. [2000] fit voxel-based volumetric templates to the data.
Background	Teichmann and Teller [1998] propose a spring-based method.
Background	Unfortunately, at present, these methods are unsuitable for real-time animation of even moderate size meshes.
Background	Because of its simplicity and efficiency (and simple GPU implementation), and despite its quality shortcomings, linear blend skinning (LBS), also known as skeleton subspace deformation, remains the most popular method used in practice.
Background	Most real-time skinning work, e.g. [Kry et al. 2002; Wang et al. 2007], has focused on improving on LBS by inferring the character articulation from multiple example meshes.
Problem	However, such techniques are unsuitable for our problem because we only have a single mesh.
Problem	Instead, we must infer articulation by using the given skeleton as an encoding of the likely modes of deformation, not just as an animation control structure.
Problem	To our knowledge, the problem of finding bone weights for LBS from a single mesh and a skeleton has not been sufficiently addressed in the literature.
Background	Previous methods are either mesh resolution dependent [Katz and Tal 2003] or the weights do not vary smoothly along the surface [Wade 2000], causing artifacts on highresolution meshes.
Background	Some commercial packages use proprietary methods to assign default weights.
Background	For example, Autodesk Maya 7 assigns weights based solely on the vertex proximity to the bone, ignoring the mesh structure, which results in serious artifacts when the mesh intersects the Voronoi diagram faces between logically distant bones.
Background	Skeleton embedding resizes and positions the given skeleton to fit inside the character.
Problem	This can be formulated as an optimization problem: “compute the joint positions such that the resulting skeleton fits inside the character as nicely as possible and looks like the given skeleton as much as possible.
Problem	” For a skeleton with s joints (by “joints,” we mean vertices of the skeleton tree, including leaves), this is a 3s-dimensional problem with a complicated objective function.
Problem	Solving such a problem directly using continuous optimization is infeasible.
Method	Pinocchio therefore discretizes the problem by constructing a graph whose vertices represent potential joint positions and whose edges are potential bone segments.
Problem	This is challenging because the graph must have few vertices and edges, and yet capture all potential bone paths within the character.
Method	The graph is constructed by packing spheres centered on the approximate medial surface into the character and by connecting sphere centers with graph edges.
Method	Pinocchio then finds the optimal embedding of the skeleton into this graph with respect to a discrete penalty function.
Method	It uses the discrete solution as a starting point for continuous optimization.
Method	To help with optimization, the given skeleton can have a little extra information in the form of joint attributes: for example, joints that should be approximately symmetric should be marked as such; also some joints can be marked as “feet,” indicating that they should be placed near the bottom of the character.
Method	We describe the attributes Pinocchio uses in a supplemental document[Baran and Popović 2007a].
Method	These attributes are specific to the skeleton but are independent of the character shape and do not reduce the generality of the skeletons.
Method	Before any other computation, Pinocchio rescales the character to fit inside an axis-aligned unit cube.
Method	As a result, all of the tolerances are relative to the size of the character.
Method	It constructs a kd-tree to evaluate the exact signed distance to the surface from an arbitrary point.
Method	It then constructs the distance field from the top down, starting with a single octree cell and splitting a cell until the exact distance is within a tolerance τ of the interpolated distance.
Method	We found that τ = 0.003 provides a good compromise between accuracy and efficiency for our purposes.
Method	Because only negative distances (i.e. from points inside the character) are important, Pinocchio does not split cells that are guaranteed not to intersect the character’s interior.
Method	The medial surface is the set of C 1 discontinuities of the distance field.
Method	Within a single cell of our octree, the interpolated distance field is guaranteed to be C 1 , so it is necessary to look at only the cell boundaries.
Method	Pinocchio therefore traverses the octree and for each cell, looks at a grid (of spacing τ ) of points on each face of the cell.
Method	It then computes the gradient vectors for the cells adjacent to each grid point—if the angle between two of them is 120 ◦ or greater, it adds the point to the medial surface sample.
Method	We impose the 120 ◦ condition because we do not want the “noisy” parts of the medial surface—we want the points where skeleton joints are likely to lie.
Method	For the same reason, Pinocchio filters out the sampled points that are too close to the character surface (within 2τ ).
Background	Wade discusses a similar condition in Chapter 4 of his thesis [2000].
Method	Then it processes these points in order and if a point is outside all previously added spheres, adds the sphere centered at that point whose radius is the distance to the surface.
Method	In other words, the largest spheres are added first, and no sphere contains the center of another sphere ( Figure 3 ).
Method	In fact, this step typically takes less than 1% of the time of the entire algorithm.
Method	Pinocchio adds an edge between two sphere centers if the spheres intersect.
Method	We would also like to add edges between spheres that do not intersect if that edge is well inside the surface and if that edge is “essential.
Method	” For example, the neck and left shoulder spheres of the character in Figure 3 are disjoint, but there should still be an edge between them.
Method	The precise condition Pinocchio uses is that the distance from any point of the edge to the surface must be at least half of the radius of the smaller sphere, and the closest sphere centers to the midpoint of the edge must be the edge endpoints.
Method	The latter condition is equivalent to the requirement that additional edges must be in the Gabriel graph of the sphere centers (see e.g. [Jaromczyk and Toussaint 1992]).
Method	While other conditions can be formulated, we found that the Gabriel graph provides a good balance between sparsity and connectedness.
Method	Pinocchio precomputes the shortest paths between all pairs of vertices in this graph to speed up penalty function evaluation.
Method	The discretization stage constructs a geometric graph into which Pinocchio needs to embed the given skeleton in an optimal way.
Method	The skeleton is given as a rooted tree on s joints.
Method	To reduce the degrees of freedom, for the discrete embedding, Pinocchio works with a reduced skeleton, in which all bone chains have been merged (all degree two joints, such as knees, eliminated), as shown in Figure 5 .
Method	The reduced skeleton thus has only r joints.
Method	This works because once Pinocchio knows where the endpoints of a bone chain are in V , it can compute the intermediate joints by taking the shortest path between the endpoints and splitting it in accordance with the proportions of the unreduced skeleton.
Method	For the humanoid skeleton we use, for example, s = 18, but r = 7; without a reduced skeleton, the optimization problem would typically be intractable.
Method	Therefore, the discrete skeleton embedding problem is to find the embedding of the reduced skeleton into G, represented by an rtuple v = (v 1 , . . . , v r ) of vertices in V , which minimizes a penalty function f (v) that is designed to penalize differences in the embedded skeleton from the given skeleton.
Method	The discrete penalty function has great impact on the generality and quality of the results.
Method	A good embedding should have the proportions, bone orientations, and size similar to the given skeleton.
Method	The paths representing the bone chains should be disjoint, if possible.
Method	Joints of the skeleton may be marked as “feet,” in which case they should be close to the bottom of the character.
Method	Designing a penalty function that satisfies all of these requirements simultaneously is difficult.
Method	Instead we found it easier to design penalties independently and then rely on learning a proper weighting for a global penalty that combines each term.
Method	Pinocchio uses k = 9 basis penalty functions constructed by hand.
Method	They penalize short bones, improper orientation between joints, length differences in bones marked symmetric, bone chains sharing vertices, feet away from the bottom, zero-length bone chains, improper orientation of bones, degree-one joints not embedded at extreme vertices, and joints far along bone-chains but close in the graph [Baran and Popović 2007a].
Method	We determine the weights Γ = (γ 1 , . . . , γ k ) semi-automatically via a new maximum margin approach inspired by support vector machines.
Method	Suppose that for a single character, we have several example embeddings, each marked “good” or “bad”.
Method	The basis penalty functions assign a feature vector b(v) = (b 1 (v), . . . , b k (v)) to each example embedding v.
Method	Let p 1 , . . . , p m be the k-dimensional feature vectors of the good embeddings and let q 1 , . . . , q n be the feature vectors of the bad embeddings.
Background	See Burges [1998] for a much more complete tutorial.
Method	If our goal were to automatically classify new embeddings into “good” and “bad” ones, we could use a support vector machine to learn a maximum margin linear classifier.
Method	In its simplest form, a support vector machine finds the hyperplane that separates the p i ’s from the q i ’s and is as far away from them as possible.
Method	More precisely, if Γ is a k-dimensional vector with Γ = 1, the classification margin of the best hyperplane normal to Γ is 1 2 ` min n i=1 Γ T q i − max m i=1 Γ T p i  ́ .
Method	Recalling that the total penalty of an embedding v is Γ T b(v), we can think of the maximum margin Γ as the one that best distinguishes between the best “bad” embedding and the worst “good” embedding in the training set.
Method	In our case, however, we do not need to classify embeddings, but rather find a Γ such that the embedding with the lowest penalty f (v) = Γ T b(v) is likely to be good.
Method	To this end, we want Γ to distinguish between the best “bad” embedding and the best “good” embedding, as illustrated in Figure 6 .
Method	We therefore wish to maximize the optimization margin (subject to Γ = 1), which we define as: n m min Γ T q i − min Γ T p i .
Method	The key difference is that structured classification requires an explicit loss function (in our case, the knowledge of the quality of all possible skeleton embeddings for each character in the training set), whereas our approach only makes use of the loss function on the training labels and allows for the possibility of multiple correct labels.
Method	This possibility of multiple correct skeleton embeddings prevented us from formulating our margin maximization problem as a convex optimization problem.
Method	However, multiple correct skeleton embeddings are necessary for our problem in cases such as the hand joint being embedded into different fingers.
Method	However, an approximately optimal Γ is acceptable, and the search space dimension is sufficiently low (9 in our case) that it is feasible to use a continuous optimization method.
Method	We use the Nelder-Mead method [Nelder and Mead 1965] starting from random Γ’s.
Method	We start with a cube [0, 1] k , pick random normalized Γ’s, and run Nelder-Mead from each of them.
Method	We then take the best Γ, use a slightly smaller cube around it, and repeat.
Method	To create our training set of embeddings, we pick a training set of characters, manually choose Γ, and use it to construct skeleton embeddings of the characters.
Method	For every character with a bad embedding, we manually tweak Γ until a good embedding is produced.
Method	We then find the maximum margin Γ as described above and use this new Γ to construct new skeleton embeddings.
Method	We manually classify the embeddings that we have not previously seen, augment our training set with them, and repeat the process.
Method	For training, we used 62 different characters (Cosmic Blobs models, free models from the web, scanned models, and Teddy models), and Γ was stable with about 400 embeddings.
Method	The weights we learned resulted in good embeddings for all of the characters in our training set; we could not accomplish this by manually tuning the weights.
Method	Examining the optimization results and the extremal embeddings also helped us design better basis penalty functions.
Method	Although this process of finding the weights is labor-intensive, it only needs to be done once.
Result	According to our tests, if the basis functions are carefully chosen, the overall penalty function generalizes well to both new characters and new skeletons.
Result	Therefore, a novice user will be able to use the system, and more advanced users will be able to design new skeletons without having to learn new weights.
Method	However, if it is easy to estimate a good lower bound on f from a partial embedding (of the first few joints), it is possible to use a branch-and-bound method.
Method	Pinocchio uses this idea: it maintains a priority queue of partial embeddings ordered by their lower bound estimates.
Method	At every step, it takes the best partial embedding from the queue, extends it in all possible ways with the next joint, and pushes the results back on the queue.
Method	The first full embedding extracted is guaranteed to be the optimal one.
Method	This is essentially the A* algorithm on the tree of possible embeddings.
Method	To speed up the process and conserve memory, if a partial embedding has a very high lower bound, it is rejected immediately and not inserted into the queue.
Method	We considered adapting an approximate graph matching algorithm, like [Gold and Rangarajan 1996], which would work much faster and enable more complicated reduced skeletons.
Method	The joints of the skeleton are given in order, which induces an order on the joints of the reduced skeleton.
Method	Referring to the joints by their indices (starting with the root at index 1), we define the parent function p R on the reduced skeleton, such that p R (i) (for 1 < i ≤ r) is the index of the parent of joint i.
Method	We require that the order in which the joints are given respects the parent relationship, i.e. p R (i) < i.
Method	Our penalty function (f ) can be expressed as the sum of independent functions of bone chain endpoints (f i ’s) and a term (f D ) that incorporates the dependence between different joint positions.
Method	The dependence between joints that have not been embedded can be ignored to obtain a lower bound on f .
Method	Because of this lower bound estimate, the order in which joints are embedded is very important to the performance of the optimization algorithm.
Method	High degree joints should be embedded first because they result in more terms in the rightmost sum of the lower bound, leading to a more accurate lower bound.
Method	For example, our biped skeleton has only two joints of degree greater than two, so after Pinocchio has embedded them, the lower bound estimate includes f i terms for all of the bone chains.
Method	In such cases it is possible for the user to provide manual hints in the form of constraints for reduced skeleton joints.
Method	For example, such a hint might be that the left hand of the skeleton should be embedded at a particular vertex in G (or at one of several vertices).
Method	Embeddings that do not satisfy the constraints are simply not considered by the algorithm.
Method	Pinocchio takes the optimal embedding of the reduced skeleton found by discrete optimization and reinserts the degree-two joints by splitting the shortest paths in G in proportion to the given skeleton.
Method	The resulting skeleton embedding should have the general shape we are looking for, but typically, it will not fit nicely inside the character.
Method	Also, smaller bones are likely to be incorrectly oriented because they were not important enough to influence the discrete optimization.
Method	Embedding refinement corrects these problems by minimizing a new continuous penalty function ( Figure 7 ).
Method	For the continuous optimization, we represent the embedding of the skeleton as an s-tuple of joint positions (q 1 , . . . , q s ) in R 3 .
Method	Because we are dealing with an unreduced skeleton, and discrete optimization has already found the correct general shape, the penalty function can be much simpler than the discrete penalty function.
Method	The continuous penalty function g that Pinocchio tries to minimize is the sum of penalty functions over the bones plus an asymmetry penalty: where p S is the parent function for the unreduced skeleton (analogous to p R ).
Method	Each g i penalizes bones that do not fit inside the surface nicely, bones that are too short, and bones that are oriented differently from the given skeleton: g i = α S g i S + α L g i L + α O g i O .
Method	Unlike the discrete case, we choose the α’s by hand because there are only four of them [Baran and Popović 2007a].
Method	Any continuous optimization technique [Gill et al. 1989] should produce good results.
Method	Pinocchio uses a gradient descent method that takes advantage of the fact that there are relatively few interactions.
Method	As a subroutine, it uses a step-doubling line search: starting from a given point (in R 3s ), it takes steps in the given optimization direction, doubling step length until the penalty function increases.
Method	Pinocchio intersperses a line search in the gradient direction with line searches in the gradient direction projected onto individual bones.
Method	Repeating the process 10 times is usually sufficient for convergence.
Method	The character and the embedded skeleton are disconnected until skin attachment specifies how to apply deformations of the skeleton to the character mesh.
Method	Although we could make use of one of the various mesh editing techniques for the actual mesh deformation, we choose to focus on the standard linear blend skinning (LBS) method because of its widespread use.
Method	If v j is the position of vertex j, T i is the transformation of the i th bone, and w j i is the weight of the i th bone for vertex j, LBS gives the position of the transformed vertex j as P i w j i T i (v j ).
Method	The attachment problem is finding bone weights w i for the vertices—how much each bone transform affects each vertex.
Method	There are several properties we desire of the weights.
Method	First of all, they should not depend on the mesh resolution.
Method	Second, for the results to look good, the weights need to vary smoothly along the surface.
Method	Finally, to avoid folding artifacts, the width of a transition between two bones meeting at a joint should be roughly proportional to the distance from the joint to the surface.
Method	Although a scheme that assigns bone weights purely based on proximity to bones can be made to satisfy these properties, such schemes will often fail because they ignore the character’s geometry: for example, part of the torso may become attached to an arm.
Method	Instead, we use the analogy to heat equilibrium to find the weights.
Method	Suppose we treat the character volume as an insulated heat-conducting body and force the temperature of bone i to be 1 while keeping the temperature of all of the other bones at 0.
Method	Then we can take the equilibrium temperature at each vertex on the surface as the weight of bone i at that vertex.
Method	Solving for heat equilibrium over a volume would require tessellating the volume and would be slow.
Method	Therefore, for simplicity, Pinocchio solves for equilibrium over the surface only, but at some vertices, it adds the heat transferred from the nearest bone.
Method	It uses the precomputed distance field to determine whether a line segment is entirely contained in the character volume.
Method	For c ≈ 0.22, this method gives weights with similar transitions to those computed by finding the equilibrium over the volume.
Method	Pinocchio uses c = 1 (corresponding to anisotropic heat diffusion) because the results look more natural.
Method	When k bones are equidistant from vertex j, heat contributions from all of them are used: p j is 1/k for all of them, and H jj = kc/d(j) 2 .
Method	Equation (1) is a sparse linear system, and the left hand side matrix −∆ + H does not depend on i, the bone we are interested in.
Method	Thus we can factor the system once and back-substitute to find the weights for each bone.
Background	Botsch et al. [2005] show how to use a sparse Cholesky solver to compute the factorization for this kind of system.
Method	Pinocchio uses the TAUCS [Toledo 2003] library for this computation.
Method	Note also that the weights w i sum to 1 for each vertex: if we sum (1) over i, we get (−∆ + H) P i w i = H · 1, which yields P i w i = 1.
Method	It is possible to speed up this method slightly by finding vertices that are unambiguously attached to a single bone and forcing their weight to 1.
Background	An earlier variant of our algorithm did this, but the improvement was negligible, and this introduced occasional artifacts.
Method	We evaluate Pinocchio with respect to the three criteria stated in the introduction: generality, quality, and performance.
Method	To ensure an objective evaluation, we use inputs that were not used during development.
Method	To this end, once the development was complete, we tested Pinocchio on 16 biped Cosmic Blobs models that we had not previously tried.
Result	The skeleton was correctly embedded into 13 of these models (81% success).
Result	For Models 7, 10 and 13, a hint for a single joint was sufficient to produce a good embedding.
Result	These tests demonstrate the range of proportions that our method can tolerate: we have a well-proportioned human (Models 1–4, 8), large arms and tiny legs (6; in 10, this causes problems), and large legs and small arms (15; in 13, the small arms cause problems).
Result	For other characters we tested, skeletons were almost always correctly embedded into well-proportioned characters whose pose matched the given skeleton.
Result	Pinocchio was even able to transfer a biped walk onto a human hand, a cat on its hind legs, and a donut.
Result	Characters with extremely thin limbs often fail because the the graph we extract is disconnected.
Result	Reducing τ , however, hurts performance.
Result	• Degree 2 joints such as knees and elbows are often positioned incorrectly within a limb.
Result	We do not know of a reliable way to identify the right locations for them: on some characters they are thicker than the rest of the limb, and on others they are thinner.
Result	Although most of our tests were done with the biped skeleton, we have also used other skeletons for other characters ( Figure 10 ).
Result	Our video [Baran and Popović 2007b] demonstrates the quality of the animation produced by Pinocchio.
Result	The quality problems of our attachment are a combination of the deficiencies of our automated weights generation as well as those inherent in LBS.
Result	A common class of problems is caused by Pinocchio being oblivious to the material out of which the character is made: the animation of both a dress and a knight’s armor has an unrealistic, rubbery quality.
Result	Other problems occur at difficult areas, such as hips and the shoulder/neck region, where hand-tuned weights could be made superior to those found by our algorithm.
Result	Table 1 shows the fastest and slowest timings of Pinocchio rigging the 16 models discussed in Section 5.1 on a 1.73 MHz Intel Core Duo with 1GB of RAM.
Result	Pinocchio is single-threaded so only one core was used.
Result	We did not run timing tests on denser models because someone wishing to create real-time animation is likely to keep the triangle count low.
Result	Also, because of our volume-based approach, once the distance field has been computed, subsequent discretization and embedding steps do not depend on the given mesh size.
Result	Embedding refinement takes about 1.2 seconds for all of these models, and the discrete optimization consumes the rest of the embedding time.
Result	We have presented the first method for automatically rigging an unfamiliar character for skeletal animation.
Result	We have shown that using this method, Pinocchio can animate a wide range of characters.
Result	We also believe that some of our techniques, such as finding LBS weights and using examples to learn the weights of a linear combination of penalty functions, can be useful in other contexts.
Future Work	We have several ideas for improving Pinocchio that we have not yet tried.
Future Work	Discretization could be improved by packing ellipsoids instead of spheres.
Future Work	Although this is more difficult, we believe it would greatly reduce the size of the graph, resulting in faster and higher quality discrete embeddings.
Future Work	Animation quality can be improved with a better skinning model [Kavan and Zára ˇ 2005] (although possibly at the cost of performance).
Future Work	One approach would be to use a technique [Wang et al. 2007] that corrects LBS errors by using example meshes, which we could synthesize using slower, but more accurate deformation techniques.
Future Work	A more involved approach would be automatically building a tetrahedral mesh around the embedded skeleton and applying the dynamic deformation method of Capell et al. [2002].
Future Work	Combining retargetting with joint limits should eliminate some artifacts in the motion.
Future Work	A better retargetting scheme could be used to make animations more physically plausible and prevent global self-intersections.
Future Work	Finally, it would be nice to eliminate the assumption that the character must have a well-defined interior.
Future Work	Beyond Pinocchio’s current capabilities, an interesting problem is dealing with hand animation to give animated characters the ability to grasp objects, type, or speak sign language.
Future Work	The variety of types of hands makes this challenging (see, for example, Models 13, 5, 14, and 11 in Figure 9 ).
Future Work	Automatically rigging characters for facial animation is even more difficult, but a solution requiring a small amount of user assistance may succeed.
Future Work	Combined with a system for motion synthesis [Arikan et al. 2003], this would allow users to begin interacting with their creations.

Problem	There are many applications that demand large quantities of natural looking motion.
Problem	It is difficult to synthesize motion that looks natural, particularly when it is people who must move.
Result	In this paper, we present a framework that generates human motions by cutting and pasting motion capture data.
Method	Selecting a collection of clips that yields an acceptable motion is a combinatorial problem that we manage as a randomized search of a hierarchy of graphs.
Method	This approach can generate motion sequences that satisfy a variety of constraints automatically.
Result	The motions are smooth and human-looking.
Result	They are generated in real time so that we can author complex motions interactively.
Result	The algorithm generates multiple motions that satisfy a given set of constraints, allowing a variety of choices for the animator.
Result	It can easily synthesize multiple motions that interact with each other using constraints.
Result	This framework allows the extensive re-use of motion capture data for new purposes.
Background	Motion is one of the most important ingredients of CG movies and computer games.
Background	Obtaining realistic motion usually involves key framing, physically based modelling or motion capture.
Problem	Creating natural looking motions with key framing requires lots of effort and expertise.
Problem	Although physically based modelling can be applied to simple systems successfully, generating realistic motion on a computer is difficult, particularly for human motion.
Background	A standard solution is motion capture: motion data for an approximate skeletal hierarchy of the subject is recorded and then used to drive a reconstruction on the computer.
Background	This allows other CG characters to be animated with the same motions, leading to realistic, “human looking” motions for use in movies or games.
Problem	Most motion capture systems are very expensive to use, because the process is time consuming for actors and technicians and motion data tends not to be re-used.
Problem	It is very hard to obtain motions that do exactly what the animator wants.
Problem	Satisfying complex timed constraints is difficult and may involve many motion capture iterations.
Problem	Examples include being at a particular position at a particular time accurately or synchronizing movement to a background action that had been shot before.
Problem	In order to make motion capture widely available, the motion data needs to be made re-usable.
Problem	This may mean using previous motion capture data to generate new motions so that certain requirements are met, transferring motions from one skeletal configuration to another so that we can animate multiple figures with the same motion without it looking “funny”, or changing the style of the motion so that the directors can have higher level control over the motion.
Background	Obtaining motion demands involves specifying constraints on the motion, such as the length of the motion, where the body or individual joints should be or what the body needs to be doing at particular times.
Background	These constraints can come from an interactive editing system used by animators, or from a computer game engine itself.
Background	Generating motion involves obtaining a rough motion that satisfies the demands.
Problem	In this paper, we describe a technique that cuts and pastes bits and pieces of example motions together to create such a motion.
Background	Post processing involves fixing small scale offensive artifacts.
Background	An example would involve fixing the feet so that they do not penetrate or slide on the ground, lengthening or shortening strides and fixing constraint violations.
Problem	In this paper, we present a framework that allows synthesis of new motion data meeting a wide variety of constraints.
Method	The synthesized motion is created from example motions at interactive speeds.
Background	In the movie industry, motion demands are usually generated by animators.
Background	However, automatic generation of motion demands is required for autonomous intelligent robots and characters [Funge et al. 1999].
Background	An overview of the automatic motion planning can be found in [Latombe 1999; O’Rourke 1998].
Background	Generating motion largely follows two threads: using examples and using controllers.
Background	Example based motion synthesis draws on an analogy with texture synthesis where a new texture (or motion) that looks like an example texture (or motion example) needs to be synthesized [Efros and Leung 1999; Heeger and Bergen 1995].
Background	Pullen and Bregler used this approach to create cyclic motions by sampling motion signals in a “signal pyramid” [2000].
Background	They also used a similar approach to fetch missing degrees of freedom in a motion from a motion capture database [Pullen and Bregler 2002].
Background	The sampling can also be done in the motion domain to pick clips of motions to establish certain simple constraints [Lamouret and van de Panne 1996; Schodl et al. 2000].
Background	A roadmap of all the motion examples can be constructed and searched to obtain a desired motion [Choi et al. 2000; Lee et al. 2002; Kovar et al. 2002].
Background	The clips in this roadmap can also be parameterized for randomly sampling different motion sequences [Li et al. 2002].
Background	The motion signals can also be clustered.
Background	The resulting Markov chain can be searched using dynamic programming to find a motion that connects two keyframes [Molina-Tanco and Hilton 2000] or used in a variable length Markov model to infer behaviors [Galata et al. 2001] or directly sampled from to create new motions [Bowden 2000].
Background	This is similar to our work.
Method	However, our clustering method does not operate on body configurations and our probabilistic search strategy is more effective than dynamic programming as it will be explained below.
Background	Types of probabilistic search algorithms have also been used in physically based animation synthesis [Chenney and Forsyth 2000] and rendering [Veach and Guibas 1997].
Background	Controller based approaches use physical models of systems and controllers that produce outputs usually in the form of forces and torques as a function of the state of the body.
Background	These controllers can be designed specifically to accomplish particular tasks [Brogan et al. 1998; Hodgins et al. 1995] or they can be learned automatically using statistical tools [Grzeszczuk and Terzopoulos 1995; Grzeszczuk et al. 1998; Mataric 2000].
Background	The motion data can also be post processed to fix problems such as feet sliding on the ground or some constraints not being satisfied [Gleicher 1998; Lee and Shin 1999; Popovic 1999; Rose et al. 1996].
Background	This usually involves optimization of a suitable displacement function on the motion signal.
Background	Different body sizes move according to different time scales, meaning that motion cannot simply be transferred from one body size to another; modifying motions appropriately is an interesting research problem [Hodgins and Pollard 1997].
Method	We assume there is a set of N motion sequences forming our dataset, each belonging to the same skeletal configuration.
Method	Every motion is discretely represented as a sequence of frames each of which has the same M degrees of freedom.
Method	This is required to be able to compare two motions and to be able to put clips from different motion sequences together.
Method	We write the i’th frame of s’th motion as s i .
Method	The collection of motion sequences could be represented as a directed graph.
Method	Each frame would be a node.
Method	There would be an edge from every frame to every frame that could follow it in an acceptable splice.
Method	In this graph, there would be (at least) an edge from the k’th frame to the k + 1’th frame in each sequence.
Method	This graph is not a particularly helpful representation because it is extremely large — we can easily have tens of thousands of nodes and hundreds of thousands of edges — and it obscures the structure of the sequences.
Method	Instead, we collapse all the nodes (frames) belonging to the same motion sequence together.
Method	This yields a graph G where the nodes of G are individual motion sequences and there is an edge from s to t for every pair of frames where we can cut from s to t.
Method	Since edges connect frames, they are labelled with the frames in the incident nodes (motion sequences) that they originate from and they point to.
Method	We also assume that the edges in G are attached a cost value which tells us the cost of connecting the incident frames.
Method	If cutting from one sequence to another along an edge introduces a discontinuous motion, then the cost attached to the edge is high.
Method	The collapsed graph still has the same number of edges.
Method	For an edge e from s i to t j , let f romMotion(e) = s, toMotion(e) = t, f romFrame(e) = i, toFrame(e) = j and cost(e) be the cost associated with the edge (defined in Appendix A).
Method	In this setting, any sequence of edges e 1 · · · e n where toMotion(e i ) = f romMotion(e i+1 ) and toFrame(e i ) < f romFrame(e i+1 ), ∀i, 1≤i < n is a valid path and defines a legal sequence of splices.
Method	We wish to construct paths in the motion graph that satisfy constraints.
Method	Many constraints cannot be satisfied exactly.
Method	For example, given two positions, there may not be any sequence of frames in the collection that will get us from the first position to the second position exactly.
Method	We define hard constraints to be those that can (and must) be satisfied exactly.
Method	Typically, a hard constraint involves using a particular frame in a particular time slot.
Method	For example, instead of considering all valid paths, we can restrict ourselves to valid paths that pass through particular nodes at particular times.
Method	This way, we can constrain the moving figure to be at a specific pose at a specific time.
Method	This enables us to search for motions such as jumping, falling, or pushing a button at a particular time.
Method	A soft constraint cannot generally be met exactly.
Method	Instead we score sequences using an objective function that reflects how well the constraint has been met and attempt to find extremal sequences.
Method	One example is the squared distance between the position of the constraint and the actual position of the body at the time of the constraint.
Method	The total number of frames should be a particular number.
Method	The motion should not penetrate any objects in the environment.
Method	The body should be at a particular position and orientation at a particular time.
Method	A particular joint should be at a particular position (and maybe having a specific velocity) at a specific time.
Method	The motion should have a specified style (such as happy or energetic) at a particular time.
Method	Finding paths in the motion graph that satisfy the hard constraints and optimize soft constraints involves a graph search.
Method	Unfortunately, for even a small collection of motions, the graph G has a large number of edges and straightforward search of this graph is computationally prohibitive.
Method	The main reason is the need to enumerate many paths.
Method	There are, in general, many perfectly satisfactory motions that satisfy the constraints equally well.
Method	For example, if we require only that the person be at one end of a room at frame 0 and near the other end at frame 5000, unless the room is very large, there are many motions that satisfy these constraints.
Method	The motion graph is too hard to search with dynamic programming as there are many valid paths that satisfy the constraints equally well.
Method	There may be substantial differences between equally valid paths — in the example above, whether you dawdle at one side of the room or the other is of no significance.
Method	This suggests summarizing the graph to a higher level and coarser presentation that is easier to search.
Method	Branch and bound algorithms are of no help here, because very little pruning is possible.
Method	In order to search the graph G in practical times, we need to do the search at a variety of levels where we do the large scale motion construction first and then “tweak” the details so that the motion is continuous and satisfies the constraints as well as possible.
Method	Coarser levels should have less complexity while allowing us to explore substantially different portions of the path space.
Method	In such a representation, every level is a summary of the one finer level.
Method	Let G ← G ← G ← · · · ← G n ← G be such a hierarchical representation where G is the coarsest level and G is the finest.
Method	We will first find a path in G and then push it down the hierarchy to a path in G for synthesis.
Method	All the edges between two nodes s and t can be represented in a matrix P st .
Method	The (i, j)’th entry of P st contains the weight of the edge connecting s i to t j and infinity if there is no such edge.
Method	In the appendix A, we give one natural cost function C(s i ,t j ) for edge weights.
Method	We now have: (P st ) i j = C(s ∞ i ,t j ) otherwise.
Method	if there is an edge from s i to t j The cost function explained in section A causes the P matrices to have non-infinite entries to form nearly elliptical groups ( figure 2 ).
Method	This is due to the fact that if two frames are similar, most probably their preceding and succeeding frames also look similar.
Method	We require that, if there is a cut between two sequences represented by an edge between two nodes in G, there be at least one edge between the corresponding nodes in G .
Method	If this were not the case, our summary would rule out potential paths.
Method	In order to insure that this condition holds and because the graph is very large, we cluster edges connecting every pair of nodes in G separately.
Method	We cluster unconnected edge groups of G from the P matrices (defined between every pair of nodes) using k-means ma joraxislength [Bishop 1995].
Method	The number of clusters is chosen as minoraxislength for each group where the axis lengths refer to the ellipse that fits to the cluster (obtained through Principal Component Analysis).
Method	Thus, in our summarized graph G , each edge is the root of a binary tree and represents all the edges in close neighborhood in terms of the edge labels.
Method	Note that the leaf edges are the edges in the original graph and intermediate edges are the averages of all the leaf edges beneath them.
Method	A path in G represents a sequence of clips; so does a path in G , but now the positions of the clip boundaries are quantized, so there are fewer paths.
Method	While searching this graph, we would like to be able to generate different alternative motions that achieve the same set of constraints.
Method	During the search, we need to find paths close to optimal solutions but do not require exact extrema, because they are too hard to find.
Method	This motivates a random search.
Method	We used the following search strategy:
Method	Start with a set of n valid random “seed” paths in the graph G 2.
Method	Score each path and score all possible mutations 3.
Method	(b) Delete some edges of the path and replace them with their children 4.
Method	Accept the mutations that are better than the original paths 5.
Method	Include a few new valid random “seed” paths 6.
Method	Since we start new random “seed” paths at every iteration, the algorithm does not get stuck at a local optimum forever.
Method	Hard constraints are easily dealt with; we restrict our search to paths that meet these constraints.
Method	Typically hard constraints specify the frame (in a particular node) to be used at a particular time.
Method	We do this by ensuring that “seed” paths meet these constraints, and mutations do not violate them.
Method	This involves starting to sample the random paths from the hard constraint nodes and greedily adding sequences that get us to the next hard constraint if any.
Method	Since the path is sampled at the coarse level, a graph search can also be performed between the constraint nodes.
Method	At every iteration we check if the proposed mutation deletes a motion piece that has a hard constraint in it.
Method	Such mutations are rejected immediately.
Method	Note that here we assume the underlying motion graph is connected.
Background	Notice that this algorithm is similar to MCMC search (a good broad reference to application of MCMC is [Gilks et al. 1996]).
Method	However, it is difficult to compute proposal probabilities for the mutations we use, which are strikingly successful in practice.
Method	This is an online algorithm which can be stopped at anytime.
Method	This is due to the fact that edges in intermediate graphs G · · · G n also represent connections and are valid edges.
Method	Thus we do not have to reach the leaf graph G to be able to create a path (motion sequence).
Method	We can stop the search iteration, take the best path found so far, and create a motion sequence.
Method	If the sequence is not good enough, we can resume the search from where we left off to get better paths through mutations and inclusion of random paths.
Method	This allows an intuitive computation cost vs. quality tradeoff.
Method	Since during the search all the paths live in a subspace implied by the hard constraints, these constraints are always satisfied.
Method	Given a sequence of edges e 1 · · · e n , we score the path using the imposed soft constraints.
Method	For each constraint, we compute a cost where the cost is indicative of the satisfaction of the constraint.
Method	Based on the scores for each of the constraints, we weight and sum them to create a final score for the path (The S function in equation 1).
Method	We also add the sum of the costs of the edges along the path to make sure we push the search towards paths that are continuous.
Method	The weights can be manipulated to increase/decrease the influence of a particular soft constraint.
Method	We now have an expression of the form:
Method	Where w c ,w f ,w b and w j are weights for the quality (continuity) of the motion, how well the length of the motion is satisfied, how well the body constraints are satisfied and how well the joints constraints are defined.
Method	We selected these weights such that an error of 10 frames increases the total score the same amount as an error of 30 centimeters in position and 10 degrees in orientation.
Method	F: For the number of frame constraints, we compute the squared difference between the actual number of frames in the path and the required number of frames.
Method	B: For body constraints, we compute the distance between the position and orientation of the constraint versus the actual position and orientation of the torso at the time of the constraint and sum the squared distances.
Method	The position and orientation of the body at the constraint times are found by putting the motion pieces implied by the subsequent edges together ( figure 1 ).
Method	This involves taking all the frames of motion toMotion(e i ) between frames f romFrame(e i+1 ) and toFrame(e i ) and putting the sequence of frames starting from where the last subsequence ends or from the first body constraint if there is no previous subsequence.
Method	Note that we require that we have at least two body constraints enforcing the position/orientation of the body at the beginning of the synthesized motion (so that we know where to start putting the frames down) and at the end of the synthesized motion.
Method	The first body constraint is always satisfied, because we always start putting the motions together from the first body constraint.
Method	J: For joint constraints, we compute the squared distance between the position of the constraint and the position of the constrained joint at the time of the constraint and sum the squared distance between the two.
Method	To determine the configuration of the body at the time at which the constraint applies, we must assemble the motion sequence up to the time of the constraint; in fact, most of the required information such as the required transformation between start and end of each cut is already available in the dataset.
Method	We implemented two types of mutations which can be performed quickly on an active path.
Method	Replace a sequence by selecting two edges e i and e i+ j where 0 ≤ j ≤ n − i, deleting all the edges between them in the path and connecting the unconnected pieces of the path using one or two edges in the top level graph G (if possible).
Method	Since in the summarized graph, there are relatively fewer edges, we can quickly find edges that connect the two unconnected nodes by checking all the edges that go out from toMotion(e i ), and enumerating all the edges that reach to f romMotion(e i+ j ) and generate a valid path.
Method	Note that we enumerate only 0 or 1 hop edges (1 edge or 2 edge connections respectively).
Method	Demoting two edges to their children and replacing them with one of their children if they can generate a valid path.
Method	Doing this mutation on two edges simultaneously allows us to compensate for the errors that would happen if only one of them was demoted.
Method	We check every possible mutation, evaluate them and take the best few.
Method	Since the summary has significantly fewer edges than the original graph, this step is not very expensive.
Method	If a motion sequence cannot generate a mutation whose score is lower that itself, we decide that the current path is a local minimum in the valid path space and record it as a potential motion.
Method	This way, we can obtain multiple motions that satisfy the same set of constraints.
Method	We create the final motion by taking the frames between toFrame(e i ) and f romFrame(e i+1 ) from each motion toMotion(e i ) where 1 ≤ i < n ( figure 1 ).
Method	This is done by rotating and translating every motion sequence so that each piece starts from where the previous one ended.
Method	In general, at the frames corresponding to the edges in the path, we will have C 0 discontinuities, because of the finite number of motions sampling an infinite space.
Method	In practice these discontinuities are small and we can distribute them within a smoothing window around the discontinuity.
Method	We do this by multiplying the magnitude of the discontinuity by a smoothing function and adding the result back to the signal ( figure 4 ).
Method	We choose the smoothing domain to be ±30 frames (or one second of animation) around the discontinuity and
Method	To make sure that we interpolate the body constraints (i.e. having a particular position/orientation at a particular frame), we take the difference between the desired constraint state, subtract the state at the time of the constraint and distribute this difference uniformly over the portion of the motion before the time of the constraint.
Method	Note that these “smoothing” steps can cause artifacts like feet penetrating or sliding on the ground.
Method	However, usually the errors made in terms of constraints and the discontinuities are so small that they are unnoticeable.
Method	Using iterative improvements of random paths, we are able to synthesize human looking motions interactively.
Method	This allows interactive manipulation of the constraints.
Method	This is important, because motion synthesis is inherently ambiguous as there may be multiple motions that satisfy the same set of constraints.
Method	The algorithm can find these “local minimum” motions that adhere to the same constraints.
Method	The animator can choose between them or all the different motions can be used to create a variety in the environment.
Method	Since the algorithm is interactive, the animator can also see the ambiguity and guide the search by putting extra constraints ( figure 6 ).
Method	Currently, we can constrain the length of the motion, the body’s position and orientation at a particular frame ( figure 5 ,6), a joint (e.g. head, hand) to a particular state at a particular frame ( figure 7 ), or constrain the entire body’s pose at a particular frame (figure 8).
Method	Notice that we can synthesize multiple interacting motions independently using hard constraints ( figure 9 ); we simply select the poses, position and orientation at which the figures interact and this framework fills in the missing motion, in a sense, interpolating the constraints.
Method	These are only a few of the constraints that can be implemented.
Method	As long as the user specifies a cost function that evaluates a motion and attaches a score that is indicative of the animator’s satisfaction with the path, many more constraints can be implemented.
Method	For example, if the motions in our database are marked with their individual stylistic attributes, we can also constrain the style of the desired motion by penalizing motions that do not have the particular style.
Method	In a computer game environment, we can constrain the synthesized motion to avoid obstacles in the environment.
Method	In such a case, body position/orientation constraints can also come from an underlying path planner.
Method	Thus, given high level goals (such as going from point A to point B, say) human looking motions can be generated automatically.
Result	We have presented a framework that allows interactive synthesis of natural looking motions that adhere to user specified constraints.
Method	We assess our results using four criteria.
Result	Firstly, the motion looks human.
Result	Secondly, the motions generated by the method do not have unnatural artifacts such as slipping feet on the ground or jerky movement.
Result	Third, the user specified constraints are satisfied, i.e. the motion passes through the required spot at the required time, or the character falls to a particular position ( figure 8 ).
Result	Finally, motions are generated interactively — typically depending on the quality of the path desired, an acceptable 300 frame motion is found in between 3 and 10 seconds on an average PC (Pentium III at 800 Mhz).
Result	This speed allows interactive motion authoring.
Method	For example, we generated the real-time screen captures in the attached video using a dataset of 60-80 unorganized, short (below 300 frames each) motion capture fragments.
Result	The average precomputation time required for this many motions (computing the motion graph) is 5 hours on the same computer.
Result	On average, the results shown in the video contain 3-30 motion pieces cut from the original motions.
Result	This framework is completely automatic.
Result	Once the input motions are selected, the computation of the hierarchic motion graph does not require any user intervention and the resulting representation is searched in real-time.
Result	For many kinds of constraints the motion synthesis problem is underconstrained; there are many possible combinations of motion pieces that achieve the same set of constraints.
Result	Randomized search is well suited to find many different motions that satisfy the constraints.
Result	On the other hand, some constraints, may not be met by any motion.
Result	In this case, randomized search will try to minimize our objective motion and find the “closest” motion.
Method	For example, if the user asks for 100 meters in 5 seconds, the algorithm will tend to put fast running motions together but not necessarily satisfying the constraints.
Method	Similarly, if the set of motions to begin with do not form a connected graph, the algorithm will perform searches confined to the unconnected graphs.
Result	If there are hard constraints in different unconnected components, we will not even be able to find starting seed paths.
Result	From this perspective, the selection of the database to work with is important.
Method	In our system, we used 60-100 football motions that have a strong bias towards motions that run forward.
Result	However, as the attached video suggest, the randomized search has no problem finding rare motions that turn back to satisfy the constraints.
Method	The motion databases that we used were unorganized except that we excluded football warming up and tackling motions unless they were desired ( figure 9 ).
Result	The randomized search scales linearly as a function of the database size with a very small constant.
Result	We have tried datasets of 50-100 motions without a noticeable change in the running time of the algorithm.
Result	The linearity in the running time comes from the linear increase in the number of alternative mutations at every step.
Result	Note that as the database size gets larger, the constant τ (Appendix A) that is used to create the edges can get lower since more motions mean that we expect to find better connections between motions, decreasing the number of edges.
Result	This will lead to a sublinear increase in the running time.
Result	The framework can work on any motion dataset: it can be created by traditional key framing, physically based modelling or motion capture.
Result	For example, we can take the motion data for “Woody” – who may well have been key-framed, from “Toy Story” and create new “Woody” motions automatically.
Result	The framework is also appli- cable to non-human motion synthesis.
Result	For example, this framework can be used to generate control signals for robots to achieve a particular task by generating the motion graph for previously known motion-control signal pairs.
Result	During the synthesis we can not only synthesize the final robot motion but also the associated control signals that achieve specific goals.
Result	Since the generated motions are obtained by putting pieces of motions in the dataset, the resulting motions will also carry the underlying style of the data.
Result	This way, we can take the motion data for one character, and produce more motions with the intrinsic style of the character.
Future Work	During the construction of the final motion, better ways of smoothing between adjacent motions could be used to improve realism [Popovic 1999].
Future Work	Using better post processing, motions could also be synthesized on non-uniform surfaces which the current framework cannot handle.
Future Work	Additional post processing may involve physically based modelling to make sure the synthesized motions are also physically correct.
Future Work	Automatic integration of higher level stylistic constraints could be incorporated into the framework, avoiding the arduous job of labelling every motion with the intrinsic style by hand.
Future Work	By analyzing patterns in the motion dataset, we might also infer these styles or obtain higher level descriptions [Brand and Hertzmann 2001].
Result	The synthesized motions are strictly bound to the motions that were available in the original dataset.
Future Work	However, it is conceivable that the motions that are very close to the dataset could also be incorporated in the synthesizable motions using learned stylistic variations.
Result	The integrity of the original dataset directly effects the quality of the synthesized motion.
Result	For example, if the incoming motion dataset does not contain any “turning left” motions, we will not be able to synthesize motions that involve “turning left”.
Future Work	An automatic way of summarizing the portions of the “possible human motions” space that have not been explored well enough by the dataset could improve the data gathering and eventually the synthesized motions.
Future Work	This could also serve as a palette for artists: some portions of the precomputed motion graph can be paged in and out of memory depending on the required motion.
Future Work	For example, the animator could interactively select the motions that need to be used during the synthesis, and only the portion of the motion graph involving the desired motions could be loaded.
Future Work	This would give animators a tool whereby they can select the set of motions to work with in advance and the new motions will be created only from the artist selected set.
Future Work	Furthermore this encourages comprehensive re-use of motion data.
Method	We define the torso coordinate frame to be the one where the body stands centered at origin on the xz plane and looks towards the positive z axis.
Method	Any point p in the torso coordinate frame can be transformed to the global coordinate frame by T (s i ) + R(s i ) · p , where T (s i ) is the 3 × 1 translation of the torso and R(s i ) is the 3 × 1 rotation of the torso and R(s i ) represents the rotation matrix associated with the rotation.
Method	We wish to have a weight on edges of the motion graph (section 3.1) that encodes the extent to which two frames can follow each other.
Method	If the weight of an edge is too high, it is dropped from the graph.
Method	To compute the weight of an edge, we use the difference between joint positions and velocities and the difference between the torso velocities and accelerations in the torso coordinate frame.
Method	Let P(s i ) be a 3 × n matrix of positions of n joints for s i in torso coordinate frame.
Method	We then define the normalizing matrices O and L in equation 3 and 4.
Method	Then the cost function function in equation 5 is used to relate s i to t j .
Method	Where diagonal (n + 2) × (n + 2) matrices M and T are used to weight different joints differently.
Method	For example, position differences in feet are much more noticeable than position differences of hands because the ground provides a comparison frame.
Method	We have found M and T matrices empirically by trying different choices.
Method	Unfortunately, defining a universal cost metric is a hard problem.
Result	The metric defined above produces visually acceptable results.
Method	Using this cost metric, we create edges from s i to t j where C(s i ,t j ) < τ .
Method	For an edge e from s i to t j , we set cost(e) = C(s i ,t j ).
Method	Note that an error that is visible on a short person may not be visible on an extremely large person.
Method	Thus, in theory, the weights must be adjusted from person to person.
Method	However, in practice, possible size variation of adult people is small enough that we used the same weights for different people without creating a visible effect.

Result	This paper describes a method to simulate realistic wrinkles on clothes without fine mesh and large computational overheads.
Background	Cloth has very little in-plane deformations, as most of the deformations come from buckling.
Background	This can be looked at as area conservation property of cloth.
Method	The area conservation formulation of the method modulates the user defined wrinkle pattern, based on deformation of individual triangle.
Result	The methodology facilitates use of small in-plane deformation stiffnesses and a coarse mesh for the numerical simulation, this makes cloth simulation fast and robust.
Result	Moreover, the ability to design wrinkles (even on generalized deformable models) makes this method versatile for synthetic image generation.
Result	The method inspired from cloth wrinkling problem, being geometric in nature, can be extended to other wrinkling phenomena.
Background	Wrinkles add life to garments in fashion.
Problem	In order to capture realistic wrinkles on a real-life garment, from a mere geometric point of view, the number of triangles required can be easily upto a hundred thousand.
Problem	Such a large number of triangles put cloth simulation off from interactive speeds, even with adaptive time steps, introduced recently [ 1 ].
Problem	Apart from simulation time, the large triangle count increases the rendering time and the cost significantly.
Problem	In order to avoid these, one can increase fineness of triangles only in the potential regions where wrinkling might occur.
Problem	This is very well possible due to advances in the triangulation and interactive systems developed [ 2 , 7 , 8 , 13 ].
Problem	Even then, a significant problem remains: how to estimate the regions and the orientations of wrinkles.
Background	Cloth has very large in-plane deformation stiffnesses compared to its ability to bend and shear.
Problem	This gives rise to very stiff equations of motion.
Background	The problem of solving stiff equations is successfully dealt with by the use of an implicit method for numerical integration by Baraff et al[ 1 ].
Problem	Here, though the problem of stiff equations has been tackled, it has been the strong motivation for the authors behind developing the methodology specifically for wrinkles.
Problem	Even if one wishes to have a fine triangular mesh, using robust and fast numerical solvers and having patience for long computations, it is not guaranteed that the wrinkles will be satisfactory.
Background	Accurate and fast collision detection methods[ 12 ], constraint methods[ 5 , 6 ] and good deformable models[ 6 , 9 , 10 ] have proved to give quality cloth animation.
Problem	However, real-life wrinkling is a complex phenomenon.
Problem	It is characterized by frictional forces (especially between body and cloth) which are difficult to model.
Background	Collision response methods and friction models developed so far have been rather simple for such a complex problem and robust numerics too.
Method	We take a geometric and texture based approach to wrinkling.
Method	As it is difficult to physically simulate real life wrinkles, the user designs them interactively as a bump map on a coarse mesh cloth/garment.
Method	It is then animated by modulating it as per cloth deformation.
Method	The key theme is conservation of cloth area.
Background	The work is continuation of earlier work [ 11 ].
Background	Other attempts to model wrinkles include those by Gotoda et al [ 3 , 4 ] and Wu et al [ 14 ].
Problem	We would like to animate the cloth using coarse triangular mesh (typically a few thousand triangles per garment), for the reasons mentioned in the Introduction.
Background	Real cloth has very little in-plane deformation as most of the deformations come from buckling.
Problem	For the coarse mesh, setting high metric (in-plane deformation) stiffnesses will not work properly.
Background	Real cloth would wrinkle to this deformation (see typical wrinkles in Figure 3A ).
Background	Consider an edge of a triangle, as shown in Figure 3B .
Background	In reality, the compression forces will buckle the edge as shown by dotted line.
Background	As the bending stiffness of the cloth is small, the buckled edge exerts small forces on the vertices.
Problem	However, in the coarse mesh situation, the buckled edge is approximated by a straight line between the vertices.
Problem	Consequently, the real life buckling is attributed to the compression of the edge.
Method	If we assume a high metric stiffness associated to this compression, the corresponding forces on the vertices will be high.
Problem	This is in contrast with real cloth situation.
Method	Thus, to animate the cloth realistically with a coarse mesh, we need to set small metric stiffnesses.
Method	This allows otherwise possible wrinkling/buckling which is embedded in the deformation of triangle.
Method	Very little in-plane deformations can be looked at as area conservation property of cloth.
Problem	We propose to capture gross cloth movements and deformations using a coarse mesh and the fine deformations (wrinkles) using a bump map (or a displacement map).
Method	Let us assume the wrinkle pattern is given by the user.
Method	We will try to modulate the amplitude of the wrinkle pattern such that, though there is a change in the area of a triangle (with the displacement map), it is invariant after applying the modulated displacement map.
Method	The method is inspired by the area conservation property, even though Section 3.3 points out that the empiricism introduced later does not actually conserve the area.
Method	First, let us state what serves as an input to the algorithm.
Method	We start with a user defined wrinkle pattern, which is given in the form of a texture and an initial undeformed triangular mesh in 3D space.
Method	This mesh may represent a garment or another deformable model.
Method	The wrinkle pattern is bump or displacement mapped onto the initial mesh by the user.
Method	Thus, we obtain a static wrinkled garment.
Method	Note that the texture mapping coordinates do not change throughout the computations described below.
Method	By introducing a fixed scale for the displacement or bump map on a mesh triangle, we obtain a function which, we call the wrinkle function.
Method	Using these inputs in step 1 (refer to Figure 5 ), the algorithm computes a set of four parameters termed wrinkling coefficients for each triangle of the mesh.
Method	The initial mesh serves as an input to a simulation engine, which in the context of cloth simulation would be the physical model with a numerical solver.
Method	The mesh that is the output by the simulation engine will be the deformed mesh.
Method	This deformed mesh is then further processed by the proposed algorithm.
Method	For each triangle, we compute the deformation transformation that relates the corresponding triangle of the initial and the deformed mesh.
Method	Using this deformation transformation and the already computed wrinkling coefficients, we compute the modulation factors.
Method	These modulation factors are used to compute a modulation map which modulates the wrinkle pattern.
Method	The modulated wrinkle pattern, which reflects the response of the wrinkled surface to the deformation of the underlying coarse triangular mesh, is used for the rendering.
Method	In the course of animation, as the simulation engine recalculates the deformed mesh, the procedure described above is iterated.
Method	However, note that the wrinkling coefficients need not to be recalculated during the animation.
Method	They are constant with respect to the animation process.
Method	They depend only on the initial wrinkle pattern, the initial mesh and the mapping coordinates.
Method	The deformation of the triangle can be described by a general 4D homogeneous coordinate transformation.
Method	However, the rotational and translational parts of the transformation are irrelevant to the derivation of the algorithm.
Method	We introduce a local rectangular right handed two dimensional coordinate system, which is defined by choosing any edge of the triangle as the x axis ( refer to Figure 5 ).
Method	Hence, x, y denote the local coordinates of the initial triangle and x , y that of the deformed triangle .
Method	The matrix elements a and d represent scaling in the x and y direction respectively, whereas b describes a shear.
Method	We define the wrinkle function f (x, y) as the function in the coordinate system xy that results from mapping the wrinkle pattern onto the initial triangular mesh.
Method	Further we require f (x, y) to be continuous and that its first partial derivatives exist and also be continuous.
Method	Note that this is a purely geometric requirement.
Method	One might think of several different approaches to meet this requirement.
Method	Our approach realizes overall area conservation by achieving area conservation on a per triangle basis of the mesh.
Method	We parameterize the area of the deformed triangle by h, that scales f (x , y ) on each triangle of the mesh.
Method	This is an equation for h, which we call modulation factor.
Method	The constants C 1 , C 2 , C 3 , C 4 are here after referred as wrinkling coefficients.
Method	The wrinkling coefficients on the other hand, are computationally expensive.
Method	However, as one can see from equation 11 in Appendix A, they depend only on quantities that are known prior to entering the animation loop and can therefore be calculated once at the beginning.
Method	• As we have pointed out in the discussion so far, we have derived an algorithm that is based on the area conservation property.
Method	Here we explain the role played by the area conservation property in our work.
Result	From a mathematical point of view, it is clear that we have presented a solution within the approximation of small deformations.
Method	There are several possibilities to deal with this restriction.
Method	One could decide to restrict the simulations to small deformations where the approximation is valid and/or take into account the higher order terms in the series expansion to extend the range of validity of the approximation.
Method	Instead, we propose a pragmatic approach.
Method	This frees us conceptually from the “burden of mathematical correctness”.
Method	This is because, we are more concerned with the visual results of the animation, rather than precise area conservation.
Method	Moreover, the deformations during cloth simulation are moderate in general.
Method	Hence, higher order terms in the expansion may become significant but not predominant.
Method	The modulation factor h is a function of the deformation of triangle and has value around one.
Method	If the triangle is net compressed, h will be greater than one.
Method	For the elongation, it will be less than one.
Method	One can scale, translate and clip it to introduce a finer control required for the animation.
Method	Note that this transformation of the modulation factor no longer satisfies the area conservation property.
Method	• Another very important property of our algorithm is that it is local.
Method	By local, we mean that wrinkling effects caused by deformations are confined to the deformed areas.
Method	This is crucial to obtain realistic wrinkling.
Method	For example, a garment wrinkles around the shoulder of an animated character as she lifts her arm, while it is stretched on the corresponding side.
Method	Locality is introduced in our algorithm by working on a per triangle basis.
Method	The size of the mesh triangles actually governs the extension of local wrinkling effects.
Method	• Wrinkling coefficients are sensitive to the wrinkle function and therefore to the wrinkle patterns.
Method	Wrinkling coefficients for two different patterns on the same triangle will generally differ.
Method	Therefore, the same deformation applied to a triangle will yield two different modulation factors (one for each pattern).
Method	Each pattern, for instance, features a “principal wrinkling direction”.
Method	Assume that the wrinkling patterns are orthogonal to each other.
Method	Then, a deformation in the orthogonal direction of one pattern will result in a smaller modulation factor as compared to a modulation factor for the other pattern.
Method	In other words, the direction of the deformation “favors one pattern over the other”.
Method	This property can be used for developing multi-fold wrinkling techniques.
Method	The numerical computation of the formulation is trivial.
Method	For the numerical integrals of the wrinkling coefficients, we use adaptive sampling in the triangular domain to give a fixed user defined error.
Method	The following issues are worth mentioning about the implementation.
Method	The wrinkle function and the wrinkle pattern, though referred to as the same entity, they differ in implementation.
Method	The wrinkle pattern is gray scale texture image defining the bump map.
Method	The user defines an overall normalization factor for the texture to map wrinkle pattern to wrinkle function.
Method	The normalization factor is important as the formulation assumes real distances for the bump map (or more precisely the displacement map).
Method	The factor should be some fraction of the overall dimensions of the average triangle of the mesh.
Method	The wrinkle function is a continuous real valued function, which is a spline approximation of the normalized texture as described in next item.
Method	The wrinkling coefficient computation involves partial derivatives of wrinkle function f (x, y) with respect to (x, y).
Method	For the reasonable numerical accuracy and stability, the wrinkling pattern needs to be smooth.
Method	We fit a spline function to the pattern to smooth out any discontinuities in the input.
Method	In addition to this, the user is advised to blur the pattern.
Method	As stated in the formulation (Appendix A), solution to equation 4 exists if the input pattern is not constant.
Method	As the pattern is user defined, one needs to watch for the invalidity of the solution (constant C 4 in equation 5 turn out to be zero) and therefore eliminates it.
Method	In this case, we define the modulation factor to be one.
Method	The modulation factor varies significantly across triangles.
Method	If we treat a constant modulation factor for a triangle (see Figure 6), wrinkles appear patchy and one can distinctly see the triangular granules.
Method	To avoid this, the modulation factors are linearly interpolated across triangles to give smooth Modulation Map ( Figure 6 ).
Method	The user is given additional control for the animation by transforming the modulation map by a scale factor, clip, and bias.
Method	The final bump/displacement map is the product of the modulation map and the wrinkling pattern.
Problem	Animating a single wrinkle pattern is not satisfactory (particularly for cloth).
Background	In real-life, the wrinkles are not mere modulations of a fixed wrinkle pattern.
Background	Rather, the pattern changes according to the deformation.
Method	Hence, we would like to apply the technique using multiple wrinkle patterns.
Method	As stated in Section 3.3, two different wrinkle patterns give different wrinkling coefficients for the same triangle geometry.
Method	Hence, for the same deformation of the triangle, corresponding to each pattern, the modulation factors will be different.
Method	It all depends on how the wrinkle pattern is oriented with respect to the deformation direction.
Method	If a pattern is orthogonal to the deformation direction (as compared to the other), corresponding modulation factor will be small.
Method	In other words, the direction of the deformation favors one pattern over the other.
Method	To illustrate this, let us consider simple cloth animation as shown in the Figure 7 .
Method	In Stage 1 cloth is undeformed.
Method	It is then stretched to the bottom left corner (Stage 2).
Method	Comes back to the neutral position (Stage 3) and finally in Stage 4, stretches to the bottom right corner.
Method	We would like to apply multiple wrinkle patterns for this animation.
Method	For simplicity of the discussion, we consider only two wrinkle patterns, though the methodology is developed for multiple patterns.
Method	The wrinkle patterns chosen are orthogonal to each other as shown in Figure 8 .
Method	As the marked triangle undergoes a series of deformations (Figure 7, Stages 1-4), it may compute different values for the modulation factor for each of the wrinkle patterns ( Figure 8 ).
Method	These two modulation factors are then plotted against each other in Figure 9 .
Method	For Stages 1 & 3 both the modulation factors are 1 as cloth is undeformed.
Method	However, for Stages 2 & 4 the modulation factors differ significantly, depending upon the direction of the deformation.
Method	The relatively small modulation factor (say M F 1 is smaller for Stage 2) indicates that the corresponding wrinkle pattern is well oriented towards the direction of the deformation.
Method	We choose this pattern for wrinkling for the deformation.
Method	This selective application of the wrinkle pattern (along with its modulation) will give a change of one pattern to the other as the deformation direction changes.
Method	However, in the animation a sudden switch of the pattern is not temporally coherent and is visually quite disturbing.
Method	To avoid this sudden switch of pattern, we introduce a user definable variance around the mean value of the wrinkling coefficients, which defines a transition zone.
Method	There will be a smooth transition between wrinkling patterns in this zone.
Method	We employ a wrinkling pattern weight function as shown in Figure 11 to achieve the smooth transition.
Method	This is in fact a simple power function with an appropriate scaling and clipping.
Method	If M F 1 is much smaller than M F 2 (stage 1 in Figure 7 ), M F 1 will be smaller than (1 − variance)(M F 1 + M F 2 )/2 and M F 2 will be bigger than (1 + variance)(M F 1 + M F 2 )/2.
Method	This gives maximum weight (W 1 = 1,W 2 = 0) to pattern 1.
Method	In the transition zone, when M F 1 and M F 2 are comparable, the two patterns will be blended smoothly.
Method	The user definable power n is representative of the tightness of the transition and n = ∞ is a sudden switch of pattern.
Method	Note that for lower left triangles in Stage 2 of the animation, both wrinkle patterns get blended.
Method	On the other hand, for lower right triangle in Stage 2, the deformation direction favors one pattern clearly.
Method	Until now, the Geometric Wrinkle formulation is developed keeping in mind a general deformable model.
Method	The garment is animated using a coarse mesh and low metric stiffnesses for the reasons explained in section 2.
Method	Though the user can design the wrinkles according to her wish, it is worthwhile to study the strain patterns in the garment.
Method	This is because, inappropriately placed wrinkles in the region where there is no deformation will not animate satisfactorily.
Method	In addition, the pattern should be orthogonal to the deformations in general, as explained in section 4.1.
Method	Dark triangles are triangles with compression and depict the regions where wrinkles might appear.
Method	Based on such strain patterns (corresponding to two distinct frames of the garment animation in Figure 12 ), two wrinkling patterns are designed as shown in the Figure 14 .
Method	The patterns have distinct wrinkles and additional irregularities to smooth out the sharp appearance of wrinkles.
Method	Each pattern represents a distinct direction of deformation.
Method	Note that they are considerably orthogonal.
Result	It is interesting to see the smooth switch of the wrinkling patterns in the animation because of multi-fold wrinkling.
Result	The frames on the left side correspond to the animation without Geometric Wrinkles.
Result	Note that, there are very few wrinkles in the second figure as there is very little deformation of the mesh.
Result	The first figure shows the modulation of the wrinkles as per the deformation.
Result	As the calculations of the wrinkling coefficients are done on a per triangle basis, the computational time is linear with respect to number of triangles.
Result	Typically, it takes 5 minutes per thousand triangles on a MIPS R10000 200 MHz processor.
Result	Once the wrinkling coefficients are computed, the time spent on modulating wrinkle pattern is negligible compared to rendering time.
Result	In fact, for small meshes (upto a hundred polygons) the modulation of wrinkle pattern can be real time (20 fps).
Result	We have developed a fast and versatile method for animating realistic wrinkles, which is geometric in nature.
Result	Hence, it can be applied to general deformable models such as cloth.
Future Work	We would like to extend the method by automatically creating wrinkle patterns from the strain pattern, which is currently a time consuming task.
Method	Now let us perform a series expansion of equation 9 in the transformation parameters and the modulation factor.
Method	For small deformations around the identity transformation and h = 1, a first order expansion represents a good approximation for the value of the surface area over a deformed triangle.
Method	We call these expansion coefficients wrinkling coefficients.
Method	C 1 , C 2 , C 3 , C 4 relate changes in the parameters a , b , d , h to changes of the area of the wrinkle function on the triangle.

Result	We present a method that allows such a mapping to be defined by example, given that the control specification is recorded motion.
Method	Our method begins by building a database of semantically meaningful instances of the mapping, each of which is represented by synchronized segments of control and target motion.
Method	A dynamic programming algorithm can then be used to interpret an input control specification in terms of mapping instances.
Method	This interpretation induces a sequence of target segments from the database, which is concatenated to create the appropriate target motion.
Method	We evaluate our method on two examples of indirect control.
Method	In the first, we synthesize a walking human character that follows a sampled trajectory.
Method	In the second, we generate a synthetic partner for a dancer whose motion is acquired through motion capture.
Problem	Authoring human motion is difficult for computer animators, as humans are exceptionally sensitive to the slightest of errors.
Problem	This process involves an animator providing a control specification which is mapped to a target motion by some means.
Background	In traditional keyframe animation, for instance, the keyframes are the control specification, and the target motion is achieved through spline interpolation.
Background	Due to advances in data acquisition technology and computational power, techniques have been developed that allow desired target motion to be specified using a human performance.
Background	This is natural for traditional keyframe animators, who often use recorded or live human motion for reference.
Background	Motion capture is the most direct method to map performances to animated humans, as it is essentially an identity mapping.
Background	However, a generalization of this approach to allow for more indirect mappings creates an array of fantastic possibilities, such as mapping voice signals to facial motion [Bra99] or gestural actions to animated reactions [JP99].
Problem	Indirect mappings, however, must still be encoded in some way.
Problem	Manually, this can be an exceptionally challenging task requiring detailed, domain-specific knowledge.
Problem	Consider a partner dance scenario in which an animator wishes to con-      trol a follower using the captured motion of a leader.
Problem	The mapping from leader to follower motion must minimally encode a significant amount of knowledge about the structure of the dance; this knowledge, unfortunately, would be out of reach to an animator who is not a skilled dancer.
Problem	Indeed, it would still be difficult for a skilled dancer to state the precise mapping.
Problem	Human dancers learn their skills by observation and practice; our objective is to emulate this process on a computer for situations, such as partner dance, when the control specification takes the form of one dancer’s motion.
Method	To learn indirect mappings, we adopt a memory-based approach which implicitly encodes the desired mapping using a database of semantically meaningful example instances.
Method	These instances store segments of synchronized control and target motion, which provide examples of how the mapping should be applied to input control motions.
Method	In partner dance, an instance might contain an example control motion of a leader pushing his or her partner forward.
Method	The corresponding example target motion would be that of the follower, taking a step backward in response.
Method	A new input control motion can be interpreted as a sequence of rigidly transformed and temporally stretched control segments from the mapping database.
Method	Through the mapping instances, a given interpretation also corresponds to a sequence of target segments that can be assembled to form a target motion.
Method	We use dynamic programming to select a sequence that balances the quality of interpretation with the continuity of the induced target motion.
Method	Various postprocessing techniques can be then be applied to smooth and adjust the desired target motion.
Method	Our approach is evaluated on two applications.
Result	In the first, we demonstrate its ability to map low-dimensional input to high-dimensional motion by controlling walk motion from mouse trajectories.
Result	In the second, we highlight our method’s capability to handle complex, stylized mappings by controlling a dance follower with the motion of a dance leader.
Background	Performance-driven animation, or computer puppetry, derives its broad appeal from its ability to map human performances automatically to animated characters [Stu98].
Background	While these mappings can be as simple as a direct copy of joint angles, the ability to discover more complex mappings gives the approach a tremendous amount of power and flexibility.
Background	In online techniques [JP99], computational speed and instantaneous results are of paramount importance; offline techniques [Bra99] allow quality and global optimality to take precedence.
Method	Our method falls into the latter category.
Background	Complex mappings often defy purely physical or mathematical encodings.
Background	As a result, many methods assume that mappings are described by parametric probabilistic models [Bra99, DB01, DYP03, JP99].
Background	An advantage of these techniques is their ability to generalize to a variety of inputs.
Problem	However, this comes at a price: statistical learning often necessitates large volumes of training data or severe restrictions on model complexity.
Problem	For certain applications, this is a worthwhile tradeoff, but for others, it can result in impractically long training times or loss of important detail.
Method	A memory-based approach like ours does not suffer from these disadvantages.
Method	An important benefit of this design choice is the ability to use segments, rather than frames, as the primitive unit of motion.
Method	This allows for explicit preservation of higherlevel motion semantics.
Background	Kim et al. demonstrate that a semantically guided segmentation of rhythmic motion allows for highly realistic motion synthesis, even using simple transition models [KPS03].
Background	Although this work, like ours, uses partner dance for evaluation, it does not address the problem of generating a follower given the motion of a leader.
Method	In the segment modeling domain, we consider our method most similar to that of Pullen and Bregler [PB02].
Background	While Pullen and Bregler’s method was shown to be an effective solution for the chosen application of texturing keyframed motion, its applicability to our problem is limited by several factors.
Background	First, their method assumes no spatial dependencies between the control (keyframed curves) and the target (textured motion).
Background	Second, there is no enforcement of motion continuity, other than a heuristic for consecutively observed segments.
Method	Our approach generates target motion segments that are amenable to simple blending.
Background	Finally, their method assumes that the input motion can be presegmented analogously to the examples, which is achieved in their work by observing sign changes in velocity.
Background	One could extend this approach for rhythmic motions using the automated approach of Kim et al. [ KPS03 ].
Problem	In the general case, however, a control motion may not admit any intuitive presegmentation.
Problem	One may wish, for instance, to generate walk motion from a constant-velocity trajectory.
Method	Our method requires no presegmentation; moreover, it produces a semantically guided segmentation as part of the optimization.
Method	In this context, our algorithm could be viewed as an extension of speech recognition methods that use connected word models [ RJ93 ].
Background	Arikan et al. describe an example-based approach to synthesizing human motion that satisfies sparse temporal annotation and pose constraints [ AFO03 ].
Background	Although their work differs from ours in intent, they also employ a dynamic programming algorithm that optimizes a weighted combination of interpretation and motion continuity.
Method	Our formulation differs in two subtle but important ways.
Method	First, our notion of continuity is dependent on the interpretation; that is, the continuity between two motion segments is undefined until a candidate interpretation specifies a coordinate frame for comparison.
Background	Second, their objective function is defined over frames instead of segments.
Background	As a result, they must use coarse-to-fine iterations of their dynamic programming algorithm to gain the temporal consistency that is intrinsic to our segment-based approach.
Background	Other related methods based on motion capture clip rearrangement include work by Kovar et al. [ KGP02 ], Lee et al. [ LCR ∗ 02 ], and Arikan and Forsyth [ AF02 ].
Background	Although these do not aim to discover control by example, they have nevertheless provided inspiration for our work.
Background	An additional distinction is that these methods do not use continuous control from human performance and focus on sparser specifications such as keyframes and nontemporal paths.
Method	Our method is not designed to handle such control specifications and therefore should be viewed as an alternative to these approaches, rather than a replacement.
Background	Many motion rearrangement techniques are derived from previous work in texture synthesis.
Method	Here, we consider our work most similar in intent to image analogies [ HJO ∗ 01 ].
Background	This method, given an unfiltered and filtered version of the same image, applies an analogous filter to a novel image.
Method	Our method, given a set of synchronized control and target motions, applies an analogous mapping to a new input control motion.
Background	Image analogies was shown to be an elegant method with applications such as texture transfer, textureby-numbers, and super-resolution.
Problem	It is our hope that our method will have the same versatility for motion.
Result	Our dance evaluation suggests an alternative view of our method as one of interaction modeling.
Background	In this domain, tech- niques have been developed that specify the mappings between character motions with explicit models of character interaction.
Background	Adaptive autonomous characters have used rules to exhibit complex flocking, herding, and locomotory behaviors [Rey87, TT94].
Background	Approaches to explicit interaction modeling have included layered architectures [BG95], procedural descriptions [PG96], and even cognitive models [FTT99].
Result	In this context, our work might be viewed as a competency module that enhances the skills of characters to enable their participation in complex interactive performances.
Method	For human motion, we use skeletal joint positions, since this representation provides a more intuitive space than joint angle representations for comparing poses [KGP02].
Method	Furthermore, point cloud representations allow for generalization to control motions without skeletal representations, such as mouse input.
Method	The examples are divided into control segments a 1 , . . . , a N and target segments b 1 , . . . , b N , where a i and b i are synchronized motions that together represent a primitive semantic instance of the mapping.
Method	Our dance motions are segmented into two-beat rhythm units, since they are a basic unit of interaction for the specific type of dance (Lindy Hop), as shown in Figure 1 .
Method	Our walk motions, on the other hand, are segmented according to gait cycles.
Method	In both cases, we use manual transcription, since each example motion must only be segmented once.
Method	Methods exist to automate this process if desired.
Method	Dance motion could be segmented using motion beat analysis [KPS03].
Method	More general motions could be segmented using annotation [AFO03] or curve clustering [CGMS03].
Method	Given a control motion x with T frames, our goal is to generate an appropriate target motion.
Method	This is achieved by selecting a sequence of appropriate target segments from the database.
Method	To make the database motions more flexible, we allow each selected target segment to be spatially transformed and uniformly stretched in time.
Method	The proper selection of segments can be achieved using an efficient dynamic programming algorithm.
Method	Before developing our general algorithm, we address the simpler problem of interpreting the input as a single control segment from the database.
Method	We quantify the similarity of the input motion x and a control segment a s with a distance function:
Method	Here, a T s represents the control segment a s , uniformly stretched in time to T frames, and M(x, a s T ) is a rigid transformation that optimally aligns x and a s T :
Method	This optimization is the solution to the Procrustes problem, which has several efficient numerical solutions [ELF97].
Method	Since our example dance and walk motions only differ by ground translation and vertical rotation, our implementation uses a closed form solution [KGP02].
Method	To compute the optimal interpretation, we determine the segment a s ∗ that is most similar to the input motion:
Method	The index s ∗ also identifies, by construction of the database, an appropriate target b s ∗ for both the control segment a s ∗ and the input motion x.
Method	The stretch T completes the specification of the optimal interpretation, M(x, a T s ∗ )a T s ∗ , and the optimal target, M(x, a T s ∗ )b T s ∗ .
Method	The optimal target may not precisely satisfy desired physical or kinematic constraints.
Method	However, given a descriptive database, it can provide a good approximation which can be adjusted appropriately during postprocessing.
Method	In practice, we limit the allowed amount of uniform time stretch by a constant factor since the distance metric does not distinguish between motions of varying speed.
Method	A dancer that pushes his partner slowly, for instance, will elicit quite a different response if he pushes quickly.
Method	Limiting the amount of stretch also has the practical benefit of reducing the search space of our general algorithm, which we will now describe.
Method	In general, we must handle the case where the optimal control and target consist of a sequence of segments.
Method	We can specify this sequence analogously to the single segment case by the number of segments L ∗ , the segment indices s ∗ 1 , . . . , s ∗ L , and the segment durations d 1 ∗ , . . . , d L ∗ .
Method	As in the single segment case, the distance metric D evaluates the interpretation quality of each segment in the sequence.
Method	However, the quality of the interpretation alone does not account for the continuity of the target motion, as shown in Figure 3 .
Method	To offset this problem, we introduce a function which measures the continuity between segments v and w:
Method	Here, α and ω represent the head and tail functions, which respectively extract the positions of the first and last frame of a segment.
Method	One could also use more frames to measure higher-order continuity if desired.
Method	Given a sequence specification L, s 1 , . . . , s L , and d 1 , . . . , d L , we define a scoring function that accounts for both the quality of interpretation and the continuity of the target:
Method	Here, x i is the subinterval of the input that is implied by the segment durations d 1 , . . . , d i .
Method	These in turn induce the transformations M i ≡ M(x i , a d s i i ).
Method	The user-specified constant k defines the balance of interpretation and continuity.
Method	The optimal substructure property of the score function, as defined by the following recurrence, can be used to find a globally optimal solution using dynamic programming:
Method	Here, x d,t represents the subsequence of input frames starting at frame t − d and ending at frame t, which in turn induces the alignment matrix M s,d,t ≡ M(x d,t , a d s ).
Method	Q s,d [t] is defined as the score of the optimization on the subsequence x t,t , given that the last segment is indexed by s and stretched to duration d.
Method	By minimizing Q s,d [T ] over all s and d, we can compute the score of the optimal sequence specification and recover it by backtracking.
Method	To solve the recurrence efficiently, values of Q are stored in a two-dimensional array.
Method	Cells in this array are indexed by the time t on one axis and by all legal combinations of s and d on the other (recall from Section 4.1 that the amount of allowed stretch is limited).
Method	First, all legal values of Q s,d [d] are initialized according to the base case given in Equation 7, and all other array cells are set to infinity.
Method	The algorithm proceeds by iterating forward through time.
Method	At each time t, all non-infinite cells are located and scores are conditionally propagated forward in time according to Equation 6.
Method	More specifically, suppose that we are currently processing the array cell Q r,c [t].
Method	For each legal combination of s and d, the candidate value z is computed:
Method	If the value in the array cell Q s,d [t + d] is greater than z, we set it to z and store a backpointer to cell Q r,c [t].
Method	By continuing this process, the entire array is filled.
Method	Since the indexing of each cell encodes a segment identifier and duration, the optimal sequence specification can be recovered by following backpointers from the best score at time T .
Method	At each time t, O(P) noninfinite cells are processed, where P is the number of legal combinations of s and d.
Method	Since processing an individual cell is an O(P) operation, the total asymptotic time complexity of the algorithm is O(P 2 T ).
Method	To increase its efficiency, we apply several heuristic optimizations.
Method	Rather than process all O(P) noninfinite cells at each time t, we only process cells with scores less than min s,d Q s,d [t] + w, where w is a user-specified constant.
Method	This technique is known as beam search, and w is known as the beam width.
Method	This is motivated by the fact that cells with worse scores are unlikely to be on the optimal backtracking path, and thus can be pruned from the search.
Method	Since the time complexity of the algorithm scales quadratically with the database size, this leads to inefficiency when the number of instances is large.
Method	To resolve this issue, redundant instances are eliminated using complete-linkage clustering [DHS00].
Method	For this, the distances between instances is defined by Equation 1.
Method	The advantage of complete-linkage clustering over other methods (such as k-means) is that it explicitly limits the distance of any two instances in a cluster by a user-defined threshold.
Method	After clusters are formed, a representative instance is chosen at random from each cluster to remain in the database, and all other instances are discarded.
Method	An additional benefit of this process is that it helps beam search; since clustering reduces ambiguity in interpretation, a larger proportion of search paths can be pruned.
Background	High sampling rates are common for systems such as motion capture, but they are generally unnecessary for interpreting the input control motion.
Method	By downsampling motions by a user-chosen constant, we can effectively reduce the length of the input sequence.
Method	However, the resulting optimal sequence specification will also be at the lower frame rate, and it is generally desirable to have it at the frame rate of the original input.
Background	Simple upsampling often introduces slight but undesirable temporal errors.
Method	To remedy this, we run a highly constrained version of our dynamic programming algorithm that only adjusts the durations appropriately.
Method	Constraints can be easily encoded by making appropriate cells in the Q array illegal.
Method	For instance, we can force the result to contain a certain target segment b s at some time t by disallowing any processing on cells Q r,c [u], where r = s and u − c ≤ t ≤ u.
Result	As described in Section 4, the output of our optimization is a specification of an appropriate target motion in terms of target segments in a database.
Result	Specifically, it provides a sequence of target segment indices s ∗ 1 , . . . , s L and durations d 1 ∗ , . . . , d L ∗ .
Method	The corresponding target segments can be copied from the database, stretched, transformed by the induced matrices M ∗ 1 , . . . , M ∗ L , and concatenated.
Method	The result is a moving point cloud that approximates the desired result.
Method	Of course, the same selections, stretches, and transformations can just as easily be applied to the source motions that generated the point cloud.
Result	From the perspective of motion synthesis, the main problem with our approach is that the raw result will generally contain some kinematic errors.
Result	In our dance example, footplant and handhold constraints are never explicitly enforced.
Result	For such constraints, existing methods can be applied to postprocess the data [KSG02], but such methods often require some amount of manual constraint annotation.
Method	Like similar motion clip rearrangement techniques, we can propagate constraints by example.
Method	In other words, each example instance can be annotated with constraints that can be transferred to the target motion.
Method	This is demonstrated by our propagation of handhold constraints, shown in Figure 4 .
Problem	We do not aim to introduce novel solutions for motion blending or constraint satisfaction.
Problem	Instead, our goal is to provide motion that is amenable to postprocessing with these approaches.
Result	To demonstrate our method’s capabilities in this regard, we show that it can generate realistic and compelling motion, even with extremely simple postprocessing.
Result	Our results, shown in the following section and in our accompanying video, are filtered with a basic smoothing operation that linearly adjusts motion curves to match across segment boundaries.
Method	We evaluate our technique with two examples.
Method	In the first, we animate a realistic walking human from time-sampled mouse movement.
Method	Walk motions, however, do not show the full ability of our technique to discover complex mappings.
Method	To better demonstrate this aspect, we apply our method to a partner dance called Lindy Hop.
Method	Specifically, we use the complex motion of the dance leader to drive the motion of the follower.
Method	In the following sections, all human motions were acquired in a motion capture studio and standard commercial tools were used to estimate joint positions [Vic03].
Method	For the point cloud representation of body motion, we used only the positions of the hands and feet, as we found that these endeffectors were sufficient to evaluate interpretation and continuity in both evaluations.
Method	To generate the motion, we applied the resulting sequence specification to the source motion and used basic smoothing.
Method	All timings were performed on a workstation with dual 2.4 Ghz Intel Xeon processors.
Method	Where applicable, we state the clock times for the dynamic programming algorithm (Section 4.3), upsampling (Section 4.4), and postprocessing (Section 5).
Method	The continuity constant, defined in Section 4.2, and the stretch limit were chosen experimentally.
Method	We acquired 2 minutes of motion captured walk footage at 30 Hz.
Method	The subject was directed to walk within the capture area with random changes in direction and speed.
Method	We artificially constructed a synchronized example control motion by projecting the positions of the hip joints onto the floor and normalizing their distance.
Method	As stated previously, the target motions were represented by end-effector positions.
Method	The walk footage was transcribed manually according to the gait cycle.
Method	More specifically, a segmentation point was manually placed at each footplant.
Method	From this process, we created 200 segments, which we reduced to 70 using clustering.
Method	In our tests, we downsampled these motions to 10 Hz and allowed each segment to be stretched ±0.2 seconds.
Method	Our first evaluation involved creating control motions from new walk motions that were not in the database.
Method	As before, we projected the hip joints onto the ground and normalized their distance.
Method	We ran our algorithm on these control motions and compared our results to the original source motions.
Result	Experimentally, we found that larger values of the continuity constant were more effective.
Result	For short walks, the generated motion was highly realistic.
Result	The frequency of the generated gait cycle nearly matched the frequency of the source, but phase differed.
Result	In more concrete terms, the generated motion might choose to start on the left foot, whereas the original source motion might start on the right.
Result	This was expected, as the control signals did not encode any phase information.
Result	For longer walks, however, we were surprised to discover that the generated motions often kept in nearly perfect phase with the source.
Result	The reason for this was that the subject preferred to make sharp turns with the same footwork pattern.
Result	These served as synchronizing signals which were propagated throughout the generated gait cycle due to the global optimization.
Method	In our timing tests, we used a 57 second control motion.
Method	We first ran the algorithm without the beam search optimiza- tion.
Result	The dynamic programming algorithm took 12.5 seconds, upsampling from 10 Hz to 30 Hz took 0.4 seconds, and postprocessing took 1.1 seconds.
Result	With the beam search optimization on, we were able to reduce the clock time of the algorithm to 1.2 seconds (47 seconds of input processed per second of clock time) while retaining visually perfect results.
Result	The upsampling and postprocessing times remained the same.
Method	We ran the algorithm on shorter and longer inputs and experimentally confirmed the asymptotic linear dependency of running time on input length, described in Section 4.4.
Method	In our second evaluation, we built an interface that allowed users to draw paths using mouse input, as shown in Figure 5 .
Method	The position of the mouse pointer was sampled at 30 Hz, and Frenet frames were used to generate a control motion.
Result	For a wide variety of user inputs, our method was capable of generating highly realistic walking motion.
Result	Since the timing of the path was important, we found that users required minor training to understand the concept of performing a path instead of drawing it.
Result	It was often tempting, for instance, to rapidly move the mouse to draw a straight line.
Result	This would correspond to a impossibly fast run, well beyond the capabilities of a human.
Method	To resolve these issues, our interface allows a user to overlay the playback of an existing motion on the drawing canvas to get a sense of speed.
Method	Furthermore, it provides options to smooth the trajectory spatially and temporally.
Result	The speed of the algorithm allows for rapid feedback.
Method	Our choice of partner dance as a demonstration was primarily motivated by the complexity of its style and mappings.
Method	From a small segmented set of example instances, we generate a follower’s motion to accompany a leader’s motion.
Method	Generating partner dance motion would be a difficult trial for both physical methods, which would yield underdetermined systems, and statistical methods, which would typically require a very large database in place of our small segmented one.
Method	Swing dance also allows for a more principled evaluation of our results than most types of motion, since the performance of the algorithm at generating valid mappings can be evaluated independently of style considerations or subjective judgments of motion quality.
Background	Lindy Hop is a subgenre of swing dance that, at a basic level, can be described as a state machine.
Method	A dance couple moves between four basic stances: open (◦), closed (•), open crosshand (◦), and closed crosshand (•).
Method	Open and closed refer to whether the couple is apart or in embrace, respectively.
Method	Crosshand refers to the case when the leader and follower hold right hands (we could also refer to it as a handshake).
Method	Basic Lindy Hop motions switch between these four stances by means of transitions: an inside turn ( ), when the follower spins towards the leader, an outside turn ( ), when the follower spins away from the leader, and a simple step (→).
Method	At the end of each transition, the dancers may also change their handhold to instantly transition between crosshand states (◦, •) and non-crosshand states (◦, •).
Method	Each of these transitions occurs over four beats of music, which are assembled from two-beat segments; this was our motivation for performing two-beat segmentation, as described in Section 3.
Background	Skilled Lindy Hop dancers use a greater variety of moves, ranging from more complex transitions such as double outside turns to complex aerial maneuvers.
Method	We did not include the entire range of motions.
Method	Instead, we constructed a smaller database with seven basic 8-beat dance patterns that every Lindy Hop dancer knows (shown in the first column of Table 1 ).
Method	We constructed the motion database from a set of 12 short dances, each containing the seven basic 8-beat patterns, giving a total of 5 minutes of motion.
Method	These dances were segmented into 364 two-beat mapping instances, with lengths varying from approximately 0.6 seconds to 1 second due to different music.
Method	For our evaluations, we captured three longer test dances (approximately 2-3 minutes each) in which the dancers were instructed to improvise with the transitions and stances included in the database.
Method	Their improvisations led to dances which included thirteen new 8-beat patterns not found in the database (shown in the last column of Table 1 ) as well as some repeats of patterns in the database.
Method	These test dances spanned a tempo range from about 120 beats per minute to about 190 beats per minute.
Method	We used the motion of the leader to control a synthetic follower, which was then compared with the actual follower.
Result	Visually, the results exhibited the fluidity, grace, and style of the original dancer.
Result	Some footskate and handhold violations are visible because we wanted to show the output in its almost raw form, with smoothing applied only for visual coherence.
Result	In a direct comparison with the actual follower motions, we found that the synthetic follower matched very well in closed stances.
Result	In open stances, the follower was much freer to include stylistic variations, so the generated motions often differed visually from the actual motions.
Result	Additionally, the synthesized dancers almost always kept in perfect rhythm with the leader.
Result	Our algorithm ably recreated the semantics of the leader to follower mapping, even for novel patterns.
Result	When the algorithm encountered a pattern that was not in the database (one of 14 such patterns shown in Table 1 ), it was able to correctly reconstruct the novel sequence by rearranging the two-beat segments.
Result	Of the 91 patterns (21 unique) in our three test dances, the synthetic dancer matched the pattern of the actual dancer in all but 5 cases, one of which is shown in Figure 6.
Result	When the algorithm did differ from the real dancer in the composition of the pattern, the leader and follower still executed a valid Lindy Hop pattern.
Result	In these misinterpreted instances, the leader’s motion is quite similar across two different follower patterns.
Result	To disambiguate these, we might add information to the control signal, such as forceplate readings, or we might accept these rare mismatches because they are in fact valid mappings.
Result	Furthermore, all 5 mismatched patterns differed by a single two-beat segment, so, of 91 × 4 = 364 two-beat segments in the test dances, the algorithm misinterpreted the signal in 5 cases for an error rate of less than 2%.
Result	For all our evaluations and timing tests, we reduced the size of the database from 364 to 168 with clustering, downsampled to 7.5 Hz, and allowed a segment stretch of ±0.15 seconds.
Result	We cite our efficiency figures for generating, from leader motion only, a particular 150 second dance motion.
Result	Without beam search, the dynamic programming algorithm ran for 78 seconds, 2 seconds were spent on upsampling, and 26 seconds were spent on postprocessing.
Result	With beam search enabled with modest parameters, we were able to drive the runtime of the dynamic programming to 10 seconds while maintaining excellent visual and semantic results.
Result	As with our walk motion evaluation, we found that clock times scaled linearly with the length of the input.
Result	We have presented a method for example-based performance control of human motion.
Method	Our dynamic programming algorithm uses segments of motion along with an objective function that accounts for both the quality of control interpretation and the continuity of the target motion to generate visually and semantically correct motions.
Method	The semantic accuracy of the generated motion was evaluated in the setting of partner dance, where the follower’s motion is generated from the leader’s motion.
Result	The algorithm generated semantically correct partner motion even from test sequences of leader motions that did not appear in the training set.
Result	Our dynamic programming algorithm performs a global optimization, which precludes the local decisions that are required for online applications.
Result	However, we demonstrate in our evaluations that it can compute results significantly faster than input motion can be recorded, thus making it suitable for rapid-feedback motion authoring applications.
Result	We believe that segmental approaches like ours hold great promise for real-time performance-driven animation, and consider it a promising area of future research.
Method	To preserve spatial dependencies in mappings, we apply rigid transformations to optimally align control segments with input control motions.
Result	Target segments inherit these transformations.
Result	This approach is effective for our applications or whenever the control signal indicates appropriate spatial and temporal cues.
Result	It is also possible to select other transformations for applications outside the domain of human motion control.
Result	For instance, allowing arbitrary homogeneous transformations in two dimensions might form an alternative segmental solution to the curve analogies prob- lem [HOCS02].
Result	Eliminating transformations entirely might also be appropriate for applications such as synthesis of facial motion from speech signals [Bra99].
Result	We have shown that our segment similarity metric is effective for our experiments.
Result	However, we acknowledge the fact that other metrics may be more appropriate for different types of motion and believe that it is a promising direction for future research.
Method	In the process of generating target motion, our dynamic programming algorithm performs a semantically guided segmentation of the input control motion.
Method	The entire process, however, relies on the availability of semantically segmented examples.
Method	For our evaluations, we were able to perform this segmentation manually by tapping a key in response to the rhythm of music or the gait pattern of a walk cycle.
Result	While specific methods exist to automate this segmentation for the cases of dance and walk, a more general method is desirable.
Result	For this, we could begin with a few manually segmented examples and grow the set of example instances by iterative application of our algorithm.
Background	This approach would be similar in spirit to the semiautomatic SVM-based annotation approach of Arikan et al. [AFO03].
Result	The annotation propagation we describe above suggests that our method could be used for interpretation rather than control.
Result	Paralleling our automatic annotation of handholds, it is possible to annotate any new control motion given a set of labeled example instances.
Result	This could be used to transcribe the motion into a symbolic representation, such as the one used in this paper, or even Laban notation [Hut73].
Result	Such a representation could then be analyzed or summarized using natural language processing techniques.

Background	The skeleton driven skinning technique is still the most popular method for animating deformable human and creature characters.
Problem	Albeit an industry de facto due to its computational performance and intuitiveness, it suffers from problems like collapsing elbow and candy wrapper joint.
Problem	To remedy these problems, one needs to formulate the non-linear relationship between the skeleton and the skin shape of a character properly, which however proves mathematically very challenging.
Method	Placing additional joints where the skin bends increases the sampling rate and is an ad hoc way of approximating this non-linear relationship.
Problem	In this paper, we propose a method that is able to accommodate the inherent non-linear relationships between the movement of the skeleton and the skin shape.
Method	We use the so-called curve skeletons along with the joint-based skeletons to animate the skin shape.
Result	Since the deformation follows the tangent of the curve skeleton and also due to higher sampling rates received from the curve points, collapsing skin and other undesirable skin deformation problems are avoided.
Result	The curve skeleton retains the advantages of the current skeleton driven skinning.
Result	It is easy to use and allows full control over the animation process.
Result	As a further enhancement, it is also fairly simple to build realistic muscle and fat bulge effect.
Result	A practical implementation in the form of a Maya plug-in is created to demonstrate the viability of the technique.
Background	A realistic and visually accurate character animation necessitates proper skin deformation of the character models.
Background	Skin deformation owes a large part to proper rigging of the characters.
Background	The virtual skeleton forms the interface by which the animator can pose or animate the characters.
Background	The joint-based skeleton has been very popular in the animation industry for many years and has nearly become a de facto standard.
Background	Other technologies like inverse kinematics, forward kinematics, motion capture etc. are built on this hierarchical system of joints.
Background	It is plain to see why the joint-based skeleton system is thoroughly integrated into the current production pipeline in animation.
Background	Where visual fidelity is of the utmost importance, with respect to film quality animation, a combination of techniques including muscle simulation is used to achieve the realistic best in mesh deformation.
Background	The attachment of mesh geometry to the underlying skeleton rig is called ‘skinning’ and this can be understood as a function mapping of the skeleton parameters to a deformation field.
Background	1 One of the common skinning methods in interactive systems is known by the following nomenclatures: sub-space deformation (SSD), smooth skinning, linear blend skinning and enveloping.
Background	The process followed by this technique is to assign influence joints and blend weights to each vertex of the character.
Background	Transforming the vertex by a weighted combination of the joints local coordinate frames completes skin computation.
Problem	But in spite of computational performance and ease of use, the joint skeleton skinning is not without its share of problems, particularly where skin deformation is concerned.
Problem	Unusual deformation artifacts appear in the skin while deforming.
Problem	Some of the commonly seen problems in joint-based skinning during deformation are: candy wrapper effect during twist deformation and collapsing joints, which would create a rubber-tube like effect.
Problem	There are certain solutions to circumvent these problems (which we will examine later in the paper) but they have their own drawbacks.
Background	Nevertheless, the joint-based system is popular owing to its interactivity and use of minimal animation data.
Background	More importantly, it is almost an integral part of the current animation workflow and animators are reluctant to abandon their familiar production practice.
Background	The relationship between a skeleton and the skin shape is highly non-linear.
Problem	The problems of joint-based skeleton skinning mentioned above, in essence arises from under-sampling.
Problem	The transformations of the two related joints are too far from each other.
Problem	And with that low-rate sampling they fail to give a good approximation of the deformed skin surface.
Result	In this paper, we introduce a novel method called curve skeleton skinning, to overcome the persisting drawbacks of joint skeleton skinning.
Problem	The basic idea is to represent the relationship between the skeletal movements and the skin deformation in a non-linear continuous fashion.
Method	Since a lot of contemporary animation technology is built upon the hierarchical joint-skeleton based system, it is not wise to entirely replace the current practice.
Method	What we propose to do is to enhance the current joint skinning system using the curve skeleton skinning and retain the current animation production pattern that the animators are familiar with.
Method	While the joint skeleton is a discrete centre line representation of an object, the curve skeleton offers a continuous skeletal representation.
Method	Thus a character will have two skeletons: the ordinary joint skeleton and a curve skeleton.
Method	The curve skeleton being continuous gives the maximum sampling rate and provides skin deformation transformation without any artifacts.
Problem	In addition, we will demonstrate how the curve skeleton technique can drive muscle-based systems to achieve realistic muscle deformation during animation.
Result	Using our technique, the animator is able to work without digressing from the familiarity of the current joint-based system, but at the same time achieves maximum visual realism in terms of skin deformation.
Background	What needs pointing out is that the term curve skeleton has been used for other applications, such as virtual navigation, reduced-model formulation, visualization improvement, surface reconstruction and it was defined as ‘a 1D subset of the medial surface of a 3D object.
Problem	’ 2 Despite some similarity, it should not be confused with what we are presenting in this paper.
Problem	One should neither confuse this with the inverse kinematics (IK) spline handle tool provided by the animation package Maya.
Problem	Despite their seeming similarity, they are in essence very different techniques.
Background	Mesh deformations due to skeletal joint influence have undergone significant improvements in the recent years.
Background	Some of the normal deformation techniques like free form deformations (FFDs) or lattices can be used in skin deformation techniques.
Background	Singh and Kokkevis 3 demonstrate this in their paper.
Background	They use surface-oriented FFDs for skinning.
Background	An interactive deformation technique for complex geometric objects using curves or wires is detailed in Reference [ 4 ].
Background	There are basically two main approaches to modeling skin deformations, namely, anatomy-based approach and skin-shape based approach (e.g., example-based skinning).
Background	The anatomical approach derives its name from its implementation using anatomical models of muscles and skeletons and other relevant interior structures.
Background	These modules undergo deformation when the body moves and a skin simulation and collision detection algorithm is run which would realistically deform the skin where and whenever it is required.
Background	Reference [ 5 ] details a technique of efficient muscle shape deformation using the anatomical skin deformation technique.
Background	Reference [ 5 ] resorts to the creation of a muscle model, which is categorized into two layers: an action line and a surface mesh.
Background	Basically, the action line is the mechanism that drives the deformation.
Background	They also implement attractive and repulsive force fields in the form of ellipsoid metaballs to stabilize the action line.
Background	Simulation of complex dynamics and performing complex collisions and also providing a visually realistic output form the main strength of the anatomical approach.
Background	Incorporating physical properties of anatomy structures can potentially improve realism.
Background	Physics can be used either at the muscle level 6 or used to help character rigging.
Background	7 Reference [ 8 ] presents another approach to deformation using an elastic surface layer model.
Background	It uses a layered structure of anatomical parts from the inside out, skeleton->bone->fat->skin.
Background	The surface is discretized and finite differencing techniques are used to evolve the deformation through time.
Background	The drawback comes in the form of computation expense.
Background	The anatomy-based approach is therefore used mainly in high-quality film visual effects where anatomical accuracy is a must for believable computer generated characters.
Background	The example-based approach forms a suitable alternative where computational expenses are to be minimized.
Background	This method takes an interpolative approach to deformation.
Background	An artist models certain key poses of the characters where a correlation is maintained for the degrees of freedom, in this case, it would be the joint positions or rotational angles.
Background	New poses are interpolated from these key poses.
Background	A modified least square fitting technique is used to compute the weights of the deformation and the subsequent generalization of skin movement to other animated poses.
Background	In Reference [ 9 ] the algorithm is trained in a statistical manner so that deformation computation for an arbitrary animated pose can be done.
Background	They use a technique called multiweight enveloping in place of single-weight enveloping for better deformation.
Background	Reference [ 10 ] also implements an example-based approach to deforming meshes by using radial basis functions to supply the interpolation weights and also for shape interpolation.
Background	A variation of example-based approach where key example poses are derived from arbitrary unrelated examples is detailed in Reference [ 11 ] where a range scan is used.
Background	Thus example-based approaches have the advantage over anatomical approaches by being computationally faster and also due to the fact that creating example poses are much easier compared to creating detailed anatomically correct models.
Background	Most of the described techniques are built upon the existing hierarchical skeletal joint system and modify 10 or even create 9,12 new weight calculations to rectify any sort of physical artifacts in the skin deformation.
Background	The example-based approach relies on key sample poses to derive a generalization of deformation, and this becomes a major disadvantage, as this in itself is an expensive and time-consuming process.
Background	It is not desirable to create many examples and train the system.
Method	Our approach builds upon the existing system using the curve skeleton for a continuous sampling of the skin surface thereby facilitating skin deformations devoid of geometry artifacts.
Method	Since our technique falls in between the two approaches, seamless integration with the two is also possible and becomes its strong advantages.
Background	A relevant technique to ours is the sweep-based skinning.
Background	13 The body of a character is segmented with a large number of sweep planes which will be transformed by the joint skeleton.
Background	These planes are used to guide the transformation of every skin point during animation.
Method	With our method, the skin surface does not need to be approximated by sweep surfaces.
Method	It will be deformed directly by the underlying curve skeleton, leading to a simpler process.
Problem	Skeleton and skin relationship in the present production pipeline is strictly linear, whereas observation of the various geometry artifacts like candy wrapper and collapsing joints intuitively point to the fact that linear blending or skeletal space deformation falls short in accurately depicting skin deformations because of their non-linear nature.
Background	This non-linear nature is explored in Reference [ 12 ] where a spherical blending is proposed.
Background	Only the translation factor is most commonly used for the skin vertices and the rotation factor is not considered.
Background	It is our knowledge that the problem reduces after weight painting only when the joint influence fall-off follows a curve pattern.
Background	Wang and Philips 9 introduce a multiweight technique to eliminate this problem in a normal joint-based skeleton skinning.
Background	However, this requires the generation of a large number of pre-modeled examples in the first place.
Background	The solution to the collapsing joints problem, which is to place additional joints 1,14 (placing additional joints is basically bringing a curve nature to the joint chain) near the main joint, has the added problems of: (1) creating a new joint in the hierarchy; (2) joint connections have to be done again to connect the new joint in the existing chain; and (3) painting of weights have to be adjusted to accommodate the new joint.
Method	With our curve skeleton technique, the curve serves as a duplicated skeleton to the actual underlying joint skeleton.
Method	Effectively any point on the curve can be considered as a joint.
Method	In other words, the skeleton is equipped with an infinite number of joints, which will influence the skin deformation.
Result	The curve nature of the skeleton makes it easier to manipulate it with a great order of flexibility.
Result	The idea to use a curve skeleton side by side with the traditional joint skeleton is conceptually simple and functionally efficient giving realistic skin deformations even under extreme mesh duress.
Result	Our curve skeleton technique takes full advantage of the nonlinearity of the skeleton-skin relationship.
Method	The curve skeleton can be generated in two ways depending on what the animator supplied in the first place.
Method	If the animator supplies a skin model and a skeleton model in the traditional manner, the curve skeleton generation is easy.
Method	If on the other hand, the animator supplies only a 3D surface model (not a voxelized representation), the generation of the skeleton becomes slightly more complex in that an additional step is required.
Method	A temporary copy of the surface model can be created (during runtime) and voxelized.
Method	Once voxelized, a curve skeleton is created using the repulsive force field function.
Method	15 Then the temporary mesh can be deleted and the skeleton can be used with the original surface model.
Method	The whole structure of a curve skeleton may involve several curves, which depend on the topology of the original joint skeleton.
Method	In a linear linkage the centre of the joint gives the first control point (CP) of the curve.
Method	Then one Bone_CP each is inserted on the opposite sides of the Joint_CP ( Figure 1a ).
Method	Both Bone_CPs have floating positions along the two neighbouring bones, its position being constrained by the angle between the two bones.
Method	The reason for the floating position is to eliminate the selfintersection of the skin mesh ( Figure 1 -a1).
Method	Before we can predict the exact movement of the Bone_CP, first we should estimate the approximate distance d from the skin surface to the relevant link of the skeleton.
Method	The condition for non-self-intersection is to check if the local radius of curvature r at the joint is not less than d.
Method	If we analyse the curve function, we can extract the exact expression from the position of Bone_CP, but because the distance d is only an approximate result, it may not fit exactly in the animation.
Method	So here the floating position of the Bone_CP is left to the animator to define interactively ( Figure 1 -a2).
Method	By providing the animator with more parameters, which he/she can tweak, we grant flexibility and freedom to adjust the animation.
Method	One curve is generated.
Method	In anatomical areas like the hip ( Figure 1b ), a fork exists in the joint chain.
Method	Hence, three curves are generated, two curves starting from the central link to the two limbs linkage (in the example) and one curve linking the two links.
Method	In the neck area, a cross exists in the joint chain.
Method	Although it appears to have four links, we only need to generate two curves for the curve skeleton, as seen in Figure 1(c) .
Method	As can be seen from the above classification, for a human character, we will use a maximum of three curves for each joint.
Method	In most cases, one curve is sufficient.
Method	In our method, the parameter t on the curve plays an important role in the deformation.
Method	We use B-splines to represent the curve skeleton.
Method	Similar to the joint-based skeleton, each point on the curve in a curve skeleton has a local frame (similar to a Frenet frame) defining the space transformation sampled at that point.
Method	This local frame is a function of the parameter t of the curve point.
Method	These points normally form the curve segment endings.
Method	They can be easily found from the curve definition.
Method	If the centre is lying on the curve, the deformed skin will move out from underneath the skeleton.
Method	The underlying structures like muscles or bones will be exposed.
Method	So here the centre of the local frame is translated on to the original skeleton shown in Figure 2b .
Method	When the bone twists around its local x-axis, it will not have any effect on the associated curve skeleton.
Method	This is not acceptable.
Method	In order to remedy this problem, here on the curve skeleton we define two extra attributes, twist angle and twist distribution.
Method	The twist angle can be easily queried from the associated joint.
Method	The rotation angle is for the curve ending.
Method	For each point on the curve, we still need a twist distribution to define how the curve twists along its path.
Method	Normally it is not evenly distributed as can be seen from the twist of a forearm.
Method	In order to perform even distribution of twisting, we provide the animator with the freedom to control how the curve twists by manipulating the distribution curve.
Method	The distribution curve ( Figure 3a ) is very much like the animation curves in Maya.
Method	Here the twist angle is distributed along the distribution curve so that the twisting is smooth and natural.
Method	The process of skin binding is to transform each skin surface point hx,y,zi at the binding pose to the local frame coordinate system hi, t, u, di, where i is the index to the specified curve segment, t is the parameter along that curve segment, u is the rotation angle around the x-axis from the y-axis, d is the distance from the local frame centre.
Method	Actually the triple parameter ht, u, di may be considered as being expressed in a cylindrical coordinate system.
Method	The values ht, u, di can be easily computed if we can settle the associated curve segment.
Method	Thus the challenging part of the work is to find the associated curve segment, and assign the weighting parameter for each curve segment—skin binding.
Background	There is a lot of work 16 associated with the traditional joint-based method, like the containment-binding algorithm, point-to-line mapping, Delaunay tetrahedralization.
Method	The relevant default weight factors w i of a skin point for the ith curve segment is determined by the distance between the skin point concerned with the relevant curve segments.
Method	If a skin point is related with only one curve, which represents the majority of cases, the weight factor is always 1.
Method	For those skin points associated with two curve segments, the default weights are proportional to the distances to the relevant curve segments, that is, the further away a skin point is from the curve segment, the smaller the weight is.
Method	This is also the case for any skin points associated with three curve segments.
Method	In all cases, the summation of the weights are constrained to one, P w i 1⁄4 1.
Method	The animator will have freedom to edit the weighting factors in the same way as the smooth skinning.
Method	Given that we have a maximum of only three curve segments for each skin point, weight assignment for a skin point is simpler than the traditional smooth skinning method and the computation for skin deformation is computationally cheaper.
Method	Smooth skinning usually involves three weights for each skin point and in many cases there could be as many as five weights.
Method	This is worsened if additional joints are placed in order to remedy the unpleasant artefacts.
Method	The more the joints, the trickier it is to determine the weight distribution.
Result	With our curved skeleton, this problem will almost certainly not arise.
Method	Once the skin is bound with the curve skeleton, deforming the skin is pretty straightforward.
Method	The local coordinates of each skin surface point are transformed with the associated local frame to obtain the new position in the world coordinate system.
Method	So the new point P, is defined by X P 1⁄4 w i M ði;tÞ P Lðu;dÞ (3) i where w i is the weight for the specific curve segment i, M (i,t) is the new transformation matrix at the parameter t position along the curve segment i.
Method	As discussed earlier, we use on average a smaller number of weights.
Method	This leads to a smaller number of summation terms needed for the calculation of the deformed skin points (see Equation (3)).
Result	As a result, our computation speed is at the same order, but is slightly faster than that of the traditional smooth skinning technique.
Method	So far, we have discussed how to realistically skin a character without taking into account the anatomical structures.
Background	But muscles will give an added layer of realism to the deformation, especially in regions where the skin is visibly influenced by the underneath muscles.
Result	With our curve skeleton technique, muscle deformation can be fully integrated where the muscles are driven and animated by our curve skeletons.
Background	One of the best third party muscle simulation systems available called muscleTK 17 deforms the muscle using the so-called action lines.
Background	The action line is basically a curve, which defines the direction of deformation.
Background	But the disadvantage is that the action line has to be manually animated each frame during animation.
Method	Using the proposed curve skeleton, we can realistically deform not only the skin directly (as explained earlier), but also the muscles, in a unified manner.
Method	Effectively, each action line is deformed by a curve skeleton, and the action line in turn deforms the muscle.
Result	Therefore, we can achieve sophisticated muscle deformations without the tediousness of animating the action lines manually every frame.
Method	When the effect of a muscle bending around the joint or the bone is required, we can first transform the control points (CP) of the action line from world space to the associated curve skeleton local frame.
Method	These CPs will then be transformed with the curve skeleton, resulting in the muscle bending around the joint or bone being automatically created ( Figure 3b ).
Background	Maya is the most widely used 3D animation package in the industry.
Background	In order for scalability and increasing the feature base of Maya, Autodesk has provided Maya APIs for developers to expand the functionality of Maya.
Method	From an interface point of view, the artist basically works with normal edit point (EP) curve tools to generate the curves according to his/her wish.
Method	Once the curve is selected and the plug-in activated, the curves become the skeleton for the skin mesh.
Method	Internally, the curve cluster is bound to the joint skeleton so that any movement of the joints affects the curvature of the curve.
Method	The local transformations of the curve points are applied to the skin mesh vertices thereby generating deformations on the skin.
Background	Skin deformation is closely linked with the movement of the skeleton of a character.
Problem	It is understandable that the relationship between both is highly non-linear, which poses a challenge if the relationship is to be modeled mathematically correctly.
Background	Existing skeletondriven techniques regard it as a much-simplified linear problem, which however, has resulted in unrealistic skin deformation in certain regions of the character body.
Result	In this paper we have presented a technique, known as the curve skeleton based skinning, by considering it as a proper non-linear problem.
Result	The main advantage of this technique is its consistency with the current animation production practice and the ability to overcome the undesirable drawbacks of skeleton-driven skinning.
Result	From the algorithmic point of view, the technique reduces a level of complexity in the skinning and deformation.
Result	By layering the curve skeleton on top of the existing joint skeleton, we allow the animator to work conventionally (as in a joint-based system) and yet receive good results.
Result	Through a combination of existing practices and newly designed ones, we have successfully created a fusion, which maximizes the efficiency of surface deformation during animation.
Result	For an articulated character, we use no more than three weights for any skin point.
Result	In fact, for the majority of cases, there is only one weight, which is 1, to be is used.
Result	In comparison with the traditional smooth skinning technique that usually requires on average 3–5 weights, our computation speed is faster.
Result	One should not confuse the curve skeleton technique with the inverse kinematics (IK) spline handle tool provided by the animation package Maya.
Background	Despite their seeming similarity, the objective of the Maya IK spline handle tool is to control the joint positions using a spline.
Background	Skin deformation is achieved using the traditional smooth skinning technique.
Method	Our curve skeleton is controlled by the joints of a character.
Method	The skin is directly deformed by the curve skeleton.
Result	The Maya plug-in implementation of the curve skeleton technique has given satisfactory results.
Result	One of the main advantages of the curve skeleton skin deformation technique is that, the curve skeleton needs not necessarily be placed on the underlying joint skeleton.
Result	With a slight modification utilizing a linear mapping of curve points to the joint skeleton, the plug-in can make use of a displaced curve skeleton which would be useful for subtle deformation on anatomical areas like the armpits.
Result	Our current implementation allows both skin and muscle deformation to be modeled within a unified framework.
Future Work	As future work, we will further improve the skinning realism by adding the fat effect.
Background	Fat usually deposits between the skin and the muscles.
Background	Effective realism occurs when the skin actually slides over the fat.
Background	This is especially true in the areas near joints where acute deformation happens.
Background	Turner and Thalmann 8 defines the fat layer as a thickness specified at each point on the skin surface and make use of reaction constraints to push the skin the required distance out from the underlying layers.
Background	Yang and Zhang 18 devises a fast method for simulating fat in which a fat bulge distribution function is described.
Background	They have used a geometric method instead of resorting to a physical simulation method, and gives convincing results without the computational expense of physical simulation.
Future Work	With a small modification, the fat bulge effect can be made even in a curve skeleton-based skinning.
Future Work	The function can be defined under the local frame of the curve skeleton.
Result	In the present context, since the skeleton is a curve, distribution and deformation can be linked with the tangent angle at a given number of curve points around the joints.
Background	As fat is largely incompressible, when a joint bends, flesh between the adjacent bones will be squeezed, producing bulges immediately near the joint and at the sides.
Future Work	Using curve tangents will provide for an accurate distribution in any given time frame because of the integrated results from the sample multiple curve points.

Problem	Cloth simulations are notoriously difficult to tune due to the many parameters that must be adjusted to achieve the look of a particular fabric.
Result	In this paper, we present an algorithm for estimating the parameters of a cloth simulation from video data of real fabric.
Method	A perceptually motivated metric based on matching between folds is used to compare video of real cloth with simulation.
Method	This metric compares two video sequences of cloth and returns a number that measures the differences in their folds.
Method	Simulated annealing is used to minimize the frame by frame error between the metric for a given simulation and the real-world footage.
Method	To estimate all the cloth parameters, we identify simple static and dynamic calibration experiments that use small swatches of the fabric.
Method	To demonstrate the power of this approach, we use our algorithm to find the parameters for four different fabrics.
Result	We show the match between the video footage and simulated motion on the calibration experiments, on new video sequences for the swatches, and on a simulation of a full skirt.
Background	Several recent major movie releases have demonstrated that the motion of clothing adds greatly to the appearance of a virtual character.
Background	This effect is particularly compelling for scenes that include both real and synthetic actors such as those with Yoda and Anakin Skywalker in Episode II: Attack of the Clones.
Background	In such scenes, the virtual clothing must move and be rendered so that it blends in seamlessly with the motion and appearance of the real clothing in the scene.
Background	Realistic virtual clothing is possible now because of recent advances in cloth simulation techniques 4 , 9 , 5 , 37 , 6 .
Background	The motion of fabric is determined by resistance to bending, stretching, shearing, external forces, aerodynamic effects, friction, and collisions.
Problem	Although with the right set of parameters good simulators produce very realistic looking motion, choosing parameters that will provide a particular appearance remains a time consuming task that requires the computation and viewing of many forward simulations.
Problem	Some parameters can be chosen based on the animator’s intuition about the fabric—a knit fabric is more stretchy than a woven fabric such as linen, for example.
Problem	But not all the parameters of a cloth simulator are intuitive or map directly to measurements that can made by a system such as the Kawabata system 22 .
Method	In our paper, we address this problem by using optimization to automatically determine these parameters from a sequence of video frames of the fabrics under consideration.
Method	The parameters are optimized on a set of static shots and motion clips of a small swatch of a particular fabric and then tested on a simulation of a full skirt made from that fabric.
Method	We designed the swatch tests to span the space of behaviors that we expect to see in the final sequences of motion with the skirt so that all parameters can be tuned appropriately.
Method	We use simulated annealing for the optimization step with an optimization function that assesses the extent to which the folds in the simulated and physical fabric match.
Method	This match is evaluated by means of a shape metric that uses projected light to detect surface orientation in real and simulated fabrics.
Method	The metric is tuned to be most sensitive along folds and to discount planar regions.
Result	We use the system to find the parameters for four different fabrics.
Result	We show the match between the video footage and the simulated motion on the calibration experiments, on new video sequences for the swatches, and on a simulation of a full skirt as shown in the image on the previous page.
Background	Cloth modeling has a long history, dating back to work in the textile community from the mid-1930s by Peirce 27 .
Background	Work on cloth modeling in computer graphics has focused on developing dynamic simulation techniques that are both realistic and fast.
Background	Baraff and Witkin describe a cloth model that uses stiff springs with implicit time integration 4 .
Background	This model was subsequently adapted to reduce the over-damping due to implicit integration 9 .
Background	Explicit time integration approaches 18 use weaker springs for stretching and shearing, often explicitly limiting the amount of stretching 29 , 6 .
Background	Choi and Ko introduced a bending energy model that more accurately captures the fine creases and bends of cloth 9 .
Background	Lahey provides a comprehensive overview of cloth hysteresis models from the perspective of computational fabric mechanics 23 .
Background	Extensive work has also been done on modeling collisions and friction.
Background	Cloth self-collision is handled either by untangling the cloth 37 , 39 , 3 or by preemptively avoiding collisions 30 , 20 , 6 .
Background	Various potential field methods have been used for general collision detection and response 33 , 32 .
Background	Despite this large body of work on cloth simulation models, little work has appeared in the computer graphics literature on estimating the parameters of these models so that they match the behavior of real fabrics.
Background	Cloth parameter estimation has been studied in the textile community (for an overview, see Breen and colleagues 17 ), but such methods have not yet enjoyed wide-spread use in the computer graphics community.
Background	An important exception is the work by Breen 5 who used the Kawabata system 22 to measure bending, shearing, and tensile parameters by subjecting a swatch of fabric to a series of mechanical tests and measuring the force needed to deform it into a standard set of shapes.
Background	Although the Kawabata system can provide accurate measurements, these measurements are problematic for computer graphics cloth simulation problems for two reasons.
Background	First, there might not be a direct and simple mapping between the parameters for a particular cloth model and the Kawabata parameters.
Background	Second, the Kawabata system does not measure dynamic cloth parameters, e.g. air drag or damping, which are of key importance for moving cloth.
Background	One promising approach for modeling cloth parameters is to automatically search for parameters that match real, observed cloth.
Background	Jojic and Huang fit parameters of a particlebased cloth model to fit a range scan of real cloth in a static rest configuration, draped over a sphere 21 .
Background	More challenging still, they attacked the problem of measuring the 3D geometry of an object from the resting shape of a piece of cloth draped over it, a problem that we do not consider in this paper.
Background	However, Jojic and Huang did not treat the problem of measuring dynamic parameters or demonstrate accurate results across a range of fabric types.
Background	More distantly related are techniques for computing the geometry of cloth from images.
Background	Coarse estimates of the time-varying geometry of cloth can be computed using traditional stereo matching techniques by using two or more cameras and treating each time instant independently (see Scharstein and Szeliski 31 for an overview).
Background	More accurate results may be obtained by projecting structured light patterns on the cloth (see Zhang et al. 40 for an overview).
Background	Rather than computing shape at every time instant independent from the next, it can be advantageous to integrate images over time to improve accuracy.
Background	Two examples of promising work along these lines are Carceroni and Kutulakos 8 and Torresani et al. 34 ; both studies demonstrated reconstructions of moving cloth.
Method	Because our framework for estimating cloth simulation parameters is independent of the cloth model, we can, in principle, select a specific model that meets a set of criteria such as accuracy or simulation speed.
Method	Our choice of a cloth model was guided by two principles, realism and practicality.
Method	We wanted to use a model that was sophisticated enough to capture the detailed dynamic behavior found in real fabrics but still straightforward to implement.
Method	Because our intention was to apply the learned cloth model parameters to arbitrary garments with varying triangle resolution, it was also important that the cloth parameters correctly scale to varying resolutions of cloth.
Method	We used the model described by Baraff and Witkin as the basis for our cloth simulator 4 .
Method	This model has sufficient richness to produce a wide variety of cloth behaviors.
Method	The underlying meshing is triangular, making clothing modelling easier.
Method	More importantly, its input parameters are independent of meshing, so that parameters recovered on one mesh (the test swatch) can safely be transferred to another (the skirt).
Background	While nonlinear models such as the buckling behavior of Choi and Ko 9 could potentially capture more realistic details of cloth, there is no straightforward way to scale the parameters of these models to meshes of varying resolutions.
Result	We expect that future application of our parameterestimation framework to other scale-invariant cloth models will provide even more realistic results.
Background	The model developed by Baraff and Witkin formulates the energy of a particular triangle in terms of so-called condition functions C(x) such that the total potential energy associated with the system is given by E u = k s C(x)C T (x) ( 1 ) 2 where k s is a stiffness coefficient associated with the particular condition function.
Method	We thus associate a stiffness coefficient k s and a damping coefficient k d with each of the C(x).
Background	In their paper, Baraff and Witkin describe a set of C(x) consisting of an in-plane stretch term, an in-plane shear term, and an out-of-plane bending term, giving a total of six parameters we can use to tune the internal cloth model.
Method	We note, however, that (as they allude to in footnote 5) energy should scale linearly with triangle area to ensure scale independence.
Method	In the course of running our experiments, we discovered that a linear drag model such as that used in previous cloth work 4 , 9 was not able to capture dynamic aspects of cloth.
Method	In order to add additional air-drag degrees of freedom to our cloth model without resorting to fully modeling aerodynamics 25 , we developed a simple nonlinear alternative.
Method	To calculate the drag force on a triangle, we decompose the average velocity on the face into two components, one normal to the surface (v N ) and one tangential (v T ).
Method	Total drag force is then a linear function of tangential velocity and a quadratic function of normal velocity, with an additional term k f that controls the degree of nonlinearity,        f drag = −a 1 + k N k |v f |v N | N 2 | 2 |v v N N | + k T v T where a is the area of the given triangle.
Method	The linear term        is merely Stokes’s law 1 ; the quadratic term matches better the experimental behavior of macroscopic bodies in low Reynold’s number flow 14 .
Method	The addition of the |v N | 2 term in the denominator which makes the force asymptotic as v N → ∞ was partially motivated by the observed phenomenon of drag crisis 14 , where under certain circumstances the drag can actually drop at the onset of turbulence 1 .
Method	The optimizer is free to eliminate this behavior or other terms of this equation by setting the corresponding parameters to zero.
Method	Initially, we used a first-order implicit Euler time integration scheme similar to the one described by Baraff and Witkin 4 .
Result	Unfortunately, we found that implicit integration introduced damping which could not be eliminated by optimizing cloth parameters.
Result	We had more success in matching realistic cloth motions by using higher-order explicit methods.
Method	The results in this paper all use an adaptive 4thorder accurate Runge-Kutta methods with embedded error estimation 2 .
Method	While this method offers the advantages of familiarity and automatic bounding of error, it is rather slow, and recent work suggests that using 2nd-order backward differences 9 or Newmark schemes 7 may be a better choice.
Method	For collision handling, we use a model similar to Bridson and colleagues 6 which combines repulsion forces with impulses to robustly prevent all collisions before they occur.
Result	However, separating repulsion forces from the cloth internal dynamics and applying them outside the Runge-Kutta solver affected stability and resulted in visible artifacts.
Method	Instead, we apply repulsion forces inside the solver loop, so that the solver’s own internal error estimation can remove these artifacts.
Result	The drawback of this technique is speed, because the system must check for collisions every time it evaluates the state derivatives (as opposed to once every collision timestep as in Bridson et al. 6 ).
Method	To achieve acceptable performance, we used a number of collision culling algorithms, including hybrid top-down/bottom-up update 24 , fast triangle reject tests 26 , and a curvature-based criterion for rejecting self-collisions that was first introduced by Volino and Thalmann 38 and later refined by Provot 30 .
Method	We use a perceptually motivated metric to compare the motion of cloth in simulation with a video sequence of real fabric motion.
Method	Our algorithm compares the two sequences frame by frame and computes an average error across the entire sequence.
Background	Real fabrics exhibit a wide variety of motion ranging from soft and flowing (satin) to stiff (linen).
Result	Our metric captures the complex dynamics of cloth motion and also helps to distinguish between different fabrics.
Background	Researchers in computational neurobiology hypothesize that the human perceptual system is sensitive to moving edges in video 11 , 12 , 36 .
Background	Studies have shown that the receptive fields of simple cells in the macaque cortex act as edge or line detectors, responding to oriented edges or lines in natural scenes 19 , 35 , 10 .
Background	In cloth, these edges correspond to folds, which are regions of high variation in shape.
Method	Hence, our perceptually motivated metric for cloth compares two video sequences, one from simulation and one from the real world, and returns a number that measures the differences in their folds.
Method	The metric also penalizes the silhouette mismatch between the two sequences.
Background	Haddon and Forsyth 15 , 16 describe a learning approach for detecting and grouping folds (and grooves) in images of fabrics.
Background	Their technique can handle lighting effects caused by diffuse inter-reflections in cloth.
Background	However, most fabrics have very complicated reflectance properties.
Method	In our experiments, we normalize the effects of lighting and material reflectance by projecting a structured light pattern of horizontal stripes onto the fabric.
Method	From the light-striped video sequence, we compute the dominant orientation for each edge pixel by convolving it with a steerable filter bank 13 .
Method	In our implementation, we use the G2/H2 quadrature pair with kernel size 12 as the basis filters.
Method	We convolve the image with the filter bank, compute the filter coefficient responses, blur the coefficients using a gaussian kernel, and compute the dominant orientation from these coefficients.
Method	We define the resulting orientation image as an angle map, shown in Fig. 1 .
Method	The angle map, which measures the local orientation of the projected pattern, has a constant value when the surface is planar and varies at folds.
Method	We threshold the gradient of the angle map to get a gradient mask M k for each frame of video ( Fig. 1 ).
Method	The gradient mask is non-zero at regions of high gradients, corresponding to folds, and zero at planar regions.
Method	We preprocess the input video sequence to compute the angle map at each frame.
Method	Similarly, in simulation, we render the cloth shape using the current parameter values and project the same striped pattern, to get a striped simulation sequence.
Method	We compute the angle map at every frame in simulation from this sequence.
Method	We then compute the SSD of the angle values for all overlapping points in the two angle maps.
Method	We pre-multiply this difference with the gradient mask, which helps to emphasize the differences in fold regions over planar regions ( Fig. 2 ).
Method	We sum the error across all frames to compute the overall error across the entire sequence.
Method	The error at any particular frame k along the sequence is S x S y E k f old = ∑ ∑ M k (i, j) · (θ real k (i, j) − θ sim k (i, j)) 2 ( 5 ) i=0 j=0 where (S x , S y ) is the size of the angle maps and θ real , θ sim are the angle values from real and simulation angle maps respectively.
Method	This penalty is proportional to the difference between the two silhouettes, i.e., the number of mismatched pixels.
Method	S x S y E k silh = ∑ ∑ | A k real (i, j) − A k sim (i, j) | ( 6 ) i=0 j=0 where 1, inside silhouette A k (i, j) = 0, otherwise ( 7 ) The total error in frame k is E k = E k f old + αE k silh ( 8 ) where α is a user-defined weight that controls the relative contribution of the two terms.
Method	We used a value of 0.1 for α in our experiments.
Method	The error across the entire sequence of length N frames is given by N E = ∑ E k ( 9 ) k=1
Method	We use optimization to estimate the parameters of the cloth simulator from video.
Method	Before we describe the details of the optimizer, we look at the error space of the angle map metric, which gives us useful insight about the parameters of the system.
Method	To generate this error map, we compared the angle map from one frame in video with several angle maps in simulation.
Method	From the figure, it is evident that the error space is fairly noisy, with many local minima, motivating the need for a global optimization technique.
Method	In addition to the parameter values, we estimate the relative importance of each parameter for a given experiment by performing a perturbation analysis at the solution point.
Method	The importance or sensitivity of a parameter p depends on its local gradient ∂E ∂p ; it relates a small change in parameter value to a change in the error value.
Method	Instead of computing the gradient, we robustly compute the variability of the param∂p eters, defined as ∂E .
Method	To compute the variability, we perturb each parameter of the simulator individually up to ±0.20% of its value, compute the error and fit a quadratic to the data ( Fig. 4 ).
Method	From the quadratic, the variability is computed as the change in parameter values that results in a 1% change in the error.
Method	Parameters with low variability have high sensitivity and are estimated reliably for a given experiment.
Method	We use simulated annealing to find the parameters that minimize the error function given in eq.
Method	Simulated annealing initially explores the space in a semi-random fashion and eventually takes downhill steps.
Method	The likelihood that it will take a step in a direction that is not locally optimal is a function of the temperature ( Fig. 5 ).
Method	We chose to use the continuous simulated annealing method presented in Press et al. 28 , which combines the Metropolis algorithm with the downhill simplex method for continuous n-variable optimization.
Method	We found it useful to reset the simplex with the current best solution when the temperature reduces by a factor of 3.
Method	Prior to optimization, we perform an exhaustive search for each fabric, where we choose four values for each cloth parameter across its entire range.
Method	This corresponds to a very coarse sampling of the parameter space.
Method	We simulate the fabric for all points in this coarse set and compute the error for each point by comparing against the real fabric.
Method	We initialize the optimizer with the point corresponding to the minimum error.
Method	We have found that this strategy allows the optimizer to locate a good minimum of the space.
Method	We designed a few simple experiments to capture the dynamics of the different types of fabrics and the air/cloth interaction.
Method	The experiments are easy to perform, capture, and repeat; yet they demonstrate the complex dynamics of cloth motion.
Method	The parameters obtained from the simple experiments were used to simulate skirts and other complex fabric motions.
Method	In essence, our experiments were designed to be a calibration setup for estimating the static and dynamic parameters of a cloth simulator.
Method	We perform two estimation experiments for each fabric, a static test and waving test.
Method	We used four types of fabrics: linen, fleece, satin and knit.
Method	These fabrics exhibit a wide range of static and dynamic behavior and span a large range of real fabrics.
Method	We perform the static and waving tests on a small swatch of each fabric.
Method	In the static test, the two top corners of the fabric are held stationary, and the fabric is allowed to sag under gravity.
Method	For a fixed separation between the top corners, different fabrics attain different static shapes as shown in Fig. 6 .
Method	The static test give a good estimate for the static stiffness and bend parameters.
Method	In the waving test, one of the top corners of the fabric is fixed and the other corner is moved back and forth ( Fig. 7 ).
Method	The waving motion of fabrics in simulation is affected by their dynamic parameters.
Result	We see from the accompanying videos that real fabrics exhibit a wide range of interesting motions.
Result	Different fabrics also exhibit different types of motion for the same input excitation.
Method	We designed the waving motion to roughly match the types of motion occurring in real garments such as skirts.
Method	This gives reasonable estimates for cloth parameters while avoiding the need to optimize directly on complex fabric geometries (e.g. skirts) involving many collisions.
Method	We measured the mass and dimensions of the fabrics.
Method	We also accurately measure the position of the two top corners using a Vicon motion capture system.
Method	We compute the projection matrices for the camera and projector using a calibration grid comprising of several motion capture markers.
Method	We performed two trials per experiment, each with slightly different initial conditions and optimized on the first 50 frames of video in each trial.
Result	Each trial took approximately 50 hours to converge on a 2.8GHz Intel Xeon processor (approximately 600 iterations of simulated annealing).
Method	For this reason, we started the optimizations on the two trials (per fabric) with the same initial guess and chose parameters (optimized) that minimized the total error on the two trials.
Method	We perform optimization on two trials for each fabric; the results are shown in Fig. 8 and Fig. 9 .
Method	The two trials have different separation distances between the top corners.
Method	For each fabric, we optimize for six parameters: stiffness and damping parameters for stretch, shear, and bend.
Method	The air drag parameters were fixed for this experiment to the mid point of their range of values.
Method	The initial values for the two trials are obtained from a coarse exhaustive search (four values per parameter).
Result	However, there is a significant disparity in the final optimized values from the two trials.
Method	In order to understand this disparity, we performed a set of optimizations (on a single fabric) with very similar initial values.
Result	From the table, we see that the final error values are very close.
Result	We get consistent estimates for parameters that have lower variability (e.g., bend, stretch).
Result	Parameters with high variability are estimated poorly, because their values do not contribute sufficiently to the error.
Result	This result is consistent with our intuition that static tests cannot be used to estimate dynamic parameters like stretch and shear damping or air drag and motivates the waving test, which excites both the static and waving parameters.
Method	We optimize for nine parameters in the waving test: the six cloth stiffness and damping parameters and three air drag parameters ( Fig. 10 ).
Method	As with the static test, we initialize the static parameters in this test from a coarse exhaustive search.
Method	The dynamic parameters were initialized using a random guess.
Method	We optimized on the first 50 frames of the sequence.
Result	The final values of the parameters from the two trials differ in part because the variability of the parameters is still fairly high ( Fig. 11 ).
Result	Different motions or larger sequence might further reduce the variability of the parameters.
Method	We choose the parameter set that minimizes the sum of the error from the two trials.
Result	For instance, in the following example of fleece waving, we choose the parameters from experiment 2.
Future Work	However, we believe that a more general solution for parameter identification using our framework is to simultaneously optimize across multiple trials of different experiments.
Result	These two figures show the progress of the optimization and indicate that the minimum corresponds to a visually compelling match.
Method	We compare each of the four optimized angle maps from simulation (corresponding to the four fabrics) with the four angle maps computed from video.
Result	We see that each fabric in simulation has a minimum error when compared to its counterpart in reality.
Method	We evaluated the parameters obtained from optimization on longer sequences (150 frames).
Method	We also validated the estimated parameters on a long sequence actuated by a robot ( Fig. 15 ).
Method	We used a a Mitsubishi PA-10 robot arm to move the corner point along a simple sinusoidal trajectory, thereby ensuring that we had the same input motion across different fabrics.
Method	Finally, we used the optimized parameters to simulate a skipping motion of a human actor wearing a skirt ( Fig. 16 ).
Method	Here, the actor repeats the same skipping motion (approximately) for the four different skirts.
Method	We used data from a full body optical motion capture of the actor performing the same skipping motion (in another trial) to drive the character for the cloth simulation.
Result	The results show that the parameters obtained from our optimization approach approximately capture the static shape and dynamic properties of skirts of different materials.
Result	This paper describes an optimization framework for identifying the simulation parameters of cloth from video.
Result	We captured the behavior of small swatches of fabric using a set of dynamic and static tests and demonstrated that the optimizer could identify appropriate simulation parameters from those tests.
Result	These parameters produced four distinct and recognizable fabrics when applied to a more complex simulation of a skirt as it was driven by motion capture data from a human figure.
Result	The cloth model was not the main focus of this research, yet in early versions of the system it was often the bottleneck in achieving appealing results.
Result	To match a video sequence accurately, the cloth physics model as well as the collision algorithms must be chosen carefully.
Result	Instabilities in the collision handling will cause perceptible quivering in the motion of cloth.
Result	Similarly, extra damping introduced by the integration method makes crisp folds impossible to match.
Method	The parameters must also be independent of the resolution of the mesh so that they can be identified on low resolution swatches and applied to higher resolution garments.
Background	Progress is being made in these areas, however, and cloth models are continually improving.
Background	For example, Bridson et al. 7 introduces a scale-independent bend model with encouraging results.
Result	Our cloth model does not diverge significantly from previous models discussed in the literature.
Result	Our only major addition was a simple nonlinearity we introduced into the drag model.
Result	Hence, our approach should generalize to any parametrized cloth model that produces a sufficiently rich set of physically realistic motions.
Result	Although the skirt is far more complex than the swatches that were used to determine the parameters, it is not as complex as many garments, for example, a form-fitting pair of pants or a tailored blazer.
Result	For more complex garments, choosing the parameters via optimization on small, flat swatches may not be sufficient because the shape of the garment is determined by darts, pleats and by the interplay of different fabrics (wool, lining, and interfacing, for example).
Result	More complex garments may require the hand design of additional tests that mimic particular behaviors or elements of the garment in isolation.
Result	Moreover, the model might need extra parameters to handle anisotropic effects, hysteresis and coupling effects (stretching along one direction causing shrinking in the other direction), all of which would need specialized tests.
Method	En route to the metric used in the experiments described here, we tried a number of other metrics: comparing the overlap of the silhouettes, the distance function between silhouette edges, and using information from internal edges marked on the fabric.
Result	The metric that measures folds and silhouettes, in concert with the projector for the light stripes, proved to be a simple and effective metric that far outperformed our earlier attempts.
Result	The space of possible metrics is vast, of course, but one class of metrics that we did not experiment with are statistical metrics that compute a function of the shape of the fabric across time rather than evaluating the match on a frame-by-frame basis.
Method	The experiments with the swatches were carefully controlled to have initial conditions for the simulation that matched those seen in the video.
Method	If instead, we were to optimize on more complicated garments, then such tight control of the initial conditions is unlikely and a statistical metric might be preferable.
Result	Such a metric might, for example, compute the average number of folds across a time sequence rather than looking for a fold to appear at a particular location on the swatch.
Future Work	Our hope is that this work will promote a more rigorous evaluation of various cloth models, especially with respect to how accurately they match reality, and perhaps lead to creation of a standardized set of benchmarks for cloth simulation models.

Method	We use a bar-network (bar-net) as a deforming mechanism.
Result	This technique can be used similarly to a conventional skinning tool, but can also make a skin surface behave in a physically plausible manner due to the inherent physical properties of the network.
Background	A bar-net is a structure commonly used in structural engineering.
Background	Its shape depends on the structural and material properties and the forces acting upon it.
Problem	Computing the rest shape of an arbitrary bar-net is a time-consuming non-linear problem.
Method	In order to speed up the computation and also for such a bar-net to be used intuitively to help computer animation, we have defined a set of properties that a desirable bar-net should satisfy.
Method	This allows a bar-net shape finding problem to be solved using linear equations.
Method	We adopt a two-layer structure for the representation of a skin surface, including a coarse mesh and a fine mesh.
Method	To deform a skin surface, we couple a bar-net to its coarse mesh, which in turn deforms the fine mesh when the coupled bar-net is deformed.
Method	The fine surface mesh can be of different forms, including Nurbs, subdivision surfaces and polygons.
Background	Skin deformation resulting from the movement of characters, such as humans and animals, is one of the most interesting and challenging topics in computer animation.
Problem	The modelling and deformation of such characters are inevitably complicated and timeconsuming, because of their structural complexity.
Problem	While realism is important, other factors such as intuitiveness, ease of interaction and computational cost are also of great importance in animation production.
Problem	Often a compromise among these factors has to be reached.
Background	There are two general categories of methods in animation practice: simulation and authoring.
Background	Simulation 1–3 refers to the use of a mathematical model to automatically recreate the physical reality on computers.
Background	A simulation method lets the animator easily create certain effect which could be otherwise almost an impossible mission with manual manipulations.
Background	However, the disadvantage is also obvious.
Background	Although the simulation techniques provide some parameters for the animator to control the animation, the connection between these parameters and the result is often implicit.
Background	It is usually difficult for an artist to understand the exact physical meaning of these parameters and connect them to the final outcome.
Background	Second, such methods are often computationally expensive.
Background	The authoring methods refer to those that the animator can use to manipulate the modelling or deformation directly.
Background	The animator is able to see the result immediately and has a full control over the deformed shape of the character in question.
Background	Both types of methods were around for a long time.
Background	However, animators turn to favour those tools that they feel they have a control and can evaluate the results directly.
Result	In this paper we present a new skinning technique for the deformation of computer-animated characters.
Result	A key advantage is that it combines the strengths of both prevalent categories discussed above.
Result	This technique is based on a physically inspired deformation model from structural engineering, known as the bar-networks (bar-nets) and can therefore deform realistically based on the physical properties leading to physically plausible outcomes.
Result	Meanwhile, instead of letting the mechanical model taking its full course, the animator is able to operate it as a physically based authoring tool in the same way as other conventional deformation tools.
Result	We call this technique the bar-net driven deformations.
Background	In animation practice, either for the film industry or games design, it is quite often for each character model to have two layers of mesh, a rough mesh (low resolution) and a fine mesh (high resolution).
Background	The high-resolution (high-res) mesh may take various forms, such as Nurbs, subdivision surfaces and polygon meshes.
Background	The detailed skin shapes including skin deformations, wrinkle, squama and feather are created on this layer.
Background	Because the mesh is very dense involving fine detail, it is inefficient to animate directly on this layer.
Background	The low-resolution (low-res) mesh thus works as an efficient intermediate layer for the modelling and deformation of the fine skin layer.
Method	Our technique adopts this two-layered strategy.
Method	The animator creates almost all skin deformation effects on the low-res layer.
Method	In order to take advantage of the physics, we couple an aforementioned mechanical bar-net with the low-res mesh in areas where deformations are expected to occur.
Method	This low-res layer gets deformed physically and in turn deforms the high-res mesh of the character’s skin model.
Method	In order for a mechanical network to be useful in skin deformation for animated characters, we devise a set of properties for the network to satisfy.
Method	These properties allow the behaviours of skin and anatomic tissues, e.g. muscle groups, to be mimicked intuitively in computer animation and to be computed rapidly.
Background	What needs pointing out is although there is a similarity between a bar-net and a mass–spring model, they have substantially different behaviours.
Background	A mass–spring model will not be able to satisfy the properties we define here.
Background	Most of the techniques on character deformation can be roughly categorized into two groups: authoring and simulation methods, although the boundary between them does not always seem clear.
Background	The technique of Free Form Deformations (FFDs) first introduced by Sederberg and Parry 4 remains popular and has been adopted by many animation software packages due to its simplicity and modelling speed.
Background	FFDs were later extended by several other researchers.
Background	5–8 All these techniques are purely geometric in nature and make no attempt to simulate the physical properties or behaviours of a character.
Background	Based on the FFDs, two very popular deformation tools were developed in Maya, the Lattice and Wrap deformers.
Background	An intuitive attempt to deform a character was involving a skeleton into skin deformation.
Background	This approach has a long history and it treats the skin as a shell that moves by an explicit function of the skeleton.
Background	Vertices of the skin are deformed by a weighted combination of the joint transformations of the character’s skeleton.
Background	9–13 Collectively, such methods are known as the smooth skinning.
Background	They are easy to understand and intuitive to use.
Background	A tedious part is the proper assignment of the weights.
Background	In production, the weights are painted by the animator, and thus the animator has full control over the outcomes.
Background	The smooth skinning approach suffers from some notorious drawbacks, called the candy wrapper effect or collapsing elbow effect, due to its lack of consideration of volume preservation for the soft tissues.
Background	The example-based methods were developed as an alternative in order to overcome this kind of problems 14–17 and have had some success.
Background	With this method, which is called Blend Shape in animation production, the animator can control the exact appearance of the character.
Background	In facial animation, for example, the animator often needs to dictate how a facial model deforms to achieve different expressions.
Background	On the downside, however, a large number of models have to be made in the pose space and stored for shape interpolation.
Background	This is an expensive process.
Background	The drive for realism in computer graphics has lead to some new modelling and deformation techniques.
Background	A group of techniques that have gained increasing popularity in the computer animation of characters are those based on characters anatomy.
Background	These models attempt to mimic their real life counterparts by reproducing their anatomical structures.
Background	These anatomy-based skinning methods differ on the complexity of the models and their behaviours of the underlying anatomical structures.
Background	Some use simple muscle shapes, such as abstract muscle operators, 18 meatballs, 19 some employ detailed models.
Background	20–23 The obvious advantage of this group of methods is its ability in achieving detailed visual quality during animation.
Background	One of the difficulties of these techniques, 24–28 however, is that they are indirect to use, as one has to model the anatomical structures before its appearance arrives.
Background	Achieving a particular look of the skin requires the determination of the shape, number and the layout of the muscles underneath.
Background	Until the skin mesh envelops the underlying structure, it is very hard to anticipate how the character looks like from the outside.
Background	To retain the advantage of the anatomy-based technique without losing intuitiveness, recent research has looked into the issue of estimating the muscles from the skin shape.
Background	29–30 This new technique has had a degree of success.
Background	The current limitations are that they could only use simple muscle shapes, which are sufficient in obtaining detailed deformations.
Background	Anatomy based multi-layered models have significantly improved the realism of the modelling of complex living creatures.
Problem	Character animation based on the deformation of underlying anatomical structures, such as muscles or fat, is a very complicated process.
Problem	Issues like mechanical forces, material properties and collision among anatomic structures all need to be properly addressed.
Problem	The computational cost is inevitably excessive.
Problem	Such computational costs place severe restrictions on many applications.
Problem	Our bar-net driven skinning method endeavours to take advantage of the anatomy-based approach, the smooth skinning approach and the physically based approach.
Method	It follows the current animation workflow, except that a bar-net is coupled with the low-res skin layer.
Method	When the low-res mesh (or a part of it) is coupled with a bar-net, the couple mesh is called the control mesh in this paper.
Method	Bar-nets deform according to both the external forces it is subject to and the stiffness properties of the network.
Method	By controlling these two factors, the animator can easily create the various skin deformation effects including muscle bulge, wrinkles and creases easily.
Method	The control mesh is bound to the character skeleton in the same way as the traditional smooth skinning method.
Method	The bar-nets work like a deformer (a term used in many animation packages, e.g. Maya) to change the shape of the skin surface.
Method	It is compatible with all the other deformation tools incorporated in current animation software.
Method	They can accumulatively deform the skin shape in a certain order which can be easily changed by the animator on the fly.
Method	The fine mesh, either in the form of Nurbs, subdivision surfaces or polygons, is deformed by the control mesh using the wrapping deformation method 8 which is available with many commercial animation packages.
Method	Further detailed deformations including wrinkle can also be added on either by manipulating the skin surface directly or by coupling a bar-net with the fine mesh using the same mechanism.
Method	A bar-net connects n s points, P i , in three-dimensional space with straight-line segments, called bars.
Method	These points on the net are known as nodes.
Method	The nodes can be either fixed or free.
Method	Fixed nodes will not have their positions changed regardless of whether they are subjected to external forces.
Method	Free nodes can be moved to balance the acting forces on the net.
Method	Each bar connects two nodes.
Method	These bars can be stretched and squashed resulting from the positioning of the end nodes, but they cannot be bent.
Method	The network described above is in fact a graph with links connecting pairs of nodes.
Method	A matrix C s , called the branch–node matrix can be formed, which represents in a tabular form the graph of the network.
Method	Assuming that there are n free nodes and n f fixed nodes, the branch–node matrix can be further subdivided into two sub-matrices, C and C f , by grouping the free-node columns and fixed-node columns of the original matrix, respectively.
Method	These matrices are used in computing the rest shape of a bar-net.
Method	A deformable part of the low-res mesh of a character can be considered as a bar-net.
Method	This analogy establishes a natural link between a mechanical bar-net and a surface patch.
Method	If a bar-net is coupled with a surface, the surface can be made to behave like a piece of elastic material.
Method	Thus many numerical methods developed in structural and mechanical engineering for the manipulation of structures and networks can be applied to control the deformation of the surfaces.
Method	Deforming the bar-net deforms the coupled surface, hence the name bar-net driven deformation.
Method	Bar-nets can have any arbitrary topology.
Method	They are not restricted to a quadrilateral topology unlike most curved surface patches.
Background	Quadrilateral patches are the easiest to control and there have been many algorithms developed to implement them.
Background	But methods for controlling the deformation of a non-quadrilateral surface patch analytically remain an interesting research topic.
Background	Such a problem could be resolved by coupling a general mechanical bar-net with the control points of a surface patch of the same topology.
Method	The principle idea of the proposed bar-net driven deformation technique is to regard the deformable area of an animated creature as a network, which deforms under an acting force.
Method	The final shape of the surface represents the rest shape of the network and is the result of the balance of all external and internal forces.
Method	One does not need to worry about the shape of the network itself.
Method	This because we use a bar-net only as a control mechanism.
Method	Changing the stiffness with other parameters unchanged has an influence on the whole network.
Method	This is in line with the physical property of human tissues and therefore makes physical sense.
Method	The x, y, z components of the external loads applied to the free nodes (non-fixed nodes) have independent influences on the deformation.
Method	The x component of the displacement is only determined by the x component of the applied force, and similarly for the y and z components.
Method	So when the animator wishes to finetune the effects on the x, y or z direction separately, the surface will deform as expected.
Method	The deformation of the free nodes satisfies the superposition principle.
Method	In other words, if one free node is subject to the influence of a number of forces simultaneously, the general deformation applied to the node is the same as the sum of all the deformations generated by applying these loads independently.
Method	The benefit from this property is that several muscles, bones, fat tissues can affect the skin deformation simultaneously through summing up of their individual forces.
Background	Network form finding is always a numerically complicated problem in mechanical and structural engineering.
Background	Various numerical methods exist.
Background	As far as most mechanical networks are concerned, the relationship between the equilibrium state and the acting forces is non-linear.
Background	Shape change cannot be trivially related to the magnitude and direction of the external forces.
Background	Often numerical algorithms are deployed to determine the rest form of a network, which is inevitably time-consuming and not very useful for animation production.
Method	In our case, the effect of stiffness of a network can be approximated by the quantity of force-length ratios of all the bars.
Background	Some researchers call this quantity the force density.
Method	Using this stiffness parameter, we found the force density method 31 satisfies the above-defined properties.
Method	Using a bar-net together with the force density form finding method, the prevailing advantages of this technique are its speed of computation and intuitiveness in shape control.
Method	Coupling bar-nets with a skin surface makes it ‘mechanically deformable’.
Background	Skin deformation can happen around the joints where its surface bends and also in places where the underlying anatomic structure, such as muscles, pushes and pulling the skin surface.
Method	Using above defined bar-net properties, deformations are achieved by applying virtual forces to the appropriate free nodes of the control mesh.
Method	We use the force density parameter (equivalent to stiffness) and external forces to control the deformation.
Method	Multiple bars can be grouped together to simulate the effect of muscle groups.
Method	The user can manipulate the force on each node to tune the deformation interactively.
Method	One can also change the force densities to make the network firmer or softer.
Method	Forces are applied to only eight nodes of the bar-net.
Method	In this example, the force densities are kept unchanged.
Method	The gradually changed forces on the control mesh are bound to the elbow rotation angle, which produce both the bulge effect and compensate for the volume loss that the traditional smooth skinning method suffers.
Background	Deformed muscles always change the shape of the skin surface.
Method	Using the model of a human arm, we illustrate how to generate the muscle effect with bar-nets.
Background	There are approximately 50 muscles in a human upper limb, most of which are large and complex.
Background	Muscles usually act in groups, some muscles act to move the joint, some to support the movement by avoiding unwanted secondary movements.
Background	The combination of these actions causes the muscles, hence the arm, to deform.
Method	In the animated arm model, we are only concerned with the muscles producing major influence on the skin.
Method	The deformation of the forearm is complex but relatively unnoticeable.
Method	Therefore, in this case, only the deformations caused by biceps brachii and triceps brachii are generated.
Method	When the arm flexes, the biceps brachii contracts and bulges.
Method	At the same time, the triceps brachii relaxes to allow this action.
Method	The opposite occurs during the extension of the forearm.
Method	The biceps brachii and triceps brachii are positioned on opposite sides of the upper arm.
Method	Accordingly only the nodes lying around the central line of the two muscles are set to free, all other nodes are fixed.
Method	All the bars in the network are initially assigned a uniform force density.
Method	Because of the tendon of the biceps brachii, flexing the arm deforms the biceps brachii in all three directions (x, y and z): it is shortened along the arm due to its contraction and it bulges in the other two directions to maintain its volume.
Method	To simulate the force of the muscles, we apply some simple loads to the midpoints of the network as shown in Figure 3(b) .
Method	These loads deform the surface to form a natural muscle bulge, as shown in Figure 3(c) .
Method	This example demonstrates that the animator can easily shape the characters using the virtual forces as user-handles.
Method	There are 2891 vertices and 2816 faces in the subdivision model.
Method	While in the bar-net, there are 12 free nodes which are the only necessary resources involved in the form finding and it involves little computation cost.
Method	Local deformations can be similarly achieved by changing the force densities.
Method	For example, reducing the force density of the network increases the size of the bulge effect as shown in Figure 3(d) .
Background	The human shoulder is a typical area where notorious skin deformities occur using a traditional skinning method.
Result	Most computer-animated characters are complex both geometrically and topologically.
Result	The use of quadrilateral meshes to model the geometry of such characters is frequently inadequate.
Background	Computer-animated characters come in different shapes, e.g. in a form of a human, an animal or a completely imaginary figure.
Background	Branches, holes, non-manifolds and irregularities are possible geometric features of their body forms.
Result	Satisfying our designed properties, the network is capable of handling any connectivity (topology).
Result	In practice, an animated character can be initially modelled by sketching its basic shape roughly.
Result	This rough model is coupled with a bar-net to act as the control mesh of the character.
Result	The fine skin surface can be represented in various surface forms.
Result	Our implementation includes three major surface modelling forms: Nurbs, subdivision surfaces and polygons.
Result	Once the control mesh is deformed, it can deform the fine surface model using the Wrap deformer available in many animation packages.
Result	Bar-net driven skinning is applicable also to the modelling of wrinkle, where the bar-net is bound to the fine mesh rather than the rough mesh in order to obtain a detailed look.
Background	Character deformation in computer animation has attracted a great deal of research effort over the last two decades.
Background	The earlier models, despite being cheap, had difficulties in creating realistic character deformations.
Background	With the quest for realism, more physically based and CPU intensive computation models have emerged, notably the multi-layered anatomy-based approach.
Problem	However, in addition to the computational cost, it is undesirable to require the animator to model many muscles before the skin shape is developed.
Result	In this paper, we propose a physically motivated deformation authoring technique, called the bar-net driven skinning.
Result	Its main strength lies in the combination of speed, intuitiveness and good realism.
Result	Our technique can achieve similar results to those of the anatomy-based techniques, but in an interactive manner.
Result	Bar-nets reach their rest shape when the acted forces equilibrate.
Result	Changing the forces and/or stiffness leads to a change of their shape.
Result	Coupling a part of surface mesh with bar-nets allows the surface deformation to be controlled by manipulating the networks and can take advantage of the physical behaviour inherent to the network.
Method	In order to allow deformations to be produced quickly and intuitively, we have devised a set of properties that an ‘ideal’ bar-net should satisfy, which make intuitive shape control and fast computation possible.
Result	To deform the skin surface of a character, we couple a bar-net with a low-res mesh, called the control mesh, which links with the skin surface.
Result	This makes the skin mechanically deformable and achieves realistic deformation outcomes.
Result	We provide two types of user-handles associated with a bar-net, the virtual forces applied to the free nodes of a network and the force density values.
Result	They can be used individually as an interactive modelling tool or collectively to mimic the muscle forces from a muscle group.
Result	We have implemented this technique into prototype program in a form of a plug-in for the Autodesk Maya software ( Figure 7 ).
Result	It provides the animator with a new deformer which can be used both as a modelling and an animation tool.
Result	The animator can interactively change the fix–free status of each node, define and manipulate the forces on each free node, tune the force densities for selected bars.
Result	On the downside, the tools developed so far are still relatively primitive.
Result	The user needs to understand the basic principles of the bar-net properties before the technique can be used efficiently.
Future Work	To remedy this problem we are currently designing higher-level tools with an interactive user interface, which will hide this complexity from the user.
Method	The equilibrium shape of the net structure is reached when all the forces applied at each node sum up to zero.
Method	p x ; p y ; p z are the external load vectors.
Method	It is clear from Equation ( 4 ) that any state of equilibrium of a general network structure can be obtained by the solution of one system of linear equations, which is computationally inexpensive.

