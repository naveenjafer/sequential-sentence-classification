Simulation of cloths has been attracting the graphics community for years. Due to its highly deformable structure, it demands numerous degrees of freedom during modelling cloth movement. Physics based particle systems can provide such degrees of freedom, but is computationally inefficient, thus impractical for real time modelling. On the other hand, geometric methods have shown superior performance in preserving detailed textures and wrinkles, but is limited by the expertise of CG artists. Detecting collision between body and cloth and among different parts of cloths makes the problem more challenging. Some data driven approach exists which can reduce the computational requirements, but at the cost of visual quality. This paper describes a novel approach to this problem, which shows superior performance in real time modelling of cloths. First it analyzes a pre-simulated animation and 'learn' the motion of the cloth due to movement of underlying skeleton. Then it reproduce the behaviour in real time for variety of cloths worn on similar virtual model. Generated animations conveniently outperform traditional methods in terms of rendering time and visual quality, making it readily applicable to computer games. This method can also be adapted for modelling other objects having similar fluid-like motion. Despite having superior performance, the quality of the animation is heavily dependent on the sequences used for pre-processing. As a result, severe quality degradation is observed for motions which is not present in these training sequences.