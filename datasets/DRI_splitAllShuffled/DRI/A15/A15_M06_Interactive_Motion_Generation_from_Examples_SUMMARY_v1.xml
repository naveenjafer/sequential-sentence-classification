<?xml version="1.0" encoding="UTF-8" standalone="no"?>
<Document xmlns:gate="http://www.gate.ac.uk" name="A15_M06_Interactive_Motion_Generation_from_Examples_SUMMARY_v1.xml">


  
    3315e831b4f59b30e8bdad883c77df9ed5f301dbb0e70be6b8443d0ad5d2b311
    3vtl
    http://dx.doi.org/10.1145/566570.566606
  
  
    
      To appear in the ACM SIGGRAPH conference proceedings
      
        <Title>Interactive Motion Generation from Examples</Title>
      
      
        
          Okan Arikan
        
      
      University of California, Berkeley
      <Abstract>
<Sentence inAbstract="true">There are many applications that demand large quantities of natural looking motion.</Sentence> <Sentence inAbstract="true">It is difficult to synthesize motion that looks natural, particularly when it is people who must move.</Sentence> <Sentence inAbstract="true">In this paper, we present a framework that generates human motions by cutting and pasting motion capture data.</Sentence> <Sentence inAbstract="true">Selecting a collection of clips that yields an acceptable motion is a combinatorial problem that we manage as a randomized search of a hierarchy of graphs.</Sentence> <Sentence inAbstract="true">This approach can generate motion sequences that satisfy a variety of constraints automatically.</Sentence> <Sentence inAbstract="true">The motions are smooth and human-looking.</Sentence> <Sentence inAbstract="true">They are generated in real time so that we can author complex motions interactively.</Sentence> <Sentence inAbstract="true">The algorithm generates multiple motions that satisfy a given set of constraints, allowing a variety of choices for the animator.</Sentence> <Sentence inAbstract="true">It can easily synthesize multiple motions that interact with each other using constraints.</Sentence> <Sentence inAbstract="true">This framework allows the extensive re-use of motion capture data for new purposes.</Sentence>
</Abstract>
	  CR Categories: I.2.7 [Artificial Intelligence]: Problem Solving, Control Methods and Search—Graph and tree search strategies I.3.7 [COMPUTER GRAPHICS ]: Three-Dimensional Graphics and Realism—Animation Keywords: Motion Capture, Motion Synthesis, Human motion, Graph Search, Clustering, Animation with Constraints
      
        
          D. A. Forsyth
        
      
    
    
      
        <H1>1 Introduction</H1>
      
      <Sentence inAbstract="false" summaryRelevanceScore="2.67">Motion is one of the most important ingredients of CG movies and computer games.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.67">Obtaining realistic motion usually involves key framing, physically based modelling or motion capture.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.67">Creating natural looking motions with key framing requires lots of effort and expertise.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.67">Although physically based modelling can be applied to simple systems successfully, generating realistic motion on a computer is difficult, particularly for human motion.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="3.67">A standard solution is motion capture: motion data for an approximate skeletal hierarchy of the subject is recorded and then used to drive a reconstruction on the computer.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="3.33">This allows other CG characters to be animated with the same motions, leading to realistic, “human looking” motions for use in movies or games.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="1.0">The biggest drawbacks of motion capture are:
      1.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="3.67">Most motion capture systems are very expensive to use, because the process is time consuming for actors and technicians and motion data tends not to be re-used.</Sentence>
      2. <Sentence inAbstract="false" summaryRelevanceScore="3.67">It is very hard to obtain motions that do exactly what the animator wants.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="3.67">Satisfying complex timed constraints is difficult and may involve many motion capture iterations.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.67">Examples include being at a particular position at a particular time accurately or synchronizing movement to a background action that had been shot before.</Sentence>
      <Sentence inAbstract="false" summaryRelevanceScore="3.67">In order to make motion capture widely available, the motion data needs to be made re-usable.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="4.00">This may mean using previous motion capture data to generate new motions so that certain requirements are met, transferring motions from one skeletal configuration to another so that we can animate multiple figures with the same motion without it looking “funny”, or changing the style of the motion so that the directors can have higher level control over the motion.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="1.0">There are three natural stages of motion synthesis:
      1.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="3.67">Obtaining motion demands involves specifying constraints on the motion, such as the length of the motion, where the body or individual joints should be or what the body needs to be doing at particular times.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="3.33">These constraints can come from an interactive editing system used by animators, or from a computer game engine itself.</Sentence> 2. <Sentence inAbstract="false" summaryRelevanceScore="3.67">Generating motion involves obtaining a rough motion that satisfies the demands.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="5.00">In this paper, we describe a technique that cuts and pastes bits and pieces of example motions together to create such a motion.</Sentence> 3. <Sentence inAbstract="false" summaryRelevanceScore="4.00">Post processing involves fixing small scale offensive artifacts.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="4.00">An example would involve fixing the feet so that they do not penetrate or slide on the ground, lengthening or shortening strides and fixing constraint violations.</Sentence>
      <Sentence inAbstract="false" summaryRelevanceScore="5.00">In this paper, we present a framework that allows synthesis of new motion data meeting a wide variety of constraints.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="4.33">The synthesized motion is created from example motions at interactive speeds.</Sentence>
      
        <H1>2 Related Work</H1>
      
      <Sentence inAbstract="false" summaryRelevanceScore="2.00">In the movie industry, motion demands are usually generated by animators.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.67">However, automatic generation of motion demands is required for autonomous intelligent robots and characters <CitSpan>[Funge et al. 1999]</CitSpan>.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.00">An overview of the automatic motion planning can be found in <CitSpan>[Latombe 1999; O’Rourke 1998]</CitSpan>.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="3.00">Generating motion largely follows two threads: using examples and using controllers.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.67">Example based motion synthesis draws on an analogy with texture synthesis where a new texture (or motion) that looks like an example texture (or motion example) needs to be synthesized <CitSpan>[Efros and Leung 1999; Heeger and Bergen 1995]</CitSpan>.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.00">Pullen and Bregler used this approach to create cyclic motions by sampling motion signals in a “signal pyramid” [2000].</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.00">They also used a similar approach to fetch missing degrees of freedom in a motion from a motion capture database <CitSpan>[Pullen and Bregler 2002]</CitSpan>.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.00">The sampling can also be done in the motion domain to pick clips of motions to establish certain simple constraints <CitSpan>[Lamouret and van de Panne 1996; Schodl et al. 2000]</CitSpan>.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.00">A roadmap of all the motion examples can be constructed and searched to obtain a desired motion <CitSpan>[Choi et al. 2000; Lee et al. 2002; Kovar et al. 2002]</CitSpan>.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.00">The clips in this roadmap can also be parameterized for randomly sampling different motion sequences <CitSpan>[Li et al. 2002]</CitSpan>.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.00">The motion signals can also be clustered.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.00">The resulting Markov chain can be searched using dynamic programming to find a motion that connects two keyframes <CitSpan>[Molina-Tanco and Hilton 2000]</CitSpan> or used in a variable length Markov model to infer behaviors <CitSpan>[Galata et al. 2001]</CitSpan> or directly sampled from to create new motions <CitSpan>[Bowden 2000]</CitSpan>.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.67">This is similar to our work.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="4.33">However, our clustering method does not operate on body configurations and our probabilistic search strategy is more effective than dynamic programming as it will be explained below.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.00">Types of probabilistic search algorithms have also been used in physically based animation synthesis <CitSpan>[Chenney and Forsyth 2000]</CitSpan> and rendering <CitSpan>[Veach and Guibas 1997]</CitSpan>.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.00">Controller based approaches use physical models of systems and controllers that produce outputs usually in the form of forces and torques as a function of the state of the body.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.00">These controllers can be designed specifically to accomplish particular tasks <CitSpan>[Brogan et al. 1998; Hodgins et al. 1995]</CitSpan> or they can be learned automatically using statistical tools <CitSpan>[Grzeszczuk and Terzopoulos 1995; Grzeszczuk et al. 1998; Mataric 2000]</CitSpan>.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.00">The motion data can also be post processed to fix problems such as feet sliding on the ground or some constraints not being satisfied <CitSpan>[Gleicher 1998; Lee and Shin 1999; Popovic 1999; Rose et al. 1996]</CitSpan>.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.00">This usually involves optimization of a suitable displacement function on the motion signal.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.00">Different body sizes move according to different time scales, meaning that motion cannot simply be transferred from one body size to another; modifying motions appropriately is an interesting research problem <CitSpan>[Hodgins and Pollard 1997]</CitSpan>.</Sentence>
      1
      To appear in the ACM SIGGRAPH conference proceedings
      
        <H1>3 Synthesis as Graph Search</H1>
        <Sentence inAbstract="false" summaryRelevanceScore="2.67">We assume there is a set of N motion sequences forming our dataset, each belonging to the same skeletal configuration.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.33">Every motion is discretely represented as a sequence of frames each of which has the same M degrees of freedom.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.00">This is required to be able to compare two motions and to be able to put clips from different motion sequences together.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="1.33">We write the i’th frame of s’th motion as s i .</Sentence>
        
          <H2>3.1 Motion Graph</H2>
          <Sentence inAbstract="false" summaryRelevanceScore="3.33">The collection of motion sequences could be represented as a directed graph.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.33">Each frame would be a node.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.67">There would be an edge from every frame to every frame that could follow it in an acceptable splice.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="3.00">In this graph, there would be (at least) an edge from the k’th frame to the k + 1’th frame in each sequence.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="3.33">This graph is not a particularly helpful representation because it is extremely large — we can easily have tens of thousands of nodes and hundreds of thousands of edges — and it obscures the structure of the sequences.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="4.33">Instead, we collapse all the nodes (frames) belonging to the same motion sequence together.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="3.33">This yields a graph G where the nodes of G are individual motion sequences and there is an edge from s to t for every pair of frames where we can cut from s to t.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="3.33">Since edges connect frames, they are labelled with the frames in the incident nodes (motion sequences) that they originate from and they point to.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="3.67">We also assume that the edges in G are attached a cost value which tells us the cost of connecting the incident frames.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="3.00">If cutting from one sequence to another along an edge introduces a discontinuous motion, then the cost attached to the edge is high.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="1.67">Appendix A introduces the cost function that we used.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.00">The collapsed graph still has the same number of edges.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="1.67">For an edge e from s i to t j , let f romMotion(e) = s, toMotion(e) = t, f romFrame(e) = i, toFrame(e) = j and cost(e) be the cost associated with the edge (defined in Appendix A).</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.67">In this setting, any sequence of edges e 1 · · · e n where toMotion(e i ) = f romMotion(e i+1 ) and toFrame(e i ) &lt; f romFrame(e i+1 ), ∀i, 1≤i &lt; n is a valid path and defines a legal sequence of splices.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="1.0">(figure 1).</Sentence>
          Path Edge 1 Edge 5 Edge 2 Edge 4 Edge 3 Edge 1 Sequences Edge 2 Edge 4 Edge 3 Motion Edge 5 Corresponding Motion Time
          
            Figure 1: We wish to synthesize human motions by splicing together pieces of existing motion capture data. This can be done by representing the collection of motion sequences by a directed graph (top). Each sequence becomes a node; there is an edge between nodes for every frame in one sequence that can be spliced to a frame in another sequence or itself. A valid path in this graph represents a collection of splices between sequences, as the middle shows. We now synthesize constrained motion sequences by searching appropriate paths in this graph using a randomized search method.
          
        
        
          <H2>3.2 Constraints</H2>
          <Sentence inAbstract="false" summaryRelevanceScore="3.33">We wish to construct paths in the motion graph that satisfy constraints.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.33">Many constraints cannot be satisfied exactly.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.00">For example, given two positions, there may not be any sequence of frames in the collection that will get us from the first position to the second position exactly.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="3.67">We define hard constraints to be those that can (and must) be satisfied exactly.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.67">Typically, a hard constraint involves using a particular frame in a particular time slot.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.00">For example, instead of considering all valid paths, we can restrict ourselves to valid paths that pass through particular nodes at particular times.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="3.00">This way, we can constrain the moving figure to be at a specific pose at a specific time.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="3.33">This enables us to search for motions such as jumping, falling, or pushing a button at a particular time.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="3.33">A soft constraint cannot generally be met exactly.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="3.33">Instead we score sequences using an objective function that reflects how well the constraint has been met and attempt to find extremal sequences.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.33">One example is the squared distance between the position of the constraint and the actual position of the body at the time of the constraint.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="1.0">Example soft constraints include:
          1.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="1.33">The total number of frames should be a particular number.</Sentence>
          2
          To appear in the ACM SIGGRAPH conference proceedings
          2. <Sentence inAbstract="false" summaryRelevanceScore="2.00">The motion should not penetrate any objects in the environment.</Sentence> 3. <Sentence inAbstract="false" summaryRelevanceScore="2.00">The body should be at a particular position and orientation at a particular time.</Sentence> 4. <Sentence inAbstract="false" summaryRelevanceScore="2.00">A particular joint should be at a particular position (and maybe having a specific velocity) at a specific time.</Sentence> 5. <Sentence inAbstract="false" summaryRelevanceScore="2.00">The motion should have a specified style (such as happy or energetic) at a particular time.</Sentence>
          <Sentence inAbstract="false" summaryRelevanceScore="3.67">Finding paths in the motion graph that satisfy the hard constraints and optimize soft constraints involves a graph search.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="4.00">Unfortunately, for even a small collection of motions, the graph G has a large number of edges and straightforward search of this graph is computationally prohibitive.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="3.33">The main reason is the need to enumerate many paths.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="3.33">There are, in general, many perfectly satisfactory motions that satisfy the constraints equally well.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.33">For example, if we require only that the person be at one end of a room at frame 0 and near the other end at frame 5000, unless the room is very large, there are many motions that satisfy these constraints.</Sentence>
        
      
      
        <H1>4 Randomized Search</H1>
        <Sentence inAbstract="false" summaryRelevanceScore="3.00">The motion graph is too hard to search with dynamic programming as there are many valid paths that satisfy the constraints equally well.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.33">There may be substantial differences between equally valid paths — in the example above, whether you dawdle at one side of the room or the other is of no significance.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="3.33">This suggests summarizing the graph to a higher level and coarser presentation that is easier to search.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="3.33">Branch and bound algorithms are of no help here, because very little pruning is possible.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="4.33">In order to search the graph G in practical times, we need to do the search at a variety of levels where we do the large scale motion construction first and then “tweak” the details so that the motion is continuous and satisfies the constraints as well as possible.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="3.67">Coarser levels should have less complexity while allowing us to explore substantially different portions of the path space.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="3.67">In such a representation, every level is a summary of the one finer level.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="1.67">Let G ← G ← G ← · · · ← G n ← G be such a hierarchical representation where G is the coarsest level and G is the finest.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="3.00">We will first find a path in G and then push it down the hierarchy to a path in G for synthesis.</Sentence>
        
          <H2>4.1 Summarizing the Graph</H2>
          <Sentence inAbstract="false" summaryRelevanceScore="1.67">All the edges between two nodes s and t can be represented in a matrix P st .</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="1.67">The (i, j)’th entry of P st contains the weight of the edge connecting s i to t j and infinity if there is no such edge.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="1.67">In the appendix A, we give one natural cost function C(s i ,t j ) for edge weights.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="1.67">We now have: (P st ) i j = C(s ∞ i ,t j ) otherwise.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="1.67">if there is an edge from s i to t j The cost function explained in section A causes the P matrices to have non-infinite entries to form nearly elliptical groups ( figure 2 ).</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.33">This is due to the fact that if two frames are similar, most probably their preceding and succeeding frames also look similar.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="1.0">In order to summarize the graph, we cluster the edges of G. We now have G , whose nodes are the same as the nodes of G, and whose edges represent clusters of edges of G in terms of their f romFrame and toFrame labels.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.33">We require that, if there is a cut between two sequences represented by an edge between two nodes in G, there be at least one edge between the corresponding nodes in G .</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="3.33">If this were not the case, our summary would rule out potential paths.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="3.00">In order to insure that this condition holds and because the graph is very large, we cluster edges connecting every pair of nodes in G separately.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.33">We cluster unconnected edge groups of G from the P matrices (defined between every pair of nodes) using k-means ma joraxislength <CitSpan>[Bishop 1995]</CitSpan>.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="3.00">The number of clusters is chosen as minoraxislength for each group where the axis lengths refer to the ellipse that fits to the cluster (obtained through Principal Component Analysis).</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="1.0">The nodes of G are the same as the nodes of G. The edges connecting nodes in G are cluster centers for clusters of edges connecting corresponding nodes in G. The centers are computed by taking the average of the edges in terms of f romFrame, toFrame and cost values.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="1.0">At this point, every edge in G represents many edges in G. We would like to have a tree of graph representations whose root is G , and whose leaves are G. We use k-means clustering to split each cluster of edges in half at each intermediate level and obtain a hierarchical representation G ← G ← G ← · · · ← G n ← G for the original graph G. This is an instance of Tree-Structured Vector Quantization <CitSpan>[Gersho and Gray 1992]</CitSpan>.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="3.67">Thus, in our summarized graph G , each edge is the root of a binary tree and represents all the edges in close neighborhood in terms of the edge labels.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="3.33">Note that the leaf edges are the edges in the original graph and intermediate edges are the averages of all the leaf edges beneath them.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="4.00">A path in G represents a sequence of clips; so does a path in G , but now the positions of the clip boundaries are quantized, so there are fewer paths.</Sentence>
          Frame i Frame j Walking Running Walking , frame i
          Clustering
          j frame Running,
          
            
            
            Figure 2: Every edge between two nodes representing different motion clips can be represented as a matrix where the entries correspond to edges. Typically, if there is one edge between two nodes in our graph, there will be several, because if it is legal to cut from one frame in the first sequence to another in the second, it will usually also be legal to cut between neighbors of these frames. This means that, for each pair of nodes in the graph, there is a matrix representing the weights of edges between the nodes. The i, j’th entry in this matrix represents the weight for a cut from the i’th frame in the first sequence to the j’th frame in the second sequence. The weight matrix for the whole graph is composed as a collection of blocks of this form. Summarizing the graph involves compressing these blocks using clustering.
          
        
        
          <H2>4.2 Searching the Summaries</H2>
          <Sentence inAbstract="false" summaryRelevanceScore="3.67">While searching this graph, we would like to be able to generate different alternative motions that achieve the same set of constraints.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="3.67">During the search, we need to find paths close to optimal solutions but do not require exact extrema, because they are too hard to find.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="3.33">This motivates a random search.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="1.67">We used the following search strategy:</Sentence>
          3
          To appear in the ACM SIGGRAPH conference proceedings
          1. <Sentence inAbstract="false" summaryRelevanceScore="2.00">Start with a set of n valid random “seed” paths in the graph G 2.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.00">Score each path and score all possible mutations 3.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="1.0">Where possible mutations are: (a) Delete some portion of the path and replace it with 0 or 1 hops.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.00">(b) Delete some edges of the path and replace them with their children 4.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.00">Accept the mutations that are better than the original paths 5.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.00">Include a few new valid random “seed” paths 6.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="1.0">Repeat until no better path can be generated through mutations
          Intuitively the first mutation strategy replaces a clip with a (hopefully) better one and the second mutation strategy adjusts the detailed position of cut boundaries.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="3.33">Since we start new random “seed” paths at every iteration, the algorithm does not get stuck at a local optimum forever.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="1.33">Section 4.2.2 explains these mutations in more detail.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="3.33">Hard constraints are easily dealt with; we restrict our search to paths that meet these constraints.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.00">Typically hard constraints specify the frame (in a particular node) to be used at a particular time.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.67">We do this by ensuring that “seed” paths meet these constraints, and mutations do not violate them.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.67">This involves starting to sample the random paths from the hard constraint nodes and greedily adding sequences that get us to the next hard constraint if any.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="3.33">Since the path is sampled at the coarse level, a graph search can also be performed between the constraint nodes.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.33">At every iteration we check if the proposed mutation deletes a motion piece that has a hard constraint in it.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="3.00">Such mutations are rejected immediately.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.33">Note that here we assume the underlying motion graph is connected.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="1.33">Section 4.2.1 explains the constraints that we used in more detail.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="1.67">Notice that this algorithm is similar to MCMC search (a good broad reference to application of MCMC is <CitSpan>[Gilks et al. 1996]</CitSpan>).</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="3.00">However, it is difficult to compute proposal probabilities for the mutations we use, which are strikingly successful in practice.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="4.00">This is an online algorithm which can be stopped at anytime.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="4.00">This is due to the fact that edges in intermediate graphs G · · · G n also represent connections and are valid edges.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="4.33">Thus we do not have to reach the leaf graph G to be able to create a path (motion sequence).</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="3.67">We can stop the search iteration, take the best path found so far, and create a motion sequence.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="3.67">If the sequence is not good enough, we can resume the search from where we left off to get better paths through mutations and inclusion of random paths.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="4.33">This allows an intuitive computation cost vs. quality tradeoff.</Sentence>
          
            <H3>4.2.1 Evaluating a Path</H3>
            <Sentence inAbstract="false" summaryRelevanceScore="4.00">Since during the search all the paths live in a subspace implied by the hard constraints, these constraints are always satisfied.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="3.33">Given a sequence of edges e 1 · · · e n , we score the path using the imposed soft constraints.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.67">For each constraint, we compute a cost where the cost is indicative of the satisfaction of the constraint.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.33">Based on the scores for each of the constraints, we weight and sum them to create a final score for the path (The S function in equation 1).</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.33">We also add the sum of the costs of the edges along the path to make sure we push the search towards paths that are continuous.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.67">The weights can be manipulated to increase/decrease the influence of a particular soft constraint.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="1.67">We now have an expression of the form:</Sentence>
            n
          
          
            <H3>4.2.2 Mutating a Path S(e · · · e ) = w ∗ ∑ cost(e ) + w ∗ F + w ∗ B + w ∗ J <CitSpan>(1)</CitSpan>
</H3>
            
              1
              1 n c i f b j
            
            i=1
            
              Figure 3: The two mutations are: deleting some portion of the path (top-left, crossed out in red) and replacing that part with another set of edges (top-right), and deleting some edges in the path (bottomleft) and replacing deleted edges with their children in our hierarchy (bottom-right)
            
            <Sentence inAbstract="false" summaryRelevanceScore="1.67">Where w c ,w f ,w b and w j are weights for the quality (continuity) of the motion, how well the length of the motion is satisfied, how well the body constraints are satisfied and how well the joints constraints are defined.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="3.00">We selected these weights such that an error of 10 frames increases the total score the same amount as an error of 30 centimeters in position and 10 degrees in orientation.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="1.0">The scores F, B and J are defined as:
            1.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.33">F: For the number of frame constraints, we compute the squared difference between the actual number of frames in the path and the required number of frames.</Sentence> 2. <Sentence inAbstract="false" summaryRelevanceScore="2.00">B: For body constraints, we compute the distance between the position and orientation of the constraint versus the actual position and orientation of the torso at the time of the constraint and sum the squared distances.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.00">The position and orientation of the body at the constraint times are found by putting the motion pieces implied by the subsequent edges together ( figure 1 ).</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.33">This involves taking all the frames of motion toMotion(e i ) between frames f romFrame(e i+1 ) and toFrame(e i ) and putting the sequence of frames starting from where the last subsequence ends or from the first body constraint if there is no previous subsequence.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="3.33">Note that we require that we have at least two body constraints enforcing the position/orientation of the body at the beginning of the synthesized motion (so that we know where to start putting the frames down) and at the end of the synthesized motion.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.33">The first body constraint is always satisfied, because we always start putting the motions together from the first body constraint.</Sentence> 3. <Sentence inAbstract="false" summaryRelevanceScore="2.00">J: For joint constraints, we compute the squared distance between the position of the constraint and the position of the constrained joint at the time of the constraint and sum the squared distance between the two.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.33">To determine the configuration of the body at the time at which the constraint applies, we must assemble the motion sequence up to the time of the constraint; in fact, most of the required information such as the required transformation between start and end of each cut is already available in the dataset.</Sentence>
            <Sentence inAbstract="false" summaryRelevanceScore="3.00">We implemented two types of mutations which can be performed quickly on an active path.</Sentence>
            4
            To appear in the ACM SIGGRAPH conference proceedings
            Domain of smoothing Discontinuity Magnitude
            Smoothed Signal
            
              
              Figure 4: In the synthesized motion, discontinuities in orientation are inevitable. We deal with these discontinuities using a form of localized smoothing. At the top left, a discontinuous orientation signal, with its discontinuity shown at the top right. We now construct an interpolant to this discontinuity, shown on the bottom right and add it back to the original signal to get the continuous version shown on the bottom left. Typically, discontinuities in orientation are sufficiently small that no more complex strategy is necessary.
            
            1. <Sentence inAbstract="false" summaryRelevanceScore="3.67">Replace a sequence by selecting two edges e i and e i+ j where 0 ≤ j ≤ n − i, deleting all the edges between them in the path and connecting the unconnected pieces of the path using one or two edges in the top level graph G (if possible).</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="4.00">Since in the summarized graph, there are relatively fewer edges, we can quickly find edges that connect the two unconnected nodes by checking all the edges that go out from toMotion(e i ), and enumerating all the edges that reach to f romMotion(e i+ j ) and generate a valid path.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.00">Note that we enumerate only 0 or 1 hop edges (1 edge or 2 edge connections respectively).</Sentence> 2. <Sentence inAbstract="false" summaryRelevanceScore="3.67">Demoting two edges to their children and replacing them with one of their children if they can generate a valid path.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="3.33">Doing this mutation on two edges simultaneously allows us to compensate for the errors that would happen if only one of them was demoted.</Sentence>
            <Sentence inAbstract="false" summaryRelevanceScore="2.00">We check every possible mutation, evaluate them and take the best few.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="3.00">Since the summary has significantly fewer edges than the original graph, this step is not very expensive.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="3.33">If a motion sequence cannot generate a mutation whose score is lower that itself, we decide that the current path is a local minimum in the valid path space and record it as a potential motion.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="3.67">This way, we can obtain multiple motions that satisfy the same set of constraints.</Sentence>
          
          
            <H3>4.2.3 Creating and Smoothing the Final Path</H3>
            <Sentence inAbstract="false" summaryRelevanceScore="2.33">We create the final motion by taking the frames between toFrame(e i ) and f romFrame(e i+1 ) from each motion toMotion(e i ) where 1 ≤ i &lt; n ( figure 1 ).</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.67">This is done by rotating and translating every motion sequence so that each piece starts from where the previous one ended.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="3.00">In general, at the frames corresponding to the edges in the path, we will have C 0 discontinuities, because of the finite number of motions sampling an infinite space.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="3.00">In practice these discontinuities are small and we can distribute them within a smoothing window around the discontinuity.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.00">We do this by multiplying the magnitude of the discontinuity by a smoothing function and adding the result back to the signal ( figure 4 ).</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="1.67">We choose the smoothing domain to be ±30 frames (or one second of animation) around the discontinuity and</Sentence>
            
              Figure 5: Body constraints allow us to put “checkpoints” on the motion: in the figure, the arrow on the right denotes the required starting position and orientation and the arrow on the left is the required ending position and orientation. All constraints are also time stamped forcing the body to be at the constraint at the time stamp. For these two body constraints, we can generate many motions that satisfy the constraints in real-time.
            
            
              Figure 6: We can use multiple “checkpoints” in a motion. In this figure, the motion is required to pass through the arrow (body constraint) in the middle on the way from the right arrow to the left.
            
            <Sentence inAbstract="false" summaryRelevanceScore="1.0"> y( f ) =       0 − 0 2 1 ∗ 2 1 ( ∗ f ( −d+s f s −d+s s ) 2 ) 2 + 2 ∗ ( f −d+s s ) − 2 d d f f − ≤ &gt; &lt; s d d f ≤ + − ≤ f s s d &lt; + d s
            as the smoothing function that gives the amount of displacement for every frame f , where d is the frame of the discontinuity and s if the smoothing window size (in our case 30).</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.00">To make sure that we interpolate the body constraints (i.e. having a particular position/orientation at a particular frame), we take the difference between the desired constraint state, subtract the state at the time of the constraint and distribute this difference uniformly over the portion of the motion before the time of the constraint.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="3.67">Note that these “smoothing” steps can cause artifacts like feet penetrating or sliding on the ground.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="3.33">However, usually the errors made in terms of constraints and the discontinuities are so small that they are unnoticeable.</Sentence>
          
        
        
          <H2>4.3 Authoring Human Motions</H2>
          <Sentence inAbstract="false" summaryRelevanceScore="4.33">Using iterative improvements of random paths, we are able to synthesize human looking motions interactively.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="4.00">This allows interactive manipulation of the constraints.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="3.33">This is important, because motion synthesis is inherently ambiguous as there may be multiple motions that satisfy the same set of constraints.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="3.33">The algorithm can find these “local minimum” motions that adhere to the same constraints.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="3.00">The animator can choose between them or all the different motions can be used to create a variety in the environment.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="3.67">Since the algorithm is interactive, the animator can also see the ambiguity and guide the search by putting extra constraints ( figure 6 ).</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="3.00">Currently, we can constrain the length of the motion, the body’s position and orientation at a particular frame ( figure 5 ,6), a joint (e.g. head, hand) to a particular state at a particular frame ( figure 7 ), or constrain the entire body’s pose at a particular frame (figure 8).</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.67">Notice that we can synthesize multiple interacting motions independently using hard constraints ( figure 9 ); we simply select the poses, position and orientation at which the figures interact and this framework fills in the missing motion, in a sense, interpolating the constraints.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.67">These are only a few of the constraints that can be implemented.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="3.67">As long as the user specifies a cost function that evaluates a motion and attaches a score that is indicative of the animator’s satisfaction with the path, many more constraints can be implemented.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.33">For example, if the motions in our database are marked with their individual stylistic attributes, we can also constrain the style of the desired motion by penalizing motions that do not have the particular style.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="3.33">In a computer game environment, we can constrain the synthesized motion to avoid obstacles in the environment.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.00">In such a case, body position/orientation constraints can also come from an underlying path planner.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="3.33">Thus, given high level goals (such as going from point A to point B, say) human looking motions can be generated automatically.</Sentence>
          5
          To appear in the ACM SIGGRAPH conference proceedings
          
            Figure 7: In addition to body constraints, joint constraints can be used to further assign “checkpoints” to individual joints. In this figure, the head of the figure is also constrained to be high (indicated by the blue line), leading to a jumping motion.
          
        
      
      
        <H1>5 Results</H1>
        <Sentence inAbstract="false" summaryRelevanceScore="5.00">We have presented a framework that allows interactive synthesis of natural looking motions that adhere to user specified constraints.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="3.33">We assess our results using four criteria.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="3.67">Firstly, the motion looks human.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="3.67">Secondly, the motions generated by the method do not have unnatural artifacts such as slipping feet on the ground or jerky movement.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="3.67">Third, the user specified constraints are satisfied, i.e. the motion passes through the required spot at the required time, or the character falls to a particular position ( figure 8 ).</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="3.67">Finally, motions are generated interactively — typically depending on the quality of the path desired, an acceptable 300 frame motion is found in between 3 and 10 seconds on an average PC (Pentium III at 800 Mhz).</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="3.00">This speed allows interactive motion authoring.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.00">For example, we generated the real-time screen captures in the attached video using a dataset of 60-80 unorganized, short (below 300 frames each) motion capture fragments.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.33">The average precomputation time required for this many motions (computing the motion graph) is 5 hours on the same computer.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.33">On average, the results shown in the video contain 3-30 motion pieces cut from the original motions.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="3.67">This framework is completely automatic.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="4.00">Once the input motions are selected, the computation of the hierarchic motion graph does not require any user intervention and the resulting representation is searched in real-time.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="4.33">For many kinds of constraints the motion synthesis problem is underconstrained; there are many possible combinations of motion pieces that achieve the same set of constraints.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="4.00">Randomized search is well suited to find many different motions that satisfy the constraints.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="3.00">On the other hand, some constraints, may not be met by any motion.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="3.67">In this case, randomized search will try to minimize our objective motion and find the “closest” motion.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.00">For example, if the user asks for 100 meters in 5 seconds, the algorithm will tend to put fast running motions together but not necessarily satisfying the constraints.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.00">Similarly, if the set of motions to begin with do not form a connected graph, the algorithm will perform searches confined to the unconnected graphs.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="4.33">If there are hard constraints in different unconnected components, we will not even be able to find starting seed paths.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="4.00">From this perspective, the selection of the database to work with is important.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.00">In our system, we used 60-100 football motions that have a strong bias towards motions that run forward.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="3.67">However, as the attached video suggest, the randomized search has no problem finding rare motions that turn back to satisfy the constraints.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.00">The motion databases that we used were unorganized except that we excluded football warming up and tackling motions unless they were desired ( figure 9 ).</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="3.67">The randomized search scales linearly as a function of the database size with a very small constant.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.33">We have tried datasets of 50-100 motions without a noticeable change in the running time of the algorithm.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="3.00">The linearity in the running time comes from the linear increase in the number of alternative mutations at every step.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="3.67">Note that as the database size gets larger, the constant τ (Appendix A) that is used to create the edges can get lower since more motions mean that we expect to find better connections between motions, decreasing the number of edges.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="4.33">This will lead to a sublinear increase in the running time.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="4.33">The framework can work on any motion dataset: it can be created by traditional key framing, physically based modelling or motion capture.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.33">For example, we can take the motion data for “Woody” – who may well have been key-framed, from “Toy Story” and create new “Woody” motions automatically.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="4.00">The framework is also appli- cable to non-human motion synthesis.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.00">For example, this framework can be used to generate control signals for robots to achieve a particular task by generating the motion graph for previously known motion-control signal pairs.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="4.33">During the synthesis we can not only synthesize the final robot motion but also the associated control signals that achieve specific goals.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="4.33">Since the generated motions are obtained by putting pieces of motions in the dataset, the resulting motions will also carry the underlying style of the data.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="4.33">This way, we can take the motion data for one character, and produce more motions with the intrinsic style of the character.</Sentence>
        
          Figure 8: Using hard constraints, we can force the figure to perform specific activities. Here, we constrain the end of the motion to be lying flat on the ground at a particular position/orientation and time. Our framework generates the required tipping and tumbling motion in real-time.
        
        6
        To appear in the ACM SIGGRAPH conference proceedings
      
      
        <H1>6 Future Work</H1>
        <Sentence inAbstract="false" summaryRelevanceScore="3.00">During the construction of the final motion, better ways of smoothing between adjacent motions could be used to improve realism <CitSpan>[Popovic 1999]</CitSpan>.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="3.67">Using better post processing, motions could also be synthesized on non-uniform surfaces which the current framework cannot handle.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.33">Additional post processing may involve physically based modelling to make sure the synthesized motions are also physically correct.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="4.00">Automatic integration of higher level stylistic constraints could be incorporated into the framework, avoiding the arduous job of labelling every motion with the intrinsic style by hand.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.67">By analyzing patterns in the motion dataset, we might also infer these styles or obtain higher level descriptions <CitSpan>[Brand and Hertzmann 2001]</CitSpan>.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="3.00">The synthesized motions are strictly bound to the motions that were available in the original dataset.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.33">However, it is conceivable that the motions that are very close to the dataset could also be incorporated in the synthesizable motions using learned stylistic variations.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.33">The integrity of the original dataset directly effects the quality of the synthesized motion.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.00">For example, if the incoming motion dataset does not contain any “turning left” motions, we will not be able to synthesize motions that involve “turning left”.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="3.00">An automatic way of summarizing the portions of the “possible human motions” space that have not been explored well enough by the dataset could improve the data gathering and eventually the synthesized motions.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.33">This could also serve as a palette for artists: some portions of the precomputed motion graph can be paged in and out of memory depending on the required motion.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="1.67">For example, the animator could interactively select the motions that need to be used during the synthesis, and only the portion of the motion graph involving the desired motions could be loaded.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.00">This would give animators a tool whereby they can select the set of motions to work with in advance and the new motions will be created only from the artist selected set.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.00">Furthermore this encourages comprehensive re-use of motion data.</Sentence>
      
      
        <H1>7 Acknowledgements</H1>
        <Sentence inAbstract="false" summaryRelevanceScore="1.0">This research was supported by Office of Naval Research grant no.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="1.0">N00014-01-1-0890, as part of the MURI program.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="1.33">We would like to thank Electronic Arts for supplying us with the motion data.</Sentence>
      
      
        <H1>A Appendix: Similarity Metric</H1>
        <Sentence inAbstract="false" summaryRelevanceScore="1.67">We define the torso coordinate frame to be the one where the body stands centered at origin on the xz plane and looks towards the positive z axis.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="1.67">Any point p in the torso coordinate frame can be transformed to the global coordinate frame by T (s i ) + R(s i ) · p , where T (s i ) is the 3 × 1 translation of the torso and R(s i ) is the 3 × 1 rotation of the torso and R(s i ) represents the rotation matrix associated with the rotation.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="1.67">We wish to have a weight on edges of the motion graph (section 3.1) that encodes the extent to which two frames can follow each other.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="1.67">If the weight of an edge is too high, it is dropped from the graph.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="1.67">To compute the weight of an edge, we use the difference between joint positions and velocities and the difference between the torso velocities and accelerations in the torso coordinate frame.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="1.33">Let P(s i ) be a 3 × n matrix of positions of n joints for s i in torso coordinate frame.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="1.33">Equation 2 gives us the difference in joint position and body velocity.</Sentence>
        
          2
          D s i ,t j = [(P(s i ) − P(t j )) (|T (s i )| − |T (t j )|) (|R(s i )| − |R(t j )|) ]
        
        <Sentence inAbstract="false" summaryRelevanceScore="1.33">We then define the normalizing matrices O and L in equation 3 and 4.</Sentence>
        
          3
          O = max s,i (|D s T i ,s i D s i ,s i+1 |)
        
        
          4
          L = max s,i (|D s T i ,s i D s i ,s i+1 |)
        
        <Sentence inAbstract="false" summaryRelevanceScore="1.67">Then the cost function function in equation 5 is used to relate s i to t j .</Sentence>
        
          5
          C(s i ,t j ) = trace(D s i ,t j MO −1 D s T i ,t j + D s i ,t j T L −1 D s T i ,t j )
        
        <Sentence inAbstract="false" summaryRelevanceScore="1.67">Where diagonal (n + 2) × (n + 2) matrices M and T are used to weight different joints differently.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="1.67">For example, position differences in feet are much more noticeable than position differences of hands because the ground provides a comparison frame.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="1.67">We have found M and T matrices empirically by trying different choices.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.67">Unfortunately, defining a universal cost metric is a hard problem.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.67">The metric defined above produces visually acceptable results.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.00">Using this cost metric, we create edges from s i to t j where C(s i ,t j ) &lt; τ .</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="1.33">For an edge e from s i to t j , we set cost(e) = C(s i ,t j ).</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="1.0">τ is a user specified quality parameter that influences the number of edges in G. We have fixed this value so that cuts created between motions along the edges do not have visible artifacts.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.00">Note that an error that is visible on a short person may not be visible on an extremely large person.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.67">Thus, in theory, the weights must be adjusted from person to person.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.67">However, in practice, possible size variation of adult people is small enough that we used the same weights for different people without creating a visible effect.</Sentence>
      
      
        <H1>References</H1>
                
          BISHOP, C. M. 1995. Neural Networks for Pattern Recognition. Clarendon Press, Oxford. BOWDEN, R., 2000. Learning statistical models of human motion.
          BRAND, M., AND HERTZMANN, A. 2001. Style machines. In Proceedings of SIGGRAPH 2000, 15–22.
          BROGAN, D. C., METOYER, R. A., AND HODGINS, J. K. 1998. Dynamically simulated characters in virtual environments. IEEE Computer Graphics &amp; Applications 18, 5, 58–69.
          CHENNEY, S., AND FORSYTH, D. A. 2000. Sampling plausible solutions to multibody constraint problems. In Proceedings of SIGGRAPH 2000, 219–228.
          CHOI, M. G., LEE, J., AND SHIN, S. Y. 2000. A probabilistic approach to planning biped locomotion with prescribed motions. Tech. rep., Computer Science Department, KAIST.
          DEMPSTER, W., AND GAUGHRAN, G. 1965. Properties of body segments based on size and weight. In American Journal of Anatomy, vol. 120, 33–54.
          EFROS, A. A., AND LEUNG, T. K. 1999. Texture synthesis by non-parametric sampling. In ICCV (2), 1033–1038.
          six-year-old children. In Research Quarterly for Exercise and Sport, vol. 54(2),126–135.
          FORTNEY, V. 1983. The kinematics and kinetics of the running pattern of two-, four and
          FUNGE, J., TU, X., AND TERZOPOULOS, D. 1999. Cognitive modeling: Knowledge, reasoning and planning for intelligent characters. In Proceedings of SIGGRAPH1999, 29– 38.
          GALATA, A., JOHNSON, N., AND HOGG, D. 2001. Learning variable length markov
          models of behaviour. In Computer Vision and Image Understanding (CVIU) Journal, vol. 81, 398–413.
          GERSHO, A., AND GRAY, R. 1992. Vector Quantization and signal compression. Kluwer Academic Publishers. GILKS, W., RICHARDSON, S., AND SPIEGELHALTER, D. 1996. Markov Chain Monte Carlo in Practice. Chapman and Hall.
          GLEICHER, M. 1998. Retargetting motion to new characters. In Proceedings of
          SIGGRAPH 1998, vol. 32, 33–42. GRZESZCZUK, R., AND TERZOPOULOS, D. 1995.
          Automated learning of muscleactuated locomotion through control abstraction. In Proceedings of SIGGRAPH 1995, 63–70.
          GRZESZCZUK, R., TERZOPOULOS, D., AND HINTON, G. 1998. Neuroanimator: Fast neural network emulation and control of physics based models. In Proceedings of SIGGRAPH 1998, 9–20.
          HEEGER, D. J., AND BERGEN, J. R. 1995. Pyramid-Based texture analysis/synthesis. In Proceedings of SIGGRAPH 1995, 229–238.
          HODGINS, J. K., AND POLLARD, N. S. 1997. Adapting simulated behaviors for new characters. In Proceedings of SIGGRAPH 1997, vol. 31, 153–162. HODGINS, J., WOOTEN, W., BROGAN, D., AND O’BRIEN, J., 1995. Animated human athletics.
          KOVAR, L., GLEICHER, M., AND PIGHIN, F. 2002. Motion graphs. In Proceedings of SIGGRAPH 2002.
          LAMOURET, A., AND VAN DE PANNE, M. 1996. Motion synthesis by example. In Eurographics Computer Animation and Simulation ’96, 199–212.
          LATOMBE, J. P. 1999. Motion planning: A journey of robots, molecules, digital actors, and other artifacts. In International Journal of Robotics Research, vol. 18, 1119–1128.
          LEE, J., AND SHIN, S. Y. 1999. A hierarchical approach to interactive motion editing for human-likefigures. In Proceedings of SIGGRAPH 1999, 39–48.
          LEE, J., CHAI, J., REITSMA, P., HODGINS, J., AND POLLARD, N. 2002. Interactive control of avatars animated with human motion data. In Proceedings of SIGGRAPH 2002.
          LI, Y., WANG, T., AND SHUM, H. Y. 2002. Motion texture: A two-level statistical model for character motion synthesis. In Proceedings of SIGGRAPH 2002.
          MATARIC, M. J. 2000. Getting humanoids to move and imitate. In IEEE Intelligent Systems, IEEE, 18–24.
          MCMAHON, T. 1984. Muscles, Reflexes and Locomotion. PhD thesis, Princeton University Press.
          MOLINA-TANCO, L., AND HILTON, A. 2000. Realistic synthesis of novel human movements from a database of motion capture examples. In Workshop on Human Motion (HUMO’00), 137–142.
          NELSON, R., BROOKS, C., AND N.PIKE. 1977. Biomechanical comparison of male and female distance runners. In Annals of the NY Academy of Sciences, vol. 301, 793–807. O’ROURKE, J. 1998. Computational Geometry in C. Cambridge University Press.
          POPOVIC, Z. 1999. Motion Transformation by Physically Based Spacetime Optimization. PhD thesis, Carnegie Mellon University Department of Computer Science.
          PULLEN, K., AND BREGLER, C. 2000. Animating by multi-level sampling. In Computer Animation 2000, 36–42. ISBN 0-7695-0683-6.
          PULLEN, K., AND BREGLER, C. 2002. Motion capture assisted animation: Texturing and synthesis. In Proceedings of SIGGRAPH 2002.
          ROSE, C., GUENTER, B., BODENHEIMER, B., AND COHEN, M. F. 1996. Efficient generation of motion transitions using spacetime constraints. In Proceedings of
          SIGGRAPH 1996, vol. 30, 147–154.
          SCHODL, A., SZELISKI, R., SALESIN, D., AND ESSA, I. 2000. Video textures. In Proceedings of SIGGRAPH 2000, 489–498.
          VEACH, E., AND GUIBAS, L. J. 1997. Metropolis light transport. In Proceedings of SIGGRAPH 1997, vol. 31, 65–76.
          WITKIN, A., AND POPOVIC, Z. 1995. Motion warping. In Proceedings of SIGGRAPH 1995, 105–108.

        
        7
        To appear in the ACM SIGGRAPH conference proceedings
        
          Figure 9: Using combinations of constraints, we can generate multiple motions interacting with each other. Here, the skeletons are constrained to be tackling each other (using hard constraints) at specified times and specified positions/orientations. We can then generate the motion that connects the sequence of tackles.
        
        8
      
    
  

</Document>
