Approach	Then BFECC is implemented as:        SingleStep(u, v, φ n , φ  ̃ ) SingleStep(−u, −v, φ  ̃ , φ  ̄ ) φ  ̃ := φ n + ( φ n − φ  ̄ )/2 SingleStep(u, v, φ  ̃ , φ n+1 )
Approach	However, density values a i j can become negative or greater than 1.0 for some grid points.
Approach	Therefore, the error can be computed as e = − 1 2 ( φ n − φ  ̄ ).
Challenge	We show that it can be applied to reduce dissipation and diffusion encountered in various advection steps in fluid simulation such as velocity, smoke density and image advections.
Approach	The cup is released upside down near the water surface.
Challenge	Smoke density advection transports smoke along the velocity field.
Background	The problem left here was the volume loss in the level set method and the solution, known as the particle level set method, proposed subsequently in [ EMF02 ], turned out to be very successful in volume preservation.
Approach	An alternative is the semi-Lagrangian style integration, i.e., φ n+1 = φ n (x − w∆ τ ) + sgn( φ n )∆ τ , where x is the location of each grid point.
Approach	Then the equation (5) becomes φ n+1 = L(u, φ n − e).
Approach	We call this process image advection.
Challenge	Sometimes, we may want to advect a colored image, which may be considered as colored smoke.
Background	In contrast, BFECC is easier to implement and exhibits second order accuracy both in space and time and is local during each of its operational steps.
Approach	If the advection step L(·, ·) is exact, the first two forward and backward steps should return the value exactly the same as the original one, i.e., φ n = φ  ̄ .
Outcome	We conclude that BFECC creates a physically correct fluctuations in a coarser grid.
Outcome	We have shown that the BFECC scheme can be used to improve the simulation of fluids.
Background	The latter is often preferred due to its stability for large time step.
Approach	We use PovRay ( http://povray.org ) to render images.
Background	The first order semi-Lagrangian method is popular in computer animation because of its simplicity.
Outcome	As is shown in (d), the dissipation of the color is significantly reduced with BFECC.
Approach	We combine these techniques with variable density projection and show that they yield a realistic animations of two-phase flows.
Outcome	BFECC can be implemented easily on top of the first order upwinding or semi-Lagrangian integration of advection equations, while providing second order accuracy both in space and time.
Outcome	Velocity advection can also be important when rigid bodies are involved.
Outcome	Once the simple first order upwinding or semi-Lagrangian steps for velocity, smoke density, image or level set advections are implemented, BFECC can be added with a trivial amount of code.
Approach	When these integration formulae for (6) are combined with BFECC, the redistancing tends to spoil good φ values computed from the second order accurate BFECC.
Approach	To measure the diffusion/dissipation amount, we design a test problem similar to Zalesak’s problem.
Approach	In our simulation, this problem was not significant and we simply clamped those values to stay in [0, 1].
Outcome	In simple bubble rising situation without rigid body, it took a few seconds per time step using a 50 3 mesh.
Approach	This step will add an additional e, which will be cancelled by the subtracted amount −e.
Approach	We use multiple pressure projections to address the seeping problem mentioned in [CMT04].
Background	In [FSJ01], vorticity is added to generate small scale fluid rolling motion.
Outcome	The computation time was 0.156 sec (without BFECC) and 0.36 sec (with BFECC) per frame on a 3GHz Pentuim4.
Challenge	In this paper, we explore four forms of advection encountered in fluid simulation: velocity, smoke density, image and level set advections.
Background	In contrast, when BFECC is used, the smoke keeps full brightness throughout the simulation as is shown in the last five images.
Background	However, the authors of [DL03] combined BFECC with their simple redistancing technique and applied it to the Zalesak’s problem, showing significantly reduced the volume loss.
Challenge	Velocity advection transports the velocity field along the velocity itself.
Approach	For multiphase flow, this BFECC needs to be turned off near the interface to prevent velocities of different fluids with different densities from being mixed, which creates momentum changes.
Background	This solution is popular for the simulation of incompressible Fluids, such as smoke [ FSJ01 ] and also for more challenging free surface flows [ FF01 , EMF02 ].
Approach	First let the function SingleStep(u, v, φ n , φ n+1 ) implement upwind or semiLagrangian integration of the scalar field φ , which can be the velocity components u,v,w, the smoke density, RGB colors of an image or the level set function φ .
Background	The introduction of the level set method to fluid animation in [ FF01 ] allowed realistic simulation of fluids with complex free surfaces.
FutureWork	Thus, we believe that it can be used in flow visualization as well.
Approach	(2) We assume ∆x = ∆y here and through the rest of the presentation.
Outcome	Also notice that the size of the image looks smaller and its position is noticeably different from the original location in (c), which is again fixed in (d) where BFECC is used.
Approach	• When the grid point is not close to the interface, i.e., when φ i, j has the same sign with its eight neighbors.
Background	However, the first order semiLagrangian contains a significant amount of numerical diffusion and dissipation.
Approach	Hence, φ n (x − w∆ τ ) is the φ value of previous location.
Outcome	We show that the implementation complexity of these schemes may be easily avoided by adding a very simple Back and Forth Error Compensation and Correction (BFECC) to an existing first order semiLagrangian schemes, thus improving its space and time accuracy to second order.
Approach	In this case, φ becomes u, v and w.
Approach	̃ Its first order discretization is ∆x ∆t 2 P i, ρ j − i− P 2 1 i−1, , j j + P i, ρ j − i+ P 1 2 i+1, , j j + P i, ρ j − i, j− P i, 2 1 j−1 + P i, ρ j − i, j+ P i, 2 1 j+1 1 = ∆x u  ̃ i+ 2 1 , j − u  ̃ i− 2 1 , j + v  ̃ i, j+ 1 2 − v  ̃ i, j− 1 2 .
Background	Also level set implementation is needed.
Outcome	However, when BFECC was added, the flow fluctuated as in the refined grid.
Approach	Water is rendered as bluish surface and olive oil is rendered in yellowish color.
FutureWork	This remains as a future work.
Approach	We call it level set advection.
Background	Advection is often used for scientific visualization, especially for various forms of flow visualization.
Background	They adopted the CIP [ TFK ∗ 03 ] method that increases the order of accuracy in space by introducing the derivatives of velocity to build a sub-cell velocity profile.
Background	While higher order interpolation can solve the problem, it involves more neighboring grid point values and increases the complexity, particularly when non-uniform mesh structures are used.
Approach	This equation can be solved by applying first order upwinding in discretizing the term w · ∇φ .
Approach	Instead of the notched disk, we place a color image and rotate it 360 degree and then compare it with the original image as is shown in Fig. 5 .
Approach	We can use (5) to implement the velocity advection step in solving the Navier-Stokes Equation.
Outcome	In this case, the flow did not fluctuate at all around the obstacles with the first order semi-Lagrangian advection.
Approach	As is shown in [DL03], BFECC is linearly stable in l 2 sense, i.e., ||a|| l 2 = ∑ |a i j | 2 is bounded, when the velocity field is constant, where a is the smoke density.
Outcome	During the advection, the image is also diffused to neighboring region, even though it is not visible.
Outcome	This example indicates that reducing velocity dissipation could be important in simulating fluid and rigid body interaction.
Approach	This first order approximation is identical to [ SSK05 ] and higher order formulations can be found in [ ABS96 , SAB ∗ 99 ].
Approach	We also apply BFECC to the advection of smoke density for the smoke simulation.
Challenge	When one uses a level set method [OS88] to simulate a free surface or a two-phase flow, for example a water surface simulation, the level set must be transported as well.
Background	Therefore high order integration of characteristics is also necessary.
Approach	The conditions to turn off redistancing is provided in [DL03], where the significant enhancement were shown for the Zalesak’s problem.
Background	However, in this CIP method, all components of velocity and their partial derivatives should be advected, increasing the implementation complexity and computation time, especially in 3D.
Approach	Obviously, if ρ is constant, we have the pressure projection ∆t ρ ∇ 2 P = ∇ · u introduced in [ Sta99 ].
Background	The semi-Lagrangian velocity advection [Sta99] comes with built-in dissipation, i.e., the velocity is dissipated quickly since the linear interpolation in the first order semiLagrangian produces large error.
Approach	This method is proven to be second order accurate both in space and time [DL03, DL04].
Approach	Since we want to apply it to various advections, we use φ to denote a quantity that is advected and reserve the symbol φ for the level set function through the presentation of this paper.
Background	BFECC was recently proposed in [DL03, DL04] as a level set interface computation method.
Approach	We also include a simple implementation of surface tension similar to [ SAB ∗ 99 ].
Approach	Even though, BFECC still has some volume loss in fluid simulation, especially for small droplets or thin filaments, it is still interesting to show how BFECC performs in the fluid simulation since it is trivial to implement and fast.
Outcome	However, in the top, we turned BFECC off for velocity advection and hence the water became dissipative, preventing the cup from tumbling.
Outcome	We show that this approach reduces velocity damping and smoke density dilution and demonstrate its benefits on the four forms of advections discussed previously.
Outcome	The cup example in Fig. 7 has multiple pressure projections and it took about 30 to 130 seconds per time step on a 70 3 grid.
Background	The stability problems in the earlier works such as [ FM96 ] were successfully remedied in [ Sta99 ] by introducing the pressure projection scheme to enforce incompressibility of the fluid and the semi-Lagrangian treatment of the advection term in the Navier-Stoke equation.
Outcome	We show that BFECC can improve the damping in the first order semi-Lagrangian implementation of velocity advection, which is a well known drawback of [Sta99].
Background	For example, [JEH02] uses semi-Lagrangian advection of dye to visualize the vector field. 
Approach	We implement the rigid fluid method [CMT04] to simulate rigid body and fluid interaction in Fig. 1 and 7.
Approach	̃ The final step is applying the variable density pressure projection step to enforce the continuity equation ∇ · u = 0, i.e, solving the equation ∇ · ∆t ρ ∇P = ∇ · u.
Approach	We, however, use BFECC and the simple redistancing for level set advection of various fluid simulations and show that sufficiently realistic fluid animation can be obtained.
Approach	We subtract this error e before the final forward advection step.
Approach	We simulate air-water and olive oil-air interactions.
Outcome	As is shown in Fig. 2 , applying BFECC adds details in smoke motion.
Outcome	Due to its weight, the cup sinks deep into water but it soon rise again because of the air in it.
Approach	In other words, turning BFECC off near the interface has little effect since it is still turned on in most of the fluid domain.
Approach	Then the first two forward and backward steps will produce error 2e, i.e., φ  ̄ = φ n + 2e.
Challenge	Those advection steps can be computed by an upwind or a semi-Lagrangian method.
Approach	We use the standard staggered grid [FSJ01].
Background	As is mentioned in [ELF05], high order methods may not prevent volume loss much.
Outcome	When applied to level set evolution, BFECC reduces volume loss significantly.
Approach	It is also easy to implement since it simply requires to perform redistancing at the points where at least one of the following two conditions are met.
Background	However, we believe that having less dissipative and diffusive advection provides significant benefits in smoke simulations as well.
Approach	We also performed the same test in a coarser grid of 100×40.
Approach	It would be interesting to apply this to the level set advection part of the particle level set method [ELF05] for more demanding simulation.
Background	Song et al [ SSK05 ] focused on applying CIP to generate more dynamic water surface behavior.
Outcome	As is shown in (d), the color of the object is little diffused into neighboring region when BFECC is used.
Approach	In contrast, BFECC is trivial to implement and provides advection of fully colored pattern of dye, if necessary.
Approach	The extension to 3D is straightforward and hence omitted.
Approach	This leads to the idea of turning redistancing off near the interface to keep good φ values there.
Outcome	As is shown in Fig. 3 , the dissipation/diffusion is very small.
Approach	We also turn it off near the boundary.
Outcome	In the bottom, we use BFECC for velocity advection, where the velocity dissipation is small and hence the cup can tumble 180 degree.
Outcome	The computation time varies in situations such as the complexity of fluid motions.
Approach	We simply turn BFECC off, i.e., use the first order semi-Lagrangian, for the grid points where | φ | < 5∆x.
Background	[Wei04] applied level set method to advect dye without diffusion.
Outcome	We demonstrate the benefits of this approach on the image advection and on the simulation of smoke, of bubbles in water, and of a highly dynamic interaction between water, a solid, and air.
Approach	We follow the operator splitting steps proposed in [Sta99] except for the advection step, where we use BFECC and for the projection step for which we use the variable density pressure projection.
Background	A nice feature of this CIP method is that it is local in the sense that only the grid point values of one cell are used in order to update a point value.
Outcome	We show that this simple extension yields significant enhancements in reducing diffusion and dissipation in velocity, smoke, image advection and in preserving volume under various situations including two-phase flows and rigid bodies.
Background	Advection steps transport some quantities from one region to another along the fluid’s velocity field.
Background	It has been used in graphics applications by [ HK03 ], where the authors simulated air bubbles rising and merging and by [TFK ∗ 03, SSK05], where splash style interactions between water surface and air are studied.
Approach	Notice that reducing velocity dissipation is equally important in the entire fluid domain, not only near the interface.
Approach	When we use the BFECC for level set advection, i.e., φ = φ , redistancing is needed to keep the level set function as a signed distance function.
Approach	Notice that these details cannot be obtained from the vorticity confinement method [FSJ01], which only adds small scale rolling motions.
Background	Therefore, higher order schemes, such as WENO or CIP [ TFK ∗ 03 ], are desired.
Background	In smoke density advection, it leads to a premature dilution of smoke, and is not able to simulate pure advec- tion.
Approach	This step is always needed in nonsteady flow simulation based on Navier-Stokes equation.
Approach	Suppose all terms in (1) except for − ρ 1 ∇P are treated and let the velocity obtained so far be u.
Approach	This simple redistancing is crucial in preserving volume [DL03].
Background	Back and Forth Error Compensation and Correction (BFECC) was recently developed for interface computation by using the level set method.
Background	In velocity advection, it yields damped fluid motion.
Approach	To visualize the diffusion amount, we plot background pixels as blue to show the region where the image has been diffused into.
Background	Only one dye color is allowed and the dye cannot be diffused at all.
Challenge	Simulation of incompressible fluid involves several computation steps including diffusion, advection and pressure projection.
Background	The two phase fluid solver using variable density projection has been broadly studied in mathematics and fluid mechanics [ SSO94 , OKBG00 , HKLS04 ].
Background	Recently, [ SSK05 ] addressed this built-in dissipation by enhancing advection itself.
Background	It is also worth noting that CIP has higher order accuracy in space only.
Approach	• When the slope is sufficiently high, i.e., when | φ i, j − φ i±1, j | or | φ i, j − φ i, j±1 | ≥ 1.1∆x.
Approach	We test BFECC in different fluid simulations.

Approach	If the constraint is in two or one dimensions, we are constraining the particle’s velocity along either two or one mutually orthogonal axes.
Approach	Given the transient nature of contact constraints between cloth and solids, this is most unappealing.
Outcome	” Proofs about CG methods are difficult in general; in practice, our method always converges, which answers the first question.
Approach	Expressing the energy E as a single monolithic function—encompassing all aspects of the cloth’s internal behavior—and then taking derivatives is impractical, from a bookkeeping point of view.
Approach	Thus in the case when no particles are constrained, our modified CG method should produce the same result as the regular CG method.
Approach	The (dense) vectors that are multiplied against this matrix are stored simply as n element arrays of threecomponent vectors.
Background	Provot [ 13 ] focuses on improving the performance of explicit methods by a post-step modification of nodal positions.
Outcome	In this paper, we demonstrate that implicit methods for cloth overcome the performance limits inherent in explicit simulation methods.
Approach	Note that x 1 and x 2 vary during the simulation but the matrix in the above equation does not.
Approach	We also ran the simulation in figure 1 with a range of stiffnesses for the bend term.
Approach	Anticipating section 5.2, we find it expedient simply to leave this term out, thereby restoring symmetry.
Challenge	To animate clothing, which is our main concern, requires much higher spatial resolution to adequately represent realistic (or even semi-realistic) wrinkling and folding configurations.
Challenge	The bottle-neck in most cloth simulation systems is that time steps must be small to avoid numerical instability.
Approach	(For that matter, neither is equation (6) unless all particles have the same mass.
Approach	We believe that the damping function should be defined not in terms of the energy E, but in terms of the condition C(x) we have been using to define energies.
Approach	Since the mechanism we describe enforces constraints exactly, and adds no extra stiffness, we turned away from penalty methods except in the case of cloth/cloth interactions.
Approach	The unmodified conjugate gradient method establishes a stopping criterion based on b T Pb.
Approach	The sparsity of the matrix generated by the implicit integrator is best represented in block-fashion: for a system with n particles, we deal with an n × n matrix, whose non-zero entries are represented as dense 3 × 3 matrices of scalars.
Approach	The use of an implicit integration method, described in the next section, generates large unbanded sparse linear systems.
Approach	We call these two forces the shear and bend forces.
Approach	CG methods exploit sparsity quite easily, since they are based solely on matrix-vector multiplies, and require only rudimentary sparse storage techniques.
Approach	The b u and b v parameters (see equation (10)) were then made smaller in certain regions to produce cuffs and waistbands, or strategically increased to induce wrinkling behavior in other regions.
Background	(The price, however, is that some of the forces in the system—notably between diagonally-adjacent and non-adjacent nodes involved in self-collisions—are treated explicitly, not implicitly.
Approach	When modified-pcg terminates, the residual error e = A v − b has the property that e i need not be close to zero if particle i is constrained.
Approach	) Whenever the simulator reduces the step size, after two successes with the reduced step size the simulator tries to increase the step size.
Approach	Additionally, since K ij is a second derivative—that is, K ij = ∂f i /∂x j = ∂ 2 E/∂x i ∂x j —we have K ij = K T ji so K is symmetric.
Approach	The stiffness weighting for this edge should simply be k u ( u) 2 + k v ( v) 2 .
Approach	) Our formulation for directly imposing and maintaining constraints is harmonious with the use of an extremely fast iterative solution algorithm—a modified version of the conjugate gradient (CG) method—to solve the O(n) × O(n) linear system generated by the implicit integrator.
Outcome	This is slightly better than O(n 1.5 ) performance, which is in line with the convergence rates of the conjugate gradient method [ 14 ] for systems such as equation (18).
Approach	During cloth/solid contacts, the particle may be attached to the surface, depending on the magnitudes of the frictional forces required; otherwise, the particle is constrained to remain on the surface, with sliding allowed.
Outcome	All of the above advantages translate directly into a fast running time.
Challenge	Our goal is animation, not engineering; thus visually pleasing results, meaning a numerically stable solution, rather than overall accuracy, is the deciding voice.
Approach	In its rest state, this product is zero.
Approach	Despite its initial failure, the ability to make arbitrary small changes in a particle’s position continued to attract our attention.
Approach	Additionally, an iterative method will generally not enforce the constraints exactly without a large number of iterations.
Outcome	We describe a simulation system that uses a triangular mesh for cloth surfaces, eliminating topological restrictions of rectangular meshes, and a simple but versatile formulation of the internal cloth energy forces.
Approach	Completely constrained particles will have v i = z i , while partially constrained particles will have a v i whose component in the constrained direction(s) is equal to z i .
Approach	Given the differential nature of our formulation, it is the particle’s acceleration, or equivalently, the change in the particle’s velocity, that is constrained.
Background	Carignan et al. [ 4 ] improved upon this somewhat, borrowing a formulation due to Platt and Barr [ 11 ]; however, their damping function—a linear function of velocity—does not match the quartic energy functions of their continuum formulation.
Background	No mention is made of damping terms.
Approach	By the small angle approximation, the product w u T w v is a reasonable approximation to the shear angle.
Background	Refinements by Eberhardt et al. [ 5 ]—notably, the use of higher-order explicit integration methods and Maple-optimized code, as well as a dynamic, not static treatment of the problem—obtain similarly realistic results, while dropping the computational cost to approximately 20–30 minutes per frame on an SGI R8000 processor.
Approach	The entire process of implicit integration can be considered to be a filtering process [ 7 ], and we postulated that a mechanism for filtering energy changes caused by displacing particles might make position alteration a viable technique.
Approach	Define x 1 = x j − x i and x 2 = x k − x i .
Approach	Taking the bottom row of equation (5) and substituting x = h(v 0 + v) yields v = hM −1 f 0 + ∂x ∂f h(v 0 + v) + ∂v ∂f v .
Approach	In equation (12), it is the term (∂C(x)/∂x i )(∂ C(x)/∂x  ̇ j ) T which breaks the symmetry.
Approach	What if we wish to constrain the particle’s acceleration in only one or two dimensions?
Approach	One solution is to use Baumgarte stabilization [ 18 ], which schedules the particle’s acceleration so that the position and velocity error of the particle with respect to the surface decay asymptotically to zero.
Approach	Recall that every cloth particle has a changing position x i in world space, and a fixed plane coordinate (u i , v i ).
Approach	In fact, e i is exactly the extra constraint force that must have been supplied to enforce the constraint.
Approach	(Note that removing the calls to filter and changing line 2 to v = 0 yields the standard preconditioned conjugate gradient method.
Background	Breen et al. [ 3 ] describes the use of the Kawabata system of measurement for realistic determination of the in-plane shearing and out-of-plane bending forces in cloth.
Approach	(A triangle’s mass is the product of the cloth’s density and the triangle’s fixed area in the uv coordinate system.
Approach	4 The forward method requires only an evaluation of the function f but the backward method requires that we solve for values of x and v that satisfy equation (4).
Approach	Similarly, the derivative of f is also sparse.
Approach	) We apply this stretch/compression measure to a triangle as follows.
Approach	The tree is created by a simple recursive splitting along coordinate axes.
Approach	The trick is to recognize instability before you see it on your screen—by then it’s too late.
Approach	Cloth/cloth contacts generate strong repulsive linear-spring forces between cloth particles.
Background	Early work by Terzopoulos et al. [ 17 ] and Terzopoulos and Fleischer [ 15 , 16 ] on deformable models correctly characterized cloth simulation as a problem in deformable surfaces, and applied techniques from the mechanical engineering and finite element communities to the problem.
Approach	Given material for which bending in the u and v directions are weighted by stiffnesses k u and k v , we can emulate this anisotropy as follows.
Approach	Assuming that C depends on only a few particle, C gives rise to a sparse force vector f.
Approach	We capture the rest state of cloth by assigning each particle an unchanging coordinate (u i , v i ) in the plane.
Challenge	Physically-based cloth animation has been a problem of interest to the graphics community for more than a decade.
Outcome	In this paper, we describe a cloth simulation system that is much faster than previously reported simulation systems.
Approach	When collisions between a cloth vertex and triangle, or two cloth edges are detected, we insert a strong damped spring force to push the cloth apart.
Approach	A property of our approach, however, is that the constraints are maintained exactly, regardless of the number of iterations taken by the linear solver.
Approach	When cloth contacts a solid, we lock the particle onto the surface, if the relative tangential velocity is low.
Outcome	Even for extremely stiff systems, numerical stability has not been an issue for our simulator.
Background	Carignan et al. recognized the need for damping functions which do not penalize rigidbody motions of the cloth (as simple viscous damping does) and they added a force which damps cloth stretch and shear (but not bend).
Approach	Instead, we define internal behavior by formulating a vector condition C(x) which we want to be zero, and then defining the associated energy as k C(x) T C(x) where k is a stiffness constant.
Approach	Since the stretch term prevents the magnitudes of w u and w v from changing overly much, we need not normalize.
Approach	For cloth/solid collisions, however, the situation is more complicated.
Approach	Our current implementation models solid objects as triangularly faced polyhedra.
Approach	(Omitting all of equation (12), however, causes serious problems.
Approach	Applying static friction forces to cloth contacts is far more difficult, and is a problem we have not solved yet.
Background	A more comprehensive discussion on cloth research can be found in the survey paper by Ng and Grimsdale [ 9 ].
Approach	However, even decomposing E into sparse energy functions is not enough.
Approach	Much of the performance of our system stems from the development of an implicit integration formulation that handles contact and geometric constraints in a direct fashion.
Background	Cloth/cloth collisions are detected by checking pairs ( p, t) and (e 1 , e 2 ) for intersections, where p and t are a cloth particle and a cloth triangle respectively, and e 1 and e 2 are edges of cloth triangles.
Approach	Finally, we tried to estimate our simulator’s performance as a function of n, the number of cloth particles.
Approach	When we began using procedure modified-pcg, we did not notice any substantial change in the number of iterations required by the method.
Approach	Equation (4) is a nonlinear equation: rather than solve this equation exactly (which would require iteration) we apply a Taylor series expansion to f and make the firstorder approximation ∂f ∂f f(x 0 + x, v 0 + v) = f 0 + ∂x x + ∂v v.
Approach	(A direct method for solving the augmented system would, however, avoid this problem.
Approach	The implicit solver easily tolerates these stiff forces.
Approach	Both cloth/cloth and cloth/solid collisions give rise to the same problem whenever two contacts form.
Approach	Suppose we write ẍ i = 1/m 0 i 1/m 0 i 0 0 f i .
Approach	We tried this for a time, and found it to be a not unreasonable constraint enforcement mechanism.
Approach	Let us consider a triangle whose vertices are particles i, j and k.
Approach	Forces and their derivatives are easily derived using equations (7) and (8).
Approach	Our idea then is to define an invariant— for all i, the component of v i in the constrained direction(s) of particle i is equal to z i —and then establish and maintain the invariant at each iteration, by defining a filtering procedure filter.
Approach	Unfortunately, we cannot apply the same transformation to equation (14), because W is singular—the filtering blocks in equation (13) are rank deficient—so we cannot multiply through by W −1 .
Approach	For contact constraints (between cloth and solid objects) we need to know what the actual force of constraint is, in order to determine when to terminate a constraint.
Approach	At an equilibrium point of E, the gradient ∂E/∂x vanishes.
Approach	Additional forces include air-drag, gravity, and user-generated generated mouse-forces (for interactive simulations).
Approach	(Most of our simulations involving human motions use a step size of 0.02 seconds.
Approach	Cloth likewise resists shearing in the plane.
Background	Much has been written about collision detection for cloth; we have nothing substantial to add to the subject of collision detection per se.
Background	Since then, other research groups (notably Carignan et al. [ 4 ] and Volino et al. [ 20 , 21 ]; Breen et al. [ 3 ]; and Eberhardt et al. [ 5 ]) have taken up the challenge of cloth.
Outcome	For example, we demonstrate results similar to those in Breen et al. [ 3 ] and Eberhardt et al. [ 5 ] (draping of a 2,600 node cloth) with a running time just over 2 seconds per frame on an SGI Octane R10000 195 Mhz processor.
Approach	The constraints we discuss in this section are either automatically determined by the user (such as geometric attachment constraints on a particle) or are contact constraints (generated by the system) between a solid object and a particle.
Approach	Clearly, basing the damping force on E  ̇ is not what we want to do.
Approach	We initially implemented constraints using equation (14) and found that it worked exactly as advertised.
Background	(For a square √ system of n nodes, the resulting linear system has bandwidth n.
Approach	A quadratic model for energy is, numerically, a better choice.
Outcome	The techniques we describe in this section could be used for multi-particle constraints; however, constraints that share particle would need to be merged.
Approach	This lets us write x 1 = w u u 1 + w v v 1 and x 2 = w u u 2 + w v v 2 .
Approach	This is possible—but it complicates the system immensely.
Approach	Unfortunately, this turns a positive definite system into an indefinite system, which means that iterative methods such as CG will need to square the system first, thereby doubling the running time and degrading the numerical conditionining of the linear system.
Approach	Real-world cloth is cut from flat sheets of material and tends to resist deformations away from this initial flat state (creases and pleats not withstanding).
Approach	Lines 5 and 15 maintain the invariant by filtering c before adding it to v.
Background	Energy functions were derived using a continuum formulation.
Outcome	In general, most of our simulations require on average from two to three time steps per frame of 30 Hz animation, even for (relatively) fast moving cloth.
Approach	The overall implementation of sparsity is completely straightforward.
Approach	Each face has an associated thickness and an orientation; particles found to be sufficiently near a face, and on the wrong side, are deemed to have collided with that face, and become subject to a contact constraint.
Background	The linear systems result- ing from the use of implicit integration techniques were solved, for small systems, by direct methods such as Choleski factorization, or using iterative techniques such as Gauss-Seidel relaxation or conjugate gradients.
Approach	At any given step of the simulation, a cloth particle is either completely unconstrained (though subject to forces), or the particle may be constrained in either one, two or three dimensions.
Approach	Because of this, we handle cloth/cloth contacts with strong springs (easily dealt with, given the simulator’s underlying implicit integration base) and “position alteration,” a technique described in section 6.
Approach	To the above forces we also add easily implemented forces such as gravity and air-drag (which is formulated on a per-triangle basis, and opposes velocities along the triangle’s normal direction).
Approach	The CG method (technically, the preconditioned CG method) takes a symmetric positive semi-definite matrix A, a symmetric positive definite preconditioning matrix P of the same dimension as A, a vector b and iteratively solves A v = b.
Approach	) Complementing the above three internal forces are three damping forces.
Approach	Since our constrained formulation ignores certain components of b, our stopping criterion should as well, so we add filtering to line 3.
Background	In this case, banded Choleski factorization [ 6 ] requires time O(n 2 ).
Approach	Since E  ̇ = (∂E/∂x) T x, we find that E  ̇ is zero when E is at its minimum, regardless of the system’s velocity x = v.
Approach	The damping forces do not dissipate energy due to other modes of motion.
Approach	We decided that using a CG method to solve the unsymmetric problem was not acceptable.
Outcome	) We also introduce a simple, unified treatment of damping forces, a subject which has been largely ignored thus far.
Approach	(Unlike previous metric-tensor-based formulations [ 15 , 16 , 17 , 4 ] which model some deformation energies as quartic functions of positions, we model deformation energies only as quadratic functions with suitably large scaling.
Approach	When the simulation is fast enough to interact with, we add user-controlled “mouse” forces.
Outcome	Similarly, we show garments (shirts, pants, skirts) exhibiting complex wrinkling and folding behavior on both key-framed and motion-captured characters.
Approach	The energies we have just described are functions of position only.
Approach	Recall from section 2.1 that we view the vector f in block form; each element f i is a vector in IR 3 .
Approach	In particular, if we want to slightly lengthen a garment (for example, a sleeve) in the u direction, we can increase b u , which causes w u to seek a larger value, and tends to induce wrinkles across the u direction.
Approach	If the particle is constrained in all three dimensions, then we are explicitly setting the particle’s velocity (at the next step).
Approach	) Using W and z, we rewrite equation (6) to directly enforce constraints.
Approach	Additionally, the running time of our simulator is remarkably insensitive to the cloth’s material properties (quite the opposite behavior of explicit methods).
Approach	The geometric state of all the particles is simply x ∈ IR 3n .
Approach	This means that the correct approach to determing constraint release is combinatoric, as in Baraff [ 2 ].
Approach	If the simulator fails at the larger step size, it reduces the size again, and waits for a longer period of time before retrying to increase the step size.
Background	An ADI method generates a series of tightly banded (and thus quickly solved) linear systems rather than one large sparse system.
Approach	We can treat w u and w v as functions of x, realizing that they depend only on x i , x j and x k and using equation (9) to obtain derivatives.
Approach	For example, the strong stretch force must be accompanied by a suitably strong damping force if we are to prevent anomalous in-plane oscillations from arising between connected particles.
Approach	Given v, we trivially compute x = h(v 0 + v).
Approach	Matrix-vector products with A are of course implemented in sparse matrix-vector fashion, using the data structures defined in section 2.3.
Approach	A dynamic simulation usually requires knowledge of the inverse mass of objects; for example, note the appearance of M −1 , and not M in equation (6).
Approach	If any triangle undergoes a drastic change in its stretch (in either the u or v direction) we discard the proposed state, reduce the step size, and try again.
Approach	Thus, we can compute constraint forces at the end of modified-pcg by performing one last matrixvector product to compute A v − b.
Approach	We can measure the extent to which cloth has sheared in a triangle by considering the inner product w u T w v .
Approach	Happily, we can make use of the filtering effect of implicit integration without any extra work.
Approach	Clearly, this situation needs to be remedied.
Approach	In general, E  ̇ is always too small near the system’s rest state.
Approach	) We use a simple preconditioner P by making P be a diagonal matrix with P ii = 1/A ii so products involving P −1 are trivially computed.
Approach	Equation (6) requires both the vector f and the matrix ∂f/∂x.
Approach	The forces, and their derivatives with respect to position and velocity, are of course included in equation (15).
Approach	A key step in our simulation process is the solution of an O(n) × O(n) sparse linear system, which arises from the implicit integration method.
Approach	Additionally, we introduce a simple method, tailored to cloth simulation, for dynamically adapting the size of time steps over the course of a simulation.
Approach	This modification gives us complete control over both the position and velocity of a constrained particle in just one step, without any extra computational cost.
Background	Although specific details vary (underlying representations, numerical solution methods, collision detection and constraint methods, etc.), there is a deep commonality amongst all the approaches: physically-based cloth simulation is formulated as a time-varying partial differential equation which, after discretization, is numerically solved as an ordinary differential equation
Approach	Meanwhile, the particle’s position at the next step follows from equation (4): x i = h(v 0i + v i ) (recall that v 0i is the particle’s current velocity).
Approach	The modified method will need to know about the particles’ constraints and the vector z.
Background	Terzopoulos et al. [ 15 , 17 ] discretized cloth as a rectangular mesh.
Approach	If we take 1/m i to be zero, we give the particle an infinite mass, making it ignore all forces exerted on it.
Approach	This is unacceptable.
Approach	Energy functions are an undesirable starting point because sensible damping functions cannot be derived from energy functions.
Approach	For high sliding velocities, we apply a dissipative tangential force, opposite the relative sliding direction, proportional to the normal force.
Approach	The idea behind our constraint enforcement mechanism is described quite simply, although the actual implementation is somewhat more complicated, to maximize performance.
Outcome	Quadratic energy models mesh well with implicit integration’s numerical properties.
Approach	However, penalty methods do not enforce constraints exactly, and they do add some additional stiffness to the system.
Approach	However, since our simulator proceeds in discrete steps, collisions resulting in a reasonably substantial interpenetration depth can occur between one step and the next.
Challenge	Explicit methods are ill-suited to solving stiff equations because they require many small steps to stably advance the simulation forward in time.
Approach	Thus, a set of four-particle constraints (such as vertex/triangle or edge/edge contacts in the cloth) might merge to form a single constraint on arbitrarily many particles, which would be expensive to maintain.
Approach	The force f arising from the energy acts only in the direction ∂C(x)/∂x, and so should the damping force.
Approach	The computation of the derivative matrices’ entries is also greatly complicated, because we must now introduce extra Jacobian matrices that relate a particle’s reduced coordinates to its motion in world-space.
Approach	• For each particle i, the component of v i in the particle’s constrained direction(s) will be exactly z i (no matter how many iterations are taken).
Approach	In particular, a fast rise to the surface was prone to noise and “jumpiness”; this could be eliminated, but at the cost of decreasing the step size.
Approach	For very small test systems, we solved equation (14) using a direct method (Gaussian elimination) without any problems.
Approach	A completely constrained particle would have no coordinates, while a particle with one dimension of constraint would have two coordinates.
Background	This work recognized the need for damping forces; however, only a simple viscous drag force −k x was used.
Approach	If we let n 1 and n 2 denote the unit normals of the two triangles and let e be a unit vector parallel to the common edge, the angle θ between the two faces is defined by the relations sin θ = (n 1 × n 2 ) · e and cos θ = n 1 · n 2 .
Approach	After each implicit step, we treat the resulting x as a proposed change in the cloth’s state, and examine the stretch terms (section 4.2) for each triangle in the newly proposed state.
Approach	We can now easily describe the internal forces acting on the cloth, by just writing condition functions.
Approach	Thus, the backward Euler step consists of evaluating f 0 , ∂f/∂x and ∂f/∂v; forming the system in equation (6); solving the system for v; and then updating x and v.
Approach	(The vector r in modified-pcg is equal to filter(A v − b), so the extra matrix-vector product to compute e really is necessary.
Approach	We define a condition for bending by writing simply C(x) = θ which results in a force that counters bending.
Approach	More elaborate preconditioners could be used, though we doubt there is a large speedup to be gained.
Approach	Again, we treat K in block fashion: K ∈ IR 3n×3n , so an element K ij is a 3 × 3 matrix.
Approach	(Of course, if stretchy cloth is specifically called for, the stretch coefficient can be made smaller.
Background	(Some previous continuum formulations have modeled stretch energy along an axis as essentially (w u T w u − 1) 2 , which is a quartic function of position [ 15 , 16 , 17 , 4 ].
Outcome	Empirically, we conclude that the two methods have similar convergence behavior.
Approach	A slower rise to the surface caused visual artifacts.
Background	) CG methods, however, require symmetric matrices.
Approach	The iteration stops when b − A v is less than b where is a user-defined tolerance value.
Approach	6 We could apply a CG method to the unsymmetric matrix of equation (14) by use of the “normal equations”; but this involves multiplying the matrix of equation (14) with its transpose which doubles the cost of each iteration while squaring the condition number of the system [ 14 ]—a less than desirable plan.
Background	The focus of this work is on static poses for cloth, as opposed to animation: thus, their simulation process is best described as energy minimization, although methods analogous to explicit methods are used.
Approach	We tried a simpler solution: when intersections occurred, rather than wait for a scheduled constraint or a penalty force to eliminate the intersection, we simply altered the positions of the cloth particles, effecting an instantaneous (and discontinuous) change in position.
Approach	Having modified the top row of equation (4), we must follow this change through: using equation (17) and repeating the derivation of section 3 and the symmetric transform from section 5 yields the modified symmetric system
Approach	Even though our cloth is modeled as a discrete set of points, grouped into triangles, it will be convenient to pretend momentarily that we have a single continuous function w(u, v) that maps from plane coordinates to world space.
Approach	Substituting this approximation into equation (4) yields the linear system
Background	For some applications, the required spatial resolution—that is, the dimension n of the state vector x—can be quite low: a resolution of only a few hundred particles (or nodal points, depending on your formulation/terminology) can be sufficient when it comes to modeling flags or tablecloths.
Approach	A dissipative force tangent to the contact is also applied, countering any sliding motion.
Approach	) Again, the constraint method we describe steps past these difficulties, so we turned away from using Lagrange multipliers.
Challenge	This results in a “stiff” underlying differential equation of motion [ 12 ].
Approach	Given a mesh of n particles, the position in world-space of the ith particle is x i ∈ IR 3 .
Approach	Additionally, the damping force should depend on the component of the system’s velocity in the ∂C(x)/∂x direction; in other words, the damping strength should depend on (∂C(x)/∂x) T x = C(x).
Approach	) For cloth/cloth collisions, we detect both face-vertex collisions between cloth particles and triangles, as well as edge/edge collisions between portions of the cloth.
Approach	At its limit, the simulator will try increasing the step size every 40 steps; thus, if the user chooses too large a step, the simulator settles down to wasting only one out of every 40 steps in attempting too large a step.
Approach	Likewise, we might decrease b v near the end of a sleeve, inducing a tight cuff, as on a sweatshirt.
Approach	A better approach is decompose E into a sum of sparse energy functions; that is, to write E(x) = α E α (x) where each E α depends on as few elements of x—as few particles—as possible.
Approach	) The particles’ accelerations are inherently dependent on one another through the matrix A of equation (16).
Approach	This simplification is clearly not physically justifiable, but we have not observed any ill effects from this omission.
Approach	Fortunately, it is easy to add one more step to modified-pcg to determine the constraint force.
Challenge	Cloth strongly resists stretching motions while being comparatively permissive in allowing bending or shearing motions.
Approach	Complete control over a particle’s acceleration is thus taken care of by storing a value of zero for the particle’s inverse mass.
Approach	Let the edge between the triangles be between particles i and j, and define u = u i − u j and v = v i − v j .
Approach	Even so, there are still times when the step size must be reduced to avoid divergence.
Approach	We ran the simulation in figure 1 with cloth resolutions of 500, 899, 2,602 (shown in figure 1 ) and 7,359 particles.
Approach	A solid object’s faces are grouped in a hierarchical bounding box tree, with the leaves of the tree being individual faces of the solid.
Approach	This makes differentiating θ with respect to x a manageable task.
Approach	This involves augmenting the linear system of equation (6) with extra variables (the multipliers) and extra equations (the constraint conditions).
Background	Reported resolutions of the garments are approximately two thousand triangles per garment (roughly 1,000 nodal points) [ 21 ] with running times of several minutes per frame for each garment on an SGI R4400 150 Mhz processor.
Approach	Note than an unconstrained particle can be considered to have the 3 × 3 inverse mass matrix 1 I, with I the identity matrix.
Approach	Combining all forces into a net force vector f, the acceleration ẍ i of the ith particle is simply ẍ i = f i /m i , where m i is the ith particle’s mass.
Approach	Our simulator models cloth as a triangular mesh of particles.
Approach	Thus, regardless of simulation size, we treat all forces as part of the implicit formulation.
Outcome	This paper describes a cloth simulation system that can stably take large time steps.
Approach	The combination of implicit integration and direct constraint satisfaction is very powerful, because this approach almost always allows us to take large steps forward.
Background	Cloth’s material behavior is customarily described in terms of a scalar potential energy function E(x); the force f arising from this energy is f = −∂E/∂x.
Approach	The condition for shearing is simply C(x) = aw u (x) T w v (x) with a the triangle’s area in the uv plane.
Approach	Stretch can be measured at any point in the cloth surface by examining the derivatives w u = ∂w/∂u and w v = ∂w/∂v at that point.
Approach	Our simulation is run with a parameter that indicates the maximum allowable step size: this parameter is set by the user, and is always less than or equal to one frame.
Approach	We experimented with this technique, but found it lacking.
Approach	Our system detects collisions between cloth particles and solid objects by testing each individual cloth particle against the faces of each solid object.
Approach	Without a constraint on those particles’ velocities there is no guarantee that they will go exactly where we want in one step, but the ability to induce sizeable jumps in position without excessively stiff spring forces adds greatly to the stability of the simulation.
Approach	Stiffness, and thus any potential instability, arises almost completely from the strong stretch forces in the cloth.
Approach	We can also add correction terms to particles involved in cloth/cloth collisions.
Approach	While this would be problematic when using a multi-step differential equation solver which expects continuity (such as a RungeKutta method), it should not interfere with a one-step solver such as the backward Euler method.
Outcome	) The speed (and ease) with which our sparse linear systems can be robustly solved—even for systems involving 25,000 variables or more—has convinced us that there is no benefit to be gained from using an ADI method instead (even if ADI methods could be applied to irregular triangular meshes).
Approach	In this equation, the derivative ∂f/∂x is evaluated for the state (x 0 , v 0 ) and similarly for ∂f/∂v.
Approach	The simulator models cloth as a triangular mesh, with internal cloth forces derived using a simple continuum formulation that supports modeling operations such as local anisotropic stretch or compression; a unified treatment of damping forces is included as well.
Approach	This requires the stretch force to have a high coefficient of stiffness, and in fact, it is the stretch force that is most responsible for the stiffness of equation (1).
Approach	Defining the derivative matrix K = ∂f/∂x, the nonzero entries of K are K ij for all pairs of particles i and j that C depends on.
Approach	We derive our modified conjugate gradient method by observing that the effect of the matrix W in equation (14) is to filter out velocity changes in the constrained directions.
Approach	We formulate the shear force on a per triangle basis, while the bend force is formulated on a per edge basis—between pairs of adjacent triangles.
Approach	The particle’s change in velocity at each step is under our control, using the constraint techniques described in section 5.
Approach	The constraints are always maintained exactly, independent of the number of conjugate gradient iterations, which is typically small.
Outcome	The running times were, respectively, 0.23 seconds/frame, 0.46 seconds/frame, 2.23 seconds/frame, and 10.3 seconds/frame.
Background	He iteratively adjusts nodal positions to eliminate unwanted stretch; the convergence properties of this method are unclear.
Approach	Note that ∂d/∂x is not a second derivative of some function as was the case in equation (8) so we cannot expect ∂d/∂x to be symmetrical.
Approach	Note that these two conditions imply that unconstrained particles have r i close to zero, while completely constrained particles have v i = z i .
Approach	The condition we write for the bend energy depends upon the four particles defining the two adjoining triangles.
Background	Speed was of secondary concern in this work.
Approach	The clothes in figures 3–6 were modeled as discrete planar panels, and then topologically seamed.
Approach	As previously discussed, the step size h must be quite small to ensure stability when using this method.
Approach	We approximate w(u, v) as a linear function over each triangle; this is equivalent to saying that w u and w v are constant over each triangle.
Approach	Friction presents a similar problem.
Approach	For both types of collisions, our detection algorithm reports an intersection, and then takes action to remedy the situation: either by enforcing a constraint (cloth/solid collisions) or by adding a penalty force (cloth/cloth) collisions.
Approach	The force is not, strictly speaking, a frictional force: rather it is proportional to the slip velocity, so it is in actuality a damping force, although it reasonably emulates dynamic friction.
Approach	The matrix is represented as an array of n rows; each row is a linked list of the non-zero elements of that row, to accommodate possible run-time changes in the sparsity pattern, due to cloth/cloth contact.
Approach	Constraints are either user-defined (the time period that a constraint is active is user-controlled) or automatically generated, in the case of contact constraints between cloth and solids.
Approach	We will create a modified version W of M −1 ; W will be a block-diagonal matrix, with off-diagonal blocks being zero, and diagonal blocks defined as follows: let ndof(i) indicate the number of degrees of freedom particle i has, and let particle i’s prohibited directions be p i (if ndof(i) = 2) or p i and q i (if ndof(i) = 1) with p i and q i mutually orthogonal unit vectors.
Approach	If we simply enforce a constraint which causes the colliding cloth particle to have a velocity consistent with the solid object’s velocity, and continue to enforce that constraint, the cloth particle will continue to remain embedded somewhere below the solid object’s surface.
Approach	Since our entire formulation is geared to handle stiffness, the usual objections to enforcing constraints with springs—very stiff equations—do not carry as much weight.
Approach	To compute the new state and velocity using an implicit technique, we must first transform equation (2) into a first-order differential equation.
Approach	We could constrain particles through the use of strong energy functions—essentially, stiff springs that attempt to prevent illegal particle motions.
Approach	We also define x = x(t 0 + h) − x(t 0 ) and v = v(t 0 + h) − v(t 0 ).
Approach	The uv coordinates associated with particles make this possible for triangular meshes as well.
Approach	) Finally, equation (6) requires the derivative ∂d/∂v.
Background	Breen et al. [ 3 ] depart completely from continuum formulations of the energy function, and describe what they call a “particlebased” approach to the problem.
Approach	While the shear and bend force stiffness coefficients depend on the material being simulated, the stretch coefficient is essentially the same (large) value for all simulations.
Approach	(This implies we can choose any value of z i for a completely constrained particle, since all directions are constrained; an unconstrained particle must have z i = 0 since it has no constrained directions.
Outcome	In practice, this has proven to work well.
Approach	Additionally, we need to know the constraint force actually exerted in order to model frictional forces properly.
Approach	Consider a particle that has collided with a solid object.
Approach	Robust dynamic cloth simulation, however, is critically dependent on well-chosen damping forces that are a function of both position and velocity.
Approach	(If relative velocities are extremely high, this simple test may miss some collisions.
Approach	We have found the ability to control shrink/stretch anisotropically to be an indispensable modeling tool.
Background	Later work by the same group includes Volino et al. [ 20 ], which focuses mainly on collision detection/response and uses a triangular mesh; no mention is made of damping forces.
Outcome	The methods introduced in all of the previous sections usually allow us to take sizeable steps forward, without loss of stability.
Approach	The implicit integration method generates a large, unbanded sparse linear system at each time step which is solved using a modified conjugate gradient method that simultaneously enforces particles’ constraints.
Approach	The strongest internal force—which we call the stretch force— resists in-plane stretching or compression, and is also formulated per triangle.
Approach	As before, d i is nonzero only for those particles that C depends on, and ∂d/∂x has the same sparsity pattern as ∂f/∂x.
Approach	The simulation system couples a new technique for enforcing constraints on individual cloth particles with an implicit integration method.
Background	There are a large number of methods for altering the size of a time step, for both explicit and implicit integrators, but these methods tend to concentrate on the accuracy of the simulation, and not the stability.
Approach	As in the case of solids, close proximity or actual intersection of cloth with itself initiates contact handling.
Approach	We find this to be needlessly stiff; worse, near the rest state, the force gradient—a quadratic function of position—is quite small, which partially negates the advantage implicit integration has in exploiting knowledge of the force gradient.
Approach	Given a condition C(x) which we want to be zero, we associate an energy function E C with C by writing E C (x) = k 2 C(x) T C(x) where k is a stiffness constant of our choice.
Approach	For every particle i, let z i be the change in velocity we wish to enforce in the particle’s constrained direction(s).
Approach	The solution to the problem of asymmetry is to modify the CG method so that it can operate on equation (15), while procedurally applying the constraints inherent in the matrix W at each iteration.
Outcome	For example, in simulating a 6, 000 node system, the solver takes only 50–100 iterations to solve the 18, 000 × 18, 000 linear system formed at each step.
Approach	We measure bend between pairs of adjacent triangles.
Background	) As previously discussed, Terzopoulos et al. made use of an ADI method for larger cloth simulations.
Approach	For that reason, we have chosen to deal with cloth/cloth contacts using penalty forces: whenever a particle is near a cloth triangle or is detected to have passed through a cloth triangle, we add a stiff spring with damping to pull the particle back to the correct side of the triangle.
Approach	Suppose for example that we want to keep particle i’s velocity from changing.
Approach	Usually, we set b u = b v = 1, though we need not always do so.
Approach	In this case, the result is symmetrical without dropping any terms.
Approach	Note that since C does not depend on v, the matrix ∂f/∂v is zero.
Approach	Given a previous known legal state of the cloth, we postulate a linear motion for the cloth particles to the current (possibly illegal) state and check for either particle/triangle or edge/edge crossings.
Approach	More generally, given a unit vector p ∈ IR 3 , a particle is prevented from accelerating along p by using an inverse mass matrix 1 (I − m i pp T ); this follows from the fact that (I − pp T )p = 0.
Approach	The magnitude of w u describes the stretch or compression in the u direction; the material is unstretched wherever w u = 1.
Approach	We could introduce additional constraint forces—that is, Lagrange multipliers—into our system to satisfy the constraints.
Approach	Stretch in the v direction is measured by w v .
Approach	We considered that perhaps some sort of extra implicit step could be used as a filter, but forming and solving an additional linear system at each step seemed too expensive.
Approach	Our system uses a very stiff stretch force to combat this problem, without any detrimental effects on the run-time performance.
Approach	Rectangular meshes make it simple to treat bending anisotropically.
Outcome	This method, though simple, has served us well.
Approach	We are not limited to constraining particles to have zero accelerations in certain directions; rather, we control exactly what the change in velocity is along the constrained directions.
Approach	We monitor the constraint force, and if the tangential force exceeds some fraction of the normal force, we allow the particle to slide on the surface.
Outcome	The variance in the running times was under 5%.
Approach	To avoid O(n 2 ) comparisons, we use a coherency-based boundingbox approach [ 1 ] to cull out the majority of pairs.
Outcome	Representative running times include a long skirt with 4,530 nodes (8,844 triangles) on a dancing character at a cost of 10 seconds per frame, and a shirt with 6,450 nodes (12,654 triangles) with a cost varying between 8 to 14 seconds per frame, depending on the underlying character’s motion.
Approach	For larger systems, we planned to use the iterative, sparsity-exploiting CG method, which immediately presents us with a problem: equation (14) is not a symmetric linear system.
Approach	Considering all of this, we immediately rejected this method of constraints.
Approach	We use this technique to bring particles quickly and stably to the surface of solid objects without creating visual artifacts or limiting the allowable step size.
Background	The reader should note that the use of implicit integration methods in cloth simulation is far from novel: initial work by Terzopoulos et al. [ 15 , 16 , 17 ] applied such methods to the problem.
Approach	This resulted in visibly “jumpy” behavior of the cloth in localized regions.
Approach	Prior to implementing modified-pcg, we used a penalty method and applied the standard CG method to equation (15).
Background	A common practice in explicitly integrated cloth systems is to improve running time by decreasing the strength of the stretch force; however, this leads to “rubbery” or “bouncy” cloth.
Approach	Collisions between cloth and solid objects are handled by preventing cloth particles from interpenetrating solid objects.
Background	The system uses the midpoint method (an explicit method) to advance the simulation.
Approach	Although we normally think of a particle’s mass as a scalar, we need not always do so.
Approach	Iterative methods do not in general solve linear systems exactly—they are run until the solution error drops below some tolerance threshold.
Background	Terzopoulos et al.’s [ 16 , 17 ] treatment of cloth used a simple viscous damping function which dissipated kinetic energy, independent of the type of motion.
Approach	In this case, analytically checking for intersection between previous and current positions can guarantee that no collisions are missed.
Background	1 Since this time though, research on cloth simulation has generally relied on explicit numerical integration (such as Euler’s method or Runge-Kutta methods) to advance the simulation, or, in the case of of energy minimization, analogous methods such as steepest-descent [ 3 , 10 ].
Approach	Our system’s faster performance begins with the choice of an implicit numerical integration method to solve equation (1).
Approach	Similarly, given two mutually orthogonal unit vectors p and q, we prevent a particle from accelerating in either the p or q direction by using the inverse mass matrix 1 (I − pp T − qq T ).
Outcome	The resulting simulation system is significantly faster than previous accounts of cloth simulation systems in the literature.
Approach	These forces and their gradients are easily derived.
Approach	The reason that changing positions after a step has been taken doesn’t work is because the particle’s neighbors receive no advance notification of the change in position: they are confronted with the alteration at the beginning of the next step.
Approach	An individual particle’s position and velocity can be completely controlled in either one, two, or three dimensions.
Challenge	2 In practice, the computational cost of an explicit method greatly limits the realizable resolution of the cloth.
Approach	Finally, correct constraint-release behavior between cloth and solid objects is difficult to achieve using a reduced coordinate formulation.
Outcome	Unaccounted overhead of the simulation (typically about 5%) includes tasks such as geometry transformations, memory allocation, etc.
Background	This is unfortunate.
Approach	The difference in the two methods is that the forward method’s step is based solely on conditions at time t 0 while the backward method’s step is written in terms of conditions at the terminus of the step itself.
Approach	The constraint techniques we use on individual particles work just as well for collections of particles; thus, we could handle cloth/cloth intersections using the technique described in section 5, but the cost is potentially large.
Approach	An added bonus is that starting from this vector-based energy description tends to result in a simpler, more compact, and more easily coded formulation for ∂f/∂x than proceeding from an energy function in which the structure of C has been lost.
Approach	Subtlety is not required: we find that an unstable step invariably results in stretch changes that are quite large, and are thus easily detected.
Approach	The simulator was used to relax the clothing from an initial deformed state, that got the clothes around the characters, to a well-fitting state on the characters.
Approach	The same component notation applies to forces: a force f ∈ IR 3n acting on the cloth exerts a force f i on the ith particle.
Background	The most critical forces in the system are the internal cloth forces which impart much of the cloth’s characteristic behavior.
Approach	We solve these systems through a modified conjugate gradient (CG) iterative method, described in section 5.
Background	Under normal conditions, cloth does not stretch appreciably under its own weight.
Background	Thus far, the accumulated work by this group (see Volino et al. [ 21 ] for an overview) gives the only published results we know of for simulated garments on moving characters.
Background	By making use of real-world cloth material properties (the Kawabata measuring system) they produced highly realistic static images of draped rectangular cloth meshes with reported resolutions of up to 51 × 51 nodes.
Approach	Unfortunately, simply changing particle positions produced disastrous results.
Approach	We use the sparse data structures described in section 2.3 to store the linear system.
Approach	Also, let u 1 = u j − u i , while u 2 = u k − u i and similarly for v 1 and v 2 .
Approach	When inverse mass is used, it becomes trivial to enforce constraints by altering the mass.
Approach	Given the known position x(t 0 ) and velocity x(t 0 ) of the system at time t 0 , our goal is to determine a new position x(t 0 + h) and velocity x(t 0 + h) at time t 0 + h.
Approach	The stretch energy term in a cloth system is extremely strong, and altering particle positions arbitrarily introduced excessively large deformation energies in an altered particle’s neighborhood.
Approach	An obvious and quite exact method for constraining a particle is to reduce the number of coordinates describing the particle’s position and velocity.
Approach	Particles can thus be attached to a fixed or moving point in space, or constrained to a fixed or moving surface or curve.
Approach	However, this strong damping force must confine itself solely to damping in-plane stretching/compressing motions: stretch damping should not arise due to motions that are not causing stretch or compression.
Approach	If we change the number of coordinates per particle, we alter the size of the derivative matrices in equation (6), as well as the sparsity pattern (this happens when a particle changes from having no coordinates to some coordinates, or vice versa).
Approach	The vector r measures the solution error b − A v, and should not include error due to the constraints; hence we add filtering at lines 4 and 8.
Outcome	We doubt that simulators based on explicit integration methods could make a similar claim.
Approach	To simplify notation, we will define x 0 = x(t 0 ) and v 0 = v(t 0 ).
Approach	Now ẍ i 0 0 0 must lie in the xy plane; no acceleration in the z direction is possible.
Approach	In the case of a single particle, we write x  ̈ i = m 1 i f i to describe a particle’s acceleration.
Outcome	The large step sizes complement the fact that the CG solver requires relatively few iterations to converge.
Approach	For cloth/cloth collisions, this would not appear to be a problem: the spring forces that are added work to counter the colliding velocities and then push the cloth apart.
Approach	Using the stiffness parameters in figure 1 as a reference, we ran the simulation with those bend stiffnesses multiplied by 0.1, 1.0, 10, 100 and 1,000 (for a total range of 10,000 in the stiffness).

Approach	Along with the equation of state, which is an equation for one thermodynamic quantity as a function of two others, this forms a complete description of the fluid, i.e. the velocity and thermodynamic state of the fluid at any point.
Approach	Scalar variables on the interface aid the software in interpreting the images, e.g. assigning values to the black and white limits of the images.
Approach	Deferred rendering means that no rendering decisions need to be made at simulation time, and no simulation time is required at render time.
Approach	For instance, images can be used to initialize temperature fields which cause dynamic buoyancy-driven vortices to evolve.
Approach	The right hand side of the equations become f y .
Outcome	The top element was scaled and had animating transforms to match to the motion of one of the magician’s hands.
Background	The decision making process is well illustrated in [ 19 ], where the end goal, creating animations of Jupiter’s atmosphere for the film 2010, guided aspects from the equations being solved to their final rendering method.
Approach	The system employs techniques from both the scientific and computer graphics communities in order to be both efficient and accessible to animators.
Approach	The equations being solved are essentially those in [ 10 ].
Outcome	The lower element had an animating transform to react to the sliding of one of his feet.
Background	With simple user set-ups, the physically accurate equations take over, generating lots of high quality animation, rich in complexity and guaranteed realistic motion.
Outcome	Some of the unique features of the system described in this paper include: a compressible version of the equations of motion; the use of images and animations for controlling the dynamics; fast accurate texture mapping features; and finally, a complete production system.
Approach	” One node maps the results of simulations done on a rectangle with periodic sides onto a circle, as in middle of figure 8, and the other renders the rectangular temperature field.
Approach	These forcing functions can be analytical functions of the other variables, such as coriolis or buoyancy terms, or can come from other sources, such as images and animations.
Background	Atmospheric researchers often use the compressible formulation because of its computational advantages over the incompressible formulation, even when using the actual speed of sound for pressure waves.
Outcome	One time step calculation takes 36.3 seconds, and one rendered frame such as at the top of figure 7 takes 4.7 seconds to render.
Approach	Conservation of mass dictates that there be areas of return flow as the cold fluid sinks, creating vortices.
Approach	This simulation was run on a 400 by 300 grid, with periodic sides.
Approach	The equations being used here do not make that assumption and buoyancyeffects dominate the dynamics in most of the examples presented.
Background	For scientific work, the non-physical compressibility effects introduced need to be rigorously justified, whereas for the creation of imagery and animation, the guiding standard is how the images look.
Outcome	The system was used in over twenty scenes in the animated feature film The Prince of Egypt.
Approach	Also, the coefficient for the sound speed is multiplied by a constant, introducing artificial compressibility, so that the time step requirement is less severe.
Background	Methods for creating these simulations vary widely, depending on the requirements for realism, controllability, rendering style, and complexity.
Approach	The subgrid scale model is replaced by diffusion terms with constant diffusion coefficients, and the rain processes and coriolis terms are neglected.
Background	Numerical integration methods for systems of equations predate the modern computer as well, and John von Neumann envisioned using the computer to solve the equations of motion for weather prediction in the 1940’s.
Approach	Before the simulation is run, the system performs a preprocessing step on the images, essentially resampling them and slightly smoothing them for the appropriate simulation resolution, and enforcing periodic conditions if needed.
Approach	The rendering process involves reading the data from disk at the simulation resolution and performing resampling with a two-pass, one-dimensional cubic convolution kernel.
Background	Creative control and the level of realism desired are two of the main concerns.
Approach	Users should have easy access to setting up the various flow situations.
Outcome	Some of the lower resolution final elements used in the film were created in under two minutes, and even the highest resolution simulations could be set up using the information gathered in simulations taking only a few minutes.
Approach	The only images that are not scaled by zero, are the images used to define the unstable profile and the random perturbations in the initial temperature.
Approach	The emphasis in this paper is on the use of the full NavierStokes equations to solve for the dynamic velocity and temperature fields numerically.
Approach	Everything can be defined and rendered in one pass within the compositing package, including the animating perspective transformation.
Outcome	Texture mapping features allow deferred rendering of flow distortions, with no need to recompute particle trajectories through a time-evolving velocity field.
Outcome	The final composite shows the circular shape being repositioned in perspective, registered to the bowl.
Approach	This typically translates into solving a large matrix equation, usually by iterative techniques, to ensure the pressure field is consistent with the velocity field.
Background	Sir Horace Lamb’s Hydrodynamics [ 11 ], from 1932, is still regarded as one of the best sources for fundamental theorems, equations, and solutions in fluid mechanics.
Approach	This makes it easy to set up shear flows and stratified layers of density.
Approach	The primary variables being advanced forward in time are u; v; and w , which are the velocity components in the x;y; and z directions, respectively, the pressure perturbation variable, , defined in equation 9, and the potential temperature,   , defined in equation 8.
Approach	The time step limitation for stability for the advection problem, i.e. negligible diffusion, is          (15)          where t is the time step, x is the grid spacing, n is the number of space dimensions, c is the speed of the fastest moving wave in the system, and m is a factor that accounts for the spatial differencing method.
Background	Today, the use of computers to solve the Navier-Stokes equations is widespread, with descriptions of particular models and their solutions filling the pages of journals such as Journal of Fluid Mechanics and Journal of the Atmospheric Sciences.
Approach	More rendering options described below are available in the compositor.
Approach	The solution vector is initialized with values at the regularly spaced grid locations, then advanced forward in time according to the time integration scheme.
Approach	The overall method is globally fourth order accurate in space and time, provided that the initial conditions, boundary conditions, and forcing functions are sufficiently smooth.
Approach	A two-dimensional version of the above equations can be derived by assuming that in one of the horizontal directions there is no flow and no change in any of the variables.
Approach	The compositor is a graph-based system (DAG) where rendering operations are “nodes” in the graph.
Approach	Calculation times are given for simulation time steps.
Background	Of the many ways of incorporating simulation into the creation of fluids animations, one end of the spectrum in a traditional animation environment is to use no simulation at all, and draw every frame of the animation.
Approach	Individual layers allow artists to make independent decisions for colors, opacities, rendering parameters, and transforms.
Outcome	An average render time for distortions such as those depicted in figure 2 is 9.8 seconds per frame.
Approach	Given appropriate initial conditions and boundary conditions, the equations can be used to advance the solution forward in time.
Approach	The simulations output information at regular intervals which is later used in the compositor for rendering.
Approach	The equation set used was derived for a meteorology application, the study of clouds [ 10 , 18 ].
Approach	The equations will now look like equation 14 where the prime in equation 14 denotes differentiation with respect to time.
Approach	At the boundaries, a well-posed problem can be formed by specifying information for all the variables except the pressure, where the solution needs to be calculated [ 8 ].
Outcome	All of the equations, including the texture mapping equations, extend to three dimensions.
Outcome	This paper presents a complete production system which enables animators to access the beauty and realism embodied in the physically accurate equations of motion, the Navier-Stokes equations.
Outcome	Time step calculation time is 2.7 seconds per time step and rendering time is 1.57 seconds per frame.
Approach	When an incompressible formulation is used, there is an elliptical partial differential equation involved, corresponding to an “infinite” speed of propagation of pressure waves.
Outcome	For computer graphics purposes, an artificial speed of sound of an order of magnitude less than the actual one is often justified, and provides a mechanism for dramatic speed increases.
Background	There may be no right or wrong answer as to what level of physical modeling is appropriate, in general, but there is usually a decision making process based on the imagery needed to guide this choice.
Approach	Each output pixel receives its color from the colors visited along a flow integration path passing through the output pixel between the two specified times.
Approach	Equations are derived for including texture mapping information, so that particle trajectories don’t need to be computed via integration later.
Outcome	The system also provides fast turn around time.
Approach	All of the parameters, such as the timing and threshold values, have animation curves.
Approach	In addition, arbitrary forcing functions, or source terms, would be desirable to make many more situations possible, even those without any physical justification.
Approach	This previewer is a simple mapping of the temperature values to the luminance of the black and white images.
Background	One simple example of this is the use of artificial compressibility, employed in the equation set presented in section 3, as a means of speeding up the calculations.
Background	Numerical methods for fluid dynamics can be found in a variety of places [ 5 , 8 ], and an extensive book list and summary of available codes can be found at http://chemengineer.miningco.com/msub74.htm .
Outcome	With this system, animators can express themselves by controlling the simulation dynamics through a familiar user interface—the use of images and animations.
Approach	It also calculates the initial pressure field from the temperature field, ensuring that the hydrostatic relationship is satisfied for vertical columns of fluid.
Approach	Particle advection through the dynamically evolving velocity field is thus precalculated, eliminating the need to calculate particle trajectories at render time.
Approach	Inputs to this node are an image to be distorted, a simulation number, a reference time, and a current time.
Background	Compared to computer graphics, the equations of fluid motion and solution methods for them have a long history.
Background	This approach gives a wide range of flexibility and control, but is a tedious process with realistic limits on the complexity that can be achieved.
Approach	The components described in sections 4.2-4.4 were built to support two-dimensional simulations which use images and animations as input.
Approach	These variables would obey equation 11, and let you know the original location of the parcel at any stage in the simulation, at the fixed grid locations.
Background	At the other extreme, there are many advantages to numerically solving the full equations of motion for fluids, usually referred to as the Navier-Stokes equations, to create an- imations of fluid behavior.
Approach	The plan was to use this technique to create “magical smoke” for the sequence Playing with the Big Boys, and the process was streamlined with this in mind.
Outcome	Another unique feature of the system is the use of images and animations as input devices, which allows animators to control initial conditions, source terms, and movable internal boundaries in an easy and flexible way.
Approach	If both map of variable, these variables z , with obey initial equation condition 11, texture then at map a later coordinates time, t , at x time x; z;t t =0 and for z the x; parcel z;t will at location contain x; the z at time t , that is, they tell where the parcel of fluid “came from.
Background	These concerns move us into the territory of computer graphics, with the highly practical production environment driving the process forward.
Approach	Taking y to be the flowless direction, equation 2 is no longer needed, and simplifications are made to equation 4 and to the material derivative and Laplacian operators to account for zero derivatives in the y direction.
Outcome	The compressible formulation, unlike any in the graphics literature, allows for the modeling of compressible effects, such as shock waves, and also provides a mechanism for speeding up flow calculations by an order of magnitude or more.
Approach	It is important to do periodic extensions before resampling to avoid seams at the periodic boundaries, and to do thresholding after resampling to avoid stair-step effects for magnification near the threshold values.
Approach	The image is distorted based on the flow field evolution between the reference time and the current time, using the texture mapping data for those two times.
Approach	A single smearing uses one static flow field and a time range for the integration, provided by the user.
Approach	Animators use images and animation sequences to drive two-dimensional numerical simulations of the time-dependent compressible Navier-Stokes equations.
Approach	At render time, a library of potentially useful simulations is already built up, and rendering involves little more than appropriate resampling (see section 4.4).
Approach	A wide variety of rendering styles increases the expressive power of scene elements and their interpretation.
Outcome	One of the most useful ideas presented here for three-dimensional simulations is the implementation of an artificial speed of sound through the compressible formulation of the equations.
Outcome	A compressible formulation and two-dimensional simulations allow for quick turnaround time in the creative cycle of creating/modifying simulations and applying the results within the compositor to the final scene.
Challenge	When the emphasis is on the look of the final images, there are new sets of concerns about how to control and modify the simulation dynamics, and what and how to render.
Approach	The idea is to initialize passive scalar variables with the original positions of the fluid parcels.
Approach	Equation 11 is the prototypical passive scalar equation, which models an arbitrary scalar being advected along with the fluid, and optionally diffusing through the non-negative diffusion coefficient .
Approach	The meteorology convention of using z as the up direction is used here.
Approach	Base state variables, denoted by overbars, are time-invariant functions of z , the vertical coordinate.
Approach	These terms have many interpretations, from molecular diffusion, to turbulence modeling, to numerical stability devices.
Approach	This Eulerian description is particularly useful in the rendering phase, since the texture mapping coordinate information is evenly spaced in the output image space.
Approach	The simulation is performed on a 960 by 321 grid, with the rendering aspect ratio adjusted to make the shapes look taller and thinner than the actual simulation, which would otherwise promote rising plumes with essentially round circulation patterns.
Approach	First and second derivative terms are replaced by their fourth order finite difference approximations, which can be found in [ 1 ].
Approach	This is usually a time consuming part of the solution method and does not scale well as grid resolution is increased.
Outcome	This paper presents a system that uses computational fluid dynamics to produce smoke, water, and other effects for traditionallyanimated films.
Outcome	By far, the biggest success was twodimensional simulations of buoyant instabilities, where the temperature field was visualized as smoke.
Approach	The simulation resolution is 150 by 151.
Background	Yaeger, Upson, and Myers [ 19 ], used two-dimensional timedependent vorticity equations to model the atmosphere of Jupiter.
Approach	Test animation resulted from three-dimensional simulations with temperature being visualized via volume rendering, two-dimensional simulations creating velocity fields used for line integral convolution of source imagery, as well as other techniques.
Approach	The lettering in “SI99RAPH” is colder than the surrounding fluid, which causes it to sink.
Approach	The solution method for solving the system of equations is the fourth order Runge-Kutta scheme, using fourth order centered finite differencing for spatial derivatives on a regular grid with equal grid spacing.
Outcome	The fluid inside the letters is colder and more dense than the surrounding fluid, causing it to sink.
Approach	For instance, comparing Runge-Kutta fourth order with Euler’s method, four function evaluations per time step are required for Runge-Kutta compared with one for Euler, but this is almost offset by the time steps which can be 2.82 times larger, according to equation 15.
Background	Although computational fluid dynamics is a fairly mature subject, the emphasis so far has been on accurately simulating physical situations for scientific purposes, rather than creating images and animations as the end goal, which has different concerns and motivations.
Approach	A convenient way to record the flow field history is through the dynamic evolution of texture map information.
Approach	For render times, the quote is for producing 640 by 480 images.
Outcome	Simulations performed on a 100 by 100 grid are detailed enough for film work and can be calculated at a rate of one frame per second.
Approach	As described in section 3.2.1, texture mapping information can be calculated along with the simulation to provide rendering information.
Approach	This involves evaluating the function f y at each of the grid points, making use of the solution vector in a stencil of grid points surrounding the grid point being evaluated.
Approach	Similarly, images and animations are employed to apply forcing terms to the momentum and energy equations.
Outcome	While this production system emphasizes the needs of a traditional animation environment, many of the concepts apply outside this context as well.
Background	Equations expressing conservation of mass, momentum, and energy, often referred to as the Navier-Stokes equations, have been around since the early 1800’s.
Approach	Images define the initial conditions for velocity and temperature.
Approach	For instance, a situation of having a colder fluid on top of a hotter fluid is not necessarily an unstable arrangement, due to the stratified hydrostatic pressure in the atmosphere.
Outcome	Additional production components make the overall process efficient for the animator.
Background	This concept is defined in most meteorology texts [ 3 ].
Approach	This paper is of that same style, describing a system built at DreamWorks to support the use of fluid dynamics simulations in the creation of special effects for the animated feature film The Prince of Egypt.
Background	Previous work in the graphics literature [ 2 , 4 , 6 , 7 , 9 , 12 , 13 , 14 , 16 , 19 ] has modeled various aspects of fluid behavior with an emphasis on efficiency and controllability issues.
Approach	The fourth order accuracy is not required for production purposes, but the effort in achieving this added accuracy is not significant, and the increased accuracy allows for the use of coarser grids.
Approach	Unless the grid is extremely large, structures moving by one grid point corresponds to a reasonable speed for an animation.
Approach	Not only does this mean that compressibility effects can be modeled, but the equations can be solved much faster.
Approach	Values outside the linear range are clamped to “clear” or “solid.
Approach	The advective terms are those not involving partial derivatives with respect to time.
Approach	Although the code is capable of handling more general situations, such as analytically defined forcing functions, gravitational fields, and diffusion coefficients, only a subset of the functionality is available via the user interface.
Outcome	Using the circular rendering option and a periodic simulation domain creates a seamless texture mapping with the appearance of blood emanating from the center of the bowl.
Approach	Many simulation and rendering techniques were used in the visual development stage of the film.
Approach	Using the simulation starting interface, animators can set other parameters such as the resolution, boundary condition types, output frequency, etc., and can monitor simulations in the viewer described below.
Approach	Ideally, animators would control many aspects of the simulation dynamics and be able to incorporate the results into the final scene in a variety of ways.
Approach	Artists choose rendering parameters later, e.g. to alter final timing or to animate contour levels that make the smoke slowly dissipate.
Outcome	Calculation time between time steps is 19.8 seconds, which include the texture mapping calculations.
Outcome	This is typical of the type of simulation that was used to generate smoke for The Prince of Egypt, where contours of temperature were rendered from a simulation driven by buoyant instabilities.
Approach	At boundary points and one point away, one-sided differencing is used.
Background	In a traditional animation studio, most artwork and animation is two dimensional; the illusion of depth comes from the drawn or painted perspective, along with the camera moves and techniques available in the compositing software.
Outcome	The use of two-dimensional simulations, the compressible formulation, and coarser grids, results in fast, useful simulations.
Approach	In addition to the basic equations of fluid motion, equations can be appended to the system which may or may not have feedback into the basic equations.
Approach	As the simulations are running, or afterward, animators can preview and optionally render the results to disk via the interface shown in figure 6 .
Background	The equations of motion cannot be solved analytically, except in simplified situations, and therefore need to be solved numerically.
Approach	The system should be able to make use of other scene elements, produce scene elements in the most convenient formats, and should be part of an efficient work flow.
Approach	Define x x; a horizonz; 0 = x=L z x; x and z; 0 a vertical = z=L z texture .
Approach	The example times quoted below are for a single processor SGI O2 with R10K floating point chip and processor chip.
Background	The strongest advocacy for use of the full Navier-Stokes equations so far in the graphics literature is from Foster and Metaxas [ 7 ], who solve the three-dimensional equations of motion to model smoke.
Background	Computer graphics simulations of fluid behavior are in demand in filmmaking for depicting gases, liquids, smoke, dust, fire, and other natural phenomena.
Approach	For fourth order centered first derivatives, this factor turns out to be 1.372, compared with 1.0 for second order centered first derivatives.
Approach	Using the compressible formulation means that calculation times for each time step are essentially linear in the number of grid points.
Background	(11)          Derivations of the equations of motion from first principles can be found in many textbooks for the interested reader [ 3 , 11 , 15 , 17 ].
Approach	The initial temperature distribution is a random noise pattern with an overall average temperature which is essentially constant except in a narrow layer near the bottom, where it is hotter.
Outcome	Render time for frames such as figure 1 is 3.16 seconds per frame.
Background	Kass and Miller [ 9 ] solve the shallow water equations, which reduce the Navier-Stokes equations down to solving for an evolving height field for the surface of a shallow body of liquid.
Approach	In figure 8 , “magical blood” is created by a simulation driven by a random forcing function in the temperature equation, defined by one of the input images.
Approach	In addition, two images are used to optionally assign profiles to the horizontal velocity and the temperature as functions of z .
Approach	If a simulation is evolving unsatisfactorily, an animator can quickly restart it using modified images or parameter settings.
Approach	The second example simulates heat being introduced at the bottom of the domain creating “magical smoke” (see figure 7 ).
Outcome	The inclusion of texture mapping differential equations, another new concept developed here, makes it possible to precalculate particle paths on a fixed grid which can be used in a straight-forward manner at render time.
Background	Some of this work makes use of existing velocity fields or allows users to create their own in a variety of ways, rather than have a simulation determine the velocity field.
Outcome	Some of the advantages of these decisions are described below.
Approach	Suppose we are running a two-dimensional simulation on a recttal angular texture domain map of variable, physical x dimensions , with initial L x condition by L z .
Outcome	Fourth order accuracy allows animators to use coarser grids, thus saving time.
Approach	Most ODE solvers (ordinary differential equation), including the fourth order Runge-Kutta scheme employed here, require some level of diffusion to avoid nonlinear instabilities.
Approach	In the first example, an image defines the initial temperature distribution and drives the dynamics of the simulation.
Approach	There is enough variation in the initial distribution such that the nonlinear equations result in pleasing graphic shapes and interesting dynamics.
Approach	In summary, conservation of mass is expressed in the compressible equations by the mathematical statement that changes in density for a parcel of fluid are the result of divergence in the velocity field.
Outcome	In addition to being image-driven, the system is unique in allowing for compressibility of the fluid, and in its use of partial differential equations for texture mapping.

Approach	First of all, they should not depend on the mesh resolution.
Background	Previous methods are either mesh resolution dependent [Katz and Tal 2003] or the weights do not vary smoothly along the surface [Wade 2000], causing artifacts on highresolution meshes.
Background	This requires placing the skeleton joints inside the character and specifying which parts of the surface are attached to which bone.
Approach	However, if it is easy to estimate a good lower bound on f from a partial embedding (of the first few joints), it is possible to use a branch-and-bound method.
Approach	To make the optimization problem computationally feasible, we first embed the skeleton into a discretization of the character’s interior and then refine this embedding using continuous optimization.
Approach	As a subroutine, it uses a step-doubling line search: starting from a given point (in R 3s ), it takes steps in the given optimization direction, doubling step length until the penalty function increases.
Approach	We then find the maximum margin Γ as described above and use this new Γ to construct new skeleton embeddings.
Approach	The paths representing the bone chains should be disjoint, if possible.
Approach	There are several properties we desire of the weights.
Approach	The joints of the skeleton are given in order, which induces an order on the joints of the reduced skeleton.
Approach	While other conditions can be formulated, we found that the Gabriel graph provides a good balance between sparsity and connectedness.
Approach	Thus we can factor the system once and back-substitute to find the weights for each bone.
Approach	The skeleton is given as a rooted tree on s joints.
Approach	We then take the best Γ, use a slightly smaller cube around it, and repeat.
Outcome	Other problems occur at difficult areas, such as hips and the shoulder/neck region, where hand-tuned weights could be made superior to those found by our algorithm.
Approach	The skin attachment is computed by assigning bone weights based on the proximity of the embedded bones smoothed by a diffusion equilibrium equation over the character’s surface.
Approach	Within a single cell of our octree, the interpolated distance field is guaranteed to be C 1 , so it is necessary to look at only the cell boundaries.
Approach	Note also that the weights w i sum to 1 for each vertex: if we sum (1) over i, we get (−∆ + H) P i w i = H · 1, which yields P i w i = 1.
Approach	This is essentially the A* algorithm on the tree of possible embeddings.
Outcome	For each of the remaining cases, one joint placement hint corrected the problem.
Approach	We evaluate Pinocchio with respect to the three criteria stated in the introduction: generality, quality, and performance.
Approach	Pinocchio uses this idea: it maintains a priority queue of partial embeddings ordered by their lower bound estimates.
Background	In particular, a spatial keyframing system expects an articulated character as input, and as-rigid-as-possible shape manipulation, besides being 2D, relies on the constraints to provide articulation information.
Approach	Pinocchio precomputes the shortest paths between all pairs of vertices in this graph to speed up penalty function evaluation.
FutureWork	Animation quality can be improved with a better skinning model [Kavan and Zára ˇ 2005] (although possibly at the cost of performance).
Background	In a conventional skeletal animation package, the user must rig the character manually.
Approach	Because we are dealing with an unreduced skeleton, and discrete optimization has already found the correct general shape, the penalty function can be much simpler than the discrete penalty function.
Outcome	Our video [Baran and Popović 2007b] demonstrates the quality of the animation produced by Pinocchio.
Approach	For the humanoid skeleton we use, for example, s = 18, but r = 7; without a reduced skeleton, the optimization problem would typically be intractable.
Approach	The discrete penalty function has great impact on the generality and quality of the results.
Outcome	The skeleton was correctly embedded into 13 of these models (81% success).
Background	Some commercial packages use proprietary methods to assign default weights.
Outcome	These tests demonstrate the range of proportions that our method can tolerate: we have a well-proportioned human (Models 1–4, 8), large arms and tiny legs (6; in 10, this causes problems), and large legs and small arms (15; in 13, the small arms cause problems).
Background	Teichmann and Teller [1998] propose a spring-based method.
Approach	We considered adapting an approximate graph matching algorithm, like [Gold and Rangarajan 1996], which would work much faster and enable more complicated reduced skeletons.
Approach	Unlike the discrete case, we choose the α’s by hand because there are only four of them [Baran and Popović 2007a].
Background	Most of the work has been focused on human models, making use of human anatomy specifics, e.g. [Moccozet et al. 2004].
Outcome	We did not run timing tests on denser models because someone wishing to create real-time animation is likely to keep the triangle count low.
FutureWork	Finally, it would be nice to eliminate the assumption that the character must have a well-defined interior.
Background	Because of its simplicity and efficiency (and simple GPU implementation), and despite its quality shortcomings, linear blend skinning (LBS), also known as skeleton subspace deformation, remains the most popular method used in practice.
Approach	To ensure an objective evaluation, we use inputs that were not used during development.
FutureWork	We have several ideas for improving Pinocchio that we have not yet tried.
Approach	To speed up the process and conserve memory, if a partial embedding has a very high lower bound, it is rejected immediately and not inserted into the queue.
Challenge	Solving such a problem directly using continuous optimization is infeasible.
FutureWork	A better retargetting scheme could be used to make animations more physically plausible and prevent global self-intersections.
Outcome	Our prototype system, called Pinocchio, rigs the given character using our algorithm.
Approach	Equation (1) is a sparse linear system, and the left hand side matrix −∆ + H does not depend on i, the bone we are interested in.
Background	The anatomically appropriate skeleton generation by Wade [2000] ameliorates this problem by techniques such as identifying appendages and fitting appendage templates, but the overall topology of the resulting skeleton may still vary.
Approach	When k bones are equidistant from vertex j, heat contributions from all of them are used: p j is 1/k for all of them, and H jj = kc/d(j) 2 .
Background	For example, for the character in Figure 1 , ears may be mistaken for arms.
Approach	To help with optimization, the given skeleton can have a little extra information in the form of joint attributes: for example, joints that should be approximately symmetric should be marked as such; also some joints can be marked as “feet,” indicating that they should be placed near the bottom of the character.
Approach	Although we could make use of one of the various mesh editing techniques for the actual mesh deformation, we choose to focus on the standard linear blend skinning (LBS) method because of its widespread use.
Approach	Pinocchio then finds the optimal embedding of the skeleton into this graph with respect to a discrete penalty function.
Approach	It uses the discrete solution as a starting point for continuous optimization.
Approach	It is possible to speed up this method slightly by finding vertices that are unambiguously attached to a single bone and forcing their weight to 1.
Approach	Then we can take the equilibrium temperature at each vertex on the surface as the weight of bone i at that vertex.
Approach	• An A ∗ -like heuristic to accelerate the search for an optimal skeleton embedding over an exponential search space (Section 3.4).
Background	Modeling in 3D is becoming much easier than before.
Approach	We use the Nelder-Mead method [Nelder and Mead 1965] starting from random Γ’s.
Background	Botsch et al. [2005] show how to use a sparse Cholesky solver to compute the factorization for this kind of system.
Challenge	For example, a child should be able to model a unicorn, click the “Quadruped Gallop” button, and watch the unicorn start galloping.
FutureWork	The variety of types of hands makes this challenging (see, for example, Models 13, 5, 14, and 11 in Figure 9 ).
Approach	Lastly, the character must be proportioned roughly like the given skeleton.
Approach	At every step, it takes the best partial embedding from the queue, extends it in all possible ways with the next joint, and pushes the results back on the queue.
Challenge	We envision a system that eliminates this tedium to make animation more accessible for children, educators, researchers, and other non-expert animators.
Approach	This works because once Pinocchio knows where the endpoints of a bone chain are in V , it can compute the intermediate joints by taking the shortest path between the endpoints and splitting it in accordance with the proportions of the unreduced skeleton.
Outcome	Therefore, a novice user will be able to use the system, and more advanced users will be able to design new skeletons without having to learn new weights.
Outcome	We also believe that some of our techniques, such as finding LBS weights and using examples to learn the weights of a linear combination of penalty functions, can be useful in other contexts.
Approach	Then it processes these points in order and if a point is outside all previously added spheres, adds the sphere centered at that point whose radius is the distance to the surface.
Approach	Pinocchio therefore traverses the octree and for each cell, looks at a grid (of spacing τ ) of points on each face of the cell.
Approach	For the same reason, Pinocchio filters out the sampled points that are too close to the character surface (within 2τ ).
Approach	Embeddings that do not satisfy the constraints are simply not considered by the algorithm.
Approach	We found that τ = 0.003 provides a good compromise between accuracy and efficiency for our purposes.
Approach	For every character with a bad embedding, we manually tweak Γ until a good embedding is produced.
Challenge	However, such techniques are unsuitable for our problem because we only have a single mesh.
FutureWork	Combined with a system for motion synthesis [Arikan et al. 2003], this would allow users to begin interacting with their creations.
Outcome	• Degree 2 joints such as knees and elbows are often positioned incorrectly within a limb.
FutureWork	One approach would be to use a technique [Wang et al. 2007] that corrects LBS errors by using example meshes, which we could synthesize using slower, but more accurate deformation techniques.
Background	Recent exceptions include Motion Doodles [Thorne et al. 2004] as well as the work of Igarashi et al. on spatial keyframing [2005b] and as-rigid-as-possible shape manipulation [2005a].
Challenge	This can be formulated as an optimization problem: “compute the joint positions such that the resulting skeleton fits inside the character as nicely as possible and looks like the given skeleton as much as possible.
Approach	Repeating the process 10 times is usually sufficient for convergence.
Approach	For c ≈ 0.22, this method gives weights with similar transitions to those computed by finding the equilibrium over the volume.
Approach	The basis penalty functions assign a feature vector b(v) = (b 1 (v), . . . , b k (v)) to each example embedding v.
Background	An earlier variant of our algorithm did this, but the improvement was negligible, and this introduced occasional artifacts.
Outcome	Characters with extremely thin limbs often fail because the the graph we extract is disconnected.
Outcome	According to our tests, if the basis functions are carefully chosen, the overall penalty function generalizes well to both new characters and new skeletons.
Outcome	Our prototype implementation, called Pinocchio, typically takes under a minute to rig a character on a modern midrange PC.
Approach	Joints of the skeleton may be marked as “feet,” in which case they should be close to the bottom of the character.
Background	In their paper, Katz and Tal [2003] describe a surface partitioning algorithm and suggest skeleton extraction as an application.
Approach	To this end, we want Γ to distinguish between the best “bad” embedding and the best “good” embedding, as illustrated in Figure 6 .
Approach	As a result, all of the tolerances are relative to the size of the character.
Outcome	For Models 7, 10 and 13, a hint for a single joint was sufficient to produce a good embedding.
Approach	We start with a cube [0, 1] k , pick random normalized Γ’s, and run Nelder-Mead from each of them.
Approach	For the continuous optimization, we represent the embedding of the skeleton as an s-tuple of joint positions (q 1 , . . . , q s ) in R 3 .
Approach	In our case, however, we do not need to classify embeddings, but rather find a Γ such that the embedding with the lowest penalty f (v) = Γ T b(v) is likely to be good.
Approach	Pinocchio intersperses a line search in the gradient direction with line searches in the gradient direction projected onto individual bones.
Outcome	Embedding refinement takes about 1.2 seconds for all of these models, and the discrete optimization consumes the rest of the embedding time.
Background	The missing portion is the rigging: motion transfer has been addressed in prior work [Gleicher 2001].
Approach	The character must be given in approximately the same orientation and pose as the skeleton.
Background	The Motion Doodles system has the ability to infer the articulation of a 2D character, but their approach relies on very strong assumptions about how the character is presented.
Approach	We impose the 120 ◦ condition because we do not want the “noisy” parts of the medial surface—we want the points where skeleton joints are likely to lie.
Approach	It uses the precomputed distance field to determine whether a line segment is entirely contained in the character volume.
Background	These approaches focus on simplifying animation control, rather than simplifying the definition of the articulation of the character.
Approach	It then constructs the distance field from the top down, starting with a single octree cell and splitting a cell until the exact distance is within a tolerance τ of the interpolated distance.
Approach	To create our training set of embeddings, we pick a training set of characters, manually choose Γ, and use it to construct skeleton embeddings of the characters.
Approach	Our penalty function (f ) can be expressed as the sum of independent functions of bone chain endpoints (f i ’s) and a term (f D ) that incorporates the dependence between different joint positions.
Approach	The latter condition is equivalent to the requirement that additional edges must be in the Gabriel graph of the sphere centers (see e.g. [Jaromczyk and Toussaint 1992]).
Approach	• Use of Laplace’s diffusion equation to generate weights for attaching mesh vertices to the skeleton using linear blend skinning (Section 4).
Approach	Pinocchio uses c = 1 (corresponding to anisotropic heat diffusion) because the results look more natural.
Approach	Therefore, the discrete skeleton embedding problem is to find the embedding of the reduced skeleton into G, represented by an rtuple v = (v 1 , . . . , v r ) of vertices in V , which minimizes a penalty function f (v) that is designed to penalize differences in the embedded skeleton from the given skeleton.
Approach	The precise condition Pinocchio uses is that the distance from any point of the edge to the surface must be at least half of the radius of the smaller sphere, and the closest sphere centers to the midpoint of the edge must be the edge endpoints.
Approach	However, multiple correct skeleton embeddings are necessary for our problem in cases such as the hand joint being embedded into different fingers.
Background	A few approaches to the skeleton extraction problem are representative.
Approach	The character mesh must be the boundary of a connected volume.
Approach	Instead, we use the analogy to heat equilibrium to find the weights.
Outcome	Table 1 shows the fastest and slowest timings of Pinocchio rigging the 16 models discussed in Section 5.1 on a 1.73 MHz Intel Core Duo with 1GB of RAM.
Approach	If v j is the position of vertex j, T i is the transformation of the i th bone, and w j i is the weight of the i th bone for vertex j, LBS gives the position of the transformed vertex j as P i w j i T i (v j ).
Background	Liu et al. [2003] use repulsive force fields to find a skeleton.
Approach	Recalling that the total penalty of an embedding v is Γ T b(v), we can think of the maximum margin Γ as the one that best distinguishes between the best “bad” embedding and the worst “good” embedding in the training set.
Challenge	For example, the legs of the character in Figure 1 would be too short if a skeleton extraction algorithm were used.
Approach	The key difference is that structured classification requires an explicit loss function (in our case, the knowledge of the quality of all possible skeleton embeddings for each character in the training set), whereas our approach only makes use of the loss function on the training labels and allows for the possibility of multiple correct labels.
Approach	Before any other computation, Pinocchio rescales the character to fit inside an axis-aligned unit cube.
Approach	Although a scheme that assigns bone weights purely based on proximity to bones can be made to satisfy these properties, such schemes will often fail because they ignore the character’s geometry: for example, part of the torso may become attached to an arm.
Approach	The resulting skeleton embedding should have the general shape we are looking for, but typically, it will not fit nicely inside the character.
Approach	Pinocchio takes the optimal embedding of the reduced skeleton found by discrete optimization and reinserts the degree-two joints by splitting the shortest paths in G in proportion to the given skeleton.
Approach	Instead we found it easier to design penalties independently and then rely on learning a proper weighting for a global penalty that combines each term.
Approach	For example, our biped skeleton has only two joints of degree greater than two, so after Pinocchio has embedded them, the lower bound estimate includes f i terms for all of the bone chains.
Approach	If our goal were to automatically classify new embeddings into “good” and “bad” ones, we could use a support vector machine to learn a maximum margin linear classifier.
Approach	Because only negative distances (i.e. from points inside the character) are important, Pinocchio does not split cells that are guaranteed not to intersect the character’s interior.
Approach	To ensure an honest evaluation and avoid overfitting, we tested our algorithm on 16 characters that we did not see or use during development.
Background	Unfortunately, at present, these methods are unsuitable for real-time animation of even moderate size meshes.
Approach	Designing a penalty function that satisfies all of these requirements simultaneously is difficult.
Background	See Burges [1998] for a much more complete tutorial.
Approach	We describe the attributes Pinocchio uses in a supplemental document[Baran and Popović 2007a].
Approach	These attributes are specific to the skeleton but are independent of the character shape and do not reduce the generality of the skeletons.
Approach	The character and the embedded skeleton are disconnected until skin attachment specifies how to apply deformations of the skeleton to the character mesh.
Approach	This method could also be useful in existing 3D packages.
Approach	In such cases it is possible for the user to provide manual hints in the form of constraints for reduced skeleton joints.
Approach	Skeleton embedding computes the joint positions of the skeleton inside the character by minimizing a penalty function.
Approach	Pinocchio adds an edge between two sphere centers if the spheres intersect.
Approach	Finally, to avoid folding artifacts, the width of a transition between two bones meeting at a joint should be roughly proportional to the distance from the joint to the surface.
FutureWork	A more involved approach would be automatically building a tetrahedral mesh around the embedded skeleton and applying the dynamic deformation method of Capell et al. [2002].
Approach	Pinocchio therefore discretizes the problem by constructing a graph whose vertices represent potential joint positions and whose edges are potential bone segments.
Approach	Although this process of finding the weights is labor-intensive, it only needs to be done once.
Approach	Solving for heat equilibrium over a volume would require tessellating the volume and would be slow.
Outcome	We have presented the first method for automatically rigging an unfamiliar character for skeletal animation.
Approach	The reduced skeleton thus has only r joints.
Approach	The weights we learned resulted in good embeddings for all of the characters in our training set; we could not accomplish this by manually tuning the weights.
Approach	It constructs a kd-tree to evaluate the exact signed distance to the surface from an arbitrary point.
Approach	To reduce the degrees of freedom, for the discrete embedding, Pinocchio works with a reduced skeleton, in which all bone chains have been merged (all degree two joints, such as knees, eliminated), as shown in Figure 5 .
Approach	We determine the weights Γ = (γ 1 , . . . , γ k ) semi-automatically via a new maximum margin approach inspired by support vector machines.
Challenge	For example, the user may have motion data for a quadruped skeleton, but for a complicated quadruped character, the extracted skeleton is likely to have a different topology.
Challenge	” For a skeleton with s joints (by “joints,” we mean vertices of the skeleton tree, including leaves), this is a 3s-dimensional problem with a complicated objective function.
Approach	In its simplest form, a support vector machine finds the hyperplane that separates the p i ’s from the q i ’s and is as far away from them as possible.
Outcome	It then transfers a motion to the character using online motion retargetting [Choi and Ko 2000] to eliminate footskate by constraining the feet trajectories of the character to the feet trajectories of the given motion.
Challenge	To our knowledge, the problem of finding bone weights for LBS from a single mesh and a skeleton has not been sufficiently addressed in the literature.
Outcome	Because a single skeleton can be used with a wide range of characters, our method, in conjunction with a library of motions for a few skeletons, enables a user-friendly animation system for novices and children.
FutureWork	Discretization could be improved by packing ellipsoids instead of spheres.
Outcome	Reducing τ , however, hurts performance.
Approach	” For example, the neck and left shoulder spheres of the character in Figure 3 are disjoint, but there should still be an edge between them.
Challenge	For the purpose of automatically animating a character, however, skeleton embedding is much more suitable than extraction.
Approach	Suppose that for a single character, we have several example embeddings, each marked “good” or “bad”.
Outcome	The quality problems of our attachment are a combination of the deficiencies of our automated weights generation as well as those inherent in LBS.
Approach	The medial surface is the set of C 1 discontinuities of the distance field.
Challenge	Instead, we must infer articulation by using the given skeleton as an encoding of the likely modes of deformation, not just as an animation control structure.
Approach	We require that the order in which the joints are given respects the parent relationship, i.e. p R (i) < i.
Approach	Given a static character mesh and a generic skeleton, our method adapts the skeleton to the character and attaches it to the surface, allowing skeletal motion data to animate the character.
Background	For example, Autodesk Maya 7 assigns weights based solely on the vertex proximity to the bone, ignoring the mesh structure, which results in serious artifacts when the mesh intersects the Voronoi diagram faces between logically distant bones.
Approach	In fact, this step typically takes less than 1% of the time of the entire algorithm.
Outcome	Pinocchio is single-threaded so only one core was used.
Approach	This possibility of multiple correct skeleton embeddings prevented us from formulating our margin maximization problem as a convex optimization problem.
Approach	The graph is constructed by packing spheres centered on the approximate medial surface into the character and by connecting sphere centers with graph edges.
Outcome	Our algorithm computed a good rig for all but 3 of these characters.
Approach	Also, smaller bones are likely to be incorrectly oriented because they were not important enough to influence the discrete optimization.
Challenge	So although we could use an existing skeleton extraction algorithm and embed our skeleton into the extracted one, the results would likely be undesirable.
Approach	The continuous penalty function g that Pinocchio tries to minimize is the sum of penalty functions over the bones plus an asymmetry penalty: where p S is the parent function for the unreduced skeleton (analogous to p R ).
Outcome	Pinocchio was even able to transfer a biped walk onto a human hand, a cat on its hind legs, and a donut.
Approach	We therefore wish to maximize the optimization margin (subject to Γ = 1), which we define as: n m min Γ T q i − min Γ T p i .
Approach	To this end, once the development was complete, we tested Pinocchio on 16 biped Cosmic Blobs models that we had not previously tried.
FutureWork	Beyond Pinocchio’s current capabilities, an interesting problem is dealing with hand animation to give animated characters the ability to grasp objects, type, or speak sign language.
Approach	For this, we designed a maximum-margin supervised learning method to combine a set of hand-constructed penalty functions.
Challenge	Bringing these static shapes to life, however, is still not easy.
Approach	Suppose we treat the character volume as an insulated heat-conducting body and force the temperature of bone i to be 1 while keeping the temperature of all of the other bones at 0.
Approach	We would also like to add edges between spheres that do not intersect if that edge is well inside the surface and if that edge is “essential.
Approach	We simplify the problem by making the following assumptions.
Outcome	We do not know of a reliable way to identify the right locations for them: on some characters they are thicker than the rest of the limb, and on others they are thinner.
Approach	Second, for the results to look good, the weights need to vary smoothly along the surface.
Approach	A good embedding should have the proportions, bone orientations, and size similar to the given skeleton.
Approach	Our algorithm consists of two main steps: skeleton embedding and skin attachment.
Approach	Pinocchio uses k = 9 basis penalty functions constructed by hand.
Challenge	A key design challenge is constructing a penalty function that penalizes undesirable embeddings and generalizes well to new characters.
FutureWork	Combining retargetting with joint limits should eliminate some artifacts in the motion.
Approach	Examining the optimization results and the extremal embeddings also helped us design better basis penalty functions.
Outcome	A common class of problems is caused by Pinocchio being oblivious to the material out of which the character is made: the animation of both a dress and a knight’s armor has an unrealistic, rubbery quality.
Approach	Pinocchio uses the TAUCS [Toledo 2003] library for this computation.
Background	User-friendly systems such as Teddy [Igarashi et al. 1999] and Cosmic Blobs ( http://www.cosmicblobs.com/) have made the creation of 3D characters accessible to novices and children.
Approach	The first full embedding extracted is guaranteed to be the optimal one.
Approach	Any continuous optimization technique [Gill et al. 1989] should produce good results.
Approach	The discretization stage constructs a geometric graph into which Pinocchio needs to embed the given skeleton in an optimal way.
Challenge	We present a method for animating characters automatically.
Background	The technique in Wade [2000] is most similar to our own: like us, they approximate the medial surface by finding discontinuities in the distance field, but they use it to construct a skeleton tree.
Approach	Because of this lower bound estimate, the order in which joints are embedded is very important to the performance of the optimization algorithm.
Approach	Pinocchio uses a gradient descent method that takes advantage of the fact that there are relatively few interactions.
Approach	For training, we used 62 different characters (Cosmic Blobs models, free models from the web, scanned models, and Teddy models), and Γ was stable with about 400 embeddings.
Background	Teichmann and Teller [1998] extract a skeleton by simplifying the Voronoi skeleton with a small amount of user assistance.
Challenge	The tedium of this process makes simple character animation more difficult than it could be.
Approach	Each g i penalizes bones that do not fit inside the surface nicely, bones that are too short, and bones that are oriented differently from the given skeleton: g i = α S g i S + α L g i L + α O g i O .
Background	Another advantage of embedding over extraction is that the given skeleton provides information about the expected structure of the character, which may be difficult to obtain from just the geometry.
Approach	For example, such a hint might be that the left hand of the skeleton should be embedded at a particular vertex in G (or at one of several vertices).
Approach	The dependence between joints that have not been embedded can be ignored to obtain a lower bound on f .
Approach	They penalize short bones, improper orientation between joints, length differences in bones marked symmetric, bone chains sharing vertices, feet away from the bottom, zero-length bone chains, improper orientation of bones, degree-one joints not embedded at extreme vertices, and joints far along bone-chains but close in the graph [Baran and Popović 2007a].
Outcome	Although most of our tests were done with the biped skeleton, we have also used other skeletons for other characters ( Figure 10 ).
FutureWork	Although this is more difficult, we believe it would greatly reduce the size of the graph, resulting in faster and higher quality discrete embeddings.
Approach	More precisely, if Γ is a k-dimensional vector with Γ = 1, the classification margin of the best hyperplane normal to Γ is 1 2 ` min n i=1 Γ T q i − max m i=1 Γ T p i  ́ .
Background	Most real-time skinning work, e.g. [Kry et al. 2002; Wang et al. 2007], has focused on improving on LBS by inferring the character articulation from multiple example meshes.
FutureWork	Automatically rigging characters for facial animation is even more difficult, but a solution requiring a small amount of user assistance may succeed.
Approach	In other words, the largest spheres are added first, and no sphere contains the center of another sphere ( Figure 3 ).
Challenge	This is challenging because the graph must have few vertices and edges, and yet capture all potential bone paths within the character.
Approach	It then computes the gradient vectors for the cells adjacent to each grid point—if the angle between two of them is 120 ◦ or greater, it adds the point to the medial surface sample.
Approach	However, an approximately optimal Γ is acceptable, and the search space dimension is sufficiently low (9 in our case) that it is feasible to use a continuous optimization method.
Approach	Embedding refinement corrects these problems by minimizing a new continuous penalty function ( Figure 7 ).
Background	Wade discusses a similar condition in Chapter 4 of his thesis [2000].
Approach	Therefore, for simplicity, Pinocchio solves for equilibrium over the surface only, but at some vertices, it adds the heat transferred from the nearest bone.
Approach	Referring to the joints by their indices (starting with the root at index 1), we define the parent function p R on the reduced skeleton, such that p R (i) (for 1 < i ≤ r) is the index of the parent of joint i.
Background	Skeleton embedding resizes and positions the given skeleton to fit inside the character.
Approach	High degree joints should be embedded first because they result in more terms in the rightmost sum of the lower bound, leading to a more accurate lower bound.
Approach	Our design decisions relied on three criteria, which we also used to evaluate our system:
Background	For segmenting and animating simple 3D models of characters and inanimate objects, Anderson et al. [2000] fit voxel-based volumetric templates to the data.
Outcome	Also, because of our volume-based approach, once the distance field has been computed, subsequent discretization and embedding steps do not depend on the given mesh size.
Approach	To support this functionality, we need a method (as shown in Figure 1 ) that takes a character, a skeleton, and a motion of that skeleton as input, and outputs the moving character.
Approach	Let p 1 , . . . , p m be the k-dimensional feature vectors of the good embeddings and let q 1 , . . . , q n be the feature vectors of the bad embeddings.
Outcome	We have shown that using this method, Pinocchio can animate a wide range of characters.
Outcome	For other characters we tested, skeletons were almost always correctly embedded into well-proportioned characters whose pose matched the given skeleton.
Approach	The attachment problem is finding bone weights w i for the vertices—how much each bone transform affects each vertex.
Approach	We manually classify the embeddings that we have not previously seen, augment our training set with them, and repeat the process.

Outcome	This is probably due to the inherent coupling of stretch and bending deformation components in this model.
Outcome	The discontinuity of stable configurations is also the cause of flickering and twitches in some of our examples.
Approach	For each different cloth sample, we have created a simulated replica with the same mass, uniformly distributed, and the same 100mm square geometry, discretized with a regular 25 × 25-node mesh, connected either with springs or with quadrilaterals split into triangles, depending on the model.
Outcome	The maximum stretch stiffness for #4 is 250 times higher than for #12, while #14 is 10 times stiffer in shear than any other fabric.
Approach	To isolate stretching we perform a uni-axial tension experiment, with forces applied to two long bar clips attached to either side of the cloth (see Figure 4 , 2nd column).
Outcome	The Springs model exhibits the worst fitting quality in shearing force-displacement curves, and the highest fitting residual for bending.
Outcome	While overall force-displacement behavior is nicely matched, the actual folding shapes of simulated cloth may deviate largely from the captured cloth, because even a small change in material properties may lead to distant stable configurations in the L 2 sense.
Background	Furthermore, most of these models define separable scalar stress components as linear functions of individual scalar strain metrics.
Background	This approach appeals through a simple and inexpensive acquisition process, but it is not possible to accurately separate internal (i.e. material-specific) and external (e.g. friction, air drag) parameters.
Approach	However, stressstrain curves are potentially nonlinear functions.
Approach	In each measurement sequence, a different set of nodes is fixed to rigid bodies representing the clips.
Outcome	We conjecture that missing cross-modal stiffening may also be, to a large extent, the reason for stiffness underestimation in the corner pulling test for the Soft Constraints and St. VK models.
Approach	We terminate the outer loop (and hence the overall optimization) when the residual is reduced by less than 1% between two consecutive iterations.
Approach	The raw data for a single deformation consists of 20 to 200 individual measurement frames, with a set of camera images and simultaneous force sensor readings for each frame.
Approach	For stretch tests, the objective function is based only on clip forces, i.e., μ = 0, λ = 1, while for bend tests it is based only on cloth positions (since there are no measured forces), i.e., μ = 1, λ = 0.
Approach	Forces are applied to the clips by fine wire cords that are pulled to defined displacements by eight linear actuators, and the tension in the cords is monitored by miniature load cells located at the actuator ends (see Figure 2).
Background	Grinspun et al. [GHDS03] and Bridson et al. [BMF03] discovered concurrently the appropriate weighting of the angle change in order to model homogeneous bending on irregular triangle meshes with a homogeneous stiffness.
Approach	However, we largely alleviate these issues with the design of the five isolated deformation measurements described in Section 3.2, which allow us to separately fit stiffness curves for the six deformation components described in Section 4.1, following an incremental parameter fitting procedure.
Approach	The formulation of A, on the other hand, requires solving |k| linear systems of type ∂F n y = b, which ∂x n we did using the conjugate gradient method.
Approach	Next, we describe in detail the strain metrics for the individual deformation components in the selected models.
Approach	The vision system also finds the cords in the images and triangulates a 3D line for each cord.
Approach	This prevents stretching of the cord, or other factors affecting the distance between the clip and the actuator, from affecting displacement accuracy.
Approach	To isolate bending deformation we slowly push the flat cloth sample off the edge of a table and measure its shape as it bends under its own weight ( Figure 4 , 4th column), for both weft and warp directions.
Background	Most elastic cloth models separate membrane (i.e., stretch and shear) and bending deformation energies.
Background	At the extreme, the elastic range can be replaced altogether by inextensibil∗ ity constraints [GHF 07, EB08].
Background	Progress in cloth simulation for computer animation and apparel design has led to a multitude of deformation models, each with its own way of relating geometry, deformation, and forces.
Approach	Our vision system recovers the space-time geometry of the deforming cloth and attached rigid clips, as well as the directions of the forces applied to the clips.
Approach	In both cases, deformation energy density can be described by the product of strain (ε) and stress (σ), i.e., W = 2 1 σ · ε.
Approach	First, we evaluate the strain histogram for the corresponding measurement sequence, and we determine maximum and minimum strains after removing outliers.
Approach	We observed that, in situations of near-homogeneous shear, the clip-parallel forces are dominated by shear, while clip-orthogonal forces are dominated by stretch.
Approach	We do this by solving quasi-static simulations until convergence on all captured frames, starting always from the measured configuration x n and using the measured clip positions x c as boundary conditions.
Approach	To fit each stiffness curve k i (ε i ), we iteratively subdivide the Hermite spline adding more control points until the residual error function (6) is reduced by less than 1% or a speci- fied maximum number of points, usually 4 or 5, is reached.
Background	But while capturing can provide accurate deformation data, parameter fitting remains very difficult without explicit control over boundary conditions, in particular loading forces.
Approach	Second, using known stretch stiffness curves, we fit the shear stiffness k s,uv (ε s,uv ), for the shear sequence.
Approach	With our separation of weft-, warpand diagonal-bending to capture anisotropy, the bending models in Discrete Shells and by Baraff and Witkin [BW98] are equivalent up to a stiffness scale factor.
Approach	To reduce the risk of falling into local minima during parameter fits, we have designed deformation sequences that produce near-isolated strains, and allow estimating stretch, shear and bending properties in a separate and incremental manner.
Background	Continuum-based approaches can accurately describe the directional variation of material properties, but regardless of the cloth model, a single set of material coefficients for the entire deformation range is not sufficient to faithfully capture the nonlinear response of typical fabrics.
Background	Today’s cloth simulators for animation, visual effects, games, and apparel design can mimic real cloth to a high degree of fidelity.
Challenge	As simulators improve, differences between these models become more important, but it is difficult to choose a model and a set of parameters to match a given real material simply by looking at simulation results.
Approach	Once the parameter values k(i + 1) are refined, we bring the cloth to a static equilibrium position, x n (i + 1).
Background	The multi-view stereo algorithm of Bradley et al. [BBH08] is among the most accurate available according to the Middlebury evaluation benchmark.
Outcome	This paper provides measurement and fitting methods that allow nonlinear models to be fit to the observed deformation of a particular cloth sample.
Approach	In principle all parameters of a cloth model can be fit to a sufficiently rich single deformation sequence, but this can result in a problem fraught with local minima.
Challenge	Considering the number of existing models, it is very hard to clearly identify or even quantify the advantages of individual approaches.
Approach	The generic force density model F = −σ ε defined above assumes a linear stress-strain curve σ = kε.
Approach	To better account for crossinfluence of shear and bending, we use their estimated values as initial guesses and run another fitting iteration.
Outcome	In the vision system, the camera calibration accuracy is within 0.3 pixels, or about 0.075 millimeters at the distance of the cloth.
Challenge	Our goal is to define a platform for comparing cloth models to the observed behavior of real cloth.
Approach	Our measurement system applies forces to a sample of cloth using actuators and force sensors that let us know the complete applied force, in 3D.
Approach	We tested our system on four fabric samples, including a knit and the three common weave patterns (plain weave, twill, and satin), and three fiber types (cotton, wool, and synthetic): cotton satin (#4), rayon/spandex knit (#12), cotton denim (#14), and wool/cotton blend (#18).
Background	While the KES covers a comprehensive set of experiments, other devices have been used in more specific context such as the Picture Frame test [ Cul79 ] for measuring shear properties and the Cantilever test [ CPGE90 ] for measuring bending properties (see also Pabst et al. [ PKST08 ]).
Outcome	It is difficult to quantify the accuracy of the temporal flow computation, but it can be visualized by compositing the reconstructed deformation on top of the input images (see accompanying video).
Approach	We do this by solving an optimization problem, leveraging that the cloth is at static equilibrium at the measured configurations.
Approach	We also capture two sequences with more complex deformation ( Figure 5 ) for validation after parameter fitting.
Outcome	To our knowledge, our method presents the first system able to record such extensive information about the behavior of a cloth sample.
Background	To this end, previous work [BHW94,EWS96, VMTF09 ] has mainly relied on the Kawabata Evaluation System (KES) [Kaw80 ] and corresponding machinery.
Approach	We consider that a piece of cloth has converged to equilibrium when F n < 10μN.
Approach	Given a per-triangle mapping function w from the undeformed 2D configuration (x a,0 , x b,0 , x c,0 ) to the deformed        3D configuration (x a , x b , x c ), the deformation gradient can be computed as −1 (w u w v ) = (x b − x a x c − x a ) x b,0 − x a,0 x c,0 − x a,0 .
Approach	In our test examples, this number was always below 10, and we solved the linear systems using LDL factorization.
Approach	If the inherent texture of the cloth is not sufficiently random, it is printed with a wavelet noise pat∗ tern [ AIH 08 ] to provide texture that can be used for stereo reconstruction and tracking.
Approach	The resulting nonlinear force density function, F i = −k i (ε i )ε i ε i yields a conservative force field, but note that the elastic energy density can no longer be defined simply as 1 2 kε 2 , and would now require the integration of the stiffness function.
Approach	Although only Volino et al. [VMTF09] propose a general nonlinear stress-strain relationship (though many systems use some form of strain limiting instead), the same construction can easily be built on any of our selected models.
Approach	We solve the optimization in an iterative manner, refining k and x n separately on two nested loops.
Approach	Due to equilibrium, the net force on the clips, produced by cord forces, gravity, and forces from fixed cloth nodes, must be zero.
Approach	In order to achieve stable fits, we have designed an incremental optimization procedure that fits model parameters a few at a time using the isolated deformations described in Section 3.2.
Approach	The cloth sample starts flat on a table and we capture the rest pose without applied tensile forces.
Approach	The test repeats three times, retracing the same loop each time after the initial extension from rest.
Outcome	Sample #12 is nearly linear in the test deformation range, while all other three fabrics exhibit nonlinearity.
Approach	We typically deform the cloth by moving the actuators at 0.5 mm/sec and capture a frame every 2 seconds.
Approach	Tests are performed on 100 mm square cloth samples using two kinds of plastic clips: small, rounded clips that grab a localized area, and long clips that grip one whole side of the sample.
Outcome	The behavior of sample #12, the most linear fabric, is predicted well in all cases, as seen in the force-displacement plots, the buckling behavior in corner pulling, and the (lower) effective shear stiffness of the sheet when allowed to buckle in the complex shear test.
Approach	We indicate with x n and F  ̃ c , respectively, the known cloth node positions and clip forces, measured as described in Section 3.
Approach	Because linear models fit the data poorly, we used the nonlinear model in all cases, resulting in a consistent set of models, parameterized by the number of spline control points, which reduces to the widely used linear models when each spline has a single control point.
Approach	Thus we have a total of five measurements per cloth sample that will be used for parameter fitting (two stretch, one shear, and two bending).
Approach	The resulting deformation is tracked by a stereo computer vision system that captures the complete deformation, also in 3D.
Approach	Weftand warp-stretch are measured through a subtle modification of the Green-Lagrange strain tensor, defining terms that are quadratic in positions instead of quartic:
Approach	Given a set of captured static deformation frames, we wish to know the (nonlinear) stress-strain curves for the deformation components of a cloth model, such that a simulated cloth matches known positions and forces as well as possible.
Approach	Shearing is captured using an approximate picture-frame experiment [Cul79], where four long clips fix the cloth boundaries and shear stress is applied as the cords pull on opposite corners ( Figure 4 , 3rd column).
Approach	For the bending measurement sequences (see Figure 4 ), we fix all cloth nodes above the edge of the table.
Approach	In an outer loop, we refine k by local minimization of the error function and, in an inner loop, we recompute x n to satisfy the equilibrium constraint.
Approach	The raw repeatability of our force sensors is about 3 millinewtons (RMS).
Outcome	The Soft Constraints and St. VK models produce results with very similar quality, which is expected as the models present only subtle differences as described in Section 4.1.
FutureWork	In order to eliminate these problems, we would like to investigate alternative ways of controlling bending deformations in the future.
Approach	In order to measure the complete answer that a simulator should predict, we need to determine the interaction between the rigid clips, the cloth, and the cords.
Background	These parameters are fitted to experimentally acquired data obtained from planar and bending deformations.
Approach	To avoid drift, we subsequently match each frame independently back to the rest pose frame using the approach described in Bradley et al. [BHPS10].
Outcome	To illustrate the fitting residuals more quantitatively, we show a force-displacement plot comparing a summary of the measured forces to the predictions of the fitted model and a vector-field plot illustrating the position error over the geometry of the fitted mesh (see caption for details).
Approach	As a result, we obtain a linear expression that relates node positions to parameter values:
Approach	Unlike standard textile testing, our system measures complex 3D deformations of a sheet of cloth, not just one-dimensional force–displacement curves, so it works under a wider range of deformation conditions.
Approach	In this optimization problem, we use the measured clip positions, x c , as known boundary conditions.
Approach	Note that not all force models define the quantities below explicitly as strains, as they often rely on the resolution of the discretization, or they differ simply by scale factors that can be embedded in the stiffness k i .
Approach	The location and orientation of the cords attached to the clips (which reveal the direction of the applied force) are also tracked.
Background	Since the first physics-based approach by Terzopoulos et al. [ TPBF87 ] a multitude of different cloth models have emerged, ranging from simple mass-spring systems [ Pro95 , CK02 ] over general particle systems [ BHW94 , BW98 , EWS96 ] to elaborate models derived from continuum mechanics [ EKS03 , VMTF09 ] or even the discrete yarn structure [ KJM08 ].
Approach	Although some of the models we look at are discrete in nature, we will use the convenient terms stress and strain to describe them.
Approach	The area of cloth occluded by the clips is used to automatically determine which cloth vertices are clamped by each clip and will therefore be constrained to it in the simulator.
Challenge	The key question of how well a given model describes a particular piece of cloth is answered by fitting the model to the measurement data: adjusting its parameters to minimize the difference between the model’s predictions and the measured behavior, both in position and force.
Background	Grinspun et al. define h 0 as a third of the average of the heights of the two triangles incident to the edge.
Approach	In that case, the energy density of each deformation component i can be written as W i = 1 2 k i ε 2 i , where k i ε i = σ i and k i is the stiffness coefficient corresponding to the deformation component ε i .
Outcome	We indeed identified stretch stiffening in the shearing deformations, therefore we chose clip-parallel forces as objective function to minimize the effect of stretch errors on shear optimization.
Challenge	But to fully exploit their capabilities, the constitutive models for cloth deformation must be tuned with great care.
Approach	Back-projecting onto the reconstructed geometry for the next frame gives new position estimates for the cloth vertices.
Challenge	Our goal is to study the fidelity of constitutive models of cloth—models that predict the forces produced in the cloth in response to deformations.
Outcome	Nevertheless, the overall deformations in complex shearing fit reasonably well.
Outcome	The force-displacement plots of the real cloth samples, shown in the supplementary document, indicate very similar behavior between fitting and test samples for #12 and #14, and a larger disparity for #4 and #18.
Outcome	The contributions of this paper are, first, a new, general system for observing cloth properties that measures more complete data than previous work in cloth capture or textile testing, and second, a new method for fitting parametric models to this type of data.
Approach	We use continuum strain definitions in all cases to fit them in a common formulation that allows us to easily compare the models.
Approach	The largest source of error in measuring the force indirectly through the cord is the internal friction in the cord as it bends around the pulleys, which introduces an artificial hysteresis of about 0.1 N.
Approach	First, we fit in parallel the weft-stretch stiffness curve, k s,u (ε s,u ), for the weft-stretch sequence, and the warp-stretch stiffness, k s,v (ε s,v ), for the warp-stretch sequence.
Approach	A few user scribbles on an input image indicate which cords are affecting each clip.
Approach	By estimating model parameters under a sequence of deformations of increasing complexity, we alleviate problems with convergence in the presence of abundant local minima.
Approach	The nonlinearity of cloth deformation, together with the complex interplay of various deformation components in the resulting forces and positions, make the optimization problem above extremely complex in the general case, prone to falling in local minima and sensitive to initialization values.
Approach	Each fabric was tested with seven deformations (see Section 3.2): for fitting, stretch in X and Y, simple shear, and bending in X and Y; and for evaluation, complex shearing and corner pulling.
Approach	The process is repeated three times, in both weft and warp directions separately.
Approach	However, unlike standard textile evaluation practices [Kaw80], and thanks to our full 3D deformation capture solution, we relax the requirement of uniform strains.
Approach	The quasi-static simulations involve linear-system solves with the cloth stiffness matrix ∂F n .
Outcome	For this reason, the traditional L 2 metric is not appropriate for evaluating error in this case.
Approach	The cloth is slowly stretched until a maximum force is reached and then slowly released back.
Approach	The optimization problem contains two unknowns: the parameter vector k and cloth node positions x n .
Background	One or two forces are measured to quantify the cloth’s resistance to deformation, and the resulting forcedisplacement curves are valuable in studying the differences between materials.
Outcome	Our measurement setup offers very accurate control over membrane deformations, but the bending tests require manual intervention and are thus less precise.
FutureWork	An extension to the nonlinear model of Wang et al. [WRO11] could help alleviate these problems.
Approach	We compute the per-frame geometry using a state-ofthe-art stereo reconstruction technique [ BBH08 ], which was specifically tailored for reconstructing cloth geome∗ try [ BPS 08 ].
Approach	All deformation components are modeled based on springs, with weft and warp ring-1 springs for stretch, and diagonal ring-1 springs for shear.
Background	The force density due to each ε i follows as F i = − W i = −σ i ε i = −k i ε i ε i .
Approach	We also concatenate in a vector k the (unknown) stiffness values at the control points of the nonlinear stress-strain curves for the deformation components of the cloth.
Outcome	Visually, the mismatch is more apparent in the complex shear test, where models with underestimated stiffness exhibit wider folds than the real fabrics.
Background	Closer to our work is the recent approach of Wang et al. [WRO11], who propose a data-driven piecewise linear elastic cloth model comprising 39 material parameters.
Background	Cloth simulation has a comparatively long history in computer graphics.
Background	Bi-phasic models, typically implemented as strain limiting methods [Pro95, BFA02, Mül08, TPS09, WOR10], improve on this by splitting the material behavior into an initial, weakly elastic range and a stiff, quasi-inextensible limit.
Outcome	The fitting residual is larger for stiffer fabrics, and the nonlinear orthotropic model variants fit anisotropic fabrics best, as expected, while linear and/or isotropic variants reach a reasonable compromise but are not always able to remain inside the hysteresis band.
Approach	Same as for membrane deformation, strain is measured as the relative change of edge length (1).
Approach	The set of deformations to measure is motivated by the goals of the parameter fitting stage (Section 5): to fit model parameters for stretch, shear and bending that best describe the cloth, and to validate the parameter fits by comparing against other measurements.
Outcome	The data from our experiments shows some of the limitations of current models.
Approach	Then, the computation of model parameters based on the minimization of position and force errors subject to the static equilibrium condition can be formulated as the following nonlinear constrained least-squares problem: k = arg min μ x n (k) − x n 2 + λ F c (x n , k) − F  ̃ c 2 ,
Approach	Since the pieces of cloth are homogeneous, we use a single curve for each deformation component for all frames and all cloth elements.
Outcome	For shearing, the fitting force residual is larger for #14, the stiffest fabric.
Outcome	The measurement shows the typical behavior of a woven fabric: a nonlinear curve with increasing stiffness for higher strain, and large hysteresis.
Approach	The deformation is measured based on weft and warp ring-2 springs for weftand warp-bend, and diagonal ring-2 springs for diagonal-bend.
Outcome	For stretching, all three cloth models fit nicely to the average of the hysteresis bands, even in highly nonlinear cases.
Approach	To represent inter-frame correspondence, we use optical flow to obtain a single triangle mesh that deforms over time, akin to the human face tracking method of Bradley et al. [BHPS10].
Approach	Specifically, we minimize the weighted error of cloth positions and clip forces over a sequence of measurement frames, subject to the constraint of static equilibrium on all frames.
Outcome	Having deformation and force information makes our data well suited to model validation—the experiment measures the complete answer that should be predicted by a cloth simulator.
Background	Then, in the diagonalized StVK, each membrane stress component depends only on its corresponding strain component, σ s,i (ε s,i ).
Approach	We fit all the models in four variants: linear (constant stiffness for each deformation mode), isotropic (identical stiffness in warp and weft), linear and isotropic (the simplest variant), and nonlinear orthotropic (the most general variant).
Background	A better approximation to the true material response can be obtained by making the material parameters functions of the deformation, rather than constants, and by fitting these functions to measured data.
Approach	This initial frame serves to compute the geometry of the cloth without any occlusion from clips.
Outcome	Across models, the Soft Constraints and St. VK models fit to the average of the shearing hysteresis band, while the Springs model deviates at times.
Approach	The final solution is smoothed using Laplacian regularization to remove noise.
Approach	We have also evaluated the fitted models on new test samples of each fabric, to validate their generality.
Outcome	Interestingly, nonlinearity may arise in some deformation modes but not in others, with no clear pattern.
Background	Volino et al. [VMTF09] approximate the standard StVK model zeroing out off-diagonal terms in the matrix that relates strain and stress, σ = Eε.
Approach	For improved conditioning, we also use this ∂x n modified stiffness matrix in the outer loop.
FutureWork	There are many paths for future work in measurement, including more complete exploration of strain space (including compression) and capture of dynamic properties, and in fitting, where new ways of evaluating fitting error are needed that can work when the cloth’s equilibrium state is unstable or non-deterministic.
Approach	The forces are rendered as red vectors with lengths proportional to the force magnitudes.
Background	In a similar spirit, capture technology can be used to record time-varying geometry of complex cloth mo∗ ∗ tions [WCF07,BPS 08,SGdA 10].
Approach	We initialize the stiffness curve with one control point (i.e., constant stiffness), and subsequently we subdivide the strain range with equidistant control points.
Outcome	At least three effects are missed by the tested models: hysteresis, Poisson effect (due to the diagonalization of the standard StVK model), and cross-modal stiffening (e.g., shear stiffening due to stretching).
Challenge	The inevitable deviations from uniform strain create modeling error that cannot be quantified without knowing the actual strain variation; and force-displacement curves can be used directly to tune a cloth model, but do not provide any way to validate the resulting fit.
Outcome	Finally we show results that illustrate the performance of several widely used cloth models.
Approach	To start, the cloth vertices in the rest pose frame (frame 0) are projected onto the input images, where optical flow predicts the projection of each vertex at the next time step.
Approach	We found that, during inter∂x n mediate iterations, the stiffness matrix may not always be well conditioned, therefore we have solved the quasi-static equilibrium problems using additive Levenberg-Marquardt, which effectively produces a modified stiffness matrix of the form ∂F n + μI.
Approach	As with all sequential tracking methods, very small errors can accumulate over time and cause temporal drift in the reconstruction.
Approach	Note that the actuator positions themselves are not part of the output, since they are superseded by the displacements measured at the clips.
Approach	In the first test, opposite edges of the cloth are pulled in opposite directions, causing shearing and buckling ( Figure 5 , top).
Approach	Then, by fitting only clip-parallel forces we reduce the sensitivity to potential errors in stretch stiffness.
Approach	Specifically, we have tested stretching on new samples of rayon/spandex knit (#12.2) and cotton denim (#14.2), and shearing on new samples of cotton satin (#4.2) and wool/cotton blend (#18.2).
Approach	The clips are produced, using rapid prototyping, with embedded codes [Fia05] that allow us to determine their identity, position, and orientation automatically.
Approach	To ensure convergence of the Newton-like iterations and to enforce non-negativity constraints on the components of k, we execute a line search from k(i) to the solution of (9) if the residual grows or if the solution violates some constraint.
Background	Most methods for testing cloth move the sample into a state of near-uniform strain, exercising one or at most two components of strain at once: pure stretching, pure shearing, or pure bending.
Approach	We ignore shear and bend parameters for stretch fits, as we have observed that they have little effect.
Approach	We have designed a general fitting method, suited for the vast majority of existing cloth models, that leverages equilibrium conditions to guide the iteration.
Approach	Our approach to model estimation is to numerically optimize nonlinear stress-strain curves to minimize errors in force and position compared to the measurement.
Outcome	For each test we show a selected frame (near maximum distortion) with renderings illustrating the captured and fitted cloth geometry and forces.
Outcome	The most obvious of these is hysteresis—all widely used cloth models are elastic, but cloth is clearly far from elastic, resulting in quite large errors for any given point in the experiment.
Approach	Also, we do not need uniform strain, and in this paper we illustrate a range of tests, some that mimic traditional tests and some with more complex deformations.
Approach	We then attach the clips, and the measurement process continues automatically, following a defined script of actuations, and recording images and forces.
Outcome	Their capture setup is appealingly simple, but ours is more general and powerful: it produces a 3D surface, rather than a 2D deformation, and it measures all forces applied to the cloth as they change during a range of different deformations.
Challenge	This paper aims to solve this problem by introducing new techniques to measure complete cloth behavior under controlled conditions and to estimate cloth deformation models from these measurements.
Outcome	All four fabrics show similar hysteresis behavior, with loading-to-unloading stretch stiffness ratios ranging from 1.4/1 to 1.8/1.
Approach	Considering possible anisotropic behavior, we distinguish six different strain components on regularly triangulated cloth: weft-stretch (ε s,u ), warp-stretch (ε s,v ), shear (ε s,uv ), weft-bend (ε b,u ), warp-bend (ε b,v ), and diagonalbend (ε b,uv ).
Approach	For bending, no forces are available, and we evaluate the position residual as well as profiles of sample curves orthogonal to the support plane.
Approach	We measure the weights of all cloth samples as well as the clips (see Table 1 ) and use these values in the optimization process.
Outcome	The combination of very complete position and force information provides an unprecedented view into the complex behavior of cloth.
Approach	The fitted models are then evaluated by comparison to measured deformations with motions very different from those used for fitting.
Approach	The pattern is printed with a flatbed inkjet printer and does not have a noticeable effect on the material behavior.
Approach	Third, we fit in parallel the weftbending stiffness k b,u (ε b,u ), for the weft-bending measurement sequence, and the warp-bending stiffness k b,v (ε b,v ), for the warp-bending sequence.
Approach	The membrane deformation is defined using the Green-Lagrange strain tensor, a formulation introduced to computer graphics by Terzopoulos et al. [TPBF87].
Outcome	In contrast to continuum models, complex parameter tuning has often been regarded as a caveat of mass-spring models; but our results indicate that satisfactory parameter estimation is possible by incorporating anisotropy and nonlinearity into the model.
Approach	For the formulation of the objective function, we concatenate in vectors the positions, x n , and the net forces, F n , of free cloth nodes at all frames, as well as the forces, F c , applied by the cords on the clips.
Outcome	The four selected fabrics span a large range of possible cloth behaviors.
Background	As an alternative, Bhat et al. [ BTH 03 ] (and recently Kunitomo et al. [ KNM10 ]) aim at avoiding the need for controlled conditions and try to extract parameters from casually captured videos of cloth.
Outcome	Furthermore, the bending tests are most accurate for samples with straight edges, but some cloth materials (in particular knit) tend to curl up at free boundaries.
Outcome	The evaluation plots for the simulation models behave similar for the test and fitting cases, but the matching quality depends on the actual disparity across cloth samples.
Background	These measurement-based approaches establish a valuable link between simulation and real-world behavior, but they rely on experiments that isolate individual deforma∗ tion modes.
Approach	For shear tests, the objective function is based only on clip forces parallel to the direction of the clips themselves.
Approach	Then, for each deformation component, we model stress as a function σ i = k i (ε i )ε i , with a strain-dependent stiffness k i encoded using Hermite splines.
Approach	Finally, we fit the diagonalbending stiffness curve k b,uv (ε b,uv ), using both weftand warp-bending measurements.
Outcome	In a nutshell, #12 is isotropic and very compliant in stretch and bending; #4 is also isotropic, very stiff in stretch but compliant in bending; #14 is stiff and quite isotropic in stretch, but extremely anisotropic in bending (with 33/1 stiffness ratio in weft and warp); and #18 is anisotropic both in stretch (with 10/1 stiffness ratio) and in bending (with 13/1 stiffness ratio).
Background	This definition implies that bending energy density is integrated over edgecentered rectangles of size l 0 × h 0 .
Approach	The measured pulling forces of the cords are applied as point forces on the rigid bodies at known locations, with known magnitudes and orientations.
Approach	The magnitudes are determined by the tension measurements, and the directions are determined by the observed directions of the cords.
Outcome	Often, the residual is dominated by a difference in curl near the edge of the sample, while the overall shape is well fit.
Approach	The input of such a model is the positions of the vertices x 1 , . . . , x n ∈ IR 3 that define the deformation state of the sheet (analogous to strain in continuum mechanics) and the output is the forces that act between those vertices in response (analogous to stress).
Challenge	However, this approach has certain limitations.
Approach	Like other cloth testing systems, we focus primarily on tensile forces, because it is hard to repeatably produce and measure compression forces in a sheet that is inclined to buckle.
Approach	We have used our system to fit three membrane models and two bending models from the graphics literature, each based on a different strain measure, and to evaluate the resulting models against more complex motions.
Outcome	Our system is different from standard textile testing systems because it captures detailed geometry information; it is different from previous cloth capture systems in that it captures complete force information and measures deformations of a 3D surface.
Approach	We worked with three cloth models built from the components described in Section 4.
Approach	The process is then repeated using the result from frame n to obtain frame n + 1.
Approach	We enforce non-negative constraints on the stiffness values at control points.
Approach	The second is a four-corner pulling test, where opposite pairs of corners are pulled in alternation, resulting in diagonal wrinkles ( Figure 5 , bottom).
Outcome	This paper has demonstrated a novel system for observing cloth behavior, including complete information about deformation and forces, and a new method for fitting and evaluating cloth models using the measurements.
Outcome	The results are too numerous to include in the paper; we refer the reader to the supplementary material, which illustrates the behavior of the nonlinear orthotropic variant of all three models for all four fabrics, and the behavior of the variants of the Soft Constraints model for denim, a largely nonlinear and anisotropic material.
Outcome	The fitting residual is similar for all fabrics, but distinctly higher for the Springs model.
Approach	We have evaluated three models for membrane deformation that fit this description (spring systems, the soft constraint model by Baraff and Witkin [BW98] and the diagonalized St.Venant-Kirchhoff (StVK) model by Volino et al. [VMTF09]), and two bending models (spring systems and the edge-based bending model in Discrete Shells [GHDS03]).
Challenge	During this tuning process it is difficult to tell which models and which parameters are giving results more like the real material.
Approach	The solution to the linear least squares problem requires solving a system Ak = b, where the size of A is given by the number of unknown stiffness values, |k|.
Background	As a central component of any cloth model, material models describe the relation between deformation and resulting forces.
Approach	The Springs model uses the spring membrane model with the spring bending model; the Soft Constraints model uses Baraff and Witkin’s membrane model with the Discrete Shells bending model; and the St. VK model uses the diagonalized St. Venant-Kirchoff membrane model with the Discrete Shells bending model.

Outcome	The input morph target set contains only one example of a folded elbow but we show two distinct folding scenarios in the full animation.
Background	This technique, also known as linear blend skinning, cannot capture complex deformations and typically has problems deforming skin near joints due to collapsing geometry (i.e. pinching), because the deformation is restricted to the subspace of the affine transformation of the joints.
Outcome	Comparing our method with the performance of single (pose-independent) elastic models, it is clear from Table 1 that our method has only a marginal extra cost, due to efficient polynomial interpolation of the dynamic morph target models.
Background	Physically based deformation algorithms, governed by the physics of muscle motion and tendon influences, provide automatic means to achieve dynamic deformations under influence of external forces and inertial effects, but are computationally more expensive [Chadwick et al. 1989; Gourret et al. 1989; Chen and Zeltzer 1992; Scheepers et al. 1997; Wilhelms and Gelder 1997; Sifakis et al. 2005].
Approach	We define the pose descriptor s ∈ R 6k , where k is the number of joints.
Approach	However, it also yields the interpolation of force derivatives, such as the ∂R(u,s) stiffness matrix .
Approach	Obviously, as the character moves from one pose to the other, the internal forces change continuously but highly non-linearly.
Outcome	As shown in Fig 2(c) , our method can correct such undesirable behavior by setting elastic properties for each of the individual morph targets, effectively mimicking muscle contraction.
Approach	The combined system is underdetermined (m + 1 vector unknowns for m vectorial equations), but it can be solved by imposing orthogonality conditions on the weights w i [Carr et al. 2001].
Outcome	Dynamic morph targets avoid complex rigging requirements of purely geometric methods, and complex musculoskeletal modeling of purely physically-based methods.
Approach	In contrast to geometric morph targets, dynamic morph targets also define pose-specific elastic properties including stiffness and plasticity.
FutureWork	The current dynamic morph target framework can be enhanced with additional features to be included in the future, such as support for (contact) constraints, and an extension to weighted pose-space deformations [Kurihara and Miyata 2004] to allow for improved localized interpolation.
Approach	All rendering was done with the opensource Blender modeling package.
Background	The former provides good control of shapes but is restricted to a given input animation, while the latter achieves rich secondary surface detail but does not provide direct manipulation of the surface.
Outcome	All our methods achieve real-time performance due to efficient pose-space interpolation of low-complexity linear elastic forces and modal reduction of either linear or semi-nonlinear StVK forces.
Approach	We have performed all our experiments on a 2.4 GHz Intel Core 2 Duo Macbook Pro laptop (us- ing one of its two cores), with 2 GB of RAM and a NVidia GeForce 8600M GT graphics card.
Background	The first work to add control in a kinematic approach is that of pose-space deformations [Lewis et al. 2000].
Outcome	While the single elastic model shows little or no dynamic behavior, our pose-dependent elastic model adds a dramatic amount of realism due to the bulging behavior and inertial skin motion.
Approach	We scale the derivatives according to the eigenvalues of the corresponding linear modes.
Background	Finally, physically based methods in graphics are based on biomechanical models of skin tissue and musculature.
Approach	The stiffness matrix K = ∂R(x) ∂x is evaluated at x 0 i , the rest configuration for input pose i, which defines a ‘goal’ deformation for the input poses.
Outcome	Our video demonstrates the imposed behavior as Herbert’s belly exposes bulging and non-flabby skin when he jumps from the diving board.
Background	Generally speaking, there are three common approaches for modeling surface deformation: purely kinematic, example-based and physically based.
Approach	As mentioned in Section 3.2, we are looking for a way to interpolate internal elastic forces R i .
Approach	When applying model reduction to (multivariate) polynomial elastic forces, it can be shown that the reduced forces are still (multivariate) polynomial elastic forces.
Outcome	With single elastic models, the belly is flabby and skinny throughout the entire simulation.
Outcome	In this paper we have presented dynamic morph targets, posedependent elastic models that allow an artist to easily author and control the geometry and elastic behavior of dynamic characters.
Challenge	Our approach seeks to bridge the gap between geometric examplebased methods and physically based approaches.
Background	Instead, artists have to tweak vertex weights, giving SSD algorithms the reputation of being tedious to control.
Background	The method by Capell et al. [2005] also enables deformations under influence of external forces, corresponding to the behavior in Fig. 2(b) , but does not influence the underlying properties of the elastic material.
Approach	Similar to geometric morph targets, dynamic morph targets associate surface and volume deformation with character pose.
Approach	Elastic properties can be assigned for each pose, such that the same skin section can be defined stiff for one pose and flabby for another pose, e.g. to mimic contraction and relaxation of a muscle, or to exaggerate skin bulging.
Background	Recent techniques have extended skinning to mesh deformations [James and Twigg 2005], motion capture data without a predefined skeleton [Park and Hodgins 2006], or interactive models [Der et al. 2006].
Approach	In highly complex areas of skin deformation such as the shoulder area, the skin is under influence of many bones for which the skinbone relationships cannot easily be determined by a human rigger or technical director.
Approach	We describe here our implementation of the reduced equations of motion, through morph target aware subspace construction.
Approach	More formally, they are pairs of elastic models E i and poses s i , i.e. pairs {E i , s i } of elastic models in pose space.
Approach	Each polynomial R i (u) is associated with a dynamic morph target at pose s i and is uniquely defined by its set of coefficients {a k } i which we collect in a vector a i .
Approach	Degrees of freedom that are associated with these elements are removed (i.e. they are ’fixed’ in the pose-space), unless they lie on the model’s boundary surface.
Background	Readers are referred to extensive surveys for other important work [Gibson and Mirtich 1997; Nealen et al. 2006].
Background	While methods that control global deformation modes have been around for a while [Witkin and Welch 1990], providing control of sculpted deformations for simulation of deformable models has only recently caught attention in graphics research.
Outcome	To the best of our knowledge, our method is the first to provide shape and surface behavior control of dynamic reduced models.
Background	Interactive physically based approaches trade accuracy for performance [Terzopoulos et al. 1987; Terzopoulos and Witkin 1988; Metaxas and Terzopoulos 1992; Picinbono et al. 2001; Capell et al. 2002; Müller and Gross 2004; Galoppo et al. 2007].
Background	Traditionally, the elastic energy is a pose-independent material potential that causes internal elastic forces R(u) in the material.
Background	Conceptually, a pose can be described in many ways, as long as it provides a description of the state of a model or character, and a metric to measure distances between poses.
Outcome	The resulting deformable models expose fully dynamic, pose-dependent behavior, driven by the artist-provided morph targets, complete with inertial effects.
Outcome	However, because we express deformation in the skeletal bind pose, we did not see any noticeable quality difference between both elastic models in our experiments.
Approach	Although our method is physically based, we avoid expensive modeling of musculature or tendon influences, and instead rely on physical constitutive models of deformable material to minimize skin pinching artifacts and bypass complex rigging requirements that are common to purely geometric approaches.
Approach	The shoulder model has 4899 degrees of freedom.
Outcome	Finally, our method also facilitates certain time-consuming rigging procedures, by providing a physically based approach to resolve co-articulation deficiencies in traditional skinning methods, such as in shoulder regions, fully automatically.
Background	Radial base functions [Powell 1987] (RBF) are a common choice for interpolating scattered data of an underlying smooth field that is non-linear.
Background	A method for physically based rigging was proposed by [Capell et al. 2005], using pose-dependent forces to guide the shape of the character.
Approach	Instead, we guide dynamic simulations by dynamic morph targets — discrete pose-space examples of skin properties and deformations.
Outcome	The shoulder example also demonstrates our method’s ability to simulate dynamic behavior at poses away from the morph target input poses ( Fig. 5 ).
Background	In its most essential form, one simply interpolates between character poses in a large database [Maestri 2006], providing ample control of skin deformation to animators.
Approach	We can then determine the posedependent elastic force R(u, s), which is also uniquely defined by its set of coefficients a(s).
Approach	Here, P i , Q ij , S ijk ∈ R r are constant vector polynomial coefficients.
Approach	We also employed the globally supported biharmonic RBF kernel φ(r) = r, since its optimal fairness allows for smoother interpolation of sparsely scattered example poses as compared to locally supported kernels [Carr et al. 2001].
Outcome	Both folding scenarios show severe self-intersection in the single pose-independent model due to the effect of linear blend skinning.
Approach	We then relax the internal nodes by performing a physical simulation, constraining the new surface positions and using the elastic model of the base mesh.
Background	Example-based approaches capture more realism by pose-space interpolation of desired skin shapes at different poses [Magnenat-Thalmann et al. 1988; Mohr and Gleicher 2003; Kry et al. 2002; Lewis et al. 2000].
Challenge	Realistic deformation is a complex and subtle phenomenon due to the tightly coupled interplay of bones and musculature governing the deformations.
Approach	Just as in Section 3.3, each dynamic morph target defines a set of coefficients a i which can then be used to set up an interpolator for the posedependent coefficients a(s).
Approach	Then, the interpolation of elastic models reduces to the interpolation of polynomial coefficients.
Approach	However, since forces are a function of the timevarying deformation u, they cannot simply be evaluated once and then interpolated at runtime.
Outcome	Therefore, stable results can be achieved with little effort from the artist and poses can then be added incrementally to areas of the posespace where the behavior is not satisfactory.
Approach	Our system can automatically deduce these relationships and reduce them to only a few significant modes.
Approach	Note that at this point, one could easily add modal derivatives, as in [Barbic and James 2005].
Approach	Moreover, as our goal is to have as few input models E i as possible, RBFs are suited because they work well with sparse input data sets.
Background	Given an input animation, shape keyframes can be used to retarget the elastic deformations [Kondo et al. 2005] or to enhance the surface deformations with physically simulated detail using subspace constraints [Bergou et al. 2007].
Approach	The interpolation of polynomial coefficients yields the interpolation of force values R(u, s) at all possible deformation values u.
Outcome	We present a method to control the behavior of elastic, deformable material in a dynamic simulation.
Approach	Then, for each morph target, a corresponding tetrahedral rest-pose mesh is defined (still in the skeletal bind pose).
Approach	The input deformations of each of the dynamic morph targets have to be well represented in the reduced space, otherwise the sculpted deformations can’t be simulated.
Approach	Given these morph targets, our algorithm then derives a dynamic model that can be simulated in time-pose-space, interpolating the dynamic morph targets at the input poses.
Approach	One subtle detail remains for defining a ∂u complete interpolation of elastic models.
Approach	We create a pose-dependent elastic model by taking into account the dynamic morph targets {E i , s i } as example inputs.
Approach	The combination of surface deformation and elastic properties defines the elastic model E i .
Approach	As mentioned in Section 3.2, we can determine the pose-dependent elastic forces R(u, s) by computing the polynomial coefficient vector a(s).
Outcome	The main advantages of our method over previous approaches are three-fold: quality of deformations, dynamic behavior and computational efficiency.
Challenge	Purely data-driven methods lack a kinematic model, making them of limited use for animation and dynamic simulation.
Approach	We use a reduced model u = Uq to enable dynamic simulation that is independent from the input resolution of the geometry.
Background	When dealing with large pose-spaces that have many example poses, PSD becomes memory inefficient due to the large database of surface displacements.
Background	Here, we will primarily focus on significant work related to control of surface deformation of kinematic and dynamic characters.
Approach	We represent a pose by a vector s ∈ S where posespace S ⊂ R k .
Approach	We define distance between two poses to be the inner product of the difference of its descriptors.
Approach	We choose a certain pose as a reference, and express the deformation of all other poses by adding the difference between rest configurations, ∆u.
Outcome	In our shoulder example, we have 6 morph targets, shown in Fig. 5(a) .
Approach	In other words, the basis has to be aware of the morph targets.
Background	PSD is a hybrid method that combines SSD with morphing and employs scattered data interpolation to compute non-linear skin corrections in posespace, resulting in a kinematic model that also has artist-sculpted poses.
Background	Common examples of such elastic models are the so-called ‘completely linear’ FEM deformation model (with or without stiffness warping [Müller and Gross 2004]), or the ’seminon-linear’ St.Venant-Kirchoff model (StVK) [Barbic and James 2005; Capell et al. 2005].
Background	Purely data-driven methods are an attractive choice for control purposes, as the input shapes provide guide examples of desired deformations.
Challenge	Due to performance requirements, one is commonly restricted to linear or quasi-linear models that cannot model pose-dependent effects such as bulging and wrinkling.
Approach	Our method easily integrates with current modeling and animation pipelines: at different poses, an artist simply provides a set of dynamic morph targets.
Approach	For reduced elastic models, a modal subspace is also constructed (Section 4).
Approach	The first morph target is a skinny version of Herbert, in which his skin is very soft and flabby, the third target is a stiff, bulged Herbert in fetal position, while the second target has been chosen in between the first and the third.
Approach	Each joint contributes 6 components to s, namely the 6-dof representation of its parent-relative coordinate frame.
Background	In terms of efficiency versus accuracy, these methods fall into two broad categories.
Approach	Here, U is a time-independent matrix specifying a basis of some r-dimensional (r << 3n) linear subspace of R 3n .
Approach	As an articulated character moves between observed configurations, its elastic model should approximate the elastic models of the input poses.
Approach	Therefore, we have opted for the more efficient linear elasticity to produce most of the images and videos unless otherwise noted (see Section 5).
Approach	We can now combine scattered polynomial interpolation from Section 3.3 with the reduced motion equations by concatenating the reduced coefficients into a = [ P i ; Q ij ; S ijk ].
Approach	Modal reduction of the pose descriptors is very effective for robustness, but is also useful when our method is used for facilitating rigging.
Approach	Whether these input states are physically plausible is completely up to the artist.
Approach	Dynamic morph targets are used to build a pose-dependent elastic model E(x, s).
Background	Purely kinematic approaches such as skeletal-subspace deformation (SSD) [Magnenat-Thalmann et al. 1988] model the deformation of the skin surface by linear blending of the animated bone transformations.
Background	The EigenSkin method [Kry et al. 2002] also provides a way to reduce per-vertex displacement memory footprint by computing an error-optimal set of eigenbases for approximating the original deformation model.
Outcome	There is no need for manual tweaking of the complex mapping of joint configuration to blending weights of geometric morph targets.
Approach	This is where our preprocessing stage starts.
Background	Pose space deformation and related example-based methods allow for direct sculpting of geometric morph targets, but are purely kinematic approaches to (quasi-)static deformation, without reference to underlying forces or mass.
Background	Unlike shape interpolation and other data-driven methods, SSD does not permit direct sculpting or control.
Approach	For linear materials, the Q ij and S ijk terms are all zero.
Background	Modal reduction has proven useful to increase performance in posespace deformation methods [Kry et al. 2002] as well as in physically based methods [Hauser et al. 2003; Choi and Ko 2005].
Approach	Using the aforementioned morph targets for Herbert, an animator can impose a stiff, bulged belly in balled-up poses, and softer, skinny belly behavior in upright poses.
Outcome	• The extension of the method to support modal reduction and therefore very efficient implementation that is linear in the number of coefficients of the force polynomial.
Approach	We select the first r principal modes to achieve the basis U .
Approach	This can be achieved by removing the elastic degrees of freedom that are associated with corresponding internal mesh nodes.
Outcome	By extending our basic framework to support modal reduction, we also achieve high runtime performance.
Background	Purely algorithmic approaches for skeleton-driven [Kavan and Zara 2005] and facial deformations [Pighin and Lewis 2006] are very fast, but have difficulty in capturing realistic skin deformation in areas with multiple influences.
Approach	For hyper-elastic materials, an elastic model can be defined as a material function E(u(x)) defining the internal elastic energy at material points x in function of the deformation u.
Approach	The characteristic deformations of all the morph targets have to be well represented.
Challenge	However, many poses are required in the database to achieve good results.
Outcome	These models can therefore be plugged into existing dynamic simulation engines, either forming interactive, deformable content in real-time games or providing secondary dynamic effects for kinematically-driven characters in feature animation films.
Background	The first category of algorithms aim for accuracy [Chen and Zeltzer 1992; Scheepers et al. 1997; Wilhelms and Gelder 1997; Koch et al. 1996; Zordan et al. 2004; Sifakis et al. 2005; Sueda et al. 2008] by simulating the actions of the individual muscles, bones and tendons in the skin.
Approach	We remove these degrees of freedom in our preprocessing step by identifying tetrahedral mesh elements that are intersected by skeletal bones.
Approach	The rest configuration at each input pose may be different, therefore the deformation u may not be consistent across poses.
Approach	Using vertex painting, he can then assign stiffness parameters such as Young’s modulus and Poisson ratio to certain parts of the skin.
Outcome	This technique makes our approach suitable for real-time applications.
Approach	Avoid redundancy in the basis set, i.e. find an orthogonal set that is as compact as possible.
Outcome	We introduce dynamic morph targets, i.e. predefined and possibly artist-authored physical descriptors of skin deformations and elastic material properties.
Approach	We compare a single (pose-independent) elastic model with our pose-dependent elastic model that employs multiple dynamic morph targets, both with and without modal reduction.
Approach	Our method builds on the concept of pose-space deformation and applies it to pose-space interpolation of dynamic morph targets to achieve not only (quasi-)static deformations, but a fully dynamic model in time-pose-space.
Outcome	Whereas the chest seems to collapse for single elastic models, it bulges more realistically with our method.
Approach	In our experiments, it was sufficient to use a constant vector Q for the polynomial Q(s).
Background	In contrast to our method, their approach does not support pose-dependent elastic properties and its performance is highly dependent on the resolution of the sculpted deformations.
Approach	In our implementation, we choose the joint configuration of an articulated character as the pose descriptor.
Approach	The use of such constitutive material models also enables response to external forces and inertial effects in dynamic simulations.
Outcome	Our dynamic morph targets add dynamic behavior to non-linear deformations such that external and inertial forces can be applied, as shown in Fig. 2 .
Outcome	• A compact way of interpolating skin geometry, elastic forces, and their derivatives, all in a unified manner.
Background	Due to its immense importance in character animation, there has been an extensive collection of work in the area of surface deformation in the last few decades.
Approach	Our work exploits the technique of [Barbic and James 2005] that enables fast modal integration of St.Venant-Kirchoff elastic forces, where the performance depends mainly on the number of simulated eigenmodes, not on the resolution of the model.
Approach	We do this by solving a homogeneous Poisson problem for the internal node weights, where the known surface node weights are set up as boundary conditions.
Approach	In our method, we have opted for elastic models for which R i (u) can be expressed as a (multivariate) polynomial function of the degrees of freedom u.
Approach	Intuitively, modal basis vectors are directions into which the model can be pushed with the smallest possible increase in elastic strain energy.
Approach	At an arbitrary pose s in pose-space, a(s) can be interpolated from the example coefficients a i .
Outcome	As Herbert jumps off a diving board and flips through different poses, we show the advantage of our pose-dependent model from an artistic viewpoint.
Approach	Additionally, we conceptually constrain the material points that are attached to internal bones.
Approach	We also account for the inertial forces caused by the moving coordinate frames of the bones [Galoppo et al. 2007].
Approach	On the other hand, it is certainly possible to use other formulations of elastic strain to define a pose-dependent model with dynamic morph targets.
Approach	By selecting modes with non-zero or large eigenvalues only, we reduce the dimension of s and define a mapping to the reduced pose descriptor s = U T s s.
Approach	In our experience, locally supported kernels such as the Gaussian RBF kernel are harder to tune and are unable to extrapolate across dynamic morph targets that are far apart in pose-space.
Outcome	In our video, we show Herbert’s belly deformations as he cycles between upright and fetal poses.
Approach	Dynamic morph targets define pose-specific soft skin behavior.
Outcome	We introduce dynamic morph targets, the equivalent in dynamic simulation to the geometric morph targets in (quasi-static) modeling.
Approach	We have performed experiments with three different input models: a simple bulging cylinder with 4 bones (see Fig. 2 ), a shoulder model with 4 bones, and Herbert, our swimsuit model with 46 bones.
Outcome	Dynamic morph targets define the pose-dependent physical state of soft objects, including surface deformation and elastic and inertial properties.
Approach	Dynamic morph targets can easily be created in existing modeling packages; very similar to creating geometric morph targets.
Challenge	Animation of skin and muscular deformations of human characters and other living creatures has long been one of the most important applications of deformable modeling in computer graphics, notably in feature animation and more recently in increasingly realistic computer games and interactive medical and training applications.
Approach	Note that our implementation uses skeletal pose, but the concept of pose can easily be extended beyond the skeletal sense; in fact any notion of state of a character can be used, such as emotional state, velocity state, contact state, or muscle activation.
Approach	This can be done by displacing the surface nodes of the base tetrahedral mesh with the morph target’s values.
Outcome	Our method provides the ability to sculpt the dynamic morph targets directly and produces a dynamic model that is not restricted to a given animation; our model can be plugged into any simulated environment and be subject to external forces.
Background	Other recent methods [Weber et al. 2007; Wang et al. 2007] learn example-based corrections on sparse points and assume that these corrections can be smoothly interpolated.
Outcome	The effect of the number of poses on the run-time performance of the algorithm is very small as it doesn’t affect the number of degrees of freedom in the simulation (see comparison 6 vs. 9 shoulder DMTs in Table 1 ).
Approach	For our experiments and in correspondence with the space in which the morph targets are defined, we choose to express elastic deformation in the skeletal bind pose as has been proposed in the past [Lewis et al. 2000; Kry et al. 2002; Galoppo et al. 2007].
Approach	Scaling is necessary to put greater weight on the more important low-frequency modes, which would otherwise be masked by highfrequency modes.
Background	These methods use simplified (quasi-)linear elastic models that cannot capture complex non-linear behavior such as muscle bulging.
Outcome	Also, in Fig. 4 , we show the use of reduced models in our method achieves the same quality of desired deformations as the computationally more expensive unreduced model.
Background	Physically based methods can only provide control through the influence of forces.
Approach	Next, we drive the skinned Herbert model with a skeletal animation and add inertial forces due to the bone’s moving frames.
Outcome	Our pose-dependent model resolves both automatically.
Approach	Instead, similar to [Barbic and James 2005], we can construct a low-dimensional motion subspace by applying mass-PCA.
Background	PSD can be extended to support per-vertex pose-space deformation (WPSD) [Kurihara and Miyata 2004; Rhee et al. 2006], largely reducing the number of required example poses.
Approach	Instead, we propose a way to increase performance and to reduce the dependency on the resolution of the input geometry by reducing the number of degrees of freedom, while still maintaining the non-linear behavior defined by the morph targets.
Approach	As described in Section 3.1, an artist begins by modeling the base model surface and a skeleton with associated SSD skinning weights, and defines a set of geometric morph targets.
Approach	We use scattered data interpolation to derive an expression for the internal elastic forces R(u, s) anywhere in pose-space S, given the expressions for the elastic forces R i (u) that are imposed by the dynamic morph targets at poses s i .
Approach	Dynamic characters enhanced with dynamic morph targets can react to external forces just as with other common physically based deformation algorithms, but they also expose non-linear deformations and elastic behavior as imposed by the dynamic morph targets.
Outcome	By using pose-space efficient polynomial interpolation to achieve pose-dependent behavior, we are able to demonstrate rich nonlinear deformation effects at relatively small extra cost compared to simple simulation of linear or semi-non-linear materials.
Approach	For each of the dynamic morph targets, we employ linear modal analysis (LMA), which provides the best deformation basis for small deformations away from the rest configuration.
Outcome	After modal reduction, we were able to accelerate the simulation significantly by using only 19 eigenmodes ( Table 1 ) with almost no visible effect on the simulation quality ( Fig. 5 ).
Approach	A modeler defines a set of m poses {s 1 , s 2 , . . . , s m } of the character and sculpts desired deformations that cannot be captured with traditional skinning methods [Kavan and Zara 2005; MagnenatThalmann et al. 1988].
Approach	In other words, elastic forces form a non-linear smooth field in pose-space.
Approach	RBFs extend easily to high dimensional domains, enabling the capture of multi-joint coupling effects.
Approach	We also use the smoothing term from [Carr et al. 2001] to achieve smoother behavior across large gaps between input poses.
Challenge	The goal of our method is to simulate controllable non-linear deformations by interpolation of dynamic morph targets at runtime, kindred to geometric morph targets in static character modeling.
Approach	The polynomial coefficients can be precomputed, given the rest pose p i .
Background	Different methods have been proposed to address the problems of linear blend skinning by inserting additional joints tuned from examples [Mohr and Gleicher 2003], or employing blending of transformations instead of weights [Kavan and Zara 2005], among others.
Approach	Hence, the positions of these points are then completely governed by the linear blend skinning transformations only.
Approach	We have simulated our examples with both linear and semi-non-linear elastic models.
Outcome	Too few input poses can cause slight popping of the animation towards the input shapes but the simulation of the pose-dependent elastic model will be stable nevertheless.
Approach	The number of coefficients is proportional to the number of nodes n in the finite element mesh for linear elastic models, and O(S 3 n) for StVK materials, where S is the average size of the neighborhood of a node.
Approach	In the reduced model, the displacement vector u is expressed as u = Uq, where U ∈ R (3n,r) is the displacement basis matrix, and q ∈ R r is the vector of reduced displacement coordinates.

Approach	A set of examples is exported, consisting of skeleton configurations paired with the deformed geometry as static meshes.
Approach	It may seem that just transforming a dress pose normal by the inverse transpose of the corresponding vertex’s transformation matrix would be correct.
Outcome	We show how we can fit the parameters of our skinning model using a sampling of an arbitrarily rigged character’s deformations.
Approach	Ideally, the influence sets would fall out naturally from the weight solving procedure (irrelevant joints would have a weight of zero) but this does not happen in practice because our samplings are necessarily not exhaustive.
Background	High-end characters often use a combination of these techniques—different tools are appropriate for different parts of the character.
Outcome	Also, since each vertex is solved independently, our algorithm is trivial to parallelize.
Outcome	Skin retargeting is useful if a particular interactive system requires characters to have a specific skeleton.
Approach	That is        n 2 min ∑ v e i − v e i i=1        for all examples where v e i is the input vertex position from the ith example and v e i is the deformed vertex computed by the skinning model at the ith example configuration.
Approach	To capture these effects, our system can add several joints that scale up and down based on the angle between particular joints.
Approach	That means for each vertex, we are able to choose the set of influencing joints, influence weights (w i ) and the dress pose vertex position (v d ).
Background	While fast to evaluate and compact in memory, this method is notorious not only for its authoring difficulty, but also for its undesirable deformation artifacts.
Background	There are two fundamental aspects of skin creation—authoring and computation.
Background	While on the surface Multi-Weight Enveloping and our technique seem very similar, they are in fact different in a fundamental way.
Approach	Instead we have single points that are computed independently.
Outcome	The characters may be rigged using any available tool since our system only requires static deformed meshes paired with skeletal configurations as input.
Background	An early 3D skeleton-driven technique that went beyond rigid skinning was presented by MagnenatThalmann, et al. [1988].
Challenge	For high-end applications such as film, the visual fidelity of characters is paramount, so artists require flexibility and control in skin authoring.
Challenge	None of the more intuitive or useful deformer primitives provided by animation systems may be used.
Approach	First we introduce some notation: T i,e = M i,e M i,d −1 .
Approach	We measure the compactness of this point cloud by taking its diameter (the maximum distance between any two points in the cloud).
Outcome	This assumption may be violated by a character whose muscle bulges only when its arm is fully bent.
Approach	Computing the normals in this manner can give undesirable results when the blended transformations are not pure rotations.
Approach	For wrinkles, we could add several joints that move and scale in concert to capture the wrinkles.
Background	However, MWE extends linear blend skinning by adding more vertex weights to the model while in contrast, our method adds more joints.
Approach	This works by first fixing the first variable and solving a linear least-squares problem to find the second, then fixing the second and solving a linear leastsquares problem for the first.
Approach	Again, since vertices may take any scaling of these new joints, a conservative large value is fine.
Approach	This makes the solving process faster.
Outcome	Our solution procedure is generally very fast.
Approach	Downstream joints are similar.
Approach	However, in all the examples in this paper, no singular values were zeroed.
Outcome	This frees the author from setting them manually.
Outcome	Another application of our technique is targeted at high-end animation.
Background	Skin computation refers to the method by which the deformed mesh geometry is evaluated for display at some skeleton configuration.
Approach	This lets us detect when our matrices are rank deficient, leading to overfitting.
Background	Some examples include FFD lattices [Sederberg and Parry 1986] or Wires [Singh and Fiume 1998].
Outcome	Even so, our method can detect and handle small amounts of overfitting if it occurs as explained in Section 5.2.
Outcome	Thus we do not have to take special precautions to avoid overfitting as in [Wang and Phillips 2002], although we include tests for robustness.
Background	In fact, high-end tools allow authors to continually develop new skin computation models through custom scripts, expressions and complex deformers.
Approach	Using this observation, we measure how rigidly a vertex transforms with every joint over all examples and use the most rigidly transforming joints for the influence set.
Background	The results of these approaches are quite good, and unlike our technique, they can handle skin deformations that depend on abstract parameters rather than only skeleton configurations.
Background	) Note that a deformed vertex position in the dress pose configuration c = d is the same as the provided dress pose vertex ( v d = v d ) if the weights are affine.
Approach	We begin with a character rigged in an animation package such as Maya.
Outcome	Using our method, interactive characters could be built that allow animators to interact with much better approximations of the deformed characters.
Approach	First, adding such a large number of joints would severely impact the performance of our resulting skins.
Background	One method solves for joint centers and vertex weights for a scanned arm [Nebel and Sibiryakov 2002] but the Multi-Weight Enveloping technique [Wang and Phillips 2002], or MWE, is most similar to our approach.
Challenge	While these systems are convenient and flexible for artists, the generality often leads to characters that are slow to compute or that require a substantial amount of memory and thus cannot be used in interactive systems.
Outcome	For instance, a video game may have an optimized engine for characters with a particular skeleton topology.
Approach	The first set is “upstream” of the driver and lies in the middle of the bone connecting the driver to its parent, the second set is “downstream” and lies in the middle of the bones connecting the driver to its children.
Outcome	Ordinarily, if a character was created for a different skeleton, the character would have to be re-rigged manually to work on the new skeleton topology.
Approach	We call a paired skeleton configuration and static mesh an example.
Outcome	Our system sees this as any other set of data and solves for the proper influence sets and blending weights.
Background	Computing the deformation in some pose involves rigidly transforming each dress pose vertex by all of its influencing joints.
Challenge	Determining the blending weights and influence sets is left to the skin author to set directly.
Background	The artifacts occur because vertices are transformed by linearly interpolated matrices.
Challenge	The linear blend skinning model is not sufficient to capture deformations well as shown in Figure 3 .
Approach	The scale parameters are computed as follows.
Outcome	None of the examples shown here took more than five minutes to solve on a modern personal computer.
Challenge	Applications range from building characters for video games and virtual environments to high-end animation previewing.
Challenge	Instead, animators typi- cally manipulate an underlying hierarchical skeleton.
Background	It cannot represent complex deformations and suffers from characteristic artifacts such as the “candy-wrapper” collapse effect on wrists and collapsing around bending joints as shown in Figure 2 .
Approach	Finally, we fit the parameters of our skinning model using this extended skeleton.
Approach	More joints with evenly distributed interpolation parameters could be added to sample this rotation space even better; however, in our experience just a single interpolated rotation is sufficient.
Background	Then the blending weights are used to combine these rigidly transformed positions.
Background	Then, each vertex is assigned a set of influencing joints and a blending weight for each influence.
Approach	For a single vertex, a rigidity score for a joint is computed as follows.
Outcome	It is important to note that since our characters are a straightforward extension to linear blend skinning, many existing interactive systems already have the software infrastructure to sup- port them.
Approach	Our system is configured to add these extra joints automatically to characters, but we allow users to fine tune the specific set of extra joints if they wish.
Approach	In contrast, since the number of weights per vertex in one of our skins remains relatively small (1 per influencing joint) and our extra joints are explicitly designed to be very different from existing joints, our technique requires no special provisions to avoid overfitting.
Background	Skin authoring refers to how artists use tool sets to describe the behavior of skin geometry as the skeleton moves.
Background	Mesh animation is interesting since it decouples skin authoring from runtime skin computation, allowing artists to use any tools they want to author characters.
Approach	We would like to choose the influence sets, weights and dress pose vertex positions that best approximate the examples and generalize well to new poses.
Outcome	All our system requires is a set of examples which is used to compute the appropriate influence sets and blending weights automatically.
Background	However, this method is widely used since these characters can be used with arbitrary amounts of animation data and can be posed at runtime.
Approach	It is unclear how to pick a good threshold because as the rigidity scores get larger, they become less meaningful.
Challenge	These particular effects cannot be captured since the joints employed in animating a character do not typically scale up and down as would be necessary to approximate these effects.
Approach	Unfortunately, adding so many extra joints is impractical.
Approach	For instance, vertices on the forearm roughly follow the forearm.
Challenge	We observe that we can help avoid the collapse problem by avoiding blending transformations that are so dissimilar.
Outcome	Collapsing and interpenetrations around hinge joints are also fixed using our method as shown in Figure 5 .
Approach	Once the compactness measures for all joints are computed for a vertex, the smallest k are chosen as the influence set for that vertex.
Background	Thus, the character computation model is fixed and artists must restrict their tool set to author characters in direct support of it.
Background	This initial character pose is referred to as “dress pose”.
Outcome	We call this process skin retargeting.
Background	A 2D skeletal bilinear deformation method was presented by Burtnyk and Wein [1976].
Background	The character mesh geometry must then be attached to the underlying skeleton so that as the skeleton deforms, the mesh also deforms appropriately.
Background	Despite its failings, this skinning algorithm is very fast and widely supported by commercial applications so it remains popular especially in games and virtual environments.
Challenge	The problem in this particular case is that as the twist approaches 180 degrees, the linearly blended matrix becomes degenerate and collapses the skin geometry.
Approach	We assume that normals are specified per vertex.
Background	Catmull [1972] introduced one of the first skeleton-driven techniques—rigid skinning to a hierarchically structured articulated figure.
Challenge	Linearly blended transformations tend to collapse the more different they are.
Outcome	While the particular extra joints we have chosen to add to our characters may not be capable of capturing the full deformation for any character, different extra joints that do capture the desired deformations may be added and solved using our technique.
Approach	Even though a point on the bicep is not truly rigid as an arm moves (due to muscle bulge), we believe that these points remain mostly rigidly attached to the upper arm, and therefore should be influenced by it.
Background	In EigenSkin [Kry et al. 2002], normals are treated as second skinning problem and are computed independently.
Background	A different character computation mechanism previously used in interactive systems is called mesh animation.
Background	Other authors have used physical simulation for interactive deformations, especially secondary animation [James and Pai 2002; Capell et al. 2002].
Approach	We can accomplish this by adding extra transformations that properly interpolates without collapsing.
Outcome	Using our method, character authors may use any tools they like to author characters.
Approach	More generally, we observe that any deformation effect could be obtained by adding joints that deform appropriately to capture that deformation effect.
Background	This technique is commonly used and is described in [Freeman and Tenenbaum 1997].
Outcome	Even though not all deformations can be captured using the extra joints presented here, new joints may be added to capture any important deformation, and our influence set and vertex weight solving framework may be applied without change.
Approach	These new joints are designed in such a way to capture richer deformations than the standard linear blend skinning model.
Approach	The key to our success is that since vertices choose weighted sums of transformations, if any linear scaling of an added joint is beneficial it may be used.
Approach	For joints that scale down, the scale parameter is simply s −1 .
Approach	We add these scaling joints as follows.
Approach	For our results, our examples were generated by exporting rigged objects from Maya, but they could have been sculpted by hand or come from another program.
Approach	For example, if a vertex in fact needed a joint that scaled by 2 instead of 8, it could be assigned a weight of 4 1 .
Approach	This step does not require a trained animator since these poses are only intended to exercise the degrees of freedom of the character and need not correspond to a realistic motion.
Outcome	Our framework for extending the linear blend model allows us to capture much more interesting deformations while retaining its efficiency.
Approach	We use an alternation technique to solve the optimization.
Background	This attachment of model geometry to an underlying skeleton is called a “skin” and can be viewed as a function that maps from the skeletal parameters to a deformation field.
Background	In contrast, interactive systems require fast computation and small memory size for characters.
Approach	However, once some set of these joints is determined, the skin may be solved using our fitting algorithm without change.
Background	While less difficult than painting the weights themselves [Lewis et al. 2000], it is a tedious process.
Background	The most common skin computation model in games and interactive systems goes by many names including SSD, enveloping, smooth skinning, and linear blend skinning.
Background	However, these methods are not appropriate for interactive characters since they require storing potentially large amounts of example data for runtime interpolation.
Approach	This static mesh is deformed according to the skeleton configuration, but it is not attached to the skeleton in any way.
Approach	In contrast, our system automatically determines the influence sets for each vertex using a heuristic algorithm.
Background	Hence, there are many different ways to create characters using commercial tools.
Approach	Instead, we extend the traditional linear blend skinning model by adding a relatively small number of joints that are simply related to the original skeletal parameters and fit using them.
Background	The task is typically accomplished by “painting” the regions of influence for each joint over the mesh.
Outcome	As mentioned in Section 2, we have found that since we are solving for a small numbers of weights using large numbers of examples, our systems are often well conditioned and do not suffer from overfitting if the input data is well sampled.
Background	The traditional interactive skinning model goes by many names.
Background	Another recent work applies these techniques to range scan data [Allen et al. 2002].
Approach	The collection of these local coordinate positions over all examples forms a point cloud as shown in Figure 7 .
Background	The linear blend skinning algorithm works by first placing a hierarchical skeleton inside a static model of a character, typically in some neutral pose.
Approach	For example, to capture muscle bulges, we can add joints that scale up when the muscle should bulge, and scale down when the muscle relaxes.
Approach	We use four upstream joints.
Approach	We then add joints that we believe will help resolve these artifacts.
Approach	Since larger rigidity scores are not particularly meaningful, it is nearly impossible to pick a meaningful threshold value.
Approach	We believe that for most characters, their skin is most heavily influenced by those joints that they are bound to.
Outcome	This technique allows artists to use any skin authoring tools they like while producing characters that meet the performance demands and work with the computation models used in interactive systems.
Approach	Also, the more joints that a vertex depends on, the slower the skin can be to compute and current hardware only supports a limited number of influences per vertex.
Approach	This process typically converges after one or two iterations.
Approach	In contrast, our method discards all example data after the fitting process so the size of our runtime structures does not scale with the number of inputs.
Approach	As in other linear blend skinning systems, influence sets need only be determined conservatively [Wang and Phillips 2002] so we allow users to choose k if desired.
Background	Lewis et. al call it Skeleton Subspace Deformation or SSD, Maya calls it “smooth skinning” and we call it linear blend skinning.
Outcome	Our method cannot capture deformations that are driven by abstract parameters such as “happiness” as in [Lewis et al. 2000; Sloan et al. 2001].
Approach	For each example, the local coordinate position of the vertex is computed as M i,e −1 v e where M i,e is the coordinate frame associated with the ith joint in the eth example and v e is the global coordinate position of the vertex on the eth example.
Background	If the interpolated matrices are dissimilar as in a rotation of nearly 180 degrees, the interpolated transformation is degenerate, so the geometry must collapse.
Approach	Next we fit the parameters of our underlying skinning model using this sampled data.
Approach	For example, a bicep bulge is small when the elbow is near full extension while the bugle is large when the elbow is near full flexion.
Approach	This alleviates the need for a general inversion operation.
Approach	Each sample consists of the skeleton configuration and the corresponding deformed skin geometry as a static mesh.
Approach	It may be tempting to use a threshold scheme to choose influence sets but we have found this problematic.
Approach	If the driver has multiple children, a vector that is the sum of the bones connecting the driver to its children is used to measure the angle.
Approach	Also, choosing the influence sets appropriately lets us bound the size of the problems we must solve to determine the weights as discussed in Section 5.2.
Approach	Once this is done, the poses are sampled regularly at k times.
Approach	For joints that scale up, the scale parameter s is s = 1 + k b 1 · b 2 + 1 2 b 1 b 2 where b 1 and b 2 are the bone vectors used to measure the angle at the driver joint and k is the maximum scale factor when the angle between b 1 and b 2 is zero.
Approach	Worse, even if we could find these transformations for the input examples, it is unclear how to determine the general relationships of these transformations to the skeletal parameters in all poses.
Approach	The scale parameters of these joints are set based on the angle of the bone connecting the driver to its parent and the bone connecting the driver to its child.
Approach	We emphasize that this is a framework for obtaining better deformations and the joints we choose to add are based on our observations of characters.
Outcome	While our technique works well for a wide variety of character skins, it has limitations.
Outcome	The most egregious deformation problems of linear blend skinning are solved by our approach.
Approach	We have found that the simple O(n 2 ) algorithm that compares each point to every other to be fast enough for our purposes but this diameter may be computed more quickly.
Approach	Finally, since our skins are computed in the same manner as linear blend skins, existing software infrastructure can make use of them with little or no changes.
Approach	An example is simply a static character mesh paired with a skeleton.
Background	These static models are then either displayed directly or are linearly interpolated at runtime.
Approach	As mentioned earlier, the input to the fitting process is a set of examples.
Approach	Using this set of examples, our system first determines the set of joints that should influence each vertex, and then solves a bilinear least-squares problem to fit the parameters of the underlying skinning model.
Approach	For instance, it may happen as an artifact of the particular input examples that points on the left shoulder move much more rigidly relative to the right leg rather than the left leg but both choices make no sense for influences.
Background	An excellent description of this method is found in Lewis et al. [2000].
Approach	The more compact this point cloud, the more rigid we believe the vertex-joint relationship to be.
Approach	First we choose a joint in the original skeleton that will drive the scaling parameters of the new joints.
Background	This skinning algorithm is notorious for its failings.
Approach	We wish to obtain a good sampling of the character’s skin deformations to fit our underlying model with.
Challenge	It is possible to accomplish this by having an artist sculpt an entire character mesh by hand for every frame of an animation sequence, but this is impractical.
Approach	We choose these extra joints by both examining the places where the standard linear blend model fails and by examining extra character deformations that we would like to capture.
Background	High-end characters often have such complex deformations that they cannot be computed interactively.
Outcome	The ability to generate compactly represented, fast to evaluate, high quality skin approximations from a set of examples is very useful.
Challenge	Aside from the deformation problems associated with using this model, authoring these skins is notoriously difficult.
Approach	We observe that vertices in a character skin typically transform nearly rigidly with respect to some joint.
Approach	For clarity, we present the matrices we solve via least-squares in block form.
Approach	We detect this by comparing the ratio of the largest singular value to the smallest, and issuing a warning if there are any singular values below some fraction of this ratio.
Background	Three examples, Pose Space Deformation, Shape by Example, and EigenSkin [Lewis et al. 2000; Sloan et al. 2001; Kry et al. 2002] use radial basis interpolation of corrections to linear blend skins.
Challenge	Instead, interactive systems restrict artists to a specific character deformation model which is fast and memory efficient but is notoriously difficult to author and can suffer from many deformation artifacts.
Approach	We use four downstream joints on each bone connecting the driver to its children that scale just as the upstream joints do.
Background	This introduces the possibility of rank deficient matrices in the least-squares solutions [Wang and Phillips 2002], especially since the matrix coefficients are usually highly correlated.
Background	More recently, novel skinning methods that start with a simple skin and use sparse data interpolation to correct errors between it and a set of examples have been introduced.
Outcome	We present a framework for extending linear blend skinning that allows us to capture these detailed skin deformations.
Background	This can lead to overfitting, which MWE must take measures to avoid.
Outcome	This paper presents an automated framework that allows character artists to use the full complement of tools in high-end systems to create characters for interactive systems.
Outcome	For instance, character deformations in our model are only driven by the skeleton’s joint parameters.
Approach	Once our system has augmented the input skeleton, we use a fitting procedure to set the parameters of the underlying skinning model to match the example data well.
Challenge	The simple linear blend skinning model commonly used in video games and other interactive applications is very fast and compact but cannot capture the high quality deformations that make convincing characters.
Background	In fact, artists sometimes do this by hand to help avoid wrist collapses.
Outcome	The scaling joints also assume that only the angle between joints is important, so bending the shoulder forward is treated the same as bending it up.
Approach	We would like to find the best vertices and weights that minimize the least-squares difference between the skin and the examples at all the example skeleton configurations.
Approach	Once this driver is chosen, there are two sets of joints that we add.
Approach	This sampling can be very simple to obtain from the user’s perspective—in our case, users must simply invoke a script we have implemented in Maya.
Approach	Another consequence of having one weight per entry in the joint transformation matrices is that MWE skins are not as easily accelerated by graphics hardware as skins created using our method.
Approach	In our system, we take the model used in existing systems as in Equation 2 and include normals in our optimization process.
Background	These techniques are similar to ours in that they take examples as input.
Approach	To demonstrate that our technique can be used on more than just simple arms and legs, Figure 9 shows a rigged upper body and its approximation by our system.
Background	Mesh animation works by storing a large number of deformed models as static meshes—one for each frame of animation.
Background	Such effects are typically created in commercial animation packages which provide very general and powerful tools.
Approach	To recover, we zero these singular values and continue with the fitting process.
Approach	Different characters with different deformations may require a different set of additional joints.
Approach	The value for k may be chosen by the user but in our experience, we have found that 8 works well for our examples.
Background	(Taken together, M i,d −1 v d represents the location of v d in the local coordinate frame of the ith influence.
Approach	Without knowledge of this relationship, our scheme would only be able to reproduce the input frames and would not work well in new poses.
Background	See [Malandain and Boissonnat 2002] for faster methods.
Approach	Our method cannot capture these secondary deformations directly; however, a technique such as DyRT [James and Pai 2002] can be applied to the characters we generate to add secondary animation.
Approach	It is not only important for the geometry in a skin approximation to be accurate, but also important for normals to be well approximated.
Background	Many deformers which drive skins by linking their control points to the skeletal parameters with custom expressions or scripts are also available.
Background	The skin is computed by transforming each vertex by a weighted combination of the joints’ local coordinate frames.
Outcome	In addition, since our skins are computed in the same manner as existing linear blend skins, they are already accelerated by current graphics hardware.
Approach	Once the influence sets have been determined, only the weights and dress pose vertex positions remain (w i and v d ).
Background	Thus, animators typically work with low fidelity versions that only roughly suggest the actual shape of the character.
Outcome	However, this can be accomplished much more easily with our system.
Outcome	To help solve the collapsing geometry problem, our system can automatically add joints that properly interpolate rotations without collapsing.
Background	MWE uses a large number of weights per vertex (12 per influencing joint).
Approach	In our experience, we have found that between three and eight influences works well, depending on the complexity of the character.
Background	Unfortunately mesh animation is only appropriate when the required animation sequences are short and are known a priori.
Approach	Two of them scale up about two axes orthogonal to the bone and a corresponding pair scale down about the two axes orthogonal to the bone.
Approach	If overfitting is a problem, provisions such as those taken in [Wang and Phillips 2002] could also be used.
Approach	These are the coordinate frames associated with all the joints in the character.
Outcome	In this paper, we present an automated method to build character skins that are fast to compute and compactly represented from a set of examples.
Challenge	To be believable, animated characters must deform in plausible ways as they move.
Approach	Thus the additional joints need not be exact.
Approach	An O(n log n) time algorithm is possible.
Approach	This process is then repeated until it converges.
Approach	We then sample this character’s skin deformations by exporting the character’s geometry in several poses.
Outcome	One just exports a set of example meshes deformed by the original skeleton but paired with corresponding poses of the new skeleton.
Approach	In the case of the twisting wrists, we can add an extra joint that interpolates the rotation angle correctly and does not collapse.
Approach	Our extension adds extra joints to the character that are simply related to the existing joints.
Approach	A linear blend skin computes a deformed vertex as described earlier in Equation 1.
Challenge	The resulting loss of volume can also be observed around hinge joints such as the knee and elbow as shown in Figure 2 .
Background	This generality and control means that the computation aspect of high-end characters is highly customizable, tightly coupled to authoring, and potentially unbounded.
Background	Many current interactive systems such as video games only support linear blend skinned characters.
Approach	We start by solving for weights since we have no good guess for them but we know that the initial dress pose vertices are ideal.
Approach	Examining this skinning model, only the M i are predetermined.
Outcome	The computation time for each vertex depends on the number of influences and the number of examples.
Background	For high-end applications, the authoring methods drive skin creation while for interactive systems, computation methods dominate.
Approach	As mentioned earlier, the skinning model we use is an extension of the standard linear blend skinning model.
Outcome	The slowest was the upper body model which has more than 6000 vertices, 50 examples, and 5 influences per vertex.
Approach	Next we hold the weights fixed and solve for vertex positions.
Approach	Our method starts with an arbitrarily rigged character in an animation system.
Outcome	Despite these limitations, our method produces high-quality yet fast and compact skinned characters that work with existing game engines, graphics hardware and other runtime systems.
Background	This technique is also incapable of generating new poses at runtime; for example, to place the character’s hand exactly on a door knob or to make footfalls land precisely on stairs.
Approach	Using these examples, we fit the parameters of a deformation model that best approximates the original data yet remains fast to compute and compact in memory.
Approach	If they are not, lighting calculations will not produce good results.
Approach	We have observed that for many characters, the substructure deformation effects from muscles and tendons are often simply related to the angles between joints.
Outcome	In this paper, we have presented a method for building fast to evaluate, compact representations that produce accurate approximations of deforming characters.
Background	Due to these limitations, mesh animation is losing popularity.
Approach	Both MWE and our technique use an extension of linear blend skinning as an underlying deformation model.
Background	MWE extends linear blend skinning by giving each vertex one weight to each coefficient of each influencing joint’s transformation matrix instead of one weight per influencing joint.
Background	They then find these weights by solving a linear leastsquares problem using a set of examples as input.
Challenge	Another type of effect not easily captured by the simple linear blend model is bulging and denting of skins caused by muscles, tendons, or other substructure.
Background	One technique involves modeling skin substructure such as muscles and tendons to drive the skin geometry [Wilhelms and Gelder 1997; Scheepers et al. 1997].
Approach	To do this, we simply add more terms to the objective function to include the differences between normal vectors.
Background	Character skin deformations are fundamental to character animation and have been addressed for some time in the literature.
Approach	We determine influence sets first for several reasons.
Challenge	Good character animation requires convincing skin deformations including subtleties and details like muscle bulges.
Approach	Thus, we would like to select a small set of good influences.
Background	As games and interactive applications use larger amounts of animation, storing every frame becomes prohibitive.
Background	Their technique used custom programmed algorithms to deform character meshes based on the nature of particular joints.
Approach	This is done by examining the rotation of a joint relative to the dress pose and computing the new joint as the halfway spherical linear interpolation [Shoemake 1985] of this rotation, located at the same position in space.
Approach	Building a skin with our system involves two major steps.
Background	This technique assigns a set of influencing joints and blending weights to each vertex in the character.
Background	In addition to these deformation problems, linear blend skins are very difficult to author [Lewis et al. 2000].
Background	This technique is widely used for interactive applications.
Approach	To do this, we pose the character to exercise all the joints fully and include its extreme poses.
Outcome	Another application of our system is to map a character originally attached to one skeleton onto a different underlying skeleton.
Approach	In order to ensure that the resulting weights are affine, we set w 1 = 1 − ∑ i=2 n w i , and solve for w 2 through w n .
Background	There has been some recent work on fitting skinning models.
Approach	We solve these least-squares problems using the singular value decomposition.
Outcome	Our system also cannot accurately reproduce deformations that are not representable as linear combinations of the transformations expressed in our skeletons.
Outcome	For instance, the scaling joints presented in this paper can only fully capture deformations that are well approximated by a scaling that is linearly related to the cosine of the angle between two bones.
Background	In most recent research, influence set determination has been left to users [Lewis et al. 2000; Wang and Phillips 2002; Sloan et al. 2001].
Outcome	In addition to solving these problems with linear blend skinning, our extension framework can capture other more subtle and detailed deformations required for convincing characters.
Approach	All upstream joints are oriented in the same way, with one axis aligned with the bone as shown in Figure 6 .
Approach	We allow users to scale normals if they wish to change their relative influence on the least-squares solution.
Outcome	This figure also shows this character in new poses from an animation sequence, demonstrating that our resulting skins generalize well to new poses.
Approach	The effect is similar for other muscles in the body.

Approach	Next we carry out cloth-to-skin (or body) attachment through skin fitting, by which the skinning data on the cloth mesh are approximated in such a way that the skinning-driven cloth shape best fits the simulated cloth shape throughout the whole pre-simulated sequence.
Background	Cordier et al. [ 5 ] proposed to segment the cloth into pieces and simulate these by different algorithms, depending on how they lie on the body surface and whether they adhere to it or flow over it.
Approach	When the lowest cost exceeds a threshold, the construction of the patch is completed.
Background	They aim for a neat combination of physically based deformation and geometric deformation.
Background	The problem of simulating the behavior of clothes is one subject the graphics community has been grappling with since almost two decades ago [19] [21].
Outcome	All examples run in real-time at approximately 25 to 50 frames per second (fps), with the coarse mesh deformation process taking about 75 % of the total CPU time.
Outcome	One of our contributions is a geometric wrinkling method that is “trained” by using a pre-simulated cloth sequence, rather than relying on users.
Approach	An optimization approach, such as the one presented by Mohr et al [15], could be adopted here.
Approach	X P and X N are respectively the position of the vertex x and its neighbors; they are all expressed in the SDD coordinate system of x.
Approach	This component gives a cost that increases with the surface area of the patch.
Approach	We first construct the cloth-to-joint relation by analyzing a presimulated sequence of the cloth to be animated.
Approach	Finally, fine details such as wrinkles are also simulated in a data-driven manner, by using the pre-simulated cloth sequence as examples.
Approach	The values α, α P and α N are the interpolation coefficients.
Approach	Collision handling at runtime consists of correcting the position of coarse mesh vertices after every simulation step so that they remain inside their respective hulls.
Approach	In order to reduce the memory usage of the lookup table, the dimension of XN,Pre-simulated was reduced prior to the construction of the interpolator, by Principal Component Analysis [16].
Approach	The objective is to obtain "well-shaped patches", patches that have a circular shape.
Approach	In practice, such case is rare; in general, the largest angle range does not exceed π radians.
Approach	Given enough variation and range of character motion, we expect these hulls to cover the allowable positions of corresponding cloth patches during the runtime simulation.
Outcome	Moreover, performance will increase due to the fact that the smallest number of triangles will be processed for the real-time rendering.
Approach	Due to the computational expenses of solving the full numerical system of the physics-based deformation, we seek simplifications by constructing a coarse mesh representation of the garment.
Outcome	We present a data-driven method for simulating clothes worn by 3D characters in real-time.
Outcome	In practice, the performance lowers down at a low rate as the complexity of the collision hulls increases, which tends to be governed by the number of pre-simulated frames (see Section 5.3).
Background	Several techniques exist for shape interpolation using examples, such as Radial Basis Functions or parametric interpolation.
Outcome	The character walks at a normal pace without any fast movements.
Approach	The reason for this choice is to lower the computation time; geometric methods are in general much faster than physically-based ones [9].
Background	A number of strategies have been suggested, such as using simplifying assumptions for the physics model and/or collision detection [ 7 ] [12].
Approach	Second, we use the pre-simulated sequence to approximate the dynamic behavior of the coarse mesh geometrically wherever possible.
Background	The skeleton-driven deformation (SDD), a classical method for the basic skin deformation is perhaps the most widely used technique in 3D character animation.
Approach	In practice, values of 0.5 cm and 4.0 cm are used to identify tight regions and floating regions, respectively.
Approach	The list of objects that can potentially interact with clothes and the way these objects interact are defined at the preprocessing stage and cannot be changed during the realtime simulation.
Background	As indicated by the authors, these methods are not intended to provide a physically-correct cloth animation.
Approach	The idea is to use the analysis of the presimulated sequence to identify the region largely explained by joint movement and to replace the physics based simulation with geometric methods wherever possible.
Approach	It starts, prior to realtime simulation, by analyzing cloth behavior in relation to the underlying skeleton movement from a pre-simulated sequence of the cloth obtained using any high quality offline simulators.
Approach	Deciding a good granularity in the coarse mesh is hand-tuned, so that a neat compromise between the simulation quality and the computation load is found.
Challenge	Moreover, determining the location and shape of wrinkles is left to CG artists.
Outcome	More generally, the clothes are unable to interact with objects other than those that have been taken into consideration during the pre-processing phase.
Background	This consideration was partly inspired by the hybrid real-time simulation method proposed in Cordier et al. [ 5 ], where a hybrid deformation method is used to combine dynamic surfaces with Skeleton-Driven Deformation (SDD).
Challenge	Dynamic simulation of complex deformable models, however, can easily involve thousands of degrees of freedom.
Outcome	This paper presents the first report of a practical and efficient method for handling real-time simulation almost automatically.
Approach	For every vertex x in a patch, the interpolator function takes the associated mass point in the coarse mesh, and its neighbors as input.
Challenge	Relatively little emphasis has been placed on the separate problem of how to achieve real-time performance in simulating cloth.
FutureWork	Therefore, for a cloth vertex, it could be possible to compute several collisions hulls in relation to different objects in the scene and to compute their intersection for real-time collision detection.
Approach	• The “cocktail” dress ( Figure 18 ) is a relatively complex model; the bottom is composed of two layers of tissues and has folds made of large number of vertices, inducing many self collisions.
Approach	We have used linear interpolation in which coefficients are defined by multi-linear regression on the pre-simulated animation, since it provides satisfactory results at a very low computation cost.
Outcome	The residual values of the fitting provide useful information on how the garments behave in relation to the body.
Approach	The real-time computation of global cloth movements is obtained with a mass-spring system together with the collision response and post-correction described above.
Approach	This condition is maintained thank to the data-driven post-correction (see Section 5.3).
Background	Researchers have concentrated mainly on two aspects of real-time cloth animation: simulating the physical properties of garments and collision handling.
Approach	We wish to keep the computation cost constant regardless of the duration of the pre-simulated sequence.
Challenge	For example, a physics-based simulator would require several minutes to compute one frame of a cloth model worn by a character.
Background	The latter point has attracted much interest in the field of real-time applications, since it requires high computation power.
Approach	In our case, however, our SDD method is non-linear and therefore the linear regression as adopted by Mohr et al is not beneficial.
Background	Several algorithms have been proposed to process robustly collisions in cloth simulation [21] [22] without reaching real-time performance.
Background	The recent advent of cloth simulation techniques has matured enough to produce highly realistic cloth movements on animated characters.
Outcome	For some body movements, the skin surface may slightly intersect the cloth surface.
Approach	In our approach, three regions are identified from the residual values of the skin fitting process ( Figure 5(d) ): those that potentially interact with several joints, those that are loosely attached to the skeleton and those that are rigidly attached to the skeleton.
Approach	To enforce the regularity of coarse mesh, which is one condition for obtaining efficient deformation with the mass-spring system [21], we consider two following components.
Outcome	The best quality is achieved when the range of the body motion in the presimulated sequence is approximately 30 % larger than the one used in the real-time simulation.
Approach	We found that the classical SDD can be greatly improved by replacing the linear combination of the matrices by the matrix operator defined by Alexa [ 1 ].
Approach	Although developing a new SDD method is not our main goal, the way the skin deforms is important in our framework since natural looking cloth shape also requires natural skin shape.
Approach	Similarly, a false assignment of region 3 into region 2 would result in the garment crossing the legs.
Approach	The velocity is updated as well.
Background	Several improvements have been proposed to reduce instability, such as the Verlet integration [11] and the explicit Euler combined with inverse dynamics [17] [20].
Approach	Pre-simulated sequences obtained by the cloth simulator of Volino et al [21] were used in our preprocessing.
Outcome	The key contributions of this paper are (1) efficient collision handling that prunes out potentially colliding objects by using the off-line simulation sequence as examples; (2) data-driven fix-up process for the coarse mesh simulation that deduces the gross behavior of the cloth; and (3) geometric approximation of the fine mesh deformation, responsible for details in the shape of the cloth such as wrinkles.
Challenge	The main difficulty is defining a fold function that can simulate all kinds of wrinkle patterns.
Approach	The coarse mesh is used to deduce the gross behavior of the cloth in a data-driven manner, based on the input pre-simulated sequence.
Challenge	Collision detection is usually one of the bottlenecks in real-time animation.
Approach	Intuitively, floating garments such as a skirt, cloth patches may collide with several joints; collisions need to be computed on these regions.
Approach	In other word, the wrinkle interpolator can only work for the input range for which it has been trained.
Challenge	The problem is particularly acute in the case of clothes because these objects are highly deformable.
Approach	To show that the simulator faithfully recreates the cloth movement used for training, we compared the real-time simulation with the presimulated one in the first video.
Approach	Despite its simplicity, linear interpolation works fairly well provided a sufficient number of pre-simulated frames for the multi-linear regression.
Approach	At each frame of the simulation, we compute the coarse mesh by a mass-spring system with the implicit Euler numerical solver [ 2 ].
Outcome	To measure the simulation quality, we compared our simulation results with the pre-simulated sequence, using a deformation metric.
Approach	Notably, the floating regions (colored in red in Figure 5(d) ) are attached to the root of the character, as shown in Figure 5(b) ; this is contributable to the fact that these regions are large in volume and they rarely collide with limbs during the walk motion.
Approach	The use of SDD for these regions makes it possible to reduce the number of mass points even further.
Approach	The first three principal components, which describe 95 % of the average variability of the data, are used.
Approach	At each pre-simulated frame, we calculate the difference between the SDD motion model and the presimulated cloth model in the local coordinate system of the SDD.
Background	Wrinkles can be generated either by tessellating the cloth mesh [12] or rendering details on texture using bump mapping [9].
Approach	Ideally, the local shape (e.g. position of the vertices in relation to their neighbors) should be a blend of those of the pre-simulated animation.
Approach	The cloth-to-joint relation enables us also to optimize collision detection by restricting the collision check to a small area around each vertex of the coarse mesh.
Approach	This effect is achieved by focusing on the analysis of cloth movements in relation to its associated skin surface, and adopting a learning strategy.
Approach	The positions of the vertices are corrected after every simulation loop.
Outcome	As expected, the quality of the simulation depends on the number and variety of examples – the pre-simulated sequence in our case.
Background	Probably the most common technique for simulating the physical properties of clothes is the particle system.
Approach	In this work, we propose a data-driven collision detection method; we use the pre-simulated sequence to localize the collision checks to neighboring cloth regions that have high probability to collide.
Outcome	Consequently, our cloth simulator is able to construct a model for real-time animation without user intervention and can deal with different types of clothes from tight to floating with low computation consumption.
Approach	Given a position of neighbors X N,Input as input, the interpolation computes the corresponding X P by a weighted summation of the X P,pre-simulated values, each weight being computed from the Euclidian distance between X N,Input and all the X N,Presimulated values.
Approach	By modifying the significance of this component, we can easily control the number of vertices to be simulated with the physically-based deformation (see Figure 4 ).
Outcome	At runtime, using these analyses, our simulation process provides both visually pleasing results and performance, as long as the motion of the character remains sufficiently close to the original sequence used for the pre-computation.
Outcome	Our simulator works well for interpolation (i.e. joint angles within the range of those of the pre-simulated sequence) but often fails for extrapolation.
Background	As recognized in earlier works [9] [13], wrinkles can be efficiently animated with a geometric method as they are geometric in nature.
Background	Others have noted that wrinkle deformation is geometric in nature and therefore can be computed with a geometric method.
Challenge	Simulating large models directly would therefore be computationally impractical.
Approach	This is necessary as we want to compute the deformation of the cloth surface in relation to the skin surface.
Background	This method works first by assigning a set of joints with weights to each vertex in the character.
Background	Unlike explicit Euler integration, the implicit Euler method offers higher stability while using large time-steps and clothes with stiff mechanical properties.
Approach	The pre-processing stage involves generating the coarse mesh, computing the cloth-to-joint relation, and constructing the collision hulls and the interpolation functions for data-driven coarse mesh deformation and wrinkle animation.
Approach	By using collision hulls, collision tests are restricted to a small area around the patch; the overall computation can be significantly reduced in comparison to classical collision detection methods in which collisions are computed between the whole skin and cloth surface.
Outcome	Unlike previous works, our simulator allows a much higher degree of interaction, as it is often needed in animating clothes on moving characters.
Approach	Both the mass-spring system and collision detection have been rewritten to take advantage of the pre-simulated sequence of the clothes to be animated.
Approach	On the other hand, the local movements of some cloth patches (like underwear) are negligible and these patches can be considered as being attached rigidly to the skeleton.
Challenge	However, real-time simulation has been largely unexplored until now.
Outcome	Subsequently, real-time animation of fully dressed human could be generated, which would be suitable for applications such as games where visual plausibility is more important than accuracy.
Approach	Unlike previous methods, however, our wrinkling function is not hand-drawn, nor geometrically approximated, but rather trained from on the analysis of the pre-simulated sequence.
Background	By blending of pre-computed orbits rather than using a mass-spring system, previous unseen results could be achieved, such as garments with stiff mechanical properties in real-time.
Approach	Collisions are handled by collision hulls the position of which is computed by our SDD.
Challenge	Cloth animation depends on a high number of parameters and therefore a data-driven approach is difficult to adapt.
FutureWork	The current mesh model of collision hulls could be replaced by implicit surfaces or voxel maps.
Approach	• The “evening” dress ( Figure 14 ) is chosen to demonstrate our wrinkle interpolator on large garment regions.
Approach	The deformation of tight regions is directly computed with the SDD (line 2 and 6 on Figure 6 ).
Approach	These are built once at the beginning of the simulation (prior to the runtime simulation) after the SDD has been computed on the coarse mesh, using the pre-simulated sequence.
Challenge	When observing the behavior of garment worn by a character, there are considerable correlations between the body motion and the movement of the garment.
Approach	Moreover, unlike the simulator used for the pre-simulated cloth sequence, the simplified mass-spring model does not accurately simulate the bending and shearing properties of the fabrics [21].
Background	Simulation process is broken down into calculating the internal forces and solving the system of Partial Differential Equations (PDE).
Challenge	The primary focus of this paper is the development of a fast cloth simulator for real-time applications.
Approach	Our simulator is based on two levels of deformation: the first deduces the gross cloth behavior by working on a coarse mesh with a physics-based approach whereas the second generates wrinkles on a fine mesh with a geometric method.
Approach	This makes our wrinkle parameterization invariant of all joints of higher hierarchy than the currently influencing joint.
Approach	We begin by constructing a coarse representation of the given cloth model that will drive the gross behavior of the simulated garment.
Approach	The simulation run on the coarse mesh hardly reproduces the gross movement of the original cloth because the initial mesh has been significantly simplified (from 4000 to a few dozen vertices) and the topology has been modified.
Outcome	It measures the still shape and movement by the sum of edge length difference and the mass velocity difference over the cloth mesh.
Approach	Note that the operator is not continuous.
Approach	We used constrained dynamics [22] to handle the collision response (i.e. modification of position and velocity in response to collision detection) at line 15.
Approach	The generation of a patch starts by finding a vertex that has not yet been attributed to a patch that is already generated.
Approach	It is not defined for a rotation of 2π radians between the matrices to be blended.
Approach	(2) A coarse mesh representation is obtained by combining a set of vertices in a patch into a single mass point located at the center.
Background	Some other methods exploit graphics hardware to compute collisions on bump maps [20]; others use implicit surfaces to check collisions on the body [18], or voxel trees, which partition the space hierarchically [14].
Background	A recent work by James et al. [10] suggests a different approach by adopting a data-driven method.
Approach	Its new value is set to the sum of the original velocity and the velocity due to the modification of the vertex position (line 11 on Figure 9 ).
Challenge	These correlations are especially clear for some clothes like tight shirts and trousers.
Approach	The basic idea is to use the pre-simulated results as examples and find the error-minimizing skin data through optimization.
Background	Very recently, James et al. [10] resented such an approach, where physics-based deformation and collision detection are both handled in a unified framework.
Approach	To effectively optimize the physics-based deformation, which is the bottleneck of the simulation, we use a coarse representation of the cloth mesh to drive the gross behavior in simulation.
Background	Kang et al. [12] proposed further optimization with a direct update formula for the positions and velocities of the cloth vertices.
Background	The basic idea is to build an interpolation space filled with a set of pairs of input parameters and the targeted graphical objects.
Approach	We measure and validate the proposed real-time cloth simulation method along three criteria: the variety of clothes to be simulated, the computation speed and the range of body motion in the pre-simulated cloth sequence.
Outcome	The computation cost of this interpolator grows as the number of pre-simulated frames increases.
Approach	After a sweep, we get a set of points that cover the path a patch takes during the simulation.
Challenge	Again, the main challenge here is obtaining the highest possible realism while maintaining acceptable computation load, in order to meet the real-time requirements.
Background	Performance is slightly slower, but only pre-processing performance is affected and not runtime performance.
FutureWork	First, the approach could be extended to simulating other physics-based models such as hair and fluid.
Outcome	A data-driven approach for real-time processing of clothes, particularly suitable for simulating dresses worn by virtual characters, is proposed.
Approach	This also keeps the smoothness of the boundaries between patches.
Approach	Note that that each patch is associated with a vertex on the coarse mesh.
Outcome	In the second video, different body movements from those of the training were supplied as input to our realtime simulator and the results are compared with the ones generated with a high quality simulator.
Approach	Apart from the position, our SDD computes the local transformation matrix of the vertices, the simulator to be optimized at least for the two following points: limiting collision checks to a small area around the vertices, and the geometric wrinkling which is processed in the SDD local coordinate system.
Approach	In our method we take advantage of these relationships to reduce the computation load on the mass-spring system and collision detection.
Outcome	Unlike that method, however, our method exhibits significantly more efficient and realistic behavior.
Approach	We then reduce the number of vertices to be physically simulated by identifying the garment regions in which the shape follows that of the underlying skin.
Approach	The smallest convex hull that contains all these points is generated for every patch using the “Quickhull” algorithm presented by Barber et al [ 3 ].
Outcome	Similarly, the same problem may arise for self-collisions on clothes.
FutureWork	We also believe that the work on collision hulls is promising.
FutureWork	There are many interesting avenues for future work.
Approach	This is achieved by constructing a set of functions of local shape deformation.
Approach	The deletion of the skin triangles covered by the garment surface can partially correct this drawback.
Approach	We used our framework to different types of clothes, as shown on the demonstration video.
Background	Unfortunately, this method is notorious for its instability when using large time steps and stiff equations.
Approach	Function minimization techniques such as Powell’s method [16] can deal with non-linear functions.
Background	The idea of building an interpolator from examples or pre-simulated data has proven to be a valuable tool in a variety of areas of CG, e.g. for modeling a variety of human body shapes and for motion synthesis.
Background	Using frame coherency to reduce computation cost has been explored by Zhang et al [23].
Outcome	As expected, the duration of the pre- simulated sequence is not a factor of the runtime computation speed.
Approach	There are two requirements which the method should fulfill for this particular use: first, it must overcome the undesirable effect of vertex collapse as shown in Figure 3(a) .
FutureWork	We also believe that the precision of the collision detection could be improved by replacing the convex shape by a surface to follows more closely the trajectories of the vertices.
Approach	We have found that best simulations are obtained when patch area covers one or two cloth wrinkles.
Background	However, they show little degrees of freedom (DoF) to the clothes under simulation; Instead of resorting to a data-driven approach for the entire simulation, we seek a neat combination of a data-driven approach with the mass-spring system.
FutureWork	Finding a method to update the list of possible interacting objects automatically could be a subject for future research.
Approach	Note that the collision hulls are generated for loose and floating garment regions only.
Approach	A list of potentially colliding body patches is defined by selecting those that approach within a certain distance of the floating regions during the pre-simulated cloth sequence.
Background	Unfortunately, the simulation quality is sacrificed in favor of computation speed, due to the approximations employed in these models.
Background	The location of a vertex is then calculated by a weighted combination of the transformation of the influencing joints.
Background	The history of research on real-time cloth is relatively recent.
Outcome	Note that the cloth simulation is also restricted to clothes worn on bodies.
Background	Desbrun et al [ 7 ] proposed solving the linear system with a precomputed inverse matrix.
Approach	We denote the vector position of a vertex P as XP, and the vector position of its neighbors as X N R 3n (n: number of neighbors of P).
Background	The explicit Euler method [ 2 ] has been one of the first numerical solvers.
Approach	The threshold values are chosen in a way that the coarse mesh deformation remains sufficiently close to the pre-simulated sequence.
Approach	They are defined by multi-linear regression on a set of pairs (positions of coarse mesh vertices, fine mesh vertices) extracted from the pre-simulated cloth sequence.
Approach	The collision hulls of tight regions are small enough to be approximated by a single point.
Background	These techniques do not suffice, however, when simulating fully dressed virtual characters in real-time, leaving the topic unexplored.
Approach	Therefore, an additional collision check is required to handle the interaction of the clothes with the whole body skeleton.
Challenge	The idea is to use this analysis to find an optimal combination of physics-based simulation and geometric approximation of the simulator; potentially colliding regions are defined on the cloth such that they will hold true for the skeleton movement that closely matches that of pre-simulated sequence.
Approach	• Minimizing the "shape factor": Square Root (Surface Area)/Contour Length.
Approach	We approach the problem by modifying the behavior of the mass-spring system through a fix-up process (similar to [14]) where the position and velocity of the coarse mesh vertices are modified in order to maintain the cloth shape as close as possible to the original one ( Figure 7 ).
Approach	Post-correction is accomplished with a function that evaluates the "ideal" position of the vertex given the position of its neighbors connected by the edges.
Approach	In this work, we choose to represent the wrinkle displacement in the local coordinate system used for SDD.
Approach	For each vertex, we construct an interpolating function F Post by using a set of (X N,Pre-simulated , X P,Pre-simulated ) pairs extracted from each frame of the pre-simulated sequence, where X N ∈R 3 (n: number of neighbors of P) denotes the position of the neighbors and X N ∈R 3n the position of the vertex in question.
Challenge	We consider that the gross cloth behavior is driven mainly by two separable contributions: the skeleton-driven movement of the character and the mechanical properties of the cloth.
Approach	The final mesh is then obtained using the winkle shape interpolator and the computed geometry of the coarse mesh.
Approach	To prune unnecessary collision tests, we pre-compute what we term “collision hulls” that exploit the skin-tocloth relation obtained from the pre-simulated sequence.
Outcome	The pre-processing of all the cloth models took less than 10 minutes.
Background	The implicit Euler method presented by Baraff et al. [ 2 ] performs the computation not by using the derivative at the current time, but the predicted derivative at the next time step.
Approach	A condition of a good working interpolator is that the input (i.e. position of the coarse mesh vertices) should be within the range of the pre-simulated data.
Approach	The vertex with the lowest cost is selected.
Approach	Second, the method must provide an easy way to compute the local coordinate system for each skin vertex.
Approach	We proceed until no vertices can be found to start a new patch.
Approach	For example, a false assignment of loose region into tight region would produce elongated deformations instead of slipping garment over the skin, and therefore generate an overly deformed coarse mesh, which is beyond the training data of the wrinkle generator.
Approach	The patch is then grown by adding neighboring vertices one after the other.
Outcome	While offering high computation speed, the cloth simulator cannot handle some cloth movements such as those appearing during dressing or undressing.
Outcome	The main reason for this limitation is collision detection, which does not allow the clothes to have different locations on the body from those calculated in the pre-simulated sequence; this makes the clothes being attached rigidly to the skeleton.
Outcome	We used our framework to produce visually pleasing motion of a wide range of clothes.
Approach	A common solution is to construct a lookup table filled with values pre-simulated by the interpolator on grid sampling.
Background	Another approach to fast garment deformations is the hybrid approach.
Outcome	With less than 70 pre-simulated frames, the real-time simulation loses its quality.
Approach	By doing so, we bring the deformation of the mass-spring system closer to the original cloth behavior.
Approach	• The “Jeans” outfit is a good example of a model where the SDD based geometric approximation can reduce the number of mass points substantially by simulating only a few regions that contribute significantly to the dynamic behavior.
Approach	To select a new vertex into the current patch, we evaluate each neighboring vertex that has not been already assigned to a patch, using a penalty function.
Outcome	Our simulator behaves fairly well on a wide variety of clothes, including those with highly stiff mechanical properties.
Outcome	However, the method may introduce flaws in simulation for some tight clothes, due to the approximate handling of collision detection.
Approach	The coarse mesh is generated by simplifying the original cloth mesh through segmentation.
FutureWork	By doing so, it may be possible to process collisions on a higher number of objects while maintaining low computation cost.
Approach	Finally, we use the cloth shape of a pre-simulated cloth sequence to correct the physicsbased simulation of the coarse mesh in order to match the original cloth behavior more closely.
Approach	Our approach to that problem is a data-driven mass-spring system: the simulation is corrected with a set of functions built from the pre-simulated animation.

Challenge	• The system should allow direct manipulation of the desired deformations [ 33 ].
Outcome	We expect that this algorithm will be a useful complement to current techniques.
Approach	With small λ many of these schemes can serve as scattered data interpolants; reference [ 5 ] is a good introduction to these approaches.
Outcome	The setup cost of the algorithm is insignificant, and the synthesis cost is only slightly more than that of shape interpolation, so real-time synthesis is possible at effective resolutions on current hardware.
Approach	In such a case a new pose space is started, and the δ is computed as a delta from the previous layered PSD synthesis rather than from the base model.
Background	Early approaches to animation were purely kinematic; an emphasis on physically based modeling appeared in the literature later.
Outcome	PSD handles all these cases simply and uniformly.
Approach	A pose is defined as the configuration of any pose controls (joints or abstract manipulators) that have changed from their default values.
Challenge	Of course the key shapes could be deformed to the moving articulated figure using some other algorithm, but this defeats the purpose of proposing shape interpolation as the means of obtaining the deformation in question.
Approach	This ensures that the previous deformations are interpolated while allowing the artist complete freedom in determining the extent of the deformation and the associated pose controls.
Challenge	The blending of rigid shapes is inconsistent with regions of the body that are bending under the action of an underlying skeleton, however.
Approach	One or more deformations will then be interpolated in this subspace using a scattered data approach.
Background	Unfortunately this simple scheme has some potentially undesirable properties.
Approach	We now have enough criteria to select a particular interpolation scheme.
Background	Van Overveld described a two-dimensional animation system in which animation is controlled by a skeleton and character deformation is driven from this skeleton through a scattered interpolation [ 20 ].
Background	On the other hand, animators consider detailed control of the animation to be part of their craft and are quite happy to have interpolation parameters exposed to them.
Approach	While there is an issue of commutativity, in our experience artists consider this iterative layered refinement to be a natural process.
Background	Some of the most impressive examples of geometry-based (as opposed to image-based) human and creature animation have been obtained in the entertainment industry.
Approach	The location in pose space is determined from the concatenated relative degrees of freedom of the pose controls (simply interpreted as independent dimensions).
Background	Shepard’s method [ 1 , 2 ] is a frequently employed scattered data interpolation scheme in computer graphics.
Background	Chadwick et. al. demonstrated expressive three-dimensional cartoon characters but deformation of a realistic character was not shown.
Approach	As such the expensive energy functional and non-convex schemes are not necessary.
Background	This work is similar in spirit to ours but differs in that it used the image plane as a global interpolation domain rather than introducing a pose space.
Approach	Once this uniform representation is identified, previously disparate deformation types can be accomplished within a single unified approach.
Approach	The most recently defined deformation may extend too far (or not far enough) in pose space, however.
Background	In fact radial basis functions have a universal convergence property similar to Fourier series, though the convergence definition is different.
Background	By writing the delta shape form as (1 − 1 w k )S 0 + 1 w k S k it is clear that the space of achievable shapes is identical in both variations.
Background	The interpolant is a linear combination of nonlinear functions of distance from the data points:
Challenge	• In addition, we target a conventional animator-controlled work process rather than an approach based on automatic simulation.
Background	The short film Tony de Peltrie [ 3 ] popularized the use of shape interpolation for facial animation.
Background	Several papers by Wilhelms and coworkers have shown anatomically representative human and animal models.
Background	If N values of d are available then the weights can be easily solved by a linear system; this can be derived either by least squares fit or by subspace projection.
Background	While this viewpoint is valid, in practice it is perhaps excessively general, for example, a skeleton is merely learned rather than being an intrinsic part of the model.
Challenge	In fact, the SSD algorithm can be easily identified in animations by its characteristic ‘collapsing joint’ defect (Figures 1, 2).
Background	There is a rich literature of schemes for optimizing radial basis parameters including σ [ 4 ].
Background	The specification and animation of surface deformation remains an active area of investigation [ 17 , 10 ].
Approach	Since the unknown edges may exist (or not exist) at any location in the domain, all combinations of possible edge locations must be considered and the interpolation cost is prima facie exponential in the surface resolution.
Background	Several papers consider animation (and indeed image synthesis in general) as a special case of neural net learning and interpolation/extrapolation [ 14 , 15 , 21 ].
Background	The algorithm is unpublished but is subsumed by more general published schemes such as [ 23 ].
Approach	The deformation is controlled by the user through the weights w k .
Approach	The preceding description maps a k-dimensional input space (arbitrary k) to a one dimensional range, i.e., it is the k-dimensional version of a height field.
Outcome	In PSD the key shapes are positioned as desired in a space of desired dimensionality.
Approach	As discussed above, the interpolation domain is (a subset of) the pose space of an articulated character, or equivalently the space defined by some set of parameters such as facial controls.
Background	The first major shortcoming of SSD results directly from the fact that the deformation is restricted to the indicated subspace.
Outcome	To illustrate these comments consider Figure 7 , which abstractly represents both SI and PSD with an identical set of expressions (neutral, half-smile, full-smile, frown).
Background	A variation of this technique uses a single base shape S 0 and a number of delta shapes, S 0 + k=1 w k (S k − S 0 ).
Approach	Based on the evaluation the artist may decide to sculpt additional poses as needed to achieve the desired motion.
Approach	This issue does not arise in our application, however, since the animator decides where in the parameter space to sculpt a pose (effectively deciding the basis function placement).
Approach	The δ values for the deformed vertices are computed (again in the local coordinate system) and they are saved in a database together with their corresponding location in a pose space.
Outcome	Pose space deformation generalizes and improves upon both shape interpolation and common skeleton-driven deformation techniques.
Approach	Our scheme can be bootstrapped on top of an existing software system: the model is posed as desired and the desired surface at that pose is sculpted.
Background	On the other hand, the algorithms are specific to particular types of joints and are perhaps too simple to portray the complexity and individual variability of real anatomy.
Approach	We have found that this potentially abstract parameter is comprehensible so long as it is possible to explore the effect of different values.
Background	Far from the data the weights will be approximately the same, d(∞) ˆ = w ∞ d k /w ∞ 1 = d k /N , i.e. the interpolated surface converges to the average of the data values.
Outcome	The algorithm introduced in the subsequent sections removes the need for such layered fix-it approaches and permits direct specification of the desired deformations.
Approach	If n = 2 pose controls are active and each has three degrees of freedom then a 3(n − 1) pose space is defined, and the particular position of the controls defines a point in that space.
Approach	The artist first positions some set of pose controls and then sculpts a deformation for that pose.
Approach	Although it would be desirable to allow deformations to change both continuously and discontinuously with respect to the pose space, creature deformations that are discontinuous with respect to pose seem unlikely.
Approach	The distance can be generalized to Mahalanobis distance (effectively rotating and stretching the basis function) [ 4 ].
Outcome	Appropriate applications include animation of facial and body deformation for entertainment, telepresence, computer gaming, and other applications where direct sculpting of deformations is desired or where real-time synthesis of a deforming model is required.
Background	Continuous deformation of a character skin was first addressed in Parke’s pioneering facial animation work [ 26 ].
Outcome	In practice this has been considered the major difficulty in applying SI when high quality animation demands large numbers of basis shapes [ 38 ].
Challenge	• The locality of deformation should be controllable, both spatially and in the skeleton’s configuration space (pose space).
Approach	At a minimum axis-aligned scaling of the falloff should be available; we have not experimented with Mahalanobis rotation of the basis.
Challenge	These issues, which will be detailed in the next section, lead us to look for a more general approach to surface deformation.
Background	This simple algorithm has been repeatedly conceived and appears in commercial software packages under several rather uninformative names such as skinning, enveloping, etc.
Approach	With p > 1 the interpolation surface is once differentiable.
Background	Pose space deformation is a shallow, purely kinematic approach to deformation (i.e. without reference to underlying forces, mass, volume), and it has consequent disadvantages.
Approach	The model is now moved to an arbitrary pose.
Outcome	Similarly a sculpted pose that represents the simultaneous activation of several parameters (e.g. happy but surprised, or smiling with a wink) can simply be saved at the appropriate location in the pose space.
Challenge	These techniques are not yet suitable for all applications, however: while a purely image-based approach can achieve very realistic images, this advantage may be lost if one needs to introduce geometry and surface reflectance in order to re-light characters to match preexisting or dynamically computed environments.
Background	Deep models promise universally accurate simulation, and the importance of representing humans justifies the needed effort.
Challenge	While shape interpolation is well-liked by production animators, it is not suitable for skeleton-driven deformation.
Background	While employed at Industrial Light and Magic the first author of the present paper developed a system that attempted to blend shape interpolation and SSD algorithms; a small portion of it remains in use in their well known Caricature animation system.
Background	The Wires technique [ 22 ] is one interesting recent contribution; this approach is notable in providing a direct manipulation interface in a form immediately familiar to sculptors (armatures).
Approach	The pose space is the space spanned by the variations of these controls.
Background	These efforts traditionally use shape interpolation for facial animation and a standard but variously-named algorithm that we will term skeleton subspace deformation (SSD) for basic body deformation [ 25 , 9 ].
Outcome	The advantages of this algorithm include improved expressive power and direct manipulation of the desired shapes yet the performance associated with traditional shape interpolation is achievable.
Approach	Surfaces can of course be interpolated by allowing different combinations of the same basis functions in different dimensions, i.e., vector valued w k .
Approach	A scattered data interpolation method is required because deformations will be sculpted at arbitrary (rather than regularly spaced) poses.
Background	Shape interpolation (also called shape blending and multi-target morphing) is probably the most widely used approach to skin deformation for facial animation [ 3 , 18 , 9 ].
Approach	Any control vertices that have moved from their rest position are found.
Background	Chadwick, Haumann, and Parent [ 7 ] introduced a multi-layered and physically inspired approach to skin deformation.
Approach	Deformations in a shoulder area will need to consider two or more degrees of freedom.
Approach	On the other hand a smooth φ() will result in a smooth interpolant (a weighted sum of continuous functions is continuous).
Background	The authors of these approaches acknowledge that producing anatomically plausible models is a daunting task, however.
Outcome	In the SI side of the diagram expressions are arranged as independent (but not orthogonal) dimensions as required by SI.
Approach	Similarly one can imagine setting up a dial that causes the character to morph; this would of course require a significant set of additional deformation poses.
Background	In this work, control vertices were deformed by custom algorithmic implementation of carefully selected high-level parameters (‘raise-upper-lip’, etc.).
Challenge	For one, the interpolation is not always smooth.
Approach	This is a well known issue; well behaved transformations are fundamental and are hopefully addressed early in the development of any character animation system.
Background	In Wilhelms and Van Gelder [ 36 ] several classes of muscles are algorithmically modeled with attention to volume conservation; skin is a spring mesh anchored to underlying tissue or bone in appropriate areas.
Challenge	Artists with a poor understanding of the underlying algorithm have difficulty distinguishing between results that can be further improved by adjusting weights and results that cannot be improved since the desired result lies outside the achievable subspace, resulting in the impression of unpredictability (“sometimes adjusting the weights helps, sometimes it doesn’t”).
Outcome	Also it is incurred at a convenient time – during setup (as a pose is saved) rather than during synthesis.
Approach	The artist also assigns a falloff (Gaussian σ), either as a symmetric radius across all controls or to each control individually (axis stretched falloff).
Background	The algorithms in this early work do not suffer the ‘collapsing elbow’ characteristic of the SSD algorithm (below).
Approach	In these schemes the interpolated or approximated surface is found as the minimum of a functional such as where the first term penalizes deviation of the surface d ˆ from the available data d and the second regularizing term votes for surface smoothness e.g. by integrating the squared second derivative of the surface.
Background	In particular, accuracy is reliant on the modeler/animator rather than being guaranteed by the simulation.
Challenge	An articulated model such as a human will typically have a number of different deformation subspaces, each with one or several deformations; the deformations in different subspaces may overlap spatially e.g. to simulate the influence of different muscles.
Approach	The neck/chest/leg blend area of many quadrupeds is a more complex case – the motion of the skin surface in these regions may depend on the relative configuration of several leg bones as well as the rib cage and possibly the neck region of the spine.
Challenge	This problem is extreme in the case of simulating the twist of a human forearm (the pose taken in turning a door handle, Figure 3).
Approach	In some of the most powerful formulations of scattered interpolation the regularizer is considered to hold everywhere except at an unknown set of edges – this is the piecewise-smooth prior desirable in image reconstruction.
Background	Drawbacks of this work included both a complicated dependence on the details of SSD and its overall conception as a “correction” to SSD.
Approach	The new deformation’s pose space may, however, be different from the previous spaces associated with the vertex!
Outcome	• In shape interpolation the key shapes and the animation parameter space are one and the same – the keys define the axes of the animation parameter space.
Background	Nedel and Thalmann [ 19 ] simulate the surface deformation of muscles using spring mesh dynamics; a modeled skin cross section is reshaped by a ray-casting procedure that finds the maximum displacement of the underlying tissue.
Background	Recent sophisticated approaches allow a hybrid of animator-controlled and physically governed animation as needed.
Background	Most recently, several groups have undertaken ambitious efforts to produce anatomically inspired multi-layered models of animals and humans with considerable verisimilitude.
Background	The region and shape of deformation is algorithmically defined in each of these approaches.
Challenge	SSD algorithms consequently have the reputation for being tedious and difficult to control.
Background	Free form deformation has been approached from several distinct perspectives.
Approach	This ‘deformation’ is associated with the joints or other parameters that have moved from their default positions to create the particular pose.
Approach	This is done in the local coordinate frame, i.e., rigid body articulated motion results in zero δ.
Outcome	On the other hand, PSD allows one to sculpt intermediate expressions (half-smile) and situate them half-way along the relevant (full-smile) axis.
Outcome	It addresses the previously mentioned drawbacks of shape interpolation and SSD while retaining the simplicity and performance associated with these techniques.
Outcome	On the other hand, our algorithm has clear advantages with respect to simplicity and generality, direct manipulation, real-time synthesis, and other criteria listed in the introduction.
Background	In practice animators object to the linear nature of the interpolation [ 34 ] and have sometimes compensated by sculpting new key shapes as often as every three to five frames [ 38 ].
Challenge	Real time synthesis is also required for applications such as avatars and computer games.
Background	Magnenat-Thalmann et. al. developed algorithms for each of the various joints in the hand.
Approach	At this point the model interpolates through the previously defined deformation(s).
Challenge	The performance of current anatomically based models prohibits animation preview and other real-time applications such as telepresence and gaming (one published result is several orders of magnitude slower than real time), and the effort needed to produce an anatomically accurate model is not always justified, nor even appropriate if the model is of a fanciful creature whose surface appearance may be inconsistent with any plausible internal anatomy in any case.
Approach	(At the boundary of several surface patches there may be shared vertices that need to be coincident to maintain surface continuity.
Challenge	Film and entertainment applications require fanciful creatures that fall outside the scope of image-based approaches.
Approach	The interpolation is done independently for each control vertex (but see additional details below); in our experience using patch surfaces this has not been problematic.
Background	Other researchers have investigated modeling the underlying body tissues in greater depth [ 27 , 24 , 8 , 35 ].
Outcome	• The animator’s task in PSD is to choose the interpolation path (and adjust interpolation parameters such as falloff if desired).
Approach	In concept the range of the interpolation function could simply be the desired movement of the surface control vertices.
Challenge	Shape interpolation also has some drawbacks for its intended role of facial animation.
Challenge	The problem of realistic facial animation is being actively and successfully addressed by image-based and hybrid techniques.
Background	Several published algorithms and commercial packages combine aspects of skeleton-driven deformation and shape interpolation in ways that anticipate our approach.
Approach	The falloff σ is also specified explicitly by the animator, as described below.
Challenge	We also wish to directly sculpt the desired deformation at various points in the parameter space, rather than working in a more abstract space such as the coefficients on various coordinate frames as required by the SSD algorithm.
Outcome	The same set of shapes can be used in both approaches.
Approach	With n poses three matrices of size n must be inverted for each surface control vertex.
Background	Komatsu [ 13 ] and Magnenat-Thalmann et. al. [ 23 ] demonstrated human body deformation driven by an underlying skeleton.
Outcome	The application of PSD to facial animation is best described by comparison with shape interpolation (SI).
Outcome	As illustrated, a PSD path from neutral to half-smile to full-smile is monotonic, as might be expected; the motion of a surface point over this interpolation is also smooth.
Challenge	On the other hand SSD produces characteristic defects and is notoriously difficult to control.
Outcome	In the PSD diagram the expressions are situated in an expression space having a happy-unhappy axis; a second axis (arousal) and an expression (delighted) on that axis are added to show a multidimensional space.
Approach	For synthesis, the basis function φ(x) can be implemented by interpolated table lookup and the sqrt required in the Euclidean distance can be composed with φ(x) in the table.
Challenge	A second difficulty with SSD is that, unlike shape interpolation, it does not permit direct manipulation; artists instead directly or indirectly edit the meshes of weights w k (for each control vertex on a surface there is one weight per skeletal frame that affects the vertex).
Challenge	But although FFDs work well (and have a direct manipulation algorithm [ 12 ]) the layered FFDs do not reduce the difficulty in adjusting the underlying SSD.
Background	As an abstract and general problem, good methods have been obtained both using the well known technique that bears this name [ 32 , 12 , 17 ] and other kinematic surface deformation techniques, and with physical models that simulate the time evolution of a membrane or solid.
Background	Various visual reconstruction schemes can be adapted for scattered data interpolation.
Background	In the pioneering work of Burtnyk and Wein, two dimensional characters were animated using a polygonal rubber sheet that afforded both skeletal and local deformation control [ 6 ].
Challenge	Consider interpolating from a smile (shape A) to a neutral pose (B) and then to a frown (C).
Background	Forsey [ 11 ] describes a characteroriented deformation scheme in which the bending of a smooth surface can be controlled by anchoring levels of a multi-resolution spline surface to the underlying skeleton.
Approach	Additional “dimensions” of deformation can be added at any time by adding a new parameter and associating additional poses with the movement of this parameter.
Approach	The crux of our approach is the identification of an appropriate space for defining deformations.
Background	Arguably the most common practice in character animation (as reflected in commercial software, animation books and courses, and some custom software) is founded on the twin techniques of shape interpolation and SSD [ 18 , 9 ].
Background	In some cases the SSD defects can be manually corrected using FFDs and other techniques, and one could consider a scheme whereby these fixes are procedurally invoked as the skeleton articulates.
Approach	Unlike some SSD implementations interpolation in pose space by definition cannot separate such vertices).
Approach	If there are previous deformations of this vertex in the same pose space then the new deformation is simply another point to interpolate.
Challenge	This deformation approach proceeds from the observation that several types of deformation can be uniformly represented as mappings from a pose space, defined by either an underlying skeleton or a more abstract system of parameters, to displacements in the object local coordinate frames.
Challenge	With a rotation of 180 degrees this line crosses the axis of the arm, i.e., the forearm collapses entirely as the SSD weights transition at some point from the forearm to wrist frames.
Outcome	Psychological research has shown that human facial expressions are largely described by two “emotional” axes [ 30 ] ( Figure 6 ); this two-dimensional space would be a convenient high-level pose space for controlling facial animation.
Approach	Singular Φ T Φ is interpreted as a user error; in practice this has turned out to be the result of saving new deformations without moving any pose controls rather than a result of actual numerical problems.
Challenge	In this case the subspace basis consists of surface points rigidly transformed by the forearm frame (no axis rotation) and the wrist frame (axis rotation).
Background	For example, secondary animation effects such as muscle bulging and swelling of the chest can be achieved by variably weighting the surface to an abstract “bone” whose translation or scale is manually animated.
Approach	Any nonlinear function φ() will interpolate the data, including odd choices such as φ(x) = x (which is nonlinear since x = x − x k is the argument), provided that the columns of Φ are independent.
Challenge	New creature topologies should be accommodated without programming or considerable setup efforts.
Background	In recent years character animation has moved beyond being a research topic and sophisticated deforming characters routinely appear in films and on television.
Approach	For example, a limb can be modeled in a particular pose both in an unloaded state and with muscles sculpted to express carrying a heavy load.
Challenge	Given the popularity and effectiveness of this simple approach, it would be desirable to employ it on regions of the body other than the face.
Background	The animation of human and creature skin deformation is arguably the most common and important application of free form deformation in computer graphics.
Outcome	Pose space deformation is not the last word in surface deformation for character animation; high quality anatomically based models are certainly preferable.
Background	Surface control vertices are simply an animated linear combination (not necessarily convex, i.e., individual weights can be greater than one or less than zero) of the corresponding vertices on a number of key shapes S k : k=0 w k S k 
Background	Litwinowicz and Williams’s system [ 16 ] is also a precedent and introduced sophisticated scattered interpolation (again in the image domain).
Background	While such creature animation can be considered a special case of general free form deformation, its importance and difficulty have lead researchers to propose a number of domain-specific algorithms that will be reviewed in Section 2.
Approach	This may be notated          p = w k L k (p) p (in more detail) p = w k L δ k L k 0 −1 L p 0 p          where L p 0 is the transform from the surface containing p to the world coordinate system, L 0 k is the transform from the stationary skeletal frame k to the world system (L 0 k −1 L 0 p together represent p in the coordinate system of skeletal frame k), and L δ k expresses the moving skeletal frame k in the world system.
Background	The depth of simulation is a prevalent issue in computer graphics, albeit one that is not always consciously considered.
Outcome	Nevertheless both anatomically based and purely kinematic models have their place.
Approach	To make the job easier for the interpolation we instead interpolate the desired deviation of a surface vertex (expressed in the local frame) from its initially computed position (the rigidly transformed position in the case of an articulated model).
Outcome	• The PSD interpolation is smooth if so desired.
Outcome	Typically n will be between 1 and 10, say, so this cost is small.
Approach	Together these comments support φ k (x) = exp( −( x−x 2σ 2 k ) 2 ) as one possible choice of radial basis ( Figure 5 ).
Approach	The position of a control vertex p on the deforming surface of an articulated object lies in the subspace defined by the rigid transformations of that point by some number of relevant skeletal coordinate frames ( Figure 1 ).
Background	(This is singular at the data points x k and should computed as (||x − x k + ) −p ).
Approach	For each control vertex that was moved during sculpting there are now one or more δ values at points in the pose space.
Background	Some commercial packages allow blending between two sculpted deformations as a function of a single-joint rotation, thereby combining shape interpolation and skeleton-driven deformation in a limited but useful setting.
Approach	Taking the latter approach, we reconsider the available data points as a single point d in an N dimensional space, and consider φ k () = φ( x j − x k ) as the kth basis vector.
Approach	Our algorithm computes the difference between the initial and resculpted model at that pose.
Background	These efforts are distinguished from the previous purely algorithmic approaches in giving the modeler control of and responsibility for the deformation.
Background	The discussion in Komatsu focuses on the elbow and shows how the skin crease on the acute side can be obtained by a suitable algorithmic manipulation of the surface control vertices.
Outcome	PSD unifies and improves upon two techniques that have been common graphics practice for more than a decade.
Approach	The ‘heavy’ pose can be associated with the ‘on’ state of an abstract parameter (e.g. an isolated bone moved into the vertical position); light and heavy loads can then be controlled by flipping this switch.
Challenge	• It should be possible to specify arbitrary desired deformations at arbitrary points in the parameter space, with smooth interpolation of the deformation between these points.
Background	In the current computer animation culture animators generally practice their craft by direct and exhaustive specification of the desired motion combined with quick evaluation using real-time playback.
Challenge	As such we require that animators be able to visualize the interaction of a reasonably high-resolution model with an environment in real time (with ‘high resolution’ defined in accord with current expectations).
Approach	A detail that was omitted previously will now be mentioned: when a deformed vertex is found the associated pose space is determined as described above.
Background	SSD is fairly versatile.
Approach	” A self-relative configuration of the controls is actually considered, for example, an elbow involves two skeletal frames but only one joint angle.
Outcome	One can assign each shape in PSD to a separate dimension, exactly as with SI.
Background	In rendering we perhaps see the opposite trend – much of the literature a decade ago focused on ever deeper simulations of reality, whereas ‘shallower’ imagebased approaches are attracting attention at present.
Outcome	Our solution, termed pose space deformation, provides a uniform and expressive approach to both facial skin deformation and skeleton-driven deformation.
Outcome	This relatively simple algorithm uniformly handles a variety of deformation situations ranging from a simple elbow to secondary animation.
Background	A serious drawback for some applications is that the derivative of the surface is zero at the data points ( Figure 4 ).
Outcome	• Whereas shape interpolation is (despite the name) a superposition of a set of shapes, PSD interpolates among these shapes.
Approach	An abstract manipulator is a UI control or arbitrary piece of geometry whose movement will control the interpolation of some deformation, such as a muscle bulge or a desired facial attribute such as “happiness.
Background	Radial basis functions [ 28 , 29 ] have become a popular choice for scattered interpolation.
Approach	Gaussian radial basis functions are reputed to be well behaved and our experience supports this judgement.
Background	Scheepers et. al. [ 31 ] produced convincing representations of muscles as well as preliminary but promising skin deformation.
Challenge	In common situations such as shoulders and elbows the desired deformation does not lie in this subspace, hence no amount of adjusting the algorithm weights will produce good results.
Approach	Thus the deforming surface is defined by p + δ with p moved rigidly by the skeleton or other underlying system, and where configuration is the configuration of the set of joints or parameters controlled by the animator.
Background	Recent research has delivered significant improvements in many areas of character animation, including surface representation, model capture, performance capture, and hybrid (partially image-based) rendering approaches.
Approach	The deformations needed for an elbow, for example, will be interpolated in the one-dimensional subspace defined by the elbow joint angle.
Approach	Since this interpolation is central to our application (the results of the interpolation will be directly visible in the animating deformation), we will consider the available scattered interpolation approaches before settling on a candidate.
Background	Gaussian radial basis functions with adjustable placement and σ are discussed in the neural net literature and optimizing over these parameters is possible.
Background	Similarly, in character deformation both deep and shallow approaches have their place.
Approach	When several such deformations have been saved (or when the artist is ready to try animating) it is necessary to solve the interpolation problem.
Background	In their model a free-form deformation abstractly represents underlying body tissues and mediates skin movement.
Background	Deeper simulation approaches intrinsically take away some of this control, and animators often argue (rightly or not) that automated processes are inferior or will not produce a human feel.
Outcome	• In both approaches a set of key shapes (or delta shapes) are sculpted.
Background	1 An attractive feature of shape interpolation is that the desired expressions can be directly specified by sculpting.
Approach	Note that the dimension of the pose space can vary across vertices, for example, a particular vertex might be modified in three sculpted deformations but a neighboring vertex might have been modified in only two deformations.
Approach	In addition we want δ to approach zero away from the data, and the width of this falloff should be selectable.
Challenge	This fact leads to considerable frustration by users of the algorithm – the character of the deformation changes as the weights are changed, sometimes sustaining the incorrect assumption that some combination of weights will produce good results.

Approach	Vectors are considered column vectors, therefore a multiplication of vector v by matrix M is written as Mv.
Approach	The task is to transform a vertex v influenced by joints j 1 , . . . , j n with convex weights W = (w 1 , . . . , w n ) to its position v in the animated skin.
Background	It comes by many names, all relating to the same algorithm: linear blend skinning (LBS), skeleton subspace deformation, vertex blending, enveloping, or simply skinning.
Approach	The most simple skin deformation algorithm computes v = F j A −1 j v where v is a vertex in the reference skin associated with joint j and v is its position in the deformed mesh.
Approach	We focus on the real-time animation systems in this paper.
Outcome	Considering the high speed and low memory demands of SBS, it provides an attractive alternative to classic LBS.
Challenge	We observed that the artifacts of LBS are caused by the straightforward, linear interpolation of vertex positions.
Approach	To obtain an upper bound of the maximal difference in the angle, we consider the extremal case with θ = π /2, depicted in Figure 4 .
Approach	Its key of success is the use of quaternions to represent rotations.
Approach	The angle α (t) on the picture can be computed by atan, and β (t) by simple linear interpolation of the right angle, which yields the difference function t π d(t) = α (t) − β (t) = atan − t 1 − t 2 It remains to find the extremes of d(t) on the interval 0, 1 .
Outcome	Fortunately, this number is surprisingly small in practice, because the joint influences tend to be local (e.g. it is unlikely to find vertices influenced by both left and right wrist).
Background	This is an apparent advantage over complex systems which rely on explicit anatomy.
Outcome	The proposed algorithm improves a deformed shape even of models that have been designed and carefully tuned for LBS.
Approach	Because these transformations usually occur together, we define the ”complete” matrix C j = F j A −1 j .
FutureWork	Similarly, it would be possible to estimate the SBS vertex weights from examples, as was done for LBS in [Mohr and Gleicher 2003].
Approach	This also shows that LBS is a special case, which is independent of the center of rotation.
Approach	Using T −1 v = v − r c and T x = x + r c , we see that v = T q(W ; T −1 C j 1 T, . . . , T −1 C j n T )T −1 v = T 0 Q T −r c + ∑ i=1 n 1 w i C j i r c v − 1 r c n = Q(v − r c ) + ∑ w i C j i r c i=1        is true for any vector v.
FutureWork	This tool has been presented for LBS in [Mohr et al. 2003], but the situation of SBS is somewhat more complex, because our interpolation method is non-linear.
Approach	Because the previous methods are not efficient enough for our purpose, we use a simple linear quaternion averaging.
Background	The input to LBS consists of a polygonal mesh representing the digital skin, a skeleton, and vertex weights for every vertex of the skin.
Background	The drawback is the necessity of acquiring the example skins.
Background	The advantage of example based methods is that they capture the designed shape, including effects like muscle bulging.
Approach	The transformation of the whole mesh by C j 1 is illustrated in the top row of Figure 3 and the transformation of the same geometry by C j 2 in the bottom row (note that the results are identical in both columns of these rows).
Background	The skeleton simplifies the animation task considerably: instead of animating each vertex individually, it is sufficient to manipulate the skeleton, and the skin deforms automatically.
FutureWork	This could also cover additional effects like muscle bulging.
Approach	If there are multiple solutions giving the minimal Dr c − e , the r c with the minimal norm is chosen.
Approach	Nonetheless, QLERP has to be executed for each vertex, since weights w 1 , . . . , w n can vary.
Background	They differ by the intended area of application and generality of allowed models.
Approach	The vertex v can be represented by a quaternion with zero real part.
Approach	The linear blend skinning allows assignment of one vertex to multiple bones.
Approach	Recall that the matrix C j i has structure C j i = C 0 rot j T i C 1 tr j i        which enables us to write out T −1 C j i T = C 0 rot j T i C j i r c 1 − r c        as can be simply verified.
Challenge	The first problem follows from the fact that the choice of the center of rotation influences the result of interpolation considerably.
Approach	An established interpolation of two rotations is spherical linear interpolation (SLERP) [Shoemake 1985].
Approach	To conclude: both SLERP and QLERP interpolate by multiplying the first quaternion with a rotation with the same, fixed axis.
Approach	In order to test the accuracy of QLERP, we experimented with spherical weighted averages presented in [Buss and Fillmore 2001].
Approach	Unfortunately, it is not possible to simply replace matrices C j i in (2) with corresponding pairs quaternion-translation.
Approach	The difference between SLERP and QLERP is only in the angle of this rotation, and is strictly less then 0.143 radians (8.15 degrees) for any interpolation parameter t ∈ 0, 1 .
Approach	Let us denote matrices by capital letters, while vectors and quaternions by bold.
Challenge	In order to achieve our goal, we cope with two main problems: determination of the center of rotation, and interpolation of multiple quaternions.
Approach	However, this is not the most serious difficulty, and we address it in section 4.1.
Outcome	This minimizes the cost of upgrade from linear to spherical blend skinning in many existing applications: the data structures and models need no change at all.
Approach	We can conclude with an important property: the SLERP can be written as pr s (t) and QLERP as pr l (t), where the rotations r s (t) and r l (t) have the same axis.
Approach	Unfortunately, the condition of zero translation cannot be always satisfied, typically for more than two influencing joints.
Approach	To compute the shape of the deformed skin, we need yet another set of matrices, describing the position and orientation of joints in the actual, animated posture.
Approach	We do not introduce a different notation for the R 3 vectors and their homogeneous R 4 counterparts with last coordinate equal to 1.
Approach	Consider that the arm geometry is influenced by two joints j 1 and j 2 , such that j 1 is a parent of j 2 , as in Figure 1 .
Challenge	Instead of trying to correct the bad results of LBS, we propose to change the interpolation method in (2).
Approach	In spite of this, we claim that QLERP is sufficient for our task.
Background	Another algorithm removes the LBS artifacts by adding additional joints, and computes the vertex weights automatically using examples [Mohr and Gleicher 2003].
Approach	The difference to SLERP is obvious: QLERP interpolates along the shortest segment, and then projects to arc, which does not result in the uniform interpolation of the arc.
Outcome	The time and memory complexity of both algorithms is comparable.
Approach	The weight w i represents the amount of influence of joint j i .
Approach	Because we consider transformations consisting of a translation and rotation, we suggest to use a quaternion representation.
Outcome	However, this amount of memory is negligible, considering the number of different non-trivial joint sets.
Background	As a result, the linear blend skinning is still widely used in many applications, in spite of the artifacts.
Background	Tools that help animators to design the vertex weights are described in [Mohr et al. 2003].
Approach	In order to obtain an appealing deformation, it is necessary to respect the computed center of rotation r c .
Background	The disadvantage is obvious: while the LBS models can be weighted manually by artists [Steed 2002], this is questionable with multiweight enveloping.
Approach	This formula is less efficient, because it blends matrices instead of vectors, but gives us a valuable insight.
Approach	It is well known that the component-wise interpolation of matrices produces odd results: it does not preserve the orthogonality of the rotational part of the matrix.
Background	Its most popular representative, known generally as the skeletal animation, is based on simple but versatile structure.
Approach	In order to change the center of rotation from the origin to r c , we define a homogeneous matrix        T = 0 I T r 1 c (7)        where I is a 3 × 3 identity matrix.
Background	Unfortunately, all these methods are substantially slower then the simple linear interpolation used in LBS.
Outcome	The proposed skin deformation system is by no means perfect; it cannot compete with complex, layered models.
Background	Later on, the basic principles of LBS were described by the game development community [Lander 1998; Lander 1999].
Background	Another deformation algorithm [Bloomenthal 2002] uses a complex auxiliary structure – a medial.
Outcome	The algorithm proposed in [Buss and Fillmore 2001] behaves like SLERP for the case of two rotations (in contrast to QLERP, which only approximates SLERP results).
Challenge	Real-time animation of deformable objects is always a compromise between visual fidelity and computation complexity.
Approach	Please note that the change of the coordinate system did not influence the rotation part C rot j i at all.
Approach	To achieve this, we extend the QLERP scheme to homogeneous matrices C j i .
Challenge	The transition to non-linear interpolation domain is not elementary.
Outcome	It is remarkable that the results of SBS are better even though the models have been optimised to work with the LBS algorithm.
Approach	This matrix is computed by multiplying all the transformations of individual joints in the chain from root to joint j.
Approach	Third, the equation (9) is nothing but a generalization of LBS to an arbitrary method of rotation interpolation.
Approach	Therefore the result of QLERP will be, according to equation (6)        q(W ; T −1 C j 1 T, . . . , T −1 C j n T ) = 0 Q T −r c + ∑ i=1 n 1 w i C j i r c        where Q stands for the interpolation of pure rotations, computed as indicated in section 4.2.
Approach	First, if we substitute r c in place of v, no rotation occurs, which means that r c is indeed a center of rotation.
Outcome	On the other hand, the increase in the execution time was quite substantial.
Approach	Since SLERP assumes cos θ = (p, q) ≥ 0, the angle θ cannot exceed π /2.
Background	Therefore, there exist many algorithms for modeling deformable objects in the literature.
Approach	Assume that vertex v is attached to joints j 1 , . . . , j n with weights w 1 , . . . , w n .
Outcome	The additional memory needed for SBS is dominated by caching the computed centers of rotation.
Approach	It turns out that the number of different non-trivial joint sets, and therefore the number of running the SVD, is surprisingly small for common models – about several tens.
Approach	In some situations, it does not preserve even the rank of the interpolated matrices.
Background	These numerous parameters are derived from examples using the least squares optimization.
Approach	From the definition of quaternion multiplication it can be seen that the real part of p ∗ q equals (p, q) = cos θ .
Challenge	In general, the mesh deformed by LBS loses volume as the joint rotation increases.
Approach	Let us denote by K the coordinate system with origin in r c and identical basis vectors as the world coordinate system.
Approach	Second, if n = 2 and C j 1 r c = C j 2 r c (as in the beginning of section 4), the translation part becomes w 1 C j 1 r c + w 2 C j 2 r c = (w 1 + w 2 )C j 1 r c = C j 1 r c which is independent of interpolation parameters (weights), i.e. the translation during interpolation is constant indeed.
Approach	The basic optimization is to pre-compute the quaternions q j i , because they do not depend on the actual vertex – only on the joint’s transformation, similarly as the rotation centers r c .
Approach	It follows that the only difference between QLERP and SLERP is in the angle of rotations r s (t) and r l (t).
Approach	Note that the shift of the center of rotation does not influence the interpolated rotation – it manifests only in the translation part.
Background	An early contribution concerning the animation of deformable objects is [Magnenat-Thalmann et al. 1988], which considers the movement of a human hand.
Approach	But even if the vertex is attached to only two joints k and l that are not neighbours of each other, some translation may be inevitable.
Background	They use radial basis functions to interpolate between example skins with different shapes.
Approach	Matrices F j are computed in a similar way as the absolute matrices, but including the actual rotation of each joint in the chain (we do not consider translating and scaling joints).
Background	The latter de-correlates the deformation displacements using principal component analysis, which reduces the memory requirements considerably.
Approach	The actual position on the segment is given by weight w 1 (or w 2 , because w 1 +w 2 = 1).
Approach	The following transformation F j returns the vertex to its current position induced by the animated skeleton.
Challenge	Since our goal is an algorithm with comparable time complexity as LBS, we propose an approximate but fast linear quaternion blending.
Outcome	We present a new algorithm which removes these shortcomings while maintaining almost the same time and memory complexity as the linear blend skinning.
Approach	Anyway, it is possible to define the rotation center as the point whose transformations by associated matrices are as close as possible.
Approach	This minimizes the drift and works even if the vertex is assigned to n joints j 1 , . . . , j n .
Challenge	It runs in real-time even on a low-end hardware but it is also notorious for its failures, such as the collapsing-joints artifacts.
Approach	The weights are coefficients of a convex combination, i.e. non-negative and ∑ n i=1 w i = 1.
Approach	Our basic idea is to change the interpolation domain: we interpolate transformations itself instead of transformed vertex positions.
Approach	It is the notorious ”candy-wrapper” artifact, which is demonstrated in Figure 2 .
Approach	We can express this matrix with respect to the world coordinate system easily T q(W ; T −1 C j 1 T, . . . , T −1 C j n T )T −1 which is exactly the formula (8).
Outcome	The measured value is an average time in milliseconds necessary to deform one model on a 2.5GHz Athlon PC (rendering time not included).
Approach	For example if n = 2 then vertex v lies on the line segment connecting C j 1 v and C j 2 v.
Background	The only displayed element is a skin, a 3D polygonal mesh, usually equipped with normal and texture data.
Approach	As mentioned in the introduction of this section the angle of rotation is twice the angle inclined by quaternions.
Approach	This is exactly the equation (9).
Approach	If the dot product (p, q) < 0, we use −p instead of p, which is possible because both p and −p represent the same rotation.
Approach	The interpretation is following: the first matrix A −1 j transforms v to the position with joint j’s coordinate system aligned to the world coordinate system.
Outcome	On the one hand, the difference in the deformed skin was barely observable, according to the results from section 4.1.
Approach	The right shoulder of the model is twisted by 180 degrees, while the left shoulder is left in the reference pose.
Outcome	The overhead of replacing an existing LBS implementation by SBS is minimal, because the input data, as well as the internal data structures, are the same.
Outcome	Put in another way, it is exactly the number of singular-value decompositions performed by the SBS algorithm.
Approach	Let us label the joints by integer numbers, assigning zero to the root.
Approach	Then        the matrix T (7) can be interpreted as a transformation from K to the world coordinate system.
Approach	In the right column of the figure, the rotation center r c is set to the translation part of A j 1 .
Approach	If the joint rotations are large, the LBS produces non-natural deformations.
Approach	If we substitute this into equation (5), we obtain sin((1 − t) θ ) + sin(t θ ) cos θ r s (t) = sin θ + u sin(t θ ) which means that the direction of the axis u is independent on t.
FutureWork	The presented algorithm opens many questions and suggests several directions of future work.
Approach	This enables the real-time performance.
Approach	This is an upper bound; practical results are much smaller and could hardly cause an observable defect in the deformed skin.
Background	Basically, this algorithm blends between rigidly transformed vertices using vertex weights, which denote the amount of influence of individual joints.
Background	Similar method is presented in [Sloan et al. 2001] and [Kry et al. 2002].
FutureWork	In order to accomplish this, a tool to explore the space of SBS deformations would help considerably.
Approach	The SLERP of p, q with interpolation parameter t ∈ 0, 1 is given by the following formula, see for example [Eberly 2001].
Approach	We can restrict our attention to this subspace (the linear hull of 1 and p ∗ q).
Approach	Let us examine the rotation r l (t) following p in QLERP: r l (t) = p ∗ l(t; p, q) = (1 (1 − − t)1 t)p + + tp tq ∗ q = (1 − t + t cos θ ) t sin θ = + u (1 − t)p + tq (1 − t)p + tq which shows that the axis of rotation has the same direction.
Approach	To perform these computations, we use the LAPACK software [Anderson et al. 1999].
Outcome	This only confirmed our choice of QLERP.
Background	A recent skin deformation algorithm presented in [Magnenat-Thalmann et al. 2004] seems to give results competitive to SBS, although it is based on a different mathematical fundament [Alexa 2002].
Background	An interesting generalization of LBS is called multi-weight enveloping [Wang and Phillips 2002].
Approach	If we substitute Q = ∑ w i C rot j i , i.e. a simple linear combination of rotation matrices, we obtain v = Q(v − r c ) + ∑ w i C j i r c = ∑ w i C rot j i v − ∑ w i C rot j i r c + ∑ w i C rot j i r c + ∑ w i C tr j i = ∑ w i C rot j i v + ∑ w i C tr j i = ∑ w i C j i v which is exactly the LBS equation (1).
Approach	In this representation, its rotation by quaternion q can be expressed as q vq ∗ , which is a quaternion with zero real part as well [Eberly 2001].
Approach	To understand why this undesirable effect occurs, it is sufficient to re-arrange the equation (1)
Approach	It means that the results of both r s (t) and r l (t) always end up in certain 2D subspace of R 4 .
Approach	The choice of QLERP is not important for (9), the matrix Q can be replaced by matrix resulting from any other interpolation scheme, such as [Buss and Fillmore 2001].
Challenge	This is exactly what happens in the ”candywrapper” problem: the single point the skin collapses to is a result of transformation by a singular matrix.
Approach	For the case of two rotations, we compare our method with the established SLERP.
Approach	For SLERP, we denote this quaternion as r s (t).
Outcome	First of all, we worked only with vertex weights optimised for LBS.
Background	An improvement based on addition of auxiliary joints has been also proposed in [Weber 2000].
Approach	In order to justify this statement, we face an interesting question by itself: how big can be the difference between QLERP and SLERP for the same input rotations?
Approach	The big advantage of QLERP is that it can be easily generalized to interpolate multiple rotations – it suffices to make a convex combination and re-normalization of multiple quaternions.
Approach	We denote the dot product of two vectors v 1 , v 2 as (v 1 , v 2 ) and the norm v 1 as a shortcut for (v 1 , v 1 ).
Approach	The quaternion 1 represents the identity (zero angle rotation).
Approach	In the extremal case of rotation by 180 degrees, the skin can collapse to a single point.
FutureWork	It would be interesting to find out how much can be the SBS results improved by a set of weights especially designed for SBS.
Approach	The whole algorithm can be summarized in the following steps:
Approach	Fortunately, the center of rotation depends only on the transformations of the joints j 1 , . . . , j n and not the vertex itself.
Approach	The rows in the middle show the progress of interpolation between C j 1 to C j 2 .
Background	The number and location of the additional joints remains questionable.
Challenge	The more important problem is to compute a convenient center of the interpolated rotations.
Approach	Each joint in the reference posture is associated with a homogeneous matrix, describing its position and orientation in the world coordinate system.
Approach	One of them, for example q j 1 , is chosen as pivot.
Background	The polygonal mesh and the skeleton are designed in a reference position, e.g. virtual characters are often posed in the da Vinci posture [Steed 2002].
Approach	Moreover, if there is only one, or two neighboring joints that influence the vertex, we can determine the center of rotation precisely (as indicated in the beginning of this section) and omit the SVD computation at all.
Approach	If (q j 1 , q j i ) < 0 for any i = 2, . . . , n, we replace q j i with −q j i (by analogy to SLERP).
Outcome	These weights are designed to suppress the LBS artifacts, even though they cannot remove them.
Challenge	Although LBS is very fast and advantageous to graphics hardware, it suffers from inherent artifacts, known as ”collapsing joints”, ”twisting elbow problem” or a ”candy-wrapper artifact”.
Approach	One of the problems is that the linear interpolation of quaternions is not equivalent to SLERP.
Challenge	The second problem is simple in the case of two quaternions [Shoemake 1985], but gets considerably harder for more than two rotations [Buss and Fillmore 2001; Park et al. 2002; Alexa 2002].
Outcome	Theoretically, the number of different non-trivial joint sets could be very high.
Challenge	Although this reduces the artifacts, the skin to joints relationship must be re-designed after joint addition.
Outcome	For the woman model, the time increased from original 4.54ms to 22.74ms.
Approach	Recall that a rotation around axis a (unit length vector) with angle 2 α corresponds to quaternion q = cos α + a sin α .
Approach	The elementary mathematical analysis discovers the global extremes in points 1/2 ± (1/ π − 1/4).
Approach	Because C j 1 r c = C j 2 r c , the transformed rotation center is linearly interpolated from C j 1 r c to C j 2 r c .
Approach	Some attention must be paid because standard routines for quaternion to matrix conversion assume a unit-length quaternion.
Approach	The absolute value of d(t) in these points is approximately 0.071 radians (4.07 degrees).
Approach	For j-th joint, we denote this matrix by A j , like ”absolute” (or reference) position.
Background	The artifacts of LBS were discovered soon [Weber 2000].
Approach	Moreover, this axis is constant, i.e. independent on the interpolation parameter t.
Outcome	Unlike other approaches, our method works with exactly the same input data as the popular linear version.
Challenge	Another problem is how the movement of the original skeleton should be propagated into the augmented one.
Approach	We tested the SBS algorithm on three models, see Figure 5 and Table 1.
Background	Some older computer games animated characters in this way, even though it does not produce nice, smooth deformations.
Approach	First, the rotation submatrices C rot j i are converted to quaternions q j i .
Approach	The SLERP of two unit quaternions p, q assumes that their dot product (p, q) ≥ 0.
Approach	Therefore, we can compute the Q matrix from (9) as Q = (s,s) Q and save the sqrt operation.
Background	In addition, it requires hand-tuning of special parameters.
Challenge	Intuitively, a linear blending is not suitable to capture deformations induced by skeleton, because their nature is rather spherical.
Challenge	A similar defect is visible also in the proximity of the singular configuration.
Background	First 3D characters used in numerous computer games were animated by simple, often unpublished algorithms.
Background	However, bones blending is limited to vertices attached to only two joints.
Background	It introduces more parameters and therefore greater flexibility to the deformation algorithm.
Approach	In this appendix we derive the formula (9), which describes the interpolation of rotations with respect to r c – a custom center of rotation.
Approach	Now we have prepared all the ingredients to describe how the SBS algorithm works.
Outcome	In contrast to other methods, the SBS does not need any additional information, such as the example skins.
Approach	By comparison with the starting mesh (drawn gray in each frame), it is obvious that the center of rotation choice in the left column is much more advantageous.
Background	Although the terminology is adopted from the virtual humanoid modeling, the skeletal animation is not limited to character animation – it can be applied to a wide range of soft objects, including imaginary (cartoon) creatures, plants, furniture, etc.
Approach	Even though LAPACK routines are efficient, computation of the center of rotation per each vertex would not result in a real-time algorithm.
Approach	In the left column, the rotation center r c is set to the translation part of matrix A j 2 (the position of joint j 2 in the reference posture).
Approach	We search the optimal solution r c in the least-squares sense.
Outcome	For small deformations, both algorithms produce similar results, as in the second row of Figure 6 (although a small loss of volume is noticeable even there).
Approach	Since p ∗ q is a unit quaternion, we can express it as p ∗ q = cos θ + u sin θ for some axis of rotation u.
Approach	This can be done in a robust way using the singular value decomposition (SVD), followed by computation of pseudo-inverse matrix.
Approach	The only difference between the two columns in Figure 3 is in the choice of the center of rotation.
Background	However, there is an established standard used in majority of real-time 3D applications.
Approach	Clearly no choice of the center of rotation can avoid this translation, because the rotation is identity.
Background	Instead of one weight per influence (joint) as in LBS, the multiweight enveloping uses twelve.
Approach	We compare the shape of the deformed skin on the model of woman, because human eye is most sensitive to the deformations of human body.
Background	The most widely used skeletal animation algorithm, linear blend skinning, is also known as skeleton subspace deformation, vertex blending, or enveloping.
Outcome	However, the SBS algorithm offers reasonable price for elimination of the notorious LBS artifacts.
Challenge	We show that this is really an important problem on an example of human arm.
Approach	The same convention is used for matrices.
Background	More formal articles consider skin deformation as an interpolation problem, such as [Lewis et al. 2000].
Approach	In this case, the interpolation of every single point is a circular arc (as in Figure 1), whereas a disturbing drift is inherent to any other choice of rotation center (such as r c ).
Outcome	We show how to compute a convenient center of rotation in real-time.
Background	To conclude, there are many methods correcting the problems of LBS, but none of them is superior to LBS in all aspects.
Approach	The desired transformation of vertex v is v = T q(W ; T −1 C j 1 T, . . . , T −1 C j n T )T −1 v
Approach	Therefore, if we encounter another vertex assigned to the same set of joints j 1 , . . . , j n , we can re-use the center of rotation computed formerly (cached).
Background	The skeletal animation in general does not specify how exactly the skeleton posture should be propagated to the skin.
Outcome	We justify both theoretically and experimentally that this solution is appropriate for our task (and probably for many others).
Background	An idea similar to spherical blend skinning (SBS) is bones blending proposed by [Kavan and Zára ˇ 2003].
Background	The skeleton is, formally speaking, a tree whose nodes are identified with the joints and edges with the bones.
Approach	Note that both r s (t) and r l (t) have a form of linear combination of quaternions 1 and p ∗ q.
Approach	In general, we cannot make any assumptions about the rank of matrix D, which can vary from 0 to 3 (consider for example n = 2 and C j 1 = C j 2 ).
Challenge	Although the matrix is regular, it involves a non-uniform scaling and skewing, which is responsible for the loss of volume of the deformed skin even for small rotations.
Background	As mentioned in the introduction, the interpolation of multiple rotations has already received some attention [Buss and Fillmore 2001; Park et al. 2002] as well as interpolation of multiple general transformations [Alexa 2002].
Approach	We focus on the interpolation of rotations – the linear interpolation of the translation part of C j i matrices is all right.
Outcome	This number participates considerably on the difference between times for LBS and SBS.
Outcome	Resolving those problems, we obtain a skin animation algorithm that deforms the mesh in much more plausible way then LBS.
Challenge	The paper discusses also theoretical properties of rotation interpolation, essential to spherical blend skinning.
Outcome	The performance of both algorithms is compared in Table 2 .
Approach	In order to challenge the speed of LBS, we apply a following trick.
Approach	However, this correspondence is not unique, because both quaternions q and −q represent the same rotation.
Background	The segments connecting the joints are conveniently interpreted as bones.
Background	This article is interesting also from the theoretical point of view, because it describes how to explore the space of all possible LBS deformations.
Outcome	Another example has been presented already in Figure 2 .
Approach	Note that C j 1 r c = C j 2 r c , therefore also the transformed rotation center is constant during the interpolation.
Approach	The equation (9) has to be evaluated once per each vertex, and therefore should be as efficient as possible.
Approach	For example consider that there is no relative rotation between C k and C l , but there is a relative translation induced by the joints in the chain between k and l.
Background	It consists of joints, given by their position and orientation.
Outcome	Because we change only the interpolation domain and not the input data, our program works with exactly the same models as LBS.
Approach	We call them F j , standing for the ”final” placement of joint j.
Challenge	Other aspects are quite important as well, for example the amount of artists work necessary to design the model.
Background	However, this method is considerably slower than LBS and therefore [Magnenat-Thalmann et al. 2004] recommends to use rather the standard LBS if the joint rotations are small.
Approach	As explained in the next section, the SBS works on a circular arc instead of segment, see Figure 1 .

Background	However, only boxboundary conditions were considered and the velocity basis fields are not strictly divergence free hence requiring a pressure projection step to enforce incompressibility.
Outcome	Again, we have a means of quantifying the deviation from non-physical energy behavior, as we have shown how to decay the spectrum according to physical viscosity.
Approach	Basis coefficients can be interpreted as a discrete spatial spectrum of the fluid with higher “frequencies” corresponding to smaller scales of vorticity.
Approach	Closed form evaluation is proportional to the number of basis functions and the number of advected quantities.
Outcome	However, for coarse objects, we have found this method to provide reasonable accuracy, and it is efficient enough to perform interactively without requiring precomputation.
Challenge	That said, the computation of pressure and other fluid quantities are expensive and approximations lead to noticeable violations of incompressibility.
Approach	Our method allows controllable viscosity, and supports general domains through a formulation on discrete meshes.
Approach	We perform Galerkin projection of the Navier-Stokes equations to derive a time evolution equation in the space of basis coefficients.
Approach	This evaluation is similar to that employed in [Mullen et al. 2009].
Outcome	This has uses in image analysis and shape deformation.
Background	A fluid’s velocity field will change continuously over time according to physical laws.
Approach	As shown in Figure 4 , larger eigenvalues of the Laplacian correspond to fields with smaller vortices.
Approach	This is unavoidable, as the nonlinear advection operator necessitates products of functions.
Approach	A grid may still be used for visualization, for example to track density or subsample the velocity from the closed form expressions to accelerate particle advection.
Approach	When acting on divergence free fields, the vector Laplacian reduces to ∆ = −curl 2 .
Background	They are often used to study homogeneous turbulence [Orszag and Patterson 1972; Rogallo et al. 1981].
Background	Vortex methods use Lagrangian elements such as particles or filaments to track vorticity, and advect these elements through the fluid’s velocity [Gamito et al. 1995; Park and Kim 2005; Angelidis et al. 2006; Weißmann and Pinkall 2010].
Background	Renormalizing to preserve the kinetic energy is a technique available in any fluid simulation method and is not particular to our approach.
Approach	This satisfies the free-slip condition when the object is at rest, and equates normal components of the fluid and boundary velocity when the object is in motion.
Outcome	Our method is fast enough to be interactive, and is very memory efficient and well formulated on rectangular domains due to the available closed form expressions.
Background	Fourier series or Chebyshev polynomials are commonly employed, as spectral methods are limited to bases admitting a fast transform.
Outcome	Modes with small eigenvalue capture the low frequency motion of the fluid.
Background	However, Laplacian eigenfunctions have many other benefits as we describe in Section 3.
Approach	Static irregular boundaries and obstacles are supported in our method through precomputation on general meshes as will be discussed in Section 8.
Approach	In our context, all the preceding expressions are equivalent, and any can be used to evaluate the advection of pairs of basis fields.
Background	The notion of structure coefficients to describe the interaction of Lie algebra basis elements of these groups is directly related to the precomputed coefficient matrices used in our method.
Approach	However, our method is not limited to these domains, and we present a formulation on structured and irregular meshes using discrete exterior calculus, in which velocity and vorticity basis fields are eigenvectors of a discrete Laplacian operator.
Approach	Either field can be easily reconstructed from the basis coefficients ω i .
Outcome	Caching the basis fields uses memory, but saves computation when many quantities are being advected through the field (density or millions of particles).
Approach	The effect of viscosity and projected forces will change the kinetic energy, so these terms are integrated following the energy renormalization.
Approach	The indices i, j are meant figuratively, as they represent tuples of integers.
Background	More recently, Agrachev et al. [2005] used vorticity Laplacian eigenfunctions to prove theorems in the mathematical control literature.
Outcome	We have used this property to enforce stability of integrators and simulate physical viscosity.
Background	Lagrangian techniques, such as mass particles, removes the dependence on the simulation domain.
Background	Model reduction is a data-driven approach that exploits a precomputed set of example simulations to obtain a low dimensional representation for fluid motion.
Approach	This approximates the true geodesic motion of the Euler fluid equations near the current state.
Outcome	The effects of basis dimensionality are illustrated through the bunny example.
FutureWork	Our method’s availability of closed form expressions for time derivatives could also prove useful in optimization algorithms.
FutureWork	We also believe there is potential for our method to be exploited in other research areas such as medical imaging and inverse flow modelling.
FutureWork	We plan to consider how the unique properties of our method could be exploited in these fields.
Outcome	We believe our algorithm and choice of basis provides an exciting avenue and will be an important complement to the methods in the literature.
Approach	However, it is of interest because it preserves the geometric viewpoint of a fluid as a high dimensional rotation group, and provides a more rigorous way of enforcing energy preservation compared to the renormalization correction step.
Outcome	Even simulations with few degrees of freedom provide visually convincing results, avoiding the artifacts common to very low-dimensional representations in Eulerian or Lagrangian simulations.
Background	Mullen et al. developed a fluid integrator capable of perfect energy preservation or desired viscosity independent of grid-resolution [Mullen et al. 2009], but this method is complex and requires a solution to a non-linear system at each timestep.
Approach	This is proportional to the mesh resolution and the dimension of the basis.
Challenge	We propose an algorithm for the interactive simulation of fluid motion that avoids many of the shortcomings of existing techniques.
Approach	Defined as above, ∆ admits only divergence free solutions in its eigendecomposition.
Approach	Smoke density or particle density are subsampled onto a grid.
Approach	To illustrate the preceding discussion, the evaluation of the structure coefficients in closed form for a 2-D rectangle is provided in Appendix A as an example.
Approach	Hence, we expect the result to factor perfectly into a linear combination of vorticity basis functions.
Background	This notion has been previously applied by Stam and Fiume using a Fourier basis to generate procedural stochastic turbulence [Stam and Fiume 1993].
Outcome	However, various issues prevent it from scaling well to very large basis dimension or grid resolutions.
FutureWork	The same could be done for additional geometries, such as a 2-D disk or a spherical surface.
Background	Hybrid particle-grid methods such as FLIP [Zhu and Bridson 2005] are effective in eliminating numerical diffusion, but still require a grid to enforce incompressibility.
Approach	We use this property in Section 4 to accurately model viscous energy decay.
Outcome	For discrete meshes, the cost of reconstructing the velocity field and projecting external forces grows linearly with the basis dimension and mesh resolution.
Background	Vorticity primitives, including particles and filaments, are very effective at simulating smoke in inviscid media but have difficulties modelling diffusion and handling boundary conditions.
Outcome	Our method is most applicable to gaseous phenomena and situations when the domain is entirely filled by fluid.
Background	In contrast, a data driven basis can only approximate flows that are in some sense “close” to those observed in training, and there is no guarantee that additional training data will substantially increase the span of the resulting PCA basis.
Approach	It has many equivalent expressions, including the the Lie derivative L u ω, or the JacobiLie bracket of vector fields −[u, ω], Adv(Φ i , φ j ) := L Φ i φ j = −[Φ i , φ j ] = curl (φ j × Φ i ).
Approach	In addition to using the bottom of the spectrum to capture the large scale motion, one may choose additional modes from much higher parts of the spectrum to incorporate smaller scales.
Approach	Our method is similar in this respect.
Approach	The eigenfunctions of the Laplacian operator are defined by their domain and boundary conditions, making the velocity and vorticity basis fields domain dependent.
Outcome	The resulting velocity basis fields are divergence free and respect boundary conditions, so that these constraints are enforced automatically without the need for additional computation.
Background	Grid-based techniques for simulating the 3-D Navier-Stokes equations were introduced by Foster and Metaxas [1996] but were unstable due to the use of explicit integrators.
Approach	Physical viscosity is achieved by decaying each coefficient exponentially as described in Section 4.
Approach	Examples of basis fields for a tetrahedral mesh are shown in Figure 9 .
Approach	A pseudo-code listing of the precomputation procedure is shown in Algorithm 2.
Approach	Our method is most analogous to the interaction coefficient method of [Silberman 1954], although we consider arbitrary domains.
Approach	We employ a representation of fluid velocity and vorticity in a finite dimensional basis of Laplacian eigenfunctions.
Approach	The contribution to ω  ̇ k is then ω  ̇ k = f k .
Approach	For discrete domains, it can be approximated numerically on a mesh as described in Section 8.
Approach	In contrast, the performance of our method is independent of the domain or grid resolution.
Approach	x We make use of external forces to allow immersed moving obstacles and to incorporate a simple buoyancy model.
Approach	Second, combined with orthogonality, our basis delivers a means of controlling the energy at different scales of vorticity by adjusting the magnitude of the basis coefficients.
Background	Stam developed an unconditionally stable integration scheme using semi-Lagrangian advection and an implicit integrator [Stam 1999].
Approach	Furthermore, closed form expressions allow symbolic evaluation of the precomputed advection operator, making this process fast and exact.
Background	Adding basis functions increases the coverage in a well defined way.
Background	However, in their case an additional set of fields they name the boundary basis are employed that are chosen based on the object’s geometry to best correct for normal velocity components.
Background	Outside of atmospheric sciences, it is not widely used due to poor scaling for large basis dimensionality.
Approach	Considering for example the Fourier basis, the multiplication of two N bandlimited functions is in general bandlimited by 2N .
Outcome	For examples including external forces (such as buoyancy or moving obstacles), the cost of projecting the forces on to the basis is noted.
Background	In 1901, Poincaré [1901] showed that by considering various group manifolds as the configuration space, Euler’s equation could apply generally to a class of physical systems.
Background	Fluid motion is naturally captivating.
Approach	The basis fields may be pre-evaluated on a mesh and stored, just as in the discrete case.
Approach	The result is a divergence free field that best satisfies the desired boundary conditions.
Background	Euler’s equations describing the dynamics of a rotating rigid body date from the 18th century.
Approach	k The Laplacian eigenfunction basis is closed under the Jacobi-Lie bracket.
Approach	The effect of viscosity on each basis coefficient is hence described by the linear first order differential equation ω  ̇ k = νλ k ω k which conveniently has the closed form solution ω  ̇ k (t) = ω k (0)e νλ k t .
Approach	For simulation, our basis must necessarily be finite dimensional.
Outcome	Also, when advecting many particles or projecting many forces the velocity basis fields must still be cached as the cost of closed form evaluations become prohibitive.
Background	This method has come to be known in the CFD literature as the interaction coefficient method.
Background	Model reduction has been applied to fluid simulation by Treuille et al. [2006].
Background	More recent physically based techniques rely primarily on numerical approximation of the Navier-Stokes equations.
Outcome	This cost is proportional to the mesh resolution and the number of basis fields.
Background	Early work focused on obtaining motion that is visually interesting and convincing.
Approach	This is analogous to the stable rotation of a rigid body about a principal axis [Arnold 1966].
Background	However, in contrast to DFFEM, for some simple domains Laplacian eigenfunctions do not require a discrete mesh.
Approach	Note that this method is not perfect, as the projected forces only approximate the desired forces to the extent that the basis fields can resolve them.
Outcome	We demonstrate flow on some simple tetrahedral meshes; however we chose a structured voxelized grid for the bunny example only to facilitate implementation.
Background	On arbitrary domains, Laplacian eigenfunctions do not in general admit a fast transform and hence do not share the inherent theoretical performance of a spectral method.
Outcome	As we show in Section 9, these costs are reasonable for typical operating parameters, but can become large for simulations employing very fine meshes and large basis dimensionality.
Approach	The position vector ω and the tangent vector ω  ̇ span an N −1 dimensional rotation plane that uniquely identifies an N ×N skew symmetric matrix ξ.
FutureWork	Additional potential uses in this vein include texture synthesis and non-photorealistic rendering.
Approach	We precompute the non-linear advection terms between pairs of basis functions and store the result as structure coefficients in a set of matrices.
Approach	Buoyancy forces at each grid centre are calculated through the Boussinesq approximation.
Background	However, for computer graphics applications speed and energy stability are important requirements.
Outcome	We have presented a fluid simulation method that uses eigenfunctions of the vector Laplacian as bases.
Background	Fluid simulation methods in the computer graphics literature belong to roughly four categories: grid-based, mass particles, vortex elements and model reduction.
Challenge	While this technique is very efficient at run-time, it suffers from significant costs for precomputation and storage, and is dependent on the performance of an existing simulator or other mechanism to obtain ground-truth data.
Background	Discrete exterior calculus (DEC) provides a principled means of describing operators and quantities on simplicial meshes [Desbrun et al. 2005].
Approach	On closed form domains, there are two alternatives for velocity reconstruction.
Approach	Laplacian eigenfunctions form an orthogonal basis, allowing one to easily compute the energy of the fluid.
Approach	This says that the magnitude of each basis coefficient decays with a time constant equal to the eigenvalue, which is physically correct, as small vortices dissipate faster than large vortices.
Approach	Physically this represents the cascading of energy to ever higher scales of turbulence.
Background	Spectral methods are characterized by the use of a fast transform allowing efficient calculation of advection in the spatial domain, thereby avoiding convolution sums in the spectral domain.
Approach	The total energy of a signal expressed in an orthogonal basis is the sum of the squares of its coefficients by Parseval’s identity.
Approach	Our method can be used directly as a means of dimensionality reduction through choice of the basis dimension N , but it differs from current approaches in many respects.
Approach	A suitable re-mapping from (i 1 , i 2 ) and (j 1 , j 2 ) to positive integers is necessary in an implementation.
Approach	This result demonstrates closure of the advection operator.
Background	Grid-based techniques are the most common approach.
Approach	Other than the discrete representation and computations described above, the rest of our fluid simulation method remains the same.
Approach	As will be detailed in Section 6, we precompute these terms and the vorticity basis coefficients of the result are stored in a set of matrices C k .
Approach	We choose a fast explicit integrator (such as forward Euler or Runge-Kutta method) to first perform an unconstrained timestep, followed by renormalization to enforce the energy constraint as depicted in Figure 6 .
Approach	Regular voxel meshes are also supported as a special case of this discretization.
Approach	For some simple domains, the basis fields have closed form expressions.
Outcome	Divergence free fields have many potential uses besides simulating natural phenomena.
Background	In the 1950’s, Silberman presented a fluid simulation algorithm for the earth’s atmosphere in a basis of spherical harmonics, which are Laplacian eigenfunctions on the surface of a sphere [Silberman 1954].
Approach	This matrix g is an element of so(N ), the Lie algebra of the N -dimensional rotation group SO(N ).
Approach	With Laplacian eigenfunctions the viscosity can be simulated accurately through a simple exponential decay of basis coefficients, but also allows arbitrary user-controlled or automatic adjustment of the spectrum to achieve a desired effect.
Approach	For discrete meshes, velocity field reconstruction requires summation of stored basis fields.
Approach	Despite closure, the advection operator may produce coefficients beyond the chosen finite bandlimit N which cannot be stored.
Outcome	We have shown that interesting dynamics can be captured in a reasonably sized basis dimension and simulated interactively.
Approach	For our simulation method, we also require the vorticity field ω = curl (u) and a vorticity basis {φ k } with φ k = curl Φ k .
FutureWork	This could be useful for the inverse modelling of real fluid flows for the purpose of parameter estimation, for example to estimate viscosity from sampled velocity measurements.
Approach	However, considering that stability has already been enforced it may not be a concern for graphics applications.
Approach	However, this grid is independent of the simulation, and its resolution may be changed without changing the performance or behavior of the underling simulation.
Approach	However, our method also supports discrete domains defined on a mesh.
Challenge	However, they suffer from high computational complexity, due to the general requirement at each simulation step to solve a system of equations whose size is proportional to the number of grid elements in the domain.
Approach	In some of our examples we incorporate a simple buoyancy model.
Approach	At each time-step we project the difference from the desired normal component onto the velocity basis Φ k and subtract the result from the current state vector w.
Approach	Additionally, Laplacian eigenfunctions of increasing eigenvalue magnitude have a natural visual correspondence with decreasing scales of vorticity.
Approach	We will continue to use the square domain as a concrete, illustrative example throughout the text, although closed form expressions also exist for many other domains including a 3-D rectangular prism [de Witt 2010], a disc, the surface of a sphere, or a planar region with a wrap around boundary condition.
Outcome	The existence of closed form solutions for simple domains allows symbolic evaluation of the advection operator and the ability to sparsely evaluate velocities on demand.
Approach	Through DEC we define the discrete Laplacian operator ∆ = −curl 2 = −d ∗ d∗ which has a representation as a sparse, symmetric matrix.
Approach	In choosing to truncate the spectrum at some finite N , the error we incur is well defined: we lose the ability to simulate vortices smaller than a given scale.
Outcome	In this respect, our method provides a principled means of dimensionality reduction of the Navier-Stokes fluid equations.
Approach	Computation is dominated by the evaluation of matrix vector products, making the run time complexity O(z), where z is the total number of non-zero entries in all the {C k } combined.
Approach	Additionally, choosing Laplacian eigenfunctions as a basis allows the velocity field to be recovered trivially, removing the need for complicated and expensive reconstruction.
Approach	Greater accuracy could also be easily achieved through high order explicit schemes using a small timestep.
Approach	Although the benefits of closed form expressions are limited to simple geometries, a 2-D rectangle and 3D rectangular cavity both represent typical simulation domains.
Approach	For example, to enforce a free-slip velocity boundary condition, we omit (set to zero) the rows of the discrete Laplacian ∆ that calculate velocity flux on boundary faces.
Approach	The inner product for vector valued f and Φ i is defined by the summation of dot product of vectors at every point x within the domain f , Φ i = f (x) · Φ i (x).
Approach	However, moving obstacles change the shape and boundary conditions of the domain dynamically, and hence require special consideration.
Approach	The operation and performance of the time integration scheme described in Section 5 does not change, since it operates only with the basis coefficients.
Background	Such performance considerations were the motivation for the development of spectral methods as pioneered by Orszag [Orszag 1969].
Approach	A final integration scheme that is theoretically interesting involves the calculation of an N dimensional rotation matrix R, which, when applied to the coefficient vector w, constrains its motion exactly to the constant energy N -sphere.
Approach	The basis coefficients of this projection are the structure coefficients that form the {C k } matrices and satisfy Adv(Φ i , φ j ) = C k [i, j]φ k .
Background	Fluid motion describes the optimal transport in an incompressible medium, and can be used to quantify volume preserving deformations.
Approach	Additionally, orthogonality implies that surfaces of constant energy in the Euclidean space of coefficients are spheres.
Background	Representing vorticity using Laplacian eigenfunctions dates back at least to Yudovich [1963], who used this method to prove existence and uniqueness theorems for the two dimensional NavierStokes equations.
Background	Smoothed particle hydrodynamics (SPH) was introduced to graphics by Desbrun and Gascuel [1996] and used subsequently to simulate water [Müller et al. 2003; Adams et al. 2007].
Approach	In our basis representation, this can be described by the continuous change of the coefficient vector w.
Outcome	We show that choosing Laplacian eigenfunctions for this basis provides benefits, including correspondence with spatial scales of vorticity and precise energy control at each scale.
Background	Treuille et al. [2006] also correct the normal velocity component through projection to a divergence free field, and our technique is similar in this respect.
Outcome	We have demonstrated some of the useful properties of our method, but many exciting avenues remain to be explored.
Approach	Note the sums of indices i 1 + j 1 and i 2 + j 2 , which reflect the doubling in bandlimit due to multiplication of sinusoidal functions.
Approach	For this, we require a set of basis fields defined on the mesh that are eigenfunctions of a discrete Laplacian operator, as well as a means to precompute their advection numerically.
Approach	Rather than using an Eulerian grid or Lagrangian elements, we represent vorticity and velocity using a basis of global functions defined over the entire simulation domain.
Background	Particle methods track a fluid’s mass through Lagrangian elements.
FutureWork	This makes it particularly attractive for use in image based settings such as painting applications that simulate fluid phenomena, as we briefly demonstrate in the video.
Outcome	Note that these high frequency modes interact and decay physically, in contrast to other post-processing turbulence models.
Outcome	Our method admits closed form solutions on simple domains but can also be implemented efficiently on arbitrary meshes.
Outcome	This demonstrates the benefit of a basis that exhibits a spectrum of scales.
Approach	The resulting finite dimensional form of the equations describes the time evolution of the basis coefficients.
Approach	Our method satisfies incompressibility automatically as it operates directly in a space of divergence free fields.
Approach	Projecting the result of the advection operator to our finite dimensional basis amounts to truncating the coefficients beyond the bandlimit N .
Approach	In contrast, our basis fields exhibit a spectrum of spatial scales (akin to a Fourier Series) allowing some guarantee of resolving obstacle features with similar length scales.
Approach	An inviscid fluid preserves kinetic energy, and should trace out a path on such a sphere.
Approach	One can verify that the φ k are also Laplacian eigenfunctions of the domain.
Approach	Laplacian eigenfunctions on a domain form an orthogonal set.
Approach	Our basis has a natural correspondence with spatial scales of vorticity that is lacking in [Treuille et al. 2006].
Background	In general, reconstructing a velocity field from a vorticity field is computationally expensive, typically involving the use of the Biot-Savart Law [Angelidis et al. 2006; Weißmann and Pinkall 2010].
Background	Enforcing incompressibility in SPH methods is computationally expensive, making them impractical for a large number of particles.
Background	Arnold [1966] showed that an ideal incompressible fluid is described similarly as geodesic motion on SDiff, the Lie group of volume preserving diffeomorphisms.
Background	Works aimed at mitigating or minimizing artificial diffusion include vorticity confinement [Fedkiw et al. 2001] and high order advection schemes [Selle et al. 2008].
Approach	For notational convenience, we choose Adv(·, ·) to represent the advection term, which is defined as Adv(u, ω) := curl (ω × u).
FutureWork	Boundaries of moving obstacles are handled only approximately and could benefit from alternate methods.
Approach	A decomposition into a spectrum of vorticity is important for at least two reasons.
Approach	Differentiating this expression produces closed form expressions for time derivatives of arbitrary order.
Background	Many of these concepts are summarized by Marsden and Ratiu [1999].
Approach	However, we use a superposition of global basis functions allowing the representation of arbitrary vorticity fields, whereas Lagrangian elements are limited to vorticity concentrated at points or on curves.
Background	To improve the performance of the iterative pressure solver, use of adaptive grids [Losasso et al. 2004] and hierarchical coarse grids for projection [Lentine et al. 2010] have been proposed.
Approach	In fact, for typical domains such as a 2-D rectangle or 3-D rectangular cavity, the global basis functions we employ have closed form expressions, removing the need for a velocity grid representation entirely.
Approach	All experiments were performed on a single CPU core.
Approach	As discussed in Section 4, external forces can be incorporated by projecting f to the velocity basis basis f i = f , Φ i .
Approach	The operator Adv(u, ω) := curl (ω × u) represents the advection of a fluid’s vorticity by its velocity field.
Background	Finally, Laplacian eigenfunctions have closed form expressions for some simple domains, in which case the precomputation time and memory requirements are vastly reduced in comparison.
Approach	Alternatively, they may be computed on demand.
Background	The fascination with fluid motion is exemplified by its long history in the computer graphics literature.
Background	Computer simulation of a model necessitates a finite representation of its spatial quantities.
Background	Up to a desired scale of vorticity, Laplacian eigenfunctions form a complete basis for divergence free fields.
Outcome	We have evaluated the advection operator symbolically for closed form expressions on rectangular 2-D and 3-D domains.
FutureWork	Also, different boundary conditions (for example, a wrap-around boundary condition) remain to be considered, which could prove useful for tilings of fluid simulation domains [Wicke et al. 2009].
Outcome	We believe our method has potential to be exploited for the expressive control of fluid phenomena.
Outcome	For irregular domains, the runtime is in general O(N 3 ).
Background	A low dimensional basis offers a good setting to implement control policies that would be intractable in higher dimensions as demonstrated for example by Barbi c et al. [Barbi c et al. 2009].
Outcome	Many of these issues are not present for domains with closed form expressions.
Outcome	However, our method is not data-driven as seen in current model reduction techniques and hence avoids the need for an existing fluid simulator or pre-existing data.
Background	However, when employing grid based velocity fields it is often undesirable as it can lead to visual artifacts.
Outcome	Each alternative has its strengths.
Approach	It could also be used to initialize or arbitrarily change a fluid’s turbulent spectrum.
Background	We survey some relevant work from geometric mechanics, computational fluid dynamics (CFD) and the computer graphics literature.
Approach	The resulting coefficients are stored in the {C k } matrices 1 C i 1 +j 1 ,i 2 +j 2 [i, j] = − 4(i 1 2 + i 2 2 ) (i 1 j 2 − i 2 j 1 ) 1 C i 1 +j 1 ,i 2 −j 2 [i, j] = 4(i 1 2 + i 2 2 ) (i 1 j 2 + i 2 j 1 ) 1 C i 1 −j 1 ,i 2 +j 2 [i, j] = − 4(i 1 2 + i 2 2 ) (i 1 j 2 + i 2 j 1 ) 1 C i 1 −j 1 ,i 2 −j 2 [i, j] = 4(i 1 2 − i 2 2 ) (i 1 j 2 − i 2 j 1 ).
Background	Furthermore, it is unclear how well this technique generalizes to arbitrary flows, as behavior is limited to the examples present in training.
Approach	However, additional expenses in the case of meshed domains include the storage of discrete basis fields, and the reconstruction of the velocity field through summation.
Approach	This allows the velocity to be evaluated at any spatial coordinate without the need for a voxelized grid or interpolation.
Approach	Because the Jacobi-Lie bracket and vector cross product are anti-symmetric operators, the structure coefficient matrices have the property 1 1 C k [i, j] = − C k [j, i].
Outcome	Currently it is not readily adaptable to typical liquid simulations that require a constantly changing fluid domain with a free surface.
Background	This technique chooses a reduced velocity basis defined on a mesh through observation of an existing fluid simulator.
Approach	The velocity basis fields satisfy a free slip boundary condition and are divergence free, due to constraints imposed implicitly through the Laplacian operator matrix.
Approach	These can be useful for alternate integration schemes to improve accuracy or allow time reversibility.
Approach	The eigenfunctions of the Laplacian operator ∆ are domain dependent.
Outcome	Notably, the bunny’s ears do not begin to be resolved until after the 64th mode.
Approach	First, because computations require our basis to be finite, this ordered structure provides a principle by which to select the finite set.
FutureWork	In particular, the elegant formulation on rectangular domains could make it useful for medical image registration.
Outcome	Our method allows considerable flexibility in choosing the basis dimensionality.
Approach	However, as u and ω are orthogonal, the vorticity basis functions have only a normal component at the boundary, and hence satisfy ∆φ k = λ k φ k
Outcome	We have described many of its unique properties and its use as a practical means of fluid simulation for computer graphics.
Outcome	A comparison to the stable fluids algorithm is included as a rough qualitative validation.
Approach	This method is more expensive than explicit integration with renormalization, and we have found that in comparison it offers very little gain in accuracy for small timesteps.
Approach	Multiplying by ∆t and exponentiating the matrix yields the N × N rotation matrix R = exp(∆tξ).
Approach	These forces are projected to the velocity basis through pointwise multiplication.
Background	Bridson presented a simple means to generate procedural divergence free flows through the curl of a vector potential stream function [Bridson et al. 2007] but this work did not address physical dynamics.
Approach	Additionally, our method supports the interaction of immersed moving obstacles and buoyancy through projection of forces to the velocity basis fields.
Approach	Although our method does not perfectly resolve the boundary, it avoids the use of multiple bases for simulation and boundaries as well as the associated expensive precomputation and memory requirements.
Background	Incompressible fluid dynamics is a vast subject.
Background	Divergence free finite element methods (DFFEM) employ bases of discrete divergence free velocity fields to solve fluid equations in a space that satisfies mass continuity a priori [Gustafson and Hartman 1983].
Outcome	Due to orthogonality of the basis and its correspondence with vorticity of varying scales, we have a unique mechanism for spectral energy control.
Approach	This simplifies to 1 Adv(Φ i , φ j ) = i 1 j 2 cos(i 1 x) cos(j 2 y) sin(j 1 x) sin(i 2 y) λ i 1 − i 2 j 1 cos(j 1 x) cos(i 2 y) sin(i 1 x) sin(j 2 y) a z .
Approach	Because φ k are Laplacian eigenfunctions, the viscous term becomes ν i ∆ω k φ k = ν k λ k ω k φ k .
Approach	In the case of the bunny, a subsampled 16 3 density grid is used for the buoyancy force calculations.
Background	Furthermore, theoretical performance scaling is less critical for the applications we consider and we show that visually detailed simulations are attainable at low cost.
Background	This basis was applied to the vorticity stream function fluid equations in two dimensions, and the advection operator was evaluated symbolically.
FutureWork	This could be used to implement timevarying filters to amplify or attenuate parts of the spectrum, such as achieving crescendos of turbulence or gradual calming.
Approach	In general, {C k } are dense and z is O(N 3 ), leading to a computational complexity similar to that of [Treuille et al. 2006].
Outcome	Flexibility in choosing basis dimensionality and the ability to integrate directly in a space of basis coefficients permits computational efficiency, enabling interactive performance.
Approach	For some practically important simulation domains such as a 2-D plane and 3-D rectangular cavity, Laplacian eigenfunctions have closed form expressions, allowing fully analytic simulation.
Outcome	A robust tetrahedral mesh implementation would have similar performance characteristics and alleviate the boundary “stair case” artifacts.
Approach	Viscosity and external forces are incorporated using linear terms, and the basis function coefficients are hence updated using a simple matrix-vector equation.
Background	Over the years, it has piqued the imagination and curiosity of artists, mathematicians and scientists.
FutureWork	Additionally, the availability of closed form expressions and flexibility in choosing the basis dimension make it an accurate and tractable model for optimization methods.
Outcome	However, any smooth curve through coefficient space, physical or not, may be perceived as “fluid-like” as it represents a continuously changing volume preserving flow that respects all boundary conditions.
Approach	We first describe our preferred integration scheme that meets these two requirements, and then discuss other available techniques.
Outcome	If only a few particles need to be advected (leaves in wind, for example), then evaluating closed form expressions is accurate and fast and does not have additional memory requirements.
Background	Many of these methods can be expensive because the optimization scales sharply with the size of the grid, making them impractical for interesting domains.
Background	Space-time control for fluids has been attempted previously in [Treuille et al. 2003; McNamara et al. 2004; Fattal and Lischinski 2004].
Approach	λ i λ j The antisymmetry reflects an important property of the our basis functions.
Outcome	We have shown how to continuously change the basis coefficients to simulate the physical motion of a fluid.
Background	It also does nothing to improve the quality of object-fluid interaction since the underlying simulation basis, to which the boundary basis must be numerically projected, remains unchanged.
Approach	We have not observed such artifacts, possibly because our basis fields are globally supported and energy is never dissipated locally through a pressure projection step as for example in [Stam 1999].
Approach	However, this truncation is physically motivated, since in a real fluid the vortices will eventually reach a small enough scale and dissipate quickly through viscosity.
Background	Elcott presented a method that preserves circulation on simplicial meshes, but does not preserve energy [Elcott et al. 2007].
Outcome	However, in this case the shape of the boundary is limited.
Approach	When outside of the storable finite range, they are discarded as described previously.
Background	Also, to our knowledge no basis employed in DFFEM exhibits all of the advantageous proper- ties of Laplacian eigenfunctions, including orthogonality, stationarity with respect to Navier-Stokes equations, global support, and correspondence with spatial scales of vorticity.
Background	Stam [2002] used the 2-D Fourier transform of a velocity field to perform fast pressure projection, but this method is limited to simple domains and boundary conditions, and still dissipates energy.
Background	It has been applied to fluid simulation in previous work, and we use a discrete formulation on tetrahedral meshes analogous to [Mullen et al. 2009; Elcott et al. 2007].
Outcome	Closed form domains are limited in their boundaries, but have notable advantages in terms of runtimes, precomputation and memory requirements.
FutureWork	We have presented a fast and stable integration scheme; however, additional time integrators could be explored, particularly symmetric integrators to allow time reversibility as was achieved in [Mullen et al. 2009].
Approach	We choose an appropriate velocity basis a priori instead of relying on observation of an existing fluid simulator.
Background	For example, in the case of a rotating rigid body the group is the rotation group SO(3).
Background	However, the result produces artificial viscosity which dampens vortices prematurely, and requires an iterative linear solver to solve for a pressure field to enforce incompressibility.
Approach	This paper was our inspiration for investigating a Laplacian eigenfunction representation of vorticity as a practical means of fluid simulation in computer graphics applications.
Approach	In other words, to handle obstacles with small spatial features, one must increase N to use basis functions of a sufficiently high spatial frequency.
Background	The resulting run-time performance is fast, but the precomputation time and memory requirements are large.
Approach	The self advection Adv(Φ k , φ k ) of a vorticity basis field φ k by its velocity Φ k is identically zero, and hence u  ̇ = 0, meaning that each velocity basis field is a stationary flow.
Approach	We also employ DEC to approximate the advection operator Adv(·, ·) using appropriate discretizations.
Approach	A further important observation is that due to linearity of the curl operator, the expansion of the vorticity ω in the φ i basis shares the same coefficients as the expansion of the velocity u in the Φ k basis          N N N ω = curl u = curl ω i Φ i = ω i curl Φ i = ω i φ i .
Approach	We summarize some additional interesting and useful properties of our basis.
Background	Simple geometries admit basis fields with closed form expressions.
Approach	We compute the eigendecomposition of this matrix to produce the discrete velocity and vorticity basis fields.
FutureWork	Time reversibility could prove useful in fluid control applications, as was demonstrated for rigid bodies by Twigg and James [2008].
Outcome	The orthogonality of the basis functions and their correspondence to a spectrum of vorticity scales enables energy control at varying turbulent scales.
Outcome	In addition to constructing completely arbitrary flows, perturbing existing physical paths offers a means to deviate from physics while quantifying this deviation.
Approach	The Adv(Φ i , φ j ) terms represent the nonlinear advection of basis fields.
Approach	Our goal is to satisfy the internal boundary conditions of immersed objects at all times.
Approach	Our algorithm can be formulated as Galerkin projection of the vorticity form of the Navier-Stokes equations onto Laplacian eigenfunctions defined over the simulation domain.
Approach	Instead, a velocity can be precisely evaluated at any spatial coordinate without the need for interpolation.
Approach	The vector fields Φ k are Laplacian eigenfunctions with eigenvalues λ k = −(k 1 2 + k 2 2 ).
Background	Gupta and Narasimhan represented fluid velocity in a basis of Legendre polynomials allowing analytic evaluation of differential operators [Gupta and Narasimhan 2007].
Approach	In these cases, no mesh is required to store the fluid’s velocity.
Approach	Coupled with orthogonality, the correspondence allows precise control of a fluid’s turbulent spectrum through adjustment of basis coefficients.
Approach	This requirement can be simply stated: in addition to remaining divergence free, the fluid velocity at an object’s boundary should be equal to the normal component of the boundary’s velocity.
Approach	For every pair of basis functions we evaluate the advection operator and express the result in the finite φ k basis.
Approach	We evaluate Adv(Φ i , φ j ) = curl (φ j × Φ i ) recalling that i, j are vector wave numbers i = (i 1 , i 2 ), j = (j 1 , j 2 ) and the eigenvalues λ i = −(i 2 1 + i 2 2 ).
Background	The boundary basis allows the free-slip constraint to be more accurately enforced in the vicinity of the boundary, but adds substantially to memory and precomputation expense.
Approach	We also use a vorticity formulation, hence requiring no explicit enforcement of the incompressibility constraint.
Approach	Time integration was performed using an explicit fourth order Runge Kutta method.
FutureWork	We plan to investigate its use for the the expressive control of fluid motion, such as spectral energy control and space time optimization.
Background	A formulation using vorticity guarantees incompressibility, but the reconstruction of the velocity field is computationally expensive, typically involving the Biot-Savart formula.
Approach	Our basis is orthogonal allowing kinetic energy to be calculated as a sum of squared coefficients.
Approach	Our solution is as follows.
Approach	i i i          This is notable since a single coefficient vector w = [ω 1 ω 2 . . . ω N ] uniquely identifies both the fluid’s velocity u and its vorticity ω.
Outcome	We present an algorithm for the simulation of incompressible fluid phenomena that is computationally efficient and leads to visually convincing simulations with far fewer degrees of freedom than existing approaches.
Background	Common to all these stable grid-based techniques previously mentioned is the need to solve a system of equations at each time integration step, the size of which is proportional to the number of grid elements.

Background	A realistic and visually accurate character animation necessitates proper skin deformation of the character models.
Approach	The values ht, u, di can be easily computed if we can settle the associated curve segment.
Background	Skin deformation is achieved using the traditional smooth skinning technique.
Background	The process followed by this technique is to assign influence joints and blend weights to each vertex of the character.
Approach	In the neck area, a cross exists in the joint chain.
Approach	In order to remedy this problem, here on the curve skeleton we define two extra attributes, twist angle and twist distribution.
Background	The virtual skeleton forms the interface by which the animator can pose or animate the characters.
Outcome	In the present context, since the skeleton is a curve, distribution and deformation can be linked with the tangent angle at a given number of curve points around the joints.
Outcome	With a slight modification utilizing a linear mapping of curve points to the joint skeleton, the plug-in can make use of a displaced curve skeleton which would be useful for subtle deformation on anatomical areas like the armpits.
Approach	This is not acceptable.
Approach	The more the joints, the trickier it is to determine the weight distribution.
Approach	This local frame is a function of the parameter t of the curve point.
Background	A relevant technique to ours is the sweep-based skinning.
Background	Fat usually deposits between the skin and the muscles.
Challenge	The transformations of the two related joints are too far from each other.
Approach	So far, we have discussed how to realistically skin a character without taking into account the anatomical structures.
Outcome	In comparison with the traditional smooth skinning technique that usually requires on average 3–5 weights, our computation speed is faster.
Background	What needs pointing out is that the term curve skeleton has been used for other applications, such as virtual navigation, reduced-model formulation, visualization improvement, surface reconstruction and it was defined as ‘a 1D subset of the medial surface of a 3D object.
Background	A variation of example-based approach where key example poses are derived from arbitrary unrelated examples is detailed in Reference [ 11 ] where a range scan is used.
Approach	If we analyse the curve function, we can extract the exact expression from the position of Bone_CP, but because the distance d is only an approximate result, it may not fit exactly in the animation.
Approach	Internally, the curve cluster is bound to the joint skeleton so that any movement of the joints affects the curvature of the curve.
Approach	Once the curve is selected and the plug-in activated, the curves become the skeleton for the skin mesh.
Background	The joint-based skeleton has been very popular in the animation industry for many years and has nearly become a de facto standard.
Outcome	From the algorithmic point of view, the technique reduces a level of complexity in the skinning and deformation.
Approach	As discussed earlier, we use on average a smaller number of weights.
Approach	Effectively, each action line is deformed by a curve skeleton, and the action line in turn deforms the muscle.
Approach	What we propose to do is to enhance the current joint skinning system using the curve skeleton skinning and retain the current animation production pattern that the animators are familiar with.
Background	The relationship between a skeleton and the skin shape is highly non-linear.
Outcome	Through a combination of existing practices and newly designed ones, we have successfully created a fusion, which maximizes the efficiency of surface deformation during animation.
Outcome	For an articulated character, we use no more than three weights for any skin point.
Approach	Although it appears to have four links, we only need to generate two curves for the curve skeleton, as seen in Figure 1(c) .
Challenge	To remedy these problems, one needs to formulate the non-linear relationship between the skeleton and the skin shape of a character properly, which however proves mathematically very challenging.
Background	They use a technique called multiweight enveloping in place of single-weight enveloping for better deformation.
Outcome	Since the deformation follows the tangent of the curve skeleton and also due to higher sampling rates received from the curve points, collapsing skin and other undesirable skin deformation problems are avoided.
Background	This method takes an interpolative approach to deformation.
Outcome	By layering the curve skeleton on top of the existing joint skeleton, we allow the animator to work conventionally (as in a joint-based system) and yet receive good results.
Background	The skeleton driven skinning technique is still the most popular method for animating deformable human and creature characters.
Approach	If on the other hand, the animator supplies only a 3D surface model (not a voxelized representation), the generation of the skeleton becomes slightly more complex in that an additional step is required.
Approach	In other words, the skeleton is equipped with an infinite number of joints, which will influence the skin deformation.
Approach	For each point on the curve, we still need a twist distribution to define how the curve twists along its path.
Background	Other technologies like inverse kinematics, forward kinematics, motion capture etc. are built on this hierarchical system of joints.
Approach	From an interface point of view, the artist basically works with normal edit point (EP) curve tools to generate the curves according to his/her wish.
Background	Reference [ 5 ] details a technique of efficient muscle shape deformation using the anatomical skin deformation technique.
Background	Effective realism occurs when the skin actually slides over the fat.
Background	There are basically two main approaches to modeling skin deformations, namely, anatomy-based approach and skin-shape based approach (e.g., example-based skinning).
Approach	Actually the triple parameter ht, u, di may be considered as being expressed in a cylindrical coordinate system.
Background	The anatomy-based approach is therefore used mainly in high-quality film visual effects where anatomical accuracy is a must for believable computer generated characters.
Background	The solution to the collapsing joints problem, which is to place additional joints 1,14 (placing additional joints is basically bringing a curve nature to the joint chain) near the main joint, has the added problems of: (1) creating a new joint in the hierarchy; (2) joint connections have to be done again to connect the new joint in the existing chain; and (3) painting of weights have to be adjusted to accommodate the new joint.
Background	Nevertheless, the joint-based system is popular owing to its interactivity and use of minimal animation data.
Background	New poses are interpolated from these key poses.
Outcome	The idea to use a curve skeleton side by side with the traditional joint skeleton is conceptually simple and functionally efficient giving realistic skin deformations even under extreme mesh duress.
Background	However, this requires the generation of a large number of pre-modeled examples in the first place.
Background	But the disadvantage is that the action line has to be manually animated each frame during animation.
Approach	If the centre is lying on the curve, the deformed skin will move out from underneath the skeleton.
Approach	It will be deformed directly by the underlying curve skeleton, leading to a simpler process.
Approach	The local coordinates of each skin surface point are transformed with the associated local frame to obtain the new position in the world coordinate system.
Background	1 One of the common skinning methods in interactive systems is known by the following nomenclatures: sub-space deformation (SSD), smooth skinning, linear blend skinning and enveloping.
Background	In Reference [ 9 ] the algorithm is trained in a statistical manner so that deformation computation for an arbitrary animated pose can be done.
Outcome	One of the main advantages of the curve skeleton skin deformation technique is that, the curve skeleton needs not necessarily be placed on the underlying joint skeleton.
Background	The action line is basically a curve, which defines the direction of deformation.
Approach	One curve is generated.
Approach	Normally it is not evenly distributed as can be seen from the twist of a forearm.
Approach	This leads to a smaller number of summation terms needed for the calculation of the deformed skin points (see Equation (3)).
Background	Mesh deformations due to skeletal joint influence have undergone significant improvements in the recent years.
Background	More importantly, it is almost an integral part of the current animation workflow and animators are reluctant to abandon their familiar production practice.
Approach	Smooth skinning usually involves three weights for each skin point and in many cases there could be as many as five weights.
Challenge	Despite their seeming similarity, they are in essence very different techniques.
Background	As fat is largely incompressible, when a joint bends, flesh between the adjacent bones will be squeezed, producing bulges immediately near the joint and at the sides.
Background	It uses a layered structure of anatomical parts from the inside out, skeleton->bone->fat->skin.
Challenge	’ 2 Despite some similarity, it should not be confused with what we are presenting in this paper.
FutureWork	With a small modification, the fat bulge effect can be made even in a curve skeleton-based skinning.
Approach	Once voxelized, a curve skeleton is created using the repulsive force field function.
Challenge	In this paper, we propose a method that is able to accommodate the inherent non-linear relationships between the movement of the skeleton and the skin shape.
Background	They use surface-oriented FFDs for skinning.
Approach	This is also the case for any skin points associated with three curve segments.
Outcome	The Maya plug-in implementation of the curve skeleton technique has given satisfactory results.
Approach	The skin is directly deformed by the curve skeleton.
Approach	The curve skeleton can be generated in two ways depending on what the animator supplied in the first place.
Background	Reference [ 5 ] resorts to the creation of a muscle model, which is categorized into two layers: an action line and a surface mesh.
Background	Skin deformation owes a large part to proper rigging of the characters.
Challenge	The basic idea is to represent the relationship between the skeletal movements and the skin deformation in a non-linear continuous fashion.
Approach	15 Then the temporary mesh can be deleted and the skeleton can be used with the original surface model.
Challenge	There are certain solutions to circumvent these problems (which we will examine later in the paper) but they have their own drawbacks.
Approach	We use B-splines to represent the curve skeleton.
Background	Despite their seeming similarity, the objective of the Maya IK spline handle tool is to control the joint positions using a spline.
Approach	We use the so-called curve skeletons along with the joint-based skeletons to animate the skin shape.
Approach	Placing additional joints where the skin bends increases the sampling rate and is an ad hoc way of approximating this non-linear relationship.
Approach	While the joint skeleton is a discrete centre line representation of an object, the curve skeleton offers a continuous skeletal representation.
Outcome	A practical implementation in the form of a Maya plug-in is created to demonstrate the viability of the technique.
Approach	If the animator supplies a skin model and a skeleton model in the traditional manner, the curve skeleton generation is easy.
Outcome	In this paper we have presented a technique, known as the curve skeleton based skinning, by considering it as a proper non-linear problem.
Approach	If a skin point is related with only one curve, which represents the majority of cases, the weight factor is always 1.
Approach	In most cases, one curve is sufficient.
Background	Maya is the most widely used 3D animation package in the industry.
Approach	Our curve skeleton is controlled by the joints of a character.
Background	The drawback comes in the form of computation expense.
Approach	Then one Bone_CP each is inserted on the opposite sides of the Joint_CP ( Figure 1a ).
Background	Where visual fidelity is of the utmost importance, with respect to film quality animation, a combination of techniques including muscle simulation is used to achieve the realistic best in mesh deformation.
Outcome	With our curve skeleton technique, muscle deformation can be fully integrated where the muscles are driven and animated by our curve skeletons.
Background	Most of the described techniques are built upon the existing hierarchical skeletal joint system and modify 10 or even create 9,12 new weight calculations to rectify any sort of physical artifacts in the skin deformation.
Background	The example-based approach forms a suitable alternative where computational expenses are to be minimized.
Outcome	As a result, our computation speed is at the same order, but is slightly faster than that of the traditional smooth skinning technique.
Background	13 The body of a character is segmented with a large number of sweep planes which will be transformed by the joint skeleton.
Approach	The local transformations of the curve points are applied to the skin mesh vertices thereby generating deformations on the skin.
Approach	Our approach builds upon the existing system using the curve skeleton for a continuous sampling of the skin surface thereby facilitating skin deformations devoid of geometry artifacts.
Background	It is our knowledge that the problem reduces after weight painting only when the joint influence fall-off follows a curve pattern.
Challenge	Skeleton and skin relationship in the present production pipeline is strictly linear, whereas observation of the various geometry artifacts like candy wrapper and collapsing joints intuitively point to the fact that linear blending or skeletal space deformation falls short in accurately depicting skin deformations because of their non-linear nature.
Approach	So here the centre of the local frame is translated on to the original skeleton shown in Figure 2b .
Approach	As can be seen from the above classification, for a human character, we will use a maximum of three curves for each joint.
Background	Simulation of complex dynamics and performing complex collisions and also providing a visually realistic output form the main strength of the anatomical approach.
Approach	These CPs will then be transformed with the curve skeleton, resulting in the muscle bending around the joint or bone being automatically created ( Figure 3b ).
Background	There is a lot of work 16 associated with the traditional joint-based method, like the containment-binding algorithm, point-to-line mapping, Delaunay tetrahedralization.
Background	An interactive deformation technique for complex geometric objects using curves or wires is detailed in Reference [ 4 ].
Approach	The twist angle can be easily queried from the associated joint.
Outcome	One should not confuse the curve skeleton technique with the inverse kinematics (IK) spline handle tool provided by the animation package Maya.
Approach	Thus the challenging part of the work is to find the associated curve segment, and assign the weighting parameter for each curve segment—skin binding.
Background	The surface is discretized and finite differencing techniques are used to evolve the deformation through time.
FutureWork	Using curve tangents will provide for an accurate distribution in any given time frame because of the integrated results from the sample multiple curve points.
Approach	With our curve skeleton technique, the curve serves as a duplicated skeleton to the actual underlying joint skeleton.
Approach	With our method, the skin surface does not need to be approximated by sweep surfaces.
Approach	When the bone twists around its local x-axis, it will not have any effect on the associated curve skeleton.
FutureWork	The function can be defined under the local frame of the curve skeleton.
Background	This non-linear nature is explored in Reference [ 12 ] where a spherical blending is proposed.
Background	This is especially true in the areas near joints where acute deformation happens.
Outcome	The curve skeleton retains the advantages of the current skeleton driven skinning.
Background	They have used a geometric method instead of resorting to a physical simulation method, and gives convincing results without the computational expense of physical simulation.
Background	One of the best third party muscle simulation systems available called muscleTK 17 deforms the muscle using the so-called action lines.
Challenge	Albeit an industry de facto due to its computational performance and intuitiveness, it suffers from problems like collapsing elbow and candy wrapper joint.
Challenge	Some of the commonly seen problems in joint-based skinning during deformation are: candy wrapper effect during twist deformation and collapsing joints, which would create a rubber-tube like effect.
Background	Existing skeletondriven techniques regard it as a much-simplified linear problem, which however, has resulted in unrealistic skin deformation in certain regions of the character body.
Background	Reference [ 10 ] also implements an example-based approach to deforming meshes by using radial basis functions to supply the interpolation weights and also for shape interpolation.
Approach	The rotation angle is for the curve ending.
Approach	Once the skin is bound with the curve skeleton, deforming the skin is pretty straightforward.
Approach	Here the twist angle is distributed along the distribution curve so that the twisting is smooth and natural.
Approach	The underlying structures like muscles or bones will be exposed.
Approach	The reason for the floating position is to eliminate the selfintersection of the skin mesh ( Figure 1 -a1).
Background	In order for scalability and increasing the feature base of Maya, Autodesk has provided Maya APIs for developers to expand the functionality of Maya.
Background	The attachment of mesh geometry to the underlying skeleton rig is called ‘skinning’ and this can be understood as a function mapping of the skeleton parameters to a deformation field.
Approach	The animator will have freedom to edit the weighting factors in the same way as the smooth skinning.
Approach	So the new point P, is defined by X P 1⁄4 w i M ði;tÞ P Lðu;dÞ (3) i where w i is the weight for the specific curve segment i, M (i,t) is the new transformation matrix at the parameter t position along the curve segment i.
Background	Turner and Thalmann 8 defines the fat layer as a thickness specified at each point on the skin surface and make use of reaction constraints to push the skin the required distance out from the underlying layers.
Background	The example-based approach relies on key sample poses to derive a generalization of deformation, and this becomes a major disadvantage, as this in itself is an expensive and time-consuming process.
Background	It is plain to see why the joint-based skeleton system is thoroughly integrated into the current production pipeline in animation.
Approach	Both Bone_CPs have floating positions along the two neighbouring bones, its position being constrained by the angle between the two bones.
Background	These modules undergo deformation when the body moves and a skin simulation and collision detection algorithm is run which would realistically deform the skin where and whenever it is required.
Approach	In all cases, the summation of the weights are constrained to one, P w i 1⁄4 1.
Background	These planes are used to guide the transformation of every skin point during animation.
Approach	Since a lot of contemporary animation technology is built upon the hierarchical joint-skeleton based system, it is not wise to entirely replace the current practice.
Approach	For those skin points associated with two curve segments, the default weights are proportional to the distances to the relevant curve segments, that is, the further away a skin point is from the curve segment, the smaller the weight is.
Outcome	Using our technique, the animator is able to work without digressing from the familiarity of the current joint-based system, but at the same time achieves maximum visual realism in terms of skin deformation.
Background	Singh and Kokkevis 3 demonstrate this in their paper.
Approach	So here the floating position of the Bone_CP is left to the animator to define interactively ( Figure 1 -a2).
Challenge	And with that low-rate sampling they fail to give a good approximation of the deformed skin surface.
Approach	When the effect of a muscle bending around the joint or the bone is required, we can first transform the control points (CP) of the action line from world space to the associated curve skeleton local frame.
Challenge	In addition, we will demonstrate how the curve skeleton technique can drive muscle-based systems to achieve realistic muscle deformation during animation.
Outcome	The curve nature of the skeleton makes it easier to manipulate it with a great order of flexibility.
Approach	Similar to the joint-based skeleton, each point on the curve in a curve skeleton has a local frame (similar to a Frenet frame) defining the space transformation sampled at that point.
Approach	In a linear linkage the centre of the joint gives the first control point (CP) of the curve.
Challenge	One should neither confuse this with the inverse kinematics (IK) spline handle tool provided by the animation package Maya.
Background	An artist models certain key poses of the characters where a correlation is maintained for the degrees of freedom, in this case, it would be the joint positions or rotational angles.
Background	They also implement attractive and repulsive force fields in the form of ellipsoid metaballs to stabilize the action line.
FutureWork	As future work, we will further improve the skinning realism by adding the fat effect.
Approach	Hence, three curves are generated, two curves starting from the central link to the two limbs linkage (in the example) and one curve linking the two links.
Approach	Since our technique falls in between the two approaches, seamless integration with the two is also possible and becomes its strong advantages.
Approach	Given that we have a maximum of only three curve segments for each skin point, weight assignment for a skin point is simpler than the traditional smooth skinning method and the computation for skin deformation is computationally cheaper.
Outcome	As a further enhancement, it is also fairly simple to build realistic muscle and fat bulge effect.
Approach	The whole structure of a curve skeleton may involve several curves, which depend on the topology of the original joint skeleton.
Approach	In anatomical areas like the hip ( Figure 1b ), a fork exists in the joint chain.
Approach	In order to perform even distribution of twisting, we provide the animator with the freedom to control how the curve twists by manipulating the distribution curve.
Background	Skin deformation is closely linked with the movement of the skeleton of a character.
Outcome	Our curve skeleton technique takes full advantage of the nonlinearity of the skeleton-skin relationship.
Challenge	But in spite of computational performance and ease of use, the joint skeleton skinning is not without its share of problems, particularly where skin deformation is concerned.
Approach	They can be easily found from the curve definition.
Background	It is not desirable to create many examples and train the system.
Approach	This is worsened if additional joints are placed in order to remedy the unpleasant artefacts.
Background	Basically, the action line is the mechanism that drives the deformation.
Background	7 Reference [ 8 ] presents another approach to deformation using an elastic surface layer model.
Challenge	The problems of joint-based skeleton skinning mentioned above, in essence arises from under-sampling.
Outcome	With our curved skeleton, this problem will almost certainly not arise.
Background	Some of the normal deformation techniques like free form deformations (FFDs) or lattices can be used in skin deformation techniques.
Outcome	It is easy to use and allows full control over the animation process.
Background	Wang and Philips 9 introduce a multiweight technique to eliminate this problem in a normal joint-based skeleton skinning.
Outcome	Therefore, we can achieve sophisticated muscle deformations without the tediousness of animating the action lines manually every frame.
Background	Thus example-based approaches have the advantage over anatomical approaches by being computationally faster and also due to the fact that creating example poses are much easier compared to creating detailed anatomically correct models.
Background	Only the translation factor is most commonly used for the skin vertices and the rotation factor is not considered.
Background	Transforming the vertex by a weighted combination of the joints local coordinate frames completes skin computation.
Approach	Thus a character will have two skeletons: the ordinary joint skeleton and a curve skeleton.
Approach	These points normally form the curve segment endings.
Approach	The curve skeleton being continuous gives the maximum sampling rate and provides skin deformation transformation without any artifacts.
Background	A modified least square fitting technique is used to compute the weights of the deformation and the subsequent generalization of skin movement to other animated poses.
Approach	A temporary copy of the surface model can be created (during runtime) and voxelized.
Approach	By providing the animator with more parameters, which he/she can tweak, we grant flexibility and freedom to adjust the animation.
Background	The anatomical approach derives its name from its implementation using anatomical models of muscles and skeletons and other relevant interior structures.
Approach	The condition for non-self-intersection is to check if the local radius of curvature r at the joint is not less than d.
Approach	The process of skin binding is to transform each skin surface point hx,y,zi at the binding pose to the local frame coordinate system hi, t, u, di, where i is the index to the specified curve segment, t is the parameter along that curve segment, u is the rotation angle around the x-axis from the y-axis, d is the distance from the local frame centre.
Background	Incorporating physical properties of anatomy structures can potentially improve realism.
Background	Yang and Zhang 18 devises a fast method for simulating fat in which a fat bulge distribution function is described.
Approach	Effectively any point on the curve can be considered as a joint.
Outcome	In fact, for the majority of cases, there is only one weight, which is 1, to be is used.
Challenge	Unusual deformation artifacts appear in the skin while deforming.
Background	Physics can be used either at the muscle level 6 or used to help character rigging.
Approach	The relevant default weight factors w i of a skin point for the ith curve segment is determined by the distance between the skin point concerned with the relevant curve segments.
Outcome	Our current implementation allows both skin and muscle deformation to be modeled within a unified framework.
Approach	Before we can predict the exact movement of the Bone_CP, first we should estimate the approximate distance d from the skin surface to the relevant link of the skeleton.
Approach	The distribution curve ( Figure 3a ) is very much like the animation curves in Maya.
Background	But muscles will give an added layer of realism to the deformation, especially in regions where the skin is visibly influenced by the underneath muscles.
Approach	In our method, the parameter t on the curve plays an important role in the deformation.
Outcome	The main advantage of this technique is its consistency with the current animation production practice and the ability to overcome the undesirable drawbacks of skeleton-driven skinning.
Outcome	In this paper, we introduce a novel method called curve skeleton skinning, to overcome the persisting drawbacks of joint skeleton skinning.
Approach	Using the proposed curve skeleton, we can realistically deform not only the skin directly (as explained earlier), but also the muscles, in a unified manner.
Challenge	It is understandable that the relationship between both is highly non-linear, which poses a challenge if the relationship is to be modeled mathematically correctly.

Approach	The function N(u t ; φ j , Λ j ) denotes the multivariate normal density function with mean φ j and covariance matrix Λ j .
Approach	Instead of using the physical laws to generate physically correct animation, we rely on statistical models of human motion to generate a statistically plausible motion.
Approach	In human body animation, y n is the position and orientation of the root and the joint angles.
Approach	This model is then used to compute the motion prior, − ln p(H).
Background	Local statistical models are sufficient if the user provides continuous control signals (the performance animation problem).
Approach	In our experiment, we extract foot positions from a source walking motion and then use it to generate a walking sequence for a new character.
Approach	Foot contact constraints were specified by the user directly.
Approach	The parameters of the Gaussian mixture models (π k , φ k , Λ k ) are automatically estimated using an Expectation-Maximization (EM) algorithm [Bishop 1996].
Approach	Finally, we discuss how to optimize motion by combining both terms: H ˆ = arg min H − ln p(E|H) − ln p(H).
Approach	The most common nonlinear constraints in human body animation might be end effector constraints, for example, foot contact constraints.
Approach	The first method is a simple linear interpolation of key frames.
Outcome	First, using a low-dimensional statistical dynamic model for the constrained optimization might achieve faster convergence and be less subject to local minima.
Approach	The facial expression data are from the same subject and contain a variety of facial expressions such as “happy” and “sad.
Approach	Our work also uses a trajectory optimization framework but replaces the physical dynamic model with a statistical dynamic model computed from a motion capture database.
Approach	If d u is equal to the number of dimensions of the system state d x , the model can be used to represent an arbitrary motion sequence with zero error.
Approach	For the examples reported here, we set the dynamic order to three and the dimensionality of control input to four for human body animation (the reconstruction error is about 0.7 degrees/joint per frame); we set the dynamic order to two and the dimensionality of control input to one for facial movement (the reconstruction error is about 0.1 mm/vertex per frame).
Challenge	An ideal motion synthesis system should allow users to specify a variety of constraints either at isolated points or across the entire motion in order to accommodate users with different skill levels.
Challenge	A more skilled user might specify a small set of poses at key time instants.
Outcome	Similarly, the prior from a walking database fails to generate a good jumping motion because of the mismatch between the prior and the user-defined constraints.
Approach	It significantly reduces the dimensionality of the motion from the space of x 1:T to the space of the initial state x 1:m and the control input u m+1:T .
Challenge	The key idea behind our approach is that motion priors learned from prerecorded motion data can be used to create natural human motion that matches constraints specified by the user.
Outcome	The quality of the animation becomes worse when we use a large and general locomotion database to generate walking.
Approach	The user can generate realistic facial animation by combining sparse keyframe constraints (three key frames) and sparse trajectory constraints (one trajectory).
Challenge	The main focus of this paper has been an exploration of the use of prior knowledge in motion capture data to generate natural motion that best satisfies user-defined constraints.
Outcome	Building anatomically accurate physical models for facial animation or whole-body motion remains challenging.
Approach	We preprocess the motion capture data by applying Principal Component Analysis (PCA) [Bishop 1996] to the motion capture data and obtain a reduced subspace representation for y n :
Approach	However, we can perform singular value decomposition (SVD) on the data matrix Z such that Z = W SV T , and then get the best possible rank d u approximation of the data matrix, factoring it into two matrices: B ˆ = W and U ˆ = SV T , where B ˆ is a d x × d u matrix and U ˆ is a d u × (T − m) matrix.
Approach	We can also combine these two constraints.
Approach	The energy term for the second term on the right side of Equation 11 can be simplified as follows:
Approach	The number of dimensions of the control input, d u , characterizes the complexity of our dynamic model.
Approach	Therefore, any non-singular transformation of the matrix B represents the motion because BT and T −1 u n are also consistent with the dynamic model.
Approach	We learn the statistical model for each individual behavior and use it to generate individual behavior based on user-defined constraints.
Background	Reducing the number of degrees of freedom to be optimized can also create tractable problems.
Approach	We extend the model to learn an efficient and low-dimensional representation of human motion and use it to generate an animation that achieves the goal specified by the user.
Approach	Functionally, a statistical dynamic model is similar to a physical dynamic model.
Approach	For example, the user can create a slightly different jumping motion by adjusting the positions of both hands at the top of the jump.
Approach	The system automatically learns a statistical dynamic model from motion capture data and then enforces this model as a motion prior.
Outcome	As would be expected, the system fails to generate a good walking motion if the motion prior is learned from running, hopping, or jumping data.
Approach	If we choose d u as “zero” (simply dropping off the control term), our model becomes the linear dynamic model used by Soatto and colleagues [2001] and has the largest reconstruction error.
Background	Therefore, one way to make the problem tractable is to simplify the governing physical laws.
Challenge	The system then automatically finds a motion that best satisfies those constraints.
Approach	The facial expression database (about 9 minutes) includes six basic facial expressions (happiness, surprise, disgust, fear, anger, sadness) and three facial movements related to everyday life (speaking, eating, and snoring).
Background	They applied the learned dynamic systems to synthesize an “infinite length” texture sequence by sampling noise from a known Gaussian distribution.
Challenge	In this paper, we present a technique for generating animation from a variety of user-defined constraints.
Approach	The constraints could be any kinematic constraints such as position, orientation, or the distance between two points on the character.
Approach	The system learns a single statistical model from the whole facial motion capture database and then uses it to create facial animation with a variety of spatial-temporal constraints.
Outcome	Solving this problem in the low-dimensional space yields optimal natural motion that achieves the goals specified by the user.
Approach	We compare the results for a database of general locomotion, running, hopping, jumping and walking.
Approach	The system allows the user to sketch out the motion in greater or lesser detail.
Background	These models lack temporal information and therefore cannot be used to generate an animation from sparse constraints such as key frames.
Approach	Solving this optimization problem in the lowdimensional space yields optimal, natural motion that achieves the goals specified by the user.
Approach	We model the control input (u t ) as a mixture with K component Gaussian densities [Bishop 1996]:
Background	Urtasun and her colleagues[2006] learned linear motion models from pre-aligned motion data via Principal Component Analysis (PCA) and used them to track 3D human body movements from video by performing nonlinear optimization over a small sliding temporal window.
Background	Statistical models of human motion have also been used for motion synthesis.
Approach	After combining the user-defined constraints and the motion prior, the constraint-based motion synthesis problem becomes the following unconstrained motion optimization problem:
Challenge	Another important issue for building any interactive animation system is to design an intuitive interface to specify the desired motion.
Background	Trajectory optimization methods, which were first introduced to the graphics community by Witkin and Kass [1988], provide a powerful framework for generating character animation from user-specified constraints, physics constraints, and an objective function that measures the performance of a generated motion.
Approach	For example, when the user specifies a small set of key frames or key trajectories, the number of constraints is not sufficient to completely determine the whole motion sequence, x 1:T .
Outcome	We also show that we can use motion priors learned from a small sequence of a normal walking motion (about 100 frames) to create walking on a slope and walking with small steps.
Outcome	Without the use of the statistical dynamic model, the system can not generate natural motions unless the user specifies a very detailed set of constraints across the entire motion.
Background	Grzeszczuk and his colleagues[1998] developed a neural network approximation of dynamics based on simulated data and use it to animate dynamic models such as fish and lunar landers.
Approach	Spatially, the constraints could provide either an exact configuration such as a full-body pose or a small subset of the joint angles or end-positions.
Challenge	For      example, a naive user might use a performance animation system to control the trajectories of the end-positions of the limbs of a character.
Approach	We also add one term in the objective function that measures the difference between the source motion and retargeted motion:
Approach	We solve the optimization problem using sequential quadratic programming (SQP) [Bazaraa et al. 1993], where each iteration solves a quadratic programming subproblem.
Approach	Alternatively, the user could rely on commercial animation software such as Maya to specify constraints.
Background	HMMs learned from human motion data have been used to interpolate key frames [Molina Tanco and Hilton 2000; Galata et al. 2001], synthesize a new style of motion [Brand and Hertzmann 2000], and generate facial expressions from speech signals [Bregler et al. 1997; Brand 1999].
Outcome	Our system can also synthesize motion that transitions from one behavior to another by using the statistical model learned from transition data.
Outcome	Second, our approach can generate slow and even stylized motions that have proven particularly difficult for physically based optimization.
Approach	We also evaluate the performance of our algorithm in terms of the motion priors and user-defined constraints.
Approach	The quality of the final animation depends on the motion priors and the user-defined constraints.
Outcome	This process is timeconsuming even for a professional artist; it is more difficult for a naive user to specify such constraints.
Outcome	The accompanying video also shows that the system can generate motions for characters with skeletal dimensions different from those in the database.
Background	One appealing solution to this problem is physically based optimization [Witkin and Kass 1988], which allows the user to specify various constraints throughout the motion and relies on optimization to compute the physically valid motion that best satisfies these constraints.
Challenge	Our objective in this paper is to design an animation system that allows users to easily create natural-looking character animation by specifying spatial-temporal constraints throughout the motion.
Approach	We evaluate the importance of motion priors by comparing our method against alternative constraint-based motion synthesis methods.
Approach	This formulation is similar to the linear time-invariant control system commonly adopted in the control community [Palm 1999].
Background	This idea has been used to compute human body poses [Rose et al. 2001] and facial expressions [Zhang et al. 2004] from kinematic constraints at a single frame.
Approach	In our experiments, most of keyframe constraints were modified from example poses in the database.
Approach	The motion was captured with a Vicon motion capture system of 12 MX-40 cameras [Vicon Systems 2004] with 41 markers for full-body movements and 92 markers for facial expressions.
Outcome	The system can generate motions for a character whose skeletal model is markedly different from those of the subjects in the database.
Approach	x n ∈ R d x and u n ∈ R d u are the system state and control input, and d u is the dimensionality of the control input u n .
Outcome	The accompanying video shows that we can generate a good walking motion with a walking database.
Approach	To remove ambiguities, we would like to constrain the generated motion to lie in the space of natural human motions by imposing a prior on the generated motion:
Approach	The system automatically learns a statistical dynamic model from motion capture data and then enforces it as a motion prior.
Approach	The user can refine the animation by incrementally modifying the constraints.
Approach	We test our system by generating both human body animation and facial animation from various forms of user-defined constraints.
Background	More recently, Liu and her colleagues [2005] introduced a novel optimization framework— Nonlinear Inverse Optimization—for optimizing appropriate parameters of the objective function from a small set of motion examples and then used the estimated parameters to synthesize a new locomotion.
Outcome	There are two limitations of our approach: an appropriate database must be available and the user cannot specify such dynamic constraints as ground reaction forces or character mass.
Approach	The motion was captured at 120Hz and then downsampled to 30Hz.
Approach	User-defined constraints for motion retargeting can either be directly computed from the source motion or specified by the user.
Approach	However, the matrix B is not unique because the control input u t is unknown.
Approach	Two kinds of constraints were used to generate most of the examples in this paper: key-frame constraints and key-trajectory constraints.
Approach	In practice, human motion is highly coordinated, and the dimensionality of the control input for accurate motion representation, d u , is often much lower than the dimensionality of the system state, d x .
Outcome	The system achieves a degree of generality beyond the motion capture data.
Approach	More importantly, our system allows the user to specify a variety of spatial-temporal constraints such as end effector constraints throughout the motion, a capability that has not been demonstrated by previous approaches.
Approach	We also compare the results by decreasing the number of key trajectories.
Approach	We follow a standard approach of representing x t and u t using cubic B-splines.
Outcome	Our video also demonstrates that the system can generate motion for characters whose skeletal models differ significantly from those in the database.
Approach	For example, the user can create a slightly different jumping motion by adjusting the positions of both hands at the top of the jump.
Approach	In facial animation, nonlinear constraints can be used to specify the distance between two points on the face or 2D projections of 3D facial points.
Approach	The system automatically learns a low-dimensional linear dynamic model from motion capture data and then enforces this as spatial-temporal priors to generate the motion.
Outcome	We have tested the creation of jumping motion from key-trajectory jumping constraints when the prior is learned from a database of jumping, general locomotion, or walking.
Background	Much of the difficulty in solving this problem appears to result from the physics constraints because optimization without physics is effective for editing [Gleicher 1998].
Outcome	We have presented an approach for generating both full-body movement and facial expression from spatial-temporal constraints while matching the statistical properties of a database of captured motion.
Outcome	Third, the optimization does not require physical models.
Approach	We assume that both the initial state, x 1:m , and the control input, u t , are independent and identically distributed.
Approach	We, therefore, evaluate how the database influences the final motion and how increasing or decreasing the number of user-defined constraints influences the final animation.
Approach	The system uses trajectory optimization to automatically find an animation H ˆ that best satisfies the userspecified constraints while matching the statistical properties of the motion capture data: H ˆ = arg min H − ln p(E|H) − ln p(H).
Background	They showed that a sequence of images of such moving scenes as sea-waves, smoke, and whirlwinds can be modeled by second-order linear dynamic systems.
Background	A number of researchers have developed statistical models for human poses and used them to solve the inverse kinematics problem.
Approach	” The average reconstruction error is the L 2 distance between the original test motion and the motion reconstructed from the linear time-invariant system and computed by cross-validation techniques.
Background	A number of researchers have used variants of Hidden Markov Models (HMMs) to statistically represent human motion: either full-body movements [Molina Tanco and Hilton 2000; Brand and Hertzmann 2000; Galata et al. 2001] or speechdriven facial expressions [Bregler et al. 1997; Brand 1999].
Approach	The Jacobian matrix and the Hessian matrix of the energy function are symbolically evaluated at each iteration.
Approach	The dimensionality of the system state, d x , can be automatically determined by choosing the d x for which the singular values drop below a threshold.
Approach	In facial animation, y n is the 3D positions of all vertices on the face model.
Approach	Our approach is also to learn a statistical dynamic model from human motion capture data; however, the dynamic behavior of our model is controlled by a continuous control state rather than a discrete hidden state as in HMMs and SLDS.
Background	Consequently, we discuss related work in constraint-based trajectory optimization and data-driven animation with an emphasis on statistical models.
Approach	We found that the optimization procedure always converges quickly (usually less than 100 iterations and less than 30 seconds).
Approach	Temporally, the constraints could be instantaneous constraints for a particular frame, multiple-frame constraints, or continuous constraints over a period of time.
Approach	Our approach is also part of an alternative set of techniques that relies on motion data to constrain the search to natural looking motions.
Outcome	We demonstrate the effectiveness of this approach in two domains: human body animation and facial animation.
Approach	Conceptually, the dynamic prior can be thought as dimensionality reduction of the motion in a spatialtemporal domain.
Background	Chai and colleagues [2003] presented a real-time vision-based performance animation system that transforms a small set of automatically tracked facial features into facial animation by interpolating examples in a database at run time.
Approach	With an appropriate database, we compare the quality of motions generated by different numbers of constraints.
Background	Switching linear dynamic system (SLDS) have also been used to model human motion.
Approach	User-defined constraints can be linear or nonlinear.
Background	For example, motion graphs can be used to resequence whole-body or facial motions (see, for example, [Arikan and Forsyth 2002; Kovar et al. 2002; Lee et al. 2002; Zhang et al. 2004].
Outcome	Our behavior-specific statistical motion model is capable of generating a rich variety of actions.
Approach	The user can also specify a small set of key trajectories for the root, hands and feet positions to generate a realistic jumping motion ( figure 1 bottom).
Approach	We also compare alternative techniques for generating animation from user-defined constraints such as linear interpolation, trajectory-based inverse kinematics, and inverse kinematics in a PCA subspace.
Outcome	The accompanying video shows that results become worse when we decrease the number of the userdefined constraints.
Outcome	The accompanying video demonstrates the effectiveness of our system for generating a number of individual behaviors, including walking, running, and jumping.
Outcome	The quality of the final animation produced by our system depends on the motion priors derived from the motion capture database and the number of user-defined constraints.
Approach	We have experimented with both key-frame and key-trajectory constraints.
Approach	We keep the constraints constant and use a cubic spline to represent the motion.
Outcome	We show that the system can generate natural-looking animation from key-frame constraints, key-trajectory constraints, and a combination of these two constraints.
Background	They also used a series of local statistical pose models constructed at run time to reconstruct full-body motion from continuous, low-dimensional control signals obtained from video cameras [Chai and Hodgins 2005].
Outcome	This motion prior, together with user-defined constraints, comprises a trajectory optimization problem.
Outcome	For example, we have generated a motion using constraints that cannot be satisfied directly by any motion in the database and found that the quality of the reconstructed motion was acceptable.
Approach	For key-frame constraints, the user defined a sparse set of walking constraints and used them to generate walking motion from the priors learned from a number of different databases.
Approach	For example, the user can generate a walking animation from a small set of key frames and foot contact constraints ( figure 1 top).
Outcome	We observe a noticeable foot sliding artifact on one foot when two key trajectories (root and one foot) are used to create a walking motion.
Approach	They could be specified either at isolated points (key frames) or across the whole motion (key trajectories).
Approach	The statistical dynamic model plays a role similar to that played by the dynamics in physically based optimization because it constrains the motion to only part of the space of possible human motions.
Approach	The likelihood term evaluates how well the synthesized motion matches the constraints specified by the user.
Approach	The human body motion capture database (about 15 minutes) includes data of locomotion (jumping, running, walking, and hopping) and interacting with the environment (standing up/sitting down, reaching/picking up/placing an object).
Approach	Rather than requiring that constraints be specified in 3D, it is often more intuitive to specify where the projection of a point on the character should be located.
Approach	Based on the statistical dynamic equation (Equation 4), the current system state x t only depends on the previous system states x t−m:t−1 and the current control input u t .
Approach	The third method is a simple data-driven inverse kinematics algorithm that minimizes the velocity changes of the motion in a reduced PCA space, x t .
Approach	Therefore, the system also allows the user to specify the 2D projections of any 3D point on a user-defined screen space.
Approach	We evaluate how the database influences the final motion by keeping the user-defined constraints constant.
Approach	The walk data set is from multiple subjects and contains different styles.
Approach	Like physically based optimization, we formulate the problem as a trajectory optimization and consider the entire motion simultaneously.
FutureWork	However, we have not yet attempted to assess how far the user’s constraints can stray from the motions in the database before the quality of the resulting animation declines to an unacceptable level.
Approach	We then compare the animations created by key frames that are spaced increasingly far apart in time.
Background	Pavlović and his colleagues [2000] present results for human motion synthesis, classification, and visual tracking using learned SLDS models.
Approach	Our approach allows the user to generate a wide range of human body and facial animation by specifying spatial-temporal constraints throughout the motion.
Approach	The dimensionality of the control input (d u ) can be automatically determined by choosing the d u for which the singular values drop below a threshold.
Approach	The statistical dynamic model, however, is usually lower dimensional than the dynamics model, making the optimization more efficient, less likely to be subject to local minima, and more likely to produce natural motion.
Outcome	For example, we can use a small set of key frames and foot contacts to generate normal walking, climbing over an obstacle, a baby walking, and mickey-mouse style walking.
Challenge	In this paper, we construct statistical models from motion capture data and then combine these models with trajectory optimization to generate a motion that satisfies user-defined constraints.
Approach	The combination of the motion prior and the user’s constraints provides sufficient information to produce motion with a natural appearance.
Approach	For whole-body animation, the user can specify the positions or orientations of any points on the body, or joint angle values for any joints.
Challenge	Unfortunately, correct physics does not ensure that the motion will appear natural for characters with many degrees of freedom.
Approach	We have the corresponding energy term E prior dynamic = − ln T t=m+1 p(x t |x t−1:t−m , u t ) ∼ −α T t=m+1 x t − i=1 m A i x t−i − Bu t 2 (12) where α is a tuning parameter.
Approach	For example, a novice user might want to control the paths of specific joints or paths over a period of time using a performance animation system while a more skilled user might prefer using key frame constraints.
Challenge	Extending this approach to generate natural motion for a full human character has proved to be hard because the system is high dimensional, the physics constraints make it highly nonlinear, and defining an objective function that reliably measures the naturalness of human motion is difficult.
Background	Another solution for data-driven inverse kinematics is to interpolate a small set of preexisting examples using constraints.
Approach	Note that we choose weak priors (static models) to model the priors for both initial states and control inputs so as not to restrict the type of motions the algorithm can generate.
Approach	Our optimization framework can also be applied to the problem of generating human body motions for a character whose skeletal model is markedly different from the subjects in the database.
Approach	Like physically based optimization [Witkin and Kass 1988], we represent the system state x t and the control signal u t independently.
Approach	For facial animation, the user can specify the positions or orientations of any points on the face, or the distance between any two points.
Approach	The system first automatically learns a statistical dynamic model from motion capture data.
Approach	The user defines various forms of constraints, E, throughout the motion, which are then used to compute the likelihood term, − ln p(E|H).
Approach	To remove this ambiguity, we assume that the matrix B is an orthogonal matrix.
Approach	The statistical dynamic model used in this paper was motivated by the dynamic model used for video textures by Soatto and his colleagues [2001].
Approach	The user selects six points on the face and specifies the 2D projections on the screen space at three key instants.
Background	Motion interpolation, on the other hand, does allow isolated constraints to be satisfied (for example, [Rose et al. 1998; Kovar and Gleicher 2004; Mukai and Kuriyama 2005]).
Approach	We choose all initial values using random values between 0 and 1 except that a linear interpolation of the user-specified keyframe constraints is used for initialization.
Approach	The matrix C is constructed from the eigenvectors corresponding to the largest eigenvalues of the covariance matrix of the data, and D is the mean of all example data, D = (Σ N n=1 y n )/N .
Approach	For example, a jumping motion can be created by specifying a start pose and the positions of both feet and root throughout the motion.
Outcome	We also show that the system can use a statistical dynamic model learned from a normal walking sequence to create new motion such as walking on a slope.
Background	These systems cannot match poses or satisfy such kinematic constraints as end effector constraints unless the motion database happens to contain a motion that satisfies those constraints.
Approach	The user can also use trajectories of a small set of high-level facial features (the mouth width and height and the openness of the eyes) to generate facial animation.
Outcome	For example, the numerical error increases steadily (0.94, 1.06, 1.81 degrees per joint per frame) when the number of constraints is decreased (6, 4, 2 key frames).
Approach	More specifically, we take one motion sequence out of the database and use it as a testing sequence.
Approach	We, therefore, have designed a number of experiments to evaluate the performance of our algorithm: The importance of the motion priors.
Approach	Many motions might satisfy the user-defined constraints.
Approach	Linear constraints can be used to define joint angle constraints in human body animation and positions in facial animation.
Background	Both Liu and Popović [2002] and Abe and his colleagues [2004] showed that many dynamic effects can be preserved by enforcing patterns of linear and angular momentum during the motion.
Outcome	This statistically based optimization approach complements a physically based optimization approach and offers a few potential advantages.
Approach	This property led us to formulate the motion synthesis problem as a trajectory optimization problem.
Outcome	In the accompanying video, we demonstrate that the user can generate a transition from walking to jumping, from walking to sitting down, and from walking to picking up an object (figure 6).
Approach	This type of constraint could be extracted by rotoscoping.
Approach	We pose constraint-based motion synthesis as a maximum a posterior (MAP) problem and develop an optimization framework that generates natural motion satisfying user constraints.
Approach	A good match between the motion and the user-defined constraints results in a low energy solution.
Background	Li and his colleagues [2002] used SLDS to synthesize and edit disco dancing motion.
Background	Grochow and colleagues [2004] applied a global nonlinear dimensionality reduction technique, Gaussian Process Latent Variable Model, to human motion data and then used the learned statistical pose model to compute poses from a small set of user-defined constraints.
Approach	Therefore, the statistical dynamic model might achieve faster convergence and be less subject to local minima.
Approach	The statistical dynamic equations, together with an automatically derived objective function and user-defined constraints, comprise a trajectory optimization problem.
Approach	We compare the methods using key-frame constraints and key-trajectory constraints.
Approach	Typically, the objective function values decrease rapidly in the early iterations and then level off as they approach the optimal value.
Outcome	We demonstrate the effectiveness of this approach by generating whole-body and facial motion from a variety of spatial-temporal constraints.
Background	However, interpolation across a complete behavior does not have enough degrees of freedom to allow the specification of full pose constraints or end effector constraints across multiple frames.
Approach	The second method is trajectory-based inverse kinematics that minimizes the velocity changes of the motion in the original configuration space, y t , without any priors.
Approach	We observe that the reconstruction error of the statistical model decreases as both the order of dynamic system and the number of dimensions of the control input increases.
Background	Reformulating the dynamics to avoid directly computing the torques also provides a significant performance improvement [Fang and Pollard 2003].
FutureWork	One of immediate directions for future work is, therefore, to design intuitive interfaces that allow the user to specify spatial-temporal constraints quickly and easily.
Approach	Key trajectory constraints were extracted from a performance interface using two video cameras [Chai and Hodgins 2005].
Approach	The user can achieve detailed control over facial movement by specifying the trajectories of a small set of 3D facial points.
Approach	This approach could be used for rotoscoping a video, or for a single camera performance animation.
Background	Recently, interpolation and motion graphs have been combined to obtain some of the advantages of each approach [Safonova and Hodgins 2007].
Approach	The second term on the right side of Equation 11 computes the prior for the initial state, x 1:m , and control input, u m+1:T .
Approach	The user can fine tune the animation by incrementally modifying the constraints.
Background	For example, Popović and Witkin [1999] showed that significant changes to motion capture data can be made by manually reducing the degrees of freedom to those most important for the task.
Background	Safonova and her colleagues [2004] demonstrated that an efficient optimization can be achieved in a behavior-specific, low-dimensional space without simplifying the dynamics.

Background	Since then, many methods have been proposed to further improve the accuracy of Eulerian surface tracking.
Approach	Their advection method is unconditionally stable and fully conservative.
Approach	The x, y and z components of fluid velocity u = (u, v, w) are stored at the center of the faces perpendicular to the x, y and z axis, respectively.
Approach	Clamp the β j to 1 by re-scaling A i j ← A i j /β j .
Approach	To extrapolate the velocities from inside the liquid into the surrounding air we use the scheme described in [CM11b], i.e. we apply the method of [JRW07] to derive the velocities a few grid cells away from the interface and then extrapolate based on a hierarchy of grids to obtain velocities far away from the surface.
Approach	To bring out these small scale details in surface rendering, we propose a post processing method.
Approach	Implementing the method described above on a GPU would require 5 scatter passes per iteration in steps 4, 6, 8, 10, and 11.
Approach	We achieve this by using density based surface tracking with a novel, unconditionally stable, conservative advection scheme and a novel interface sharpening method.
Approach	The scalar pressure p and the density ρ are stored at cell centers following [MMTD07].
Approach	This artificial divergence pushes the excess density away from the cells whose ρ > 1.
Approach	However, we cannot directly use ρ because a cell with V < 0.5 will likely have ρ < 0.5 causing the solver to treat it erroneously as air.
Outcome	We achieved a frame rate of over 30fps with two GPUs, one for simulation and one for ray-tracing.
Outcome	We proposed a method for simulating liquids that conserves mass and is effective in keeping the volume defined by the 0.5 iso-contour close to constant.
Approach	Finally, we enforce incompressibility by making the velocity field divergence free.
Outcome	Even though the density values are nonzero, marching cubes does not generate surface meshes in those regions.
Approach	The total mass is computed by integrating ρ over the whole simulation grid.
Approach	The surface density ρ contains small scale details that are not captured by the 0.5 iso-contour.
Outcome	Our method conserves the liquid’s mass as expected and prevents the water level from decreasing.
Approach	Since the surface density can deviate from 1 temporarily, the overall volume may vary over time though.
Background	Lentine et al. [LGF11] achieve this by first iterating through all cells j with β j > 1 and re-scaling all A i j to A i j /β j .
Approach	Scale A by the γ i , i.e. A i j ← A i j /γ i .
Background	To bring them even closer to 1 Lentine et al. apply a diffusion step on ρ n+1 and the γ i .
Approach	Advect γ i using the semi-Lagrangian method (set to 1 in the first time step).
Background	The downside of CLVOF is the need to use two representations which can be quite computationally intensive.
Approach	This way mass only moves from the air side to the liquid side.
Background	This problem can be reduced by re-distributing mass only within connected regions as pro∗ posed by [KLL 07].
Approach	For all the examples we used a time step size of 1/30s, ∆x = 0.05m, gravity 10m/s 2 and D = 2.1.
Approach	Apply diffusion as in the original approach.
Background	Mullen et al. [MMTD07] also added this term to the divergence but with λ = 1 and η = ∞ which can cause stability problems when ρ is much larger than 1.
Approach	To enforce incompressibility, we first compute the pressure using a variational framework [BBB07] and then use the pressure gradient to make velocity field divergence free.
Approach	They also exist on the air side of the surface of large liquid regions.
Outcome	However, in contrast to PLS, when such features join the main body of water again, they correctly contribute to its volume so that the global level remains constant.
Outcome	First, although our sharpening scheme ensures that the ρ = 0.5 interface is sharp, it does not modify regions where ρ > 0.5.
Approach	We solve for the pressure p with the multigrid method of [CM11a] which enforces separating solid boundary conditions.
Challenge	With global volume loss the water level decreases over time while local volume loss causes small detail such as thin sheets and droplets to disappear.
Approach	If a grid point is in a solid we set the corresponding weight to zero and re-normalize the weights.
Approach	We solve this problem by manipulating ρ to sharpen the interface.
Outcome	Another case is when the ratio of surface area to volume is large.
Approach	With the method described above, this problem gets gradually corrected over time.
Approach	At this point, all the β j are 1 but the γ i might still deviate from 1.
Approach	We implemented our method using CUDA and ran the simulations on an NVIDIA GTX 680.
Approach	We used the PLS implementation of [MF] and set the number of particles per cell to 64.
Approach	Re-compute the β j from the updated matrix A. 9.
Approach	Here, the regions where 0 < ρ < 0.5 represent features such as small splashes and thin sheets that are too small to be captured with the grid resolution used.
Background	This technique was extended and used for con∗ serving volume of bubbles [KLL 07], highly deformable objects [ISF07] and liquids [MMTD07].
Approach	Compute the new γ i from the updated matrix A. 7.
Background	Apart from the Eulerian formulation we use, there are many alternative models to simulate 3D liquids such as the LatticeBoltzmann method [TR04] and [TR09], approaches based on the discrete sin-cosine transform [LR09] or particle based ∗ methods such as [MCG03], [PTB 03], [APKG07], [SP09], and [SG11].
Approach	When then follow the gradient of the solid signed distance function away from the solid for a distance of S∆x and scatter d to nearby grid points.
Approach	For each cell j whose β j < 1, add ρ n j (1 − β j ) to ρ n+1 by distributing the value among the ρ n+1 k , where k are the cells reached by the forward tracing and tri-linear interpolation, i.e. ρ k n+1 += ρ n j (1 − β j )w + jk .
Outcome	These examples demonstrate the ability of our method to simulate liquid in a non-axis aligned moving container.
Background	The surface can then be extracted from the Level Set.
Approach	It starts from the cell center and follows the gradient field of the density ρ until it reaches the 0.5 iso-contour.
Background	Various approaches have been proposed to track the liquid domain more faithfully.
Outcome	We have demonstrated the strength of our technique in various scenarios.
Background	Lentine et al. [LAF11] propose a method to ensure the β j are all 1 while the γ i stay close to 1.
Approach	So in what follows, we use the symbol ρ for the surface density.
Outcome	We show the effectiveness of the proposed method in several practical examples all running either at interactive rates or in real-time.
Approach	Forward trace the velocity field to add the weights (1 − β j ) to A for all cells j where β j < 1 by distributing them among the A k j , where k are the cells reached by forward tracing and tri-linear interpolation as before, i.e. A k j += (1 − β j )w + jk .
Approach	If the cell is partially solid, we first compute the excess density d = ρ i − V i .
Approach	Evaluate ρ n+1 from ρ n and γ from γ by backward tracing and tri-linear interpolation from cells l but this time scale the weights by max(1,β γ i l ) , i.e. ρ n+1 i += ∑ l max(1,β γ i l ) w − li ρ n l ) 5.
Approach	The equations are solved in the domain specified by a surface density field ρ [MMTD07], in the region where ρ > 0.5.
Outcome	We also propose a density post-processing method to reveal sub-grid details of the liquid surface.
Approach	The matrix A is computed by performing multiple forward and backward traces as follows: 1.
Background	They iterate through all the cells dimension-by-dimension.
Outcome	These are difficult cases for level set approaches while our method handles them without any problem.
Background	Enright et al. [EMF02] devised the Particle Level Set (PLS) method which uses particles on both sides of liquid-air interface to reduce volume loss.
Approach	Let A be the matrix of the discretized advection operator such that ρ n+1 = Aρ n , where ρ n and ρ n+1 are the density in the current and the next time step respectively.
FutureWork	This is part of our future work.
Background	Sussman and Puckett [SP00] proposes coupled Level Set and Volume-ofFluid (CLVOF) which track the fluid interface with both representations, where VOF is used for re-initializing the Level Set.
Challenge	However, despite several improvements in subsequent works such [PP04], [AGDJ08], reconstructing surface normal and curvature from VOF is still difficult.
Approach	However, both are just approximations to the doubly-stochastic matrix (all rowand column sums are one) closest to the original discrete advection operator.
Approach	After this we subtract d from ρ i .
Approach	Scale A by the γ i , i.e. A i j A i j /γ i .
Approach	This method keeps ρ i ≤ V i in most cells near solid boundary and guarantees ρ i = 0 inside the solid.
Outcome	Parameter tuning to get visually appealing results did not take much time.
Outcome	Our method handles moving solid boundaries as well as cells that are partially filled with solids.
Approach	The tricky part in our case is to determine the fraction of liquid in each cell.
Approach	We then define ρ i = min(max(γ ρ i i ,θ),1) and extract the liquid surface as the 0.5 iso-surface of this modified density field.
Approach	Then, β j = ∑ i A i j is the fraction of mass from cell j that gets advected.
Approach	Density post-processing was turned off unless otherwise stated.
Background	In incompressible fluid simulations, the fluid-density is 1 everywhere and therefore not stored.
Approach	The basic idea is to reorder the forward tracing and the re-scaling steps to simplify the calculations.
FutureWork	A way to improve the results further would be to apply thinning to the parts of the surface that come from region with ρ < 0.5 in order to compensate for the density up-scaling.
Background	The problem of loss of liquid mass and momentum has also been addressed by proposing elaborate advection methods such as BFECC [KLLR05], modified MacCormack ∗ [SFK 08], derivatives advection [KSK08] and conservative semi-Lagrangian advection [LGF11], [LAF11].
Approach	Compute A by performing a backward tracing step as before, i.e. A i j = w − ji .
Approach	Another advantage of our new scheme is that A does not need to be stored explicitly because the order of the operations allow for updating ρ n+1 , β and γ directly.
Approach	This fraction is used to decide whether a cell is included in the linear pressure solve.
Background	Then they distribute a fraction of the total mass change back to each cell based on a local area measure.
Approach	Let w ij − (and w + ij ) represent the fraction of value that cell i gives to cell j which is found by backward (and forward) tracing and computing the tri-linear interpolation weights.
Outcome	The density post processing method we proposed is an effective way to alleviate this effect.
Approach	We then extrapolate ρ from cells that have V > 0 to adjacent cells with V = 0 so they are included in the linear system.
Outcome	Several solid objects move at high speed across the tank sloshing the liquid up to the air.
Approach	If, for two neighboring cells i and j, γ j > γ i , they move ρ j (γ j − γ i )/2γ j from cell j to cell i and set both γ j and γ i to γ j +γ 2 i .
Approach	However, it does not conserve mass.
Approach	So far, the two cases above are not distinguished.
Approach	If γ j < γ i , the flow happens in the opposite direction.
Background	An alternative to VOF is to track a smeared-out surface density and keep it relatively sharp with a sharpening operation.
Challenge	Ideally, the surface density has the form of a step function at the liquid-air interface.
Background	Therefore, [MMTD07] apply a sharpening filter at each time step which conserves mass globally but not locally.
Approach	In the first line we make sure that ρ ≥ 0 at the next time step.
Background	The main advantage of this class of methods is that they handle topological changes implicitly in contrast to mesh-based tracking methods.
Approach	This process is repeated 1 to 7 times per time step.
FutureWork	An alternative to our sharpening method is to perform antidiffusion step [SHA11], which is an interesting avenue for future work.
Challenge	Even though these methods reduce volume loss, they cannot guarantee complete volume conservation.
Approach	Re-compute the γ i from the updated A. 11.
Outcome	In contrast, with PLS, most of the liquid disappears in the course of the simulation due to the large time step size used.
Background	This method works well for compressible flow on fine grids.
Background	CLVOF is extended to handle multiple interfaces in [KPyNS10].
Approach	It is also needed in the ghost fluid method [ENGF03] to accurately handle the liquid-air boundary.
Background	However, as discussed in [LAF11], the scheme produces artifacts when used for incompressible flow on coarser grids.
Approach	In the second line we make sure that cells with ρ > 0.5 are not modified.
Approach	We discretize the simulation domain using a regular staggered grid [HW65].
Approach	TraceAlongField determines where to put the lost mass.
Background	As an alternative to the signed distance field, [MMTD07] in- troduced the idea of using a density field as the scalar field for surface tracking with the liquid surface being the 0.5 isosurface.
Background	For an overview of existing methods we recommend the class notes of Wojtan et al. [WMFB11].
Approach	We advect ρ using our unconditionally stable conservative advection method which we derived from the method proposed by Lentine et al. in [LGF11] and [LAF11] and improved in terms of computational cost.
Approach	While the visual results are of similar quality as shown in Figure 2 and the accompanying video, our simplification reduces the number of scatter passes from 5 to 3.
Approach	With constant mass, local volume loss causes a local increase of the density used for surface tracking which we detect and correct over time.
Outcome	Our method conserves mass in all examples and generally keeps the volume close to the true liquid volume.
Approach	Here is our modified scheme: 1.
Approach	After this we advect the velocity field and take external forces into account.
Outcome	One such case is when a liquid ball hits the ground and spreads out until it becomes thinner than the grid spacing.
Approach	While our approach conserves mass, volume loss is still possible but only temporarily.
Approach	In the latter case, we want to leave ρ unchanged but in the former we want to scale up ρ so that the features appear in the 0.5 iso-surface.
Approach	We computed the mass and the volume enclosed by the 0.5 iso-contour of the liquid over time in various examples.
Approach	We chose to use surface density instead of the signed distance field because there are advection methods that strictly conserve quantities like density such as the one proposed by [LAF11].
Approach	Similarly, for each cell j whose β j < 1, add (1 − β j ) to γ by distributing the value among the γ k , where k are the cells reached by the forward tracing and tri-linear interpolation, i.e. γ k n+1 += γ n j (1 − β j )w + jk .
Approach	With this choice excess density gets removed from solid quickly enough to not cause visual artifacts.
Approach	To handle the cells with ρ i > 1 (whether or not V = 1 or V < 1), we add min(λ(ρ i −1),η) to the divergence, where we ∆x use λ = 0.5 and η = 1 in all our examples.
Approach	The tracing stops if a predefined distance D∆x is reached or if it crosses a solid boundary.
Approach	The resulting discrete conservative advection operator is not the same as the one computed with the original scheme.
Approach	To measure the volume we used marching cubes to extract the 0.5 contour triangle mesh of ρ and determined the enclosed volume.
Outcome	Our method conserves mass and prevents volume loss in this difficult case as well.
Approach	During the simulation, the value of ρ i can become larger than V i in some cells which is a non-valid state.
Background	Mullen et al. [MMTD07] modify it to conserve mass by summing up the mass change due to this update across all cells.
Approach	The case where V i = 1 is handled in the incompressibility enforcement step described in the next section.
Approach	We used σ = 2∆x for the Gaussian blur filter and θ = 0.01 in this example.
Approach	Advect γ i using the backward semi-Lagrangian method (set to 1 in the first time step).
Approach	An indicator of this amount are the γ i = ∑ j A i j .
Background	Later Foster and Fedkiw [FF01] employed the semi-Lagrangian method introduced by Stam [Sta99] to solve the advection term and the level set method and particles to track liquid surface.
Approach	In the level-set approach, these features are destroyed by the redistancing step.
Approach	This update sharpens the interface.
Challenge	Moreover, Lagrangian components add significant run-time cost and complicate the implementation significantly, especially for GPUs.
Challenge	A way to alleviate this problem is to introduce Lagrangian components such as particles [FF01], [EMF02] or triangle meshes [BGOS05].
Approach	We compared our method with the particle level set (PLS) approach [EMF02].
Challenge	Local mass conservation prevents small scale details of the free surface from disappearing, a problem that plagues many previous approaches, while global mass conservation ensures that the total volume of the liquid does not decrease over time.
Background	In a second step they iterate through all cells j with β j < 1 and forward trace the velocity field to adding the weights (1 − β j ) by distributing them among the A k j , where k are the cells reached by forward tracing and tri-linear interpolation.
Approach	ScatterValue deposits −∆ρ i to nearby grid points using tri-linear weights.
Approach	Add the weights γ i to β by distributing them among the β l , where l are the cells reached by backward tracing and tri-linear interpolation, i.e. β l += w − li γ i .
Outcome	The method has its limitations as well.
Approach	(This can be done in-place during the previous step).
Approach	Our time integration scheme is summarized in Algorithm 1.
Approach	We use values of D between 1.1 to 3.1 in all of our examples.
Outcome	Due to its stability, it allows the use of large time steps which makes it suitable for both off-line and real-time applications.
Approach	γ ← γ .
Approach	As demonstrated in Table 1 , our method keeps γ in a similar range to that of [LAF11], while [LGF11] has a much larger range, resulting in visible compressibility artifacts.
Approach	We then add back −∆ρ i by using Algorithm 2.
Background	The traditional semi-Lagrangian method ensures that all the γ i are 1 while the β j are arbitrary.
Background	Grid-less methods work with Lagrangian elements only such as particles [ZB05], [APKG07] or [YT10], triangles meshes [M 09],  ̈ [BB09] and [WTGT10].
Approach	With this approach, the overall mass defined by the surface density is conserved.
Background	A popular way to compensate volume gain or loss is to modify the divergence of the velocity field as proposed in [FOA03].
Outcome	The jet has a very fast flow rate and generates fast moving liquid splashes and sheets.
Approach	Then we update ρ i using this modified ∆ρ i in Equation 16.
Approach	In contrast, since γ < 0.5 everywhere inside small scale features, blurring will still result in γ being small.
Approach	For the ghost fluid method, we also need a signed distance function near the free surface.
Approach	A scenario in which this happens is when liquid flows very fast towards a solid boundary and gets reflected due to our method for removing excess density from the solid.
Approach	For rendering, we extract the triangle mesh of the 0.5 isocontour of ρ using the marching cubes method [LC87].
Approach	The interaction of the liquid with the environment is handled by considering the appropriate Dirichlet and Neumann boundary conditions.
Background	This approach is typically used in level-set based liquid simulations as well to extract the zero contour of the signed distance field [EMF02].
Challenge	A well known drawback of the level set method is that volume is lost both globally and locally.
Approach	Our code run at interactive rates in all examples.
Approach	Our fluid domain tracking approach builds upon this work and make it conserve mass both locally and globally.
Background	Until recently, the level set method was the method of choice in graphics.
Background	However, even with this technique, local mass loss can still occur due to moving mass away from small features resulting in the disappearance of small surface details.
Approach	We approximate this field by defining φ i = −(ρ i − 0.5)∆x and use the method of [CM11a] to compute the coefficients of linear system for pressure projection.
Outcome	We propose a new sharpening method which conserves mass both locally and globally.
Background	This successfully conserves mass globally.
Approach	To ensure that mass is conserved, A needs to be modified such that all the β j are 1.
Background	Here, the signed distance field is used as the scalar field with the zeroiso-surface as the liquid surface.
Background	3D Eulerian liquid simulation was introduced to computer graphics by Foster and Metaxas [FM96] who used a finite difference approach to solve the governing equations.
Background	In contrast, the scheme described above ensures that all the β j are 1, while the γ i are arbitrary.
Approach	However, this can be achieved by applying a Gaussian blur filter to γ.
Approach	The parameter τ controls the maximum difference in density between two adjacent cells, which we set to 0.4 as in [MMTD07].
Background	At this point, all the β j are 1, i.e. A is mass conserving.
Background	As an alternative to level-set, the fluid domain can be tracked with a Volume-of-Fluid (VOF) approach [HN81] where the volume fraction of fluid in each cell is evolved over time.
Background	One artifact of this approach is that mass moves far, potentially across the entire simulation domain.
Approach	The entries of A in the standard semi-Lagrangian advection is hence A i j = w − ji .
Approach	Now, since γ > 0.5 inside liquid, those values spread across the interface and cause γ to raise toward 1.
Challenge	Over time, however, the initially sharp boundary blurs out due to numerical diffusion.
Approach	So far, the method does not take solid fraction and solid velocity into account.
Outcome	In this paper we propose several methods to preserve volume both globally and locally using the information stored in the density field.
Approach	These two steps can be done concurrently.
Approach	Initialize β ← 0.
Approach	Compute the β j from A. 5.
Approach	We handle the situation differently depending on whether the cell is partially solid (V i < 1) or completely non-solid (V i = 1).
Background	This density field is not to be mistaken for the density field of the liquid.
Background	With proper care, VOF can be made mass conserving.
Approach	Adding additional divergence is important because in our case, ρ > 1 results in visual volume loss.
Outcome	One way coupling with fast moving solids is shown in Figure 11 and the accompanying video.
Challenge	Tracking the free surface of a liquid is an important and challenging problem.
Approach	However, the density field smooths out over time blurring the 0.5 iso-contour with the effect that we can no longer track the movement of the liquid surface accurately.
Approach	Notice that cells that are completely solid (V = 0) have ρ = 0.
Outcome	However, there are several situations where our method loses volume visually.
Approach	We use u s = (u s , v s , w s ) for the solid velocity and V i for the fraction of non-solid matter, i.e. fluid and f f f air in cell i.
Approach	The technique above guarantees that mass is conserved.
Approach	To this end, we define an additional function γ i = 2 min(ρ i , 0.5) and define the regions in which ρ needs to be scaled up as the regions where γ ≤ 0.5.
Approach	Then, we advect the surface density field and sharpen it.
Outcome	Another limitation is the possibility of losing local volume temporarily as discussed in the previous section.
Approach	Not storing A explicitly is possible in the original scheme as well but it would complicate the process considerably and would require even more scatter operations.
Approach	This yields the following density correction:
Background	To this end they keep track of the cumulative γ i over time as separate variables.
Approach	We use S = 1 in all of our examples.
Approach	Finally, we use the pressure field to make the velocity field divergence free.
Outcome	It could theoretically be possible that the region with ρ slightly above 0.5 expands so that the volume defined by the 0.5 iso-contour grows by a factor of two while keeping its original mass.
Approach	Evaluate ρ n+1 = Aρ n .
Approach	This modified method only requires 3 scatter passes in the steps 3, 6, and 7.
Approach	We propose a modification of this method.
Background	The most popular approach is to advect a scalar field with the fluid and define the liquid surface to be one of the isosurfaces.
Approach	The overall structure is the same as the one proposed in [MMTD07] with our novel modifications to the advection, sharpening and pressure incompressibility enforcement steps.
Approach	However, in contrast to the level set method where such variations go unnoticed, volume deviations are reflected in the density field.
Outcome	Even though our method cannot guarantee complete volume conservation at all times, it reduces this problem significantly in comparison to all the previous methods we have investigated.
Outcome	In this case, there are large regions with ρ < 0.5 that do not contribute to the volume because the 0.5 iso-contour is empty.
Background	Lentine et al. [LGF11] modified the semi-Lagrangian advection scheme to conserve mass by ensuring that each cell distributes all its mass of the current time step among some cells at the next time step.
Approach	We also clamp small positive densities to zero so that we do not have to apply the sharpening operator to this cell at the next time step, thus reducing computation cost.
Approach	Note that these diffusion iterations do not affect the β j , so they remain 1.
Background	[BGOS05] used a triangle mesh representation in connection with a level set grid, [HK10] augmented the level set grid with quadrature points.
Approach	This is done using multiple forward Euler sub-steps.
Approach	We propose a novel method to conserve mass during the sharpening phase that conserves mass both locally and globally.
Background	This method was introduced to computer graphics by Mullen et al. [MMTD07].
Approach	The problem is due to the clamping of the β j by re-scaling which limits the amount of density that reaches certain cells.
Outcome	With our approach we were able to create, for the first time, a 3d water demo that is both simulated and ray-traced in real time.
Approach	An important observation is that regions in which 0 < ρ < 0.5 do not necessarily represent small scale features.
Challenge	In this paper we focus on fluid mass and volume conservation.
Approach	Scattering is expensive on GPU’s because it either requires atomic operations or a prefix-scan.
Approach	The scalars V i+( 1 ,0,0) , V i+(0, 1 ,0) , and V i+(0,0, 1 ) 2 2 2 represent the fraction of non-solid area of the positive x, y, and z faces respectively.
Background	The mass conserving sharpening method of [MMTD07] transfers the mass from the liquid balls to the pool causing them to disappear mid-air.

Approach	This has to be done at every time step, because triangles on the boundary are moved and deformed.
Approach	The traction τ ra is dependent on the distance of the surface element from the particle p and has unit force per area in order to yield a force when integrated over the triangle.
Background	Therefore, Monaghan, one of the founders of the SPH formalism, uses special boundary or ghost particles on fixed borders to model interactions [ 16 ].
Approach	We use the seven point rule which has convergence order O(L 6 ) with respect to the triangle size L. (see Fig. 5(a) and Tab.
Background	Approaches to approximate this integral were proposed by Bloomenthal [ 24 ] and Sherstyuk [ 25 ].
Approach	The continuous equations and boundary conditions described in the previous section need to be discretized in space and time via a numerical method before they can be used in a computer simulation.
Outcome	In this paper, we present a new technique to model interactions between particle based fluids and mesh based deformable solids which meets these constraints.
Background	Later, Stora et al. [ 12 ] used a similar particle based model to animate lava flows.
Outcome	The generated waves, in turn, deform the pool walls.
Approach	All we require for our interaction method to work is • that the solid object is represented by a mesh and • that the displacements, velocities and forces are carried by the nodes of the mesh.
Approach	Then, we query all grid cells intersecting the extended box.
Approach	Analog to positions, the velocities of boundary particles are interpolated from the velocities of the triangle nodes.
Approach	The weighted summation of their potentials approximates the convolution of the potential over the domain of the boundary triangle in an optimal way.
Background	Then, a distribution scheme is used to compute the corresponding reaction impulses for the three vertices of the triangle.
Approach	The boundary conditions relate the quantities of the two adjacent materials to each other at the interface.
Background	They are typically derived from simple geometric primitives.
Background	The behavior of materials at these limits is defined by boundary conditions.
Background	Thus, the nodes of a mass-spring network are not very well suited for the application of interaction forces.
Approach	A force field with discontinuous first derivatives, in turn, yields artifacts such as the so called cooking of particles in concave regions and reduced stability of the simulation.
Background	The majority of publications in the area of physically based animation focuses on physical systems of one single type.
Approach	We do not go into the details of how equation (1) for elastic objects can be solved numerically.
Approach	The free surface of the particle system is rendered using the Marching Cubes algorithm.
Approach	The normalization warrants second order interpolation convergence.
Approach	For fluids we focus on particle based methods such as SPH for which this term can be omitted.
Approach	It is designed to be zero for r = r 0 which is the preferred distance of fluid particles from the interface.
Outcome	Our interaction model simulates repulsion, adhesion and friction near the fluid-solid interface.
Background	More recently, there has been an increased interest in efficient methods for the realistic simulation of fluids.
Approach	If the computations of steps three to five are grouped around single triangles, only data relevant for the current triangle has to be stored at a time ( Fig. 6 ).
Approach	Interaction modeling, thus, reduces to the problem of simulating the interaction between particles and triangulated surfaces.
Background	Materials, which are homogeneous at the macroscopic level, can mathematically be described as a continuum [ 18 ].
Approach	At every time step of the solid and fluid simulator, the following five steps are executed: 1.
Outcome	We mentioned the application to modeling with implicit surfaces.
Approach	To demonstrate the stability of our model in connection with concave surfaces, we filled a pool composed of 800 tetrahedral elements with 2000 fluid particles (see Fig. 7(a) ).
Background	They added space-adaptivity in [ 11 ].
Background	Early techniques were mostly based on mass-spring systems, which are still popular for cloth simulation [ 2 , 3 ].
Outcome	On today’s hardware only a limited number of fluid particles can be simulated in real-time which yields a relatively coarse fluid surface.
Approach	We define a threshold for the maximal acceptable distance between boundary particles.
Approach	In this step, positions and velocities are interpolated from the triangle nodes for each boundary particle.
Approach	We extend the axes aligned bounding box (AABB) of t along all axes about the interaction range.
Challenge	With the ability to simulate both, deformable solids and fluids, a new problem has been introduced, namely the mod- eling of the interaction of these structures.
Approach	Processing the five phases one after the other would have a negative impact on storage requirements.
Approach	The potential function is given by physical laws.
Outcome	In this paper, we present a method for simulating the interaction of fluids with deformable solids.
Challenge	An interaction model suitable for the use in interactive environments needs to be computationally efficient and the generated interaction forces must not induce any instabilities to the dynamic simulation.
Approach	The no-slip condition models friction between the fluid and the solid (see Fig. 2(c) ).
Approach	Our idea to solve the convolution integral is to use Gauss quadrature rules [ 17 ].
Background	The fluids typically interact with solid walls or the ground.
Approach	Unfortunately, normalization just distributes the distortions to adjacent regions of triangle interfaces as Fig. 3(c) shows.
Challenge	As important as the plausible animation of these substances is the fast and stable modeling of their interaction.
Background	In [ 13 ], Müller et al. derived inter particle forces from SPH and the Navier Stokes equation to simulate water with free surfaces at interactive rates.
Approach	A physical model relates these quantities to each other via partial differential equations (PDEs).
Approach	Therefore, we consider macroscopic models for both, solids and fluids.
Background	For the simulation of deformable solids, a variety of models have been proposed ranging from efficient mass-spring approaches to methods based on the physically more accurate Finite Element Method (FEM).
Approach	Thus, we cannot afford several seconds or even minutes per frame for the reconstruction and rendering of the free fluid surface as in off-line simulations [ 14 , 15 ] which explains the simplistic renderings of the fluids.
Approach	While the Euclidean distance between two points is uniquely defined, the distance between a point and a triangle or a point and a triangulated surface needs to be defined.
Challenge	In physically based animation, we are interested in the simulation of macroscopic effects at interactive speed.
Approach	Although the seven point rule yields good approximations of the convolution integral, triangles that are large in comparison to the interaction range of the surface would induce a poor sampling of the boundary field.
Background	Besides deformable models, they play an essential role in applications such as surgery simulation.
Approach	If the solid is considered to be impermeable, no fluid element is allowed to cross the boundary, which is described in the following equation:
Background	In the field of computer graphics, a large number of mesh based methods for the physically based simulation of deformable objects have been proposed since the pioneering paper of Terzopoulos [ 1 ].
Background	The idea of ghost particles was picked up in several following projects including our own.
Approach	By replacing the skeleton S with the triangulated surface T we get a smooth potential field around T (see Fig. 3(d) ).
Outcome	The simulation took about 70 ms per time step.
Approach	Another difficulty introduced by the weighted field method is the choice of the support radius h with respect to the size of the features of the boundary T .
Approach	The core idea to get smooth interaction fields is to place boundary particles onto the surface triangles according to Gauss quadrature rules.
Background	So far, only a few interactive methods for the simulation of fluids with free surfaces have been proposed.
Approach	We compute the relative vectors from the triangle nodes (shown in blue) to the boundary particles (shown in red) only once because they are the same for all subdivision triangles.
Outcome	The key contribution of our paper is to place these ghost particles onto boundary triangles of deformable objects and to derive their locations and weights according to Gauss integration [ 17 ], which allows to model fluid-solid interactions stably at interactive rates.
Approach	To compute interaction forces in step 5 we iterate over all the boundary particles of a triangle.
Approach	Comparison of the right hand side of the two equations of motion (1) and (2) reveals, that the Eulerian description makes the additional convection term v · ∇v necessary.
Approach	Note that most of the simulations are recorded in a real-time interactive environment.
Approach	We simulate the flow of 3000 particles through a virtual vessel, consisting of a deformable mesh composed of 560 tetrahedra.
Background	To resolve vertex-triangle collisions, an impulse is applied to the colliding vertex.
Outcome	The animation of the mesh and the particles are possible in real time at 60 ms per time step, while surface reconstruction took about half a second per frame.
Approach	The stress tensor σ f = 2μ (v) − pI is composed of the viscosity stress and the pressure stress.
Outcome	The method is designed for the use in interactive systems such as virtual surgery simulators where the real-time interplay of liquids and surrounding tissue is important.
Approach	Newton’s Third Law demands the continuity of stresses σ s and σ f throughout the boundary (see Fig. 2(d) ).
Approach	Let the kernel W (d, h) ∈ C 1 be a positive smooth monotonously decreasing function which is zero for d ≥ h and has a vanishing derivative at d = h.
Approach	These sampling points can be interpreted as boundary particles, which are placed and weighted according to the chosen Gauss quadratur
Approach	In the experiment shown in Fig. 10 , we turned on fracture of the Finite Element mesh.
Approach	Those discontinuities lead to discontinuous derivatives in forces since the forces depend on the distance field.
Background	Since T. Reeves [ 8 ] introduced particle systems as a technique for modeling fuzzy objects twenty years ago, a variety of special purpose, partice based fluid simulation techniques have been developed in the field of computer graphics.
Approach	Similarly, mechanical properties of incompressible Newtonian fluids can be described by the following two equations in Eulerian form where fluid quantities are observed in a fixed coordinate frame
Background	Bloomenthal uses radial Gauss kernels which can be separated with respect to different dimensions.
Outcome	This idea might be useful in other graphic domains as well.
Background	In physics, interaction potentials of two objects always depend on the distance between them.
Background	Desbrun and Cani [ 9 ] where among the first to use Smoothed Particle Hydrodynamics (SPH) [ 10 ] to derive interaction forces for particle systems.
Outcome	We have presented a new method for the simulation of interactions of deformable solids with fluids.
Approach	Now, the vessel is torn open when the elastic stresses caused by blood pressure exceed the material threshold.
Approach	The problem with the weighted sum approach arises when when multiple triangles meet.
Approach	To model the solid-fluid interaction we use virtual boundary particles.
Approach	We can, thus, use SPH-based approaches to approximate the boundary conditions stated in Sections 3.2, 3.3 and 3.4.
Background	More recent methods discretize continuous elasticity equations via the Boundary Element Method (BEM) [ 4 ] or the Finite Element Method (FEM) [ 5 , 6 , 7 ].
Approach	If both independent boundary conditions (4) and (5) hold, we simply have ∂t ∂ u = v at the boundary, i.e. both materials have the same velocity at the boundary.
Background	For possible solutions using the Finite Element Method (FEM) we refer the reader to [ 19 ], [ 6 ] or [ 7 ].
Background	Some of these methods allow the simulation of elastically and plastically deformable solids at interactive speed.
Approach	Our method connects these two areas of research.
Approach	For large supports, small features are smoothed out while small supports reduce the interaction range of T .
Background	Sherstyuk discovered a special kernel which can be analytically convoluted over a triangle domain.
Outcome	This scene demonstrates the interplay of various physical phenomena provided by the fluid simulator, the solid simulator and the interaction model.
Background	These approaches can be employed to represent blood or other liquids.
Approach	We present our interaction model with fluids represented by a Smoothed Particle Hydrodynamics approach (SPH) and with deformable solids represented by a Finite Element approach.
Outcome	The smoothness of the force fields is important for the stability of the simulation.
Background	However, the scheme is not completely error free.
Outcome	However, the general interaction model we propose works with any type of deformation technique as long as the object surface is represented by a polygonal mesh and the fluid by Lagrangian particles.
Approach	They are placed on the surface of the solid objects according to Gaussian quadrature rules allowing the computation of smooth interaction potentials that yield stable simulations.
Approach	We use the same scheme to distribute the forces to the vertices of the triangle surface.
Background	They propose a method to simulate the interaction between solids represented by mass-spring networks and an Eulerian fluid grid by applying spring forces to the mass-less marker particles in the fluid and the nodes of the mass-spring network.
Approach	Equation (2) again states that the change of momentum equals the internal forces derived from the stresses σ f plus the externally applied body forces f .
Background	Monaghan [ 16 ] uses a Lennard-Jones-like force to generate repulsive forces which approximate the no-penetration condition.
Approach	So far, we have applied forces to fluid particles only.
Approach	All experiments described in this section have been performed on an AMD Athlon 1.8 GHz PC with 512 MB RAM and a GeForce Ti 4400 graphics card with 128 MB RAM.
Outcome	We demonstrated the usability of our method in an interactive simulation environment with several scenes.
Outcome	Deformable boxes float freely on the water surface (see Fig. 7(b) ).
Approach	Force magnitudes can get amplified – at most by a factor of 8/7 – at the triangle center.
Approach	However, as Fig. 3(b) shows, the resulting field is distorted near triangle boundaries.
Background	Bridson et al. [ 26 ] solve a similar problem in the context of cloth simulation.
Background	Deformable objects are interesting to study in their own right.
Approach	However, according to Newton’s Third Law, proper reaction forces need to be applied to the deformable solid as well.
FutureWork	Thus, ongoing work focusses on fast algorithms for surface reconstruction.
Approach	Neither method is suitable for computing physical interactions because we are not free in the choice of the kernel.
Approach	From the fluid simulation method we require • that the fluid is represented by a set of particles and • that positions, velocities and internal forces are carried by the particles.
Approach	We dropped an additional large box into the pool (see Fig. 1 ).
Approach	The kernel W visc is designed such that its Laplacian ∇ 2 W visc takes the linear form above, but satisfies the normalization criterion on the kernel itself.
Approach	Thereby, quantities such as the density ρ, viscosity μ, deformation u or velocity v are all mathematically expressed by continuous functions over space and time.
Background	Most of the methods used in computer graphics to simulate deformable objects meet these constraints including massspring systems, the Finite Volume Method (FVM) and the Boundary Element Method (BEM).
Background	In all these papers, boundary conditions are not treated explicitly.
Approach	We use the normalized kernel W visc proposed in [ 13 ] for viscosity computations.
Approach	We focus on three main types of boundary conditions.
Outcome	We demonstrate our approach in an interactive simulation environment for fluids and deformable solids.
Background	The problems mentioned in the previous section are well known in the field of implicit surface modeling introduced by Blinn [ 23 ].
Approach	In this paper we concentrate on Lagrangian methods because they allow fluids with free surfaces to move freely in space while in the Eulerian case fluid computations are restricted to a spatially fixed and bounded grid.
Background	Materials such as fluids or solids are bounded by spatial limits.
Outcome	When it touches the water, it emits a wave that hits the pool boundary and causes it to fracture.
Approach	The traction has an order four repulsion term and an order two attraction term.
Approach	In the case of fluid-solid interaction, the geometrical domain of the interface Γ is defined as a surface between the volumetric solid continuum and the volumetric fluid continuum (see Fig. 2(a) ).
Approach	The equation is in Lagrangian form since the displacement vectors u follow the material points.
Approach	We also tested tighter queries which generate fewer neighbor candidates but their increased time complexity was not compensated by the reduced cost of interaction computations.
Approach	These vectors are then added to the blue nodes to generate the complete set of boundary particles.
Background	However, solids are typically represented by coarse meshes, especially in interactive simulations.
Approach	By pulling the pool wall, the user indirectly influences the water.
Outcome	Character skinning is another application where bulges or knees are known problems in regions where several close bones meet.
Background	Genevaux et al. [ 15 ] address the interaction problem explicitly.
Challenge	The method we describe in this paper models the exchange of momentum between Lagrangian particle-based fluid models and solids represented by polygonal meshes.
Approach	After t is processed, they are discarded.
Approach	When the convolution integral is used, the interaction of p with the surface T is modeled as the interaction of p with all the infinitesimal points in T .
Background	In computer graphics, a variety of techniques have been proposed to model liquids and deformable objects at interactive rates.
Approach	The velocity of the fluid particles is color coded visualizing the friction of the fluid with the boundary.
Approach	Neighbor references and boundary particles for all triangles would have to be stored at the same time.
Outcome	An important application of our method is the simulation of bleeding during virtual operations.
Approach	We propose a Lennard-Jones-like force that models both repulsion and adhesion to the contact surface.
Approach	Therefore, an efficient scheme is needed.
Outcome	A difficulty in connection with the interactive simulation of fluids is the extraction and rendering of a plausible fluid surface in real time.
Background	In these simulation environments, deformable objects play an important role.
Approach	Now that we have replaced the triangulated surface by a set of particles, the problem of triangle-particle interaction reduces to particle-particle interaction.
Approach	Therefore, we subdivide the boundary triangle until a sufficient sampling rate is provided.
Outcome	The output of step 3 is a list, containing all fluid particles within interaction range h of a triangle t.
Approach	The force contributions of boundary particles have to be distributed among the boundary triangle vertices so they can be picked up by the simulator of the deformable object.
Approach	The implicit surface is defined by selecting an iso-surface of F S .
Approach	The simulation runs at 20 frames per second.
Background	The separation allows post evaluation of the convolution in 3D space, only considering the distance to the triangle plane.
Background	Recently, Premoze et al. [ 14 ] introduced the Moving-Particle SemiImplicit (MPS) method to computer graphics for the simulation of fluids.
Background	According to [ 26 ] this distribution scheme provides continuity across triangle boundaries and introduces appropriate torques for off-center interactions.
Approach	There is a trade-off between computation time for the neighbor search and the quality of the neighbor list.
Approach	The boundary particles for a triangle t are kept only temporarily for the interaction computation.
Approach	In this case, all triangles contribute as a whole to the sum and generate bulges.
Approach	This threshold is chosen relative to the maximal interaction radius of the fluid particles and can be regulated by the user.
Approach	Our simulation of a blood vessel is a first step into this direction.
Approach	However, this error did not cause any artifacts or stability problems in our simulations.
Approach	In step 4, boundary particles are only generated for those triangles that have fluid particle neighbors.
Approach	The fact that for r = 0 the traction is finite (τ ra (0) = k) and that both, traction and first derivative vanish for r = h are important for robust real time simulations.
Approach	In contrast, the convolution integral sums up infinitesimal parts of the skeleton each properly weighted (see Fig. 4 ).
Approach	The boundary particles are generated by subdividing the triangle domain and by application of the Gauss quadrature rule to the resulting triangles (see Fig. 5(b) ).
Background	As a mesh-free method, it is closely related to SPH but in contrast to standard SPH, it allows the simulation of incompressible fluids.
Approach	The equation states that the components of the velocities of the fluid and the deformable object perpendicular to Γ are equal.
Background	In fluid simulation, on the other hand, boundary conditions are often considered a necessary but not a central issue.
Approach	The stresses σ s are functions of the displacements u.
Approach	One way to remove the problem is to replace the minimum by a weighted sum.
Approach	Unfortunately, concavities as well as close disconnected meshes generate discontinuous first derivatives of the distance field.
Approach	To speed up the search for these particles we use a regular grid with spatial hashing [ 27 ].

Approach	The above discussions assume that the basic skinning algorithm is SSD, but in many circumstances, other deformation schemes will be adopted [ 9 ], [ 10 ], most of which have been implemented in most animation packages.
Approach	In the synthesis process, for an intermediate pose x, a delta d x ( or d x r ) is synthesized by equation 7.
Background	The final animation can be synthesized by linearly blending RBF functions with the solved weights.
Approach	Then for the vertex v r = [v 0x , v 0y ], SSD θ (v r ) transforms v from rest pose to [v SSD x , v SSD y ] = [v 0x cos θ − v 0y sin θ , v 0x sin θ + v 0y cos θ ].
Background	Existing systems typically allow layering of both basic skinning methods such as Skeleton Subspace Deformation (SSD) and other deformations such as lattices, etc., and commercial systems may further allow additional proprietary deformation algorithms as part of the character skinning.
Approach	When a character goes wrong in some pose, animators can adjust joint influence weights.
Approach	We implement this unified approach as a Maya plug-in.
Background	Simpler parametric skinning approaches (of which SSD is the prototype) have a fixed number of parameters; these have also seen some development in recent years [ 6 ], [ 7 ].
Approach	We adopt Gaussian Radial Basis functions to interpolate d i r .
Approach	Although PSD and improved example-based schemes have been discussed in many publications [ 2 ], [ 3 ], [ 4 ], the reason why the inverse should be performed is still ambiguous.
Approach	For a vertex v, if sculpted in N example poses, then there are N delta d i , i = 0, . . . , N − 1 corresponding to each pose x i , i = 0, . . . , N − 1.
Background	Skinning using free form lattices [ 8 ], [ 9 ] or NURBS curves [ 10 ] instead of skeletons to drive character surface are also common practices in the entertainment production.
Approach	Some opportunities for control are provided to the animators.
Approach	In the forward case, α p is formed by the vector (v ssd x , v x p ) and the line y = Y v ssd x , where Y v x ssd is the y coordinate of v x ssd .
Outcome	We can see that in forward case, the direction of deformed vertex always keeps the same with the example cylinder ( figure 4 ).
Approach	v x represents the final position of vertex v in pose x.
Challenge	Therefore, providing a flexible and efficient solution to animation remains an open problem.
Background	A nice review of SSD is given in [ 1 ].
Background	Example based skinning methods such as Pose Space Deformation (PSD) are candidates for correcting SSD limitations.
Approach	We use two angles α p and α I p to analyze how directions of a deformed vertex change with the pose.
Approach	Here W and D r are column vectors with ith element ω i and d i r respectively.
Approach	When the character is animated, the position of a vertex in the animated pose is the result of weighted linear blending of its transformation by each associated joint.
Approach	ω k is the corresponding weight.
Challenge	The challenge in implementing example-based skinning in an existing system lies in the fact that it is generally believed that the interpolation of the examples is best performed before doing other skinning deformations (although there has been no analysis as to why this is the case), whereas the examples are specified by the user after the other deformations are performed.
Approach	We add this delta to the original character surface and then let SSD or any other skinning scheme finish the final transformation.
Approach	The first phase is to find each delta in the rest pose corresponding to each example pose.
Outcome	For inverse PSD however, that direction is changed along with the rotation of the joint.
Approach	In this step we need implement the inverse skinning operator SSD −1 .
Background	The range of breathtaking realistic 3D models is only limited by the creativity of artists and resolution of devices.
Outcome	By formulating the inverse process as a minimization problem we propose a unified model not only for SSD but also for other skinning schemes, into which shape interpolation can be incorporated.
Approach	M is the dimensionality of the function f ().
Approach	For example how to measure the distance between differing poses such as “lying down” and “pitching”?
Approach	Minimizing the function f (d ) in a particular direction is actually minimization problem of one variable, which is also called line minimization.
Background	Related research efforts have improved the speed and power of example-based skinning.
Background	With the help of modelling tools or capture devices, complicated 3D character models are widely used in fields of entertainment, virtual reality, medicine etc.
Approach	In the synthesis phase, for an intermediate pose x, we can obtain the delta d for this vertex by:
Challenge	Our goal is to incorporate examplebased skinning into a system having a variety of other skinning and deformation operations, and to be able to invert these operations regardless of their nature.
Approach	For each example pose P i , we have a d i , then we can apply radial basis function to d i (i = 0 . . . n − 1) in pose space to obtain ω i (i = 0 . . . n − 1).
Outcome	We formulate editing geometry in rest pose as an optimization problem and propose a unified framework which can be implemented on high-end commercial packages while allowing any proprietary skinning operators to be incorporated.
Approach	Therefore, by solving above equation we have: ω 1x = φ 11 −1 d 1x + φ 12 −1 d 2x = φ 12 −1 d 2x ω 2x = φ 21 −1 d 1x + φ 22 −1 d 2x = φ 22 −1 d 2x = d 2x ω 1y = φ 11 −1 d 1y + φ 12 −1 d 2y = φ 12 −1 d 2y ω 2y = φ 21 −1 d 1y + φ 22 −1 d 2y = φ 22 −1 d 2y = d 2y where φ i −1 j is the (i, j)th element of Φ −1 , and if i = j, φ i −1 j = 1.
Outcome	The cost of the inverse operation is not critical, however, since it is a one time “setup” cost, and the compute time is insignificant compared to the human time required to sculpt the desired deformations.
Approach	d y and d x are delta values in x, y coordinates computed from equation 3.
Approach	In our proposed framework, this step will be replaced by an optimization routine.
Background	The main idea is introduced by [ 11 ], and is also known as soft skinning, linear blending or Single Weight Enveloping (SWE).
Background	In Maya, “tweaking” is a procedure adding delta values to original surface vertices before any deformations.
Challenge	This paper is mainly dedicated to geometric solutions.
Approach	Other basis functions also can be candidates.
Approach	Although singular cases are rare (one example is a joint with 180 o rotation and equal 2 1 , 2 1 weights on the two joint frames, which is an unrealistic case of selfintersection), it is possible to handle these cases with a small rearrangement of the inverse PSD approach.
Approach	Then we have the final synthesis result:
Approach	The blue and green curve represent σ = 1.0 and σ = 2.0 respectively.
Approach	Next we build a new delta vector Dr with ith element as d i r , and replace D in equation 2 with d i r to get a new weight vector W r .
Approach	In synthesis phase, a d x in an intermediate pose x can be computed by equation 3 based on its position x in pose space d x = ∑ n−1 i=0 ω i φ (||x − x i ||).
Approach	For the situation where other unknown skinning operations are adopted, we propose a unified framework which will be discussed in the following section.
Background	Their values such as rotation degrees can be chosen as coordinates of the abstract pose space.
Challenge	In our situation, the function form is not explicit, and the computing burden increases with the number of example poses increases.
Background	Driving 3D models in a natural and believable manner is not trivial, especially when the model is very detailed and playback of animation becomes quite heavy and time consuming.
Background	Besides the geometric solutions mentioned in the previous section, physical modelling and animation is another field providing realistic character simulations.
Challenge	Besides SSD, other skinning approaches such as rigid skinning, Free Form Deformation etc. can also be applied.
Approach	Taking the model in rest pose as an example is a common practice when applying shape interpolation, since interpolating effects from other examples should not change the original model in rest pose.
Outcome	Once the linear system is solved, the synthesis is potentially realtime since no extra computing is involved in this process compared to the forward PSD.
Outcome	It interoperates with their closed-source “Smooth Skinning” deformation.
Approach	This weight is usually a function of distance between v r and its associated joints, and is defined when we apply SSD to the rigged character.
Background	Because of this limitation SSD cannot synthesize many parts of a character skin involving complicated joint structures.
Approach	, we use Gaussian Radial Basis functions to interpolate 3 points.
Approach	But the domain of adjusting one vertex in this way is strictly limited to the linear subspace formed by the vertex as transformed by joints influencing this vertex.
Approach	For N examples, a vertex v is first transformed from rest pose by SSD to positions v i , i = 0, . . . , N − 1, then animators move it to example positions to obtain delta values d i , i = 0, . . . , N − 1.
Background	The data needed for these methods grows with the number of examples, but arbitrary deformations can be approximated as a result.
Approach	The idea here is that, since w i is being minimized, it will be generally be zero, and will be non-zero only if it is not possible to obtain the desired deformation v i using SKINNING i (v r + d i ).
Approach	Basic skinning provided by Maya is called in the loop of minimization scheme.
Background	This approach is not commonly applied, however, since editing in the rest pose will influence most other poses.
Challenge	Each time when a frame goes wrong, a production cannot afford major revisions such as resculpting models or re-rigging skeletons.
Outcome	We provide detailed reasons why and how the inverse operation can improve the results.
Background	[ 4 ] introduce weighted pose space deformation for deforming realistic models of human hand.
Outcome	For a simplified condition where only one joint rotation and two example poses are considered, we demonstrate this inverse strategy has a better performance than the same framework without it.
Background	Pose Space Deformation [ 1 ] combines shape blending and Skeleton Subspace Deformation by formulating a scattered data interpolation problem over sculpted (or otherwise obtained) example poses.
Approach	The delta value in the first pose is zero.
Approach	If SSD is adopted to define this relation, each vertex or control point of the character surface is provided with a list of joints, that will influence it, along with the weight indicating the amount of influence.
Background	SSD is widely used in games, virtual reality and other realtime applications due to its ease of implementation and low cost of computing.
Outcome	We demonstrate the direction of deformed vertex in inverse skinning is linearly proportional to joint rotations in a simplified example, while the forward PSD does not incorporate the direction information.
Outcome	In addition the cost of the animation software must be considered (for example, the Maya API implements a run-time type interpretation system on all operations).
Outcome	This demonstration provides for the first time a clear theoretical reason why inverse operation is required.
Approach	And now we take a look at a real cylinder model with one vertex sculpted in the second pose, shown in the Figure 4 .
Outcome	This cost depends on the size of deformed character, parameters of minimization methods (Powell) such as convergence precision, and the number of example poses.
Background	Normally this relation is defined in the rest pose, and determines how characters move according to their skeletons thereafter.
Outcome	All these parts would rotate from the rest pose with some angle to other poses.
Approach	Similarly, we compute the tangent of α I p : tan α I p = − v v Inp Inp x y − − v v SSD SSD x y = − d x sin θ + d y cos θ = − tan( β + θ ) d x cos θ − d y sin θ where tan β = d y = d 2y .
Challenge	Unfortunately, understanding and accessing their various parameters can be laborious at best, and we do not have access to the algorithms in the case of commercial packages.
Approach	We reformulate the problem as f (y i ) = v i + w i − SKINNING i (v r + d i ) 2 + λ w i 2 where y i is a concatenated vector y i = [d i , w i ] and λ is an arbitrary small number.
Background	Articulated character animation is a process of deforming the skin surface by manipulating influencing objects such as skeletons, IK, wire frames and Nurbs curves etc.
Approach	For the Gaussian function φ (x) = e − σ x 2 2 , σ is used to control the “fall-off”.
Background	Using established terminology from statistical modeling, these example-based approaches can be considered as non-parametric skin deformation methods.
Approach	We still study SSD as the underlying skinning, since an explicit form of basic skinning can help to simplify our task of explanation.
Approach	Given two examples as shown in Figure 2 (a) and (b) respectively, vertex v with the position v r in the rest pose ( 0 degrees ) is sculpted to a “target position” v ti in an example pose (90 degrees).
Outcome	But the minimizing process will introduce more cost.
Challenge	It is therefore necessary to invert the operation of these skinning and deformation operators.
Background	For those applications that require visual fidelity, such as movies, SSD serves only as a basic framework, on which lots of more complicated deformation approaches are built as a compensation.
Approach	The final positions of v in example poses are v i + d i , i = 0, . . . , N − 1, and we call them target positions vt i .
Approach	We will adopt Powell’s method as the solution to this minimization problem.
Approach	In an intermediate pose x, we have its corresponding rest position as v r x = [v 0x + d x , v 0y + d y ], and here the [d x , d y ] are interpolated result computing from equation 3.
Approach	In the case where the SSD transform is nearsingular, the solved d i can be much large than other d k , which can result in poorly posed interpolation.
Background	The pose in which the skeleton is rigged normally is referred to as the rest pose.
Approach	Because we are treating the skinning operations as a “black box”, their gradient is not available, so Powell’s method is suitable.
Background	[ 3 ] precompute principal components of the deformation influences for individual kinematic joints instead of storing displacements for key poses, thereby enabling realtime rendering large nonlinear finite element models of human hands.
Approach	In the inverse approach we instead apply the inverse of SSD i (∗) to v i t to obtain a modified rest pose vertex v r i .
Approach	For a vertex in rest pose v , its transformed position in pose p is v p .
Approach	Otherwise, large amount of unnecessary works of building examples will be required, and the distance between different poses is also meaningless.
Approach	Since SSD is the most representative in the family of basic skinning, we will discuss how it performs in the inverse operation of PSD scheme.
Approach	The output of the first phase, the delta in the rest pose, is input to into the second phase that is a linear system performing RBF interpolation to obtain the PSD weights.
Background	Character geometries in problematic poses will be re-sculpted by animators and then resulting displacement (referred as delta values in this paper) from the original geometries will be stored as “scattered data” for interpolation phase.
Challenge	Therefore the action of the SSD and any other deformations must be “inverted” in order to push the example compensation before these operations.
Approach	For two examples shown in Figure 2 (a) and (b), we have delta values d 1 = [d 1x , d 1y ] and d 2 = [d 2x , d 2y ].
Approach	Since SSD is a 3D transformation, SSD −1 simply is the inverse transformation matrix generated by SSD.
Background	[ 2 ] incorporate linear elements into RBF to produce constant changes between examples.
Approach	Then we take a look at α I p in the inverse case.
Background	Powell’s idea is trying to find each minimum of function f (d ) in different direction until f (d ) stops decreasing.
Background	One advantage of Powell’s classic method is that it does not need explicit computation of the function’s gradient [ 12 ].
Approach	To find delta d i in the rest pose: v i = SKINNING i (v r ) + d i = SKINNING i (v r + d i ) we can setup a minimization problem to minimize the function:
Background	The interpolation is performed in the pose space which consists of skeleton joints, or other potentially abstract controllers.
Approach	The difference of vr i and vr produces new delta value d i r , which will be the input of linear system (equation 2) introduced in the previous section.
Background	How to choose the next direction is the main concern of Powell’s method, and it has been proved that after repeated cycles of M line minimizations on conjugate directions, the optimization will in due course converge to the minimum [ 12 ].
Background	It provides the relation between characters and their underlying skeletons.
Outcome	The case described above is quite common in practice when animating shoulder, elbow, knee, hip-bone, neck, etc.
Background	Given physical principles, this category can generate more believable animation effects compared to its geometric counterpart.
Background	But they are seldom applied to interactive applications because of the high cost of computing and complicated algorithms.
Approach	Then we can see α I p = d x d 2x −( θ + β ), which is linearly proportional to the pose rotation θ .
Background	The latest work [ 5 ] identifies statistically relevant bones and approximates bone transforms from example mesh animations.
Approach	We just apply the simplified SSD to v x r to obtain v I x p : v Inp x = (v 0x + d x ) cos θ − (v 0y + d y ) sin θ and v Inp y = (v 0x + d x ) sin θ + (v 0y + d y ) cos θ .
Background	Due to its simplicity and efficiency, SSD is widely applied to interactive applications such as games and virtual reality, and it is implemented in most commercial animation packages.
Outcome	Therefore the inverse approach presents better performance and more consistent interpolation ( Figure 7 to Figure 10 ).
Outcome	We implement this unified example-based approach as a Maya plugin.
Approach	Then we apply forward and inverse PSD respectively to interpolate these two poses.
Background	A skeleton should be rigged to a character surface beforehand, roughly based on the anatomy of the character and kinetic rules.
Background	Since vertex transformations can be easily implemented in the graphic card, SSD is very popular in circumstances that require animating a number of characters in real time.
Approach	As presented in Figure 6 , the whole system is divided into two phases.
Approach	This function can be given to Powell’s method to find d i at the minimum of f (d ).
Background	After a model is posed and resculpted in different example poses, a multidimensional linear system is built by implementing an interpolation scheme using Radial Basis Functions (RBF), and the output of this system is the weights of each example pose.
Approach	First a N ∗ N matrix Φ is built with the (i, j)th element as φ ( x i − x j ), where x i − x j means the Euclidean distance between pose x i and pose x j , then we have a linear system:
Approach	Rectangles represent animated sections in each of two frames and the curve shows the blended result of both frames.
Background	It is actu- ally Maya’s form of rest-pose editing for their built-in deformation operators.
Approach	If the SSD transformation in equation 1 is singular, some types of inverse PSD deformation will not be possible, because any component of the desired deformation that lies in the null space of the SSD matrix will be ignored.
Approach	To address this case, we further modify the objective function as        f (y i ) = v i +w i −SKINNING i (v r +d i ) 2 + λ w i 2 + μ d i 2 where 0.0001 is a sufficient value for both λ and μ .
Approach	The final deformed vertex is computed by Maya skinning as in equation 10.
Background	PSD smoothly interpolates these meshes in pose space and produces visually attractive animations.
Outcome	We propose a layered framework for incorporating example-based skinning algorithms such as Pose Space Deformation or Shape-by-Example into an existing character animation system.
Background	The basic relationship between surfaces and skeletons is defined at the rest pose, and all motions of the character will be influenced thereafter.
Background	Example geometric models paired with underlying skeletons in different poses are provided by artists with carefully sculpting and posing.
Background	Skeleton Subspace Deformation (SSD) is a basic algorithm that is used to define how the character surface deforms following movements of its underlying skeletons.
Approach	Forward PSD and the corresponding inverse PSD in the same poses (30, 45 and 60 degree of one rotated joint ) are illustrated respectively in Figure 5 .
Background	On the other hand SSD is also notorious for artifacts at rotating elbows and extreme poses.
Challenge	However, although PSD may be used as a compensation to the underlying SSD, and the animator specifies the PSD examples after the SSD has been performed, it is generally believed that the examples are best interpolated in the rest pose, before the SSD has been applied.
Approach	For an intermediate pose x, we have two distinct deforming vertices resulting from two algorithms, as illustrated in Figure 3 , v ssd x , v x p , v x I p are the deformed positions from SSD, forward and inverse PSD in an intermediate pose x.
Approach	Our framework implements existing PSD theory and the distinction is that we insert an optimization module into the PSD pipeline by applying a unified inverse approach assuming the knowledge of basic skinning is unavailable.
Background	The famous SSD problem of “collapsed elbow” is recognized in [ 1 ] as being due to the fact that deforming is limited to a linear subspace.
Approach	Then in an intermediate pose x for α p , we have tan α p = d d x y .
Approach	These are converted to rest pose displacements using d i r = SSD −1 (d i ).
Background	For a minimization problem, there are many candidate algorithms according to the form of function, knowledge of the derivative, computing capacity, and requirements for the rate of convergence, etc.
Approach	On the other hand, as a matter of experience, PSD is supposed to be a method as “local” correction, which means pose space should not be extended to a whole space that has to incorporate all influenced objects.
Approach	We transform two examples to rest pose to obtain delta values: d 1 r = [d 1x , d 1y ] = [0, 0] and d r 2 = [d 2x , d 2y ].
Background	Sometimes, artists will edit the geometry of characters in the rest pose to fine-tune animations.
Background	Skeleton Subspace Deformation (SSD) is the predominant approach to character skinning at present.
Approach	The “forward PSD” approach then concludes by interpolating d i as a function of pose.
Outcome	Inverse skinning integrates SSD and shape interpolation more firmly than its forward rival.
Approach	Given a basic skinning method supported by animation packages we can deform the original character model from rest pose to another specific pose.
Background	Built on the SSD scheme, the Pose Space Deformation (PSD) is proposed by [ 1 ] as a combination of SSD and shape blending providing nice solution to above mentioned problems.
Challenge	Therefore we propose a unified framework in which no explicit inverse operation is necessitated.
Outcome	For a simplified case, we show that the direction of deformed vertices from inverse skinning is a linear function of joint rotation, while in the forward approach, that direction is kept as a constant.
Approach	We call the PSD scheme without the inverse operation as “forward PSD”, and comparison to it will be used to demonstrate the superiority of the inverse method.
Background	T pk means the kth joint’s transformation from rest pose to pose p. Readers can find details on how to compute T pk in [ 1 ].
Approach	The final synthesis is then v x = SKINNING(v r + d x ) + w x where w x is interpolated after SKINNING by applying the same RBF scheme as used for d x (thus, only minimal code changed are required).

Background	Foster and Metaxas [ FM96 ; FM97 ], and Griebel et al. [ GDN98 ] presented a solver for the fully three dimensional Navier-Stokes equations.
Approach	Therefore, the divergence of each cell in the grid has to be projected to zero using the Helmholtz-Hodge decomposition [Sta03].
Approach	Note that the somewhat tempting simplification of tagging each cell to either have wind in it or not is not valid.
Background	Recently, Wei et al. [ WZF + 03 ] presented an interesting approach to simulate lightweight objects like soap bubbles and feathers in a wind flow using a Lattice Boltzmann Model extended with a subgrid model.
Approach	This approach is much easier to implement and can be added to existing simulation modules without additional computational cost.
Background	The major advantage of Navier-Stokes based approaches consists in the fact that the evolution of the wind flow over time is calculated.
Approach	If we now place a solid object in between these two sources a rather undesired effect would occur using this simplification: on both sides of the solid object all cells would be tagged as having wind.
Approach	Finally, for every marked cell in the scene the previously stored normals are averaged in one space cell which are used to update the velocity at the cell to satisfy the Neumann boundary condition.
Challenge	However, aerodynamic effects are obviously capable of enhancing the realism of an animated scene and thus are an important part of a cloth simulation system.
Approach	Note that in the case of a windless situation, i.e. u = 0, we still have air resistance for moving objects.
Approach	The field w does not account for lee effects caused by objects in the flow.
Background	CFD are applied in this field for engineering tasks with a high degree of quality requirements.
Background	Rigid objects like walls will influence the fluid field but will not be affected by fluid forces themselves.
Approach	Here, u describes the (three-dimensional) velocity field, ν is the kinematic viscosity of the fluid, ρ its density, p the pressure in the wind field, and f accounts for external forces.
Approach	For every deformable object the velocity value of the surrounding wind field for every vertex of the representing mesh is tracked.
Background	A vast literature exists on how to solve these equations numerically.
Approach	The first term on the right hand side reflects the change of velocity due to advection, while the second expression accounts for any external force f and acceleration caused by the local pressure gradient ∇p and by viscous drag depending on ν.
Approach	This path is then tested for collisions with the objects in the scene.
Approach	Let them further have equal velocity magnitude and no distance attenuation.
Approach	Then, the aerodynamic forces as described in section 3 are calculated.
Background	Simple models consist in the calculation of lift and drag forces from the surrounding velocity field [SF92; Pro95; KCC + 00; KCCL01].
Challenge	In this work we discuss two different approaches to      model force fields describing air motion and show how these forces can be applied to generate aerodynamic effects on textiles.
Background	Then they update the cell’s velocities according to the divergence value computed in each direction, respectively, using an explicit integration scheme.
Approach	The drag force per face is then given by F i,D = 2 1 C D ρ|v i,rel | 2 A · ( n i · v i,rel ) · (− v i,rel ) ,        where C D is the specific air resistance coefficient, ρ the density of air, A is the area of the corresponding face, and v i,rel the unit relative velocity vector of the face.
Approach	The first equation states that the velocity field should be incompressible while the second one describes the evolution of a velocity field over time.
Approach	The wind force acting on objects in an air stream is decomposed into two components: the lift force F L and the drag force F D (see figure 1 ).
Background	Kajiya et al. [ KvH84 ], Yaeger et al. [ YU86 ], and Gamito et al. [ GLG95 ] worked on fluid dynamics solvers in two dimensions, and many improvements and variants followed [ CdVLHM97 ; KM90 ].
Background	For interaction of highly deformable objects and especially cloth-like objects only few models have been investigated.
Approach	Here we propose a method which meets both requirements.
Approach	We then use a par- ticle tracing method in the defined wind field to determine the effect of lee by detecting windless areas.
Outcome	In this work, we compare the models’ advantages and disadvantages and show practical results of the described methods.
Approach	This in fact is a major difficulty.
Approach	Two flags are exposed to a wind field, but the wind is blocked by a wall, so one of the flags is not affected by the wind.
Approach	To calculate the wind particles’ positions we used the explicit Euler integration scheme.
Background	Many models use this method to move objects in the wind field through the scene [ Ree83 ; Sim90 ; WH91; BLM95 ].
Approach	Then the lift force is calculated as F i,L = 1 2 C L ρ|v i,rel | 2 A cos θ · u i , where C L is the lift force coefficient, and θ is the angle between v i,rel and the actual face.
Background	To enable faster simulations, a solution with an unconditionally stable solver was introduced by Stam [Sta99 ] and further extended in [ FSJ01 ; Sta01 ; Sta03 ].
Challenge	The numerical algorithms used in CFD to solve these equations are designed for physical accuracy for engineering applications and are expensive in computation.
Approach	The velocity field u is then computed as for each grid cell separately, where w i are all those wind sources whose particles have reached the cell.
Outcome	Even with this straightforward approach, nice, realistic looking results can be achieved which is illustrated in the next section.
Approach	This model is extended to interaction of the wind flow with textiles.
Challenge	Of course, both approaches have different characteristics and aim at different applications for wind simulation.
Challenge	The first method is based on modelling air flows with the Navier-Stokes equations.
Outcome	Here, the same method as described for rigid objects (section 4.2.2) can be applied.
Outcome	Hence, the global wind field model is better suited for an easy to implement tool which is easy to adapt to specific situations.
Background	More complex interaction models calculate the wind force by a panel method [LDG96; Li00] introducing local vortices.
Challenge	For example, air resistance is a vital component which cannot be neglected if realistic animation is desired [ BTH + 03 ].
Approach	We implemented the wind models described in sections 4.1 and 4.2 in a cloth animation system that employs a fast finite element method to simulate the drape of textiles with measured material properties [EKS03].
Background	Deformable objects like cloth are supposed to both experience fluid forces and itself influence the fluid flow.
Background	That means in particular that all objects in the scene interact with the fluid present in it, i.e. in our case clothes with the wind.
Approach	Since the arising wind velocities are clearly below the speed of sound, compressibility effects are negligible, and the wind is modelled as an incompressible constant density fluid.
Outcome	However implementing the fluid solver is quite complex and using a high grid resolution is computationally expensive.
Approach	As a particle moves along its path in space, all grid cells colliding with the path are updated with the velocity of the associated wind source with respect to the position of the particle.
Approach	The first model is based on the work of Stam [Sta97] and calculates the numerical solution of the Navier-Stokes equation with a semi-Lagrangian approach.
Approach	For this, the computational domain is diced up into equally sized cubes forming a grid as described in section 4.2.2, and sample values of velocity and pressure are defined at the cell centres.
Background	Foster and Metaxas [FM96] use a finite difference approximation for the discretisation of the operators in equation (4.2).
Approach	Imagine the simple scene in which there are two directional wind sources with opposite wind directions.
Approach	The wind velocity at the vertex positions of the object is recorded.
Approach	This is due to the extinguishing effect of the superposition of the two wind sources.
Background	Here, global functions are defined to model the velocity of wind.
Background	Modelling interaction of fluids with solid objects has been investigated by Takahashi et al. [ TFK + 03 ] and Génevaux et al. [ GHD03 ].
Approach	But in our case where this precision is not necessary simplifications can be made which greatly reduce the computation costs as described by Stam [Sta03].
Background	On the one hand the wind deforms the objects which on the other hand change the wind flow.
Challenge	This is mostly due to the fact that conventional CFD applications require enormous computational power.
Outcome	It produces nice swirls and vortices derived from dynamical characteristics of the fluid.
Approach	Since u is determined using the wind particles, every point p that could not be reached by any wind particle will hold zero velocity even if w may hold a nonzero velocity.
Approach	To show the improved realism when simulating lee effects, we let the the wind act on all polygons of the shirt on the right (no lee effect).
Approach	While the linear terms in equation (4.2) are straightforward to solve implicitly, the term −(u · ∇)u is nonlinear and deserves special attention.
Background	Notice that the movement of the particles in a wind gust is only affected by the wind source they belong to.
Approach	A simple approach to generate complex air flows is to define a wind field by mathematical functions which assign to each point in space a unique velocity value.
Outcome	As illustrated in the previous section both methods produce realistic looking results which are capable of enhancing the realism of computer animations.
Background	Unfortunately, it is quite difficult to apply these algorithms in computer graphics due to enormous calculation times.
Approach	Thus, this method solves the problems described in section 4.2.1.
Approach	Thus, a nonzero velocity could be mistakenly assigned to cells lying inside an object.
Outcome	All the methods apply the same except for simple changes.
Outcome	For physically accurate simulations based on the common method in fluid dynamics the model introduced by Stam produces realistic effects which global wind field models can never achieve.
Approach	The wind force effective on objects in the scene is then computed from the velocity field u.
Approach	The second model employs precomputed wind flows and particle tracing methods.
Challenge	While the simulation of wind is an area of vast interest in aerodynamic engineering, computational fluid dynamics (CFD), and animation/visualisation of fluids in computer graphics, it has been a rather abandoned subject in simulation of deformable objects such as cloth simulation.
Background	Either special flow primitives can be combined [ WH91 ; LDG96 ; Li00 ] or visually pleasing functions introducing random turbulence [ SF92 ; SF93 ; Sta97 ] are taken into account to model even complex wind scenes.
Approach	Here, particles are moved along the wind field to determine the effect of objects in the scene.
Outcome	We present a model to exploit these wind models for calculating the interaction of deformable objects with the air flow by a boundary condition method.
Background	However, fixed flow functions lack interaction with the user or objects in the scene.
Approach	For a wind particle at position p t and time t this results in a path s(p t , p t+∆t ), where p t+∆t denotes the position after time step ∆t according to p t+∆t = p t + w i (p t , ∆t) .
Outcome	All methods described in this work should be easy to extend to three-dimensional deformable objects.
Outcome	We presented two models for including advanced wind effects into cloth simulation systems.
Approach	We discuss two different approaches to model force fields describing air motion and show how these models can be augmented to exhibit interaction with deformable thin objects such as textiles.
Approach	A different issue is how to deal with the inside of (rigid) objects.
Approach	As usual, values between the defining points of the grid are interpolated using trilinear functions.
Outcome	Moreover, in the wind field computation care has to be taken that no wind field is present in the object.
Background	Hence, with increasing computer power, computer graphics concentrates on physically more accurate simulations.
Approach	The so determined flow field is used to compute the wind force which is added to the forces that act on the textiles.
Outcome	For this case, we present a much simpler model based on tracing wind particles that move along a global force field.
Background	As already stated by Stam [Sta03] “a velocity field of its own isn’t really visually interesting until it starts moving objects [...
Outcome	While the first model has a wider range of applications, the second one provides an easy method which still delivers realistic effects such as air resistance and lee.
Outcome	Moreover, we extend the more straightforward approach of global wind field functions by the effect of lee.
Approach	Hence, given a wind flow represented by a velocity field in the scene we calculate the forces which are exerted on the simulated objects.
Approach	Therefore, it is crucial for the particles to have the associated velocity of their wind source and not just the velocity resulting from the global superposition of all wind sources.
Outcome	Both methods have been integrated in an existing cloth simulation system, and we compare their respective advantages and disadvantages.
Approach	Another more serious drawback of this model for our application consists in the lack of interaction with objects.
Approach	To solve these equations numerically they first have to be discretised.
Approach	By detecting collisions between the wind particles and objects in the scene, we are able to simulate the important effect of lee even with this straightforward method.
Approach	To solve the described problems we propose a model which combines the simple global wind flow techniques with a particle tracing method.
Approach	On the other hand, the wind velocity orthogonal to the object’s surface is just what causes the aerodynamic forces.
Approach	During the simulation, the wind field is evaluated for each wind particle at its current position.
Background	While this works for simple objects this approach is not feasible at all with deformable objects like textiles.
Approach	We used the particle tracing method described in section 4.2 to model the effects of a directional wind field on the flag.
Background	There are two common approaches to discretising the continuous velocity field defined in space: one can either choose the midpoint of a cell [Sta99] or its six faces [FM96] to define the field.
Outcome	For the shirt on the left we used the Particle Tracing Method to simulate lee effects which, we think, gives more realistic results (see also the accompanying video).
Approach	In every time step each particle in a wind gust moves along its velocity field w i defined by the corresponding wind source.
Approach	Here, a different approach based on the method of characteristics is used to solve the advection equation.
Approach	Additionally, the normals of these vertices are stored.
Background	Hence, faster fluid solvers were investigated for computer graphics applications.
Background	Models for fluid dynamics can be essentially subdivided into two categories.
Outcome	Since three-dimensional objects define an inner and outer part, the adaption of the face normals in equation (3.1) is not necessary.
Approach	To describe the above situation by a physical model we require the Neumann boundary condition ∂u =0 ∂n to be satisfied for the wind flow u at any boundary point of an object with normal n.
Approach	The wind particles are emitted into the velocity field w i of the corresponding wind source which is defined on a grid.
Outcome	This method is very easy to implement and yields very plausible and nicely looking results.
Background	Particle systems are very common in the simulation engines and most functionality can be adapted to integrate the proposed wind model.
Approach	On the one hand, we want the Neumann boundary condition u(p b ) · n = 0 to be satisfied.
Approach	The direction of the lift force, which is perpendicular to v i,rel and lies in the plane spanned by v i,rel and n i , is given by u i = ( n i × v i,rel ) × v i,rel .
Approach	However, this method can be combined with the aerodynamic model described in section 3 to give nice and fast results as will be shown in section 5.
Approach	Without further remedial action setting the boundary according to the Neumann condition would mean that the fluid will not exert forces on the objects.
Background	The approach to model solid objects in the scene taken by Wejchert et al. consists in placing a wind source using a mirror principle in order to extinguish the air flow at the boundary of the object.
Approach	Therefore we compute the wind field u containing these effects as follows.
Background	Simple models which are commonly used in most computer graphics applications describe the wind flow by predefined flow functions.
Approach	To define a wind scene we first built up the air flow by simple primitives such as parallel directed wind fields, vortices, etc.
Approach	To incorporate wind effects in a physically based animation we have to apply additional external forces in the dynamical model of the deformable objects.
Approach	The first concentrates on physically accurate computations using a semi-Lagrangian approach to solve the Navier-Stokes equations, the second model incorporates a particle tracing method for global wind fields.
Approach	The method to set boundary conditions as described above does not account for the interior of objects.
Background	Due to explicit integration methods very small step sizes had to be used.
Approach	The specific emission intervals and amounts depend on the properties of the flow sources.
Background	In addition, physically based fluid dynamics solving equations of motions with particle methods were presented recently [ IK03 ].
Approach	Thus, the boundary conditions are met and yet aerodynamic forces are obtained.
Approach	The direction of the drag force F D is diametral to the relative velocity v rel = v object − u, where v object is the object’s velocity and u is the velocity field of the wind.
Approach	The wind flow defined by the primitives will not react on objects in the scene which means for example that tissues in the lee of other objects will be affected by the wind flow as well.
Approach	Since time steps in explicit computations usually need to be very small, we follow Stam [Sta99] who proposes an implicit integration scheme, which allows stable simulations with large time steps.
Approach	It enables us to model global effects like convection and diffusion on a physical basis.
Outcome	In this work, we show how recent results in fluid dynamics for computer graphics can be exploited to simulate interaction of wind flows with textiles.
Approach	One drawback of this model is that it cannot handle objects exhibiting complex boundaries.
Approach	With this model, the effect of wind fields on smoke has already been investigated [FSJ01], and in this paper we extend this approach to wind effects on textiles.
Approach	This model divides the scene into parallelepiped cells.
Challenge	In this paper we show how to incorporate effects of wind fields in cloth animations.
Approach	If this is the case, the path of the particle has to be subdivided into parts not exceeding the size of a grid cell.
Background	The global superposition of all wind sources has no effect on these particles.
Approach	The basic idea of the particle tracing method is to trace wind particles through a field w = i w i defined by linear superposition of wind sources corresponding to flow primitives with respective velocity fields w i .
Approach	Consider a point p b on the boundary of a deformable object in the scene.
Approach	But evaluating the wind field at every cell we would obtain a zero velocity.
Outcome	In each case, we present a method for simulating the interaction of cloth movements with the wind field.
Approach	Equation (4.2) does not provide a divergent-free velocity field.
Approach	The particle might cross several grid cells on its way during a single time step.
Approach	For collision detection (between deformable objects, rigid objects, and wind particles) we use k-DOP hierarchies as described in [MKE03].
Background	In many fields the Navier-Stokes equations are the standard mathematical formulation to model fluid dynamics.
Approach	The first model is based on the Navier-Stokes equations, while the second method extends simple particle tracing methods by the effect of lee.
Approach	Let u(p b ) be the corresponding wind velocity at that point and n be its normal.
Approach	To avoid this situation, the path of the wind flow is checked for object intersection, whereby the collision detection of the cloth simulation system provides a simple method to deal with this issue [MKE03].
Challenge	However, the solution of the sophisticated NavierStokes equations is not desired and not necessary in all situations where wind effects shall be integrated into cloth simulations.

Approach	One potential issue, not unique to our method, is that despite enforcing a lower bound on the distance between pressure samples, our unstructured sampling can cause sliver tetrahedra in the unmodified Delaunay tetrahedralization.
Approach	Add external forces—typically just gravity.
Outcome	All figures are averages per frame and all timings are in seconds.
Approach	Second, we can ensure that the solver sees the correct surface topology so that the physics responds to merging or splitting only when the surface mesh itself merges or splits.
Outcome	This yields accurate and comparatively stable surface tension effects without artificial smoothing.
Approach	For front tracking, we used Brochu & Bridson’s El Topo code [2009], in particular using its triangle mesh surface to determine the location of pressure samples for our Voronoi simulation mesh.
Approach	This placement may miss very thin sheets or other fine structures: to robustly sample such features, we check line segments of length ∆x from each surface vertex in both offset directions for intersection with the rest of the surface mesh.
Outcome	With regular pressure samples, sheets of this kind often end up between samples, effectively disappearing from the solver.
Approach	Velocities for each of these new points need to be computed; while previous work used the generalized barycentric interpolant for this transfer step, we found that simply averaging the velocities of the surrounding ring or cell of Voronoi vertices is quicker and equally effective.
Background	The issues that arise from regular, non-geometry-aware pressure sampling are common and consistent across Cartesian grids, octrees, Voronoi meshes, and tetrahedral meshes.
Background	Past work in graphics has extensively explored finite volume methods for tetrahedral meshes [Feldman et al. 2005a; Feldman et al. 2005b; Klingner et al. 2006; Chentanez et al. 2006; Elcott et al. 2007; Wendt et al. 2007; Chentanez et al. 2007], and now many of the features of standard grid-based solvers are supported on tetrahedra, including free surfaces and implicit coupling to dynamic solids.
FutureWork	Pursuing a more efficient, fully implicit surface tension model is a promising future direction.
Approach	We simulate inviscid liquids with semi-Lagrangian advection and an embedded-boundary finite volume pressure projection.
Background	In a related approach, Sin et al. [2009] developed a particle method which solves a finite volume pressure projection on the Voronoi diagram of the liquid particles.
Outcome	Because our simulation does not use diffusive Laplacian mesh smoothing and applies accurate mesh-based surface tension forces discontinuously at the interface, we retain substantially greater detail in the resulting capillary wave motion.
Approach	We will therefore use Voronoi meshes throughout, and simply compare our geometryaware sampling against naıve regular sampling.
Background	An advantage of a Voronoi-based discretization is the freedom to explicitly choose pressure sample locations, which is critical for accurate ghost fluid free surface conditions as the signed distance at these samples communicate the surface geometry to the solver.
Approach	We could then apply the usual generalized barycentric interpolant over Voronoi cells, but this is expensive [Chentanez et al. 2007] and requires special case handling to avoid degeneracies [Meyer et al. 2002a].
Outcome	Our method also resolves thin sheets and small surface details generated by large splashes, as shown in figure 1 .
Background	For example, conforming the simulation mesh to solid walls makes the no-flow boundary condition trivial, and adaptivity can be easily introduced by grading mesh elements as desired.
FutureWork	Lastly, many common extensions to basic inviscid liquid simulation rely on regular grids, and would need to be adapted to accomodate our approach.
Background	Another approach is to work strictly on the triangle mesh itself, using “mesh surgery” for repairs.
Outcome	As seen in figure 11 , our barycentric method is substantially less damped than the naıve barycentric interpolation approach, and matches the more complex generalized barycentric interpolant.
Approach	In some cases this is much more accurate than the estimate derived from signed distances, but in practice we found it made minimal visual difference.
FutureWork	Likewise, improvements to front tracking would be welcome, such as curvature-driven adaptivity, or greater robustness and efficiency.
Approach	Conveniently, the duality/orthogonality relationship between Voronoi and Delaunay meshes lets the accuracy benefits of the method carry over.
Approach	(With regular sampling, merging will depend on where grid points happen to fall with respect to the surface; hence the physics can respond as if merged when the surfaces are still as much as ∆x apart, as in figure 9 .
Approach	Apply a simple graph-based extrapolation of velocities to fill in velocities near the liquid.
Approach	Often this intersection point will coincide with a surface mesh vertex due to our choice of sampling scheme; where it does not, we use simple linear interpolation between the vertices of the surface triangle mesh.
Background	Batty et al. [2010] augmented this approach with embedded boundaries [Enright et al. 2003; Batty et al. 2007], improving free surface accuracy and reducing remeshing complexity.
Approach	If the vertex lies on a locally smooth patch it is moved in the plane tangent to the surface, but if on a ridge or corner it is moved only along this line.
Background	El Topo uses a sequence of edge subdivision, collapse and flipping operations, combined with null-space Laplacian smoothing.
Approach	Curvature is evaluated at the intersection point between the the triangle mesh surface and the line joining an interior pressure sample to an exterior one.
Outcome	When combined with highresolution explicit surface tracking this allows us to simulate nearly arbitrarily thin features, while eliminating noise and other artifacts that arise when there is a resolution mismatch between the simulation and the surface—and allowing a precise inclusion of surface tension based directly on and at the same resolution as the surface mesh.
Approach	This idea motivates our work.
Outcome	In summary, our key contribution is coupling an explicit surface tracker to a Voronoi-based liquid simulator with: • a pressure sample placement strategy that captures the complete liquid surface geometry, • an accurate surface tension model combining mesh-based curvature estimates and ghost fluid boundary conditions, • embedded free surface and solid boundary conditions adapted to Voronoi cells, avoiding the need for more onerous conforming tetrahedral mesh generation, • and a new velocity interpolant over unstructured meshes.
Background	Wojtan & Turk [2008] handle this with Laplacian smoothing to eliminate small features: note, however, this non-physical operation is dissipative rather than conservative.
Outcome	More fundamentally, our Voronoi simulator is in many ways dual to a tetrahedral scheme, and for a given mesh the number of velocity samples is identical; we believe that approximately comparable costs are therefore reasonable to expect.
Outcome	Moreover, explicit surface tension schemes, such as the ghost-fluid-based method used in this paper, 3 suffer from a stringent O(∆x 2 ) time step restriction for stability, which is particularly costly when small scale capillary waves are not erroneously damped out.
Outcome	We have shown that with careful placement of pressure samples, our Voronoi mesh-based fluid solver makes it possible for explicit surface tracking to achieve its full potential in capturing small scale liquid features.
Challenge	We introduce an Eulerian liquid simulation framework based on the Voronoi diagram of a potentially unorganized collection of pressure samples.
Background	However, in the Voronoi setting, the faces are arbitrary convex planar polygons rather than triangles.
Background	An important reason for their popularity is that careful control of mesh geometry can simplify the discretization or improve accuracy.
Approach	Lastly, grid-scale features often disappear and reappear in regular grid sampling, from the perspective of the solver, as the surface translates through the grid.
Approach	) After placing the surface-adapted pressure samples, we complete the sampling of the domain by adding regularly-spaced points from a BCC lattice with cell size 2∆x, again rejecting samples which fall too near existing samples—of course, a graded octree or any other strategy could also be used to fill the domain.
Approach	First, we can inform the solver of all local geometric extrema, allowing the physics to act upon them correctly.
Approach	Surface tension was only used for examples in subsections 7.2 and 7.3.
Approach	However, the interpolation onto tetrahedra vertices discards any local extrema at the Voronoi vertices, thereby severely over-smoothing the velocity field in practice, damping out interesting flow behavior.
Approach	This eliminates the accumulation of erroneous surface noise without requiring non-physical smoothing; this is especially vital for surface tension where spurious noise affects the curvature estimates and induces disastrously large yet futile compensating velocities that destabilize the simulation.
Challenge	We will address these problems by constructing a simulator that “sees” every detail in the explicit liquid surface.
Outcome	The main contribution of this paper is the coupling of simulation elements to an existing explicit surface tracking method, and not the explicit surface tracking itself.
Background	In previous work, face normal components on tetrahedra were used to reconstruct velocities at circumcenters (Voronoi vertices).
Background	Kim et al. also introduced extra surface smoothing to prevent retention of small-scale noise.
Approach	This family of redistancing schemes is described by Bridson [2008], and is easily adapted to tetrahedra.
Background	Purely explicit front tracking algorithms generally use mesh refinement and coarsening to maintain a high quality discretization as the surface deforms.
Approach	The solver runs through the following stages each time step: 1.
FutureWork	Several directions for future work remain.
Background	However, this scales poorly since many of the extra samples yield little benefit, while incurring memory and computational overhead.
Approach	Rather than discard extrema at Voronoi vertices, we use a slightly refined tetrahedral mesh that includes them.
Approach	We revisit our surface tension block example to compare different interpolation schemes.
Outcome	For example, a surface with two disjoint volumes of liquid may appear to the solver as one volume, resulting in a premature response.
Outcome	These simulations used no more than 320K tetrahedra each, whereas recent tetrahedra-based free surface methods used up to 4 times more tetrahedra to achieve a similar level of detail.
Approach	In summary, the steps of our interpolation scheme are: 1.
Outcome	Because our adaptively-placed samples match the topology of the surface tracker, they easily correct this spurious motion.
Approach	To counteract gradual volume drift, we do add a corrective motion-in-the-normaldirection [Brochu 2006; Müller 2009], which further aids in pre- serving thin sheets.
Challenge	When combined with surface tension forces, noisy sub-mesh details can also severely hamper stability if they are not artificially smoothed out.
Approach	We follow this general framework, with two modifications.
Approach	We placed outward samples at 2 ∆x 1 and inner samples at 4 ∆x, though other ratios would work as well.
Approach	We carefully generate pressure sample points near the liquid surface, build a Voronoi simulation mesh from these points and a background lattice, and apply a ghost fluid/finite volume pressure discretization which captures the precise position of the liquid interface.
Approach	To illustrate the benefits of our sampling approach in the context of surface tension, we launch an identical simulation using the same time steps on a regular mesh.
Outcome	Applying an excessively strict timestep restriction only brings the simulation to a halt as the surface noise introduces increasingly sharp features.
Background	In level set schemes, finite differences are often used to estimate mean curvature, though this can be quite inaccurate without careful modification (e.g. [Shin 2007]) and cannot capture small details.
Approach	For example, the smoothing moves vertices only in the null space of the local quadric metric tensor [Garland and Heckbert 1997], as suggested by Jiao [2007].
Approach	Therefore we take the inward and outward normal at each surface vertex (averaged from the incident surface triangles), and attempt to place a pressure sample 1 a short distance along each.
Approach	To resolve all surface details with our volumetric mesh, we need to place pressure samples so that they capture the surface’s local geometric extrema, i.e. around surface mesh vertices.
Challenge	This can lead to a variety of visible artifacts including lingering surface noise, liquid behaving as if it were connected when it is not (and vice versa), and thin features simply halting in mid-air because the simulator fails to see them [Bargteil et al. 2006; Kim et al. 2009].
Background	Recent advances in explicit surface tracking with triangle meshes [Wojtan et al. 2009; Brochu and Bridson 2009; Müller 2009] have made feasible the geometric representation and manipulation of small features, without the loss of detail exhibited by implicit surface methods.
Approach	To enforce embedded solid boundary conditions, we need to estimate the partial unobstructed area of each element face ( figure 3(d) ).
Approach	Reconstruct full velocity vectors at Voronoi vertices using least squares.
Approach	By choosing sample points to precisely capture the geometry rather than naıvely increasing sample density, we can guarantee sampling of features which would require potentially orders of magnitude more samples with pure adaptive lattices.
Approach	To incorporate surface tension, we follow Enright et al. [2003] in setting the free surface pressure p fs = p air + γκ fs , where p air is the constant air pressure, γ is the surface tension coefficient and κ fs is the mean curvature of the surface.
Outcome	With regular sampling, the droplet begins to influence the static liquid before the surfaces are actually joined.
Background	Kim et al. [2009] coupled a high resolution particle level set to a low resolution ghost fluid-based liquid solver, but ensured that pressure projection captured all liquid geometry by resampling an inflated level set at the pressure grid resolution—however, this can exacerbate other artifacts, since liquid components behave as if half a cell-width larger than they appear.
Challenge	One of the most visually compelling aspects of liquids is the variety of complex thin sheets and droplets that arise during splashing.
Outcome	Because this mesh cannot respond and correct high frequency sub-mesh details present in the curvature estimates, the simulation becomes unstable almost immediately.
Outcome	Thin sheets rapidly develop as the fluid spreads out across the floor.
Approach	We can visualize the solver’s “knowledge” by contouring this level set: figures 5 and 6 illustrate how uniform sampling may fail.
Background	While this is difficult in general, Brochu & Bridson [2009] recently showed that the problem can be simplified using ideas from cloth animation, enforcing the invariant that the surface remain intersection-free.
Approach	To interpolate at a point, locate the sub-tetrahedron containing the point and apply basic barycentric interpolation from its four associated data points (i.e. one site, one face centroid, and two Voronoi vertices).
Background	However, the resolution of the underlying grid imposes a severe limit on the smallest representable feature, beyond which geometry either vanishes (LS, SLC) or artificially coalesces into grid-scale “flotsam and jetsam” (VOF).
Background	Surface tension models can also be compared in terms of how the force itself is approximated.
Background	Unfortunately these methods still are subject, in complex regions, to a resolution limited by the voxel grid.
Approach	Therefore, sharp features are preserved, allowing the present paper’s algorithm to handle them physically.
Outcome	) Likewise, despite the use of featurepreserving mesh improvement, some popping artifacts due to onthe-fly remeshing are still visible in our animations.
Approach	We also remedy a shortcoming of existing mesh-based approaches: that surface details below the simulation resolution add energy but cannot be correctly evolved by the solver; without correct feedback from the physics this noise tends to worsen and destroy stability.
Background	Ensuring temporal coherence and avoiding visual artifacts due to the use of regular grids can also be problematic.
Background	Furthermore, there remains no guarantee that features below the smallest grid cell size will be captured.
Outcome	In contrast, regular samples cannot fully capture the initial surface perturbation, so it cannot be rectified.
Approach	By instead combining our surface tension model with a geometry-aware sampling, we ensure all relevant details are properly resolved.
Background	The greatest challenge is handling topological change, due to mesh tangling that may occur during merging and splitting.
Approach	Unfortunately, merging in this scenario can often take several time steps to resolve because the interpolated velocity in the air gap still averages to zero, thereby preventing surface geometry from actually intersecting and flagging a collision.
Approach	Rather than using level set finite differences, we compute curvature directly from the surface mesh to accurately capture high-frequency features.
Approach	This is considerably more difficult than non-conforming Delaunay tetrahedralization, and generally requires more Steiner points, worse-shaped tetrahedra, and/or the loss of the Delaunay property.
Approach	This method appears highly accurate, and leads to much less damping than that of Wojtan et al. [2009].
Approach	Since our method uses embedded boundary conditions, we do not require conforming elements.
Approach	Advect velocities onto the new mesh with semi-Lagrangian advection (section 6).
Approach	For maximum fidelity at the face centroids, we also replace the normal component of the averaged full velocity with the exact normal component already stored at the face.
Challenge	However, these remain among the most difficult features to simulate plausibly and accurately with existing techniques.
Approach	We solve the resulting symmetric positive definite linear system using incomplete Cholesky-preconditioned conjugate gradients.
Approach	Normal components of velocity lie on the faces of the Voronoi cells, so that the velocity sample is parallel to the line segment connecting the pressure samples in the Delaunay mesh.
Approach	Simple and efficient barycentric interpolations can then be applied on the resulting smaller tetrahedra.
Approach	We use finite volumes on a Voronoi mesh for the pressure projection step, similar to Sin et al. [2009].
Outcome	Rather than quickly collapsing into a sphere, a cascade of detailed capillary waves propagate along the surface, causing it to oscillate rapidly.
Outcome	Therefore, not all artifacts due to surface tracking are addressed.
Background	Goktekin et al. [2004] experimented with a doubleresolution level set, trading better volume conservation for other artifacts.
Background	One solution is to determine problematic regions, switch to an implicit surface to repair the tangles there, then stitch back in a new consistent mesh patch [Du et al. 2006; Wojtan et al. 2009].
Challenge	However, when the surface is coupled to a standard Eulerian simulator, the liquid volume must first be resampled onto the simulation mesh or grid to provide geometric information for boundary conditions.
Approach	We begin by choosing a characteristic length scale for the simulation, ∆x, and configure El Topo to try to maintain triangle edge 1 3 lengths in the range [ 2 ∆x, 2 ∆x].
FutureWork	For example, it may be possible to enhance our sampling scheme in various ways, perhaps by exploiting curvature adaptivity, topological information, or measures of vorticity and velocity variation.
Approach	We further reject new pressure samples which are too close to an existing sample by some epsilon, which would cause a very short edge in the final mesh.
Approach	This is necessary because the divergence constraint is not enforced on air cells, so they can act as liquid sinks [Losasso et al. 2006] and destroy liquid volume until the geometry finally merges.
Background	For example, Wojtan & Turk [2008] used a surface mesh coupled to a lower resolution finite element solver; forcing the simulation mesh to have the same topology, if not resolution, as the embedded surface mesh may improve realism [Teran et al. 2005; Nesme et al. 2009].
Approach	Inspired by an example from the work of Wojtan & Turk [2008], we run another zero gravity simulation on a rectangular block (see figure 11 ).
Approach	Because the sharper, more accurate velocities at the Voronoi vertices are retained and merely augmented with additional data, this is far less dissipative, yielding results that closely match generalized barycentric interpolation (see figure 11 ).
Background	The shortcomings of implicit schemes have spurred interest in explicit methods, i.e. “front tracking” [Glimm et al. 1998].
Outcome	Our sampling ensures that almost arbitrarily thin sheets of liquid remain visible to the solver, and as such, interesting rippling and splashing motion still occurs.
Outcome	Though the ghost fluid method on regular samples does detect some differences in surface height, this actually exacerbates the problem because noisy sub-mesh details will appear to the simulator as rapid discontinuous changes in surface position over time, inducing noisy responses in the fluid velocity.
Approach	We therefore extrapolate velocities outwards from the fluid using a breadth-first graph propagation: each unknown point in a layer is set by averaging all adjacent known points from previous layers, repeating until we have a sufficiently large band of velocities surrounding the surface.
Background	Bargteil et al. [2006] similarly coupled an octree contouring method to a uniform grid fluid solver and explicitly discussed potential artifacts due to resolution mismatch, such as erroneously preserving surface noise and the solver interpreting disconnected fluid regions as connected.
FutureWork	Obvious optimizations include: reducing the number of tetrahedra through smarter sampling, improving the broad phase algorithm for point-location queries, and streamlining the construction of mesh data structures.
Approach	A prime focus of our work is matching the surface mesh resolution to that of the liquid solver.
Approach	If we find any triangle closer than ∆x, we store the distance d to the closest intersection, and use d in place of ∆x in the offset distance calculations above (see figure 7 ).
Approach	Our method extends these advantages to Voronoi meshes.
Approach	A slight improvement can be achieved by casting rays to find the exact position of the surface mesh between pressure samples.
Background	Implicit surfaces have long been used to capture liquid geometry in animation; this family of schemes includes level set (LS) methods [Enright et al. 2002a], volume-of-fluid (VOF) [Mihalef et al. 2006; Mullen et al. 2007], and semi-Lagrangian contouring (SLC) [Bargteil et al. 2006].
Challenge	As this resampling process typically destroys small details, they are invisible to the fluid solver and cannot be advanced appropriately.
Approach	By not placing a sample point in these very small gaps, our simulator treats the two liquid bodies as merged and prevents volume loss; the geometric merge is usually then processed within a few timesteps.
Approach	To handle this, we temporarily place an extra vertex at the face centroid, and use it to triangulate the face.
Approach	All samples are then run through a Delaunay mesh generator such as TetGen [Si 2006].
Approach	A simple and fast alternative discussed by Klingner et al. and Chentanez et al. is to first interpolate velocities to Voronoi sites (tetrahedra vertices) and apply standard (and fast) barycentric interpolation over each tetrahedron.
Background	An advantage of this approach is that the pressure degrees of freedom are directly tied to the number of particles, so there can never be a resolution mismatch between surface geometry and simulator.
FutureWork	Our implementation is not heavily optimized, and we defer various potential performance gains to future work.
Approach	Solve for the embedded-boundary pressure projection on the Voronoi mesh, including surface tension forces (section 4).
Approach	This configuration requires a slightly different velocity reconstruction compared to previous methods, but semi-Lagrangian advection is otherwise straightforward.
Background	The latter is exemplified by the ghost fluid method and related approaches [Enright et al. 2003; Hong and Kim 2005; Hong et al. 2007], and has been shown to provide more realistic results.
Approach	This simple method, suggested in the context of cloth-fluid coupling by [Guendelman et al. 2005], sufficed for all our animations.
Approach	Our goal in many of the other examples was to highlight the ability to track thin sheets, whereas surface tension would break these sheets into droplets.
Approach	Advect the explicit surface with 2.
Approach	If the distance between the surface vertex and the first intersection 1 is below some threshold (e.g. 20 ∆x) at which we consider the two surfaces to have effectively collided, and the proposed sample is an air sample, we also discard it.
Background	Then barycentric or generalized barycentric interpolation between those locations interpolates velocity over the full domain.
Approach	By specifically placing points inside such small features, we ensure they cannot be missed.
Approach	If mesh quality cannot be improved sufficiently, using additional nearby velocity samples in the reconstruction can ameliorate this at the cost of a smoother result.
Approach	While these operations change mesh connectivity, they are designed to be geometry-preserving.
Outcome	We suspect that because our method retains sharp wave peaks and splashes rather than continually eroding them, their extra kinetic and gravitational potential energy is retained in the simulation, accounting for this reduced dissipation.
Background	Batty et al. [2010] used marching triangles cases for computing tetrahedra face fractions from signed distance values on the vertices.
Approach	As accuracy requires that tetrahedral schemes store pressures at circumcenters [Klingner et al. 2006; Batty et al. 2010], and since circumcenters often lie outside their associated tetrahedra, even filling a thin feature with conforming tetrahedra provides no guarantee that its interior will be sampled at all.
Background	(Note that this advantage is shared by the method of Batty et al. [2010].
Outcome	In addition, we adapted embedded boundary pressure projection techniques to Voronoi meshes, introduced a simple improvement to barycentric velocity interpolation for Voronoi/Delaunay meshes, and extended the ghost fluid surface tension model with mesh-based curvature in order to capture complex capillary waves with minimal damping.
Approach	We generally follow the tetrahedral scheme of Batty et al. [2010] with modifications to use specially designed Voronoi meshes instead.
Outcome	For example, El Topo delays handling some very difficult collisions for a few timesteps until the topological operations can be safely processed, which occasionally yields visible lingering surface noise.
Approach	Lastly, note that reconstructions should only use face velocities which were assigned valid data by the pressure projection, and thus we can only reconstruct reasonable velocities inside the fluid.
Approach	In particular, we try to ensure that one edge of the Delaunay triangulation passes through each surface vertex, with one sample inside and one outside.
Approach	While we found this posed little problem for the pressure projection, it can cause the least squares velocity reconstructions to be ill-conditioned due to nearly co-planar face normals.
Approach	We chose the operator of Meyer et al. [2002b] because it provides high quality estimates using just the one-ring of triangles surrounding each vertex, but others could work too.
Approach	Careful pressure sample placement with respect to the surface helps in three important ways.
Outcome	It initially inverts almost completely into an octahedron (the geometric dual of a cube), and continues to oscillate for many subsequent frames.
Outcome	(Reducing the time step size can help by introducing fewer and simpler collisions, and more aggressive simplification can also be enabled by tuning the volume change tolerance that El Topo uses to decide whether to accept a given simplification.
Approach	We conceptually tetrahedralize the Voronoi cells themselves by placing additional vertices at Voronoi face centroids and Voronoi sites (see figure 10 ).
Approach	Generate a new simulation mesh as the Voronoi diagram of a lattice with extra samples near the liquid surface (section 5).
Approach	As a result, surface mesh normal directions will often align exactly with a velocity sample in the simulation mesh; this lends additional accuracy to the vertex’s normal motion, and to the incorporation of the normal force due to surface tension calculated at the vertex.
Background	Implicit approaches naturally yield smooth surfaces and seamlessly handle topological change.
Background	Given such an interpolant, advection of velocities and geometry is straightforward.
Background	Here the surface is represented explicitly as a triangle mesh, whose vertices are moved with the fluid velocity field.
Background	Mismatched resolutions have been found useful for deformable solids, particularly as surface details are expected to generally persist, unlike in liquids.
Approach	We use this method in the presented examples, though note that other front tracking methods could easily be used instead—for example, recent work by Campen & Kobbelt [2010] suggests that the need for collision processing could be obviated with exact Boolean operations.
Approach	We take the best of each, computing an accurate force from the surface mesh and incorporating it precisely at the surface with the ghost fluid method.
Approach	Subdivide the Voronoi cells into sub-tetrahedra using the sites and face centroids (see figure 10 ).
Approach	We chose El Topo because its resolution is not constrained to a regular grid and it is therefore able to showcase very thin features; nevertheless our method could adapt to any of the front tracking methods mentioned in section 2.2.
Approach	) Moreover, the position of pressure samples plays a more important role in free surface conditions than the position of element faces.
Approach	Like Sin et al. [2009], we place pressure samples on the vertices of a Delaunay tetrahedral mesh, corresponding to the sites of the dual Voronoi diagram (figures 3(a) and 3(b)).
Approach	To actually compute the liquid signed distance field on the tetrahedral mesh, we compute exact geometric distance for a narrow band of tetrahedra near the surface, then use a graph- based propagation of closest triangle indices to roughly fill in the rest of the mesh.
Approach	Assign full velocity vectors to Voronoi sites and faces using simple averaging from neighboring vertices.
Background	Velocity interpolation methods for unstructured meshes typically proceed in two steps [Klingner et al. 2006; Elcott et al. 2007; Batty et al. 2010].
Background	If a surface mesh is available, a more accurate approach is either to use mesh-based curvature operators (e.g. [Meyer et al. 2002b]), or as proposed recently, to model a physical tension directly in the surface mesh geometry [Perot and Nallapati 2003; Brochu 2006; Wojtan and Turk 2008].
Background	First, a full velocity vector is reconstructed at selected mesh locations using a least-squares fit to the nearby velocity components.
Background	Most level set-based solvers use one level set sample per pressure grid cell, conservatively avoiding resolution inconsistencies (e.g. [Foster and Fedkiw 2001; Enright et al. 2002b]).
Outcome	The practical benefits of such a system include: • improved animation of detailed liquid features, including very thin sheets, tendrils and droplets, • elimination of noise in explicit surface tracking without nonphysical smoothing, • more detailed and less damped surface tension effects, • and faster semi-Lagrangian advection on unstructured meshes without increased dissipation.
Approach	The embedded (ghost fluid) free surface condition uses signed distance estimates at pressure samples to estimate the surface position; these are now located at Voronoi sites rather than tetrahedra circumcenters, but the method is otherwise unchanged ( figure 3(c) ).
Background	Franklin & Lee [2010] subdivide polyhedra into tetrahedra for interpolation similar to our method, but our method is simpler due to use of the Voronoi diagram.
Approach	We couple this with a semi-Lagrangian advection scheme and a new approach to surface tension, arriving at a complete liquid simulator.
Approach	However, rather than applying boundary conditions as they describe, we adapt the embedded boundary methods of Batty et al. [2010] to Voronoi meshes.
Approach	This generates non-physical air bubbles which linger for many timesteps before they self-collide and are eliminated.
Background	Approaches to surface tension generally fall into two categories: those which apply surface tension as a body force in a region around the interface via smeared delta functions [Brackbill et al. 1992; Hong and Kim 2003; Zheng et al. 2006; Wojtan et al. 2009], and those which apply surface tension discontinuously at the interface, typically as a boundary condition in the pressure projection step.
Approach	In our configuration, velocity components instead lie along the tetrahedra edges (Voronoi faces) so we perform the least squares fit on this data instead.
Background	Topological operations are only allowed when safe, while robust collision processing is used as a last resort to avoid tangles, i.e. the surface is minimally perturbed to avoid problems.
Outcome	Although we are using only first-order semi-Lagrangian advection, the liquid motion remains lively and active throughout.
Background	Unstructured and semi-structured meshes have a long history in computational fluid dynamics, and have gained traction in computer animation as well.
Approach	Constructing the simulation mesh in this way allows us to place samples anywhere in the computational domain; we exploit this by choosing samples that accurately capture the geometry and topology of the liquid surface.
Challenge	Such detailed behaviour is extremely computationally expensive to resolve because of the tremendous grid resolution required for both the fluid solver and the surface tracking mechanism.
FutureWork	Further experimentation with relative mesh spacing parameters could yield improved results.
Approach	This can be readily resolved by requesting that the mesh generator add Steiner points to enforce fairly lax quality bounds; because our embedded pressure projection does not require the mesh generator to match boundaries, this is relatively inexpensive and effective.
Approach	We then use signed distance estimates at the vertices to compute each sub-triangle’s partial area, and sum them to determine the partial area for the complete face.
Background	Müller [2009] takes a similar grid-based approach to untangling, rebuilding a consistent mesh using marching-cubeslike stencils.

Outcome	More precisely, we see that accuracy is well preserved with one Conjugate Gradient iteration up to a K value of 4, and increasing the iteration number n times also increases the K value n 2 times for the same accuracy.
Background	A nice solution described in [ EBE 00 ], which makes sense when efficiency relies on the use of a constant Hessian matrix, is to perform the implicit resolution on a linear constant approximation, and to simulate the nonlinear and variable component, unlikely to cause stiffness problems, using an explicit method.
Approach	The solution for this is to approximate the Hessian matrix for taking into account the changes that may be observed from the change of the system state between successive iterations.
Background	The literature is abundant about various integration methods which aim to solve linear systems of first-order ordinary differential equations [ PRE 92 ].
Approach	Our purpose is here to find the computation time necessary to obtain the fabric in its vertical position.
Outcome	Real-world simulations do not have this regularity, and numerical instability with explicit methods occur in the stiffest regions of the mesh, which, even if they are marginal in the whole mechanical system, may totally “explode” and destroy the simulation and therefore will rule the size of the largest time step possible.
Approach	Our first investigation is to evaluate the iteration computation time for each of these methods.
Background	It requires one mechanical evaluation and the resolution of a sparse linear system per iteration, as well as one storage of the system state additionally to those required for the system resolution algorithm.
Background	The cloth surface shape is represented by the geometry between neighboring particles.
Approach	With implicit methods, the resulting inaccuracies may be unnoticed when taking a time step adapted to the average stiffness.
Outcome	All these considerations should be carefully taken into account when designing a mechanical simulation engine, as they are the keys to efficient simulation, and therefore complex models that, for garment simulation, express fully visual experience of real fashion models.
Background	While rarely causing numeric “explosions” as with explicit methods, nonlinearity may disrupt the stability of simulations integrated with implicit models with large disturbing vibrations, particularly when using large time steps that cause iterations to converge to the equilibrium state of the mechanical objects rather than simulating accurately their mechanical behavior.
Approach	Given a discretization into elements averaging one centimeter and a simulation time step of ten milliseconds, the condition coefficient of the problem computed with (1) is K = 2 0 0 .
Approach	Performance timings are done on the mechanical computation only, and do not take into account display and data structure management.
Outcome	As a matter of simulation accuracy, both Midpoint and Runge-Kutta seem to preserve accuracy correctly within their range of numerical stability.
Approach	Knowledge of the expected state changes between successive time steps are required to perform this approximation correctly.
Outcome	Their stability gives a false sense of efficiency, allowing obtaining quickly a result by “cheating” on the time step size.
Approach	We measure the time it takes for this fabric piece to fall a height of 1 m .
Background	A particle system represents the mechanical system as a set of punctual masses.
Approach	For this, we count the number of computation iterations necessary for obtaining the fabric in its vertical position in its first oscillation, not being interested by the realism of this motion (Fig.5).
Approach	Without any damping, we expect that in its first oscillation, the fabric reach a roughly vertical position after slightly more than half a second.
Background	Among the available methods, there are finite elements methods [ EIS 96 ], continuum mechanics [ TER 87 ] or particle systems [ BRE 94 ].
Outcome	Several interesting facts arise from this experiment.
Approach	This is a draping problem involving to obtain a rest position of the garment as quickly as possible.
Background	It also requires two storages of the state vector.
Outcome	Our first finding is that the explicit methods seem quite not adapted for draping.
Approach	In order to test the efficiency of our model in the context of garment animation, the algorithms have been integrated in a 3D design framework allowing the management of complex garment objects in interaction with animated virtual characters.
Approach	It is possible to define similar coefficients related to bending and viscosity modulus.
Outcome	While not exactly reproducing real mechanical behavior, the simulation with large time steps provides a quite efficient convergence to equilibrium, and the numerical errors quite often act as extra damping, removing the need of adding them explicitly to the model.
Approach	An object-oriented framework written in C++ integrate all these technologies into a single application allowing simulation of cloth objects of any shape with specified parameters.
Outcome	The backward Euler method is robust enough to handle the problem without instability for any time step.
Approach	We checked experimentally with our implementation that any scaling of a simulation along distance, time and mass which leaves K unchanged does not change anything to the simulation result.
Background	The laws ruling these interactions also rank from linear to highly nonlinear involving discontinuities and hysteretic curves.
Approach	These factors describe our investigation field in the following sections.
Challenge	The correct choice of the simulation method and its implementation is a very important issue in the design of an efficient cloth simulation system.
Background	No initial matrix setup is required, suppressing also the need of separating linear and nonlinear components as discussed in [ EBE 00 ].
Approach	For measuring accuracy and numerical stability of the algorithms, we need to set up a “standard” material on which the experiments are carried out, as well as the rules allowing to extrapolate the results to any material of different size and parameters.
Approach	The mesh elements are roughly five centimeters in size, and therefore the resulting condition coefficient K is roughly 8 with a simulation time step of 10 milliseconds.
Approach	These tests will help us to choose the method that gives the best compromise between accuracy and computation speed, as discussed in the next section.
Approach	We have also carried out some preliminary tests with the Rosenbrook method, which is an implicit implementation of a fourth-order Runge-Kutta method.
Background	This numerical system has to be integrated numerically, for finally obtaining the evolution of the mechanical system along time, usually as a sequence of successive positions of the object along regular time intervals.
Background	For instance, the strain-stress relation describing elasticity may actually be complex curves, which furthermore may take into account timedependent and hysteretic behaviors.
FutureWork	The integration methods have to be tuned to take precisely these effects into account.
Approach	The dynamical motion of the cloth is important here.
Outcome	For dynamic problems where accurate evolution of the mechanical system along time is needed, the advantage of implicit methods is less obvious.
Background	This method is supposed to provide approximate results that are not subject to numerical instability as the time step is increased.
Outcome	However, the more drastic these approximations are, the less accurate the simulation will be for dynamic simulations, and the slower the simulation will converge for draping problems.
Outcome	Anyhow, this experiment shows clearly that when accurate reproduction of dynamic motion is required, it is not possible to increase the time step of implicit methods as much as desired, as this cause very noticeable inaccuracy as weak forces will be “neglected” relatively to stiff forces.
Outcome	We implemented this method using the algorithm described in [ PRE 92 ], but preliminary experiments have shown very deceptive results, and the gain of accuracy did not compensate the large calculations required for each iteration, whereas increased instability problems did not allow time steps much larger than those used for good accuracy with backward Euler.
FutureWork	We intend to pursue our investigations for dealing with damping in a more accurate way.
Outcome	Instability concerns will force parameters and time step size to ensure good accuracy for the simulation of all particles of the discrete mechanical representation, and therefore for the entire mechanical object.
Outcome	Contrary the perception of the implicit model iteration being slow because of the linear system resolution it involves, the inverse Euler iteration often proves to be faster than the explicit Runge-Kutta method of higher order, if an adequate approximate linear system resolution is implemented.
Approach	This allows the iterations of the Conjugate Gradient algorithm to distribute the resolution numerical errors as evenly as possible between the particles, so that to obtain for instance a fall speed that does not depend on the mass of the particle.
Approach	We implemented this method for garment simulation in [ VOL 95 ].
Approach	However, it should be noted that the experiment was carried out using a uniformly discretized mesh, and uniform mechanical parameters.
Outcome	There is an obvious advantage of using implicit methods, and particularly the inverse Euler method, for draping problems where quick convergence to a rest position is required quickly.
Outcome	It seems that there is still some benefit in using the Backward Euler method than any other explicit method for dynamic simulations thanks to the reduced time it takes to compute one iteration, which also only requires one derivation of the particle forces from the state of the system.
Outcome	For the dynamical animation, comparable accuracy could be obtained between Runge-Kutta and Backward Euler using eight iterations of the Conjugate Gradient, which gave similar computation times.
Approach	Using a “typical” cloth object made of a common fabric material, we compare the computation speed and accuracy of each integration methods depending several simulation contexts, giving the reader an overview of the performance he can expect from each method.
Background	This method was experimented in [ EBE 96 ] and [ VOL 97 ].
Outcome	Given the fact that a Runge-Kutta iteration takes only three times more computation than a Midpoint iteration (Fig.1), the Runge-Kutta method seems to be computationally two times more efficient than the Midpoint method.
Approach	This is particularly true when simulating very heterogeneous mechanical systems (elements of various sizes and various mechanical properties) where, using explicit models, the most critical elements would rule the time step size for all the simulation.
Background	Performance is a key issue in choosing the adequate integration method, as cloth simulation usually involves very large mechanical systems described by a huge number of variables, and the numerical resolution of the system is therefore critical to the total computation time.
Approach	Accuracy increases along with time step reduction as better as the method is high-order.
Approach	This depends on the complexity of the method, and also related to the number of times the forces of the system have to de derived from the system state using the laws of mechanics.
Outcome	While the implicit Euler method seems stable for any K value, its accuracy is however very degraded by high K values and reduced numbers of Conjugate Gradient iterations.
Approach	We will focus on the latter, which has shown to bring the best compromise between accuracy and speed for highly deformable objects such as cloth [ VOL 95 ] [ VOL 97 ].
Approach	When using implicit methods, we perform a preconditioning of the system state variables of the linear system to be resolved using the inverse square root of the mass of the corresponding particle.
Challenge	It rather intends to evaluate quantitatively the performance of the main integration methods in terms of speed and accuracy.
Outcome	The number of iterations should also be set sensitively to the stiffness of the mechanical problem, for limiting the potential inaccuracies that become particularly visible when an accurate simulation of a dynamical system is wanted.
Approach	Without any additional external forces considered (no aerodynamic interactions), we expect this to happen in a constant time of 0.45 s.
Background	Draping is another context of simulation, where only the final static equilibrium state of the mechanical system is to be computed.
Outcome	We also see that similar requirement of accuracy bring the two methods in parity in terms of computation time (Fig.1).
Outcome	Furthermore, while increasing the time step seems not limited by instability with implicit methods, it should be kept in mind that this is still done at the expense of accuracy of the whole simulation.
Outcome	From this, we can see that the Inverse Euler method needs at least four Conjugate Gradient iterations to reach the accuracy of the Runge-Kutta method.
Approach	With nonlinear mechanical behavior, one solution is to take the steepest parts of the curves as derivatives, whereas for the element orientation problem, isotropic derivatives considering force evolution equally in any directions may be considered.
Approach	For the simulation, the surface square is discretized into elements which roughly have the length l, and the computation is carried out with time steps of size t.
Outcome	Our test have shown that the inverse Euler method allow to perform a draping problem almost ten times as fast as with the Runge-Kutta method.
Background	The reason for that is that the hypothetical equilibrium state is derived from the knowledge of the Hessian matrix, which relates the firstorder evolution of the forces as the deformations change.
Outcome	This indicates that with Runge-Kutta, it is possible to use simulation time steps which are almost six times larger than with Midpoint.
Approach	We did not consider in our tests the methods aimed toward simplifications which might highly approximate and degrade the dynamic behavior of deformable models, such as implicit integration with precomputed inverse matrices [ DES 99 ] which involves high simplification and linrarization of the Hessian matrix and which also becomes very unpractical for large matrix sizes (the inverse of a sparse matrix is not necessarily sparse).
Approach	The base element of this simulation is a triangle of the mesh describing the surface, and the elasticity laws are computed as interactions between the three vertices of a triangle reflecting all the mechanical behavior curves which, for this study, are restricted to be linear.
Outcome	We got substantial improvements through the implementation of the implicit Midpoint method [ VOL 00 ], which however had the drawback of increasing the numerical instability problem, forcing additional use of isotropic force gradients, at the expense of accuracy.
Outcome	From this it is clear that when K exceeds the dynamic accuracy limit of a given implicit integration method, the time step does not really reflect a time interval anymore.
Outcome	While this factor is what cause explicit methods to become so inefficient with refined discretizations as this scaling has to be strictly observed for preventing instability, implicit methods are a bit more tolerant if only “visual” accuracy matters, accuracy which is not related to the size of the elements.
Approach	In the scope of our study, we restrict the experimentation to linear metric elasticity of an isotropic cloth material, described by a Young modulus E and a surface density d.
Background	This method is supposed to provide high accuracy, which increases significantly as the time step is reduced.
Approach	We shall restrict our consideration to three different methods which explore the range of these classes, and which seem to fit the best the requirements set for cloth simulation problems, in terms of implementation simplicity and efficiency for particle systems using large numbers of particles that interact sparsely and with a constant topology.
Approach	In such kind of simulation, the interest is to reproduce exactly the motion of a cloth object along time, the accuracy of its evolution being the key of the realism of an animation involving simulated cloth.
Outcome	The simpler Midpoint method may have some interest only in very particular cases involving very loose materials with rough discretization, or when numerous fast iterations with small time steps are required for other reasons (high motion sampling, collision detection, very discontinuous models).
Outcome	However, we see that larger time steps do not proportionally translate into fewer steps for performing the draping.
Outcome	The explicit methods have still their interest, and should be reserved for simulations requiring high accuracy and particularly those where involving low mechanical damping and where mechanical energy conservation is important.
Background	Various models exist for this representation, which rank from the simple spring-mass representation (spring forces between particle couples depending on the distance between the particles) to accurate surface or volume models (involving complex interactions between several neighboring particles).
Background	It requires five mechanical derivations per iteration, as well as five storages of the state vector.
Outcome	As the time step becomes larger, and as the corresponding K coefficient exceeds the theoretical limit observed in the previous section, we quickly observe a “saturation” of the number of iterations to a constant which seems to be inversely proportional to the number of Conjugate Gradient iterations that were performed.
Challenge	One can easily turn the second-order systems relating dynamical mechanical systems into first-order systems by constructing a state vector defined by the concatenation of position and speed states of the system, such as to fit the requirements of any of these algorithms.
Outcome	We simulated such algorithm using accurate resolution on an accordingly approximated constant matrix, and we found that these approximations produced more simulation errors (on dynamic behavior of wrinkles and motion damping particularly) than producing a quick and rough linear system solution using a reduced number of Conjugate Gradient iterations with an accurate matrix.
Approach	Bending is also implemented, but not taken into account in this study.
Approach	This is particularly true for drastic linearisations as for example used in [ DES 99 ].
Background	It is supposed to combine the stability of implicit methods with the accuracy of high-order methods.
Approach	Nonlinearity causes this matrix to change between the successive iterations, and this evaluation to be inaccurate, despite high system resolution accuracy that can be reached with numerous Conjugate Gradient iterations.
Approach	From the dynamic study described above, implicit methods should be quite strong on this point, as they do not suffer from numerical instability, and allow large time steps to be used at the expense of dynamic accuracy which can here be neglected.
Outcome	The 5th-order Runge-Kutta method das proven to be a good solution [ EBE 96 ] [ VOL 97 ], because of its high accuracy, and because it furthermore provides integration error evaluation, which is a very good hint to the very sensitive problem of optimal time step size determination.
Approach	A typical cloth simulation problem could involve a cotton fabric cloth surface, which typically have a density d = 0.1 kg.m -2 and a Young modulus E = 2 0 N .
Background	It requires two mechanical derivations per iteration and returns a second-order accurate solution relative to the time step.
Background	* During the simulation, the orientation of the mechanical elements change, and this modifies the expressions of the mechanical laws in the world coordinates.
Challenge	The aim of this study is not to describe the implementation of these methods, which has already been carried out extensively in [ EBE 96 ] [ VOL 97 ] [ BAR 98 ] [ VOL 00 ], and with some adaptations in [ DES 99 ] [ EBE 00 ] [ KAN 00 ].
Approach	We implemented this method combined with a Conjugate Gradient algorithm using linear system matrix products computed on the fly, as described in [ VOL 00 ], and thus able to take into account the anisotropy and nonlinearities of the mechanical model as the actual Hessian matric is used for each current state of the mechanical system.
Background	Even more drastic simplifications [ KAN 00 ] reduce the matrices to their diagonal component.
Approach	While an underestimation of de derivatives may lead to an equilibrium state valuation too far from the current state, and by this cause instability, an overestimation of the derivatives will place this evaluation nearer to the current state, therefore stabilizing the simulation, at the expense of extra numerical damping and slow convergence.
Outcome	With one iteration only, it is barely worse than the very simple explicit Midpoint method.
Approach	Here, the interest is to converge to the equilibrium state as quickly as possible, with minimum computation charge.
Approach	Given the fact that there are also n 2 times more elements to handle, the total computation time is finally multiplied by a drastic n 3 (even n 4 if curvature stiffness rule the simulation accuracy).
FutureWork	This still remains an important issue to dynamic realism of cloth simulation models, which has to take into account viscosity, the dissipative effect of hysteretic behavior, as well as collision damping and friction.
Challenge	The choice of the adequate integration method has to be carried out using various considerations related to the kind of problem to be simulated.
Approach	The corresponding K coefficients are respectively multiplied by additional l -2 and t factors.
Background	The evolution of the system is computed numerically from these equations that form a large and sparse ordinary differential equation system, which, through adequate modeling, is also first-order.
Outcome	This paper presents a quantitative comparison of the efficiency of the most common integration techniques used for cloth simulation, and raises the key considerations for optimal implementations depending on the practical kind of simulation problematic.
Outcome	As a matter of numerical stability, the Midpoint method supports K values up to almost 3 whereas the RungeKutta method supports K values up to almost 100.
Approach	A limited number of Conjugate Gradient iterations seems suitable for this.
Approach	Considering a simulation involving elements n times smaller, maintaining accuracy and stability (preserving K constant in formula (1)) would require a time step n times smaller, and therefore n times as many iterations for simulating the mechanical system along a constant duration.
Outcome	While this is not an issue for draping problems where only the final state is desired, this aspect has to be taken into account when accurate reproduction of the whole evolution is wanted.
Outcome	This gives a very efficient implementation when using a low number of Conjugate Gradient iterations (no heavy preprocessing for building the matrix), which is often sufficient for most applications.
Outcome	The implicit Euler method seems effectively a good candidate for most situations involving cloth simulation, because of the robustness resulting from not being prone to numerical instability.
Approach	Our implementation, described in [ VOL 00 ] does not explicitly construct the matrix of the system to be resolved by the Conjugate Gradient, but computes “on the fly” the product of this matrix with vectors when needed by the Conjugate Gradient algorithm.
Approach	We have simulated a 2000 Polygon garment made of the cotton material described in Section 3.
Approach	As the full evolution of the cloth along time is not an interest, accuracy can be traded away for computation speed.
Approach	In simulations that consider simultaneously all these forms of mechanical behaviors, the dominant K coefficient rules the “numerical difficulty” of the problem.
Outcome	The garment assembly and seaming operations could be performed almost four times faster with the Backward Euler (2 minutes) than with Runge-Kutta (8 minutes), knowing that collision detection and response account for more than the half of the computation time, and actually limits the time step size when contact starts between the cloth and the body.
Outcome	This may however require prohibitive computation times for very stiff and discretized models.
Outcome	Our tests have shown a roughly doubled speed for the accuracy corresponding to the limit of stability of the Runge-Kutta method.
Approach	This model is one of the simplest that a cloth simulation application would use.
Background	Most mechanical simulations work with numerical equations that are not linear.
Background	This can for instance be observed when simulating stretched flat surfaces without curvature forces.
Outcome	These artifacts are still augmented by the approximations made to the Hessian matrix, possibly in the purpose of reducing instability, while excessive reduction of the Conjugate Gradient iterations produce additional inaccuracy and slow convergence.
Background	Recent literature has emphasized on the relevance of implicit methods for cloth simulation.
Background	The mechanical behavior is represented as interaction forces between the particles, which depend on the relative position and speed of the particles, measuring deformation and deformation speed.
Approach	The application is run on a SGI Octane having a 200 MHz R100000 processor, and enough memory for working without swapping.
Challenge	Choosing the adequate method should be done with full knowledge of the advantages and weaknesses of the main techniques.
Background	The total computation time is the time required for computing one iteration times the number of iterations.
Approach	The implementation also supports collision detection and response, which were disabled for these tests.
Approach	For these measurements, we have simulated a square of fabric with a given discretization both with the accurate and simplified models, using the Midpoint, the RungeKutta and the Backward Euler methods, with 1, 2, 4, 8 iterations in the Conjugate Gradient algorithm for the latter, and measured computation time (Fig.1).
Approach	This integration has been carried out in the form of a 3DStudio Max plugin (Fig.6), running on a 500 MHz PentiumIII PC.
Approach	In such case, the implicit method will only evaluate an approximation of the rest state of the mechanical system by linear extrapolation from the Hessian matrix, whose accuracy depends on the number of Conjugate Gradient iterations that were used to resolve the corresponding linear system.
Approach	We preferred this method to the still simpler first-order Euler method, because of the obvious gains of accuracy and stability which, despite the additional mechanical evaluation, makes it largely more efficient.

Background	Moreover, full musculoskeletal models are significantly more difficult to construct than joint-actuated models.
Approach	This formulation captures the tendency to rotate the shoulder backwards and inwards while bending the elbow.
Background	In particular, as was the case in SIMBICON [Yin et al. 2007], the gait is largely hip-driven, as can be seen by the large hip torques and small ankle torques compared to human data.
Background	Our use of biologically-based actuators enables the estimation of metabolic energy expenditure based on the internal state of the MTUs [Anderson 1999].
Approach	Unlike in previous work, where a gait cycle is broken down into four states, only two are needed (triggered by left/right foot-strike) since DOFs with the most complex activities are actuated by muscles.
Challenge	Can we synthesize appropriate gaits for older or younger characters?
Approach	The sagittal hip, knee, and ankle degrees-of-freedom are actuated using a set of eight Hill-type musculotendon models in each leg, with biologically-motivated control laws.
Approach	A simple variable moment arm model is assumed for MTUs attached to the knee or ankle: τ = r j cos(θ − φ j M )F MTU , where θ is the current knee or ankle angle in the sagittal plane, and r j is the maximum MTU-joint moment arm, which occurs at the joint angle φ j M .
Outcome	Likely due to our modeling of human-like torque generation and activation delays, our controllers cannot tolerate nearly as much external force as recently developed controllers for purely joint-actuated characters [Mordatch et al. 2010; Wang et al. 2010].
Approach	For the upper body and the non-sagittal DOFs in the lower body, we optimize the PDcontrol parameters (spring-damper constants, target angle, balance feedback) for all joints except for arms, where only a target elbow angle and a swing scale parameter are optimized (Section 4.4).
Outcome	We have presented a biologically-motivated control parameterization that can be used to automatically generate 3D human-like walking and running controllers of different speeds.
Approach	The scale constant and the desired elbow angle are among the parameters set by optimization, as described in the next section.
Approach	Much like in the stance phase, each muscle has an initial constant excitation value (q m ).
Outcome	The hip ◦ angle range and maximum knee flexion both increased by 30 as running speed increased from 2.0 m/s to 5.0 m/s, while locations of both the maximum hip extension and ankle plantarflexion shifted earlier by 5% and 10%, respectively.
Outcome	Both the hip and ankle torque outputs increased with speed, though the ankle torque curves did not differ significantly between 4.0 m/s and 5.0 m/s.
Outcome	The resulting gaits match human ground truth to a greater extent than state-of-the-art walking controllers that do not rely on motion capture data.
Approach	These musculotendon units generate torques for the most important degrees-of-freedom (DOFs) during locomotion— the sagittal plane hip, knee, and ankle DOFs.
Approach	We also optimized for a 4.0 m/s running controller tolerant of 50 N, 0.4 s pushes, as shown in the video.
Approach	Here we define where M is the set of MTUs, and a m,t is the activation level of MTU m at timestep t (with w M = 60000).
Outcome	We demonstrate how musculotendon actuators, biologicallymotivated control laws, and a more realistic effort term can be used to produce more human-like locomotion gaits.
Outcome	Since the foot is a relatively light link, the actual magnitude of the dorsiflexion torque is not large even when the TA is fully activated, therefore it does not incur a large penalty in the torque objective.
Approach	The main part of our control algorithm consists of functions that determine muscle excitation values for each of the lower body MTUs, which actuate the hip, knee, and ankle DOFs in the sagittal plane.
Approach	Two different sets of control laws apply for each muscle, depending on whether the leg is in stance or swing phase (i.e., foot is on the ground or not).
Approach	We empirically set w M = 100, w R = 1, and w L = 0.5 for all experiments.
Approach	The control algorithm specified in Section 4 has a large number of parameters, which we set by optimization [Wang et al. 2010].
Approach	To this end, we augment the jointactuated humanoid model with a set of Hill-type musculotendon units (MTUs).
Approach	We evaluate the metabolic energy expenditure objective described in Section 5 against the simple sum of squared torques objective, by redefining where Q s is the set of sagittal hip, knee, and ankle DOFs (with w M = 5).
Outcome	As demonstrated in supplemental material, our controllers generate more human-like gaits compared to optimized controllers from Wang et al. [2010] at faster walking speeds (Wang10f, Wang10vf ) as well.
Approach	Much like human locomotion, our controllers utilize significant ankle torque and generate smooth torque trajectories.
Approach	More specifically, each of the u m F , u m L , and u m θ laws have one, two, and three parameters, respectively.
Outcome	On the other hand, our plantarflexion torques have a lower peak than human data, resulting in a strategy that relies on the knees more than the ankles.
Background	A num- ber of projects have since focused on expanding the controller repertoire for simulated bipeds [Jain et al. 2009; Coros et al. 2010; de Lasa et al. 2010] and on locomotion in complex environments [Mordatch et al. 2010; Wu and Popović 2010].
Background	However, in the absence of knee joints, these models cannot be used to simulate accurate gait pat- terns.
Background	In particular, Anderson and Pandy [2001] showed that human-like lower body motor patterns can be found by minimizing metabolic energy expenditure per distance travelled, and we adopt their proposed model of metabolic energy in our work.
Background	Animation researchers have been interested in the control of locomotion for 3D humanoid characters for almost 20 years [Hodgins et al. 1995; Laszlo et al. 1996; Faloutsos et al. 2001].
Approach	The task terms are based on Wang et al. [2010] and are defined in the supplemental material.
Challenge	The mapping from excitation to torque is highly complex due to variable moment arms, biarticular muscles, and the dependence of musculotendon forces on fiber length and contraction velocity [Zajac 1989].
Background	Knee hyperextension, another common gait abnormality, causes patients to vault the body forward over the extended stance limb, and can result from hamstring lengthening surgery in cerebral palsy patients [Kay et al. 2002].
Approach	In particular, we optimized controllers that can tolerate 100 N, 0.4 s pushes to the torso.
Approach	The suppression prevents hyperextension of the knee during mid-stance.
Background	At the same time, efforts have been made to make the synthesized motions more human-like, or “natural.
Approach	The parallel-elastic element (PE) models passive forces (F PE ) generated by the muscle fibers, while the serial-elastic element (SE) models the tendon.
Background	Comparatively, the corresponding 100 N controller presented by Wang et al. [2010], who did not model biological torque generation constraints, did not employ a gait that is significantly different from the undisturbed baseline controller.
Approach	The optimization is terminated after 3000 iterations, which takes approximately 10 hours using 50 compute cores on a cluster of Dell PowerEdge 1950 servers.
Approach	The amount of excitation in the HFL also depends on the value of upper body lean at the beginning of the swing phase (Θ lto ): the further the upper body leans forward compared to the reference lean angle (Θ d ), the more excitation is supplied from the HFL during the swing phase.
Background	In the biomechanics literature, abstract planar models have been used to study high-level principles of human locomotion.
Approach	This data is available from http://graphics.stanford.edu/projects/bio-locomotion .
Approach	The optimization aims to maximize the following return function: T R (w) = r(s t ) − w e J effort .
Outcome	Note that the same angle for the gait ◦ generated by nwalk is 9 .
Approach	First, for running we found it necessary to enter into swing initiation using the d  ̃ > d  ̃ SI condition, rather than just wait for double stance.
Approach	The precise initialization values are provided in the supplemental material.
Challenge	Despite impressive progress, the gaits produced by existing controllers fall short of the natural appearance of human locomotion.
Approach	Controllers are optimized to satisfy a set of high-level task terms while minimizing an effort term based on modeling the rate of metabolic energy expenditure.
Approach	The maintenance heat rate similarly models the heat rate for the muscle to maintain contraction at a certain level, and depends additionally on the current fiber length.
Outcome	Note that our work does not exhibit unnatural torque spikes due to state switching that are present in the previous works.
Approach	The force feedback is the main source of activation to the SOL, GAS, and VAS muscles during the stance phase.
Approach	Following Wang et al. [2010], the target features for the ankle and hip joints in the coronal plane are the global foot and pelvis orientations, respectively.
Background	Using a 2D model with knees and musculotendon actuators, Geyer and Herr [2010] showed that patterns of human walking can be generated by a set of simple control laws motivated by muscle reflexes, which inspired our work.
Background	The spring-loaded inverted pendulum (SLIP) model [Blickhan 1989] has been used as a basis for predicting center-of-mass (COM) movements of human runners [Full and Koditschek 1999].
Outcome	Our result also exhibits a range of knee motion more similar to humans compared to previous works.
Approach	F 0 and l opt are musclespecific maximum isometric force and optimal fiber length parameters.
Background	Hase et al. [2003] optimize a CPG-based (central pattern generator) locomotion controller [Taga 1995] for 3D musculoskeletal models without tendon or activation dynamics, but their results were not compared to human kinematic and dynamic gait patterns.
Approach	Note that F  ̃ m MTU cannot increase indefinitely since the muscle’s force generation capacity depends nonlinearly on the length and contraction velocity of the muscle fiber.
Background	The resulting torque patterns are highly unnatural ( Figure 6b ), leading to artifacts such as excessive plantarflexion and sharp changes in kinematics ( Figure 6a ).
Background	Finally, our work is complementary of the recent work of Jain and Liu [2011], who showed that simulating soft tissue deformation at contact sites could lead to more robust and realistic character motion.
Outcome	Our maximum knee flexion is also lower than human data.
Approach	Notably, walking and running emerge from the same optimization process simply by changing the target velocity and initialization.
Outcome	Simply increasing the penalty on ankle torques does not account for the effort difference between generating torques in different directions.
Outcome	However, all four controllers show excessive dorsiflexion before heel-strike.
Outcome	Comparing the mean curves for walking speeds from 1.0 m/s to 1.75 m/s, we found that the range of hip angles in our subjects during walking increased by approx◦ imately 10 , while the location of maximum ankle plantarflexion shifted slightly earlier in the gait cycle.
Approach	We further define a swing initiation state within the stance phase, and a stance preparation state within the swing phase, where control laws for a subset of MTUs are modified ( Figure 4 ).
Approach	Initializing with the normal controller, we then optimized for a 1.0 m/s slow walk controller (swalk) and a 1.5 m/s fast walk controller (fwalk).
Background	In living humans and animals, metabolic energy expenditure can be estimated by oxygen consumption.
Approach	During double stance, these control laws are only active for the leading leg, denoted as u Θ m lead .
Approach	Our control laws for the actuators are based on the muscle-reflex controller introduced by Geyer and Herr [2010].
Approach	As the heel loses ground contact in late stance, the same muscle activation rapidly shortens the fiber length, which reduces force output and the activation through u F GAS .
Approach	We have added the rectus femoris since we found that it improves the walking knee flexion profile during swing when compared to human data.
Outcome	In this work we are particularly interested in comparing our results to the mean and standard deviation curves for the sagittal hip, knee, and ankle joints for multiple subjects over multiple walking and running speeds.
Approach	Specifically, control torques for the hip, knee, and ankle joint DOFs in the sagittal plane—key DOFs for gait analysis [Perry and Burnfield 2010]—are exclusively generated by eight MTUs in each leg.
Approach	Each muscle has an initial constant excitation, or pre-stimulation value p m .
Approach	The tasks include moving the COM forward at a target velocity while not falling down for 10 seconds, and maintaining head stability and upper body orientation.
Outcome	For higher speeds, the maximum knee flexion angle is lower than human data, and the location of maximum ankle plantarflexion occurs earlier in the gait cycle.
Approach	Additionally, we set the toe joint to be a spring with spring constant of 30 Nm/rad, target angle 0, and no damping.
Approach	The leg motion relies significantly on passive dynamics during the swing phase [Collins et al. 2005], as most muscles are only excited at low levels.
Approach	From the original model, we adjust the lower-body joint locations and mass distributions to better match human data [Hamner et al. 2010].
Approach	The dynamics is modeled by a first-order differential equation [Zajac 1989; Geyer et al. 2003], which can be integrated by a t+1 = 100h(u t − a t ) + a t , where h is the stepsize (1/2400 s) and a t and u t are the muscle activation and excitation values at the t-th timestep.
Outcome	An important advantage of optimization over hand-tuning is the ability to create controllers based on high-level objectives such as walking speed.
Approach	As to be discussed in Section 4.1, the nonlinearity introduced by these relations is crucial for how simple control laws for muscle excitation can lead to complex force and torque trajectories.
Challenge	In this work, we have chosen to focus on reproducing humanlike kinematics and torque trajectories.
Approach	In addition, soft joint limit torques as defined by Geyer and Herr [2010] are applied to these DOFs.
Approach	The biarticular MTUs ( Figure 1c ) supply torques to two joints simultaneously.
Challenge	Perhaps more importantly, controllers relying on hand-tuned trajectories cannot be easily used to investigate how the control strategies change with respect to new constraints.
Approach	For the upper body and the remaining DOFs in the lower body, we rely on a pose-graph controller [Yin et al. 2007].
Outcome	The main contribution to our effort measurement is the total rate of metabolic energy expenditure ( E)  ̇ over all MTUs.
Approach	In particular, given the length and velocity of CE (l CE , v CE ), as well as the current muscle activation level (a), we can compute the MTU force (F MTU ) as follows: F MTU = F CE + F PE , F CE = aF 0 f l ( ̃ l CE )f v ( v CE ), where  ̃ l CE = l CE /l opt and v CE = v CE /l opt .
Outcome	These controllers chose to walk in a stiff crouch gait, with lowered COM and a constantly dorsiflexed ankle to ensure foot clearance (see accompanying video).
Approach	We include the hamstring (HAM), which extends the hip and flexes the knee, the rectus femoris (RF), which flexes the hip and extends the knee, and the gastrocnemius (GAS), which flexes the knee and plantarflexes the ankle.
Approach	The muscle activation heat rate models the rate of energy that is converted to heat by a muscle given a certain level of activation, and is a function of both the mass of the muscle and the excitation signal.
Outcome	The gait resulting from torque minimization exhibits too much knee flexion during the swing phase and too much dorsiflexion before heel-strike.
Approach	We optimize control parameters and the initial state using Covariance Matrix Adaptation (CMA) [Hansen 2006], with stepsize σ = 0.005 and 50 samples per iteration.
Approach	For quantitative evaluation, we collected experimental ground truth data from 20 human subjects walking and running at eight speeds on an instrumented treadmill.
Approach	The conversion does not occur instantaneously and is referred to as activation dynamics.
Approach	A simple objective that could approximate effort given a musculoskeletal model is the sum of squared muscle activations, which is commonly used in static optimization—a technique for recovering activations given motion capture and force plate data [Anderson 1999].
Approach	The control laws map time-delayed features of the body to muscle excitation signals.
Approach	We found that more human-like arm swing can be generated by relating the elbow and shoulder target angles as θ s l = α arm θ h l − θ h r + βθ e d and φ l s = γθ e d , where θ s l and φ l s are the shoulder angles in the sagittal and transverse planes, respectively; θ h l and θ h r are the current left and right sagittal hip angles; θ e d is the desired elbow angle, β, γ are constants chosen based on human motion data (see supplemental material), and α arm is a scale constant that determines the magnitude of the arm swing.
Outcome	Through comparisons to kinematic and torque data of human walking, we show that our results adopt a human-like torque generation strategy while producing kinematic data significantly closer to humans than previous work.
Background	1 Examining differences in torque generation, we can see that the controller presented by Coros et al. [2009] does not employ a human-like torque distribution between the joints ( Figure 6b ).
Approach	The tibialis anterior (TA) and the soleus (SOL) generate dorsiflexion and plantarflexion torques at the ankle, respectively.
Outcome	Note that 100 N is approximately the weight of a 10 kg object, a significant push to a human.
Background	Such models have been used in facial animation [Waters 1987; Lee et al. 1995; Sifakis et al. 2005], simulation of the human hand [Sueda et al. 2008], neck [Lee and Terzopoulos 2006], torso [Zordan et al. 2006], and the complete upper body [Lee et al. 2009].
Approach	The HFL introduces a hip flexion torque through a length feedback, which is suppressed when the HAM is stretched in during late swing.
Outcome	Our controller architecture and objective function is not limited or specific to walking alone.
Approach	Our upper body control also largely follows Wang et al. [2010], with the exception that the target feature of our back joint in the coronal plane is the global orientation of the torso instead of the local joint angle between the torso and the pelvis.
Approach	The main exceptions are the TA, which maintains the length feedback (u L TA ) to avoid toestubbing, and the HAM, which is activated at late swing phase to prevent the knee from being overextended before landing.
Background	Knee angles lack flexion during swing, but lack extension at heelstrike.
Background	Similar 2D models have been used for gait prediction [Ackermann and van den Bogert 2010], and to generate human-like responses to disturbances [Murai and Yamane 2011].
Approach	Two main differences between our stance phase control laws compared to Geyer and Herr [2010] lie in how the swing initiation state functions.
Background	For example, energy minimization has been suggested as the criterion for humans in determining step length given walking speed [Kuo 2001], as well as in selecting between walking and running [Srinivasan and Ruina 2006].
Approach	The TA ensures foot clearance during swing using a length feedback (u L TA ), but the activation is suppressed during stance in proportion to the current force generated from SOL.
Outcome	In the accompanying video, we show that our optimization indeed results in a mild hyperextension gait after weakening HAM to a quarter of its original strength, with a mini◦ mum knee flexion angle of 2 .
Approach	We chose to focus on generating human-like locomotion in a straight line and on flat ground.
Outcome	While noticeable kinematic differences are seen in the gaits produced by different objectives, the torque curves are smooth due to the muscle model and the control parameterization.
Outcome	As we have touched on in Section 6.2, our approach can be used to develop predictive biomechanical models to investigate the effects of muscle and control properties on gait.
Approach	These values are initialized close to zero, but are then optimized.
Background	However, these biomechanical simulations only recovered muscle activation trajectories, and did not produce locomotion controllers that can function beyond the duration of input data.
Approach	We can see that u GAS F produces a positive feedback during mid-stance, when the muscle activation does not produce a significant change in muscle fiber length, as the foot is planted on the ground.
Approach	The braces sign is positive if torque generated by m is in the opposing direction of θ—e.g., if m is the hip extensor and θ is the hip flexion angle—and negative otherwise.
Background	Simulation studies on detailed 3D musculoskeletal models have been employed to understand muscle functions during locomotion tasks [Anderson and Pandy 2001; Liu et al. 2008; Hamner et al. 2010].
Outcome	Optimizing without activation dynamics and with ∆t m = 0 for all MTUs results in a solution where ankle torques build up too quickly in the stance phase, leading to shorter step-lengths compared to human data.
Challenge	For example, how would the character’s motion style change given a physical disability?
Approach	We initialize walking parameters of the MTU control laws based on hand-tuned values for 2D walking from Geyer and Herr [2010].
Approach	The choice of muscles is based on the planar model proposed by Geyer and Herr [2010].
FutureWork	One clear aspect for improvement is to adopt a more physically-accurate simulation engine [Sherman et al. 2011], as ODE “emphasizes speed and stability over physical accuracy” [Smith 2006].
Approach	u L m is most useful during the swing phase, as the TA must be activated to dorsiflex so that toe-stubbing can be avoided.
Approach	We fix the spring and damper constants for all arm joints to 30 Nm/rad and 3 Nms/rad, respectively, with target angles set to 0.
FutureWork	Finally, an exciting area for future work is to automatically synthesize locomotion controllers for more detailed, fully muscle-actuated human models [Weinstein et al. 2008; Lee et al. 2009].
Approach	We compute the mean standard score against human data over 100 evenly spaced points on the curves.
Challenge	In contrast, it is less clear how metabolic energy expenditure should be modeled for simulated characters.
Outcome	Our work demonstrates the importance of modeling constraints on torque generation due to muscle physiology, both in restricting the space of possible torque trajectories and in providing a realistic model of effort.
Approach	The reward is defined as the negative sum of a number of task terms (i.e., r(s t ) = − i K i (s t )), which can be thought of as high-priority goals that the controller must satisfy while minimizing effort.
Approach	Body features include MTU force, fiber length, joint angle, and segment orientation.
Background	The feature-based controller of Mordatch et al. [2010] is robust and flexible, but their basic walking gait shows an obvious crouch.
Approach	Intuitively, f l models the fact that muscles can generate force more efficiently near l opt , and f v captures how the muscle loses its ability to generate force as the contraction velocity increases [Zajac 1989].
Outcome	We show how their basic ideas can be embedded in a 3D humanoid model and extended to running.
Approach	The only free parameter is a positive gain constant G m , which is different for each MTU.
Background	On the other hand, state-of-the-art bipedal locomotion control methods directly output joint torques, which ignore constraints and energetic costs imposed by muscle anatomy and physiology.
Approach	As F  ̃ m MTU starts to decrease due to muscle physiology, u F m starts to decrease as well.
Challenge	While many sets of parameters are capable of achieving this task, the quality of the resulting motion varies significantly among them.
Challenge	Consequently, to accomplish a motion task, controllers often employ torque patterns that are inefficient or even impossible for humans.
Background	A common substitute is the sum of squared joint torques [Schultz and Mombaur 2010], which does not account for the different effort levels required to generate torques in different joints, directions, and body configurations.
Approach	The joint torques generated by a given MTU is a function of the current body configuration.
Background	While these methods were shown to produce gaits for a variety of characters and environmental conditions, they do not employ realistic effort measures or biologicallyplausible control torques.
Approach	This global target allows our model to better keep the head upright during locomotion.
Outcome	We found that weakening the VAS to one-tenth of its original strength leads to a motion similar to quadriceps avoidance gait, which is seen in patients with quadriceps weakness and anterior cruciate ligament (ACL) deficiency [Timoney et al. 1993].
Approach	The PD-control laws are employed by the hip muscles during the stance phase to maintain the global upper body orientation, as well as during stance preparation to prepare for ground contact.
Approach	These mappings serve as building blocks for the control laws, and we discuss each in turn in this section.
Approach	We demonstrate the presented approach by optimizing locomotion controllers for a wide range of speeds.
Background	While locomotion controllers discussed above all operate on joint-actuated models, musculoskeletal models have also been investigated in computer graphics.
Outcome	However, we can still follow Wang et al. [2010] and optimize explicitly for controllers that can deal with external forces.
Background	” As discussed by Wang et al. [2009], the original SIMBICON-style controllers tend to produce gaits lacking hip extension with a constant foot orientation.
Outcome	However, as demonstrated in the accompanying video, this objective also does not lead to faithful walking kinematics.
Background	While more human-like ankle motions have been produced, differences in the hip and knee angles persist ( Figure 6a ).
Background	The crouch gait is commonly found in cerebral palsy patients, and weakness in the plantarflexors is one of many factors thought to contribute to the gait abnormality [Steele et al. 2010].
Background	In contrast, previous optimization-based control synthesis methods required including torque ratios specific to walking as part of the objective [Wang et al. 2009] or adding spring elements for running [Wu and Popović 2010].
Approach	Specifically, A  ̇ = mass · f A (u) and M  ̇ = mass · g(  ̃ l CE )f M (a), where mass is the muscle mass and  ̃ l CE is the normalized muscle fiber length.
Approach	We use 100 samples per iteration and a 0.25 m/s optimization increment for speeds over 4.0 m/s.
Outcome	While the total amount of activations is reduced, the resulting gait walks in a crouch and relies heavily on the knee.
Approach	Controllers optimized for each of the two objectives (nwalk, min torque) are demonstrated in the accompanying video.
Approach	We acquired kinematics and dynamics data for a range of walking and running speeds (from 1.0 m/s to 5.0 m/s).
Approach	There are 56 parameters in total (30 stance, 26 swing) for the MTU control laws.
Challenge	The goal of our work is to enhance the realism of locomotion gaits exhibited by physically-simulated humanoids without dependence on motion capture data.
Approach	Instead, we acquired our own ground truth data using an instrumented treadmill with 20 subjects.
Approach	Second, we found it unnecessary to modulate the muscle-driven PD-control laws in the hip by ground reaction forces.
Approach	Our unified approach to both walking and running is consistent with the view that humans select between walking and running by minimizing energy at different speeds [Srinivasan and Ruina 2006].
Outcome	Our result suggests that under the condition of weakened plantarflexors, the mild crouch gait may be metabolically efficient compared to other gait choices.
Approach	The overall effort of a particular motion is defined as J effort = w M J M + w R J R + w L J L , a weighted sum between the terms.
Approach	The parameters of these functions are optimized to yield gaits that move the character forward without falling down.
Background	More nuanced objectives can be learned from inverse optimization [Liu et al. 2005], but are dependent on training data.
Outcome	We demonstrate significantly more human-like kinematic and torque trajectories and show that the same control parameterization and effort objective produce both walking and running.
Approach	In contrast, our approach is to actuate key DOFs using Hill-type MTUs and to measure effort based on metabolic energy expenditure.
Approach	We simulate for T = 24000 timesteps (10 s) in each evaluation.
Outcome	More pronounced differences are present between running data at different speeds.
Outcome	We found that weakening the GAS and SOL to a quarter of their original strength, while keeping all other objectives identical (target speed 1.25 m/s), results in a mild crouch gait characterized by excessive knee flexion (see accompanying video).
Approach	f l and f v are the force-length and force-velocity curves (Figure 3).
Outcome	We show that the use of biologically-based actuators and objectives measurably increases the realism of gaits generated by locomotion controllers that operate without the use of motion capture data, and that metabolic energy expenditure provides a simple and unifying measurement of effort that can be used for both walking and running control optimization.
Outcome	Supplemental figures indicate that our kinematic patterns generally agree with data over a range of speeds and especially at lower speeds.
Challenge	One likely cause of these differences is the control force generation mechanism.
Outcome	In contrast, the metabolic energy objective captures the fact that activating and maintaining contraction of TA generates significant heat and should therefore be discouraged.
Approach	In practice, these terms are weighed more heavily than the effort term.
Background	In turn, controllers from Wang et al. [2010] generated larger amounts of ankle torque by optimizing for a human-like torque ratio, but did not come close to matching the shapes of human torque data.
Outcome	Controllers optimized using the torque and activation objectives both exhibit large errors compared to nwalk, especially at the ankle joint.
Approach	However, unlike the standard PD-controller, muscles can only activate after a time-delay and each muscle can only generate forces to rotate the angular DOF in one direction.
Approach	The GLU, HFL, and VAS work to guide the hip and knee joints toward a desired pose to prepare for ground contact: u VAS = q VAS + u VAS θ k , u GLU = q GLU + u θ GLU h , u HFL = q HFL + u θ HFL h .
Outcome	In the gait produced by the controller that minimizes this objective (min act), activations from the GAS/SOL are significantly lowered, while activations from VAS are increased.
Approach	A step-response graph for the activation dynamics, as well as details on the l CE and v CE computations (contraction dynamics) are given in the supplemental material.
Challenge	We present a technique for automatically synthesizing walking and running controllers for physically-simulated 3D humanoid characters.
Approach	We compare running motions generated by our controller at 4.0 m/s with human running data in Figure 7 .
Approach	The rest of the DOFs are controlled using standard joint-space PDcontrollers with state-dependent parameters.
Approach	Human joint moment (torque) curves during locomotion can be computed from motion capture and ground reaction force data.
Approach	We found the addition of the stance preparation state to be important for discovering running gaits.
Approach	The simulations were implemented using Open Dynamics Engine (ODE) with a frequency of 2400 Hz.
Challenge	For example, physics-based walking controllers that do not rely on motion capture data commonly produce walking motion with exaggerated hip flexion which appears more crouched and less fluid than typical human walking.
Background	More recent controllers improve motions by designing better target trajectories in joint or feature space [Coros et al. 2009; Coros et al. 2010; de Lasa et al. 2010].
Approach	Note that Θ d is the same as the target angle in u Θ HFL .
Approach	The computation of F PE and the analytic forms of f l and f v are described in the supplemental material.
Approach	The controller outputs neural excitation signals (u), which are converted to muscle activations (a).
Background	Biological control systems output neural excitation signals, which then generate musculotendon forces that lead to joint torques.
Approach	Unlike previous work, where the model is actuated by setting torques to all joints, we use a model that is partially actuated by Hill-type MTUs ( Figure 1 ).
Approach	The coronal swing hip target angles follow the same feedback law as θ h .
FutureWork	However, more scientific validation of our simulation results is needed before we can conclude that our results apply to real humans.
Background	The development of physics-based locomotion controllers de novo, independent from stock motion data, has been a long-standing objective in computer graphics research and has seen resurgence in recent years.
Outcome	Note that we found time-delays to be important for generating human-like motion given our control model.
Approach	The dependence on muscle mass captures the fact that while larger muscles are generally capable of generating more force, they are also more costly to use.
Approach	We use cylinders to approximate the heel and ball of the foot, which allows for some amount of foot rolling after heel-strike.
Approach	A 1.75 m/s very fast walk controller (vfwalk) is optimized by initializing from fwalk.
Outcome	By simply changing the target velocity and initialization (changing the initial velocity from 1.3 m/s to 3.05 m/s, doubling the initial force feedback gains for GAS and SOL, and bending the elbow), the same procedure yields running controllers, without any modifications to the control parameterization.
Outcome	The result is a locomotion control optimization procedure that minimizes a physiologically-based objective within a parameter space restricted to biologically plausible torque patterns.
Background	While such data for walking is readily available [Perry and Burnfield 2010], only scattered data are available for running [Novacheck 1998; Yokozawa et al. 2007; Hamner et al. 2010].
Approach	Note that unlike in previous work, we did not need to include human-like speed to step-length ratio and minimal angular momentum about the COM as task terms.
Outcome	Note that our results show the lowest average standard score for all speeds.
FutureWork	More accurate simulations and detailed models present additional computational challenges both in simulation speed and in parameter optimization, but are crucial for potential scientific and medical applications.
Approach	The forms of f A , f M , and g are described in the supplemental material.
Background	One important recent contribution is SIMBICON [Yin et al. 2007], a remarkably robust 3D humanoid locomotion controller based on the balance control of Raibert and Hodgins [1991].
Outcome	All angle and moment curves shown are averaged over multiple cycles.
Approach	Much like the standard torquebased PD-controller, the muscle-driven PD control aims to adjust θ towards the target angle θ m while damping its velocity.
Challenge	These biologically implausible torque patterns diminish the naturalness of the resulting gaits.
Approach	To produce gaits that have a high degree of realism, we employ an objective based on minimization of metabolic energy expenditure, thus choosing the most effortless gait that achieves the task [Alexander 2003].
Outcome	Two main discrepancies are the timing of knee flexion during stance, and ankle dorsiflexion before heel-strike.
Approach	Conceptually, the contractile element (CE) models muscle fibers that can actively generate force (F CE ) depending on the current activation level (a).
Approach	An optimized controller can be simulated at interactive rates using standard hardware.
Approach	A single desired hip target angle (θ h ) is adjusted according to the SIMBICON balance feedback law [Yin et al. 2007] and is shared by both the GLU and HFL.
Approach	The suppression allows the generated TA activation patterns to better match human data during locomotion.
Approach	Instead, the responsibility to maintain upper body orientation is always assigned to the lead leg.
Approach	Positive length feedback is defined as          u m L = G m  ̃ l m CE (t − ∆t m ) − H m , + where  ̃ l m CE (t − ∆t m ) is the length of the muscle fiber normalized by the l m opt with a time-delay of ∆t m .
Outcome	Furthermore, we show that by simply changing the initialization and target velocity, the same optimization procedure leads to running controllers.
Background	Impressive results have also been achieved by controllers based on tracking motion capture data [da Silva et al. 2008; Muico et al. 2009; Kwon and Hodgins 2010; Lee et al. 2010; Ye and Liu 2010].
Outcome	The faster running results are optimized sequentially in 0.5 m/s increments (e.g., 4.0 m/s initialized from 3.5 m/s).
Challenge	However, as with methods that tune joint trajectories or controller parameters by hand, motion capture driven controllers have a limited ability to predict changes in gait.
Outcome	In the supplemental material and the video, we include results for running at speeds ranging from 3.0 m/s to 5.0 m/s.
Approach	To actuate these muscles, we define biologically-motivated control functions that map the current state of the body (joint angles, muscle fiber lengths, etc.) to excitation signals.
Approach	We also define a muscle-driven PD control law with respect to an angular feature θ as where K m , D m , θ m are free parameters of the PD-controller.
Outcome	A main discrepancy is that our hip and knee joints both reach maximum extension earlier than human running data.
Approach	The parameters of these control laws are set by an optimization procedure that satisfies a number of locomotion task terms while minimizing a biological model of metabolic energy expenditure.
Approach	Depending on the input feature, three different mappings are defined: positive force feedback, positive length feedback, and muscle-driven proportional derivative (PD) control.
FutureWork	A natural extension is to investigate whether our control parameterization and effort term can be combined with the popular task-space controllers [Coros et al. 2010; de Lasa et al. 2010; Wu and Popović 2010] and higher-level planning [Coros et al. 2009; Mordatch et al. 2010] to create humanlike motions on uneven terrains [Wu and Popović 2010] or obstacle courses [Mordatch et al. 2010; Ye and Liu 2010]—scenarios that have only been addressed using purely joint-actuated characters.
Outcome	Our work demonstrates that measurable increase in locomotion realism can be produced by employing musculotendon actuators for a small subset of the body DOFs.
Approach	We similarly define J L to penalize the average sum of squared soft joint limit torques for the hip, knee, and ankle joints, specified in Geyer and Herr [2010].
Outcome	Note that unlike dorsiflexion torques, large ankle plantarflexion torques can be generated with relative ease.
Approach	We define the average rate of metabolic expenditure due to MTUs as where B  ̇ is the basal metabolic energy rate, set to 1.51 times body mass [Anderson 1999].
Outcome	Our knee extension torque reaches maximum earlier than human data, which can cause the knee to extend too quickly during the stance phase.
Approach	The rate of metabolic energy expenditure for a given muscle can be modeled as the sum of heat released and mechanical work done by the muscle: E  ̇ = A  ̇ + M  ̇ + S  ̇ + W,  ̇ where A  ̇ is the muscle activation heat rate, M  ̇ is the muscle maintenance heat rate, S  ̇ is the muscle shortening heat rate, and W  ̇ is the positive mechanical work rate.
Outcome	As the target velocity increases, finding a satisfactory local minimum appears more difficult.
Approach	The positive length feedback effectively models a stretch reflex, which activates the muscle when the fiber is stretched beyond a fixed length.
Outcome	An obvious artifact of all controllers from Wang et al. [2010] is the excessive plantarflexion in the early swing phase, which is not present in our result.
Approach	The time-delay (∆t) models the time for neural signal propagation, set to 5 ms for MTUs connected to the hip, 20 ms for MTUs connected to the ankle, 10 ms for the VAS and ground contact [Geyer and Herr 2010].
Approach	The supplemental material includes angle and moment plots for all speeds, as well as details on our data collection.
Approach	We first optimized for a normal walking controller (referred to below as nwalk) with a target velocity of 1.25 m/s, which is approx- imately the human self-selected walking speed.
Approach	Our 3D humanoid model has 30 joint DOFs and mass distributions approximating a 180 cm, 70 kg male [Wang et al. 2010].
Approach	Let E  ̇ m,t denote the rate of metabolic energy expenditure computed for MTU m at timestep t.
Approach	Given MTU m, the positive force feedback law is defined as u F m = G m F  ̃ m MTU (t − ∆t m ),          where F  ̃ m MTU (t − ∆t m ) is the MTU force normalized by F m 0 with a time-delay of ∆t m .
Approach	For this comparison, we use a target speed of 1.25 m/s, which is the same as nwalk.
Approach	In addition, the HFL relies on length feedback to generate hip flexion torque during early swing, especially during running.
Background	Alternatively, de novo controller optimization has been used to capture features of human walking [Wang et al. 2009; Wang et al. 2010].
Approach	The difference is that F MTU is the net force (both active and passive) produced in the MTU, while F CE is only the active force.
Outcome	Similar to our walking results, our knee joint flexes less during the stance phase compared to humans.
Approach	The SOL and GAS both rely on positive force feedback and are the main sources of torque during walking.
Approach	For running, we double the initial gain parameters of GAS and SOL, and initialize θ e d to set the elbow in a bent position.
Approach	The hip joint is extended by the gluteal muscles (GLU) and flexed by the hip flexor muscles (HFL), while the knee joint is extended by the vasti (VAS).
Approach	Using muscle-driven PD control laws, the HAM, GLU, and HFL are responsible for maintaining the global orientation of the upper body (Θ), defined as the vector between the COM of the upper body and the COM of the pelvis projected onto the sagittal plane.
Approach	MTUs attached to the hip are assumed to have a constant moment arm: τ = r j F MTU .
Approach	The total lower extremity joint torques in the sagittal plane are obtained by summing over contributions from all relevant muscles:
Approach	M is the set of all sixteen muscles defined in the model.
Approach	The force feedback on the VAS creates a strong knee extension torque following ground contact, but excitation is suppressed when the knee flexion angle (θ k ) is extended below an offset (θ k off ) with an extension velocity ( θ  ̇ k < 0).
Approach	G m and H m are free positive parameters and {} ± means only positive or negative values (0 otherwise).
Approach	Additionally, torques generated by the PD-controllers in the rest of the DOFs are penalized by the average sum of torque squared objective: T 1 2 J R = τ j,t , T t=1 j∈Q r where Q r is the set of all joint DOFs except for the sagittal hips, knees, and ankles.
Approach	To quantify E,  ̇ we implement a model described by Anderson [1999], which is later expanded by Bhargava et al. [2004].
Approach	The balance feedback law allows robust control strategies to be found in difficult environments (e.g., being pushed by random forces).
Outcome	Our running kinematic results do not match human data as well as walking, though the basic features of the curves are still present.
Outcome	A major artifact from all of the previous works is the lack of hip extension during mid-gait, which does not occur in our result.
Approach	We employ a Hill-type model [Zajac 1989], where each MTU consists of three elements: contractile, parallel-elastic, and serialelastic.
Background	The plantarflexors (GAS and SOL) are largely responsible for forward propulsion in normal walking [Liu et al. 2008].
Outcome	Another cause of knee hyperextension is weakened quadriceps, which can be simulated by weakening the VAS in our model.
Approach	When combined with 33 free parameters describing the initial state of the simulation, 124 parameters (w) fully define a simulated motion {s 1 . . . s T } over T timesteps.

Approach	Secondly, particles near the surface may leave gaps when they spread out quickly.
Approach	A second, less obvious implication of the smaller linear system is that it effectively prevents artifacts known as locking.
Approach	To avoid the creation of holes, we temporarily reassign each particle’s radius: r i temp = max(r i , −kφ i ) where φ i is the particle’s stored level set value from the previous time step, and k is a constant set to 0.75 in our simulations.
FutureWork	In the future we would like to optimize the surface computation.
Approach	We construct them on the fly when a sample is requested from one of the original cells.
Approach	Usually, this means computing a pressure value for nodes outside of the liquid so that a linear interpolation along an edge of a cell gives zero at the correct position [Enright et al. 2005; Lew and Buscaglia 2008].
Approach	It consists of a m×n matrix, computing a per-tetrahedron gradient from nodal values.
Outcome	Just to illustrate the amount of detail in this setup – our adaptive version initially used 1.7 million particles, while a regular sampling at the finest resolution would have required roughly 400 million.
Outcome	The large open region is successfully coarsened by our sizing function, resulting in subtle wave motions around the splashes.
Outcome	Here the computational resources are focused on the visible region of a rotating camera, as the liquid splashes around a U-shaped corridor.
Approach	This means that for our discretization, the ghost pressure coefficients θ n are given by the tetrahedron’s matrix entries from Eq.10.
Approach	Considering two pressure samples along an edge, we’ll denote values inside the air with a G subscript, and values inside the liquid with an L subscript in the following.
Approach	As a result, we are allowed to aggressively remesh the tetrahedral background grid without worrying about excessive damping or re-sampling artifacts.
Approach	In line with the traditional ghost fluid method, we define p G uniquely for each tetrahedron.
Approach	For particles near the interface, this pulling force acts in addition to the position correction.
Approach	The new particle’s position is equal to the weighted average of all nearby midpoints: x new = ω i m i / ω i .
Outcome	In this way, we can resolve the detailed flow of liquid through the holes in the obstacle.
Background	The Marker-And-Cell (MAC) approach [Harlow and Welch 1965], which stores velocity components at cell faces and pressure samples at cell centers, results in discretizations with good properties in terms of stability and accuracy.
Approach	The graded BCC tetrahedra, on the other hand, can be of lower quality and can require the use of Eq.
Challenge	The main idea is to approximate the fluid surface with the union of the convex hulls of each triplet of nearby particles close to the surface.
Outcome	The per-frame time is low at the beginning and end of the simulation, but strongly peaks during the complex splash in its middle.
Approach	Note that for p i that are not inside of the liquid, we set w i = 0.
Challenge	The aim of our method is to solve the Navier-Stokes equations, which for incompressible, Newtonian, inviscid flows can be written as ρDu/Dt = − p + f , with the additional constraint · u = 0 to enforce a divergence-free velocity field.
Approach	For a Cartesian MAC grid, the ghost pressure value p G is given by p G = p L φ G /φ L .
Approach	Although we cannot prove that a local configuration over-constraining the velocities will never occur, the larger number of degrees of freedom for our velocities effectively prevents locking artifacts, and we have not encountered any in our tests.
Approach	In line with finite element methods using linear elements, we define the gradient based on the partial derivatives of the barycentric interpolation.
Approach	The [ ] T [ ] matrix-matrix multiplication results in a square n × n matrix, which is symmetric and positive definite.
Background	Both of these approaches discretize velocities with per-face flux values, while we store velocity vectors at cell barycenters.
Challenge	In this section, we introduce a new strategy for computing an implicit surface from a set of particles of various sizes.
Outcome	We have additionally presented a novel surface creation method that yields smooth surfaces in the presence of strongly varying particle radii, which turned out to be an important building block for our framework.
Background	One approach that is commonly used is to compute a signed distance function with averaged particle radii and centroids [Zhu and Bridson 2005].
Outcome	Our fluid simulator works well with spatially adaptive tetrahedral meshes, but it is another question to decide exactly how these adaptive meshes should be generated.
Approach	Note that a full sampling of the initial configuration with a regular grid would have required approximately 6 million particles.
Outcome	Our simulations perform quite well for large differences in resolutions, but we have only been able to push them to a certain point in our current implementation.
Approach	We solve this system analytically by first finding the line of common intersection of the first three equations, and then intersecting this line with the cylinder represented by the final equation.
Approach	For this setup, resolutions from 8 to 256 were used, resulting in 6 levels of adaptivity.
Approach	We also introduce two special behaviors when the particles are close to the liquid surface (less than a distance of six times the particle radius).
Approach	More specifically, for k = 1 this yields full second-order accuracy, while for badly shaped tetrahedra the resulting k = 0 means that we revert to the standard rounding strategy of a first order accurate method.
Approach	More specifically, by those for the vertex that is located outside of the liquid, i.e., α, β and γ.
Background	Finite volume methods [Batty et al. 2010] repair these spatial artifacts at the expense of solving a significantly larger system of equations and sacrificing computational stability near poorly-shaped elements.
Approach	We next derive second-order Dirichlet boundary conditions consistent with our discretization to benefit from the subtle surface dynamics associated with an accurate pressure solve.
Approach	We check whether the ghost fluid boundary conditions would violate diagonal dominance of an equation in our linear system.
Background	Both methods primarily target particles with constant radius.
Approach	As the rank of top three rows of the matrix is 2, we can drop one of them.
Outcome	This is partly due to the fact that it is a mostly serial operation that is difficult to parallelize (most other steps of our algorithm parallelize easily).
Outcome	The particle velocity update of line 12 uses barycentric interpolations as explained in Section 3.
Approach	Numerical viscosity in fluid simulations is tightly coupled to the spatial resolution resolving the flow.
Approach	Note that by assuming a piece-wise constant velocity and a linear change of pressure within a cell, this setup results in a constant pressure gradient per tetrahedron, by construction.
Approach	To evaluate the basis of our adaptive model without any influence of the camera dependent sizing function, we have simulated the simple geometric configuration shown in Figure 3 .
Approach	Our method achieves adaptivity by varying the mesh resolution over the computational domain.
Approach	If a particle is too small, then we merge it with its nearest neighboring particle, resulting in a particle whose radius is given by the combined volume of the two original particles.
Approach	That means the values w n are determined by those of the θ n coefficients, which we will compute in the following.
Approach	Our method, by construction, has more degrees of freedom for representing velocity fields than pressure fields.
Approach	Intuitively, the first three equations ensure that the plane is the right distance away from each particle with the normal facing away from them, and the final equation ensures that the plane equation is normalized to a distance function.
Approach	Having the information from the sizing functions ready, we create a new BCC mesh and perform particle merging and splitting.
Outcome	While we presented specific parameters for the sake of reproducibility, these values were not meticulously tuned and are certainly not optimal.
Approach	Note that these four smaller tetrahedra do not have to be stored explicitly.
Outcome	Concretely, the contributions of our work are: • a novel tetrahedral discretization of the pressure projection step that is efficient to solve and robust to poor-quality elements; • an accurate treatment of second-order boundary conditions within the tetrahedral mesh; • a new technique for extracting a smooth surface from particles with varying radii; • and the inclusion of a flexible sizing function to focus computational resources on important areas of the flow with minimal overhead.
Approach	In the beginning of each step (line 2), we typically compute the level-set for the current particle configuration as described in Section 5.
Outcome	In the graded region, this can result in two pressure samples from adjacent tetrahedra being placed at the exact same position.
Approach	The final surface creation is trivially parallelized, and takes around five minutes average per frame for all of our simulations.
Background	Both methods lead to an increased computational cost in comparison to the more efficient tetrahedral BCC meshes.
Approach	FLIP particles that partake in splashes and sprays can pose a significant burden on computational resources, especially in an adaptive framework like ours.
Approach	We investigate various methods for generating these adaptive meshes by experimenting with several sizing functions, allowing us to precisely dictate where simulation detail should occur.
Approach	A time step is completed by performing the pressure projection and advecting the particles in the resulting divergence-free velocity field.
Approach	If a given particle is bigger than the desired size, then the particle is split in two.
Outcome	These contributions work together to produce a practical fluid simulator that exhibits low computational and memory complexity, fewer visual artifacts, and a high effective simulation resolution.
Approach	To compute the spatially-varying background grid, we start with the Delaunay tetrahedralization of a set of points distributed in a body-centered cubic lattice configuration.
Background	Different methods have been proposed to circumvent these problems, e.g., using linear elements for pressure instead of piece-wise constant ones [Irving et al. 2007].
Approach	Theoretically, we know that such a small region with purely free-surface boundary conditions will yield zero internal forces, so we simply detect individual FLIP particles that have no neighbors within six times their radius, remove them from the pressure solve, and accelerate them with gravity instead.
Background	FLIP derives its success from the fact that it uses particles to compute an accurate, nondiffusive transport of flow quantities, in combination with a gridbased solve to accurately enforce constraints for mass conservation.
Approach	First, we impose the constraint that the position correction step may only move particles near the surface tangentially to the fluid interface.
Approach	We efficiently compute the distance to these planes by analytically solving the polynomial system: ax 1 +by 1 +cz 1 +d = r 1 , ax 2 +by 2 +cz 2 +d = r 2 , ax 3 + by 3 + cz 3 + d = r 3 , a 2 + b 2 + c 2 = 1 .
Approach	The reason is that our velocity samples are not in line with the direct connections of the pressure samples – they are not locally orthogonal to each other.
Background	One example is the work of Klingner et al. [Klingner et al. 2006] which demonstrated the use of a Stable Fluids based solver for tetrahedral grids conforming to object boundaries.
Background	The groundbreaking work of Losasso et al. [2004] introduced an octree for spatial adaptivity, but it suffers from spurious flows at T-junctions.
Approach	Instead of interpolating these averaged values directly (which would result in smeared out motion), we temporarily subdivide the cells of our mesh by inserting a vertex at the center where we have an accurate velocity sample.
Approach	Here the θ n are a set of barycentric coordinate coefficients such that θ 1 +θ 2 +θ 3 = 1, and a tilde superscript denotes a value interpolated with the barycentric weights.
FutureWork	Finally, we are highly interested in applying our method to other types of phenomena, such as smoke and fire simulations, or visco-elastic materials.
Approach	We combat these problems by directly manipulating particle positions.
Approach	Similar to [Batty et al. 2010], we generate a new tetrahedral mesh every ten time steps, instead of rebuilding the mesh on every consecutive step.
Outcome	Our method can simulate this setup very efficiently, and in a fully coupled manner with an effective high resolution.
Approach	The motion of the fluid is computed in a Lagrangian manner using particles, while the pressure projection step is computed on an Eulerian grid.
Outcome	We store the pressure variables on tetrahedral vertices, and there are far fewer vertices than tetrahedra in a given mesh.
Outcome	However, our implementation of their method exhibited slow convergence and the velocity artifacts despite this fix.
Approach	We evaluate the level set on each of the vertices of our adaptive BCC mesh, and we extract a triangle mesh using a marching tetrahedra algorithm.
Outcome	We compare our surface creation routine with a few existing methods in Figure 4 .
Approach	For the final visualization, we compute an especially highresolution BCC mesh from all of our particles and proceed with the algorithm above.
Approach	The algorithm still follows the general ideas of the Stable Fluid solver [Stam 1999], and can be readily combined with second-order treatment of free surface boundary conditions [Enright et al. 2003].
Approach	As we assume a linear change of the pressure for each cell, we can use simple barycentric interpolation to retrieve the pressure p at a position inside a cell.
Approach	Assuming, without loss of generality, that the first vertex is the one outside of the liquid volume, we embed the boundary condition into        M based on the w n coefficients.
Background	The work of [Adams et al. 2007] shares similarities with our approach, as it is able to simulate a wider range of particle radii, and it proposes a surface reconstruction method in the adaptive setting.
Approach	Instead, we have found the following approach to yield high speed and good accuracy: we first interpolate the centered velocities to the nodes, similar to [Chentanez et al. 2007].
Approach	For this, we modify the strategy of Ando et al. [2012] to work within our framework: at each remeshing step, we loop through the particles and determine whether the resolution needs to be changed.
Approach	In our method, a novel, robust discretization works together with accurate embedded boundary conditions and a flexible sizing function to allow for aggressive adaptivity and high computational performance.
Outcome	We also introduce a new method for computing an implicit surface from a set of particles.
Background	Thus, many works have proposed methods to focus the computations on regions that are of particular interest.
Approach	When these particles eventually enter the neighborhood of other particles at some point in the future, we resume treating them like fluid by returning them to the pressure solve.
Approach	With our BCC mesh, all regular BCC tetrahedra have very good quality and valid θ n values.
Background	Sin et al. [2009] proposed an alternative method for hybrid Lagrangian-Eulerian solvers which combines a Voronoi-based pressure solver and particles.
Outcome	We have presented a novel framework for highly adaptive liquid simulation.
Background	On the other hand, FLIP simulations have a well-known problem of creating noisy particle distributions, because there are typically several times more particles than velocity variables on the background grid.
Outcome	Consequently, the pressure solve has fewer variables and is faster to solve.
Outcome	The algorithm as described works perfectly for computing the level set outside of our particle surface, but it may lead to small gaps inside.
Approach	These methods are primarily suitable for uniformly sampled particles, and we will demonstrate in Section 7 that their placement of pressure samples at tetrahedral circumcenters leads to numerical problems in combination with graded BCC meshes.
Background	This approach, however, suffers from numerical diffusion and an inconsistent discretization near the tree’s T-junctions.
Background	Traditionally, Cartesian grids are very popular for fluid simulations.
Approach	In our case a regularization via PIC interpolation acts to diminish any highfrequency artifacts.
Approach	When enough time has passed to trigger an update of the mesh, it becomes necessary to evaluate the sizing function.
Approach	We then perform barycentric interpolation based on these subdivided cells, ensuring a C 0 continuous velocity that retains the original velocities at cell centers.
Background	Several useful methods for computing a surface from a collection of particles have been proposed in the past [Zhu and Bridson 2005; Adams et al. 2007; Yu and Turk 2010], but they tend to produce undesirably bumpy surfaces when considering particles of highly variable radii ( Figure 4 ).
Outcome	Occasionally, this can also lead to an overly strong weight for such particles during the velocity mapping, resulting in momentum artifacts.
Background	Using this Vornoi-based approach for tetrahedral meshes would yield a pressure matrix similar to ours.
Background	The FLIP algorithm is heavily used in the special effects industry, and recent advances have introduced accurate coupling with obstacles [Batty et al. 2007], highly viscous materials [Batty and Bridson 2008], and two-phase flows [Boyd and Bridson 2012].
Background	Although Cartesian grids are widely used, they are limited in their flexibility to adapt to a simulation setup.
Approach	Here, φ denotes a tolerance factor that we set to φ = 0.25.
Approach	Note that, theoretically, θ n could take any values as long as they add up to one.
Approach	Our simulator is versatile enough to cope with any of these sizing functions, resulting in efficient simulations with highly variable levels of detail.
Approach	To evaluate our final level set value, we compute the minimum signed distance from a query point to all nearby convex hulls.
Background	More recently, a level-set based method was proposed that computes a constrained optimization with bihar- monic smoothing [Bhattacharya et al. 2011].
Outcome	Without adaptivity, the large open liquid surface with complex splashes in a localized region would require huge amounts of computational resources.
Approach	Here we describe how to compute the ghost fluid coefficients θ n given the 4 × 4 pressure matrix entries of a single tetrahedron.
Approach	In this case, the resulting matrix is symmetric positivedefinite and can be easily inverted by the commonly used preconditioned conjugate gradient methods.
Approach	a, b, c, d are the variables defining our plane with the signed distance function ax + by + cz + d = 0.
Approach	We chose a BCC mesh generation because it is, to the best of our knowledge, the fastest way to generate high-quality meshes.
Background	In combination with a suitable method to discretize the problem at hand, they allow for very flexible computational grids.
Approach	We implement a similar step in our algorithm to overcome numerical problems resulting from badly shaped cells.
Approach	This decision allows us to avoid aggressively refining the tetrahedral mesh in locations where the physical motion is uninteresting.
Approach	Unlike these methods, we make use of a non-conforming grid with Body-Centered Cubic (BCC) lattices.
Approach	V (x, y) is a view-dependent function that returns the value y if x is within the camera’s visible region and returns the maximum particle radius r max (representing the minimum surface resolution) otherwise.
Approach	Similarly, κ solid (x) returns 1.6 W smooth (d solid , r max ) divided by the extrapolated curvature of the solid interface, where W smooth (x, h) is a smooth kernel function (1 − ||x|| 2 /h 2 ) 3 and d solid is the closest distance to the solid boundary.
Challenge	This paper aims to produce fluid simulations with a high degree of spatial adaptivity.
Approach	In contrast to previous work, our pressure solve is a linear system that has n degrees of freedom, n being the number of nodes in the tetrahedral mesh.
Outcome	These flat surfaces represent the equilibrium state of a fluid simulation, so our animations are able to smoothly settle down as time progresses.
Background	A variant of this approach, taking into account information about the spatial variance of the particle’s neighborhood was proposed by Yu et al. [2010].
Background	Clausen et al. [2013] and Misztal et al. [2010] have proposed a method to simulate liquids with a computational grid conforming to a triangulation of a liquid surface.
Approach	A small l shows more surface details, while a larger l tends to fill in small concavities.
Background	Another direction of research performs fluid simulations based on arbitrary elements.
Approach	Some examples are a surface curvature-based metric that adds detail only where needed on the fluid surface, a turbulence metric that adds detail only where interesting fluid motion occurs, and a visibility metric that adds detail only in front of a virtual camera.
Outcome	However, the lower number of pressure constraints also implies that the highest frequencies of the velocity field may be unconstrained.
Approach	Given a sizing function that indicates the desired spatial level of detail, our method first creates a tetrahedral mesh with varying spatial resolution, and then it locally changes the particle density by splitting and merging operations.
Approach	We have experimented with several different sizing functions depending on factors such as distance to a camera, distance to the liquid surface, curvature of the liquid surface, measures of fluid turbulence, and arbitrary analytical number fields.
Outcome	In this case, the whole simulation with 8 different octree levels and a maximum resolution of up to 1024 cells took on average only 4.6 minutes per frame to compute.
Approach	Thus, we do not worry about re-sampling data when computing a new tetrahedral mesh.
Challenge	Furthermore, many existing methods still are not truly spatially adaptive in the sense that their computational complexity is still tied to a uniform grid or spatial parameter.
Approach	Our FLIP simulation performs computation on both a background volumetric mesh and on a set of particles.
Outcome	Most previous algorithms perform poorly in this comparison because they were not designed for particles with varying radii.
Outcome	One comparison that is particularly interesting is the one comparing our method to an FVM based simulation.
Approach	In order to make the mesh resolution change over space, we use the octree-based grading method which was proposed by Labelle and Shewchuk [2007] and later adopted in several adaptive simulation environments [Chentanez et al. 2007; Wojtan and Turk 2008; Batty et al. 2010].
Approach	Note that this scaling does not break the symmetry of the resulting linear system.
Approach	Only a small percentage of the particles are simulated in this way, e.g., 1.7% on average for Figure 6 .
Approach	Also, we must take care to ensure that particles close to the surface do not introduce interfacial bumps when they split or merge; whenever we create a new particle that is less than 1.25 times its radius away from the surface (through either a split or a merge event), we move it in the surface normal direction such that its sphere lies exactly tangent to the liquid interface.
Approach	The κ solid component of our sizing function ensures that geometrically complex regions near the obstacle are simulated with higher accuracy.
Approach	Then we find the closest particle to each midpoint and store the squared distance as a weight ω i .
Challenge	Finally, we explore several new sizing functions for determining spatially adaptive simulation resolutions, and we show how to couple them to our simulator.
Approach	Here, u, p and f denote velocity, pressure and external forces, respectively, while D/Dt denotes the material derivative.
Approach	For the free surface, we have to ensure that the Dirichlet boundary condition p = 0 is satisfied at the interface position.
Approach	We require the distance to the surface in several steps of our algorithm, so we store the level set values for each particle (line 3).
Approach	At this point, additional user-defined sizing functions could be computed as well.
Approach	Next, we enable subtle free-surface phenomena by deriving novel second-order boundary conditions consistent with our discretization.
Approach	After a split or merge operation, the new particle’s velocity is computed using a volume-weighted average.
Background	Because of this, tetrahedral grids are popular for methods targeting adaptivity.
Background	Additionally, a robust and efficient method for adaptive SPH simulations was introduced by Solenthaler et al. [2011], but this work primarily targets the coupling of two different particle resolutions.
Approach	A direct implication of this smaller linear system is that it is faster to solve.
Approach	In all of the examples in this paper, the sizing function is defined as a combination of five different metrics:
Background	One example are octrees, which were used by Losasso et al. [2004; 2005] to refine the computational grid in a controllable way.
Background	Several other methods have been proposed to reconstruct smooth surfaces around collections of particles without orientation.
Approach	In the following, we denote the number of cells with m and the number of nodes with n, and we indicate discretized quantities with caret notation.
Outcome	Along the way, we provide a new method for generating a smooth and detailed surface from a set of particles with variable sizes.
Approach	In these cases we consider the tetrahedron to have a poor quality.
Approach	Thus, choosing a more restrictive basis for pressure, as in [Irving et al. 2007], or explicitly removing high-frequency information from the pressure [Misztal et al. 2010], reduces the chance of locking.
Approach	In our case, however, this approach does not yield the desired result.
Approach	We can extract two constraints for each θ n from this form, which, together with the barycentric coefficient constraint, give us a 3 × 3 matrix M that can be inverted analytically.
Background	Both methods, in contrast to ours, focus on static computational grids and are restricted to smaller differences in particle size.
Outcome	We introduce a combination of techniques that successfully makes adaptive fluid simulation practical at large scales.
Background	Like our method, Brochu et al. [2010] used this discretization in combination with embedded second-order boundary conditions.
Outcome	One major benefit of our method is that it can easily create perfectly flat surfaces from a mixture of differently-sized particles.
Outcome	The influence of the different components of our sizing function on the evolution of a simulation is difficult to depict with static images, so we refer to the accompanying video for a comparison.
Background	Targeting a similar direction as our work, Hong et al. [2009] and Ando et al. [2012] have demonstrated methods to adapt the resolution of FLIP particles in a simulation.
FutureWork	The task of choosing an ideal sizing function is still an open problem that we are interested in pursuing in the future.
Approach	To evaluate the performance and robustness of our method in comparison to previous work we have performed an extensive series of tests.
Approach	We combine this robust and efficient tetrahedral meshbased fluid simulator with a spatially adaptive method for sampling particles for FLIP-based velocity advection, giving us a method free from any single spatial resolution.
Approach	Luckily, in our tests these tetrahedra make up only a very small fraction of the mesh.
Approach	In the following we will show how to derive suitable free-surface boundary conditions to ensure second-order accuracy within our framework.
Approach	We then perform a light mesh smoothing to increase the reliability of any curvature computations.
Approach	This has the effect that motion near the surface has higher priority than motions far inside the bulk volume of the liquid.
Outcome	Without a method for accurately reproducing flat surfaces, second-order boundary conditions will introduce additional forces in the locations of surface bumps, which artificially prevent a simulation from settling down.
Background	Another example is the non-linear fluid solver developed by Mullen et al. [2009], which leads to an energy conserving solve.
Approach	We store all physical variables on the FLIP particles, so information is carried from one time step to the next in a Lagrangian manner.
Approach	For this we need to construct a continuous velocity field based on the discrete values in our tetrahedral mesh.
Background	Previous approaches have made great strides towards this goal, but they often exhibit visual artifacts, a lack of computational robustness, or an unacceptably hefty computational expense.
Approach	In general, locking can be observed if the pressure basis can represent more, and higher-frequency, functions than the basis for the velocity.
Approach	As the w n linearly depend on θ n , that means: αθ 2 = βθ 1 , γθ 1 = αθ 3 , and βθ 3 = γθ 2 .
Approach	However, positive off-diagonal terms of the matrix can result in values of θ outside of the range [0, 1], leading to an indefinite linear system.
Approach	The system has two solutions, representing the top and bottom planes of our convex hull shape.
Approach	Before we go ahead to define [ ], we want to outline the rest of the steps for our pressure solve.
Outcome	For example, when small particles land in very coarse cells after violent splashes, these particles can get stuck in mid air.
Approach	Our work is based on the Fluid-Implicit Particle (FLIP) method introduced to the computer graphics community by Zhu and Bridson [2005], which arguably represents the state-of the art for detailed and robust liquid simulations.
Outcome	We will show in Section 5 that our surface creation method results in surfaces with fewer visual artifacts.
Approach	We only consider particles that are less than a given distance apart, with the maximum distance equal to a constant scale factor l times the sum of the two particle radii.
Approach	In the following, however, we prefer an alternate view that looks at this problem from an energy minimization perspective: we want to compute the minimal change in kinetic energy necessary to reach a divergence-free state of the flow similar to [Batty et al. 2007].
Background	These meshes were also used by Chentanez et al. [2007] and by Batty et al. [2010] for liquid simulations.
FutureWork	So, instead of computing the mesh from scratch each time, we are interested in exploring techniques for continuous re-meshing.
FutureWork	It will be interesting to see how these could be incorporated into our framework.
Approach	This has the advantage of giving us a natural way to handle cells of different size, while yielding a consistent discretization of the differential operators involved.
FutureWork	This could lead to more gradual changes in resolution, at the expense of a slightly higher particle count.
Background	To alleviate this problem, [Batty et al. 2010] propose to slightly offset the pressure samples from the faces.
Background	Other works explicitly smooth the pressure field to reduce locking problems [Misztal et al. 2010].
Outcome	Our solver efficiently resolves the complex motion near the camera, while effectively reducing the computational cost for parts that are not visible.
Approach	We couple this discretization with a spatially adaptive Fluid-Implicit Particle (FLIP) method, enabling efficient, robust, minimally-dissipative simulations that can undergo sharp changes in spatial resolution while minimizing artifacts.
Approach	Effectively, this means reverting to first-order accuracy when second-order accuracy is intractable.
Outcome	We noticed that our new surface creation routine is essential for maintaining detailed simulations in the presence of accurate freesurface boundary conditions.
Approach	We used l = 2 for most of the simulations in this paper.
Approach	Our method naturally fills in these gaps by slightly pulling each particle towards the fluid interface.
Approach	We combine each of these elements to produce a simulation algorithm that is capable of creating animations at high maximum resolutions while avoiding common pitfalls like inaccurate boundary conditions and inefficient computation.
Outcome	Also, by counting degrees of freedom and constraints, we can see that our discretization prevents the locking ar- tifacts which are common in other methods.
FutureWork	In particular, we are interested in taking more temporal information into account.
Approach	In order to do this we need to compute the coefficients w n .
Outcome	Also, our choice of piece-wise constant basis functions for velocity indicates that our discretization could lead to difficulties when it is used for diffusion or viscosity solves.
Approach	When we re-write these constraints in matrix form, and include the barycentric coordinate constraint θ 1 + θ 2 + θ 3 = 1 we get the following linear system:
Approach	We will now describe how we compute the pressure projection using a tetrahedral discretization.
Outcome	We found that this method out-performs previous methods in cases of extreme spatial adaptivity by exhibiting smoother surfaces without sacrificing detail.
Challenge	We introduce a new method for efficiently simulating liquid with extreme amounts of spatial adaptivity.
Outcome	Using a graded BCC mesh leads to problems with the latter, as the position of the circumcenter lies exactly on a face for the graded tetrahedrons.
Approach	We attempt to speed up the surface creation routine used for simulation computations by computing on the moderate-resolution BCC mesh used for simulation and ignoring ballistic particles (Section 3).
Approach	The next two metrics are designed to prioritize geometric detail of the liquid surface and of obstacles by computing a desired resolution based on cuvature.
Approach	We ultimately represent our surface as the union of all such local convex hull shapes, and the minimum signed distance from these shapes to a point in space defines the outer part of our level set function.
Approach	Sizing Functions We define the level of detail in our simulations with a spatially varying sizing function S(x).
Approach	Consequently, we define the divergence operator to be the transpose of the discretized gradient.
Approach	Given our set of FLIP particles with variable radii, we aim to implicitly represent the fluid surface by computing its signed distance function.
Approach	Here, Ω represents the domain of the computational grid, and we choose to discretize this space using tetrahedral cells.
Approach	These four equations represent the intersection of three hyperplanes and a hypercylinder in 4D {a, b, c, d} space.
Approach	We first reduce memory and computational costs by switching from a finite volume method to a discretization with a significantly smaller linear system for the pressure solve, which has the side effect of increasing the simulator’s robustness to poor-quality elements and effectively preventing locking artifacts.
Approach	The two new particles are placed randomly within the original particle’s radius and redistributed with a heuristic that attempts to fill in nearby gaps: We first compute the 24 midpoints m i between this particle and its 24 nearest neighbors.
Approach	In addition to our adaptive FLIP simulator, we also introduce a new method for computing a surface from a distribution of particles with variable radii.
Approach	Also, the tetrahedral mesh is only temporarily used for the pressure solver, so no information is transferred from one time step to the next by storing it on the grid.
Approach	The density ρ is constant in our case.
Approach	For this simulation, the initial configuration consisted of 168, 161 particles, and momentarily peaked up to 1, 048, 776 during the maximal extent of the splash (settling down again to around 250 thousand in the end).
Approach	These artifacts are commonly observed in finite element methods for problems in elasticity.
Approach	The above calculation describes how to find the planar regions of the convex hull of a set of three spheres.
Background	However, such an optimization would be complicated to apply in our unstructured setting.
Challenge	We desire to enable a simulator to focus its computational resources on the visually interesting regions of a fluid flow, while remaining computationally efficient and avoiding common artifacts due to a spatially adaptive pressure solve.
Approach	The computation of the ghost fluid ρ values is independent of the right-hand side b, so we will restrict the discussion to the left hand side.
Approach	As we know that the resulting matrix needs to be symmetric, which gives us the following constraints: a + αw 2 = a + βw 1 , b + γw 1 = b + αw 3 , and c + βw 3 = c + γw 2 .
FutureWork	It will be very interesting to leverage the benefits of our framework for extreme adaptivity in these situations.
Approach	We will denote this class of algorithms as Finite Volume Methods (FVM).
Outcome	However, despite its efficiency, mesh generation is still a bottleneck for our simulation.
Approach	We change the size and number of particles in our simulation with splitting and merging operations.
Approach	If we detect such a case, we smoothly transition to first order accuracy.
Approach	In contrast to these methods, our approach for surface creation computes the union of convex hulls around triplets of particles, which leads to a smooth and closed surface around a collection of arbitrarily sized particles.
Approach	We utilize particle repositioning to improve the distribution quality, at the expense of slight inaccuracies due to displacing physical variables.
Approach	κ liquid (x) returns 0.8 divided by the extrapolated curvature of the liquid interface.
Approach	Using this temporary radius to compute the signed distance as described above will remove erroneous gaps inside the liquid.
Outcome	Likewise, the grid-based velocity extrapolation of line 10 uses the nodal velocities of Section 3.
Approach	We found that this strategy adequately eliminates any artifacts due to spatially varying numerical viscosity.
Approach	During each time step, we apply the position correction algorithm of Ando et al. [2012]; this algorithm essentially pushes each particle away from its neighbors to prevent clustering.
Approach	Our method uses a FLIP scheme instead of a purely Eulerian method.
Outcome	We found that using too sharp of a grading in our sizing function can place coarse and fine simulation elements too close together and potentially result in artifacts.
Approach	For each set of three FLIP particles near the surface, the convex hull forms a thickened triangle shape with rounded edges ( Figure 5 ).
Approach	If the quality of a tetrahedron is good, 0 < θ n < 1 is guaranteed.
Outcome	In this way, we can efficiently compute tough simulation setups, such as large surfaces with very localized details.
Background	Adaptive simulations have also been explored in the context of SPH simulations without Eulerian grids.
Approach	Unfortunately, performing interpolations within arbitrary Voronoi cells would be expensive and require a large amount of computation compared to the other steps of our simulator.
Approach	This inefficiency stems from the fact that water droplets undergo extremely simple ballistic motion.
Outcome	Our measurements show that the run-time of our method has a strong linear relationship to the number of particles, and thus the visual complexity of the simulation.
Approach	We store pressure samples at the nodes of the tetrahedral mesh, while velocities are stored at cell centers.
Approach	Note that each of the θ n has two degree of freedom, and thus each w n also has two degrees of freedom.
Approach	We need to compute liquid surfaces both for final visualization as well as for several calculations during the progress of our simulation.
Approach	For our BCC mesh, n is in practice smaller than the number of tetrahedra m (by a factor of 6 on average).
Approach	We solve these equations using operator splitting [Stam 1999], and a level set φ(x) = 0 defines the position of the liquid-gas interface.
Approach	We compensate for spatiallyvarying numerical viscosity caused by particles of various sizes in our simulation by adjusting the PIC/FLIP blending parameter in our FLIP simulation [Bridson 2008].
Approach	Given quantities Q i,PIC and Q i,FLIP computed at particle i from PIC and FLIP simulations, respectively, the new quantity Q i is computed as a weighted blend between the two:
Approach	Instead, we have to ensure the boundary conditions result in the correct pressure value at the cell center.
Background	An inherent difficulty is that simulations on regular grids become prohibitively expensive for large resolutions.
Approach	As a last component of our sizing function we found it beneficial to invest computational resources into keeping interesting motion of the flow field alive.
Approach	As we store velocities at the cell centers, the interpolation would ideally use the dual mesh consisting of the Voronoi cells of each node [Brochu et al. 2010].
Outcome	While we believe that our surface creation routine is indispensable, it is quite expensive to compute.
Approach	In practice, we compute the local convex hull by finding the two outermost planes tangent to a set of three spheres.
Approach	By computing the conic and spherical convex hull facets ( Figure 5 , bottom right) in a similar fashion, we can easily compute the signed distance between this convex hull and a point in space.

Approach	Our implementation makes heavy use of a structure we call the distance tree.
Approach	We begin with a triangle mesh and an octree annotated with signed-distance field samples.
Background	Surfels store a surface normal as well as position and there are generally many more surfels than simulation particles.
Approach	The marching-cubes algorithm works well for our purposes because each triangle generated by marching cubes sits strictly inside a single cell of the distance tree, making the distance tree an especially effective spatial index.
Approach	When building an octree from a triangle mesh (either in initialization, or after some geometric operation has been applied to the triangle mesh) we use the following splitting criterion:
Background	Since there is no guarantee that the same particle will be chosen at subsequent timesteps, the method is extremely susceptible to high-frequency temporally incoherent perturbations of the surface.
Approach	An approximation with the correct sign is sufficient.
Approach	Then φ(x, t n+1 ) is set equal to the interpolated value, φ(s(t n ), t n ).
Approach	Instead, we avoid topological issues by updating the surface using an implicit representation.
Approach	Consequently, we briefly discuss the mathematical foundation of semi-Lagrangian methods.
Approach	While this smoothing technique may be quite useful in some applications, we did not use this method for any of the results in this article.
Outcome	This implicit representation allows us to update the surface without explicitly addressing any of the difficult topological issues which plague other approaches.
Approach	We make use of two different methods for building distance trees in this work.
Approach	In this way, we ensured that, at every timestep, every vertex in the mesh mapped back to some point on the initial surface.
FutureWork	We plan to incorporate a multiresolution fluid simulator as part of our future work.
Approach	Finally, it allows us to take advantage of the many tools and algorithms which have been developed in computer graphics for manipulating and rendering triangle meshes.
Background	The contouring problem has been well studied in computer graphics and a number of approaches have been suggested.
Background	In particular, the published particle correction rules choose a single particle to provide the signed-distance value.
Background	Dual contouring depends on normal estimates at edge crossings and is very sensitive to inaccuracies in these normal estimates.
Approach	The octree vertices are annotated with signeddistance values and each cell of the octree contains a list of the triangles with which it intersects.
Approach	These situations can be resolved by computing an angle-weighted pseudonormal for each edge and vertex of the mesh and using these pseudonormals to determine the sign when the nearest point is on an edge or vertex of the mesh.
Approach	In solving this advection term, our method differs from the simple CIR scheme discussed earlier in two ways.
Background	Bærentzen and Christensen [2002] built a sculpting system using a level-set surface representation which could be manipulated by a user with a variety of sculpting tools.
Approach	—A cell’s size is proportional to its distance to the surface.
Approach	Ideally we would use a multiresolution fluid simulation, like the octree method of Losasso et al. [2004].
Outcome	These changes only improve the accuracy (consistency) of our method and do not affect the unconditional stability.
Approach	The key difference between our method and volume-of-fluid methods is that we never compute volume fractions.
Approach	It is important to note that, while this method traces back through the velocity field with second-order accuracy, the velocity field is frozen over the course of the timestep, leading to first-order accuracy in time.
Approach	Since we know that the tracked value should always be a point on the initial surface we could find the point on the initial mesh which was closest to the value the tracking method supplied.
Approach	In general, semi-Lagrangian schemes satisfy the CFL condition by shifting the stencil, rather than restricting the timestep.
Approach	While the semi-Lagrangian procedure for backward advection does not change significantly when going from twoto three-dimensional problems, significant surface tracking issues arise when moving to three dimensions.
Background	Unfortunately, this representation does not admit accurate curvature estimates, which are essential to surface tension computations.
Outcome	In fact, the only parameters to our system are the upper and lower corners of the domain, the maximum depth of the octree (a resolution parameter), and some resolution tolerances.
Background	However, the scalar function is defined and maintained in the embedding three-dimensional space, rather than just on the two-dimensional surface.
Approach	Our implementation is based on Bloomenthal’s [1994].
Approach	Many of our examples were rendered with a matte shader so that the surface detail can be seen.
Background	However, they used a two-level structure rather than a full octree.
Approach	This optional processing might include smoothing the surface, improving the shape of the triangles, or any other operation that returns a closed manifold.
Approach	For example, CIR with linear interpolation is unconditionally stable in the 2-norm.
Approach	To deal with the fact that ψ n+1 is not a distance function and that the value at the cell’s center may not be the minimum over the cell, we multiply the edge length by some constant before doing the comparison.
Approach	At each timestep, the morphogens were advected along with the surface and then allowed to react.
Approach	Notice that we can vary this constant to achieve high-resolution bands of varying width around the surface.
Approach	This surface is textured by advecting reference coordinates along with the flow and applying a procedural checkerboard texture.
Approach	All of our fluid examples used a standard regular-grid Eulerian fluid simulator with the elasticity model of Goktekin et al. [2004].
Approach	Because our fluid simulator has a regular grid its resolution is notably coarser than the surface tracker, which uses an octree.
Background	Alternatively, several adaptive contouring methods [Shu et al. 1995; Shekhar et al. 1996; Poston et al. 1998] seek to use adaptive grids and regain compatibility through various crack-patching techniques.
Background	Many of the most successful solutions to the surface tracking problem are based on level-set methods, which were originally introduced by Osher and Sethian [1988].
Background	The most significant drawback to using level-set methods to track liquid surfaces is their tendency to lose volume in underresolved, high-curvature regions.
Approach	Thus we apply Criterion (13) as if ψ n+1 were a distance function.
Approach	The distance tree is a balanced octree subdivision of the spatial domain.
Approach	Our redistancing method comprises three steps: —coarsen the octree; —compute exact distances at vertices of cells which contain triangles; —run a fast marching method over the remaining vertices.
Approach	Next, we extract the zero set of this function using a contouring algorithm.
Background	Unfortunately, marching triangles is not guaranteed to produce closed, manifold meshes in the presence of sharp or thin features.
Approach	If vertex v in the current mesh maps to point p in the old mesh and some surface property was stored at p, this property can be copied to v.
Approach	Once we had this mapping we could copy any property stored on the initial surface, whether it be the reference coordinates, texture coordinates, or color values.
Approach	To address this problem, we coarsen parts of the tree which have been refined but did not generate surface.
Outcome	The motion of the spots on the surface occurs both from the motion of the surface and from the reactiondiffusion system seeking equilibrium on the moving surface.
Approach	Consistency (loosely speaking, the local accuracy of the method), however, is conditional.
Approach	However, if we know something about the property we are tracking, we may be able to “clean up” the blurred signal.
Approach	Although we did not find it necessary, after the contouring step the mesh can be processed in any way that preserves the closed-manifold invariant.
Background	Premo ze et al. [2003] went a step further and used particle positions and velocities to guide a level-set solution.
Approach	For nonlinear PDEs, CIR still converges when the solution is smooth.
Approach	One of the key differences between our method and other surface tracking methods is that we build an explicit representation of the surface at every timestep.
Approach	Furthermore, we use the distance tree we have already built to guide the marching cubes, avoiding the need to build a second structure to determine the topology of the new mesh.
Approach	Thus information propagates over long distances in one timestep.
Background	Sussman and Puckett [2000] coupled volume-of-fluid and level-set methods to model droplet dynamics in ink-jet devices.
Approach	The theoretical framework for this method comes from a series of articles by Strain [1999b, 1999c, 1999a, 2000, 2001] that described and analyzed a method for contour tracking in two dimensions.
Background	The oldest and most widely used is marching cubes, which was first presented by Wyvill et al. [1986], and later named and popularized by Lorensen and Cline [1987].
Approach	In practice, we use the value of φ at the cell’s center to determine whether we should split the cell.
Background	Also, the method has a large number of parameters and rules, such as the number of particles per cell and the reseeding strategy, which need to be decided, often in an application-specific way.
Background	The methods available for tracking free surfaces of liquids can be roughly sorted into four categories: level-set methods, particle-based methods, particle level-set methods, and semi-Lagrangian contouring.
Approach	A new polygonal surface is generated by contouring or extracting the zero set of ψ.
Approach	Such artifacts are a form of aliasing and can be reduced by jittering the grid each timestep.
Approach	More specifically, we define a scalar-valued function which relates the surface at the current timestep to the surface at the previous timestep.
Challenge	The surface tracking problem can be phrased as: given a surface representation and a velocity field at time t, build a representation of the surface at time t + t.
Outcome	There are still plenty of open problems in the area of texturing liquid surfaces.
Approach	Thus CIR is consistent to O( t) if a condition t ≥ O( x) is satisfied, contrary to the usual hyperbolic condition t ≤ C x.
Background	This problem is fixed to some degree by dual contouring [Ju et al. 2002], which also provides adaptive contouring and an elegant means of preserving sharp boundaries.
Background	Recently, these methods have been extended to work with octrees [Enright et al. 2005; Losasso et al. 2004], allowing for very high-resolution surface tracking.
Background	A number of researchers [Terzopoulos et al. 1989; Desbrun and Gascuel 1995; Foster and Metaxas 1996; Desbrun and Cani 1996; Cani and Desbrun 1997; Stora et al. 1999; M uller  ̈ et al. 2003, 2004; Premo ze et al. 2003; Zhu and Bridson 2005; Pauly et al. 2005] have used particles to track surfaces.
Background	These methods represent the current state of the art on tracking liquid surfaces for animation, but do have some drawbacks.
Approach	However, if the nearest point in the mesh lies on more than one triangle (i.e., on an edge or vertex of the mesh), the triangles do not always agree on the sign.
Approach	It then returns the distance from x to the surface, S n−1 , at the previous timestep.
Outcome	The motion of the two streams causes this thin surface to form a spiral shape as the streams separate.
Approach	Let y and n(y) denote the closest point on the surface to x and its normal, respectively.
Approach	Additionally, when finding the zero crossing along any edge (which will eventually be a vertex in the triangle mesh), we use a secant method to speed up convergence and evaluate our full composite field function, including exact evaluation of the previous signed-distance function.
Approach	In fact, each vertex in our polygon mesh can be mapped to some point on some triangle in the mesh at the previous timestep.
Approach	The fluid simulator and the surface tracking module were only very loosely coupled: the fluid simulator provided the surface tracker with a velocity function and, in turn, the surface tracker provided the simulator with the signed-distance function.
Outcome	Finally, and most importantly, we are able to produce detailed, flicker-free animations of complex fluid motions.
Approach	By constraining the mesh vertex to be on the edge of the marching-cubes grid, we still guarantee a consistent, closed, manifold triangulation.
Approach	We define a scalar-valued field function, ψ(x), which relates the surface at the current timestep to the surface at the previous timestep.
Outcome	In addition to creating poorly shaped triangles, marching cubes is nonadaptive.
Background	Semi-Lagrangian methods have been widely used in computer graphics since they were introduced by Stam [1999] to solve the nonlinear advection term of the Navier-Stokes equations.
Background	Level-set methods represent a surface as the zero set of a scalar function which is updated over time by solving a partial differential equation, known as the level-set equation.
Approach	However, the jumps in φ decrease in size in cells near the surface because of the triangle inequality.
Background	The principal drawback of these methods is that generating high-quality time-coherent surfaces can be difficult: directly visualizing the particles is insufficient for high-quality animations, methods which convert the particles to some other representation on a per-frame basis often lack temporal coherence, and methods which must run sequentially through the frames or run during the simulation are often quite costly.
Approach	To avoid the topological difficulties of directly updating an explicit surface representation, we update the surface in time through an implicit representation (see Figure 2 ).
Background	This operation is relatively expensive, but many triangles can be pruned, especially when x is very close to the surface, by using standard bounding-box techniques and our octree data structure (see Section 6).
Outcome	In this work, we are able to leverage the advantages of semi-Lagrangian advection, without incurring the interpolation error that would otherwise undesireably smooth surface detail.
Outcome	Similar effects can be seen in real-world footage.
Outcome	Fourth, our method does not have any ad hoc rules or parameters to tune.
Approach	—Cells coarsen very rapidly away from the surface: if there are N childless cells touching the surface, then the entire tree contains only O(N log N ) cells.
Approach	Our method maintains an explicit polygonal mesh that defines the surface, and an octree data structure that provides both a spatial index for the mesh and a means for efficiently approximating the signed distance to the surface.
Approach	The distance to the surface is min i d i .
Approach	Thus, if image textures were preferred over procedural textures, texture coordinates could be copied instead of reference coordinates.
Approach	These grids were then randomly perturbed so that grids at adjacent timesteps were slightly offset from one another.
Challenge	The fundamental problem of tracking a surface as it is advected by some velocity field arises frequently in applications such as surface reconstruction, image segmentation, and fluid simulation.
Outcome	In general, we found the increased surface resolution to be worth these artifacts.
Background	However, accurate curvature estimates are easily computed from level-set representations.
Outcome	One of the primary advantages of this method is that it enables tracking surface characteristics, such as color or texture coordinates.
Background	Some volume-of-fluid methods build an explicit surface representation from the volume fractions stored in each voxel.
Approach	The octree structure we use to build and index the polygonal mesh is quite similar to adaptively sampled distance fields [Frisken et al. 2000].
Approach	Consequently, our octree, unlike those used by Losasso et al. [2004], does not necessarily coarsen away from the surface.
Background	For example, pieces of surface could appear connected when the simulator thinks they are disconnected and vice versa.
Challenge	In this article, we present a semi-Lagrangian surface tracking method for use with fluid simulations.
Outcome	In addition to enabling exact evaluation, this explicit representation also allows us to leverage 30 years of computer graphics technology which has been optimized for polygonal meshes.
Approach	As pointed out earlier, every vertex in a polygon mesh corresponds to some point on some triangle in the previous mesh.
Approach	While our method bears a number of similarities to level-set methods and takes advantage of many techniques developed for those methods, we are not directly solving the level-set equation.
Background	To address the volume loss of level-set methods, Enright and his colleagues [2002a, 2002b, 2005] built on the work of Foster and Fedkiw [2001] to develop particle level-set methods.
Background	Recently, Strain [1999b, 1999c, 1999a, 2000, 2001] has written a series of articles building a theoretical framework culminating in the formulation of surface tracking as a contouring problem.
Approach	Once we have resolved ψ on our distance tree, we need to create an explicit representation of our surface at the new timestep.
Outcome	Thus it took about 2 days to simulate 10 s of animation, with roughly half the time spent solving for the velocity field and half the time updating the surface.
Approach	Essentially, we are having trouble because we are resampling the surface at every timestep.
Challenge	In this article we present a surface tracking method that explicitly represents the surface as a set of polygons.
Approach	At each timestep, a new surface is constructed by extracting the zero set of an advected signed-distance function.
FutureWork	Such methods could easily be used here and we plan to explore adaptive methods in future work.
Approach	First, we propagate the triangle lists up the tree so that the triangle list of a cell is the union of the triangle lists of a cell’s descendants.
Background	In many of these methods, the simulation elements are particles, which are already being tracked throughout the volume of the deforming liquid or solid.
Background	This problem, referred to as redistancing, has been well studied by the level-set community and a number of methods have been suggested.
Background	Marching triangles requires significantly less computation time and fewer triangles, and produces higher-quality triangles than marching cubes.
Challenge	Unfortunately, the na ̈ ive approach of simply advecting the vertices of a polygonal mesh, or other explicit representation of the surface, quickly encounters problems such as tangling and self-intersection.
Approach	—If φ is the signed distance to the surface at vertices and we extend φ into each cell by trilinear interpolation, then, because cells vary in size, φ will be discontinuous.
Approach	Instead, our explicit representation is generated by contouring an advected signed-distance function.
Approach	Splitting ends when the tree reaches a predetermined maximum depth.
Outcome	These properties can be easily stored directly on the polygonal mesh and efficiently mapped onto the new surface during semi-Lagrangian advection.
Approach	It is also very difficult to guarantee that we will still have a manifold when the inserted vertices are moved to the surface.
Approach	Thus the interpolated φ is nearly continuous near the surface.
FutureWork	Decoupling the timesteps of the fluid simulator and surface tracker, so that the surface tracker runs only once per frame, is an interesting area of future work.
Outcome	Our choice of contouring algorithm does result in some limitations.
Approach	The ability to compute exact distances is one of the chief advantages of having an explicit surface representation.
Approach	For linear PDEs, such as Equation (1), the Lax-Richtmyer equivalence theorem [LeVeque 1990] guarantees that CIR will converge to the exact solution as t, x → 0 if it is stable and consistent.
Approach	Essentially, we are advecting the signed-distance function through the velocity field given by the fluid simulator.
Background	One of the key issues that distinguishes various level-set and similar approaches is the representation of the scalar field, which must capture whatever surface properties are important to a given application.
Approach	This jittering limits the reusability of our octrees, but since we build new octrees every timestep, this limitation is not significant.
Outcome	Both the fluid simulator and the surface tracking module took 11 timesteps per frame.
Background	This observation forms the basis of the backward characteristic or CIR scheme developed by Courant, Isaacson, and Rees [1952], which is the simplest semi-Lagrangian scheme.
Approach	Criterion (11) results in a three-color octree, as described by Samet [1990], where each cell of the octree has one of three types: interior, exterior, and boundary (see Figure 4 ).
Background	An alternative structure for storing narrow-band level-set functions is the dynamic tubular grid of Nielsen and Museth [2006].
Approach	A new distance must be built only if the mesh is modified.
Background	Unfortunately, this splitting technique is not easily extended to three dimensions as splitting a triangle either creates an incompatible triangulation or produces even more poorly shaped triangles.
Approach	The final mesh vertex is an average of these two points.
Approach	Our octrees are always built in a top-down manner where each cell is split based on some variation of the following splitting criterion:
Approach	A new distance tree can then be built from this modified mesh using Criterion (15).
Approach	By taking advantage of the details of our method, we can very efficiently achieve limited smoothing in two ways.
Approach	When computing the signed distance from a point x to a surface, S, we first find the smallest octree cell, C, containing x .
Outcome	Our colored and textured examples illustrate how easily a variety of properties may be attached to the surface.
Approach	All of our images were rendered with the open-source renderer Pixie [Arikan 2005].
Outcome	The explicit surface representation also facilitates other common operations, such as rendering, while reconstruction from a scalar function allows operations that rely on an implicit representation.
Background	Because surface tracking arises in a variety of contexts, the topic has received a significant amount of attention.
Approach	These methods provide the foundation for our surface tracking method.
Approach	This polygon mesh is used for exact evaluation of the distance function near the surface.
Approach	The vertices are shared between triangles, allowing for easy computation of smooth vertex normals and other common mesh operations.
Approach	By formulating surface tracking as a contouring problem, we avoid many of the issues that complicate level-set methods.
Approach	The stability properties of the CIR scheme are excellent.
Approach	This function is quite similar to the functions used in semi-Lagrangian level-set methods [Strain 1999b; Enright et al. 2005].
Background	However, when evaluating the distance function after the semi-Lagrangian path tracing, they interpolated distance values stored on a regular grid, while our explicit surface representation allows us to compute exact distances near the surface.
Approach	Most of the examples in this article used grids which were slightly larger than the simulation domain.
Background	Mueller et al. [2004] and Pauly et al. [2005] used special particles, called surfels, to represent the surface.
Approach	We divide each cube into six tetrahedra to simplify the implementation.
Approach	Interpolation can produce substantial errors (see Figure 3 ) which are compounded over time.
Approach	The implicit representation is then used to construct a new mesh at the current timestep.
Approach	The distance tree (see Section 6) provides a spatial index for the mesh.
Approach	Thus we can find φ values at any time t by finding the characteristic curve passing through (x, t), following it backward to some previous point (x 0 , t 0 ) where the value of φ is known, and setting φ(x, t) = φ(x 0 , t 0 ).
Approach	This test is efficiently implemented using Green and Hatch’s [1995] cube/triangle intersection test.
Background	They also used semi-Lagrangian methods to update their level-set function.
Approach	Additionally, our splitting criterion is different from that presented by Frisken et al. [2000].
Approach	When marching cubes encounters an edge whose vertices have different signs, we find a point which evaluates to zero for each composite function.
Outcome	One of the primary advantages of this formulation is that it enables tracking of surface characteristics, such as color or texture coordinates, at negligible additional cost.
Approach	As our title suggests, we formulate surface tracking as a contouring problem.
Outcome	Finally, the method produces detailed, well-defined surfaces that are suitable for realistic animation and that do not jitter or exhibit other undesirable behaviors.
Approach	We do this coarsening in two steps.
Outcome	That is, the sampling is as dense in flat regions as in regions of high curvature.
Approach	The second difference is that, when evaluating φ at points near the surface, we do not interpolate values stored on a grid.
Approach	For a point x at the current timestep, the function, ψ, first uses backward path tracing, a semiLagrangian integration technique, to find the point x at the previous timestep which flows to x.
Approach	This condition is extremely convenient, because t = O( x) balances time and space resolution in this first-order accurate scheme.
Approach	First, it allows us to compute exact signeddistance values near the mesh.
Approach	First, we can define a second composite function to be the combination of path tracing backward in time followed by the evaluation of a high-order polynomial interpolant of the distances at the vertices of the octree.
Approach	We have found that 1/3 works well in practice—always dividing near the surface, without spuriously dividing too many cells.
Approach	Second, it allows us to store properties on mesh vertices, rather than at points near the mesh.
Background	A complete review of level-set methods is beyond the scope of this article, and we recommend the excellent surveys by Sethian [1999] and Osher and Fedkiw [2003].
Approach	However, for some applications this interpolation can produce unwanted smoothing.
Outcome	Second, we have an implicit representation.
Approach	A number of our examples were also rendered with a glass shader (using water’s index of refraction) for comparison to previous methods and real fluids, and to demonstrate how the method can be used to generate realistic results.
Background	See Enright et al. [2002a] for an excellent discussion of the reasons for this volume loss.
Background	However, this method appears to be prohibitively expensive for something which must run at every timestep.
Outcome	The sphere was restored to a nearly identical shape (see Figure 8 ), while the bunny exhibited a small amount of smoothing.
Outcome	First, we have an explicit representation.
Background	To address this lack of resolution in high-curvature areas, Strain [2001] split line segments whose centers were far from the surface, yielding arbitrarily high accuracy.
Background	Despite these drawbacks, the particle level-set methods have been very successful and represent a significant step forward in the area of surface tracking for liquid simulations.
Approach	Using adaptive octree data structures, we can efficiently and reliably construct the new surface and corresponding signed-distance function.
Approach	Second, repeatedly using the same grid for contouring can produce grid artifacts.
Approach	Contrariwise, if C is not at the finest level of the octree or if there are no triangles in the concentric triple of C, then x is not near the surface and we do not require an exact distance.
Background	The artifacts are most noticeable when the surface thins out below the grid resolution and particles happen to be near some of the sample points, but not others.
Approach	Our method pulls together solutions to a number of well-studied problems to arrive at a method for tracking surfaces.
Background	Instead, a family of methods, known as level-set methods, has been developed for surface tracking.
Background	This equation relates change of the scalar function to an underlying velocity field.
Outcome	Creating detail where a surface stretches is also an open problem.
Background	Previous methods, such as the one proposed by Rassmussen et al. [2004], have been limited to tracking properties in the volume near the surface and interpolating them to the surface.
Background	The idea of using different resolutions for the fluid and surface is not new; Foster and Fedkiw [2001] used different timesteps for their fluid and surface calculations and Goktekin et al. [2004] found that increasing the spatial resolution of the surface tracking grid dramatically reduced volume loss.
Approach	We could try to advect the mesh points through the flow field, but would quickly encounter significant topological difficulties.
Approach	Finally, a new signed-distance field is computed through a process known as redistancing (see Figure 1 ).
Approach	We have tested this surface tracking method coupled with a fluid simulation on several examples such as the ones shown in Figures 5 and 6.
Approach	This explicit representation is a closed, manifold triangle mesh, which is stored as an array of vertices and an array of triangles.
Approach	But nonsmooth shock solutions of conservation laws move at the wrong speed because CIR is not in conservative form.
Outcome	In practice, we believe that advected properties could be used effectively with standard shading techniques to generate a wide range of interesting effects.
Outcome	We include several examples demonstrating that the method can be effectively used as part of a fluid simulation to animate complex and interesting fluid behaviors.
Background	Schneider and Eberly [2002] detailed a method for computing the distance from a point to a triangle.
Approach	Instead, we perform exact evaluation at all vertices of the cells that contain triangles, but then run a fast marching method [Sethian 1996; Losasso et al. 2004] over the remaining vertices.
Outcome	As the streams oscillate from side-to-side, they collide and produce a thin, web-like surface between them.
Approach	Signing the distance values turns out to be somewhat difficult near sharp corners.
Approach	The octree is built recursively from the root cell C 0 by the following splitting criterion:
Approach	In many cases it is sufficient to use barycentric interpolation to compute a value at p and copy this interpolated value to v.
Approach	Most often, we wish to build a distance tree to resolve the zero set of our field function ψ.
Outcome	In particular, it is difficult to deal with large discontinuities in surface properties, which occur when two surfaces merge, or a surface splits.
Approach	For example, a sphere of fluid falling under gravity will develop creases along the coordinate axes.
Background	By using this implicit representation, level-set methods avoid dealing with complex topological changes.
Approach	Instead, we compute exact distance values.
Background	When used for velocity advection, interpolation produces such significant smoothing that researchers have proposed a number of methods to add detail back to the flow [Fedkiw et al. 2001] or avoid semi-Lagrangian advection altogether [Zhu and Bridson 2005].
Approach	(3) It guides the contouring algorithm, quickly identifying cells which have vertices of different sign and, thus, contain triangles.
Background	These structures adaptively sample distance fields according to local detail and store samples in a spatial hierarchy.
Approach	The key difference between adaptively sampled distance fields and our surface representation is that we store a polygon mesh in addition to distance samples.
Approach	In particular, we do not have the same volume loss issues which prompted the particle levelset methods: while we do not explicitly conserve volume, our semi-Lagrangian path tracing tends to conserve volume in the same way as the Lagrangian particles in the particle level-set method.
Approach	Hence the surface is resolved accurately at minimal cost.
Background	Finally, the method tends to produce very smooth surfaces with very little detail, which is desirable in some, but not all, applications.
Background	While the asymptotic times for their structure match ours, they are able to exploit cache coherence to provide extremely fast run times for most level-set operations.
Approach	Our cubes are the leaf cells in the distance tree which have vertices of differing sign.
Background	Yet another alternative is marching triangles [Hilton et al. 1996], which takes a surface-based rather than volume-based approach to contouring.
Approach	Unfortunately, in our method we do not have accurate normal information until after the contouring step, when we have the triangle mesh.
Approach	Creating this explicit representation amounts to extracting the zero set of ψ and is an instance of the contouring problem, which has been well studied in computer graphics.
Approach	In fact, this interpolation error is one of the most significant drawbacks to semi-Lagrangian methods in general.
FutureWork	Integrating the methods presented here with this data structure is a promising area for future work.
Background	Strain [1999a] suggested redistancing by performing an exact evaluation at every vertex of the octree.
Background	More recently, Boissonnat and Oudot [2003] presented a contouring technique which uses Delaunay triangulation methods to generate provably good triangulations.
Approach	We also tested it in the spiraling analytical test field from Enright et al. [2002a].
Approach	Consequently, we need not worry about patching the marching-cubes solution.
Approach	Each new value φ(x, t n+1 ) is a single interpolated value of φ at time t n , so unconditional stability is guaranteed in any norm where the interpolation does not increase norms.
Background	Such methods incur significant cost, introduce substantial smoothing, and blur properties between nearby surfaces.
Outcome	The fluid simulation also required about 1 min/timestep.
Background	These methods track the characteristics of the fluid flow with Lagrangian particles, which are then used to fix the level-set solution, essentially increasing the effective resolution of the method.
Approach	Our method is based on the method presented by Strain [2001], but with variations and extensions to deal with problems that arise in three-dimensional computer animation.
Outcome	Rendering, texture mapping, and a variety of other applications are all very straightforward.
Approach	However, in three dimensions, we have found it to be prohibitively expensive and unnecessary.
Background	He demonstrated his semi-Lagrangian contouring method on a variety of two-dimensional examples.
Approach	For its simplicity, robustness, and speed, we choose to use a marching-cubes method in our implementation.
Background	Volume-of-fluid [Hirt and Nichols 1981] techniques represent the surface by storing, in each voxel, a volume fraction—the proportion of the voxel filled with liquid.
Approach	If C is at the finest level of the octree, then x may be near the surface and all the triangles in the up to 27 cells in the concentric triple 1 of C are considered when computing the minimum distance to the surface.
Background	The particles can be visualized directly, or can be used to define an implicit representation using blobbies or moving least-squares methods.
Background	Thus, the authors combined volume-of-fluid and level-set representations to model surface tension in ink droplets.
Approach	Since level-set solutions have no shocks, CIR is a natural scheme for moving interfaces.
Background	This method is relatively efficient since the tree coarsens rapidly away from the surface and works well in two dimensions.
Background	Marching cubes suffers from a tendency to create ill-shaped triangles.
Approach	In our method, there may be some parts of the domain where the octree was refined but did not result in any triangles, such as when the surface becomes thinner than the resolution of the tree.
Approach	Thus in the limit, t = O( x) → 0, Criterion (13) reduces to (11), yielding the properties noted above.
Background	As noted by Losasso et al. [2004], using different spatial resolutions can produce artifacts.
Background	Even in the limited context of fluid animation, there has been a great deal of excellent work on simulating fluids with free surfaces, including Foster and Metaxas [1996], Foster and Fedkiw [2001], Enright et al. [2002b], Carlson et al. [2002, 2004], Losasso et al. [2004], Goktekin et al. [2004], Hong and Kim [2005], Wang et al. [2005], Guendelman et al. [2005], and Zhu and Bridson [2005].
Outcome	Semi-Lagrangian contouring offers an elegant and effective means for surface tracking and has a number of advantages over competing methods.
Approach	Second, we remove all the children of any cell whose concentric triple does not contain any triangles.
Background	Like us, they used adaptive grid structures to store the scalar field.
Background	Any cell whose fraction is not one or zero contains surface.
Background	In practice, scalar function values need only be accurately maintained very near the surface, resulting in a cost that is roughly linear in the complexity of the surface.
Approach	Unfortunately, the nonadaptive nature of marching cubes limits the resolution we can achieve in high-curvature areas, but is necessary to ensure compatibility.
Approach	Otherwise, the computed distance is a very good estimate but may be slightly larger than the actual distance.
Approach	In this way we can track surface properties on the actual surface as we build the surface, so we do not incur any significant additional cost.
Approach	(2) It provides a fast, approximate signed-distance function, which is sufficient when evaluating the signed distance far from the surface.
Approach	After the triangle mesh at the current timestep has been extracted, we must assign true distance values to the vertices of our octree.
Outcome	One of the primary advantages of our method is the ability to track surface properties, such as color, texture coordinates, or even simulation variables, accurately at negligible additional cost.
Approach	However, it is also useful to build a distance tree from an existing triangle mesh.
Approach	Thus, semi-Lagrangian advection provides a mapping between surfaces at adjacent timesteps.
Challenge	This article discusses these issues, as well as the general method, and demonstrates how semi-Lagrangian surface contouring can be useful for animating the complex and interesting behavior of fluids.
Background	The surface can then be implicitly defined as the boundary between where the particles are and where they aren’t.
Approach	To compute the exact distance from a point x , we compute the distances d i to all the nearby triangles.
Approach	Near the surface, our distance tree is refined to the maximum level and looks like a uniform grid.
Outcome	This mapping allows us to accurately track surface properties on the actual surface at negligible complexity and cost.
Approach	For example, in our examples with checkerboard textures, we tracked reference coordinates which were passed to a simple function to determine color.
Background	Bærentzen and Aanæs [2002] provided a proof that this procedure results in accurate signing (in exact arithmetic).
Outcome	It is important to note that, given a perfect semi-Lagrangian path tracer, the method could take arbitrarily large timesteps.
Outcome	Third, semi-Lagrangian advection gives us a mapping between surfaces at adjacent timesteps.
Approach	We take advantage of this fact when advecting surface properties.
Background	Additionally, surface features may be maintained when a more detailed fluid simulator would smooth them away.
Approach	Our discussion follows that of Strain [1999b].
Approach	In this case, we use trilinear interpolation of the distance values stored at the vertices of C.
Background	These methods represent the surface implicitly as the zero set of a scalar field defined over the problem domain.
Approach	By storing the nearest distance seen so far and using standard bounding-box techniques, many of these triangles can be pruned before computing distances, especially when x is very near the surface.
Background	The methods are widely used, and the texts by Sethian [1999] and Osher and Fedkiw [2003], and Osher and Sethian’s [1988] seminal article, provide an excellent introduction to the topic.
Outcome	For most of our examples the surface tracking module took roughly 1 min/timestep at an effective resolution of 512 3 .
Background	This structure can be combined with run-length encoding schemes [Houston et al. 2006], providing extremely compact, high-resolution representations of level-set functions.
Approach	The explicit representation provides our method with several advantages.
Approach	Consequently, the vertices of our polygon mesh are guaranteed to lie on the implicit surface (within an tolerance).
Background	Additional difficulties arise when trying to ensure a good sampling of the surface.
Background	One difficulty with level-set methods is that they generally require very high-order conservation-law solvers, though fast semi-Lagrangian methods have been shown to work in some cases [Strain 1999b; Enright et al. 2005].
Approach	The value of ψ at a point x, at current time t, is obtained by first tracing backward through the flow field to find the previous location x at time t − t, and then returning the signed distance of x from the previous surface.
Approach	If the computed distance is less than C’s edge length, then the distance is guaranteed to be exact.
Approach	Semi-Lagrangian backward path tracing is used to advect the signed-distance function.

Approach	In fact, MeshIK is well-suited to cloth data and we use it to bind reconstruction of our pants to motion capture data.
Approach	The orientation of the surface is unknown, yielding four possible directions, or two bits of structural ambiguity.
Approach	To maximize the density of reconstructed points, we print the smallest markers that we can reliably detect.
Challenge	However, because fast non-rigid regions of the cloth are complex, small temporal errors are often difficult to notice.
Approach	To find correspondence, we match each image marker to a marker in the parametric domain.
Approach	This hole filling procedure has a number of requirements: the missing section needs to be replaced by a section with the same topology; the new section needs to obey a number of point constraints around the edge of the hole, and the splicing method should respect properties of cloth (specifically strain).
Background	However, the range of motion is limited to avoid occlusion (e.g., arms are always held at 90 degrees to the torso).
Background	The real-time system described in [Guskov et al. 2003] introduces markers of constant color, resulting in significantly fewer correspondence errors than in [Pritchard and Heidrich 2003].
Approach	We then reconstruct the 3D location of surface points by detecting corresponding points in multiple views ( figure 4 ).
Background	They use 5 colors which, without errors, yields C = log 2 5 bits per marker.
Approach	Subsequently, we use the value 10 −5(N+1) where N is the number of neighbors.
Background	Second, in their paper, they say that oblique views cause another bit of uncertainty.
Approach	We start with N = 3 and end with N = 0.
Approach	The goal of our acquisition pipeline is to compute correspondence using minimal neighborhoods.
Background	Little work has been done to capture garments with folds and scenes with occlusion.
Approach	As such, these regions are not going to match.
Outcome	This approach covers a reasonably large range of motion, but ignores cloth dynamics.
Approach	At this stage, we compute color information for each marker and eliminate hypothetical correspondences from further consideration that have large color differences.
Outcome	So that other researchers can benefit from our work, we are releasing our capture data at http://www.ryanmwhite.com/data.
Approach	For our work, C is an empirical observation.
Challenge	Typical temporal smoothing is dangerous because fast non-rigid movements can easily become physically implausible when blurred over time.
Approach	Smaller variations indicates rigid movement and benefit from more substantial smoothing.
Approach	Our best efforts are to improve C – the number of bits from each marker observation.
Outcome	One drawback to our approach is the loss of secondary kinematic motion, such as the sway of loose cloth.
Approach	Our work differs from [Anguelov et al. 2005] because our hole filling procedure does not assume a skeleton that drives the surface and our procedure estimates a single coefficient per example.
Approach	For the pants capture, we iteratively refine a set of 27 extreme poses which were captured specifically for filling holes.
Background	As a result, they recover anywhere from 1.65 to 2.04 bits per marker.
Approach	Relaxing the constraint to distances in 3D (surface distance is always more than the distance in 3D), we can use strain to exclude possible correspondences.
Outcome	As a result, our system is capable of capturing a full range of motion with folding and occlusion.
Background	MeshIK works by choosing a combination of deformation gradients from the examples and then solving for the missing point locations.
Outcome	Because MeshIK does not use velocity information, the resulting animation appears damped.
Approach	In this framework we can accurately minimize the number of neighbors required for correspondence and observe folds better.
Approach	Large variations in location indicate non-rigid movement and consequently receive little smoothing.
Outcome	In most cases, we observe more than 9 bits of strain information.
Approach	These holes appear in different places in different meshes and we create complete meshes in an iterative method.
Background	In contrast, methods based on the Laplacian of the mesh ([Sorkine et al. 2004]) do little to penalize these strains and can show many artifacts around the edge of the mesh.
Approach	Each marker in the printed pattern has a randomly chosen color, subject to the constraint that neighboring marker colors must be dissimilar.
Outcome	Depending on the lighting and camera configuration, we get anywhere from 5 to 7 bits.
Outcome	One of our major contributions is a data driven approach to hole filling: we fill holes with previously observed sections of cloth.
Approach	In subsequent sections we adopt the following strategy: maximize information obtained from marker color and eliminate the information needed from neighbors.
Challenge	The primary challenge is to increase marker density while correctly assigning correspondence between markers.
Approach	These two goals are in tension: small markers are less discriminative.
Outcome	Cloth capture makes it easy to capture large amounts of cloth, including fast light cloths that create instabilities in simulation.
Approach	We suggest markers per megapixel as an appropriate metric for comparison ( figure 3 ) because it measures the method instead of the equipment.
Approach	First, deformation gradients naturally yield cloth like properties.
Approach	This approach works from flat regions in the first iteration to foldy regions in the later iterations.
Approach	In order for a small basis to adequately express a full range of motion, each basis pose must be an extreme configuration.
Approach	Note that this is effectively less than four colors!
Outcome	Our results include several challenging examples: a wrinkled shirt sleeve, a dancing pair of pants, and a rag tossed onto a cup.
Approach	This measures distances appropriately in parts of the scene where the cloth is receding from view and discourages links between markers with wildly different tilts.
Background	We recommend readers unfamiliar with these techniques refer to [Forsyth and Ponce 2002].
Approach	Both of these computations are easier than detecting occluding contours.
Approach	We use a novel data driven hole-filling technique to fill occluded regions.
FutureWork	We plan to pursue more tools to edit and repurpose captured data.
Outcome	Much of the cloth is in contact with the floor and unobservable – yielding fewer bits of strain.
Approach	Instead, we insert proxy points for knee and hip joints in each of our basis meshes.
Outcome	As a result, we determine correspondence using regions that are 25 times smaller than in previous work ( figure 6 ).
Approach	Marker color and strain constraints are more useful than neighboring markers because they place fewer requirements on local cloth geometry.
Background	These descriptors are often mismatched and require significant pruning.
Approach	We use a size adjusted gaussian to smooth in this reference frame.
Outcome	Our pants animation is by far the most challenging, and we analyze some of the details a little more closely.
Approach	The process is iterated for increasing thresholds on the affinity value in the first stage, using the portions of the image where detection failed in previous stages.
Background	Previous work in cloth motion capture has focused on placing high density markers in correspondence between multiple views.
Approach	We use the conservative estimate of C = 5 bits per marker.
Challenge	However, capturing large amounts of data is far easier than simulating large amounts of data and provides more control than image based rendering.
Approach	For each hole in each frame, we cut out the missing region plus a ring of two triangles around the region.
Approach	The second stage takes the center of mass of each blob from the first stage, computes the mean color and grows a region based on distance to the mean color (it is computationally intractable to use this as the first stage of the blob detection).
Approach	Our analysis is based on the information entropy definition: H(X) = − ∑ n i=1 p(x i ) · log 2 x i .
Approach	Our gaussian noise model has a single free parameter, the variance, which must be computed empirically for each recording setup.
Approach	The 3D locations of these points are recreated in each frame by averaging points near the seam.
Background	These methods have several advantages: simulation gives significant user control and produces higher resolution meshes while image based rendering techniques produce more accurate illumination.
Background	They introduce a rudimentary strain metric, as measured along the surface, to rule out incorrect matches.
Approach	The resulting transformed joints are used as constraint points in MeshIK, which produces the final output meshes.
Approach	When the surface is heavily curved only small portions of the surface are visible before the cloth curves out of view.
Approach	This is better than label propagation methods.
Challenge	Many regions on the surface are impossible to observe due to occlusion.
Background	[Scholz et al. 2005] improve upon [Guskov et al. 2003] by creating a non-repeating grid of color markers.
Approach	However, for pants the relationship is more complex: the fact that no folding occurs in a small bend does not imply that folding will be absent in a larger bend.
Approach	These points are created once per garment by hand clicking on photos of the each seam.
Approach	The first discards reconstructed points that cause physically unrealistic strain on the surface of the mesh and the second constrains our search for correspondence.
Approach	When neighborhoods are not used, there is no structural ambiguity.
Approach	This procedure has a number of advantages.
Approach	The second tool is information theory: we look at the predictive power of different cues in a capture system.
Background	Results include a human wearing a shirt and a skirt captured using eight 1K x 1K cameras.
Approach	To achieve this, we need markers that are both small in scale and highly discriminative.
Challenge	In these regions correspondence is essential for detailed reconstruction yet can be challenging to identify.
Background	Their work identifies parameterization as one of the key aspects of cloth capture.
Outcome	Because the identity of the marker is overspecified, there are few mistakes.
Outcome	Like human motion capture, this tool requires significant engineering effort.
Outcome	The output is a sequence of triangle meshes with static connectivity and with detail at the scale of individual markers in both smooth and folded regions.
Outcome	In our video, we show some of the uses of this data, including editing using [Kircher and Garland 2006] and posing using [Sumner et al. 2005].
Approach	We optimize our correspondence technique by analyzing the information provided by different cues.
Approach	We evaluate previous work by examining the quality of the reconstructed cloth in still images and video.
Outcome	We make three main contributions: we improve the color pattern and matching procedure to get more information per marker, we introduce strain constraints to simplify correspondence and we create a data driven hole filling technique that splices previously captured cloth into the mesh.
Approach	First, we fill all holes with a naive linear algorithm (specifically, we triangulate across gaps and use barycentric coordinates to place the missing points – this gets the job done, but works poorly).
Approach	We accomplish this through an iterative algorithm where we alternate between computing correspondence and pruning bad matches based on those correspondences.
Outcome	An added attraction of cloth capture is that complex interaction between the cloth and the body is recorded without complicated human models.
Approach	To detect markers, our code looks for uniformly colored blobs in two stages: first regions are built by growing neighborhoods based on similarity between pixels.
Background	While successful, their static reconstructions show numerous correspondence errors.
Approach	Strain naturally fits in to our information theory framework: if strain excludes 87.5% of the possible correspondences, then strain has added 3 bits (because log 2 (1 − 0.875) = −3).
Approach	Our video sequences were taken with synchronized firewire cameras (Foculus FO214C) with a capture resolution of 640 x 480 and a capture rate of 24 frames per second.
Approach	In contrast, our iterative approach relies on strain constraints – which require computing the distance between a point and a line, and color detection – which requires averaging color within a marker.
Approach	Our strain constraint is based on the work of [Provot 1995] who noted that strain in cloth does not exceed 20% in practice.
Approach	As a result we use flexibility preserving smoothing, a procedure that smoothes rigid movement more heavily than non-rigid movement.
Background	For more reading on information theory, consult [Cover and Thomas 1991].
Approach	In the first iteration, we require three neighbors to make a match.
Background	When working with cloth, markers are typically painted on the surface.
Approach	To do this, we define affinities a i, j between image marker i and parametric marker j.
Approach	Our cloth was printed by a digital mail order fabric printing service.
Challenge	In the acquisition process, occlusion inevitably creates holes in the reconstructed mesh ( figure 8 ).
Approach	We can compare our work to previous methods using this framework ( figure 6 ).
Approach	As a result, we opt for the smallest markers that we can reliably detect and we make small markers more distinctive.
Outcome	Finally, we demonstrate that cloth capture is reusable by animating a pair of pants using human motion capture data.
Approach	This method is sensitive to image noise and can produce oversized regions when the color boundaries are smoothed.
Outcome	Our capture results are best evaluated by looking at our video and figures 1,12,13.
Approach	We insert artificial points where two pieces of fabric come together.
Approach	To maximize the information contained in the color of each marker, we print colors that span the gamut of the printer-camera response, then use a gaussian color model (section 4.1).
Outcome	The resulting surface meshes have an isometric parameterization and maintain static connectivity over time.
Approach	Adequate lighting is critical: from our experience fewer lights degrade performance due to harsh shadows and dim lighting causes motion blur through slower shutter speeds.
Outcome	Camera setup and calibration are time consuming and the equipment is costly.
Approach	Our work falls in the third category: regions of contant color.
Background	These methods have far fewer markers per megapixel because they affix individual markers.
Approach	Then, we reconstruct the point locations from the deformation gradients.
Approach	We capture the motion of cloth using multiple video cameras and specially tailored garments.
Background	Simulation and image based rendering both provide methods to generate animation of cloth (a limited simulation list includes [House and Breen 2000; Terzopoulos et al. 1987; Choi and Ko 2002; Bridson et al. 2003; Baraff et al. 2003] and a limited image based rendering list includes [Bradley et al. 2005; White and Forsyth 2006; Lin and Liu 2006; Scholz and Magnor 2006]).
Approach	For each frame of animation we set the proxy points’ locations according to joint angles in the skeletal mocap data.
Background	The most common errors are marker mismatches and are observable in reconstructions by local strain in the reconstructed surface.
Background	They use thin-plate splines to fill holes.
Outcome	Our marker observations average 56 pixels per marker per image.
Approach	For the cloth toss sequence, we chose the simpler approach: iteratively refine the entire sequence.
Challenge	The 3D location of a region is determined by intersecting rays through the corresponding observations in the image set ( figure 4 ).
Approach	By penalizing elements that deviate in this matrix, we have a fairly direct penalty on large changes in scale or strain.
Approach	The size of the neighborhood is chosen so that we get more than enough bits to meet our information budget (log 2 M bits – typically 11 to 13).
Challenge	Illumination is also problematic and takes two forms: direct illumination on a lambertian surface and indirect illumination.
Approach	Finally, blobs are thresholded based on size.
Approach	We solve the correspondence problem both by improving the pattern printed on the surface of the cloth and by improving the method used to match regions.
Outcome	This metric is designed to predict scaling as technology moves from the research lab to the professional studio.
Challenge	In contrast, small errors in regions of the cloth that move rigidly are typically easy to observe.
Approach	This iterative approach allows us to match without neighborhoods.
Challenge	Next, correspondence is determined by matching regions across multiple views.
Approach	In the final iteration, markers are matched using color and strain alone.
Outcome	Strain information is difficult to compute and depends on the geometry of the surface and the orientation of the camera.
Approach	However, structural ambiguities in the pattern subtract information lost to determine which neighbor is which.
Approach	It takes log 2 M bits to determine the identity of each observed marker on a garment with M total markers.
Approach	Next, we need to determine the neighborhood relationships.
Approach	We capture the shape of moving cloth using a custom set of color markers printed on the surface of the cloth.
Background	Methods such as [Lipman et al. 2005] don’t allow vertex constraints.
Approach	Each affinity is a product over different cues.
Outcome	As a result, MeshIK is most useful when a basis is carefully chosen to prevent extrapolation artifacts.
Background	Previous work, such as [Scholz et al. 2005], yields pleasing results.
Approach	These frames are then used as examples in MeshIK to hole fill in the rest of the sequence.
Background	As shown in figure 5 , occluding contours are both common and difficult to detect.
Approach	The advantage of this apporach is that the example poses are chosen to capture the relevant degrees of freedom – yielding better results.
Approach	Initially, we learned this threshold from labelled data, but we found that changing it by several orders of magnitude had little effect on our results.
Approach	For each marker, we construct a covariate neighborhood (a fitted ellipse) and vote for links to the three closest markers with similar covariate neighborhoods.
Approach	While our pattern is composed of tesselated triangles ( figure 5 ), any shape that tiles the plane will work (squares and hexagons are also natural choices).
Approach	Second, our mesh is triangular and there are three possible neighborhood rotations, yielding A = log 2 3 = 1.59 bits of structural ambiguity.
Background	For [Scholz et al. 2005], the equation in section 3.1 is reduced to I = 9 ∗ C − A because they use 8 neighbors and no strain constraints.
Approach	Deformation gradients are the transformation matrix between triangles in two poses of the mesh.
Approach	To downweight the linear data, we select the examples with the highest percentage of viewed points in the missing section.
Approach	In this approach, we fit deformation gradients for the missing section to a combination of deformation gradients in other observed sections.
Approach	The largest challenge is that captured cloth meshes contain only points on the cloth surface, so we do not know joint locations.
Background	[White et al. 2005] introduce a combined strain reduction/bundle adjustment that improves the quality of the reconstruction by minimizing strain while reconstructing the 3D location of the points on the surface of the cloth.
Approach	In the pants sequences, we used seven lights totalling 1550 Watts to illuminate the scene.
Approach	These points are then connected to a small set of nearby triangles in the original mesh.
Approach	Because independent information adds linearly, we can compute the information needed to meet this threshold by adding information from the different cues: color, neighbors and strain.
Approach	We use reprojection error to prune bad matches (reprojection errors average 0.3 pixels and we discard points with errors larger than 2 pixels).
Approach	These comparisons must be made in the proper color space: we photograph the surface of the printed cloth with our video cameras to minimize the effect of non-linearities in the printing process.
Approach	In addition, we cannot increase camera resolution without bound because camera bandwidth becomes very expensive.
Outcome	Using our MATLAB implementation of MeshIK, this process takes around 5-10 seconds per frame.
Outcome	In addition, the camera images were not output in a linear color space, reducing the number of color bits.
Approach	We do not correct for indirect illumination.
Approach	We fill these holes using reconstructions of the same surface region taken from other points in time.
Challenge	Efficiency is important because camera resolution and bandwidth are expensive: the goal is to get more performance from the same level of equipment.
Approach	We select a reconstruction technique based on deformation gradients [Sumner and Popovic 2004].
Approach	In practice, we never observe complete ex- ample meshes – each mesh is missing some triangles.
Approach	We combine information from three cues to establish correspondence: marker color, neighboring markers and strain constraints in the reconstruction.
Approach	We produce a mesh by forming equilateral triangles for sections of cloth that are printed with a contiguous pattern by referencing the triangle stucture of markers on the cloth.
Approach	To do this, we take a local region around each vertex in the mesh (typically 25 points) and compute a rigid transformation to previous and subsequent frames.
Background	Over the course of roughly half a dozen papers on cloth capture a prevailing strategy has emerged.
Approach	All links that receive two votes (one from either side) are kept while the rest are discarded.
Approach	We do some pre-processing to get marker locations and connectivity from raw images.
Background	[White et al. 2006] introduce the use of silhoutte cues to improve reconstruction of difficult to observe regions.
Approach	We use the same 27 bases poses for MeshIK based reconstruction.
Outcome	In combination, these two modifications eliminate the need for neighborhood information in the final iteration of our algorithm.
Approach	In our comparison, we use C = 1.93 bits for color information from their method (five percent error, with equal probabilities for all remaining choices).
Approach	For simple objects such as a cylinder, a small bend (for example) is sufficient to extrapolate to a larger bend [Sumner et al. 2005].
Approach	To correct for variations in direct illumination, we remove the luminosity component from our color modelling.
Outcome	If we factor out the pixels lost to background, we get 3500 3D markers per foreground megapixel or 282 foreground pixels per recovered 3D marker.
Outcome	Our method gets more information per pixel than previous methods by drawing from the full colorspace instead of a small finite set of colors in the printed pattern.
Approach	We use occlusion free meshes from other frames to automatically interpolate holes.
Background	They cite an error rate of five to ten percent.
Approach	Final correspondence does not require neighborhood information.
Approach	Aligning the regions with this transformation, we compute the movement of the vertices in this reference frame as a proxy for rigidity.
Approach	The first, markers per megapixel, is a measure of efficiency in capture systems.
Challenge	Folds and occlusion are common, especially when dealing with real garments such as pants where limbs block interior views and cloth collects around joints.
Approach	Occluding contours, which are common in heavily folded regions, no longer disrupt the matching procedure.
Approach	In heavily folded regions, often neighboring markers on the image do not neighbor on the surface of the cloth.
Background	Each marker has five possible colors and all three by three groups are unique.
Approach	Our recovered markers are at the center of each triangle – so we average points to get out the vertices and subsequently the original mesh.
Background	Additionally, the complexity of the color pattern limits the method to simple geometry.
Approach	We introduce flexibility preserving smoothing – a method similar to anisotropic diffusion [Perona and Malik 1990] that smoothes near-rigid movement without effecting flexible deformation.
Approach	Code is written in MATLAB.
Approach	Overall, we observe that constant color markers perform the best.
Approach	We suggest two tools to evaluate marker-based capture systems.
Approach	We use the automated calibration technique in [White and Forsyth 2005], but any standard calibration will work ([Zhang 2002] and [Bouguet 2005] are good choices).
Approach	We use the points from the ring of known triangles around the hole as constriants in MeshIK.
Approach	Specifically, neighboring markers are observed only when the cloth is relatively flat.
Approach	We compute markers’ coordinates in space using correspondence across multiple synchronized video cameras.
Approach	After each iteration we shrink the size of the neighborhood used to match.
FutureWork	Future work in cloth capture should involve more cameras, higher resolution (leading to smaller denser markers), different garments and different materials.
Challenge	Our goal is high marker density in the 3D reconstruction – especially in regions with high curvature.
Approach	In this paper we use folding to refer to local phenomena such as wrinkles around a knee and occlusion to refer to large scale effects such as one limb blocking the view of another.
Background	This allows substantially larger sections of cloth and virtually eliminates correspondence errors.
Approach	Correspondence is determined from color information in small neighborhoods and refined using a novel strain pruning process.
Outcome	Our experiments suggest that loss is largely attributable to camera response because larger markers produced substantially more information.
Challenge	One would like to fill these holes with real cloth.
Background	[Pritchard and Heidrich 2003] used cloth with unique line drawings as markers.
Background	As a result A = 3 bits.
Approach	Links that bridge markers with conflicting color information are also discarded (typically on internal silhouettes).
Approach	On a P4 2.4 GHz machine, acquisition takes roughly 6 minutes and mesh processing 2 minutes per frame.
Approach	We do this by picking marker color from the full colorspace instead of a small discrete set of colors.
Challenge	Reconstruction is done independently on a frame by frame basis and the resulting data is smoothed and interpolated.
Outcome	As a result, we terminated the correspondence algorithm at N = 2.
Approach	Our still captures were taken using a digital SLR camera and then downsampled to approximate available video resolutions.
Approach	We start by converting each image to HSV, disregarding the luminosity (V) and using polar coordinates to compute distances in hue and saturation.
Outcome	With an average of 2405 observed markers, there were 979 3D markers per megapixel.
Outcome	In contrast, capture is relatively quick (our code is 8 minutes per frame in MATLAB); parameters are set by selecting the type of cloth [Bhat et al. 2003] and tangling is relatively uncommon.
Approach	However, larger marker regions have the disadvantage that curvature can cause local occlusions and prevent observation of the entire region.
Approach	The most restrictive aspect of MeshIK is that it requires example meshes without holes.
Approach	Second, we compute structural ambiguities in their method which account for uncertainty in observations.
Challenge	First, a pattern is printed on the cloth surface such that small regions of the pattern are unique.
Background	These markers can be broken into three categories: complex surface gradients [Pritchard and Heidrich 2003; Scholz and Magnor 2004; Hasler et al. 2006] (typically detected using SIFT descriptors [Lowe 2004]), intersecting lines [Tanie et al. 2005] and regions of constant color [Guskov and Zhukov 2002; Guskov et al. 2003; Scholz et al. 2005].
Approach	This neighbor is one of four possible neighbors – thus it takes two bits to specify which neighbor we found (A = 2).
Approach	We found that MeshIK ([Sumner et al. 2005]), a tool originally developed for mesh posing and animation, is appropriate for filling holes in cloth.
Background	Most high density full frame-rate capture has focused on cloth, however, there has been some recent work enhancing human motion capture [Park and Hodgins 2006].
Challenge	However, there is a distinction in scale and different methods are required to solve each problem.
Approach	Then, we do another pass through all the data, where we replace the linear sections with sections created using MeshIK on the linearly filled data.
Approach	We print a random colored pattern on the surface of cloth in an attempt to maximize the information available per pixel.
Challenge	Both phenomena are symptoms of the same problem: views of the surface are blocked by other parts of the surface.
Challenge	When a surface is heavily folded, contiguous visible regions are often small and oddly shaped.
Approach	Additionally, because cloth cannot stretch much before ripping, we use strain constraints to eliminate candidates in an iterative search for correspondence.
Approach	From a system view, the printer-camera response is a sequence of lossy steps: we generate a color image on a computer, send the image to the printer, pose the cloth, and capture it with a camera.
Approach	Second, deformation gradients can be converted into vertex locations by inverting a linear system, allowing us to specify vertex locations as constraints.
Background	This system uses a Kalman smoothing filter and is heavily damped.
Approach	By doing simple bit calculations, we direct our design efforts more appropriately.
Challenge	Common simulation complaints include long computation times, significant parameter tweaking and tangling.
Approach	Conversely, if a decent amount of folding occurs in a small bend, we do not expect extreme folds in a corresponding larger bend.
Approach	We select a set of examples of the enlarged region, then use MeshIK ([Sumner et al. 2005]) to reconstruct the surface.
Outcome	However, once these obstacles have been overcome, capturing large amounts of data is relatively easy.
Outcome	We have brought cloth capture from constrained laboratory examples to real settings by providing robust methods for dealing with occlusion and folding.
Approach	In contrast, in the last iteration, no neighbors are necessary.
Approach	In the recognition stage, we detect markers by comparing colors to a known color.
Approach	This variance determines the color response for the entire setup — smaller variances mean more bits from color.
Approach	To acquire a 3D point cloud of the cloth surface, we print a colored pattern on the cloth, sew it together, and record its motion using multiple synchronized cameras.
Background	They use a stereo camera to acquire 3D and SIFT descriptors to establish correspondence.

Background	More accurate results may be obtained by projecting structured light patterns on the cloth (see Zhang et al. 40 for an overview).
Outcome	The final values of the parameters from the two trials differ in part because the variability of the parameters is still fairly high ( Fig. 11 ).
Approach	We designed a few simple experiments to capture the dynamics of the different types of fabrics and the air/cloth interaction.
Approach	The air drag parameters were fixed for this experiment to the mid point of their range of values.
Outcome	We show the match between the video footage and the simulated motion on the calibration experiments, on new video sequences for the swatches, and on a simulation of a full skirt as shown in the image on the previous page.
Approach	We perform two estimation experiments for each fabric, a static test and waving test.
Background	Studies have shown that the receptive fields of simple cells in the macaque cortex act as edge or line detectors, responding to oriented edges or lines in natural scenes 19 , 35 , 10 .
Challenge	Some parameters can be chosen based on the animator’s intuition about the fabric—a knit fabric is more stretchy than a woven fabric such as linen, for example.
Approach	The waving motion of fabrics in simulation is affected by their dynamic parameters.
Approach	The importance or sensitivity of a parameter p depends on its local gradient ∂E ∂p ; it relates a small change in parameter value to a change in the error value.
Background	Rather than computing shape at every time instant independent from the next, it can be advantageous to integrate images over time to improve accuracy.
Approach	In the waving test, one of the top corners of the fabric is fixed and the other corner is moved back and forth ( Fig. 7 ).
Approach	We perform optimization on two trials for each fabric; the results are shown in Fig. 8 and Fig. 9 .
Approach	We define the resulting orientation image as an angle map, shown in Fig. 1 .
Outcome	For instance, in the following example of fleece waving, we choose the parameters from experiment 2.
Background	The motion of fabric is determined by resistance to bending, stretching, shearing, external forces, aerodynamic effects, friction, and collisions.
Outcome	We see that each fabric in simulation has a minimum error when compared to its counterpart in reality.
Approach	In the course of running our experiments, we discovered that a linear drag model such as that used in previous cloth work 4 , 9 was not able to capture dynamic aspects of cloth.
Approach	We also accurately measure the position of the two top corners using a Vicon motion capture system.
Outcome	Each trial took approximately 50 hours to converge on a 2.8GHz Intel Xeon processor (approximately 600 iterations of simulated annealing).
Approach	In essence, our experiments were designed to be a calibration setup for estimating the static and dynamic parameters of a cloth simulator.
Approach	The experiments are easy to perform, capture, and repeat; yet they demonstrate the complex dynamics of cloth motion.
Approach	For this reason, we started the optimizations on the two trials (per fabric) with the same initial guess and chose parameters (optimized) that minimized the total error on the two trials.
Background	Lahey provides a comprehensive overview of cloth hysteresis models from the perspective of computational fabric mechanics 23 .
Approach	These fabrics exhibit a wide range of static and dynamic behavior and span a large range of real fabrics.
Outcome	We had more success in matching realistic cloth motions by using higher-order explicit methods.
Outcome	The cloth model was not the main focus of this research, yet in early versions of the system it was often the bottleneck in achieving appealing results.
Background	Cloth parameter estimation has been studied in the textile community (for an overview, see Breen and colleagues 17 ), but such methods have not yet enjoyed wide-spread use in the computer graphics community.
Approach	Total drag force is then a linear function of tangential velocity and a quadratic function of normal velocity, with an additional term k f that controls the degree of nonlinearity,        f drag = −a 1 + k N k |v f |v N | N 2 | 2 |v v N N | + k T v T where a is the area of the given triangle.
Outcome	Hence, our approach should generalize to any parametrized cloth model that produces a sufficiently rich set of physically realistic motions.
Approach	Our algorithm compares the two sequences frame by frame and computes an average error across the entire sequence.
Approach	The likelihood that it will take a step in a direction that is not locally optimal is a function of the temperature ( Fig. 5 ).
Approach	We simulate the fabric for all points in this coarse set and compute the error for each point by comparing against the real fabric.
Approach	Initially, we used a first-order implicit Euler time integration scheme similar to the one described by Baraff and Witkin 4 .
Approach	We used four types of fabrics: linen, fleece, satin and knit.
Background	Extensive work has also been done on modeling collisions and friction.
Outcome	From the table, we see that the final error values are very close.
Background	Realistic virtual clothing is possible now because of recent advances in cloth simulation techniques 4 , 9 , 5 , 37 , 6 .
Background	This effect is particularly compelling for scenes that include both real and synthetic actors such as those with Yoda and Anakin Skywalker in Episode II: Attack of the Clones.
Outcome	These two figures show the progress of the optimization and indicate that the minimum corresponds to a visually compelling match.
Background	Despite this large body of work on cloth simulation models, little work has appeared in the computer graphics literature on estimating the parameters of these models so that they match the behavior of real fabrics.
Approach	S x S y E k silh = ∑ ∑ | A k real (i, j) − A k sim (i, j) | ( 6 ) i=0 j=0 where 1, inside silhouette A k (i, j) = 0, otherwise ( 7 ) The total error in frame k is E k = E k f old + αE k silh ( 8 ) where α is a user-defined weight that controls the relative contribution of the two terms.
Challenge	Cloth simulations are notoriously difficult to tune due to the many parameters that must be adjusted to achieve the look of a particular fabric.
Outcome	Similarly, extra damping introduced by the integration method makes crisp folds impossible to match.
Outcome	Instabilities in the collision handling will cause perceptible quivering in the motion of cloth.
Outcome	We show the match between the video footage and simulated motion on the calibration experiments, on new video sequences for the swatches, and on a simulation of a full skirt.
Approach	We optimize for nine parameters in the waving test: the six cloth stiffness and damping parameters and three air drag parameters ( Fig. 10 ).
Approach	We optimized on the first 50 frames of the sequence.
Outcome	For more complex garments, choosing the parameters via optimization on small, flat swatches may not be sufficient because the shape of the garment is determined by darts, pleats and by the interplay of different fabrics (wool, lining, and interfacing, for example).
Background	Baraff and Witkin describe a cloth model that uses stiff springs with implicit time integration 4 .
Background	More distantly related are techniques for computing the geometry of cloth from images.
Approach	We use simulated annealing to find the parameters that minimize the error function given in eq.
Approach	While this method offers the advantages of familiarity and automatic bounding of error, it is rather slow, and recent work suggests that using 2nd-order backward differences 9 or Newmark schemes 7 may be a better choice.
Approach	Simulated annealing is used to minimize the frame by frame error between the metric for a given simulation and the real-world footage.
Approach	The underlying meshing is triangular, making clothing modelling easier.
Outcome	The drawback of this technique is speed, because the system must check for collisions every time it evaluates the state derivatives (as opposed to once every collision timestep as in Bridson et al. 6 ).
Approach	For collision handling, we use a model similar to Bridson and colleagues 6 which combines repulsion forces with impulses to robustly prevent all collisions before they occur.
Approach	En route to the metric used in the experiments described here, we tried a number of other metrics: comparing the overlap of the silhouettes, the distance function between silhouette edges, and using information from internal edges marked on the fabric.
Approach	The angle map, which measures the local orientation of the projected pattern, has a constant value when the surface is planar and varies at folds.
Approach	We wanted to use a model that was sophisticated enough to capture the detailed dynamic behavior found in real fabrics but still straightforward to implement.
Background	In their paper, Baraff and Witkin describe a set of C(x) consisting of an in-plane stretch term, an in-plane shear term, and an out-of-plane bending term, giving a total of six parameters we can use to tune the internal cloth model.
Background	Two examples of promising work along these lines are Carceroni and Kutulakos 8 and Torresani et al. 34 ; both studies demonstrated reconstructions of moving cloth.
Background	For example, Bridson et al. 7 introduces a scale-independent bend model with encouraging results.
Approach	The optimizer is free to eliminate this behavior or other terms of this equation by setting the corresponding parameters to zero.
Approach	Our choice of a cloth model was guided by two principles, realism and practicality.
Background	Cloth self-collision is handled either by untangling the cloth 37 , 39 , 3 or by preemptively avoiding collisions 30 , 20 , 6 .
Background	In such scenes, the virtual clothing must move and be rendered so that it blends in seamlessly with the motion and appearance of the real clothing in the scene.
Approach	We found it useful to reset the simplex with the current best solution when the temperature reduces by a factor of 3.
Outcome	Our only major addition was a simple nonlinearity we introduced into the drag model.
Background	Progress is being made in these areas, however, and cloth models are continually improving.
Background	The model developed by Baraff and Witkin formulates the energy of a particular triangle in terms of so-called condition functions C(x) such that the total potential energy associated with the system is given by E u = k s C(x)C T (x) ( 1 ) 2 where k s is a stiffness coefficient associated with the particular condition function.
Approach	We sum the error across all frames to compute the overall error across the entire sequence.
Background	First, there might not be a direct and simple mapping between the parameters for a particular cloth model and the Kawabata parameters.
Approach	The gradient mask is non-zero at regions of high gradients, corresponding to folds, and zero at planar regions.
Approach	If instead, we were to optimize on more complicated garments, then such tight control of the initial conditions is unlikely and a statistical metric might be preferable.
Approach	We evaluated the parameters obtained from optimization on longer sequences (150 frames).
Background	Explicit time integration approaches 18 use weaker springs for stretching and shearing, often explicitly limiting the amount of stretching 29 , 6 .
Background	Coarse estimates of the time-varying geometry of cloth can be computed using traditional stereo matching techniques by using two or more cameras and treating each time instant independently (see Scharstein and Szeliski 31 for an overview).
Approach	We pre-multiply this difference with the gradient mask, which helps to emphasize the differences in fold regions over planar regions ( Fig. 2 ).
Outcome	Parameters with high variability are estimated poorly, because their values do not contribute sufficiently to the error.
Approach	We then compute the SSD of the angle values for all overlapping points in the two angle maps.
Outcome	The results show that the parameters obtained from our optimization approach approximately capture the static shape and dynamic properties of skirts of different materials.
Outcome	The space of possible metrics is vast, of course, but one class of metrics that we did not experiment with are statistical metrics that compute a function of the shape of the fabric across time rather than evaluating the match on a frame-by-frame basis.
Background	While nonlinear models such as the buckling behavior of Choi and Ko 9 could potentially capture more realistic details of cloth, there is no straightforward way to scale the parameters of these models to meshes of varying resolutions.
Approach	We also validated the estimated parameters on a long sequence actuated by a robot ( Fig. 15 ).
Approach	To estimate all the cloth parameters, we identify simple static and dynamic calibration experiments that use small swatches of the fabric.
Approach	In our implementation, we use the G2/H2 quadrature pair with kernel size 12 as the basis filters.
Approach	We compare each of the four optimized angle maps from simulation (corresponding to the four fabrics) with the four angle maps computed from video.
Outcome	These parameters produced four distinct and recognizable fabrics when applied to a more complex simulation of a skirt as it was driven by motion capture data from a human figure.
Approach	This corresponds to a very coarse sampling of the parameter space.
Outcome	We get consistent estimates for parameters that have lower variability (e.g., bend, stretch).
Approach	We perform the static and waving tests on a small swatch of each fabric.
Approach	The two trials have different separation distances between the top corners.
Outcome	Unfortunately, we found that implicit integration introduced damping which could not be eliminated by optimizing cloth parameters.
Outcome	Such a metric might, for example, compute the average number of folds across a time sequence rather than looking for a fold to appear at a particular location on the swatch.
Approach	The parameters obtained from the simple experiments were used to simulate skirts and other complex fabric motions.
Approach	The metric is tuned to be most sensitive along folds and to discount planar regions.
Approach	We compute the angle map at every frame in simulation from this sequence.
Approach	The metric also penalizes the silhouette mismatch between the two sequences.
Outcome	This result is consistent with our intuition that static tests cannot be used to estimate dynamic parameters like stretch and shear damping or air drag and motivates the waving test, which excites both the static and waving parameters.
Approach	The dynamic parameters were initialized using a random guess.
Approach	The addition of the |v N | 2 term in the denominator which makes the force asymptotic as v N → ∞ was partially motivated by the observed phenomenon of drag crisis 14 , where under certain circumstances the drag can actually drop at the onset of turbulence 1 .
Approach	Finally, we used the optimized parameters to simulate a skipping motion of a human actor wearing a skirt ( Fig. 16 ).
Approach	More importantly, its input parameters are independent of meshing, so that parameters recovered on one mesh (the test swatch) can safely be transferred to another (the skirt).
Background	An important exception is the work by Breen 5 who used the Kawabata system 22 to measure bending, shearing, and tensile parameters by subjecting a swatch of fabric to a series of mechanical tests and measuring the force needed to deform it into a standard set of shapes.
Approach	From the light-striped video sequence, we compute the dominant orientation for each edge pixel by convolving it with a steerable filter bank 13 .
Approach	To generate this error map, we compared the angle map from one frame in video with several angle maps in simulation.
Approach	Before we describe the details of the optimizer, we look at the error space of the angle map metric, which gives us useful insight about the parameters of the system.
Approach	Prior to optimization, we perform an exhaustive search for each fabric, where we choose four values for each cloth parameter across its entire range.
Approach	We used data from a full body optical motion capture of the actor performing the same skipping motion (in another trial) to drive the character for the cloth simulation.
Approach	This metric compares two video sequences of cloth and returns a number that measures the differences in their folds.
Approach	The experiments with the swatches were carefully controlled to have initial conditions for the simulation that matched those seen in the video.
Background	Work on cloth modeling in computer graphics has focused on developing dynamic simulation techniques that are both realistic and fast.
FutureWork	Our hope is that this work will promote a more rigorous evaluation of various cloth models, especially with respect to how accurately they match reality, and perhaps lead to creation of a standardized set of benchmarks for cloth simulation models.
Background	Researchers in computational neurobiology hypothesize that the human perceptual system is sensitive to moving edges in video 11 , 12 , 36 .
Approach	Parameters with low variability have high sensitivity and are estimated reliably for a given experiment.
Background	However, Jojic and Huang did not treat the problem of measuring dynamic parameters or demonstrate accurate results across a range of fabric types.
Background	Various potential field methods have been used for general collision detection and response 33 , 32 .
Approach	We designed the waving motion to roughly match the types of motion occurring in real garments such as skirts.
Background	Cloth modeling has a long history, dating back to work in the textile community from the mid-1930s by Peirce 27 .
Background	Haddon and Forsyth 15 , 16 describe a learning approach for detecting and grouping folds (and grooves) in images of fabrics.
Approach	In our experiments, we normalize the effects of lighting and material reflectance by projecting a structured light pattern of horizontal stripes onto the fabric.
Background	Real fabrics exhibit a wide variety of motion ranging from soft and flowing (satin) to stiff (linen).
Approach	We used a a Mitsubishi PA-10 robot arm to move the corner point along a simple sinusoidal trajectory, thereby ensuring that we had the same input motion across different fabrics.
Outcome	However, separating repulsion forces from the cloth internal dynamics and applying them outside the Runge-Kutta solver affected stability and resulted in visible artifacts.
Approach	We have found that this strategy allows the optimizer to locate a good minimum of the space.
Background	This model was subsequently adapted to reduce the over-damping due to implicit integration 9 .
Approach	The parameters must also be independent of the resolution of the mesh so that they can be identified on low resolution swatches and applied to higher resolution garments.
Approach	Hence, our perceptually motivated metric for cloth compares two video sequences, one from simulation and one from the real world, and returns a number that measures the differences in their folds.
Background	Second, the Kawabata system does not measure dynamic cloth parameters, e.g. air drag or damping, which are of key importance for moving cloth.
Approach	We performed two trials per experiment, each with slightly different initial conditions and optimized on the first 50 frames of video in each trial.
Approach	For a fixed separation between the top corners, different fabrics attain different static shapes as shown in Fig. 6 .
Approach	Simulated annealing initially explores the space in a semi-random fashion and eventually takes downhill steps.
Approach	We note, however, that (as they allude to in footnote 5) energy should scale linearly with triangle area to ensure scale independence.
Approach	To achieve acceptable performance, we used a number of collision culling algorithms, including hybrid top-down/bottom-up update 24 , fast triangle reject tests 26 , and a curvature-based criterion for rejecting self-collisions that was first introduced by Volino and Thalmann 38 and later refined by Provot 30 .
Approach	Similarly, in simulation, we render the cloth shape using the current parameter values and project the same striped pattern, to get a striped simulation sequence.
Approach	We compute the projection matrices for the camera and projector using a calibration grid comprising of several motion capture markers.
Approach	In order to understand this disparity, we performed a set of optimizations (on a single fabric) with very similar initial values.
Approach	We measured the mass and dimensions of the fabrics.
Approach	Instead of computing the gradient, we robustly compute the variability of the param∂p eters, defined as ∂E .
Background	Their technique can handle lighting effects caused by diffuse inter-reflections in cloth.
Outcome	Our cloth model does not diverge significantly from previous models discussed in the literature.
Outcome	Although the skirt is far more complex than the swatches that were used to determine the parameters, it is not as complex as many garments, for example, a form-fitting pair of pants or a tailored blazer.
Outcome	Different fabrics also exhibit different types of motion for the same input excitation.
Approach	We use simulated annealing for the optimization step with an optimization function that assesses the extent to which the folds in the simulated and physical fabric match.
Approach	To compute the variability, we perturb each parameter of the simulator individually up to ±0.20% of its value, compute the error and fit a quadratic to the data ( Fig. 4 ).
Approach	In our paper, we address this problem by using optimization to automatically determine these parameters from a sequence of video frames of the fabrics under consideration.
Approach	Because our intention was to apply the learned cloth model parameters to arbitrary garments with varying triangle resolution, it was also important that the cloth parameters correctly scale to varying resolutions of cloth.
Background	Choi and Ko introduced a bending energy model that more accurately captures the fine creases and bends of cloth 9 .
Approach	The static test give a good estimate for the static stiffness and bend parameters.
Approach	We used a value of 0.1 for α in our experiments.
Outcome	We captured the behavior of small swatches of fabric using a set of dynamic and static tests and demonstrated that the optimizer could identify appropriate simulation parameters from those tests.
Challenge	But not all the parameters of a cloth simulator are intuitive or map directly to measurements that can made by a system such as the Kawabata system 22 .
Outcome	More complex garments may require the hand design of additional tests that mimic particular behaviors or elements of the garment in isolation.
Approach	From the quadratic, the variability is computed as the change in parameter values that results in a 1% change in the error.
Approach	To calculate the drag force on a triangle, we decompose the average velocity on the face into two components, one normal to the surface (v N ) and one tangential (v T ).
Approach	This penalty is proportional to the difference between the two silhouettes, i.e., the number of mismatched pixels.
Approach	This match is evaluated by means of a shape metric that uses projected light to detect surface orientation in real and simulated fabrics.
Approach	We designed the swatch tests to span the space of behaviors that we expect to see in the final sequences of motion with the skirt so that all parameters can be tuned appropriately.
Background	Jojic and Huang fit parameters of a particlebased cloth model to fit a range scan of real cloth in a static rest configuration, draped over a sphere 21 .
Outcome	The metric that measures folds and silhouettes, in concert with the projector for the light stripes, proved to be a simple and effective metric that far outperformed our earlier attempts.
FutureWork	However, we believe that a more general solution for parameter identification using our framework is to simultaneously optimize across multiple trials of different experiments.
Approach	From the figure, it is evident that the error space is fairly noisy, with many local minima, motivating the need for a global optimization technique.
Approach	The initial values for the two trials are obtained from a coarse exhaustive search (four values per parameter).
Approach	This model has sufficient richness to produce a wide variety of cloth behaviors.
Approach	To demonstrate the power of this approach, we use our algorithm to find the parameters for four different fabrics.
Approach	A perceptually motivated metric based on matching between folds is used to compare video of real cloth with simulation.
Approach	This gives reasonable estimates for cloth parameters while avoiding the need to optimize directly on complex fabric geometries (e.g. skirts) involving many collisions.
Approach	We initialize the optimizer with the point corresponding to the minimum error.
Approach	The error across the entire sequence of length N frames is given by N E = ∑ E k ( 9 ) k=1
Outcome	However, there is a significant disparity in the final optimized values from the two trials.
Outcome	We use the system to find the parameters for four different fabrics.
Approach	We threshold the gradient of the angle map to get a gradient mask M k for each frame of video ( Fig. 1 ).
Approach	As with the static test, we initialize the static parameters in this test from a coarse exhaustive search.
Outcome	Different motions or larger sequence might further reduce the variability of the parameters.
Approach	We use a perceptually motivated metric to compare the motion of cloth in simulation with a video sequence of real fabric motion.
Outcome	Our metric captures the complex dynamics of cloth motion and also helps to distinguish between different fabrics.
Background	However, most fabrics have very complicated reflectance properties.
Approach	We choose the parameter set that minimizes the sum of the error from the two trials.
Approach	The results in this paper all use an adaptive 4thorder accurate Runge-Kutta methods with embedded error estimation 2 .
Background	In cloth, these edges correspond to folds, which are regions of high variation in shape.
Background	Several recent major movie releases have demonstrated that the motion of clothing adds greatly to the appearance of a virtual character.
Approach	We preprocess the input video sequence to compute the angle map at each frame.
Outcome	We expect that future application of our parameterestimation framework to other scale-invariant cloth models will provide even more realistic results.
Background	Although the Kawabata system can provide accurate measurements, these measurements are problematic for computer graphics cloth simulation problems for two reasons.
Approach	We used the model described by Baraff and Witkin as the basis for our cloth simulator 4 .
Approach	We chose to use the continuous simulated annealing method presented in Press et al. 28 , which combines the Metropolis algorithm with the downhill simplex method for continuous n-variable optimization.
Approach	Here, the actor repeats the same skipping motion (approximately) for the four different skirts.
Approach	We thus associate a stiffness coefficient k s and a damping coefficient k d with each of the C(x).
Approach	The error at any particular frame k along the sequence is S x S y E k f old = ∑ ∑ M k (i, j) · (θ real k (i, j) − θ sim k (i, j)) 2 ( 5 ) i=0 j=0 where (S x , S y ) is the size of the angle maps and θ real , θ sim are the angle values from real and simulation angle maps respectively.
Outcome	We see from the accompanying videos that real fabrics exhibit a wide range of interesting motions.
Approach	The linear term        is merely Stokes’s law 1 ; the quadratic term matches better the experimental behavior of macroscopic bodies in low Reynold’s number flow 14 .
Outcome	In this paper, we present an algorithm for estimating the parameters of a cloth simulation from video data of real fabric.
Outcome	Moreover, the model might need extra parameters to handle anisotropic effects, hysteresis and coupling effects (stretching along one direction causing shrinking in the other direction), all of which would need specialized tests.
Approach	We convolve the image with the filter bank, compute the filter coefficient responses, blur the coefficients using a gaussian kernel, and compute the dominant orientation from these coefficients.
Approach	In the static test, the two top corners of the fabric are held stationary, and the fabric is allowed to sag under gravity.
Approach	Instead, we apply repulsion forces inside the solver loop, so that the solver’s own internal error estimation can remove these artifacts.
Outcome	To match a video sequence accurately, the cloth physics model as well as the collision algorithms must be chosen carefully.
Approach	Because our framework for estimating cloth simulation parameters is independent of the cloth model, we can, in principle, select a specific model that meets a set of criteria such as accuracy or simulation speed.
Approach	In addition to the parameter values, we estimate the relative importance of each parameter for a given experiment by performing a perturbation analysis at the solution point.
Outcome	This paper describes an optimization framework for identifying the simulation parameters of cloth from video.
Background	One promising approach for modeling cloth parameters is to automatically search for parameters that match real, observed cloth.
Approach	The parameters are optimized on a set of static shots and motion clips of a small swatch of a particular fabric and then tested on a simulation of a full skirt made from that fabric.
Approach	For each fabric, we optimize for six parameters: stiffness and damping parameters for stretch, shear, and bend.
Challenge	Although with the right set of parameters good simulators produce very realistic looking motion, choosing parameters that will provide a particular appearance remains a time consuming task that requires the computation and viewing of many forward simulations.
Approach	In order to add additional air-drag degrees of freedom to our cloth model without resorting to fully modeling aerodynamics 25 , we developed a simple nonlinear alternative.
Background	More challenging still, they attacked the problem of measuring the 3D geometry of an object from the resting shape of a piece of cloth draped over it, a problem that we do not consider in this paper.
Approach	We use optimization to estimate the parameters of the cloth simulator from video.

Background	Approaches to explicit interaction modeling have included layered architectures [BG95], procedural descriptions [PG96], and even cognitive models [FTT99].
Approach	The entire process, however, relies on the availability of semantically segmented examples.
Approach	To remedy this, we run a highly constrained version of our dynamic programming algorithm that only adjusts the durations appropriately.
Approach	We used the motion of the leader to control a synthetic follower, which was then compared with the actual follower.
Challenge	Indeed, it would still be difficult for a skilled dancer to state the precise mapping.
Approach	In our tests, we downsampled these motions to 10 Hz and allowed each segment to be stretched ±0.2 seconds.
Approach	Generating partner dance motion would be a difficult trial for both physical methods, which would yield underdetermined systems, and statistical methods, which would typically require a very large database in place of our small segmented one.
Background	Many motion rearrangement techniques are derived from previous work in texture synthesis.
Approach	A dancer that pushes his partner slowly, for instance, will elicit quite a different response if he pushes quickly.
Outcome	In these misinterpreted instances, the leader’s motion is quite similar across two different follower patterns.
Approach	In the first, we synthesize a walking human character that follows a sampled trajectory.
Background	While Pullen and Bregler’s method was shown to be an effective solution for the chosen application of texturing keyframed motion, its applicability to our problem is limited by several factors.
Approach	Dance motion could be segmented using motion beat analysis [KPS03].
Background	Although these do not aim to discover control by example, they have nevertheless provided inspiration for our work.
Approach	The index s ∗ also identifies, by construction of the database, an appropriate target b s ∗ for both the control segment a s ∗ and the input motion x.
Outcome	This could be used to transcribe the motion into a symbolic representation, such as the one used in this paper, or even Laban notation [Hut73].
Approach	Like similar motion clip rearrangement techniques, we can propagate constraints by example.
Approach	The continuity constant, defined in Section 4.2, and the stretch limit were chosen experimentally.
Approach	In our timing tests, we used a 57 second control motion.
Approach	Here, α and ω represent the head and tail functions, which respectively extract the positions of the first and last frame of a segment.
Approach	Our dance motions are segmented into two-beat rhythm units, since they are a basic unit of interaction for the specific type of dance (Lindy Hop), as shown in Figure 1 .
Approach	In the process of generating target motion, our dynamic programming algorithm performs a semantically guided segmentation of the input control motion.
Approach	Where applicable, we state the clock times for the dynamic programming algorithm (Section 4.3), upsampling (Section 4.4), and postprocessing (Section 5).
Challenge	However, this comes at a price: statistical learning often necessitates large volumes of training data or severe restrictions on model complexity.
Outcome	In open stances, the follower was much freer to include stylistic variations, so the generated motions often differed visually from the actual motions.
Approach	This allows for explicit preservation of higherlevel motion semantics.
Approach	All timings were performed on a workstation with dual 2.4 Ghz Intel Xeon processors.
Approach	Our method requires no presegmentation; moreover, it produces a semantically guided segmentation as part of the optimization.
Background	This is natural for traditional keyframe animators, who often use recorded or live human motion for reference.
Approach	At each time t, all non-infinite cells are located and scores are conditionally propagated forward in time according to Equation 6.
Approach	Of course, the same selections, stretches, and transformations can just as easily be applied to the source motions that generated the point cloud.
Outcome	For such constraints, existing methods can be applied to postprocess the data [KSG02], but such methods often require some amount of manual constraint annotation.
Approach	A memory-based approach like ours does not suffer from these disadvantages.
Challenge	It is our hope that our method will have the same versatility for motion.
Outcome	Eliminating transformations entirely might also be appropriate for applications such as synthesis of facial motion from speech signals [Bra99].
Approach	Given a control motion x with T frames, our goal is to generate an appropriate target motion.
Background	Second, their objective function is defined over frames instead of segments.
Background	Second, there is no enforcement of motion continuity, other than a heuristic for consecutively observed segments.
Approach	A dynamic programming algorithm can then be used to interpret an input control specification in terms of mapping instances.
Approach	The semantic accuracy of the generated motion was evaluated in the setting of partner dance, where the follower’s motion is generated from the leader’s motion.
Approach	In the second, we generate a synthetic partner for a dancer whose motion is acquired through motion capture.
Background	Although this work, like ours, uses partner dance for evaluation, it does not address the problem of generating a follower given the motion of a leader.
Outcome	For a wide variety of user inputs, our method was capable of generating highly realistic walking motion.
Approach	We constructed the motion database from a set of 12 short dances, each containing the seven basic 8-beat patterns, giving a total of 5 minutes of motion.
Approach	A dance couple moves between four basic stances: open (◦), closed (•), open crosshand (◦), and closed crosshand (•).
Background	Motion capture is the most direct method to map performances to animated humans, as it is essentially an identity mapping.
Approach	Open and closed refer to whether the couple is apart or in embrace, respectively.
Approach	The walk footage was transcribed manually according to the gait cycle.
Approach	In general, we must handle the case where the optimal control and target consist of a sequence of segments.
Outcome	For short walks, the generated motion was highly realistic.
Approach	More specifically, suppose that we are currently processing the array cell Q r,c [t].
Outcome	Our dynamic programming algorithm performs a global optimization, which precludes the local decisions that are required for online applications.
Approach	Furthermore, it provides options to smooth the trajectory spatially and temporally.
Outcome	For instance, allowing arbitrary homogeneous transformations in two dimensions might form an alternative segmental solution to the curve analogies prob- lem [HOCS02].
Outcome	To demonstrate our method’s capabilities in this regard, we show that it can generate realistic and compelling motion, even with extremely simple postprocessing.
Approach	Our approach generates target motion segments that are amenable to simple blending.
Outcome	For all our evaluations and timing tests, we reduced the size of the database from 364 to 168 with clustering, downsampled to 7.5 Hz, and allowed a segment stretch of ±0.15 seconds.
Approach	Furthermore, point cloud representations allow for generalization to control motions without skeletal representations, such as mouse input.
Approach	An additional benefit of this process is that it helps beam search; since clustering reduces ambiguity in interpretation, a larger proportion of search paths can be pruned.
Outcome	As described in Section 4, the output of our optimization is a specification of an appropriate target motion in terms of target segments in a database.
Approach	To make the database motions more flexible, we allow each selected target segment to be spatially transformed and uniformly stretched in time.
Outcome	For this, we could begin with a few manually segmented examples and grow the set of example instances by iterative application of our algorithm.
Background	Due to advances in data acquisition technology and computational power, techniques have been developed that allow desired target motion to be specified using a human performance.
Outcome	The algorithm generated semantically correct partner motion even from test sequences of leader motions that did not appear in the training set.
Approach	Here, x d,t represents the subsequence of input frames starting at frame t − d and ending at frame t, which in turn induces the alignment matrix M s,d,t ≡ M(x d,t , a d s ).
Background	Lindy Hop is a subgenre of swing dance that, at a basic level, can be described as a state machine.
Outcome	Since the timing of the path was important, we found that users required minor training to understand the concept of performing a path instead of drawing it.
Approach	Our method begins by building a database of semantically meaningful instances of the mapping, each of which is represented by synchronized segments of control and target motion.
Approach	Specifically, we use the complex motion of the dance leader to drive the motion of the follower.
Approach	As before, we projected the hip joints onto the ground and normalized their distance.
Outcome	Without beam search, the dynamic programming algorithm ran for 78 seconds, 2 seconds were spent on upsampling, and 26 seconds were spent on postprocessing.
Background	High sampling rates are common for systems such as motion capture, but they are generally unnecessary for interpreting the input control motion.
Outcome	For longer walks, however, we were surprised to discover that the generated motions often kept in nearly perfect phase with the source.
Approach	From this process, we created 200 segments, which we reduced to 70 using clustering.
Approach	Since our example dance and walk motions only differ by ground translation and vertical rotation, our implementation uses a closed form solution [KGP02].
Approach	Through the mapping instances, a given interpretation also corresponds to a sequence of target segments that can be assembled to form a target motion.
Approach	In the segment modeling domain, we consider our method most similar to that of Pullen and Bregler [PB02].
Approach	To preserve spatial dependencies in mappings, we apply rigid transformations to optimally align control segments with input control motions.
Approach	In partner dance, an instance might contain an example control motion of a leader pushing his or her partner forward.
Background	As a result, they must use coarse-to-fine iterations of their dynamic programming algorithm to gain the temporal consistency that is intrinsic to our segment-based approach.
Approach	As in the single segment case, the distance metric D evaluates the interpretation quality of each segment in the sequence.
Outcome	The speed of the algorithm allows for rapid feedback.
Outcome	In the second, we highlight our method’s capability to handle complex, stylized mappings by controlling a dance follower with the motion of a dance leader.
Approach	Our choice of partner dance as a demonstration was primarily motivated by the complexity of its style and mappings.
Approach	After clusters are formed, a representative instance is chosen at random from each cluster to remain in the database, and all other instances are discarded.
Approach	This optimization is the solution to the Procrustes problem, which has several efficient numerical solutions [ELF97].
Challenge	Instead, our goal is to provide motion that is amenable to postprocessing with these approaches.
Approach	Instead, we constructed a smaller database with seven basic 8-beat dance patterns that every Lindy Hop dancer knows (shown in the first column of Table 1 ).
Approach	Our first evaluation involved creating control motions from new walk motions that were not in the database.
Outcome	Such a representation could then be analyzed or summarized using natural language processing techniques.
Approach	Each of these transitions occurs over four beats of music, which are assembled from two-beat segments; this was our motivation for performing two-beat segmentation, as described in Section 3.
Outcome	When the algorithm did differ from the real dancer in the composition of the pattern, the leader and follower still executed a valid Lindy Hop pattern.
Approach	An important benefit of this design choice is the ability to use segments, rather than frames, as the primitive unit of motion.
Outcome	In a direct comparison with the actual follower motions, we found that the synthetic follower matched very well in closed stances.
Approach	Rather than process all O(P) noninfinite cells at each time t, we only process cells with scores less than min s,d Q s,d [t] + w, where w is a user-specified constant.
Approach	For instance, we can force the result to contain a certain target segment b s at some time t by disallowing any processing on cells Q r,c [u], where r = s and u − c ≤ t ≤ u.
Approach	Since the indexing of each cell encodes a segment identifier and duration, the optimal sequence specification can be recovered by following backpointers from the best score at time T .
Background	Simple upsampling often introduces slight but undesirable temporal errors.
Approach	We ran the algorithm on shorter and longer inputs and experimentally confirmed the asymptotic linear dependency of running time on input length, described in Section 4.4.
Approach	Various postprocessing techniques can be then be applied to smooth and adjust the desired target motion.
Approach	To resolve this issue, redundant instances are eliminated using complete-linkage clustering [DHS00].
Outcome	While specific methods exist to automate this segmentation for the cases of dance and walk, a more general method is desirable.
Approach	Since the time complexity of the algorithm scales quadratically with the database size, this leads to inefficiency when the number of instances is large.
Approach	Here, a T s represents the control segment a s , uniformly stretched in time to T frames, and M(x, a s T ) is a rigid transformation that optimally aligns x and a s T :
Approach	One could also use more frames to measure higher-order continuity if desired.
Background	Adaptive autonomous characters have used rules to exhibit complex flocking, herding, and locomotory behaviors [Rey87, TT94].
Outcome	The annotation propagation we describe above suggests that our method could be used for interpretation rather than control.
Approach	Our approach is evaluated on two applications.
Background	An additional distinction is that these methods do not use continuous control from human performance and focus on sparser specifications such as keyframes and nontemporal paths.
Approach	The proper selection of segments can be achieved using an efficient dynamic programming algorithm.
Approach	The examples are divided into control segments a 1 , . . . , a N and target segments b 1 , . . . , b N , where a i and b i are synchronized motions that together represent a primitive semantic instance of the mapping.
Outcome	The dynamic programming algorithm took 12.5 seconds, upsampling from 10 Hz to 30 Hz took 0.4 seconds, and postprocessing took 1.1 seconds.
Outcome	Additionally, the synthesized dancers almost always kept in perfect rhythm with the leader.
Background	Performance-driven animation, or computer puppetry, derives its broad appeal from its ability to map human performances automatically to animated characters [Stu98].
Challenge	We do not aim to introduce novel solutions for motion blending or constraint satisfaction.
Approach	We acquired 2 minutes of motion captured walk footage at 30 Hz.
Approach	To compute the optimal interpretation, we determine the segment a s ∗ that is most similar to the input motion:
Outcome	Some footskate and handhold violations are visible because we wanted to show the output in its almost raw form, with smoothing applied only for visual coherence.
Background	Image analogies was shown to be an elegant method with applications such as texture transfer, textureby-numbers, and super-resolution.
Approach	For our evaluations, we captured three longer test dances (approximately 2-3 minutes each) in which the dancers were instructed to improvise with the transitions and stances included in the database.
Outcome	It is also possible to select other transformations for applications outside the domain of human motion control.
Approach	We artificially constructed a synchronized example control motion by projecting the positions of the hip joints onto the floor and normalizing their distance.
Outcome	Of the 91 patterns (21 unique) in our three test dances, the synthetic dancer matched the pattern of the actual dancer in all but 5 cases, one of which is shown in Figure 6.
Approach	Our walk motions, on the other hand, are segmented according to gait cycles.
Approach	The subject was directed to walk within the capture area with random changes in direction and speed.
Approach	By minimizing Q s,d [T ] over all s and d, we can compute the score of the optimal sequence specification and recover it by backtracking.
Background	Arikan et al. describe an example-based approach to synthesizing human motion that satisfies sparse temporal annotation and pose constraints [ AFO03 ].
Approach	In both cases, we use manual transcription, since each example motion must only be segmented once.
Approach	This technique is known as beam search, and w is known as the beam width.
Approach	However, the resulting optimal sequence specification will also be at the lower frame rate, and it is generally desirable to have it at the frame rate of the original input.
Challenge	One may wish, for instance, to generate walk motion from a constant-velocity trajectory.
Approach	In practice, we limit the allowed amount of uniform time stretch by a constant factor since the distance metric does not distinguish between motions of varying speed.
Outcome	We have shown that our segment similarity metric is effective for our experiments.
Outcome	Our dance evaluation suggests an alternative view of our method as one of interaction modeling.
Background	Skilled Lindy Hop dancers use a greater variety of moves, ranging from more complex transitions such as double outside turns to complex aerial maneuvers.
Outcome	Specifically, it provides a sequence of target segment indices s ∗ 1 , . . . , s L and durations d 1 ∗ , . . . , d L ∗ .
Background	However, a generalization of this approach to allow for more indirect mappings creates an array of fantastic possibilities, such as mapping voice signals to facial motion [Bra99] or gestural actions to animated reactions [JP99].
Background	This method, given an unfiltered and filtered version of the same image, applies an analogous filter to a novel image.
Approach	This interpretation induces a sequence of target segments from the database, which is concatenated to create the appropriate target motion.
Approach	Methods exist to automate this process if desired.
Approach	Cells in this array are indexed by the time t on one axis and by all legal combinations of s and d on the other (recall from Section 4.1 that the amount of allowed stretch is limited).
Approach	The corresponding target segments can be copied from the database, stretched, transformed by the induced matrices M ∗ 1 , . . . , M ∗ L , and concatenated.
Outcome	Visually, the results exhibited the fluidity, grace, and style of the original dancer.
Challenge	In the general case, however, a control motion may not admit any intuitive presegmentation.
Approach	In this context, our algorithm could be viewed as an extension of speech recognition methods that use connected word models [ RJ93 ].
Outcome	From the perspective of motion synthesis, the main problem with our approach is that the raw result will generally contain some kinematic errors.
Approach	These in turn induce the transformations M i ≡ M(x i , a d s i i ).
Approach	We did not include the entire range of motions.
Outcome	As with our walk motion evaluation, we found that clock times scaled linearly with the length of the input.
Approach	We quantify the similarity of the input motion x and a control segment a s with a distance function:
Approach	Q s,d [t] is defined as the score of the optimization on the subsequence x t,t , given that the last segment is indexed by s and stretched to duration d.
Approach	Their improvisations led to dances which included thirteen new 8-beat patterns not found in the database (shown in the last column of Table 1 ) as well as some repeats of patterns in the database.
Background	As a result, many methods assume that mappings are described by parametric probabilistic models [Bra99, DB01, DYP03, JP99].
Outcome	With the beam search optimization on, we were able to reduce the clock time of the algorithm to 1.2 seconds (47 seconds of input processed per second of clock time) while retaining visually perfect results.
Approach	To offset this problem, we introduce a function which measures the continuity between segments v and w:
Approach	For this, the distances between instances is defined by Equation 1.
Outcome	With beam search enabled with modest parameters, we were able to drive the runtime of the dynamic programming to 10 seconds while maintaining excellent visual and semantic results.
Challenge	This process involves an animator providing a control specification which is mapped to a target motion by some means.
Outcome	However, we acknowledge the fact that other metrics may be more appropriate for different types of motion and believe that it is a promising direction for future research.
Outcome	This approach is effective for our applications or whenever the control signal indicates appropriate spatial and temporal cues.
Approach	To learn indirect mappings, we adopt a memory-based approach which implicitly encodes the desired mapping using a database of semantically meaningful example instances.
Approach	More specifically, a segmentation point was manually placed at each footplant.
Outcome	We believe that segmental approaches like ours hold great promise for real-time performance-driven animation, and consider it a promising area of future research.
Background	While these mappings can be as simple as a direct copy of joint angles, the ability to discover more complex mappings gives the approach a tremendous amount of power and flexibility.
Approach	Walk motions, however, do not show the full ability of our technique to discover complex mappings.
Approach	If the value in the array cell Q s,d [t + d] is greater than z, we set it to z and store a backpointer to cell Q r,c [t].
Background	Although their work differs from ours in intent, they also employ a dynamic programming algorithm that optimizes a weighted combination of interpretation and motion continuity.
Outcome	Target segments inherit these transformations.
Approach	Swing dance also allows for a more principled evaluation of our results than most types of motion, since the performance of the algorithm at generating valid mappings can be evaluated independently of style considerations or subjective judgments of motion quality.
Approach	We can specify this sequence analogously to the single segment case by the number of segments L ∗ , the segment indices s ∗ 1 , . . . , s ∗ L , and the segment durations d 1 ∗ , . . . , d L ∗ .
Approach	More general motions could be segmented using annotation [AFO03] or curve clustering [CGMS03].
Approach	Constraints can be easily encoded by making appropriate cells in the Q array illegal.
Outcome	The upsampling and postprocessing times remained the same.
Approach	Since processing an individual cell is an O(P) operation, the total asymptotic time complexity of the algorithm is O(P 2 T ).
Approach	First, all legal values of Q s,d [d] are initialized according to the base case given in Equation 7, and all other array cells are set to infinity.
Approach	Our method falls into the latter category.
Approach	From a small segmented set of example instances, we generate a follower’s motion to accompany a leader’s motion.
Challenge	Authoring human motion is difficult for computer animators, as humans are exceptionally sensitive to the slightest of errors.
Approach	This is achieved by selecting a sequence of appropriate target segments from the database.
Background	In traditional keyframe animation, for instance, the keyframes are the control specification, and the target motion is achieved through spline interpolation.
Approach	The result is a moving point cloud that approximates the desired result.
Approach	In other words, each example instance can be annotated with constraints that can be transferred to the target motion.
Background	In online techniques [JP99], computational speed and instantaneous results are of paramount importance; offline techniques [Bra99] allow quality and global optimality to take precedence.
Approach	For each legal combination of s and d, the candidate value z is computed:
Approach	By continuing this process, the entire array is filled.
Outcome	Experimentally, we found that larger values of the continuity constant were more effective.
Outcome	This would correspond to a impossibly fast run, well beyond the capabilities of a human.
Approach	The algorithm proceeds by iterating forward through time.
Approach	The position of the mouse pointer was sampled at 30 Hz, and Frenet frames were used to generate a control motion.
Outcome	This was expected, as the control signals did not encode any phase information.
Challenge	Indirect mappings, however, must still be encoded in some way.
Approach	These dances were segmented into 364 two-beat mapping instances, with lengths varying from approximately 0.6 seconds to 1 second due to different music.
Approach	Crosshand refers to the case when the leader and follower hold right hands (we could also refer to it as a handshake).
Approach	Before developing our general algorithm, we address the simpler problem of interpreting the input as a single control segment from the database.
Approach	To better demonstrate this aspect, we apply our method to a partner dance called Lindy Hop.
Approach	In the following sections, all human motions were acquired in a motion capture studio and standard commercial tools were used to estimate joint positions [Vic03].
Outcome	Furthermore, all 5 mismatched patterns differed by a single two-beat segment, so, of 91 × 4 = 364 two-beat segments in the test dances, the algorithm misinterpreted the signal in 5 cases for an error rate of less than 2%.
Approach	In the first, we animate a realistic walking human from time-sampled mouse movement.
Background	Finally, their method assumes that the input motion can be presegmented analogously to the examples, which is achieved in their work by observing sign changes in velocity.
Approach	We ran our algorithm on these control motions and compared our results to the original source motions.
Approach	Here, we consider our work most similar in intent to image analogies [ HJO ∗ 01 ].
Approach	The optimal substructure property of the score function, as defined by the following recurrence, can be used to find a globally optimal solution using dynamic programming:
Approach	The advantage of complete-linkage clustering over other methods (such as k-means) is that it explicitly limits the distance of any two instances in a cluster by a user-defined threshold.
Outcome	In our dance example, footplant and handhold constraints are never explicitly enforced.
Outcome	When the algorithm encountered a pattern that was not in the database (one of 14 such patterns shown in Table 1 ), it was able to correctly reconstruct the novel sequence by rearranging the two-beat segments.
Background	First, their method assumes no spatial dependencies between the control (keyframed curves) and the target (textured motion).
Approach	Given a sequence specification L, s 1 , . . . , s L , and d 1 , . . . , d L , we define a scoring function that accounts for both the quality of interpretation and the continuity of the target:
Approach	Limiting the amount of stretch also has the practical benefit of reducing the search space of our general algorithm, which we will now describe.
Outcome	We present a method that allows such a mapping to be defined by example, given that the control specification is recorded motion.
Approach	By downsampling motions by a user-chosen constant, we can effectively reduce the length of the input sequence.
Outcome	However, we demonstrate in our evaluations that it can compute results significantly faster than input motion can be recorded, thus making it suitable for rapid-feedback motion authoring applications.
Challenge	Human dancers learn their skills by observation and practice; our objective is to emulate this process on a computer for situations, such as partner dance, when the control specification takes the form of one dancer’s motion.
Approach	This is demonstrated by our propagation of handhold constraints, shown in Figure 4 .
Approach	Here, x i is the subinterval of the input that is implied by the segment durations d 1 , . . . , d i .
Approach	The optimal target may not precisely satisfy desired physical or kinematic constraints.
Approach	Our formulation differs in two subtle but important ways.
Approach	The stretch T completes the specification of the optimal interpretation, M(x, a T s ∗ )a T s ∗ , and the optimal target, M(x, a T s ∗ )b T s ∗ .
Approach	For the point cloud representation of body motion, we used only the positions of the hands and feet, as we found that these endeffectors were sufficient to evaluate interpretation and continuity in both evaluations.
Outcome	The frequency of the generated gait cycle nearly matched the frequency of the source, but phase differed.
Outcome	These served as synchronizing signals which were propagated throughout the generated gait cycle due to the global optimization.
Approach	Our dynamic programming algorithm uses segments of motion along with an objective function that accounts for both the quality of control interpretation and the continuity of the target motion to generate visually and semantically correct motions.
Challenge	Manually, this can be an exceptionally challenging task requiring detailed, domain-specific knowledge.
Approach	First, our notion of continuity is dependent on the interpretation; that is, the continuity between two motion segments is undefined until a candidate interpretation specifies a coordinate frame for comparison.
Background	One could extend this approach for rhythmic motions using the automated approach of Kim et al. [ KPS03 ].
Approach	To generate the motion, we applied the resulting sequence specification to the source motion and used basic smoothing.
Challenge	For certain applications, this is a worthwhile tradeoff, but for others, it can result in impractically long training times or loss of important detail.
Approach	The corresponding example target motion would be that of the follower, taking a step backward in response.
Approach	We first ran the algorithm without the beam search optimiza- tion.
Approach	However, the quality of the interpretation alone does not account for the continuity of the target motion, as shown in Figure 3 .
Approach	In our second evaluation, we built an interface that allowed users to draw paths using mouse input, as shown in Figure 5 .
Approach	To solve the recurrence efficiently, values of Q are stored in a two-dimensional array.
Approach	For human motion, we use skeletal joint positions, since this representation provides a more intuitive space than joint angle representations for comparing poses [KGP02].
Outcome	We cite our efficiency figures for generating, from leader motion only, a particular 150 second dance motion.
Outcome	The reason for this was that the subject preferred to make sharp turns with the same footwork pattern.
Outcome	It was often tempting, for instance, to rapidly move the mouse to draw a straight line.
Outcome	In this context, our work might be viewed as a competency module that enhances the skills of characters to enable their participation in complex interactive performances.
Outcome	To disambiguate these, we might add information to the control signal, such as forceplate readings, or we might accept these rare mismatches because they are in fact valid mappings.
Outcome	In the first, we demonstrate its ability to map low-dimensional input to high-dimensional motion by controlling walk motion from mouse trajectories.
Background	An advantage of these techniques is their ability to generalize to a variety of inputs.
Outcome	Our algorithm ably recreated the semantics of the leader to follower mapping, even for novel patterns.
Outcome	Paralleling our automatic annotation of handholds, it is possible to annotate any new control motion given a set of labeled example instances.
Approach	The user-specified constant k defines the balance of interpretation and continuity.
Outcome	In more concrete terms, the generated motion might choose to start on the left foot, whereas the original source motion might start on the right.
Approach	Basic Lindy Hop motions switch between these four stances by means of transitions: an inside turn ( ), when the follower spins towards the leader, an outside turn ( ), when the follower spins away from the leader, and a simple step (→).
Approach	A new input control motion can be interpreted as a sequence of rigidly transformed and temporally stretched control segments from the mapping database.
Approach	We evaluate our technique with two examples.
Approach	At each time t, O(P) noninfinite cells are processed, where P is the number of legal combinations of s and d.
Approach	This is motivated by the fact that cells with worse scores are unlikely to be on the optimal backtracking path, and thus can be pruned from the search.
Challenge	The mapping from leader to follower motion must minimally encode a significant amount of knowledge about the structure of the dance; this knowledge, unfortunately, would be out of reach to an animator who is not a skilled dancer.
Approach	Our method, given a set of synchronized control and target motions, applies an analogous mapping to a new input control motion.
Background	In this domain, tech- niques have been developed that specify the mappings between character motions with explicit models of character interaction.
Background	Complex mappings often defy purely physical or mathematical encodings.
Approach	These test dances spanned a tempo range from about 120 beats per minute to about 190 beats per minute.
Outcome	We have presented a method for example-based performance control of human motion.
Approach	As stated previously, the target motions were represented by end-effector positions.
Approach	However, given a descriptive database, it can provide a good approximation which can be adjusted appropriately during postprocessing.
Background	This approach would be similar in spirit to the semiautomatic SVM-based annotation approach of Arikan et al. [AFO03].
Outcome	Our results, shown in the following section and in our accompanying video, are filtered with a basic smoothing operation that linearly adjusts motion curves to match across segment boundaries.
Approach	These instances store segments of synchronized control and target motion, which provide examples of how the mapping should be applied to input control motions.
Approach	To resolve these issues, our interface allows a user to overlay the playback of an existing motion on the drawing canvas to get a sense of speed.
Approach	To increase its efficiency, we apply several heuristic optimizations.
Approach	We evaluate our method on two examples of indirect control.
Approach	Our method is not designed to handle such control specifications and therefore should be viewed as an alternative to these approaches, rather than a replacement.
Approach	We use dynamic programming to select a sequence that balances the quality of interpretation with the continuity of the induced target motion.
Challenge	Consider a partner dance scenario in which an animator wishes to con-      trol a follower using the captured motion of a leader.
Approach	For our evaluations, we were able to perform this segmentation manually by tapping a key in response to the rhythm of music or the gait pattern of a walk cycle.
Background	Kim et al. demonstrate that a semantically guided segmentation of rhythmic motion allows for highly realistic motion synthesis, even using simple transition models [KPS03].
Approach	At the end of each transition, the dancers may also change their handhold to instantly transition between crosshand states (◦, •) and non-crosshand states (◦, •).
Background	Other related methods based on motion capture clip rearrangement include work by Kovar et al. [ KGP02 ], Lee et al. [ LCR ∗ 02 ], and Arikan and Forsyth [ AF02 ].

Outcome	Finally, we would like to emphasize that the main advantage of our approach may be as part of a more complete animation system.
Approach	One traditional approach is to use the integral of the sum of squared joint torques to produce a motion that approximately minimizes energy expenditure:
Approach	The usual way to compute aggregate momentum is to formulate the following recursion:
Outcome	The number of free parameters of the optimization problem also grows linearly with total time allotted for the animation.
Approach	We wish this point to have linear velocity b r,des and linear acceleration b  ̇ r,des , expressed in the world coordinate frame.
Outcome	The fact that first derivatives can be computed in linear time instead of quadratic time suggests that our problem is simpler than previous physically based approaches and similar in complexity to very successful kinematic approaches such as minimizing distance to a reference motion.
Approach	The aggregate force is a representation of all external forces and torques (excluding gravity) that would have to be applied to the character root to explain the character’s motion.
Outcome	No touch-up was done on the results.
Background	During ground contact, the feet can only push, not pull on the ground, contact forces should not require an unreasonable amount of friction, and the center of pressure must fall within the support polygon of the feet.
Outcome	All of these effects are obtained as a result of the optimization process.
Approach	In the swing example of Figure 1 , it may be convenient to root the character at the hands for the swing, at the center of mass for flight, and at the feet for landing.
Outcome	We show that qualities such as squash-and-stretch that are expected from physically based optimization result from our approach.
Approach	This paper describes how a broad range of physics constraints can be expressed based on aggregate forces and torques applied to the character, and how expressing physics constraints in this way allows us to compute the constraint Jacobian in linear time (Section 4).
Challenge	If some torques (e.g. torques at the hip joints) are found to be important, it seems quite certain that many others (e.g. torques at the fingers) can be ignored for many motions.
FutureWork	Incorporating physics constraints into traditionally kinematic animation approaches is one direction of future work.
Background	Running times were far from interactive, but show that optimization techniques can produce realistic motion for systems of human-level complexity.
Outcome	This effect is eliminated in the optimization by enforcing the physics constraints of ground contact.
Approach	The derivative of interest can be expressed in terms of q, q,  ̇ and q  ̈ using the chain rule:
Outcome	Our results suggest, however, that physics constraints and a kinematic measure of smooth motion such as minimizing the sum of squared joint accelerations are sufficient to capture dynamic effects such as squashand-stretch and tucking for faster rotation, as shown in Figure 1 .
Outcome	We suspect that our solution landscape will be smoother than previous physically based optimization approaches, making it feasible to handle more complex characters.
Approach	A term superscripted with an asterix should be treated only as an intermediary quantity, unless its subscript is zero in which case it is the desired aggregate result.
Approach	Constraints that enforce physical validity can be formulated as linear equality or inequality constraints on aggregate force.
Approach	Derivatives of all equations with respect to parameters describing the motion can be computed in O(D) time.
Background	The mix of animator control and physics present in Witkin and Kass [1988] has been expanded upon in interactive techniques developed to control physical simulations of rigid bodies [Popović et al. 2000], and a number of researchers have shown that the freefall portion of a dive can be efficiently optimized for a simplified character [Liu and Cohen 1994][Crawford 1998][Albro et al. 2000], as can motions such as weight lifting and pushups [Lo and Metaxas 1999].
Approach	Spatial force also combines linear and angular quantities:
Outcome	Complexity in the number of degrees of freedom of the character is not the only concern in physically based optimization.
Outcome	Minimizing sum squared torques would produce the desired results.
Approach	Both terms are expressed in the body i local frame, and the superscript on s i indicates that the spatial vector is expressed in body i local frame coordinates.
Outcome	We have shown that physics constraints can be enforced in an efficient manner.
Approach	This velocity should be b r,des .
Approach	In general, the initial motion was determined directly from constraints, with no additional user input, using linear interpolation between constrained poses.
Outcome	In the present paper, we show that it is possible to optimize motion with physics constraints in an efficient manner, so that reasonable friction conditions, for example, can be easily enforced.
Outcome	(Of course, truly passive motion can be created much more easily using forward dynamic simulation.
FutureWork	To make this motion appear more natural, we would need to consider proper timing for the running stride, a more accurate foot model, torques at some of the joints, and perhaps also aspects of style that are not driven by physics or energy.
Approach	We use cubic B-splines as basis functions and follow the standard approach of enforcing constraints at a fixed set of points in time (t i ).
Approach	Numerically the partial derivatives are identical.
Approach	When the character is swinging on a high bar or monkey bars, the amount of torque that can be applied about the bar axis is constrained.
Approach	This objective function is similar to the one used in Gleicher [1997].
Outcome	For example, the peg running motion appears very athletic because it would require high torques at the knee and hip joints.
FutureWork	An interesting research problem is to determine automatically when torques at a given joint should be considered.
Background	Constrained optimization techniques were introduced to the graphics community by Witkin and Kass [1988], who created a variety of animations involving a jumping Luxo lamp from simple descriptions including start pose, end pose, and a physically based objective function.
Approach	As a result, typical objective functions such as minimizing the sum of squared joint torques are excluded from our restricted problem setup.
Approach	We begin with a discussion of the momentum equations and present an argument that the momentum Jacobian can be computed in linear time.
Approach	Other objective functions we have attempted include an integral of squared contact forces:
Approach	An objective function that we have found to work well is to minimize the integral of the sum of squared, weighted joint accelerations:
Background	Cohen and his colleagues [Cohen 1992] [Liu et al. 1994] introduced techniques to give the user more control, including an ability to focus on windows in time, and employed a hierarchical wavelet description to allow incremental changes to affect the motion at different time scales.
Challenge	Physical validity is important, however, in situations such as those shown in Figure 1 .
Approach	The key thing to notice here is that p ∗ i is expressed as a function of v i , which is a local variable at link i.
Approach	Both of these changes complicate the problem description presented to the optimizer.
Background	Preexisting motion data can simplify the optimization process.
Challenge	One possible reason is that there is a cost to this approach that may be higher for robotics applications than for graphics applications.
Approach	First, we note that if the basis functions have local influence, the vector and matrix quantities computed during optimization are very sparse.
Background	Grzeszczuk, Terzopoulos, and Hinton [1998] developed a neural network approximation of dynamics so that gradient search could be performed on this neural network, resulting in faster convergence to a solution.
Approach	For rotational joints, joint axis s i is represented as follows:
Approach	To empirically test the advantage of our method for fast derivative computation, we ran the peg example (bottom row of Figure 6) 5 times, each time with the identical setup except that a different technique was used to compute all required first derivatives.
Outcome	All timing information is for a 750 MHz Pentium 3 computer.
Approach	To obtain the correct velocity at the effective root, simply add the desired correction (b r,des − v b r ) to the reference frame velocity:
FutureWork	The idea of dynamic patterns is an exciting one.
Approach	The adjustment to a 0 is derived using similar reasoning.
Challenge	Optimization is a promising way to generate new animations from a minimal amount of input data.
Background	Although the inverse dynamics computation is relatively expensive, many efficient algorithms exist, and the process is well known to require time linear in the number of degrees of freedom of the character.
Outcome	1 We show that straightforward analytical computation of the force Jacobian would require time quadratic in the number of degrees of freedom of the character.
Background	Linear time derivatives for physics constraints do not result from direct differentiation of the equations of motion in either the Newton-Euler or the Lagrangian formulation; in either case, symbolic differentiation would result in a quadratic time algorithm.
Approach	Minimizing contact jerk (the time derivative of force) can be achieved using forward differences:
Approach	In this paper, we describe a set of objective functions and constraints that lead to linear time analytical first derivatives.
Approach	There is no clever way to simplify the calculation by aggregating terms when it is presented in this form.
Approach	Implementing any inverse dynamics algorithm requires selecting a character root.
Approach	Also note that p ∗ i is in general not equal to p i if i = 0.
Outcome	In this paper, we describe how the Newton-Euler equations of motion can be rewritten to allow first derivatives of aggregate forces and torques to be computed in linear time.
Approach	If a subset of K torques are required, it is straightforward to extend our approach to measure torques at these joints in O(KD) time.
Approach	As before, f ∗ i is in general not equal to f i where i = 0.
Approach	The Jacobian of this function is computable in linear time; our physics constraints are based upon it.
Approach	To automatically compute initial motion in a constrained pose, all joints are set at zero angle, the character is in a vertical posture, and the relevant end effector is placed at a user-specified point (e.g. hand at a specific point on the monkey bars).
Background	Similar ideas have also been developed in graphics by [Ko and Badler 1996], who bend the torso of a character to reduce torques at the desired ZMP, and [van de Panne 1997] who ensure that reasonable forces are available to accelerate the center of mass without creating angular acceleration.
Outcome	This paper contributes to physically based optimization by defining and exploring a restricted class of optimization problems where physics constraints are included and first derivatives of constraints and objective functions can be computed in linear time.
Approach	However, p ∗ i is in general not equal to p i where i = 0 and should only be used as an intermediary quantity in computing the aggregates.
Background	Full scale human motion can be optimized when closely spaced keyframes are available [Liu and Cohen 1995] or when only transitions between existing motion segments are required [Rose et al. 1996].
Outcome	The character would fall over.
Background	Constrained optimization has been shown to be a very powerful approach for obtaining appealing dynamic motions from a minimal amount of input information.
Outcome	This paper presents an approach to physically based optimization that is efficient and appears to scale well to more complex characters.
Approach	Efficiently computing ∂ f 0 / ∂ q, the force Jacobian, requires efficiently computing ∂ p 0 / ∂ q, the momentum Jacobian, because aggregate force f 0 is the time derivative of aggregate momentum p 0 .
Approach	However, if joint torques are not required, then this value and first derivatives for constraints based on this value can be computed in linear time.
Approach	We observe that rewriting the recursion solves this dilemma:
Approach	One way of enforcing correct physics during flight is to ensure that the aggregate momentum of the body remains constant throughout the flight phase.
Approach	These effects can be modeled with equations that constrain the linear and angular forces separately.
Approach	This equation has the properties we are looking for.
Approach	The exception was initial control points for the character root in the first example, which were set to create the overall body rotation required for the backflip.
Approach	Two implementation issues were especially important for achieving the results described in this paper.
Background	Coulomb’s model dictates that the linear reaction force must fall within a friction cone oriented along the contact normal with angular half-width tan −1 μ , where μ is the coefficient of friction.
Outcome	In these examples, the initial motion is rigid translation of the entire character.
Approach	For activities where joint torque limits are important, this torque information must be taken into account to produce good results.
Background	When physics does not dominate the motion, kinematic techniques can give the animator interactive control for motion editing (e.g., [Gleicher 1997] [Lee and Shin 1999] [Arikan and Forsyth 2002]).
Approach	We used an objective function that enforces smooth motion, with a linear time Jacobian computation and a constant Hessian.
Background	For example, the sequential quadratic programming algorithm used in [Witkin and Kass 1988] makes use of first derivatives of the constraints (the constraint Jacobian) and both first and second derivatives of the objective function (the Jacobian and the Hessian).
Approach	Note that the analytical Hessian for this objective function is constant, symmetric, positive definite, and band-diagonal.
Approach	We use spatial notation as in Featherstone [1987] for conciseness.
Approach	For example, the weight for the left-knee during a left-legged support is the entire body mass minus the left lowerleg.
Approach	Where a reference motion q R (t) is available, a simple objective function with low cost is to simply minimize the distance from the reference motion:
Background	In a Newton-Euler inverse dynamics formulation, rerooting is typically done by changing parent / child relationships, which requires inverting joint angles and transforms at each joint and altering the flow of dynamic terms from leaves to root.
Approach	Velocities v i are propagated from base to leaf, and momentum p i is propagated from leaf to base.
Approach	Where superscripted with an asterix (e.g., I ∗ i ) the quantity represents aggregated information accumulated from L to i.
Approach	In Equation 51, v b r is the linear velocity of the effective root expressed in world coordinates.
FutureWork	However, relying on momentum patterns without computing interaction forces between the character and the environment may result in problems with certain types of physics constraints (e.g., keeping forces within a friction cone) when the initial motion is not favorable.
Background	Dynamic filters have been developed for processing motion capture data for physical correctness [Yamane and Nakamura 2000] [Dasgupta and Nakamura 1999] [Pollard and Reitsma 2001].
Approach	During flight, no forces, with the exception of gravity, may be derived from the environment.
Approach	However, typical choices for the numerical optimizer in Figure 2 also require derivatives of the constraints and objective function.
Outcome	To our knowledge, our paper is the first to present a linear time algorithm for computing the force Jacobian for an articulated character or robot.
Approach	A linear time expression for the momentum Jacobian can be derived in a straightforward manner based on this form of the recursion.
Outcome	But often it is due to overly restrictive parameters, such as friction coefficients, joint limits, poor selection of timings, etc.
Outcome	Our experience, however, was that as long as an expected motion sequence could be thought of as motion about some neutral position, then when the character was started in that neutral position there was no problem descending toward the expected minimum.
Outcome	Note the looser tuck and the higher flight trajectory in the 0.8s motion.
Outcome	We note that it is not possible to compute derivatives for torques at all of the characters joints in linear time.
Background	In robotics, this information must be computed because it corresponds to signals sent to the motors of the robot.
Approach	All partial derivatives are expressed in frame i.
Background	Popović and Witkin [1999] have shown that significant changes to motion capture data can be made by optimizing with a physically based objective function when the character is reduced to the degrees of freedom most important for the task.
Approach	) The flight constraint is thus f 0 = 0.
Approach	We classify the physics constraints for the motions in our examples into the categories of flight, bar contact, and ground contact.
Outcome	When physical parameters at certain joints are identified as important, our method can be extended to provide and differentiate these parameters for any K joints with running times of O(KD), reaching the expected bound of O(D 2 ) when all joint torques are required.
Background	Kinematic optimization [Gleicher 1997], which has been shown to be successful for complex characters, depends on constraints and objective functions for which first derivatives can be computed in linear time.
Approach	Adopting this function would negate our effort in constructing efficient physics constraints.
Approach	It is interesting to compare our approach to that of Liu and Popović [2002].
Approach	Aggregate force is translated to a constraint point c as follows:
Challenge	We believe that physical correctness and optimization functions enforcing smooth motion are sufficient to obtain many natural characteristics of human motion.
Approach	Spatial transform X i j takes spatial quantities from frame i to frame j:
Approach	As a result, only propagation from leaf to base is required, and each parameter q j does not affect terms computed for joints j + 1 and beyond ( Figure 4 ).
Outcome	Any optimization technique that makes use of local derivatives has potential problems with local minima.
Outcome	An extreme example of this situation is the passive swing of a multilink chain.
Outcome	We were able to create a jumping Luxo and highly dynamic human motions with good success.
Challenge	Several challenges remain, however, to achieving fast, flexible, and realistic optimization of human motion.
Approach	The vertical ”zero posture” had arms up for the bar swings, legs out for the monkey bars, and arms down for the ground motions.
Approach	To set up these examples, we used 15-30 control points per degree of freedom.
Approach	The current velocity of body i in the body i frame is v i .
Approach	Second, we outline the issue of rerooting.
Approach	Our argument and implementation is constructed around a NewtonEuler formulation of inverse dynamics.
Outcome	Our animation system is particularly useful for synthesizing highly dynamic motions, and we show examples of swinging and leaping motions for characters having from 7 to 22 degrees of freedom.
Approach	Note that as with aggregate momentum, f ∗ i is in general different from the actual joint force f i if i = 0.
Approach	The effective root can be relocated more easily, however, by leaving the actual root and the flow of the dynamics computation fixed and computing velocities and accelerations at the root to maintain the desired constraint.
Approach	Obtaining these derivatives is a computational bottleneck, and complex derivatives can lead to poor optimization performance and problems with local minima.
Challenge	Our goal was to require a minimal amount of information from the animator.
Challenge	One challenge is incorporating physics into an interactive animation system.
Approach	Aggregate momentum p 0 and the momentum Jacobian are exactly the same in both formulations.
Approach	Parameter q i appears in the coordinate transforms X i i+1 and X i+1 i , and so every v j for j > i depends on q i , and every p j for j ≥ 0 depends on q i .
Outcome	We believe the combination of correct physics and knowledge of natural dynamic patterns of human motion such as momentum or movement of the center of pressure in the roll of the foot on the ground could be very powerful.
Approach	As expected, the proposed method is linear in the degrees of freedom, while direct differentiation shows quadratic growth.
Outcome	In these examples, notice the swinging of the legs and arms, as well as body roll, pitch, and yaw.
Outcome	With this objective function and our linear time algorithm for computing the constraint Jacobian, we are able to show that physically based optimization can be performed for a 22 degree of freedom character at interactive speeds.
Approach	Once all physics constraints have been expressed as constraints on aggregate force, computing derivatives on the physics constraints becomes a problem of differentiating aggregate force with respect to the free parameters of the problem.
Approach	The equations of motion of a serial multibody chain are compactly expressed in recursive form as follows:
FutureWork	Details of the desired motion could be fleshed out using motion capture data, procedural techniques, keyframes, and/or objective functions appropriate to the specific task.
Outcome	Running on flat ground shows a combination of difficulties.
Outcome	) More commonly, a limited set of torques or energy terms may be important.
Approach	Enforcing physics constraints or minimizing a dynamic property such as sum squared joint torques requires an inverse dynamics computation at each time t i .
Background	Optimal control techniques, introduced to the graphics community by Brotman and Netravali [1988], have been used with success by Pandy and Anderson [2000] for simulating human lower body motions such as optimal height jumping and walking.
Background	Physics constraints have been used to plan biped walking motions, exploiting the idea that dynamic equilibrium can be maintained by ensuring that the zero moment point (ZMP)—the point on the ground at which ground reaction moments about horizontal axes are zero—lies within the support polygon of the feet [Vukobratović 1970] [Takanishi et al. 1985] [Nagasaka et al. 1999].
Background	One appealing vision in animation is that the animator should be able to create and edit motion by defining and adjusting a small number of keyframes and constraints—and that the resulting motion should remain optimal in some way.
Approach	There are D terms q i , and this approach will lead to an O(D 2 ) computation for the momentum Jacobian.
Approach	Unfortunately, the constraint Jacobian that results from constraining momenta is denser than necessary as the control points that determine take-off affect all constraint equations governing the flight phase.
Challenge	Intuitively, quadratic time is required because motion at any joint affects torque at all joints.
Approach	Unrolling the recursion to collect terms for ∂ p 0 / ∂ q i requires O(D) time.
Outcome	When the optimization does not converge, we can usually trace it back to the problem setup.
Approach	Gaits generated using this function have a certain ‘tip-toe’ quality to them, as the function minimizes the amount of reaction force derived from the contacts.
Outcome	We found that a number of time slices (for constraint evaluation) equal to the number of control points produced good results and did not need to adjust this value for individual motions.
Outcome	For less dynamic activities, our system would require additional input; physics constraints plus smooth motion would not in general produce the desired results.
Outcome	This set includes most common constraints required for physically correct animation, such as conserving linear and angular momentum during flight, ensuring that ground contact forces can be explained by foot placement, constraining torque applied about an axis (e.g. the high bar in Figure 1 ), and limiting the coefficient of friction at any contact with the environment.
Approach	Spatial inertia represents both body mass and rotational inertia:
Approach	An ability to move the effective root to different parts of the character is very convenient.
Approach	In contrast, we argue that for animation of human motion, many of the effects we expect to see in physically based optimization do not depend on joint torques.
Challenge	Kinematic optimization alone is unlikely to capture the coordination of different parts of the body that is required to perform this task, such as the preparatory back swing, the tuck, or the motion of the legs to drive the character upward that is shown in the bottom row of the figure.
Background	In his dissertation, Liu [1996] also describes how symbolic differentiation of the equations of motion can be made efficient (although still quadratic time) by cleverly aggregating terms.
Background	Traditional approaches often require optimizing or constraining parameters involving joint torques; obtaining first derivatives for these parameters is generally an O(D 2 ) process, where D is the number of degrees of freedom of the character.
Approach	The motivation for this approach is that solution techniques for nonlinear constrained optimization problems (e.g. SQP) typically require either analytical or numerical derivatives.
Approach	Velocity v i and acceleration a i are local to link i, and terms are propagated from leaf to base only.
Approach	When these changes are made, the actual character root can remain at the pelvis, for example, while the effective root is moved from hand to pelvis to foot or other bodies as needed.
Outcome	We have found that constraints on physics that can be derived from the aggregate force and torque applied to the character can also be differentiated in linear time.
Approach	Compute:
Approach	We use a standard problem formulation—iteratively adjust character motion to meet animator constraints and minimize an objective function.
Approach	Suppose we wish to place the effective root of the character at the point on body i that is located at point r in body i coordinates.
Approach	Each motion was set up using a constraint configuration file containing the information listed in the tables.
Approach	Let T x and T y be orthogonal vectors spanning the rectangular support, and let δ x and δ y be the distances from c to the edge of the support along along T x and T y respectively.
Approach	Our approach is based on restricting the definition of this optimization problem to constraints and objective functions that can be differentiated in time linear in the degrees of freedom of the character.
Approach	The Newton-Euler equations propagate quantities in two directions.
Outcome	The characteristics of the final motions fall out of the requirements of physical validity, a simple kinematic optimization function, and timing values selected for each phase of the motion.
Approach	We constrain the linear force using Coulomb’s contact model.
Outcome	Our vision is that the ability to enforce physics constraints efficiently should be just one of the tools available to the animator.
Background	It must in general also be part of optimization routines, because en- ergy consumption and joint torque limits are of particular concern when operating a robot, and none of the joints can be ignored.
Outcome	The surprising finding is that this set includes constraints on physical validity, such as ground contact constraints.
Approach	The torques about T x and T y may be constrained as:
Background	An optimization approach to animation has proven useful for editing human motion capture data, refining a “sketched” version of an animation, and for creating entirely new motions for simple characters or short segments.
Outcome	Details of the optimization setup are in Figure 7 .
Approach	The articulated model is a serial chain ranging from 3 to 50 links.
Approach	In a standard Newton-Euler formulation, force parameter f i (Equation 17) contains all of the joint force information for joint i, in particular forces in the actuated directions of motion (joint torques).
Outcome	We add to this body of work the insight that it is possible to incorporate constraints on physics as efficiently as constraints on kinematic parameters and an O(D) algorithm for computing first derivatives of a broad range of physics constraints for improved performance in a optimization context.
Outcome	The initial motion (shown in the top row of Figure 6) appears very unstable at landing.
Outcome	In particular, the geometry of the monkey bars and the pegs was not modeled.
Approach	While animator constraints such as key poses or an objective based on proximity to a reference motion can easily be incorporated into the system, no motion capture data is used in our examples, and user-supplied constraints are minimal (e.g., see Figure 7 ).
Approach	It is also observed that despite overheads in computing aggregate intermediate terms, the linear time method shows a computational advantage with as few as 5 degrees of freedom.
Approach	We use the publicly-available Lancelot optimization package [Conn et al. 1992] where sparsity is accounted for by groupseparability.
Approach	A more elegant solution is to restrict illegal forces during flight.
Approach	The Jacobian may be constructed in time linear in the number of degrees of freedom as follows.
Challenge	Physically based optimization techniques, however, are difficult to scale to complex animated characters, in part because evaluating and differentiating physical quantities becomes prohibitively slow.
Background	Optimization approaches with physically based objective functions have proven difficult to extend to complex articulated characters, however, and much research has been focused on this problem.
Approach	It combines linear and angular quantities such as force and torque or linear and angular velocity into single vectors, as shown in Equations 1 through 3.
Outcome	Minimizing accelerations while maintaining physics constraints would produce a result that was valid for the body as a whole but would require non-zero torques at the joints—no whipping motion would be seen.
Background	Liu and Popović [2002] show that some dynamic effects can be preserved by enforcing patterns of linear and angular momentum, which does not require computation of dynamic parameters such as contact forces and joint torques.
Outcome	Finer time slices would overly constrain the system, and sparser time slices allowed too much freedom for error.
Approach	Let the aggregate force be denoted by f 0 .
Approach	I ∗ 0 and p ∗ 0 are the aggregate inertia and momentum of the entire body, and p ∗ 0 is equal to p 0 computed from the previous NewtonEuler recursive equations.
Approach	Parameters q  ̈ i do not include translational or rotational acceleration of the character root.
Approach	(In the spatial notation used here, f 0 contains both linear forces and torques.
Approach	At present, timings are set by the user and their values need to be reasonable (e.g., the character cannot leap too far in too short a time).
Approach	We represent multiple degree of freedom joints as sequences of single degree of freedom joints, connected by massless and inertialess bodies.
Approach	The main point of the paragraphs below is to show how the force Jacobian can be computed efficiently.
Background	The user adjusts the problem description in the form of keyframes, constraints, and objectives; an optimizer computes an optimal animation given this problem description; and the process repeats until the user obtains a final animation ( Figure 2 ).
Outcome	Considering only constraints and objective functions that lead to linear time first derivatives results in fast per-iteration computation times and an optimization problem that appears to scale well to more complex characters.
Background	The idea of physically valid motion has appeared in both graphics and robotics.
Approach	This function is expensive because computing its gradient requires O(D 2 ) work.
Background	Their paper describes the power of patterns (e.g., momentum patterns) in creating desirable animation effects, and their approach could be adapted easily to obtain linear time performance by rewriting the momentum equations as described in Section 4.2 of this paper.
Approach	Spatial notation involves 6-dimensional vectors, 6x6 coordinate transformations, and 6x6 inertia tensors.
Approach	Contact torques are constrained by geometrically confining the center of pressure to the support area.
Approach	The high bar final pose was the only pose provided as a constraint in these examples.
Approach	Additional information would be required to fill in the details of the standing motion.
Approach	The effective root can even be set to the center of mass to obtain correct ballistic motion during flight.
Background	We have not yet attempted any long motion sequences, but we note that Liu, Gortler, and Cohen [Liu et al. 1994] have shown that time complexity can be effectively managed in an optimization context, in part because the influence of any one parameter is localized in time.
Outcome	” Given this problem definition, our system would identify a static pose near the initial guess where the projection of the center of mass is in support area.
Outcome	Sometimes it is due to overconstrained equations (setup error).
Approach	The term ∂ f 0 / ∂ q, which we will refer to as the force Jacobian, is the most difficult term in this expression.
Approach	At any time t, character position q, velocity q,  ̇ and acceleration q  ̈ are known.
Approach	The magnitude of the normal force can be constrained as follows:

Approach	• Another very important property of our algorithm is that it is local.
Approach	They depend only on the initial wrinkle pattern, the initial mesh and the mapping coordinates.
Background	Real cloth would wrinkle to this deformation (see typical wrinkles in Figure 3A ).
Outcome	In fact, for small meshes (upto a hundred polygons) the modulation of wrinkle pattern can be real time (20 fps).
Approach	This allows otherwise possible wrinkling/buckling which is embedded in the deformation of triangle.
Challenge	Even then, a significant problem remains: how to estimate the regions and the orientations of wrinkles.
Approach	Moreover, the deformations during cloth simulation are moderate in general.
Challenge	This gives rise to very stiff equations of motion.
Approach	The garment is animated using a coarse mesh and low metric stiffnesses for the reasons explained in section 2.
Approach	The area conservation formulation of the method modulates the user defined wrinkle pattern, based on deformation of individual triangle.
Approach	The wrinkling coefficients on the other hand, are computationally expensive.
Approach	Though the user can design the wrinkles according to her wish, it is worthwhile to study the strain patterns in the garment.
Approach	As stated in the formulation (Appendix A), solution to equation 4 exists if the input pattern is not constant.
Approach	This gives maximum weight (W 1 = 1,W 2 = 0) to pattern 1.
Approach	Each pattern, for instance, features a “principal wrinkling direction”.
Approach	However, as one can see from equation 11 in Appendix A, they depend only on quantities that are known prior to entering the animation loop and can therefore be calculated once at the beginning.
Approach	For the numerical integrals of the wrinkling coefficients, we use adaptive sampling in the triangular domain to give a fixed user defined error.
Approach	As the marked triangle undergoes a series of deformations (Figure 7, Stages 1-4), it may compute different values for the modulation factor for each of the wrinkle patterns ( Figure 8 ).
Approach	Hence, for the same deformation of the triangle, corresponding to each pattern, the modulation factors will be different.
Approach	There are several possibilities to deal with this restriction.
Background	Cloth has very little in-plane deformations, as most of the deformations come from buckling.
Approach	The normalization factor is important as the formulation assumes real distances for the bump map (or more precisely the displacement map).
Approach	However, in the animation a sudden switch of the pattern is not temporally coherent and is visually quite disturbing.
Approach	Note that the texture mapping coordinates do not change throughout the computations described below.
Approach	Comes back to the neutral position (Stage 3) and finally in Stage 4, stretches to the bottom right corner.
Outcome	The methodology facilitates use of small in-plane deformation stiffnesses and a coarse mesh for the numerical simulation, this makes cloth simulation fast and robust.
Background	Rather, the pattern changes according to the deformation.
Approach	Note that this transformation of the modulation factor no longer satisfies the area conservation property.
Approach	If a pattern is orthogonal to the deformation direction (as compared to the other), corresponding modulation factor will be small.
Outcome	The frames on the left side correspond to the animation without Geometric Wrinkles.
Approach	Now let us perform a series expansion of equation 9 in the transformation parameters and the modulation factor.
Approach	This is because, we are more concerned with the visual results of the animation, rather than precise area conservation.
Approach	We parameterize the area of the deformed triangle by h, that scales f (x , y ) on each triangle of the mesh.
FutureWork	We would like to extend the method by automatically creating wrinkle patterns from the strain pattern, which is currently a time consuming task.
Approach	We fit a spline function to the pattern to smooth out any discontinuities in the input.
Approach	This deformed mesh is then further processed by the proposed algorithm.
Approach	Hence, x, y denote the local coordinates of the initial triangle and x , y that of the deformed triangle .
Background	Other attempts to model wrinkles include those by Gotoda et al [ 3 , 4 ] and Wu et al [ 14 ].
Approach	By local, we mean that wrinkling effects caused by deformations are confined to the deformed areas.
Approach	Each pattern represents a distinct direction of deformation.
Approach	To avoid this sudden switch of pattern, we introduce a user definable variance around the mean value of the wrinkling coefficients, which defines a transition zone.
Approach	This is an equation for h, which we call modulation factor.
Challenge	For the coarse mesh, setting high metric (in-plane deformation) stiffnesses will not work properly.
Background	This can be looked at as area conservation property of cloth.
Approach	Note that this is a purely geometric requirement.
Approach	Let us assume the wrinkle pattern is given by the user.
Outcome	We have developed a fast and versatile method for animating realistic wrinkles, which is geometric in nature.
Approach	However, the rotational and translational parts of the transformation are irrelevant to the derivation of the algorithm.
Approach	This frees us conceptually from the “burden of mathematical correctness”.
Challenge	This is in contrast with real cloth situation.
Approach	The wrinkle patterns chosen are orthogonal to each other as shown in Figure 8 .
Approach	However, note that the wrinkling coefficients need not to be recalculated during the animation.
Background	Wrinkles add life to garments in fashion.
Approach	These two modulation factors are then plotted against each other in Figure 9 .
Approach	Based on such strain patterns (corresponding to two distinct frames of the garment animation in Figure 12 ), two wrinkling patterns are designed as shown in the Figure 14 .
Approach	Hence, higher order terms in the expansion may become significant but not predominant.
Approach	The user is given additional control for the animation by transforming the modulation map by a scale factor, clip, and bias.
Approach	This is crucial to obtain realistic wrinkling.
Background	Accurate and fast collision detection methods[ 12 ], constraint methods[ 5 , 6 ] and good deformable models[ 6 , 9 , 10 ] have proved to give quality cloth animation.
Approach	Then, a deformation in the orthogonal direction of one pattern will result in a smaller modulation factor as compared to a modulation factor for the other pattern.
Approach	• Wrinkling coefficients are sensitive to the wrinkle function and therefore to the wrinkle patterns.
Approach	One might think of several different approaches to meet this requirement.
Challenge	Here, though the problem of stiff equations has been tackled, it has been the strong motivation for the authors behind developing the methodology specifically for wrinkles.
Approach	However, for Stages 2 & 4 the modulation factors differ significantly, depending upon the direction of the deformation.
Approach	If the triangle is net compressed, h will be greater than one.
Approach	We choose this pattern for wrinkling for the deformation.
Outcome	Note that, there are very few wrinkles in the second figure as there is very little deformation of the mesh.
Background	The problem of solving stiff equations is successfully dealt with by the use of an implicit method for numerical integration by Baraff et al[ 1 ].
Approach	Thus, to animate the cloth realistically with a coarse mesh, we need to set small metric stiffnesses.
Outcome	Once the wrinkling coefficients are computed, the time spent on modulating wrinkle pattern is negligible compared to rendering time.
Approach	The modulation factor varies significantly across triangles.
Approach	They are constant with respect to the animation process.
Challenge	We would like to animate the cloth using coarse triangular mesh (typically a few thousand triangles per garment), for the reasons mentioned in the Introduction.
Approach	Note that for lower left triangles in Stage 2 of the animation, both wrinkle patterns get blended.
Outcome	From a mathematical point of view, it is clear that we have presented a solution within the approximation of small deformations.
Approach	The mesh that is the output by the simulation engine will be the deformed mesh.
Approach	These modulation factors are used to compute a modulation map which modulates the wrinkle pattern.
Approach	We introduce a local rectangular right handed two dimensional coordinate system, which is defined by choosing any edge of the triangle as the x axis ( refer to Figure 5 ).
Approach	The modulation factor h is a function of the deformation of triangle and has value around one.
Approach	The modulated wrinkle pattern, which reflects the response of the wrinkled surface to the deformation of the underlying coarse triangular mesh, is used for the rendering.
Approach	The wrinkling coefficient computation involves partial derivatives of wrinkle function f (x, y) with respect to (x, y).
Approach	C 1 , C 2 , C 3 , C 4 relate changes in the parameters a , b , d , h to changes of the area of the wrinkle function on the triangle.
Approach	Note that they are considerably orthogonal.
Approach	Very little in-plane deformations can be looked at as area conservation property of cloth.
Approach	The size of the mesh triangles actually governs the extension of local wrinkling effects.
Approach	Dark triangles are triangles with compression and depict the regions where wrinkles might appear.
Approach	In this case, we define the modulation factor to be one.
Challenge	Animating a single wrinkle pattern is not satisfactory (particularly for cloth).
Background	Real cloth has very little in-plane deformation as most of the deformations come from buckling.
Approach	Until now, the Geometric Wrinkle formulation is developed keeping in mind a general deformable model.
Approach	This mesh may represent a garment or another deformable model.
Background	The work is continuation of earlier work [ 11 ].
Approach	As it is difficult to physically simulate real life wrinkles, the user designs them interactively as a bump map on a coarse mesh cloth/garment.
Approach	On the other hand, for lower right triangle in Stage 2, the deformation direction favors one pattern clearly.
Approach	We call these expansion coefficients wrinkling coefficients.
Approach	• As we have pointed out in the discussion so far, we have derived an algorithm that is based on the area conservation property.
Approach	This property can be used for developing multi-fold wrinkling techniques.
Challenge	In order to capture realistic wrinkles on a real-life garment, from a mere geometric point of view, the number of triangles required can be easily upto a hundred thousand.
Approach	By introducing a fixed scale for the displacement or bump map on a mesh triangle, we obtain a function which, we call the wrinkle function.
Approach	We will try to modulate the amplitude of the wrinkle pattern such that, though there is a change in the area of a triangle (with the displacement map), it is invariant after applying the modulated displacement map.
Approach	If we treat a constant modulation factor for a triangle (see Figure 6), wrinkles appear patchy and one can distinctly see the triangular granules.
Approach	The user definable power n is representative of the tightness of the transition and n = ∞ is a sudden switch of pattern.
Challenge	Apart from simulation time, the large triangle count increases the rendering time and the cost significantly.
Challenge	Such a large number of triangles put cloth simulation off from interactive speeds, even with adaptive time steps, introduced recently [ 1 ].
Approach	The user defines an overall normalization factor for the texture to map wrinkle pattern to wrinkle function.
Outcome	Hence, it can be applied to general deformable models such as cloth.
Approach	This selective application of the wrinkle pattern (along with its modulation) will give a change of one pattern to the other as the deformation direction changes.
Approach	The following issues are worth mentioning about the implementation.
Approach	In other words, the direction of the deformation favors one pattern over the other.
Approach	Thus, we obtain a static wrinkled garment.
Approach	We take a geometric and texture based approach to wrinkling.
Approach	To illustrate this, let us consider simple cloth animation as shown in the Figure 7 .
Approach	The wrinkle pattern is bump or displacement mapped onto the initial mesh by the user.
Outcome	Typically, it takes 5 minutes per thousand triangles on a MIPS R10000 200 MHz processor.
Approach	As the pattern is user defined, one needs to watch for the invalidity of the solution (constant C 4 in equation 5 turn out to be zero) and therefore eliminates it.
Challenge	However, real-life wrinkling is a complex phenomenon.
Background	Cloth has very large in-plane deformation stiffnesses compared to its ability to bend and shear.
Outcome	As the calculations of the wrinkling coefficients are done on a per triangle basis, the computational time is linear with respect to number of triangles.
Approach	To avoid this, the modulation factors are linearly interpolated across triangles to give smooth Modulation Map ( Figure 6 ).
Approach	Assume that the wrinkling patterns are orthogonal to each other.
Approach	The method is inspired by the area conservation property, even though Section 3.3 points out that the empiricism introduced later does not actually conserve the area.
Approach	For Stages 1 & 3 both the modulation factors are 1 as cloth is undeformed.
Approach	Further we require f (x, y) to be continuous and that its first partial derivatives exist and also be continuous.
Background	As the bending stiffness of the cloth is small, the buckled edge exerts small forces on the vertices.
Approach	Our approach realizes overall area conservation by achieving area conservation on a per triangle basis of the mesh.
Approach	Using these inputs in step 1 (refer to Figure 5 ), the algorithm computes a set of four parameters termed wrinkling coefficients for each triangle of the mesh.
Background	Collision response methods and friction models developed so far have been rather simple for such a complex problem and robust numerics too.
Approach	In other words, the direction of the deformation “favors one pattern over the other”.
Approach	Hence, we would like to apply the technique using multiple wrinkle patterns.
Outcome	This paper describes a method to simulate realistic wrinkles on clothes without fine mesh and large computational overheads.
Background	Consider an edge of a triangle, as shown in Figure 3B .
Approach	The constants C 1 , C 2 , C 3 , C 4 are here after referred as wrinkling coefficients.
Approach	The matrix elements a and d represent scaling in the x and y direction respectively, whereas b describes a shear.
Approach	The relatively small modulation factor (say M F 1 is smaller for Stage 2) indicates that the corresponding wrinkle pattern is well oriented towards the direction of the deformation.
Approach	For simplicity of the discussion, we consider only two wrinkle patterns, though the methodology is developed for multiple patterns.
Approach	For the elongation, it will be less than one.
Approach	We employ a wrinkling pattern weight function as shown in Figure 11 to achieve the smooth transition.
Approach	The wrinkle function is a continuous real valued function, which is a spline approximation of the normalized texture as described in next item.
Approach	Using this deformation transformation and the already computed wrinkling coefficients, we compute the modulation factors.
Challenge	It is characterized by frictional forces (especially between body and cloth) which are difficult to model.
Approach	In addition, the pattern should be orthogonal to the deformations in general, as explained in section 4.1.
Background	In reality, the compression forces will buckle the edge as shown by dotted line.
Approach	The numerical computation of the formulation is trivial.
Challenge	We propose to capture gross cloth movements and deformations using a coarse mesh and the fine deformations (wrinkles) using a bump map (or a displacement map).
Outcome	It is interesting to see the smooth switch of the wrinkling patterns in the animation because of multi-fold wrinkling.
Approach	We would like to apply multiple wrinkle patterns for this animation.
Challenge	However, in the coarse mesh situation, the buckled edge is approximated by a straight line between the vertices.
Challenge	Consequently, the real life buckling is attributed to the compression of the edge.
Approach	It all depends on how the wrinkle pattern is oriented with respect to the deformation direction.
Approach	There will be a smooth transition between wrinkling patterns in this zone.
Outcome	The first figure shows the modulation of the wrinkles as per the deformation.
Approach	It is then stretched to the bottom left corner (Stage 2).
Approach	Here we explain the role played by the area conservation property in our work.
Approach	If M F 1 is much smaller than M F 2 (stage 1 in Figure 7 ), M F 1 will be smaller than (1 − variance)(M F 1 + M F 2 )/2 and M F 2 will be bigger than (1 + variance)(M F 1 + M F 2 )/2.
Approach	We start with a user defined wrinkle pattern, which is given in the form of a texture and an initial undeformed triangular mesh in 3D space.
Approach	In Stage 1 cloth is undeformed.
Challenge	In order to avoid these, one can increase fineness of triangles only in the potential regions where wrinkling might occur.
Background	In real-life, the wrinkles are not mere modulations of a fixed wrinkle pattern.
Approach	The wrinkle function and the wrinkle pattern, though referred to as the same entity, they differ in implementation.
Challenge	This is very well possible due to advances in the triangulation and interactive systems developed [ 2 , 7 , 8 , 13 ].
Challenge	Even if one wishes to have a fine triangular mesh, using robust and fast numerical solvers and having patience for long computations, it is not guaranteed that the wrinkles will be satisfactory.
Approach	The patterns have distinct wrinkles and additional irregularities to smooth out the sharp appearance of wrinkles.
Approach	The factor should be some fraction of the overall dimensions of the average triangle of the mesh.
Approach	One can scale, translate and clip it to introduce a finer control required for the animation.
Approach	First, let us state what serves as an input to the algorithm.
Approach	One could decide to restrict the simulations to small deformations where the approximation is valid and/or take into account the higher order terms in the series expansion to extend the range of validity of the approximation.
Approach	The initial mesh serves as an input to a simulation engine, which in the context of cloth simulation would be the physical model with a numerical solver.
Approach	In addition to this, the user is advised to blur the pattern.
Approach	Wrinkling coefficients for two different patterns on the same triangle will generally differ.
Approach	The wrinkle pattern is gray scale texture image defining the bump map.
Approach	It is then animated by modulating it as per cloth deformation.
Approach	We define the wrinkle function f (x, y) as the function in the coordinate system xy that results from mapping the wrinkle pattern onto the initial triangular mesh.
Approach	For example, a garment wrinkles around the shoulder of an animated character as she lifts her arm, while it is stretched on the corresponding side.
Approach	In the course of animation, as the simulation engine recalculates the deformed mesh, the procedure described above is iterated.
Approach	In the transition zone, when M F 1 and M F 2 are comparable, the two patterns will be blended smoothly.
Approach	For each triangle, we compute the deformation transformation that relates the corresponding triangle of the initial and the deformed mesh.
Approach	The final bump/displacement map is the product of the modulation map and the wrinkling pattern.
Approach	Therefore, the same deformation applied to a triangle will yield two different modulation factors (one for each pattern).
Approach	Instead, we propose a pragmatic approach.
Approach	For small deformations around the identity transformation and h = 1, a first order expansion represents a good approximation for the value of the surface area over a deformed triangle.
Approach	For the reasonable numerical accuracy and stability, the wrinkling pattern needs to be smooth.
Approach	Locality is introduced in our algorithm by working on a per triangle basis.
Approach	This is in fact a simple power function with an appropriate scaling and clipping.
Approach	If we assume a high metric stiffness associated to this compression, the corresponding forces on the vertices will be high.
Outcome	Moreover, the ability to design wrinkles (even on generalized deformable models) makes this method versatile for synthetic image generation.
Approach	The deformation of the triangle can be described by a general 4D homogeneous coordinate transformation.
Approach	The key theme is conservation of cloth area.
Approach	This is because, inappropriately placed wrinkles in the region where there is no deformation will not animate satisfactorily.
Outcome	The method inspired from cloth wrinkling problem, being geometric in nature, can be extended to other wrinkling phenomena.
Approach	As stated in Section 3.3, two different wrinkle patterns give different wrinkling coefficients for the same triangle geometry.

Outcome	Animation results are presented for a very large nonlinear finite element model of a human hand rendered in real time at minimal cost to the main CPU.
Approach	Vertex displacements between a given pose and the SSD model are mapped back to the neutral character pose, providing a displacement field pose correction.
Approach	Instead of storing displacements for key poses (which may be numerous), we precompute principal components of the deformation influences for individual kinematic joints, and so construct error-optimal eigenbases describing each joint’s deformation subspace.
Approach	Notice that this limit is not hard since careful choices and packing of per vertex data permit more than 10 of the 16 available tuples to be allocated for EigenSkin data.
Background	Significant work has occurred in graphics for deforming articulated characters using geometric methods [Magnenat-Thalmann et al. 1988; Singh and Kokkevis 2000; Lewis et al. 2000] and physicallybased methods [Wilhelms and van Gelder 1997; Scheepers et al. 1997; Gourret et al. 1989].
Background	It is extremely popular for its simplicity and plausibility, and is also widely supported by graphics hardware accelerators.
Approach	As guaranteed by PCA, adding successive corrections with the eigendisplacement basis provides approximations which are better in a formal, least squares, sense [Golub and van Loan 1996].
Approach	For notational convenience, suppose the articulated figure has a tree structure, i.e., does not have loops, such as for humanoids, and joints are denoted by the index of the adjacent bone furthest from the root of the hierarchy.
Background	A hybrid approach which effectively combines SSD and morphing, is the work of Lewis et al. who introduced “Pose Space Deformations” (PSD) [Lewis et al. 2000] to overcome the limitations of linear transform blending while retaining a kinematic approach.
Approach	If a vertex is in many supports then the number of eigendisplacements renderable by current hardware may be too severely restricted.
Approach	Our interpolation is one dimensional since all our observations involved perturbations of individual joints.
Approach	We denote u ˆ jk the eigendisplacement i of vertex i in the basis of support j with importance k where k goes from 1 (the principal component) up to |P j |.
Background	Despite this, most character animation in interactive applications, such as video games, is based on a geometric skeletal deformation technique commonly referred to as linear blending, or matrix palette skinning, or Skeletal-Subspace Deformation (SSD), in which vertex locations are weighted averages of points in several coordinate frames (see [Magnenat-Thalmann et al. 1988; Magnenat-Thalmann and Thalmann 1991]).
Approach	For example, in our case we used four percent of the maximum observed displacement (we will see that memory constraints also play a large part).
Approach	In this case it is useful to smoothly mask the support groups to smaller regions, otherwise fewer eigendisplacements must be used.
Approach	Principal Component Analysis (PCA) of joint support displacements yields an orthogonal displacement basis, which we term eigendisplacements.
Background	Modern vertex programming hardware (e.g., [Lindholm et al. 2001]) is ideally suited to performing the per-vertex weighted linear superposition of eigendisplacements (contained in the large brackets of Equation 2) performed prior to the SSD weighted transformation.
Approach	Let P j ⊂ P be the set of pose indices used to compute the support for joint j and let S j be the set of vertex indices in the joint support.
Outcome	Using commodity graphics hardware, EigenSkin enables the simulation of subtle nonlinear surface deformations of geometrically complex models at little more than the cost of rendering.
Background	While methods have been proposed to address this and have been effectively employed by the motion picture industry [Lewis et al. 2000], due to memory and graphics hardware constraints nearly all video game character animation is still done using traditional SSD.
Approach	For each joint j we construct a rectangular matrix, A j , of size 3|S j | × |P j |, whose columns consist of the x,y, and z components of the vertex displacements on the joint support.
Approach	Our approach is to start with an artist’s SSD approximation of the character in question, as well as with geometry corresponding to particular key poses not well approximated by SSD.
Approach	Likewise, bending one finger of our finite element hand model does not cause noticeable deformations in the others (see Figure 4 ).
Approach	Let P be the set of indices of observed poses with 0 ∈ P representing the rest pose and let the observed vertex positions and bone transforms for pose p ∈ P be denoted as v p and T p , respectively.
Background	We note that a large class of pose-dependent quasi-static deformations can be described using the EigenSkin approach, largely independent of their origin, whether artist-drawn, measured, or anatomically based physical models.
Approach	Finite element analyses were performed on a cluster of modern workstations and consumed several hundred CPU hours.
Approach	Note that the matrix V j and the singular values combine to gives the coordinates of our observed displacements in the eigendisplacement basis.
Outcome	As shown in Figure 7 , the eigendisplacement approximations of the hand model produce a clear improvement over the traditional SSD algorithm.
FutureWork	While good eigendisplacement bases can often be constructed using displacements resulting from single joint motions, in practice it is desirable to allow general pose sets and to recover nonlinear joint-joint coupling phenomena.
Approach	Conveniently, the least squares solution for any number of eigendisplacements, n j , is available from the singular value decomposition computed in Section 2.3.
Approach	Radial basis function interpolation of the pose-space data is performed on the main CPU, with eigendisplacement amplitudes and bone transforms set as input parameters to the EigenSkin vertex programs which are compiled as static display lists.
Approach	Note that Equation 2 provides a powerful model for shape deformation (see, in particular, [James and Pai 2002a]).
Approach	i Instead of choosing each n j individually, we take an equal number of eigendisplacements from each support.
Approach	That is, J i = { j|i ∈ S j } ⊂ B\{0}.
Approach	Pose-dependent deformations are then expressed in terms of these reduced eigenbases, allowing precomputed coefficients of the eigenbasis to be interpolated at run time.
Challenge	Rendering of complex physical deformation models for character animation remains a significant hurdle for interactive applications, but one that has been largely overcome for off-line animation.
Approach	The hand was moved into various poses by applying position constraints to vertices adjacent to the rigid bones, and computing the resulting tissue deformation using geometrically nonlinear static finite element analyses [Zienkiewicz 1977] with (a modified version of) the CalculiX program [Dhondt and Wittig].
Outcome	EigenSkin constitutes an error-optimal set of eigenbases for approximating the original deformation model, for a given amount of per-vertex displacement memory.
Background	Radial basis functions [Powell 1987] (RBF) are a common choice for interpolating scattered data, and have been used by Lewis et al. [Lewis et al. 2000] for pose space deformation and by Sloan et al. [Sloan et al. 2001] for shape interpolation with articulated figures.
Outcome	We introduce a method for extending SSD that enhances its range of modeling capabilities at very little cost, and in a manner optimized for real time graphics hardware.
Background	Like our method, interpolation occurs in the rest pose before SSD is applied, however, the interpolation involves blending over all of the example shapes for every vertex.
Background	Although the pose displacements computed for independently perturbed joints may be used as a basis for describing displacements of new configurations, significant redundancy exists in the pose displacements, e.g., skin bulging in similar directions.
Outcome	The deformations can be compactly represented in an efficient datadependent basis and rendered in real time using vertex shaders in commodity graphics hardware, e.g., see [Lindholm et al. 2001].
Approach	Note that we consider only single joint perturbations due to the high dimensionality of our hand model’s configuration space.
Approach	Although the process is shown for displacements, it applies similarly to the construction of linear normal corrections, allowing EigenSkin to correct SSD for both shape and shading.
Approach	For the truncated set of eigendisplacements at each support, we need the coordinates in the truncated basis which give displacements closest to the observed displacements.
Background	Related deformation topics include a morphable model for face synthesis [Blanz and Vetter 1999], modal analysis for dynamic vibrations [Pentland and Williams July 1989 ; James and Pai 2002a], decomposition of static deformations [Bookstein 1989], and recognition applications in computer vision, e.g., face recognition [Turk and Pentland 1991].
Approach	If the deformations vary smoothly over pose space, then interpolated displacements provide a good approximation of deformations at configurations between observations.
Approach	Although the finite element model deformations resulting from a change to a single joint are global, the displacement magnitudes are imperceptible at vertices that are far from the joint.
Approach	Instead of storing these displacement fields for each key pose and then interpolating between them at runtime, as in Pose Space Deformation (PSD) [Lewis et al. 2000], we use Principal Component Analysis (PCA) to construct an error-optimal eigendisplacement basis for representing this potentially large set of pose corrections.
Challenge	We present a technique which allows subtle nonlinear quasi-static deformations of articulated characters to be compactly approximated by data-dependent eigenbases which are optimized for real time rendering on commodity graphics hardware.
Approach	Approximately half a dozen poses were computed for each joint degree of freedom to estimate the locally supported joint eigendisplacements, and 25 additional poses were computed for validation.
Outcome	We refer to the final resulting character skinning construct as the model’s EigenSkin.
Approach	The surface skin model and matching skeleton are based on Loop subdivision [Loop 1987] of a hand mesh exported from Curious Labs Poser [Curious Labs Inc.
Approach	Note that the joint supports depend on the SSD weights and in general they do not correspond to the sets of vertices influenced by bone transforms.
Approach	For revolute joints, we can easily compute the distance, r, by comparing the joint angles directly.
Approach	At this point we can truncate each eigendisplacement basis expansion knowing that the error will be minimized in the least squares sense.
Approach	Letting n j < |P j | be the size of the truncated basis set of joint support j, this constraint can be written as max n j |J i | ≤ maximum possible displacements.
Background	More closely related to character animation is anatomically based modeling of physical deformable models [Wilhelms and van Gelder 1997]; examples include musculature [Chen and Zeltzer 1992; Scheepers et al. 1997] and faces [Lee et al. 1995].
Background	For example, pose-space parameterization of nonhysteretic cloth on articulated characters has recently been considered [Herman 2001], and could be optimized for hardware rendering using the techniques presented herein.
Outcome	Even with only five leading eigendisplacements, the EigenSkin approximation is essentially indistinguishable from the original FEM model.
Background	Depending on the number of eigendisplacements used, the weighted eigendisplacement vector accumulations are about as costly as the weighted transform matrix-vector multiplyaccumulate operations.
Approach	This leads us to the problem of computing the eigendisplacement coordinates for arbitrary configurations.
Approach	Nevertheless, we can still approximate linear coupling effects since we let the joint supports overlap.
Approach	We refer to the set of vertices significantly affected by a joint motion as the joint support.
Outcome	Currently, our unoptimized implementation renders the EigenSkinned hand model only slightly slower than the traditional SSD model.
Approach	To find the support of a joint we compute the deformations that result from moving the joint to different positions in its full range of motion while keeping all other joints fixed to the rest pose position.
Background	Nevertheless, such approaches are common, especially for facial animation [Parke et al. 1996].
Outcome	We illustrate our method by rendering a very large finite element model (which took several hundred hours to compute) at interactive rates on a PC with negligible cost to the main CPU.
Approach	The hardware limits the size of each truncated basis set as there is a limited amount of per vertex data memory in which we can send the eigendisplacements to the EigenSkin vertex program (see Section 2.5).
Background	Finally, the use of reduced eigenbasis representations for highdimensional models has a long history in science, with foundations on Principal Component Analysis and Karhunen-Loeve theory [Jolliffe 1986; Hyvarinen et al. 2001].
Approach	Our interactive simulation uses a CyberGlove [Immersion Corporation] input device to interactively drive our EigenSkin hand model, while graphical feedback is rendered using OpenGL and a GeForce3 graphics card.
Approach	These coordinates are computed to interpolate between observed displacements, as shown below.
Approach	In the singular value decomposition, A j = U j D j V T j , the matrix U j has the same size as A j and consists of columns of eigendisplacements for support j in the same block column format that was used to build A j .
Outcome	Despite these limitations, the model reasonably describes bulk tissue deformations and was sufficient to illustrate our method.
Approach	For joints with more than one rotational degree of freedom, we compute distance as the angle in the axis-angle representation of the joint’s rotation matrix.
Approach	This yields reasonable bone weights which change smoothly over the mesh.
Approach	As an articulated character moves between observed configurations, its shape should interpolate the observed poses.
Background	Current vertex programs limit per vertex data to 16 4-tuples of floats.
Outcome	The resulting memory sensitive set of locally supported eigendisplacement basis functions constitutes the EigenSkin approximation, and is well suited to rendering in graphics hardware.
Background	Such models have been widely used [Terzopoulos and Fleischer 1988; Terzopoulos and Witkin 1988; Metaxas and Terzopoulos 1992; CaniGascuel 1998; O’Brien and Hodgins 1999; Pai et al. 2001; Allen et al. 2002], although most approaches are not intended for real time (hardware) rendering.
Approach	To make our hardware implementation possible, we exploit the observation that localized changes to the configuration of an articulated character often result in local deformations.
Background	While these approaches give animators great control over character deformation, they have the disadvantage of requiring a potentially very large number of poses for animation, and also lack an underlying kinematic model.
Approach	In the case of our hand model, however, we only have approximately half a dozen pose perturbations for each joint degree of freedom (for a total of approximately 120 poses).
Approach	To illustrate our EigenSkin method, we have constructed a finite element model of the human hand (see Figure 6 ) which exhibits subtle nonlinear skin deformations.
Outcome	EigenSkin works best when SSD corrections are localized, providing independence between different parts of the mesh, and are stable (i.e., corrections vary slowly over posespace), allowing accurate and efficient interpolation.
Background	This becomes inefficient and difficult to map to hardware with the large number of examples required for a highly articulated figure since the independence of abstract space dimensions is not taken into account (e.g., bend in left elbow and bend in right elbow).
Outcome	A large 55,904 triangle hand model renders at 47 frames per second (FPS), while a coarser 13,976 triangle model achieves 181 FPS.
Approach	We use Gaussian interpolation shape functions, φ (r) = exp(−r/r 0 ).
Approach	Instead, we decompose the model into locally supported domains learned from the influence of individual joints on the displacement fields (described in detail in Section 2.2).
Approach	Ideally, with a large number of observed joint perturbations per support we would interpolate using fewer interpolation basis functions ( φ ) than observations.
Background	At run time, the character may be simulated by mapping interpolated displacements onto the underlying SSD character model, thereby providing a kinematic deformation model which also has artist-drawn poses.
Approach	Computing principal components with the Euclidean norm is equivalent to computing the singular value decomposition (in the case of a square symmetric matrix it is equivalent to eigenanalysis).
Approach	In our one dimensional case, the α jk only depend on the distance of joint j from its settings in poses P j .
Background	Our interest is more closely related to quasi-static deformation, for which fast deformation techniques also exist [Cotin et al. 1999; James and Pai 1999] but are unfortunately restricted to small deformations unlike those associated with articulated characters (although see [James and Pai 2002b]).
Background	This independence occurs in most articulated characters, and certainly exists in realistic human hands.
Background	One alternative is to store a large database of character poses, and interpolate between them [Maestri 1999].
Approach	Denoting 0 ∈ B as the root, joints have nonzero index.
Approach	To do this we interpolate the eigendisplacement coordinates of the observed configurations.
FutureWork	However, an alternate approach involves optimizing bone weights to allow better EigenSkin approximations of the displacements and normals.
Outcome	The method extends the common Skeletal-Subspace Deformation (SSD) technique to provide efficient approximations of the complex deformation behaviours exhibited in simulated, measured, and artist-drawn characters.
Approach	In our implementation we impose a limit of 10 eigendisplacements per vertex (or 5 eigendisplacements and 5 normal corrections), which still leaves room for texture coordinates after specifying the vertex position, normal, colour, and bone weights.
Background	While this is a big improvement over character morphing, and sufficiently interactive for animators, storing surface displacements for each pose in a large pose space is a memory inefficient approach for hardware applications.
Approach	A finite element mesh containing 11,171 high-order 10-node tetrahedral elements was generated using NETGEN [Schoberl 1997] (and subsequent simplification).
Approach	We compute our SSD bone weights as a function of vertex bone distances in the neutral pose.
Approach	The set of vertices having a displacement larger than a given threshold in any of these computed poses then becomes the support of this joint.
Background	Recently, approaches for fast simulation of physical dynamic volumetric deformations have appeared [Zhuang and Canny 1999; Debunne et al. 2001; Picinbono et al. 2001] for interactive applications, such as surgical simulation.
Approach	Furthermore, let J i be the set of joints whose supports contain vertex i.
Outcome	The resulting EigenSkin construct allows subtle character deformations for skin and clothing, such as those derived from highly realistic artist-drawn poses, measurements from the real world, or laboriously computed anatomically and physically-based models.
Approach	Although we could use a simpler interpolant, we also choose RBFs because they extend easily to the higher dimensional domains needed to let EigenSkin capture nonlinear multi-joint coupling effects (a subject of future work).
Challenge	In addition to character poses created by 3D artists, we also wish to efficiently render deformation behaviour computed using physically-based and reality-based deformable models.
Approach	The singular values, in the diagonal matrix D j , identify the importance that each eigendisplacement has in reproducing the observed poses (they relate to the proportion of variation explained by each principal component).
Outcome	We assume that an initial SSD model is provided and then show how the EigenSkin corrections are beneficial.
Approach	Filtering may be required to force each bone’s weights to zero at the edges of its influence to prevent discontinuities.
Challenge	In this paper, we present a practical technique which overcomes all aforementioned SSD problems, and can be achieved using a memory-efficient linear correction to the traditional SSD method.
Background	Currently, most real time character animation, e.g., for video games, is done using a very common linear transform blending technique called (among other things) Skeletal-Subspace Deformation (SSD) [Magnenat-Thalmann et al. 1988].
Outcome	Our results confirm that the EigenSkin method is an effective tool for character skinning when compressed hardware renderable approximations are required for an articulated character’s nonlinear quasi-static deformations.
FutureWork	In principle, the weights can be computed to optimize the quality of the EigenSkin correction, and this is a topic of future research.
Approach	However, we do not simply use PCA on the displacement field defined over the entire surface, since this would lead to a large number of important basis functions and be inefficient for hardware rendering.
Background	The abstract space consists of dimensions describing global properties of the shape, such as age and gender, but also includes dimensions used to describe configuration, such as the amount of bend at an elbow.
Background	Bending a single joint in one finger, though difficult without bending any other joints, does not cause noticeable deformations in the other fingers.
Background	Similar to PSD, Sloan et al. show a more efficient method of interpolating an articulated figure using example shapes scattered in an abstract space [Sloan et al. 2001].
Background	Starting with a (simple) SSD model, they then store vertex displacement offsets between the SSD surface and various character poses.
Approach	This justifies our use of interpolation basis functions since the total cost of constructing and evaluating the RBF interpolant for half a dozen poses is negligible.
Approach	Vertex program hardware can then efficiently render nonlinear skin deformations using a small number of eigendisplacements stored in graphics hardware.

Approach	To compute the weight of an edge, we use the difference between joint positions and velocities and the difference between the torso velocities and accelerations in the torso coordinate frame.
Approach	This graph is not a particularly helpful representation because it is extremely large — we can easily have tens of thousands of nodes and hundreds of thousands of edges — and it obscures the structure of the sequences.
Background	However, automatic generation of motion demands is required for autonomous intelligent robots and characters [Funge et al. 1999].
Outcome	However, as the attached video suggest, the randomized search has no problem finding rare motions that turn back to satisfy the constraints.
Approach	During the search, we need to find paths close to optimal solutions but do not require exact extrema, because they are too hard to find.
Approach	This motivates a random search.
Outcome	The framework is also appli- cable to non-human motion synthesis.
Background	These controllers can be designed specifically to accomplish particular tasks [Brogan et al. 1998; Hodgins et al. 1995] or they can be learned automatically using statistical tools [Grzeszczuk and Terzopoulos 1995; Grzeszczuk et al. 1998; Mataric 2000].
FutureWork	For example, the animator could interactively select the motions that need to be used during the synthesis, and only the portion of the motion graph involving the desired motions could be loaded.
Outcome	In this paper, we present a framework that generates human motions by cutting and pasting motion capture data.
Background	They also used a similar approach to fetch missing degrees of freedom in a motion from a motion capture database [Pullen and Bregler 2002].
Outcome	Finally, motions are generated interactively — typically depending on the quality of the path desired, an acceptable 300 frame motion is found in between 3 and 10 seconds on an average PC (Pentium III at 800 Mhz).
Outcome	This framework is completely automatic.
Approach	Hard constraints are easily dealt with; we restrict our search to paths that meet these constraints.
Approach	Instead, we collapse all the nodes (frames) belonging to the same motion sequence together.
Approach	We cluster unconnected edge groups of G from the P matrices (defined between every pair of nodes) using k-means ma joraxislength [Bishop 1995].
Outcome	The randomized search scales linearly as a function of the database size with a very small constant.
Approach	Include a few new valid random “seed” paths 6.
Approach	The motion should have a specified style (such as happy or energetic) at a particular time.
Approach	A particular joint should be at a particular position (and maybe having a specific velocity) at a specific time.
Approach	We now have: (P st ) i j = C(s ∞ i ,t j ) otherwise.
Approach	For an edge e from s i to t j , let f romMotion(e) = s, toMotion(e) = t, f romFrame(e) = i, toFrame(e) = j and cost(e) be the cost associated with the edge (defined in Appendix A).
Outcome	Note that as the database size gets larger, the constant τ (Appendix A) that is used to create the edges can get lower since more motions mean that we expect to find better connections between motions, decreasing the number of edges.
Approach	This way, we can constrain the moving figure to be at a specific pose at a specific time.
Background	Notice that this algorithm is similar to MCMC search (a good broad reference to application of MCMC is [Gilks et al. 1996]).
Approach	For example, instead of considering all valid paths, we can restrict ourselves to valid paths that pass through particular nodes at particular times.
Challenge	It is difficult to synthesize motion that looks natural, particularly when it is people who must move.
Outcome	It can easily synthesize multiple motions that interact with each other using constraints.
Approach	Start with a set of n valid random “seed” paths in the graph G 2.
Challenge	This may mean using previous motion capture data to generate new motions so that certain requirements are met, transferring motions from one skeletal configuration to another so that we can animate multiple figures with the same motion without it looking “funny”, or changing the style of the motion so that the directors can have higher level control over the motion.
Approach	In our system, we used 60-100 football motions that have a strong bias towards motions that run forward.
Approach	The weights can be manipulated to increase/decrease the influence of a particular soft constraint.
Background	The resulting Markov chain can be searched using dynamic programming to find a motion that connects two keyframes [Molina-Tanco and Hilton 2000] or used in a variable length Markov model to infer behaviors [Galata et al. 2001] or directly sampled from to create new motions [Bowden 2000].
Approach	Every motion is discretely represented as a sequence of frames each of which has the same M degrees of freedom.
Approach	In this setting, any sequence of edges e 1 · · · e n where toMotion(e i ) = f romMotion(e i+1 ) and toFrame(e i ) < f romFrame(e i+1 ), ∀i, 1≤i < n is a valid path and defines a legal sequence of splices.
Background	An example would involve fixing the feet so that they do not penetrate or slide on the ground, lengthening or shortening strides and fixing constraint violations.
Approach	There may be substantial differences between equally valid paths — in the example above, whether you dawdle at one side of the room or the other is of no significance.
Approach	Replace a sequence by selecting two edges e i and e i+ j where 0 ≤ j ≤ n − i, deleting all the edges between them in the path and connecting the unconnected pieces of the path using one or two edges in the top level graph G (if possible).
Background	Post processing involves fixing small scale offensive artifacts.
Approach	This allows an intuitive computation cost vs. quality tradeoff.
Approach	This suggests summarizing the graph to a higher level and coarser presentation that is easier to search.
Approach	Score each path and score all possible mutations 3.
Outcome	We have tried datasets of 50-100 motions without a noticeable change in the running time of the algorithm.
Outcome	Since the generated motions are obtained by putting pieces of motions in the dataset, the resulting motions will also carry the underlying style of the data.
Approach	Accept the mutations that are better than the original paths 5.
Approach	This approach can generate motion sequences that satisfy a variety of constraints automatically.
Approach	However, our clustering method does not operate on body configurations and our probabilistic search strategy is more effective than dynamic programming as it will be explained below.
Approach	Note that we require that we have at least two body constraints enforcing the position/orientation of the body at the beginning of the synthesized motion (so that we know where to start putting the frames down) and at the end of the synthesized motion.
Approach	Where w c ,w f ,w b and w j are weights for the quality (continuity) of the motion, how well the length of the motion is satisfied, how well the body constraints are satisfied and how well the joints constraints are defined.
Approach	While searching this graph, we would like to be able to generate different alternative motions that achieve the same set of constraints.
Approach	The body should be at a particular position and orientation at a particular time.
Approach	If cutting from one sequence to another along an edge introduces a discontinuous motion, then the cost attached to the edge is high.
Approach	Since in the summarized graph, there are relatively fewer edges, we can quickly find edges that connect the two unconnected nodes by checking all the edges that go out from toMotion(e i ), and enumerating all the edges that reach to f romMotion(e i+ j ) and generate a valid path.
Approach	Note that an error that is visible on a short person may not be visible on an extremely large person.
Background	A roadmap of all the motion examples can be constructed and searched to obtain a desired motion [Choi et al. 2000; Lee et al. 2002; Kovar et al. 2002].
Approach	We will first find a path in G and then push it down the hierarchy to a path in G for synthesis.
Approach	The position and orientation of the body at the constraint times are found by putting the motion pieces implied by the subsequent edges together ( figure 1 ).
Approach	One example is the squared distance between the position of the constraint and the actual position of the body at the time of the constraint.
Approach	We define hard constraints to be those that can (and must) be satisfied exactly.
Approach	Thus, in our summarized graph G , each edge is the root of a binary tree and represents all the edges in close neighborhood in terms of the edge labels.
Challenge	In this paper, we present a framework that allows synthesis of new motion data meeting a wide variety of constraints.
Approach	If a motion sequence cannot generate a mutation whose score is lower that itself, we decide that the current path is a local minimum in the valid path space and record it as a potential motion.
Approach	We assess our results using four criteria.
Background	Types of probabilistic search algorithms have also been used in physically based animation synthesis [Chenney and Forsyth 2000] and rendering [Veach and Guibas 1997].
Outcome	Secondly, the motions generated by the method do not have unnatural artifacts such as slipping feet on the ground or jerky movement.
Approach	For example, if the motions in our database are marked with their individual stylistic attributes, we can also constrain the style of the desired motion by penalizing motions that do not have the particular style.
Approach	We require that, if there is a cut between two sequences represented by an edge between two nodes in G, there be at least one edge between the corresponding nodes in G .
Outcome	We have presented a framework that allows interactive synthesis of natural looking motions that adhere to user specified constraints.
Approach	In order to insure that this condition holds and because the graph is very large, we cluster edges connecting every pair of nodes in G separately.
FutureWork	Additional post processing may involve physically based modelling to make sure the synthesized motions are also physically correct.
Approach	Currently, we can constrain the length of the motion, the body’s position and orientation at a particular frame ( figure 5 ,6), a joint (e.g. head, hand) to a particular state at a particular frame ( figure 7 ), or constrain the entire body’s pose at a particular frame (figure 8).
FutureWork	Automatic integration of higher level stylistic constraints could be incorporated into the framework, avoiding the arduous job of labelling every motion with the intrinsic style by hand.
Approach	There are, in general, many perfectly satisfactory motions that satisfy the constraints equally well.
FutureWork	This would give animators a tool whereby they can select the set of motions to work with in advance and the new motions will be created only from the artist selected set.
Background	Obtaining motion demands involves specifying constraints on the motion, such as the length of the motion, where the body or individual joints should be or what the body needs to be doing at particular times.
Approach	This is an online algorithm which can be stopped at anytime.
Approach	In general, at the frames corresponding to the edges in the path, we will have C 0 discontinuities, because of the finite number of motions sampling an infinite space.
Approach	Typically, a hard constraint involves using a particular frame in a particular time slot.
Approach	This enables us to search for motions such as jumping, falling, or pushing a button at a particular time.
FutureWork	Furthermore this encourages comprehensive re-use of motion data.
Approach	Demoting two edges to their children and replacing them with one of their children if they can generate a valid path.
Approach	Since the path is sampled at the coarse level, a graph search can also be performed between the constraint nodes.
Background	This is similar to our work.
Challenge	It is very hard to obtain motions that do exactly what the animator wants.
Approach	This involves taking all the frames of motion toMotion(e i ) between frames f romFrame(e i+1 ) and toFrame(e i ) and putting the sequence of frames starting from where the last subsequence ends or from the first body constraint if there is no previous subsequence.
Approach	There would be an edge from every frame to every frame that could follow it in an acceptable splice.
Approach	J: For joint constraints, we compute the squared distance between the position of the constraint and the position of the constrained joint at the time of the constraint and sum the squared distance between the two.
Approach	We also assume that the edges in G are attached a cost value which tells us the cost of connecting the incident frames.
Outcome	During the synthesis we can not only synthesize the final robot motion but also the associated control signals that achieve specific goals.
Approach	The first body constraint is always satisfied, because we always start putting the motions together from the first body constraint.
Approach	We also add the sum of the costs of the edges along the path to make sure we push the search towards paths that are continuous.
Approach	Branch and bound algorithms are of no help here, because very little pruning is possible.
Challenge	In order to make motion capture widely available, the motion data needs to be made re-usable.
Outcome	This speed allows interactive motion authoring.
Outcome	The framework can work on any motion dataset: it can be created by traditional key framing, physically based modelling or motion capture.
Outcome	This way, we can take the motion data for one character, and produce more motions with the intrinsic style of the character.
FutureWork	During the construction of the final motion, better ways of smoothing between adjacent motions could be used to improve realism [Popovic 1999].
Approach	In this graph, there would be (at least) an edge from the k’th frame to the k + 1’th frame in each sequence.
Approach	Let P(s i ) be a 3 × n matrix of positions of n joints for s i in torso coordinate frame.
Challenge	There are many applications that demand large quantities of natural looking motion.
Approach	For each constraint, we compute a cost where the cost is indicative of the satisfaction of the constraint.
Approach	This way, we can obtain multiple motions that satisfy the same set of constraints.
FutureWork	Using better post processing, motions could also be synthesized on non-uniform surfaces which the current framework cannot handle.
Outcome	The synthesized motions are strictly bound to the motions that were available in the original dataset.
Approach	The algorithm can find these “local minimum” motions that adhere to the same constraints.
Background	In the movie industry, motion demands are usually generated by animators.
Challenge	Satisfying complex timed constraints is difficult and may involve many motion capture iterations.
Approach	In a computer game environment, we can constrain the synthesized motion to avoid obstacles in the environment.
Approach	The synthesized motion is created from example motions at interactive speeds.
Background	Different body sizes move according to different time scales, meaning that motion cannot simply be transferred from one body size to another; modifying motions appropriately is an interesting research problem [Hodgins and Pollard 1997].
Approach	Many constraints cannot be satisfied exactly.
Approach	Selecting a collection of clips that yields an acceptable motion is a combinatorial problem that we manage as a randomized search of a hierarchy of graphs.
Approach	If the weight of an edge is too high, it is dropped from the graph.
Approach	The animator can choose between them or all the different motions can be used to create a variety in the environment.
Approach	Note that here we assume the underlying motion graph is connected.
Approach	For example, position differences in feet are much more noticeable than position differences of hands because the ground provides a comparison frame.
Approach	Since edges connect frames, they are labelled with the frames in the incident nodes (motion sequences) that they originate from and they point to.
Approach	The number of clusters is chosen as minoraxislength for each group where the axis lengths refer to the ellipse that fits to the cluster (obtained through Principal Component Analysis).
Approach	The collection of motion sequences could be represented as a directed graph.
Approach	We wish to construct paths in the motion graph that satisfy constraints.
Outcome	This framework allows the extensive re-use of motion capture data for new purposes.
Approach	This is important, because motion synthesis is inherently ambiguous as there may be multiple motions that satisfy the same set of constraints.
FutureWork	An automatic way of summarizing the portions of the “possible human motions” space that have not been explored well enough by the dataset could improve the data gathering and eventually the synthesized motions.
Approach	However, it is difficult to compute proposal probabilities for the mutations we use, which are strikingly successful in practice.
Background	Generating motion largely follows two threads: using examples and using controllers.
Approach	(b) Delete some edges of the path and replace them with their children 4.
Approach	The motion graph is too hard to search with dynamic programming as there are many valid paths that satisfy the constraints equally well.
Background	Example based motion synthesis draws on an analogy with texture synthesis where a new texture (or motion) that looks like an example texture (or motion example) needs to be synthesized [Efros and Leung 1999; Heeger and Bergen 1995].
Outcome	On the other hand, some constraints, may not be met by any motion.
Approach	To make sure that we interpolate the body constraints (i.e. having a particular position/orientation at a particular frame), we take the difference between the desired constraint state, subtract the state at the time of the constraint and distribute this difference uniformly over the portion of the motion before the time of the constraint.
Approach	Where diagonal (n + 2) × (n + 2) matrices M and T are used to weight different joints differently.
Outcome	This will lead to a sublinear increase in the running time.
Background	Motion is one of the most important ingredients of CG movies and computer games.
Background	A standard solution is motion capture: motion data for an approximate skeletal hierarchy of the subject is recorded and then used to drive a reconstruction on the computer.
Approach	To determine the configuration of the body at the time at which the constraint applies, we must assemble the motion sequence up to the time of the constraint; in fact, most of the required information such as the required transformation between start and end of each cut is already available in the dataset.
Outcome	The integrity of the original dataset directly effects the quality of the synthesized motion.
Background	The motion signals can also be clustered.
Approach	Instead we score sequences using an objective function that reflects how well the constraint has been met and attempt to find extremal sequences.
Approach	For an edge e from s i to t j , we set cost(e) = C(s i ,t j ).
Approach	Thus, in theory, the weights must be adjusted from person to person.
Outcome	Randomized search is well suited to find many different motions that satisfy the constraints.
Approach	Note that these “smoothing” steps can cause artifacts like feet penetrating or sliding on the ground.
Approach	We can stop the search iteration, take the best path found so far, and create a motion sequence.
FutureWork	This could also serve as a palette for artists: some portions of the precomputed motion graph can be paged in and out of memory depending on the required motion.
Approach	Thus, given high level goals (such as going from point A to point B, say) human looking motions can be generated automatically.
Background	Obtaining realistic motion usually involves key framing, physically based modelling or motion capture.
Challenge	Examples include being at a particular position at a particular time accurately or synchronizing movement to a background action that had been shot before.
Outcome	For example, we can take the motion data for “Woody” – who may well have been key-framed, from “Toy Story” and create new “Woody” motions automatically.
Approach	We wish to have a weight on edges of the motion graph (section 3.1) that encodes the extent to which two frames can follow each other.
Background	These constraints can come from an interactive editing system used by animators, or from a computer game engine itself.
Approach	In order to search the graph G in practical times, we need to do the search at a variety of levels where we do the large scale motion construction first and then “tweak” the details so that the motion is continuous and satisfies the constraints as well as possible.
Approach	This allows interactive manipulation of the constraints.
Approach	For example, if we require only that the person be at one end of a room at frame 0 and near the other end at frame 5000, unless the room is very large, there are many motions that satisfy these constraints.
Approach	Since the summary has significantly fewer edges than the original graph, this step is not very expensive.
Approach	We do this by multiplying the magnitude of the discontinuity by a smoothing function and adding the result back to the signal ( figure 4 ).
Approach	B: For body constraints, we compute the distance between the position and orientation of the constraint versus the actual position and orientation of the torso at the time of the constraint and sum the squared distances.
Approach	For example, if the user asks for 100 meters in 5 seconds, the algorithm will tend to put fast running motions together but not necessarily satisfying the constraints.
Outcome	If there are hard constraints in different unconnected components, we will not even be able to find starting seed paths.
Approach	This involves starting to sample the random paths from the hard constraint nodes and greedily adding sequences that get us to the next hard constraint if any.
Approach	A path in G represents a sequence of clips; so does a path in G , but now the positions of the clip boundaries are quantized, so there are fewer paths.
Background	An overview of the automatic motion planning can be found in [Latombe 1999; O’Rourke 1998].
Approach	We check every possible mutation, evaluate them and take the best few.
Approach	F: For the number of frame constraints, we compute the squared difference between the actual number of frames in the path and the required number of frames.
Approach	In such a representation, every level is a summary of the one finer level.
Outcome	The average precomputation time required for this many motions (computing the motion graph) is 5 hours on the same computer.
Approach	Notice that we can synthesize multiple interacting motions independently using hard constraints ( figure 9 ); we simply select the poses, position and orientation at which the figures interact and this framework fills in the missing motion, in a sense, interpolating the constraints.
Approach	In the appendix A, we give one natural cost function C(s i ,t j ) for edge weights.
Outcome	The algorithm generates multiple motions that satisfy a given set of constraints, allowing a variety of choices for the animator.
Approach	In such a case, body position/orientation constraints can also come from an underlying path planner.
Approach	We selected these weights such that an error of 10 frames increases the total score the same amount as an error of 30 centimeters in position and 10 degrees in orientation.
Background	The sampling can also be done in the motion domain to pick clips of motions to establish certain simple constraints [Lamouret and van de Panne 1996; Schodl et al. 2000].
Challenge	Most motion capture systems are very expensive to use, because the process is time consuming for actors and technicians and motion data tends not to be re-used.
Approach	We then define the normalizing matrices O and L in equation 3 and 4.
Approach	We do this by ensuring that “seed” paths meet these constraints, and mutations do not violate them.
Approach	We have found M and T matrices empirically by trying different choices.
Approach	The (i, j)’th entry of P st contains the weight of the edge connecting s i to t j and infinity if there is no such edge.
Outcome	The linearity in the running time comes from the linear increase in the number of alternative mutations at every step.
Outcome	For example, this framework can be used to generate control signals for robots to achieve a particular task by generating the motion graph for previously known motion-control signal pairs.
FutureWork	However, it is conceivable that the motions that are very close to the dataset could also be incorporated in the synthesizable motions using learned stylistic variations.
Approach	Doing this mutation on two edges simultaneously allows us to compensate for the errors that would happen if only one of them was demoted.
Approach	Finding paths in the motion graph that satisfy the hard constraints and optimize soft constraints involves a graph search.
Approach	Given a sequence of edges e 1 · · · e n , we score the path using the imposed soft constraints.
Approach	if there is an edge from s i to t j The cost function explained in section A causes the P matrices to have non-infinite entries to form nearly elliptical groups ( figure 2 ).
Approach	Unfortunately, defining a universal cost metric is a hard problem.
Approach	We define the torso coordinate frame to be the one where the body stands centered at origin on the xz plane and looks towards the positive z axis.
Approach	However, in practice, possible size variation of adult people is small enough that we used the same weights for different people without creating a visible effect.
Challenge	Although physically based modelling can be applied to simple systems successfully, generating realistic motion on a computer is difficult, particularly for human motion.
Approach	Thus we do not have to reach the leaf graph G to be able to create a path (motion sequence).
Outcome	Firstly, the motion looks human.
Approach	Based on the scores for each of the constraints, we weight and sum them to create a final score for the path (The S function in equation 1).
Approach	We create the final motion by taking the frames between toFrame(e i ) and f romFrame(e i+1 ) from each motion toMotion(e i ) where 1 ≤ i < n ( figure 1 ).
Approach	A soft constraint cannot generally be met exactly.
Approach	Similarly, if the set of motions to begin with do not form a connected graph, the algorithm will perform searches confined to the unconnected graphs.
Approach	If the sequence is not good enough, we can resume the search from where we left off to get better paths through mutations and inclusion of random paths.
Outcome	From this perspective, the selection of the database to work with is important.
Approach	This is due to the fact that if two frames are similar, most probably their preceding and succeeding frames also look similar.
Approach	We used the following search strategy:
Approach	Note that we enumerate only 0 or 1 hop edges (1 edge or 2 edge connections respectively).
Approach	As long as the user specifies a cost function that evaluates a motion and attaches a score that is indicative of the animator’s satisfaction with the path, many more constraints can be implemented.
Approach	Typically hard constraints specify the frame (in a particular node) to be used at a particular time.
Approach	Each frame would be a node.
Background	Controller based approaches use physical models of systems and controllers that produce outputs usually in the form of forces and torques as a function of the state of the body.
Approach	These are only a few of the constraints that can be implemented.
FutureWork	By analyzing patterns in the motion dataset, we might also infer these styles or obtain higher level descriptions [Brand and Hertzmann 2001].
Approach	All the edges between two nodes s and t can be represented in a matrix P st .
Background	This usually involves optimization of a suitable displacement function on the motion signal.
Approach	Using this cost metric, we create edges from s i to t j where C(s i ,t j ) < τ .
Background	Pullen and Bregler used this approach to create cyclic motions by sampling motion signals in a “signal pyramid” [2000].
Approach	The motion databases that we used were unorganized except that we excluded football warming up and tackling motions unless they were desired ( figure 9 ).
Approach	We write the i’th frame of s’th motion as s i .
Outcome	For many kinds of constraints the motion synthesis problem is underconstrained; there are many possible combinations of motion pieces that achieve the same set of constraints.
Approach	The main reason is the need to enumerate many paths.
Approach	The total number of frames should be a particular number.
Approach	We assume there is a set of N motion sequences forming our dataset, each belonging to the same skeletal configuration.
Approach	Unfortunately, for even a small collection of motions, the graph G has a large number of edges and straightforward search of this graph is computationally prohibitive.
Approach	However, usually the errors made in terms of constraints and the discontinuities are so small that they are unnoticeable.
Outcome	They are generated in real time so that we can author complex motions interactively.
Approach	This is due to the fact that edges in intermediate graphs G · · · G n also represent connections and are valid edges.
Outcome	Once the input motions are selected, the computation of the hierarchic motion graph does not require any user intervention and the resulting representation is searched in real-time.
Approach	This yields a graph G where the nodes of G are individual motion sequences and there is an edge from s to t for every pair of frames where we can cut from s to t.
Approach	This is required to be able to compare two motions and to be able to put clips from different motion sequences together.
Approach	Let G ← G ← G ← · · · ← G n ← G be such a hierarchical representation where G is the coarsest level and G is the finest.
Approach	At every iteration we check if the proposed mutation deletes a motion piece that has a hard constraint in it.
Approach	We implemented two types of mutations which can be performed quickly on an active path.
Background	Generating motion involves obtaining a rough motion that satisfies the demands.
Outcome	For example, if the incoming motion dataset does not contain any “turning left” motions, we will not be able to synthesize motions that involve “turning left”.
Approach	The motion should not penetrate any objects in the environment.
Approach	Since the algorithm is interactive, the animator can also see the ambiguity and guide the search by putting extra constraints ( figure 6 ).
Outcome	In this case, randomized search will try to minimize our objective motion and find the “closest” motion.
Approach	Since we start new random “seed” paths at every iteration, the algorithm does not get stuck at a local optimum forever.
Approach	This is done by rotating and translating every motion sequence so that each piece starts from where the previous one ended.
Approach	Note that the leaf edges are the edges in the original graph and intermediate edges are the averages of all the leaf edges beneath them.
Approach	We choose the smoothing domain to be ±30 frames (or one second of animation) around the discontinuity and
Approach	For example, we generated the real-time screen captures in the attached video using a dataset of 60-80 unorganized, short (below 300 frames each) motion capture fragments.
Approach	The collapsed graph still has the same number of edges.
Outcome	Third, the user specified constraints are satisfied, i.e. the motion passes through the required spot at the required time, or the character falls to a particular position ( figure 8 ).
Background	The clips in this roadmap can also be parameterized for randomly sampling different motion sequences [Li et al. 2002].
Approach	Any point p in the torso coordinate frame can be transformed to the global coordinate frame by T (s i ) + R(s i ) · p , where T (s i ) is the 3 × 1 translation of the torso and R(s i ) is the 3 × 1 rotation of the torso and R(s i ) represents the rotation matrix associated with the rotation.
Challenge	Creating natural looking motions with key framing requires lots of effort and expertise.
Approach	If this were not the case, our summary would rule out potential paths.
Outcome	On average, the results shown in the video contain 3-30 motion pieces cut from the original motions.
Challenge	In this paper, we describe a technique that cuts and pastes bits and pieces of example motions together to create such a motion.
Approach	Using iterative improvements of random paths, we are able to synthesize human looking motions interactively.
Background	This allows other CG characters to be animated with the same motions, leading to realistic, “human looking” motions for use in movies or games.
Approach	In practice these discontinuities are small and we can distribute them within a smoothing window around the discontinuity.
Approach	Coarser levels should have less complexity while allowing us to explore substantially different portions of the path space.
Approach	Since during the search all the paths live in a subspace implied by the hard constraints, these constraints are always satisfied.
Background	The motion data can also be post processed to fix problems such as feet sliding on the ground or some constraints not being satisfied [Gleicher 1998; Lee and Shin 1999; Popovic 1999; Rose et al. 1996].
Approach	We now have an expression of the form:
Approach	Such mutations are rejected immediately.
Approach	For example, given two positions, there may not be any sequence of frames in the collection that will get us from the first position to the second position exactly.
Approach	Then the cost function function in equation 5 is used to relate s i to t j .
Outcome	The metric defined above produces visually acceptable results.
Outcome	The motions are smooth and human-looking.



