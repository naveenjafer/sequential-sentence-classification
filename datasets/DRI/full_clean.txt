Outcome	We present a new collision resolution scheme for cloth collisions.
Challenge	Our main concern is to find dynamically convincing resolutions, i.e. positions and velocities of cloth elements, for any kinds of collisions occuring in cloth simulation (cloth-cloth, cloth-rigid, and cloth-cloth-rigid).
Approach	We define our cloth surface as connected faces of mass particles where each particle is controlled by its internal energy functions.
Approach	Our collision resolution method finds appropriate next positions and velocities of particles by conserving the particles’ momentums as accurately as possible.
Challenge	Cloth-cloth collision resolution is a special case of deformable N-body collision resolution.
Approach	So to solve deformable N-body collision resolutions, we propose a new collision resolution method, which groups cloth particles into parts and resolves collisions between parts using the law of momentum conservation.
Approach	To resolve collisions, we solve a system of linear equations derived from the collision relationships.
Approach	A system of linear equations is built using a scheme adapted from the simultaneous resolution method for rigid N-body collisions [ 1 ].
Approach	For the special case where we can find cyclic relationships in collisions, we solve a system of linear inequalities derived from the collision relationships.
Background	Collision handling in Computer Graphics has two phases.
Background	One is to detect collisions and the other is to resolve collisions.
Background	In cloth collision detection, the computation time to detect collisions is not negligible because the number of geometrical entities (nodes, faces, edges) the collision detection algorithm has to handle is considerable (over 10,000 particles for regular attire).
Background	For this reason, several approaches have tried to expedite the collision detection processes [ 16 , 3 ].
Background	Collision resolution is to find the correct next positions and velocities of colliding objects.
Background	Cloth resolution methods so far have found non-penetrating positions, velocities and accelerations of cloth surface particles [ 14 , 3 , 15 ].
Background	This scheme works fine for cloth-rigid collisions and for the special case of cloth-cloth collisions where the dynamic interactions between cloth surfaces in cloth-cloth collisions do not have to be noticeable.
Background	Volino et. al. [ 15 ] applied the conjugate gradient method to find the actual particles’ positions where a group of particles are colliding into each other.
Background	By preserving barycentric relationships of collision entities, their method resolves collisions where numerous cloth surfaces are colliding together as a group, which is a novel way to resolve multiple collisions at once.
Background	However it does not conserve the momentum of cloth surfaces in cloth-cloth collisions.
Background	Another method for cloth-cloth collisions has been proposed by Provot [ 12 ], which resolves collisions by giving an average velocity to all the particles of collisions.
Background	Provot’s method is easy to implement but it cannot give proper visual effect of collisions since we cannot get dynamic interactions between particles once the particles collide into each other.
Background	Cloth-cloth collision resolution is a special case of deformable N-body collision resolution.
Outcome	To solve deformable N-body collision resolutions, we propose a new collision resolution method which gives a visually reasonable response by ensuring the conservation of N-body momentums.
Approach	Our cloth system is particle-based, as many systems are in other cloth research groups [ 14 , 6 , 12 , 3 ].
Approach	To resolve collisions, we first divide the colliding particles into parts and build a system of linear equations based on the collision relationships between these parts.
Approach	Then we solve the whole system using the law of N-body momentum conservation.
Approach	The system of equalities is based on the scheme adapted from the simultaneous resolution method for rigid N-body collisions proposed by Baraff [ 1 ].
Background	However his original inequality relationships between relative velocities before and after collisions are purely heuristic, which may not be physically correct.
Background	Though this physical inaccuracy has been an inherent problem of simultaneous collision resolutions, it appears to give graphically agreeable results.
Outcome	Hence with the help of the law of N-body momentum conservation, we found the results of our resolutions are visually acceptable.
Background	A swept volume is a volume made by two sets of positional entities of a face one at time t and one at time t + t .
Approach	Connecting these old and new positions of all particles in a face gives us a volume.
Background	Any collision happening within an integration time step always can be detected by this swept volume method, unless the motions of faces are highly rotational.
Approach	An interesting case is where the faces are not actually intersecting but two swept volumes report a intersection anyway.
Approach	Though this case is not an actual collision, it happens only when two faces are very close.
Approach	Hence we resort to the collision report of this case, since we consider this case as a violation of the proximity law.
Approach	We use classical edge-polygon detection algorithms to detect collisions among swept volumes.
Approach	We use this swept volume approach for cloth and the dynamic rigid body alike, but for the non-moving rigid body only the surface faces are used for collision detection.
Approach	In addition, we add proximity regions to the normal directions of faces of a swept volume to add proximity violation regions.
Challenge	Though detected collisions are reported as pairs of face-face, we cannot respond to each collision individually since these individual responses may introduce another new collision or one face may possibly be related to several other collisions.
Approach	So we save all detected collisions in a data structure, i.e. a set of zones of impact [ 12 ] during the collision detection phase.
Approach	All stored detected collisions will be resolved comprehensively by the rule described in the next section.
Background	Originally a zone of impact (IZ) is an area where multiple self-collisions occur [ 12 ].
Approach	We extend Provot’s definition of an IZ to an area where collisions happen, including collisions against bodies and self-collisions.
Approach	An object O is a set of particles, faces, and edges, where faces and edges are defined based on the positions of particles by the rule comprising cloth surface.
Approach	An area A is a subset of O such that all the particles and edges constituting a face in A are members of A .
Approach	An area A is called separable when, for all faces 2 A , does not collide with any face in A .
Approach	An area A is called colliding when, for all faces 2 A , collides with at least one face in A .
Approach	An IZ is a separable colliding area.
Approach	An area A is called visitable when, for all particles P 2 A , P can be encountered by traversing from any other particle in A using edges in A .
Approach	Otherwise, the area A is non-visitable.
Approach	We call a visitable subset area of an IZ a collision cluster (CC).
Approach	When a face-face collision is detected, the entities of each colliding face (the particle and the edges of , and itself) are inserted into a CC, where the CC can be encountered by traversing from the particles in using only edges in .
Approach	When there is no such CC, becomes a CC.
Approach	When two or more such CCs are found, these CCs are merged into one CC connected by .
Background	A widely used method for detecting cloth collisions is to put small repellent proximity forces between the cloth surface and the rigid or cloth surface [ 4 , 14 , 3 ] while the actual collisions are tested with pairs of particle-face or face-face of the current positions.
Background	When objects are moving fast, however, these preventive proximity forces cannot prevent collisions since a particle can pass through the proximity violation region during one integration time step.
Background	This problem can be negligible when the integration time step is very small, so we rarely have those pass-through cases.
Background	Numerous approaches [ 14 , 12 , 3 , 15 ] have been introduced for cloth collision resolution: the correct next positions and velocities of colliding cloth particles.
Background	So far, however, no cloth collision resolution method which considers cloth-cloth momentum conservation has been introduced, while we cannot achieve realistic cloth interactions in cloth animation without conserving cloth-cloth momentums.
Background	Having this characteristic is visually distinctive when cloth surfaces are moving fast and interact with each other.
Background	For rigid N-body collisions by graphics and robotics groups [ 11 , 1 , 10 , 9 ] and for flexible-rigid collision resolution [ 2 ], several approaches have been suggested.
Challenge	But they are not directly applicable for deformable N-body collision resolutions, which is the case cloth requires.
Background	Cloth resolution methods so far compute non-penetrating positions, velocities or accelerations of particles [ 14 , 3 , 15 ], which work fine for the collisions against fixed bodies.
Challenge	Using these methods, however, we cannot achieve visually satisfying dynamics of cloth-cloth collisions.
Background	Adjusting particle orientations after collision resolution as suggested by [ 14 ] to sustain the geometrical consistency of colliding faces also does not warrant reasonable dynamic movements of cloth-cloth collisions.
Background	Handling collisions in an IZ as a bundle, proposed by Provot [ 12 ], also does not give a proper visual effect.
Outcome	We propose our cloth collision resolution method which resolves simultaneous collisions while ensuring conservation of momentum as accurately as possible.
Approach	Since simultaneous resolution does not blindly resolve a collision without considering neighboring collisions within an IZ, we do not introduce any new collisions while resolving a collision.
Approach	After we handle each IZ separately, we check whether any new collisions between IZs are introduced by collision resolutions, and handle them if there are any.
Approach	In an IZ, we first check whether it has CCs from rigid bodies.
Approach	In case we do not find any CCs from rigid bodies, the collisions in that IZ are categorized as cloth-cloth collisions.
Approach	If we find CCs from rigid bodies in an IZ, we extract them temporarily from the IZ so that only cloth-cloth collisions remain in the IZ.
Approach	After resolving these cloth-cloth collisions, we take care of cloth collisions against rigid bodies so that the resolutions against rigid bodies will be done on top of the result of self-collision resolutions.
Approach	This sequence of resolutions is chosen to avoid the case where self-collisions are ignored while collisions against rigid bodies are handled.
Approach	For some cases, an IZ has only one CC (for example, in the case of extreme bending).
Approach	When an IZ has only one CC, we cannot handle the particles in that CC as a bundle as usual.
Approach	Since the particles in that CC will stick together after resolution, the movements of cloth would not be natural and satisfactory.
Approach	Hence we divide one CC into parts so that we can find proper collision responses within these parts.
Approach	Segmenting one CC into parts is performed by identifying border edges.
Approach	A border edge is an edge where we identify a “significant” bending between two faces adjoining in that edge.
Approach	When an IZ has three or more CCs, we reduce the total number of CCs by merging closely located CCs.
Approach	This merger is performed to prevent undesirable collision resolution.
Approach	If CCs are closely located, it means the cloth patches represented by these CCs are closely located.
Approach	We do not want to handle closely located CCs separately since it might instantly introduce instabilities to the system by allowing closely located CCs to have different velocities.
Approach	However, there is an exception.
Approach	When we find a significant bending between these closely located CCs, we have to resolve collisions between these CCs by handling them separately.
Approach	Bending between CCs is considered significant in the same way as in the case of bending between faces.
Approach	We do not want to handle closely located CCs separately except for the case where the bending is significant (CCs are considered to be closely located heuristically when they can be connected using at most two edges which are not members of both CCs).
Approach	Hence the candidates of the CC merger are the CCs closely located, where we do not witness any significant bending between the CCs.
Approach	After merging, we still possibly have more than two CCs.
Approach	By definition, an IZ is a set of CCs.
Approach	Since we pre-processed a single CC IZ previously, we assume an IZ always has two or more CCs.
Approach	The important part of the collision resolution of these multiple CCs is to find the proper directions of collisions.
Approach	Collision direction is a direction to which two CCs collide into each other.
Approach	Since the velocities of CCs after collision are computed based on this collision direction, finding the correct collision direction is important to achieve proper visual effect of collisions.
Approach	In the case of the two billiard ball collision, the collision direction is computed by connecting the two ball centers of mass.
Approach	But in cloth-cloth collisions, connecting two centers of CC masses is not a proper way to decide the collision direction.
Approach	We choose the collision direction to be the average direction of the two face normals of colliding CCs.
Approach	To have the proper average direction, the CC face normals, N 1 and N 2 , have to be properly signed as N 1 N 2 0 .
Approach	The face normal of a CC is the average normal of all faces in the CC.
Approach	We handle a CC as a sphere mass where the diameter of the sphere reflects the minimum proximity region.
Approach	This approach serves us well empirically.
Approach	The velocity of a CC is defined as the average velocity of all particles in that CC.
Approach	When we have collisions of three or more CCs in an IZ, it is not straightforward to resolve the collisions.
Approach	As has been discussed in multiple collisions of rigid bodies, we can think of two ways to solve this multiple cloth collision problem.
Background	One way of resolving these multiple collisions is to handle them as staggered collisions [ 11 , 10 ]; the other way is to handle them as simultaneous collisions [ 1 ].
Background	The staggered collision approach handles multiple collisions as a series of single collisions [ 11 ] or desynchronized groups of collisions [ 10 ].
Background	The simultaneous collision approach treats multiple collisions as simultaneous collisions within a time-step.
Approach	The staggered collision approach gives us a more physically correct solution than the other.
Approach	In the synchronized staggered collision method, we have to find the first collision among multiple collisions.
Approach	After we resolve it, we march the time step until we find the next collision.
Approach	Then we repeat the same procedure.
Approach	This whole process is not only computationally expensive but also we have to consider the possibility that the resolution of a collision can create new multiple collisions, which we have to employ another strategy to resolve.
Approach	In the desynchronized staggered collision method, we identify groups of collisions, and redefine the integration front-end by allowing time desynchronization.
Approach	In addition to the substantial computational expense and complexity, the visual advantage of those staggered methods is not considered significant compared to that of the simultaneous collision method.
Background	The simultaneous collision handling method, proposed by Baraff [ 1 ], resolves multiple rigid body collisions by solving a system of linear inequalities, where the system of linear inequalities is based on the colliding relationships between rigid objects.
Approach	When CC bodies are considered as vertices, an edge exists between two vertices where the bodies represented by those two vertices collide.
Approach	We call the resultant graph a collision graph.
Approach	When the collision graph of an IZ has a loop, we call the collisions in the IZ cyclic.
Approach	However a problem arises when collision resolutions of an IZ create new collisions against objects around the IZ.
Approach	This happens when objects do not move fast enough to penetrate objects outside an IZ, but just fast enough to make the result of collision resolutions penetrate the proximity region of objects outside the IZ.
Approach	To our relief, this case appears to be very rare.
Approach	However we can resolve this case by maintaining the barycentric relationship between cloth surfaces and the newly introduced colliding entities.
Approach	Apparently, in the worst case, this involves repetitious processes as we may introduce other new collisions when we resolve the current collisions.
Approach	For the special case where we observe cyclic collisions in an IZ, we build a system of linear inequalities based on the collision rela- tionships between grouped particle parts.
Approach	We find the feasible solution of the linear inequality system, while trying to minimize the energy we introduce into the simulation artificially.
Approach	This inequality relationship between the relative velocities before and after collision is an artificial relationship set up heuristically, not based on physics.
Approach	This inequality relationship, first used for rigid body multiple collisions [ 1 ], appears to serve the graphical purpose well.
Approach	The system of inequalities with an objective function can be solved using a Linear Programming Method.
Approach	If an IZ has CCs from rigid bodies (rigid CCs) along with CCs from cloth (cloth CCs), the collision resolutions against rigid bodies are performed after cloth-cloth collisions are resolved.
Approach	When an IZ has rigid CCs, collision responses are different based on whether rigid CCs are moving or fixed or a mixture of both.
Approach	If the rigid CCs in an IZ are all fixed, we handle particles in that IZ individually.
Approach	Where N face is the normal of a rigid face, V is a particle velocity, V normal and V tangential are the normal and tangential components of V with respect to the rigid face, particles are considered separating if V normal N face 0 .
Approach	Particles are ignored if they are not in the vicinity of a face in fixed rigid CCs, where the size of vicinity is the thickness of cloth.
Approach	Furthermore, particles separating from the rigid bodies are also ignored.
Approach	The new particle velocity V new is , C e V normal + C f V tangential , where C e is an elastic coefficient and C f is a frictional coefficient.
Approach	If the rigid CCs in an IZ are all moving, we handle particles as a bundle as long as particles are in the vicinity of moving rigid CCs.
Approach	We find the x and the velocity V rigid of a moving rigid CC, where V rigid is defined as the translational velocity of the center of mass of the moving rigid CC.
Approach	Then the positions of all particles we have to handle will be incremented by x and the velocities of the particles will be updated as V rigid .
Approach	If an IZ has both moving and fixed rigid CCs along with cloth CCs, collision resolutions against rigid bodies are done based on the proximities of particles to the rigid CCs.
Approach	Cloth collision resolutions against rigid CCs will be computed based on the closest rigid CC.
Approach	Collisions between rigid bodies (rigid-rigid) have to be handled independently from cloth collisions.
Approach	All our simulations were done on SGI Octane with R10000 CPU and R10010 FPU.
Approach	For numerical integration, we used the CG method proposed by Baraff [ 3 ].

Outcome	We present a method to control the behavior of elastic, deformable material in a dynamic simulation.
Outcome	We introduce dynamic morph targets, the equivalent in dynamic simulation to the geometric morph targets in (quasi-static) modeling.
Outcome	Dynamic morph targets define the pose-dependent physical state of soft objects, including surface deformation and elastic and inertial properties.
Approach	Given these morph targets, our algorithm then derives a dynamic model that can be simulated in time-pose-space, interpolating the dynamic morph targets at the input poses.
Approach	Our method easily integrates with current modeling and animation pipelines: at different poses, an artist simply provides a set of dynamic morph targets.
Approach	Whether these input states are physically plausible is completely up to the artist.
Outcome	The resulting deformable models expose fully dynamic, pose-dependent behavior, driven by the artist-provided morph targets, complete with inertial effects.
Outcome	Our deformable models are computationally efficient at runtime through modal reduction and pose-space polynomial interpola-	     tion.
Outcome	These models can therefore be plugged into existing dynamic simulation engines, either forming interactive, deformable content in real-time games or providing secondary dynamic effects for kinematically-driven characters in feature animation films.
Outcome	Finally, our method also facilitates certain time-consuming rigging procedures, by providing a physically based approach to resolve co-articulation deficiencies in traditional skinning methods, such as in shoulder regions, fully automatically.
Challenge	Animation of skin and muscular deformations of human characters and other living creatures has long been one of the most important applications of deformable modeling in computer graphics, notably in feature animation and more recently in increasingly realistic computer games and interactive medical and training applications.
Challenge	Realistic deformation is a complex and subtle phenomenon due to the tightly coupled interplay of bones and musculature governing the deformations.
Background	Generally speaking, there are three common approaches for modeling surface deformation: purely kinematic, example-based and physically based.
Background	Purely algorithmic approaches for skeleton-driven [Kavan and Zara 2005] and facial deformations [Pighin and Lewis 2006] are very fast, but have difficulty in capturing realistic skin deformation in areas with multiple influences.
Background	Example-based approaches capture more realism by pose-space interpolation of desired skin shapes at different poses [Magnenat-Thalmann et al. 1988; Mohr and Gleicher 2003; Kry et al. 2002; Lewis et al. 2000].
Background	Physically based deformation algorithms, governed by the physics of muscle motion and tendon influences, provide automatic means to achieve dynamic deformations under influence of external forces and inertial effects, but are computationally more expensive [Chadwick et al. 1989; Gourret et al. 1989; Chen and Zeltzer 1992; Scheepers et al. 1997; Wilhelms and Gelder 1997; Sifakis et al. 2005].
Challenge	Our approach seeks to bridge the gap between geometric examplebased methods and physically based approaches.
Outcome	We introduce dynamic morph targets, i.e. predefined and possibly artist-authored physical descriptors of skin deformations and elastic material properties.
Outcome	• A compact way of interpolating skin geometry, elastic forces, and their derivatives, all in a unified manner.
Outcome	• The extension of the method to support modal reduction and therefore very efficient implementation that is linear in the number of coefficients of the force polynomial.
Outcome	The main advantages of our method over previous approaches are three-fold: quality of deformations, dynamic behavior and computational efficiency.
Approach	Although our method is physically based, we avoid expensive modeling of musculature or tendon influences, and instead rely on physical constitutive models of deformable material to minimize skin pinching artifacts and bypass complex rigging requirements that are common to purely geometric approaches.
Approach	The use of such constitutive material models also enables response to external forces and inertial effects in dynamic simulations.
Challenge	Due to performance requirements, one is commonly restricted to linear or quasi-linear models that cannot model pose-dependent effects such as bulging and wrinkling.
Approach	Instead, we guide dynamic simulations by dynamic morph targets — discrete pose-space examples of skin properties and deformations.
Background	Due to its immense importance in character animation, there has been an extensive collection of work in the area of surface deformation in the last few decades.
Background	Here, we will primarily focus on significant work related to control of surface deformation of kinematic and dynamic characters.
Background	Readers are referred to extensive surveys for other important work [Gibson and Mirtich 1997; Nealen et al. 2006].
Background	Purely data-driven methods are an attractive choice for control purposes, as the input shapes provide guide examples of desired deformations.
Background	In its most essential form, one simply interpolates between character poses in a large database [Maestri 2006], providing ample control of skin deformation to animators.
Challenge	However, many poses are required in the database to achieve good results.
Challenge	Purely data-driven methods lack a kinematic model, making them of limited use for animation and dynamic simulation.
Background	Purely kinematic approaches such as skeletal-subspace deformation (SSD) [Magnenat-Thalmann et al. 1988] model the deformation of the skin surface by linear blending of the animated bone transformations.
Background	This technique, also known as linear blend skinning, cannot capture complex deformations and typically has problems deforming skin near joints due to collapsing geometry (i.e. pinching), because the deformation is restricted to the subspace of the affine transformation of the joints.
Background	Different methods have been proposed to address the problems of linear blend skinning by inserting additional joints tuned from examples [Mohr and Gleicher 2003], or employing blending of transformations instead of weights [Kavan and Zara 2005], among others.
Background	Recent techniques have extended skinning to mesh deformations [James and Twigg 2005], motion capture data without a predefined skeleton [Park and Hodgins 2006], or interactive models [Der et al. 2006].
Background	Unlike shape interpolation and other data-driven methods, SSD does not permit direct sculpting or control.
Background	Instead, artists have to tweak vertex weights, giving SSD algorithms the reputation of being tedious to control.
Background	The first work to add control in a kinematic approach is that of pose-space deformations [Lewis et al. 2000].
Background	PSD is a hybrid method that combines SSD with morphing and employs scattered data interpolation to compute non-linear skin corrections in posespace, resulting in a kinematic model that also has artist-sculpted poses.
Background	When dealing with large pose-spaces that have many example poses, PSD becomes memory inefficient due to the large database of surface displacements.
Background	PSD can be extended to support per-vertex pose-space deformation (WPSD) [Kurihara and Miyata 2004; Rhee et al. 2006], largely reducing the number of required example poses.
Background	The EigenSkin method [Kry et al. 2002] also provides a way to reduce per-vertex displacement memory footprint by computing an error-optimal set of eigenbases for approximating the original deformation model.
Background	Other recent methods [Weber et al. 2007; Wang et al. 2007] learn example-based corrections on sparse points and assume that these corrections can be smoothly interpolated.
Background	Pose space deformation and related example-based methods allow for direct sculpting of geometric morph targets, but are purely kinematic approaches to (quasi-)static deformation, without reference to underlying forces or mass.
Approach	Our method builds on the concept of pose-space deformation and applies it to pose-space interpolation of dynamic morph targets to achieve not only (quasi-)static deformations, but a fully dynamic model in time-pose-space.
Background	Finally, physically based methods in graphics are based on biomechanical models of skin tissue and musculature.
Background	In terms of efficiency versus accuracy, these methods fall into two broad categories.
Background	The first category of algorithms aim for accuracy [Chen and Zeltzer 1992; Scheepers et al. 1997; Wilhelms and Gelder 1997; Koch et al. 1996; Zordan et al. 2004; Sifakis et al. 2005; Sueda et al. 2008] by simulating the actions of the individual muscles, bones and tendons in the skin.
Background	Interactive physically based approaches trade accuracy for performance [Terzopoulos et al. 1987; Terzopoulos and Witkin 1988; Metaxas and Terzopoulos 1992; Picinbono et al. 2001; Capell et al. 2002; Müller and Gross 2004; Galoppo et al. 2007].
Background	These methods use simplified (quasi-)linear elastic models that cannot capture complex non-linear behavior such as muscle bulging.
Background	Physically based methods can only provide control through the influence of forces.
Background	While methods that control global deformation modes have been around for a while [Witkin and Welch 1990], providing control of sculpted deformations for simulation of deformable models has only recently caught attention in graphics research.
Background	A method for physically based rigging was proposed by [Capell et al. 2005], using pose-dependent forces to guide the shape of the character.
Background	In contrast to our method, their approach does not support pose-dependent elastic properties and its performance is highly dependent on the resolution of the sculpted deformations.
Background	Given an input animation, shape keyframes can be used to retarget the elastic deformations [Kondo et al. 2005] or to enhance the surface deformations with physically simulated detail using subspace constraints [Bergou et al. 2007].
Background	The former provides good control of shapes but is restricted to a given input animation, while the latter achieves rich secondary surface detail but does not provide direct manipulation of the surface.
Outcome	Our method provides the ability to sculpt the dynamic morph targets directly and produces a dynamic model that is not restricted to a given animation; our model can be plugged into any simulated environment and be subject to external forces.
Background	Modal reduction has proven useful to increase performance in posespace deformation methods [Kry et al. 2002] as well as in physically based methods [Hauser et al. 2003; Choi and Ko 2005].
Approach	Our work exploits the technique of [Barbic and James 2005] that enables fast modal integration of St.Venant-Kirchoff elastic forces, where the performance depends mainly on the number of simulated eigenmodes, not on the resolution of the model.
Outcome	This technique makes our approach suitable for real-time applications.
Outcome	To the best of our knowledge, our method is the first to provide shape and surface behavior control of dynamic reduced models.
Challenge	The goal of our method is to simulate controllable non-linear deformations by interpolation of dynamic morph targets at runtime, kindred to geometric morph targets in static character modeling.
Approach	Dynamic morph targets define pose-specific soft skin behavior.
Approach	More formally, they are pairs of elastic models E i and poses s i , i.e. pairs {E i , s i } of elastic models in pose space.
Approach	Similar to geometric morph targets, dynamic morph targets associate surface and volume deformation with character pose.
Approach	In contrast to geometric morph targets, dynamic morph targets also define pose-specific elastic properties including stiffness and plasticity.
Approach	The combination of surface deformation and elastic properties defines the elastic model E i .
Approach	We represent a pose by a vector s ∈ S where posespace S ⊂ R k .
Approach	Note that our implementation uses skeletal pose, but the concept of pose can easily be extended beyond the skeletal sense; in fact any notion of state of a character can be used, such as emotional state, velocity state, contact state, or muscle activation.
Approach	Dynamic morph targets can easily be created in existing modeling packages; very similar to creating geometric morph targets.
Approach	A modeler defines a set of m poses {s 1 , s 2 , . . . , s m } of the character and sculpts desired deformations that cannot be captured with traditional skinning methods [Kavan and Zara 2005; MagnenatThalmann et al. 1988].
Approach	Elastic properties can be assigned for each pose, such that the same skin section can be defined stiff for one pose and flabby for another pose, e.g. to mimic contraction and relaxation of a muscle, or to exaggerate skin bulging.
Approach	Dynamic characters enhanced with dynamic morph targets can react to external forces just as with other common physically based deformation algorithms, but they also expose non-linear deformations and elastic behavior as imposed by the dynamic morph targets.
Approach	Dynamic morph targets are used to build a pose-dependent elastic model E(x, s).
Approach	For hyper-elastic materials, an elastic model can be defined as a material function E(u(x)) defining the internal elastic energy at material points x in function of the deformation u.
Approach	For our experiments and in correspondence with the space in which the morph targets are defined, we choose to express elastic deformation in the skeletal bind pose as has been proposed in the past [Lewis et al. 2000; Kry et al. 2002; Galoppo et al. 2007].
Approach	On the other hand, it is certainly possible to use other formulations of elastic strain to define a pose-dependent model with dynamic morph targets.
Background	Traditionally, the elastic energy is a pose-independent material potential that causes internal elastic forces R(u) in the material.
Approach	We create a pose-dependent elastic model by taking into account the dynamic morph targets {E i , s i } as example inputs.
Approach	We use scattered data interpolation to derive an expression for the internal elastic forces R(u, s) anywhere in pose-space S, given the expressions for the elastic forces R i (u) that are imposed by the dynamic morph targets at poses s i .
Approach	However, since forces are a function of the timevarying deformation u, they cannot simply be evaluated once and then interpolated at runtime.
Approach	In our method, we have opted for elastic models for which R i (u) can be expressed as a (multivariate) polynomial function of the degrees of freedom u.
Approach	Then, the interpolation of elastic models reduces to the interpolation of polynomial coefficients.
Background	Common examples of such elastic models are the so-called ‘completely linear’ FEM deformation model (with or without stiffness warping [Müller and Gross 2004]), or the ’seminon-linear’ St.Venant-Kirchoff model (StVK) [Barbic and James 2005; Capell et al. 2005].
Approach	We have simulated our examples with both linear and semi-non-linear elastic models.
Outcome	However, because we express deformation in the skeletal bind pose, we did not see any noticeable quality difference between both elastic models in our experiments.
Approach	Therefore, we have opted for the more efficient linear elasticity to produce most of the images and videos unless otherwise noted (see Section 5).
Approach	Each polynomial R i (u) is associated with a dynamic morph target at pose s i and is uniquely defined by its set of coefficients {a k } i which we collect in a vector a i .
Approach	We can then determine the posedependent elastic force R(u, s), which is also uniquely defined by its set of coefficients a(s).
Approach	At an arbitrary pose s in pose-space, a(s) can be interpolated from the example coefficients a i .
Approach	The interpolation of polynomial coefficients yields the interpolation of force values R(u, s) at all possible deformation values u.
Approach	However, it also yields the interpolation of force derivatives, such as the ∂R(u,s) stiffness matrix .
Approach	One subtle detail remains for defining a ∂u complete interpolation of elastic models.
Approach	The rest configuration at each input pose may be different, therefore the deformation u may not be consistent across poses.
Approach	We choose a certain pose as a reference, and express the deformation of all other poses by adding the difference between rest configurations, ∆u.
Background	Conceptually, a pose can be described in many ways, as long as it provides a description of the state of a model or character, and a metric to measure distances between poses.
Approach	In our implementation, we choose the joint configuration of an articulated character as the pose descriptor.
Approach	We define the pose descriptor s ∈ R 6k , where k is the number of joints.
Approach	Each joint contributes 6 components to s, namely the 6-dof representation of its parent-relative coordinate frame.
Approach	We define distance between two poses to be the inner product of the difference of its descriptors.
Approach	As an articulated character moves between observed configurations, its elastic model should approximate the elastic models of the input poses.
Approach	As mentioned in Section 3.2, we are looking for a way to interpolate internal elastic forces R i .
Approach	Obviously, as the character moves from one pose to the other, the internal forces change continuously but highly non-linearly.
Approach	In other words, elastic forces form a non-linear smooth field in pose-space.
Background	Radial base functions [Powell 1987] (RBF) are a common choice for interpolating scattered data of an underlying smooth field that is non-linear.
Approach	Moreover, as our goal is to have as few input models E i as possible, RBFs are suited because they work well with sparse input data sets.
Approach	RBFs extend easily to high dimensional domains, enabling the capture of multi-joint coupling effects.
Approach	As mentioned in Section 3.2, we can determine the pose-dependent elastic forces R(u, s) by computing the polynomial coefficient vector a(s).
Approach	In our experiments, it was sufficient to use a constant vector Q for the polynomial Q(s).
Approach	We also employed the globally supported biharmonic RBF kernel φ(r) = r, since its optimal fairness allows for smoother interpolation of sparsely scattered example poses as compared to locally supported kernels [Carr et al. 2001].
Approach	In our experience, locally supported kernels such as the Gaussian RBF kernel are harder to tune and are unable to extrapolate across dynamic morph targets that are far apart in pose-space.
Approach	We also use the smoothing term from [Carr et al. 2001] to achieve smoother behavior across large gaps between input poses.
Approach	The combined system is underdetermined (m + 1 vector unknowns for m vectorial equations), but it can be solved by imposing orthogonality conditions on the weights w i [Carr et al. 2001].
Approach	By selecting modes with non-zero or large eigenvalues only, we reduce the dimension of s and define a mapping to the reduced pose descriptor s = U T s s.
Approach	Modal reduction of the pose descriptors is very effective for robustness, but is also useful when our method is used for facilitating rigging.
Approach	In highly complex areas of skin deformation such as the shoulder area, the skin is under influence of many bones for which the skinbone relationships cannot easily be determined by a human rigger or technical director.
Approach	Our system can automatically deduce these relationships and reduce them to only a few significant modes.
Approach	The number of coefficients is proportional to the number of nodes n in the finite element mesh for linear elastic models, and O(S 3 n) for StVK materials, where S is the average size of the neighborhood of a node.
Approach	Instead, we propose a way to increase performance and to reduce the dependency on the resolution of the input geometry by reducing the number of degrees of freedom, while still maintaining the non-linear behavior defined by the morph targets.
Approach	We use a reduced model u = Uq to enable dynamic simulation that is independent from the input resolution of the geometry.
Approach	When applying model reduction to (multivariate) polynomial elastic forces, it can be shown that the reduced forces are still (multivariate) polynomial elastic forces.
Approach	Here, P i , Q ij , S ijk ∈ R r are constant vector polynomial coefficients.
Approach	The polynomial coefficients can be precomputed, given the rest pose p i .
Approach	For linear materials, the Q ij and S ijk terms are all zero.
Approach	We can now combine scattered polynomial interpolation from Section 3.3 with the reduced motion equations by concatenating the reduced coefficients into a = [ P i ; Q ij ; S ijk ].
Approach	Just as in Section 3.3, each dynamic morph target defines a set of coefficients a i which can then be used to set up an interpolator for the posedependent coefficients a(s).
Approach	As described in Section 3.1, an artist begins by modeling the base model surface and a skeleton with associated SSD skinning weights, and defines a set of geometric morph targets.
Approach	Using vertex painting, he can then assign stiffness parameters such as Young’s modulus and Poisson ratio to certain parts of the skin.
Approach	This is where our preprocessing stage starts.
Approach	We do this by solving a homogeneous Poisson problem for the internal node weights, where the known surface node weights are set up as boundary conditions.
Approach	Then, for each morph target, a corresponding tetrahedral rest-pose mesh is defined (still in the skeletal bind pose).
Approach	This can be done by displacing the surface nodes of the base tetrahedral mesh with the morph target’s values.
Approach	We then relax the internal nodes by performing a physical simulation, constraining the new surface positions and using the elastic model of the base mesh.
Approach	For reduced elastic models, a modal subspace is also constructed (Section 4).
Approach	We also account for the inertial forces caused by the moving coordinate frames of the bones [Galoppo et al. 2007].
Approach	Additionally, we conceptually constrain the material points that are attached to internal bones.
Approach	This can be achieved by removing the elastic degrees of freedom that are associated with corresponding internal mesh nodes.
Approach	Hence, the positions of these points are then completely governed by the linear blend skinning transformations only.
Approach	We remove these degrees of freedom in our preprocessing step by identifying tetrahedral mesh elements that are intersected by skeletal bones.
Approach	Degrees of freedom that are associated with these elements are removed (i.e. they are ’fixed’ in the pose-space), unless they lie on the model’s boundary surface.
Approach	We describe here our implementation of the reduced equations of motion, through morph target aware subspace construction.
Approach	In the reduced model, the displacement vector u is expressed as u = Uq, where U ∈ R (3n,r) is the displacement basis matrix, and q ∈ R r is the vector of reduced displacement coordinates.
Approach	Here, U is a time-independent matrix specifying a basis of some r-dimensional (r << 3n) linear subspace of R 3n .
Approach	For each of the dynamic morph targets, we employ linear modal analysis (LMA), which provides the best deformation basis for small deformations away from the rest configuration.
Approach	Intuitively, modal basis vectors are directions into which the model can be pushed with the smallest possible increase in elastic strain energy.
Approach	The stiffness matrix K = ∂R(x) ∂x is evaluated at x 0 i , the rest configuration for input pose i, which defines a ‘goal’ deformation for the input poses.
Approach	Note that at this point, one could easily add modal derivatives, as in [Barbic and James 2005].
Approach	Avoid redundancy in the basis set, i.e. find an orthogonal set that is as compact as possible.
Approach	The characteristic deformations of all the morph targets have to be well represented.
Approach	The input deformations of each of the dynamic morph targets have to be well represented in the reduced space, otherwise the sculpted deformations can’t be simulated.
Approach	In other words, the basis has to be aware of the morph targets.
Approach	Instead, similar to [Barbic and James 2005], we can construct a low-dimensional motion subspace by applying mass-PCA.
Approach	We scale the derivatives according to the eigenvalues of the corresponding linear modes.
Approach	We select the first r principal modes to achieve the basis U .
Approach	Scaling is necessary to put greater weight on the more important low-frequency modes, which would otherwise be masked by highfrequency modes.
Outcome	By using pose-space efficient polynomial interpolation to achieve pose-dependent behavior, we are able to demonstrate rich nonlinear deformation effects at relatively small extra cost compared to simple simulation of linear or semi-non-linear materials.
Approach	We have performed experiments with three different input models: a simple bulging cylinder with 4 bones (see Fig. 2 ), a shoulder model with 4 bones, and Herbert, our swimsuit model with 46 bones.
Approach	We compare a single (pose-independent) elastic model with our pose-dependent elastic model that employs multiple dynamic morph targets, both with and without modal reduction.
Approach	The first morph target is a skinny version of Herbert, in which his skin is very soft and flabby, the third target is a stiff, bulged Herbert in fetal position, while the second target has been chosen in between the first and the third.
Outcome	In our video, we show Herbert’s belly deformations as he cycles between upright and fetal poses.
Outcome	While the single elastic model shows little or no dynamic behavior, our pose-dependent elastic model adds a dramatic amount of realism due to the bulging behavior and inertial skin motion.
Approach	Next, we drive the skinned Herbert model with a skeletal animation and add inertial forces due to the bone’s moving frames.
Outcome	As Herbert jumps off a diving board and flips through different poses, we show the advantage of our pose-dependent model from an artistic viewpoint.
Outcome	With single elastic models, the belly is flabby and skinny throughout the entire simulation.
Approach	Using the aforementioned morph targets for Herbert, an animator can impose a stiff, bulged belly in balled-up poses, and softer, skinny belly behavior in upright poses.
Outcome	Our video demonstrates the imposed behavior as Herbert’s belly exposes bulging and non-flabby skin when he jumps from the diving board.
Outcome	Also, in Fig. 4 , we show the use of reduced models in our method achieves the same quality of desired deformations as the computationally more expensive unreduced model.
Outcome	There is no need for manual tweaking of the complex mapping of joint configuration to blending weights of geometric morph targets.
Outcome	In our shoulder example, we have 6 morph targets, shown in Fig. 5(a) .
Outcome	The shoulder example also demonstrates our method’s ability to simulate dynamic behavior at poses away from the morph target input poses ( Fig. 5 ).
Outcome	The input morph target set contains only one example of a folded elbow but we show two distinct folding scenarios in the full animation.
Outcome	Both folding scenarios show severe self-intersection in the single pose-independent model due to the effect of linear blend skinning.
Outcome	Our pose-dependent model resolves both automatically.
Outcome	Whereas the chest seems to collapse for single elastic models, it bulges more realistically with our method.
Approach	The shoulder model has 4899 degrees of freedom.
Outcome	After modal reduction, we were able to accelerate the simulation significantly by using only 19 eigenmodes ( Table 1 ) with almost no visible effect on the simulation quality ( Fig. 5 ).
Approach	We have performed all our experiments on a 2.4 GHz Intel Core 2 Duo Macbook Pro laptop (us- ing one of its two cores), with 2 GB of RAM and a NVidia GeForce 8600M GT graphics card.
Approach	All rendering was done with the opensource Blender modeling package.
Outcome	All our methods achieve real-time performance due to efficient pose-space interpolation of low-complexity linear elastic forces and modal reduction of either linear or semi-nonlinear StVK forces.
Outcome	Comparing our method with the performance of single (pose-independent) elastic models, it is clear from Table 1 that our method has only a marginal extra cost, due to efficient polynomial interpolation of the dynamic morph target models.
Outcome	Too few input poses can cause slight popping of the animation towards the input shapes but the simulation of the pose-dependent elastic model will be stable nevertheless.
Outcome	Therefore, stable results can be achieved with little effort from the artist and poses can then be added incrementally to areas of the posespace where the behavior is not satisfactory.
Outcome	The effect of the number of poses on the run-time performance of the algorithm is very small as it doesn’t affect the number of degrees of freedom in the simulation (see comparison 6 vs. 9 shoulder DMTs in Table 1 ).
Outcome	Our dynamic morph targets add dynamic behavior to non-linear deformations such that external and inertial forces can be applied, as shown in Fig. 2 .
Background	The method by Capell et al. [2005] also enables deformations under influence of external forces, corresponding to the behavior in Fig. 2(b) , but does not influence the underlying properties of the elastic material.
Outcome	As shown in Fig 2(c) , our method can correct such undesirable behavior by setting elastic properties for each of the individual morph targets, effectively mimicking muscle contraction.
Outcome	In this paper we have presented dynamic morph targets, posedependent elastic models that allow an artist to easily author and control the geometry and elastic behavior of dynamic characters.
Outcome	Dynamic morph targets avoid complex rigging requirements of purely geometric methods, and complex musculoskeletal modeling of purely physically-based methods.
Outcome	By extending our basic framework to support modal reduction, we also achieve high runtime performance.
FutureWork	The current dynamic morph target framework can be enhanced with additional features to be included in the future, such as support for (contact) constraints, and an extension to weighted pose-space deformations [Kurihara and Miyata 2004] to allow for improved localized interpolation.

Challenge	We introduce a new method for efficiently simulating liquid with extreme amounts of spatial adaptivity.
Approach	Next, we enable subtle free-surface phenomena by deriving novel second-order boundary conditions consistent with our discretization.
Approach	We couple this discretization with a spatially adaptive Fluid-Implicit Particle (FLIP) method, enabling efficient, robust, minimally-dissipative simulations that can undergo sharp changes in spatial resolution while minimizing artifacts.
Outcome	Along the way, we provide a new method for generating a smooth and detailed surface from a set of particles with variable sizes.
Challenge	Finally, we explore several new sizing functions for determining spatially adaptive simulation resolutions, and we show how to couple them to our simulator.
Approach	We combine each of these elements to produce a simulation algorithm that is capable of creating animations at high maximum resolutions while avoiding common pitfalls like inaccurate boundary conditions and inefficient computation.
Challenge	This paper aims to produce fluid simulations with a high degree of spatial adaptivity.
Challenge	We desire to enable a simulator to focus its computational resources on the visually interesting regions of a fluid flow, while remaining computationally efficient and avoiding common artifacts due to a spatially adaptive pressure solve.
Background	Previous approaches have made great strides towards this goal, but they often exhibit visual artifacts, a lack of computational robustness, or an unacceptably hefty computational expense.
Background	The groundbreaking work of Losasso et al. [2004] introduced an octree for spatial adaptivity, but it suffers from spurious flows at T-junctions.
Background	Finite volume methods [Batty et al. 2010] repair these spatial artifacts at the expense of solving a significantly larger system of equations and sacrificing computational stability near poorly-shaped elements.
Challenge	Furthermore, many existing methods still are not truly spatially adaptive in the sense that their computational complexity is still tied to a uniform grid or spatial parameter.
Outcome	We introduce a combination of techniques that successfully makes adaptive fluid simulation practical at large scales.
Approach	We first reduce memory and computational costs by switching from a finite volume method to a discretization with a significantly smaller linear system for the pressure solve, which has the side effect of increasing the simulator’s robustness to poor-quality elements and effectively preventing locking artifacts.
Approach	We next derive second-order Dirichlet boundary conditions consistent with our discretization to benefit from the subtle surface dynamics associated with an accurate pressure solve.
Approach	We combine this robust and efficient tetrahedral meshbased fluid simulator with a spatially adaptive method for sampling particles for FLIP-based velocity advection, giving us a method free from any single spatial resolution.
Approach	In addition to our adaptive FLIP simulator, we also introduce a new method for computing a surface from a distribution of particles with variable radii.
Outcome	We found that this method out-performs previous methods in cases of extreme spatial adaptivity by exhibiting smoother surfaces without sacrificing detail.
Outcome	Our fluid simulator works well with spatially adaptive tetrahedral meshes, but it is another question to decide exactly how these adaptive meshes should be generated.
Approach	We investigate various methods for generating these adaptive meshes by experimenting with several sizing functions, allowing us to precisely dictate where simulation detail should occur.
Approach	Some examples are a surface curvature-based metric that adds detail only where needed on the fluid surface, a turbulence metric that adds detail only where interesting fluid motion occurs, and a visibility metric that adds detail only in front of a virtual camera.
Outcome	Concretely, the contributions of our work are: • a novel tetrahedral discretization of the pressure projection step that is efficient to solve and robust to poor-quality elements; • an accurate treatment of second-order boundary conditions within the tetrahedral mesh; • a new technique for extracting a smooth surface from particles with varying radii; • and the inclusion of a flexible sizing function to focus computational resources on important areas of the flow with minimal overhead.
Outcome	These contributions work together to produce a practical fluid simulator that exhibits low computational and memory complexity, fewer visual artifacts, and a high effective simulation resolution.
Approach	Our work is based on the Fluid-Implicit Particle (FLIP) method introduced to the computer graphics community by Zhu and Bridson [2005], which arguably represents the state-of the art for detailed and robust liquid simulations.
Approach	The algorithm still follows the general ideas of the Stable Fluid solver [Stam 1999], and can be readily combined with second-order treatment of free surface boundary conditions [Enright et al. 2003].
Background	FLIP derives its success from the fact that it uses particles to compute an accurate, nondiffusive transport of flow quantities, in combination with a gridbased solve to accurately enforce constraints for mass conservation.
Background	The FLIP algorithm is heavily used in the special effects industry, and recent advances have introduced accurate coupling with obstacles [Batty et al. 2007], highly viscous materials [Batty and Bridson 2008], and two-phase flows [Boyd and Bridson 2012].
Background	Traditionally, Cartesian grids are very popular for fluid simulations.
Background	The Marker-And-Cell (MAC) approach [Harlow and Welch 1965], which stores velocity components at cell faces and pressure samples at cell centers, results in discretizations with good properties in terms of stability and accuracy.
Background	An inherent difficulty is that simulations on regular grids become prohibitively expensive for large resolutions.
Background	Thus, many works have proposed methods to focus the computations on regions that are of particular interest.
Background	One example are octrees, which were used by Losasso et al. [2004; 2005] to refine the computational grid in a controllable way.
Background	This approach, however, suffers from numerical diffusion and an inconsistent discretization near the tree’s T-junctions.
Background	Targeting a similar direction as our work, Hong et al. [2009] and Ando et al. [2012] have demonstrated methods to adapt the resolution of FLIP particles in a simulation.
Background	Both methods, in contrast to ours, focus on static computational grids and are restricted to smaller differences in particle size.
Background	Although Cartesian grids are widely used, they are limited in their flexibility to adapt to a simulation setup.
Background	Because of this, tetrahedral grids are popular for methods targeting adaptivity.
Background	In combination with a suitable method to discretize the problem at hand, they allow for very flexible computational grids.
Background	One example is the work of Klingner et al. [Klingner et al. 2006] which demonstrated the use of a Stable Fluids based solver for tetrahedral grids conforming to object boundaries.
Background	Another example is the non-linear fluid solver developed by Mullen et al. [2009], which leads to an energy conserving solve.
Approach	Unlike these methods, we make use of a non-conforming grid with Body-Centered Cubic (BCC) lattices.
Background	These meshes were also used by Chentanez et al. [2007] and by Batty et al. [2010] for liquid simulations.
Approach	We will denote this class of algorithms as Finite Volume Methods (FVM).
Approach	These methods are primarily suitable for uniformly sampled particles, and we will demonstrate in Section 7 that their placement of pressure samples at tetrahedral circumcenters leads to numerical problems in combination with graded BCC meshes.
Background	Another direction of research performs fluid simulations based on arbitrary elements.
Background	Clausen et al. [2013] and Misztal et al. [2010] have proposed a method to simulate liquids with a computational grid conforming to a triangulation of a liquid surface.
Background	Both methods lead to an increased computational cost in comparison to the more efficient tetrahedral BCC meshes.
Background	Sin et al. [2009] proposed an alternative method for hybrid Lagrangian-Eulerian solvers which combines a Voronoi-based pressure solver and particles.
Background	Using this Vornoi-based approach for tetrahedral meshes would yield a pressure matrix similar to ours.
Background	Like our method, Brochu et al. [2010] used this discretization in combination with embedded second-order boundary conditions.
Background	Both of these approaches discretize velocities with per-face flux values, while we store velocity vectors at cell barycenters.
Background	Adaptive simulations have also been explored in the context of SPH simulations without Eulerian grids.
Background	The work of [Adams et al. 2007] shares similarities with our approach, as it is able to simulate a wider range of particle radii, and it proposes a surface reconstruction method in the adaptive setting.
Outcome	We will show in Section 5 that our surface creation method results in surfaces with fewer visual artifacts.
Background	Additionally, a robust and efficient method for adaptive SPH simulations was introduced by Solenthaler et al. [2011], but this work primarily targets the coupling of two different particle resolutions.
Background	Several other methods have been proposed to reconstruct smooth surfaces around collections of particles without orientation.
Background	One approach that is commonly used is to compute a signed distance function with averaged particle radii and centroids [Zhu and Bridson 2005].
Background	A variant of this approach, taking into account information about the spatial variance of the particle’s neighborhood was proposed by Yu et al. [2010].
Background	Both methods primarily target particles with constant radius.
Background	More recently, a level-set based method was proposed that computes a constrained optimization with bihar- monic smoothing [Bhattacharya et al. 2011].
Background	However, such an optimization would be complicated to apply in our unstructured setting.
Approach	In contrast to these methods, our approach for surface creation computes the union of convex hulls around triplets of particles, which leads to a smooth and closed surface around a collection of arbitrarily sized particles.
Challenge	The aim of our method is to solve the Navier-Stokes equations, which for incompressible, Newtonian, inviscid flows can be written as ρDu/Dt = − p + f , with the additional constraint · u = 0 to enforce a divergence-free velocity field.
Approach	Here, u, p and f denote velocity, pressure and external forces, respectively, while D/Dt denotes the material derivative.
Approach	The density ρ is constant in our case.
Approach	We solve these equations using operator splitting [Stam 1999], and a level set φ(x) = 0 defines the position of the liquid-gas interface.
Approach	The motion of the fluid is computed in a Lagrangian manner using particles, while the pressure projection step is computed on an Eulerian grid.
Approach	We will now describe how we compute the pressure projection using a tetrahedral discretization.
Approach	In the following, however, we prefer an alternate view that looks at this problem from an energy minimization perspective: we want to compute the minimal change in kinetic energy necessary to reach a divergence-free state of the flow similar to [Batty et al. 2007].
Approach	Here, Ω represents the domain of the computational grid, and we choose to discretize this space using tetrahedral cells.
Approach	This has the advantage of giving us a natural way to handle cells of different size, while yielding a consistent discretization of the differential operators involved.
Approach	We store pressure samples at the nodes of the tetrahedral mesh, while velocities are stored at cell centers.
Approach	Note that by assuming a piece-wise constant velocity and a linear change of pressure within a cell, this setup results in a constant pressure gradient per tetrahedron, by construction.
Approach	In the following, we denote the number of cells with m and the number of nodes with n, and we indicate discretized quantities with caret notation.
Approach	It consists of a m×n matrix, computing a per-tetrahedron gradient from nodal values.
Approach	Consequently, we define the divergence operator to be the transpose of the discretized gradient.
Approach	Before we go ahead to define [ ], we want to outline the rest of the steps for our pressure solve.
Approach	The [ ] T [ ] matrix-matrix multiplication results in a square n × n matrix, which is symmetric and positive definite.
Approach	As we assume a linear change of the pressure for each cell, we can use simple barycentric interpolation to retrieve the pressure p at a position inside a cell.
Approach	In line with finite element methods using linear elements, we define the gradient based on the partial derivatives of the barycentric interpolation.
Approach	In contrast to previous work, our pressure solve is a linear system that has n degrees of freedom, n being the number of nodes in the tetrahedral mesh.
Approach	For our BCC mesh, n is in practice smaller than the number of tetrahedra m (by a factor of 6 on average).
Approach	A direct implication of this smaller linear system is that it is faster to solve.
Approach	A second, less obvious implication of the smaller linear system is that it effectively prevents artifacts known as locking.
Approach	These artifacts are commonly observed in finite element methods for problems in elasticity.
Background	Different methods have been proposed to circumvent these problems, e.g., using linear elements for pressure instead of piece-wise constant ones [Irving et al. 2007].
Background	Other works explicitly smooth the pressure field to reduce locking problems [Misztal et al. 2010].
Approach	In general, locking can be observed if the pressure basis can represent more, and higher-frequency, functions than the basis for the velocity.
Approach	Thus, choosing a more restrictive basis for pressure, as in [Irving et al. 2007], or explicitly removing high-frequency information from the pressure [Misztal et al. 2010], reduces the chance of locking.
Approach	Our method, by construction, has more degrees of freedom for representing velocity fields than pressure fields.
Approach	Although we cannot prove that a local configuration over-constraining the velocities will never occur, the larger number of degrees of freedom for our velocities effectively prevents locking artifacts, and we have not encountered any in our tests.
Approach	For the free surface, we have to ensure that the Dirichlet boundary condition p = 0 is satisfied at the interface position.
Approach	Usually, this means computing a pressure value for nodes outside of the liquid so that a linear interpolation along an edge of a cell gives zero at the correct position [Enright et al. 2005; Lew and Buscaglia 2008].
Approach	Considering two pressure samples along an edge, we’ll denote values inside the air with a G subscript, and values inside the liquid with an L subscript in the following.
Approach	For a Cartesian MAC grid, the ghost pressure value p G is given by p G = p L φ G /φ L .
Approach	In our case, however, this approach does not yield the desired result.
Approach	The reason is that our velocity samples are not in line with the direct connections of the pressure samples – they are not locally orthogonal to each other.
Approach	Instead, we have to ensure the boundary conditions result in the correct pressure value at the cell center.
Approach	In the following we will show how to derive suitable free-surface boundary conditions to ensure second-order accuracy within our framework.
Approach	Note that for p i that are not inside of the liquid, we set w i = 0.
Approach	In line with the traditional ghost fluid method, we define p G uniquely for each tetrahedron.
Approach	In order to do this we need to compute the coefficients w n .
Approach	Here the θ n are a set of barycentric coordinate coefficients such that θ 1 +θ 2 +θ 3 = 1, and a tilde superscript denotes a value interpolated with the barycentric weights.
Approach	That means the values w n are determined by those of the θ n coefficients, which we will compute in the following.
Approach	Note that, theoretically, θ n could take any values as long as they add up to one.
Approach	The computation of the ghost fluid ρ values is independent of the right-hand side b, so we will restrict the discussion to the left hand side.
Approach	Assuming, without loss of generality, that the first vertex is the one outside of the liquid volume, we embed the boundary condition into        M based on the w n coefficients.
Approach	We can extract two constraints for each θ n from this form, which, together with the barycentric coefficient constraint, give us a 3 × 3 matrix M that can be inverted analytically.
Approach	If the quality of a tetrahedron is good, 0 < θ n < 1 is guaranteed.
Approach	In this case, the resulting matrix is symmetric positivedefinite and can be easily inverted by the commonly used preconditioned conjugate gradient methods.
Approach	However, positive off-diagonal terms of the matrix can result in values of θ outside of the range [0, 1], leading to an indefinite linear system.
Approach	In these cases we consider the tetrahedron to have a poor quality.
Approach	Effectively, this means reverting to first-order accuracy when second-order accuracy is intractable.
Approach	We implement a similar step in our algorithm to overcome numerical problems resulting from badly shaped cells.
Approach	We check whether the ghost fluid boundary conditions would violate diagonal dominance of an equation in our linear system.
Approach	If we detect such a case, we smoothly transition to first order accuracy.
Approach	Here, φ denotes a tolerance factor that we set to φ = 0.25.
Approach	Note that this scaling does not break the symmetry of the resulting linear system.
Approach	More specifically, for k = 1 this yields full second-order accuracy, while for badly shaped tetrahedra the resulting k = 0 means that we revert to the standard rounding strategy of a first order accurate method.
Approach	With our BCC mesh, all regular BCC tetrahedra have very good quality and valid θ n values.
Approach	The graded BCC tetrahedra, on the other hand, can be of lower quality and can require the use of Eq.
Approach	Luckily, in our tests these tetrahedra make up only a very small fraction of the mesh.
Approach	For this we need to construct a continuous velocity field based on the discrete values in our tetrahedral mesh.
Approach	As we store velocities at the cell centers, the interpolation would ideally use the dual mesh consisting of the Voronoi cells of each node [Brochu et al. 2010].
Approach	Unfortunately, performing interpolations within arbitrary Voronoi cells would be expensive and require a large amount of computation compared to the other steps of our simulator.
Approach	Instead, we have found the following approach to yield high speed and good accuracy: we first interpolate the centered velocities to the nodes, similar to [Chentanez et al. 2007].
Approach	Instead of interpolating these averaged values directly (which would result in smeared out motion), we temporarily subdivide the cells of our mesh by inserting a vertex at the center where we have an accurate velocity sample.
Approach	We then perform barycentric interpolation based on these subdivided cells, ensuring a C 0 continuous velocity that retains the original velocities at cell centers.
Approach	Note that these four smaller tetrahedra do not have to be stored explicitly.
Approach	We construct them on the fly when a sample is requested from one of the original cells.
Approach	We combat these problems by directly manipulating particle positions.
Approach	During each time step, we apply the position correction algorithm of Ando et al. [2012]; this algorithm essentially pushes each particle away from its neighbors to prevent clustering.
Approach	We also introduce two special behaviors when the particles are close to the liquid surface (less than a distance of six times the particle radius).
Approach	First, we impose the constraint that the position correction step may only move particles near the surface tangentially to the fluid interface.
Approach	Secondly, particles near the surface may leave gaps when they spread out quickly.
Approach	Our method naturally fills in these gaps by slightly pulling each particle towards the fluid interface.
Approach	For particles near the interface, this pulling force acts in addition to the position correction.
Approach	FLIP particles that partake in splashes and sprays can pose a significant burden on computational resources, especially in an adaptive framework like ours.
Approach	This inefficiency stems from the fact that water droplets undergo extremely simple ballistic motion.
Approach	Theoretically, we know that such a small region with purely free-surface boundary conditions will yield zero internal forces, so we simply detect individual FLIP particles that have no neighbors within six times their radius, remove them from the pressure solve, and accelerate them with gravity instead.
Approach	When these particles eventually enter the neighborhood of other particles at some point in the future, we resume treating them like fluid by returning them to the pressure solve.
Approach	This decision allows us to avoid aggressively refining the tetrahedral mesh in locations where the physical motion is uninteresting.
Approach	Only a small percentage of the particles are simulated in this way, e.g., 1.7% on average for Figure 6 .
Approach	Our method achieves adaptivity by varying the mesh resolution over the computational domain.
Approach	Our FLIP simulation performs computation on both a background volumetric mesh and on a set of particles.
Approach	Given a sizing function that indicates the desired spatial level of detail, our method first creates a tetrahedral mesh with varying spatial resolution, and then it locally changes the particle density by splitting and merging operations.
Approach	To compute the spatially-varying background grid, we start with the Delaunay tetrahedralization of a set of points distributed in a body-centered cubic lattice configuration.
Approach	In order to make the mesh resolution change over space, we use the octree-based grading method which was proposed by Labelle and Shewchuk [2007] and later adopted in several adaptive simulation environments [Chentanez et al. 2007; Wojtan and Turk 2008; Batty et al. 2010].
Approach	Similar to [Batty et al. 2010], we generate a new tetrahedral mesh every ten time steps, instead of rebuilding the mesh on every consecutive step.
Approach	Also, the tetrahedral mesh is only temporarily used for the pressure solver, so no information is transferred from one time step to the next by storing it on the grid.
Approach	Thus, we do not worry about re-sampling data when computing a new tetrahedral mesh.
Approach	We change the size and number of particles in our simulation with splitting and merging operations.
Approach	For this, we modify the strategy of Ando et al. [2012] to work within our framework: at each remeshing step, we loop through the particles and determine whether the resolution needs to be changed.
Approach	If a particle is too small, then we merge it with its nearest neighboring particle, resulting in a particle whose radius is given by the combined volume of the two original particles.
Approach	If a given particle is bigger than the desired size, then the particle is split in two.
Approach	The two new particles are placed randomly within the original particle’s radius and redistributed with a heuristic that attempts to fill in nearby gaps: We first compute the 24 midpoints m i between this particle and its 24 nearest neighbors.
Approach	Then we find the closest particle to each midpoint and store the squared distance as a weight ω i .
Approach	The new particle’s position is equal to the weighted average of all nearby midpoints: x new = ω i m i / ω i .
Approach	After a split or merge operation, the new particle’s velocity is computed using a volume-weighted average.
Approach	Also, we must take care to ensure that particles close to the surface do not introduce interfacial bumps when they split or merge; whenever we create a new particle that is less than 1.25 times its radius away from the surface (through either a split or a merge event), we move it in the surface normal direction such that its sphere lies exactly tangent to the liquid interface.
Approach	Numerical viscosity in fluid simulations is tightly coupled to the spatial resolution resolving the flow.
Approach	We compensate for spatiallyvarying numerical viscosity caused by particles of various sizes in our simulation by adjusting the PIC/FLIP blending parameter in our FLIP simulation [Bridson 2008].
Approach	Given quantities Q i,PIC and Q i,FLIP computed at particle i from PIC and FLIP simulations, respectively, the new quantity Q i is computed as a weighted blend between the two:
Approach	We found that this strategy adequately eliminates any artifacts due to spatially varying numerical viscosity.
Approach	Sizing Functions We define the level of detail in our simulations with a spatially varying sizing function S(x).
Approach	We have experimented with several different sizing functions depending on factors such as distance to a camera, distance to the liquid surface, curvature of the liquid surface, measures of fluid turbulence, and arbitrary analytical number fields.
Approach	Our simulator is versatile enough to cope with any of these sizing functions, resulting in efficient simulations with highly variable levels of detail.
Approach	In all of the examples in this paper, the sizing function is defined as a combination of five different metrics:
Approach	This has the effect that motion near the surface has higher priority than motions far inside the bulk volume of the liquid.
Approach	V (x, y) is a view-dependent function that returns the value y if x is within the camera’s visible region and returns the maximum particle radius r max (representing the minimum surface resolution) otherwise.
Approach	The next two metrics are designed to prioritize geometric detail of the liquid surface and of obstacles by computing a desired resolution based on cuvature.
Approach	κ liquid (x) returns 0.8 divided by the extrapolated curvature of the liquid interface.
Approach	Similarly, κ solid (x) returns 1.6 W smooth (d solid , r max ) divided by the extrapolated curvature of the solid interface, where W smooth (x, h) is a smooth kernel function (1 − ||x|| 2 /h 2 ) 3 and d solid is the closest distance to the solid boundary.
Approach	As a last component of our sizing function we found it beneficial to invest computational resources into keeping interesting motion of the flow field alive.
Outcome	We also introduce a new method for computing an implicit surface from a set of particles.
Approach	Given our set of FLIP particles with variable radii, we aim to implicitly represent the fluid surface by computing its signed distance function.
Background	Several useful methods for computing a surface from a collection of particles have been proposed in the past [Zhu and Bridson 2005; Adams et al. 2007; Yu and Turk 2010], but they tend to produce undesirably bumpy surfaces when considering particles of highly variable radii ( Figure 4 ).
Challenge	In this section, we introduce a new strategy for computing an implicit surface from a set of particles of various sizes.
Challenge	The main idea is to approximate the fluid surface with the union of the convex hulls of each triplet of nearby particles close to the surface.
Approach	For each set of three FLIP particles near the surface, the convex hull forms a thickened triangle shape with rounded edges ( Figure 5 ).
Approach	We only consider particles that are less than a given distance apart, with the maximum distance equal to a constant scale factor l times the sum of the two particle radii.
Approach	A small l shows more surface details, while a larger l tends to fill in small concavities.
Approach	We used l = 2 for most of the simulations in this paper.
Approach	We ultimately represent our surface as the union of all such local convex hull shapes, and the minimum signed distance from these shapes to a point in space defines the outer part of our level set function.
Approach	In practice, we compute the local convex hull by finding the two outermost planes tangent to a set of three spheres.
Approach	We efficiently compute the distance to these planes by analytically solving the polynomial system: ax 1 +by 1 +cz 1 +d = r 1 , ax 2 +by 2 +cz 2 +d = r 2 , ax 3 + by 3 + cz 3 + d = r 3 , a 2 + b 2 + c 2 = 1 .
Approach	a, b, c, d are the variables defining our plane with the signed distance function ax + by + cz + d = 0.
Approach	Intuitively, the first three equations ensure that the plane is the right distance away from each particle with the normal facing away from them, and the final equation ensures that the plane equation is normalized to a distance function.
Approach	These four equations represent the intersection of three hyperplanes and a hypercylinder in 4D {a, b, c, d} space.
Approach	We solve this system analytically by first finding the line of common intersection of the first three equations, and then intersecting this line with the cylinder represented by the final equation.
Approach	The system has two solutions, representing the top and bottom planes of our convex hull shape.
Approach	The above calculation describes how to find the planar regions of the convex hull of a set of three spheres.
Approach	By computing the conic and spherical convex hull facets ( Figure 5 , bottom right) in a similar fashion, we can easily compute the signed distance between this convex hull and a point in space.
Approach	To evaluate our final level set value, we compute the minimum signed distance from a query point to all nearby convex hulls.
Approach	We evaluate the level set on each of the vertices of our adaptive BCC mesh, and we extract a triangle mesh using a marching tetrahedra algorithm.
Approach	We then perform a light mesh smoothing to increase the reliability of any curvature computations.
Outcome	The algorithm as described works perfectly for computing the level set outside of our particle surface, but it may lead to small gaps inside.
Approach	To avoid the creation of holes, we temporarily reassign each particle’s radius: r i temp = max(r i , −kφ i ) where φ i is the particle’s stored level set value from the previous time step, and k is a constant set to 0.75 in our simulations.
Approach	Using this temporary radius to compute the signed distance as described above will remove erroneous gaps inside the liquid.
Approach	We need to compute liquid surfaces both for final visualization as well as for several calculations during the progress of our simulation.
Approach	For the final visualization, we compute an especially highresolution BCC mesh from all of our particles and proceed with the algorithm above.
Approach	The final surface creation is trivially parallelized, and takes around five minutes average per frame for all of our simulations.
Approach	We attempt to speed up the surface creation routine used for simulation computations by computing on the moderate-resolution BCC mesh used for simulation and ignoring ballistic particles (Section 3).
Outcome	We compare our surface creation routine with a few existing methods in Figure 4 .
Outcome	Most previous algorithms perform poorly in this comparison because they were not designed for particles with varying radii.
Approach	In the beginning of each step (line 2), we typically compute the level-set for the current particle configuration as described in Section 5.
Approach	We require the distance to the surface in several steps of our algorithm, so we store the level set values for each particle (line 3).
Approach	When enough time has passed to trigger an update of the mesh, it becomes necessary to evaluate the sizing function.
Approach	At this point, additional user-defined sizing functions could be computed as well.
Approach	Having the information from the sizing functions ready, we create a new BCC mesh and perform particle merging and splitting.
Outcome	The particle velocity update of line 12 uses barycentric interpolations as explained in Section 3.
Outcome	Likewise, the grid-based velocity extrapolation of line 10 uses the nodal velocities of Section 3.
Approach	A time step is completed by performing the pressure projection and advecting the particles in the resulting divergence-free velocity field.
Approach	To evaluate the performance and robustness of our method in comparison to previous work we have performed an extensive series of tests.
Outcome	One comparison that is particularly interesting is the one comparing our method to an FVM based simulation.
Outcome	Using a graded BCC mesh leads to problems with the latter, as the position of the circumcenter lies exactly on a face for the graded tetrahedrons.
Outcome	In the graded region, this can result in two pressure samples from adjacent tetrahedra being placed at the exact same position.
Background	To alleviate this problem, [Batty et al. 2010] propose to slightly offset the pressure samples from the faces.
Outcome	However, our implementation of their method exhibited slow convergence and the velocity artifacts despite this fix.
Outcome	The influence of the different components of our sizing function on the evolution of a simulation is difficult to depict with static images, so we refer to the accompanying video for a comparison.
Approach	To evaluate the basis of our adaptive model without any influence of the camera dependent sizing function, we have simulated the simple geometric configuration shown in Figure 3 .
Approach	For this setup, resolutions from 8 to 256 were used, resulting in 6 levels of adaptivity.
Approach	For this simulation, the initial configuration consisted of 168, 161 particles, and momentarily peaked up to 1, 048, 776 during the maximal extent of the splash (settling down again to around 250 thousand in the end).
Approach	Note that a full sampling of the initial configuration with a regular grid would have required approximately 6 million particles.
Outcome	Our measurements show that the run-time of our method has a strong linear relationship to the number of particles, and thus the visual complexity of the simulation.
Outcome	The per-frame time is low at the beginning and end of the simulation, but strongly peaks during the complex splash in its middle.
Outcome	Here the computational resources are focused on the visible region of a rotating camera, as the liquid splashes around a U-shaped corridor.
Outcome	Our solver efficiently resolves the complex motion near the camera, while effectively reducing the computational cost for parts that are not visible.
Approach	The κ solid component of our sizing function ensures that geometrically complex regions near the obstacle are simulated with higher accuracy.
Outcome	In this way, we can resolve the detailed flow of liquid through the holes in the obstacle.
Outcome	Without adaptivity, the large open liquid surface with complex splashes in a localized region would require huge amounts of computational resources.
Outcome	Our method can simulate this setup very efficiently, and in a fully coupled manner with an effective high resolution.
Outcome	The large open region is successfully coarsened by our sizing function, resulting in subtle wave motions around the splashes.
Outcome	In this case, the whole simulation with 8 different octree levels and a maximum resolution of up to 1024 cells took on average only 4.6 minutes per frame to compute.
Outcome	Just to illustrate the amount of detail in this setup – our adaptive version initially used 1.7 million particles, while a regular sampling at the finest resolution would have required roughly 400 million.
Outcome	We store the pressure variables on tetrahedral vertices, and there are far fewer vertices than tetrahedra in a given mesh.
Outcome	Consequently, the pressure solve has fewer variables and is faster to solve.
Outcome	Also, by counting degrees of freedom and constraints, we can see that our discretization prevents the locking ar- tifacts which are common in other methods.
Outcome	However, the lower number of pressure constraints also implies that the highest frequencies of the velocity field may be unconstrained.
Approach	In our case a regularization via PIC interpolation acts to diminish any highfrequency artifacts.
Approach	Our method uses a FLIP scheme instead of a purely Eulerian method.
Approach	We store all physical variables on the FLIP particles, so information is carried from one time step to the next in a Lagrangian manner.
Approach	As a result, we are allowed to aggressively remesh the tetrahedral background grid without worrying about excessive damping or re-sampling artifacts.
Background	On the other hand, FLIP simulations have a well-known problem of creating noisy particle distributions, because there are typically several times more particles than velocity variables on the background grid.
Approach	We utilize particle repositioning to improve the distribution quality, at the expense of slight inaccuracies due to displacing physical variables.
Outcome	We noticed that our new surface creation routine is essential for maintaining detailed simulations in the presence of accurate freesurface boundary conditions.
Outcome	One major benefit of our method is that it can easily create perfectly flat surfaces from a mixture of differently-sized particles.
Outcome	These flat surfaces represent the equilibrium state of a fluid simulation, so our animations are able to smoothly settle down as time progresses.
Outcome	Without a method for accurately reproducing flat surfaces, second-order boundary conditions will introduce additional forces in the locations of surface bumps, which artificially prevent a simulation from settling down.
Outcome	While we believe that our surface creation routine is indispensable, it is quite expensive to compute.
FutureWork	In the future we would like to optimize the surface computation.
Outcome	Our simulations perform quite well for large differences in resolutions, but we have only been able to push them to a certain point in our current implementation.
Outcome	We found that using too sharp of a grading in our sizing function can place coarse and fine simulation elements too close together and potentially result in artifacts.
Outcome	For example, when small particles land in very coarse cells after violent splashes, these particles can get stuck in mid air.
Outcome	Occasionally, this can also lead to an overly strong weight for such particles during the velocity mapping, resulting in momentum artifacts.
Outcome	While we presented specific parameters for the sake of reproducibility, these values were not meticulously tuned and are certainly not optimal.
FutureWork	The task of choosing an ideal sizing function is still an open problem that we are interested in pursuing in the future.
FutureWork	In particular, we are interested in taking more temporal information into account.
FutureWork	This could lead to more gradual changes in resolution, at the expense of a slightly higher particle count.
Outcome	We have presented a novel framework for highly adaptive liquid simulation.
Approach	In our method, a novel, robust discretization works together with accurate embedded boundary conditions and a flexible sizing function to allow for aggressive adaptivity and high computational performance.
Outcome	In this way, we can efficiently compute tough simulation setups, such as large surfaces with very localized details.
Outcome	We have additionally presented a novel surface creation method that yields smooth surfaces in the presence of strongly varying particle radii, which turned out to be an important building block for our framework.
Approach	We chose a BCC mesh generation because it is, to the best of our knowledge, the fastest way to generate high-quality meshes.
Outcome	However, despite its efficiency, mesh generation is still a bottleneck for our simulation.
Outcome	This is partly due to the fact that it is a mostly serial operation that is difficult to parallelize (most other steps of our algorithm parallelize easily).
FutureWork	So, instead of computing the mesh from scratch each time, we are interested in exploring techniques for continuous re-meshing.
Outcome	Also, our choice of piece-wise constant basis functions for velocity indicates that our discretization could lead to difficulties when it is used for diffusion or viscosity solves.
FutureWork	It will be interesting to see how these could be incorporated into our framework.
FutureWork	Finally, we are highly interested in applying our method to other types of phenomena, such as smoke and fire simulations, or visco-elastic materials.
FutureWork	It will be very interesting to leverage the benefits of our framework for extreme adaptivity in these situations.
Approach	Here we describe how to compute the ghost fluid coefficients θ n given the 4 × 4 pressure matrix entries of a single tetrahedron.
Approach	Note that each of the θ n has two degree of freedom, and thus each w n also has two degrees of freedom.
Approach	As we know that the resulting matrix needs to be symmetric, which gives us the following constraints: a + αw 2 = a + βw 1 , b + γw 1 = b + αw 3 , and c + βw 3 = c + γw 2 .
Approach	As the w n linearly depend on θ n , that means: αθ 2 = βθ 1 , γθ 1 = αθ 3 , and βθ 3 = γθ 2 .
Approach	When we re-write these constraints in matrix form, and include the barycentric coordinate constraint θ 1 + θ 2 + θ 3 = 1 we get the following linear system:
Approach	As the rank of top three rows of the matrix is 2, we can drop one of them.
Approach	This means that for our discretization, the ghost pressure coefficients θ n are given by the tetrahedron’s matrix entries from Eq.10.
Approach	More specifically, by those for the vertex that is located outside of the liquid, i.e., α, β and γ.

Challenge	There are many applications that demand large quantities of natural looking motion.
Challenge	It is difficult to synthesize motion that looks natural, particularly when it is people who must move.
Outcome	In this paper, we present a framework that generates human motions by cutting and pasting motion capture data.
Approach	Selecting a collection of clips that yields an acceptable motion is a combinatorial problem that we manage as a randomized search of a hierarchy of graphs.
Approach	This approach can generate motion sequences that satisfy a variety of constraints automatically.
Outcome	The motions are smooth and human-looking.
Outcome	They are generated in real time so that we can author complex motions interactively.
Outcome	The algorithm generates multiple motions that satisfy a given set of constraints, allowing a variety of choices for the animator.
Outcome	It can easily synthesize multiple motions that interact with each other using constraints.
Outcome	This framework allows the extensive re-use of motion capture data for new purposes.
Background	Motion is one of the most important ingredients of CG movies and computer games.
Background	Obtaining realistic motion usually involves key framing, physically based modelling or motion capture.
Challenge	Creating natural looking motions with key framing requires lots of effort and expertise.
Challenge	Although physically based modelling can be applied to simple systems successfully, generating realistic motion on a computer is difficult, particularly for human motion.
Background	A standard solution is motion capture: motion data for an approximate skeletal hierarchy of the subject is recorded and then used to drive a reconstruction on the computer.
Background	This allows other CG characters to be animated with the same motions, leading to realistic, “human looking” motions for use in movies or games.
Challenge	Most motion capture systems are very expensive to use, because the process is time consuming for actors and technicians and motion data tends not to be re-used.
Challenge	It is very hard to obtain motions that do exactly what the animator wants.
Challenge	Satisfying complex timed constraints is difficult and may involve many motion capture iterations.
Challenge	Examples include being at a particular position at a particular time accurately or synchronizing movement to a background action that had been shot before.
Challenge	In order to make motion capture widely available, the motion data needs to be made re-usable.
Challenge	This may mean using previous motion capture data to generate new motions so that certain requirements are met, transferring motions from one skeletal configuration to another so that we can animate multiple figures with the same motion without it looking “funny”, or changing the style of the motion so that the directors can have higher level control over the motion.
Background	Obtaining motion demands involves specifying constraints on the motion, such as the length of the motion, where the body or individual joints should be or what the body needs to be doing at particular times.
Background	These constraints can come from an interactive editing system used by animators, or from a computer game engine itself.
Background	Generating motion involves obtaining a rough motion that satisfies the demands.
Challenge	In this paper, we describe a technique that cuts and pastes bits and pieces of example motions together to create such a motion.
Background	Post processing involves fixing small scale offensive artifacts.
Background	An example would involve fixing the feet so that they do not penetrate or slide on the ground, lengthening or shortening strides and fixing constraint violations.
Challenge	In this paper, we present a framework that allows synthesis of new motion data meeting a wide variety of constraints.
Approach	The synthesized motion is created from example motions at interactive speeds.
Background	In the movie industry, motion demands are usually generated by animators.
Background	However, automatic generation of motion demands is required for autonomous intelligent robots and characters [Funge et al. 1999].
Background	An overview of the automatic motion planning can be found in [Latombe 1999; O’Rourke 1998].
Background	Generating motion largely follows two threads: using examples and using controllers.
Background	Example based motion synthesis draws on an analogy with texture synthesis where a new texture (or motion) that looks like an example texture (or motion example) needs to be synthesized [Efros and Leung 1999; Heeger and Bergen 1995].
Background	Pullen and Bregler used this approach to create cyclic motions by sampling motion signals in a “signal pyramid” [2000].
Background	They also used a similar approach to fetch missing degrees of freedom in a motion from a motion capture database [Pullen and Bregler 2002].
Background	The sampling can also be done in the motion domain to pick clips of motions to establish certain simple constraints [Lamouret and van de Panne 1996; Schodl et al. 2000].
Background	A roadmap of all the motion examples can be constructed and searched to obtain a desired motion [Choi et al. 2000; Lee et al. 2002; Kovar et al. 2002].
Background	The clips in this roadmap can also be parameterized for randomly sampling different motion sequences [Li et al. 2002].
Background	The motion signals can also be clustered.
Background	The resulting Markov chain can be searched using dynamic programming to find a motion that connects two keyframes [Molina-Tanco and Hilton 2000] or used in a variable length Markov model to infer behaviors [Galata et al. 2001] or directly sampled from to create new motions [Bowden 2000].
Background	This is similar to our work.
Approach	However, our clustering method does not operate on body configurations and our probabilistic search strategy is more effective than dynamic programming as it will be explained below.
Background	Types of probabilistic search algorithms have also been used in physically based animation synthesis [Chenney and Forsyth 2000] and rendering [Veach and Guibas 1997].
Background	Controller based approaches use physical models of systems and controllers that produce outputs usually in the form of forces and torques as a function of the state of the body.
Background	These controllers can be designed specifically to accomplish particular tasks [Brogan et al. 1998; Hodgins et al. 1995] or they can be learned automatically using statistical tools [Grzeszczuk and Terzopoulos 1995; Grzeszczuk et al. 1998; Mataric 2000].
Background	The motion data can also be post processed to fix problems such as feet sliding on the ground or some constraints not being satisfied [Gleicher 1998; Lee and Shin 1999; Popovic 1999; Rose et al. 1996].
Background	This usually involves optimization of a suitable displacement function on the motion signal.
Background	Different body sizes move according to different time scales, meaning that motion cannot simply be transferred from one body size to another; modifying motions appropriately is an interesting research problem [Hodgins and Pollard 1997].
Approach	We assume there is a set of N motion sequences forming our dataset, each belonging to the same skeletal configuration.
Approach	Every motion is discretely represented as a sequence of frames each of which has the same M degrees of freedom.
Approach	This is required to be able to compare two motions and to be able to put clips from different motion sequences together.
Approach	We write the i’th frame of s’th motion as s i .
Approach	The collection of motion sequences could be represented as a directed graph.
Approach	Each frame would be a node.
Approach	There would be an edge from every frame to every frame that could follow it in an acceptable splice.
Approach	In this graph, there would be (at least) an edge from the k’th frame to the k + 1’th frame in each sequence.
Approach	This graph is not a particularly helpful representation because it is extremely large — we can easily have tens of thousands of nodes and hundreds of thousands of edges — and it obscures the structure of the sequences.
Approach	Instead, we collapse all the nodes (frames) belonging to the same motion sequence together.
Approach	This yields a graph G where the nodes of G are individual motion sequences and there is an edge from s to t for every pair of frames where we can cut from s to t.
Approach	Since edges connect frames, they are labelled with the frames in the incident nodes (motion sequences) that they originate from and they point to.
Approach	We also assume that the edges in G are attached a cost value which tells us the cost of connecting the incident frames.
Approach	If cutting from one sequence to another along an edge introduces a discontinuous motion, then the cost attached to the edge is high.
Approach	The collapsed graph still has the same number of edges.
Approach	For an edge e from s i to t j , let f romMotion(e) = s, toMotion(e) = t, f romFrame(e) = i, toFrame(e) = j and cost(e) be the cost associated with the edge (defined in Appendix A).
Approach	In this setting, any sequence of edges e 1 · · · e n where toMotion(e i ) = f romMotion(e i+1 ) and toFrame(e i ) < f romFrame(e i+1 ), ∀i, 1≤i < n is a valid path and defines a legal sequence of splices.
Approach	We wish to construct paths in the motion graph that satisfy constraints.
Approach	Many constraints cannot be satisfied exactly.
Approach	For example, given two positions, there may not be any sequence of frames in the collection that will get us from the first position to the second position exactly.
Approach	We define hard constraints to be those that can (and must) be satisfied exactly.
Approach	Typically, a hard constraint involves using a particular frame in a particular time slot.
Approach	For example, instead of considering all valid paths, we can restrict ourselves to valid paths that pass through particular nodes at particular times.
Approach	This way, we can constrain the moving figure to be at a specific pose at a specific time.
Approach	This enables us to search for motions such as jumping, falling, or pushing a button at a particular time.
Approach	A soft constraint cannot generally be met exactly.
Approach	Instead we score sequences using an objective function that reflects how well the constraint has been met and attempt to find extremal sequences.
Approach	One example is the squared distance between the position of the constraint and the actual position of the body at the time of the constraint.
Approach	The total number of frames should be a particular number.
Approach	The motion should not penetrate any objects in the environment.
Approach	The body should be at a particular position and orientation at a particular time.
Approach	A particular joint should be at a particular position (and maybe having a specific velocity) at a specific time.
Approach	The motion should have a specified style (such as happy or energetic) at a particular time.
Approach	Finding paths in the motion graph that satisfy the hard constraints and optimize soft constraints involves a graph search.
Approach	Unfortunately, for even a small collection of motions, the graph G has a large number of edges and straightforward search of this graph is computationally prohibitive.
Approach	The main reason is the need to enumerate many paths.
Approach	There are, in general, many perfectly satisfactory motions that satisfy the constraints equally well.
Approach	For example, if we require only that the person be at one end of a room at frame 0 and near the other end at frame 5000, unless the room is very large, there are many motions that satisfy these constraints.
Approach	The motion graph is too hard to search with dynamic programming as there are many valid paths that satisfy the constraints equally well.
Approach	There may be substantial differences between equally valid paths — in the example above, whether you dawdle at one side of the room or the other is of no significance.
Approach	This suggests summarizing the graph to a higher level and coarser presentation that is easier to search.
Approach	Branch and bound algorithms are of no help here, because very little pruning is possible.
Approach	In order to search the graph G in practical times, we need to do the search at a variety of levels where we do the large scale motion construction first and then “tweak” the details so that the motion is continuous and satisfies the constraints as well as possible.
Approach	Coarser levels should have less complexity while allowing us to explore substantially different portions of the path space.
Approach	In such a representation, every level is a summary of the one finer level.
Approach	Let G ← G ← G ← · · · ← G n ← G be such a hierarchical representation where G is the coarsest level and G is the finest.
Approach	We will first find a path in G and then push it down the hierarchy to a path in G for synthesis.
Approach	All the edges between two nodes s and t can be represented in a matrix P st .
Approach	The (i, j)’th entry of P st contains the weight of the edge connecting s i to t j and infinity if there is no such edge.
Approach	In the appendix A, we give one natural cost function C(s i ,t j ) for edge weights.
Approach	We now have: (P st ) i j = C(s ∞ i ,t j ) otherwise.
Approach	if there is an edge from s i to t j The cost function explained in section A causes the P matrices to have non-infinite entries to form nearly elliptical groups ( figure 2 ).
Approach	This is due to the fact that if two frames are similar, most probably their preceding and succeeding frames also look similar.
Approach	We require that, if there is a cut between two sequences represented by an edge between two nodes in G, there be at least one edge between the corresponding nodes in G .
Approach	If this were not the case, our summary would rule out potential paths.
Approach	In order to insure that this condition holds and because the graph is very large, we cluster edges connecting every pair of nodes in G separately.
Approach	We cluster unconnected edge groups of G from the P matrices (defined between every pair of nodes) using k-means ma joraxislength [Bishop 1995].
Approach	The number of clusters is chosen as minoraxislength for each group where the axis lengths refer to the ellipse that fits to the cluster (obtained through Principal Component Analysis).
Approach	Thus, in our summarized graph G , each edge is the root of a binary tree and represents all the edges in close neighborhood in terms of the edge labels.
Approach	Note that the leaf edges are the edges in the original graph and intermediate edges are the averages of all the leaf edges beneath them.
Approach	A path in G represents a sequence of clips; so does a path in G , but now the positions of the clip boundaries are quantized, so there are fewer paths.
Approach	While searching this graph, we would like to be able to generate different alternative motions that achieve the same set of constraints.
Approach	During the search, we need to find paths close to optimal solutions but do not require exact extrema, because they are too hard to find.
Approach	This motivates a random search.
Approach	We used the following search strategy:
Approach	Start with a set of n valid random “seed” paths in the graph G 2.
Approach	Score each path and score all possible mutations 3.
Approach	(b) Delete some edges of the path and replace them with their children 4.
Approach	Accept the mutations that are better than the original paths 5.
Approach	Include a few new valid random “seed” paths 6.
Approach	Since we start new random “seed” paths at every iteration, the algorithm does not get stuck at a local optimum forever.
Approach	Hard constraints are easily dealt with; we restrict our search to paths that meet these constraints.
Approach	Typically hard constraints specify the frame (in a particular node) to be used at a particular time.
Approach	We do this by ensuring that “seed” paths meet these constraints, and mutations do not violate them.
Approach	This involves starting to sample the random paths from the hard constraint nodes and greedily adding sequences that get us to the next hard constraint if any.
Approach	Since the path is sampled at the coarse level, a graph search can also be performed between the constraint nodes.
Approach	At every iteration we check if the proposed mutation deletes a motion piece that has a hard constraint in it.
Approach	Such mutations are rejected immediately.
Approach	Note that here we assume the underlying motion graph is connected.
Background	Notice that this algorithm is similar to MCMC search (a good broad reference to application of MCMC is [Gilks et al. 1996]).
Approach	However, it is difficult to compute proposal probabilities for the mutations we use, which are strikingly successful in practice.
Approach	This is an online algorithm which can be stopped at anytime.
Approach	This is due to the fact that edges in intermediate graphs G · · · G n also represent connections and are valid edges.
Approach	Thus we do not have to reach the leaf graph G to be able to create a path (motion sequence).
Approach	We can stop the search iteration, take the best path found so far, and create a motion sequence.
Approach	If the sequence is not good enough, we can resume the search from where we left off to get better paths through mutations and inclusion of random paths.
Approach	This allows an intuitive computation cost vs. quality tradeoff.
Approach	Since during the search all the paths live in a subspace implied by the hard constraints, these constraints are always satisfied.
Approach	Given a sequence of edges e 1 · · · e n , we score the path using the imposed soft constraints.
Approach	For each constraint, we compute a cost where the cost is indicative of the satisfaction of the constraint.
Approach	Based on the scores for each of the constraints, we weight and sum them to create a final score for the path (The S function in equation 1).
Approach	We also add the sum of the costs of the edges along the path to make sure we push the search towards paths that are continuous.
Approach	The weights can be manipulated to increase/decrease the influence of a particular soft constraint.
Approach	We now have an expression of the form:
Approach	Where w c ,w f ,w b and w j are weights for the quality (continuity) of the motion, how well the length of the motion is satisfied, how well the body constraints are satisfied and how well the joints constraints are defined.
Approach	We selected these weights such that an error of 10 frames increases the total score the same amount as an error of 30 centimeters in position and 10 degrees in orientation.
Approach	F: For the number of frame constraints, we compute the squared difference between the actual number of frames in the path and the required number of frames.
Approach	B: For body constraints, we compute the distance between the position and orientation of the constraint versus the actual position and orientation of the torso at the time of the constraint and sum the squared distances.
Approach	The position and orientation of the body at the constraint times are found by putting the motion pieces implied by the subsequent edges together ( figure 1 ).
Approach	This involves taking all the frames of motion toMotion(e i ) between frames f romFrame(e i+1 ) and toFrame(e i ) and putting the sequence of frames starting from where the last subsequence ends or from the first body constraint if there is no previous subsequence.
Approach	Note that we require that we have at least two body constraints enforcing the position/orientation of the body at the beginning of the synthesized motion (so that we know where to start putting the frames down) and at the end of the synthesized motion.
Approach	The first body constraint is always satisfied, because we always start putting the motions together from the first body constraint.
Approach	J: For joint constraints, we compute the squared distance between the position of the constraint and the position of the constrained joint at the time of the constraint and sum the squared distance between the two.
Approach	To determine the configuration of the body at the time at which the constraint applies, we must assemble the motion sequence up to the time of the constraint; in fact, most of the required information such as the required transformation between start and end of each cut is already available in the dataset.
Approach	We implemented two types of mutations which can be performed quickly on an active path.
Approach	Replace a sequence by selecting two edges e i and e i+ j where 0 ≤ j ≤ n − i, deleting all the edges between them in the path and connecting the unconnected pieces of the path using one or two edges in the top level graph G (if possible).
Approach	Since in the summarized graph, there are relatively fewer edges, we can quickly find edges that connect the two unconnected nodes by checking all the edges that go out from toMotion(e i ), and enumerating all the edges that reach to f romMotion(e i+ j ) and generate a valid path.
Approach	Note that we enumerate only 0 or 1 hop edges (1 edge or 2 edge connections respectively).
Approach	Demoting two edges to their children and replacing them with one of their children if they can generate a valid path.
Approach	Doing this mutation on two edges simultaneously allows us to compensate for the errors that would happen if only one of them was demoted.
Approach	We check every possible mutation, evaluate them and take the best few.
Approach	Since the summary has significantly fewer edges than the original graph, this step is not very expensive.
Approach	If a motion sequence cannot generate a mutation whose score is lower that itself, we decide that the current path is a local minimum in the valid path space and record it as a potential motion.
Approach	This way, we can obtain multiple motions that satisfy the same set of constraints.
Approach	We create the final motion by taking the frames between toFrame(e i ) and f romFrame(e i+1 ) from each motion toMotion(e i ) where 1 ≤ i < n ( figure 1 ).
Approach	This is done by rotating and translating every motion sequence so that each piece starts from where the previous one ended.
Approach	In general, at the frames corresponding to the edges in the path, we will have C 0 discontinuities, because of the finite number of motions sampling an infinite space.
Approach	In practice these discontinuities are small and we can distribute them within a smoothing window around the discontinuity.
Approach	We do this by multiplying the magnitude of the discontinuity by a smoothing function and adding the result back to the signal ( figure 4 ).
Approach	We choose the smoothing domain to be ±30 frames (or one second of animation) around the discontinuity and
Approach	To make sure that we interpolate the body constraints (i.e. having a particular position/orientation at a particular frame), we take the difference between the desired constraint state, subtract the state at the time of the constraint and distribute this difference uniformly over the portion of the motion before the time of the constraint.
Approach	Note that these “smoothing” steps can cause artifacts like feet penetrating or sliding on the ground.
Approach	However, usually the errors made in terms of constraints and the discontinuities are so small that they are unnoticeable.
Approach	Using iterative improvements of random paths, we are able to synthesize human looking motions interactively.
Approach	This allows interactive manipulation of the constraints.
Approach	This is important, because motion synthesis is inherently ambiguous as there may be multiple motions that satisfy the same set of constraints.
Approach	The algorithm can find these “local minimum” motions that adhere to the same constraints.
Approach	The animator can choose between them or all the different motions can be used to create a variety in the environment.
Approach	Since the algorithm is interactive, the animator can also see the ambiguity and guide the search by putting extra constraints ( figure 6 ).
Approach	Currently, we can constrain the length of the motion, the body’s position and orientation at a particular frame ( figure 5 ,6), a joint (e.g. head, hand) to a particular state at a particular frame ( figure 7 ), or constrain the entire body’s pose at a particular frame (figure 8).
Approach	Notice that we can synthesize multiple interacting motions independently using hard constraints ( figure 9 ); we simply select the poses, position and orientation at which the figures interact and this framework fills in the missing motion, in a sense, interpolating the constraints.
Approach	These are only a few of the constraints that can be implemented.
Approach	As long as the user specifies a cost function that evaluates a motion and attaches a score that is indicative of the animator’s satisfaction with the path, many more constraints can be implemented.
Approach	For example, if the motions in our database are marked with their individual stylistic attributes, we can also constrain the style of the desired motion by penalizing motions that do not have the particular style.
Approach	In a computer game environment, we can constrain the synthesized motion to avoid obstacles in the environment.
Approach	In such a case, body position/orientation constraints can also come from an underlying path planner.
Approach	Thus, given high level goals (such as going from point A to point B, say) human looking motions can be generated automatically.
Outcome	We have presented a framework that allows interactive synthesis of natural looking motions that adhere to user specified constraints.
Approach	We assess our results using four criteria.
Outcome	Firstly, the motion looks human.
Outcome	Secondly, the motions generated by the method do not have unnatural artifacts such as slipping feet on the ground or jerky movement.
Outcome	Third, the user specified constraints are satisfied, i.e. the motion passes through the required spot at the required time, or the character falls to a particular position ( figure 8 ).
Outcome	Finally, motions are generated interactively — typically depending on the quality of the path desired, an acceptable 300 frame motion is found in between 3 and 10 seconds on an average PC (Pentium III at 800 Mhz).
Outcome	This speed allows interactive motion authoring.
Approach	For example, we generated the real-time screen captures in the attached video using a dataset of 60-80 unorganized, short (below 300 frames each) motion capture fragments.
Outcome	The average precomputation time required for this many motions (computing the motion graph) is 5 hours on the same computer.
Outcome	On average, the results shown in the video contain 3-30 motion pieces cut from the original motions.
Outcome	This framework is completely automatic.
Outcome	Once the input motions are selected, the computation of the hierarchic motion graph does not require any user intervention and the resulting representation is searched in real-time.
Outcome	For many kinds of constraints the motion synthesis problem is underconstrained; there are many possible combinations of motion pieces that achieve the same set of constraints.
Outcome	Randomized search is well suited to find many different motions that satisfy the constraints.
Outcome	On the other hand, some constraints, may not be met by any motion.
Outcome	In this case, randomized search will try to minimize our objective motion and find the “closest” motion.
Approach	For example, if the user asks for 100 meters in 5 seconds, the algorithm will tend to put fast running motions together but not necessarily satisfying the constraints.
Approach	Similarly, if the set of motions to begin with do not form a connected graph, the algorithm will perform searches confined to the unconnected graphs.
Outcome	If there are hard constraints in different unconnected components, we will not even be able to find starting seed paths.
Outcome	From this perspective, the selection of the database to work with is important.
Approach	In our system, we used 60-100 football motions that have a strong bias towards motions that run forward.
Outcome	However, as the attached video suggest, the randomized search has no problem finding rare motions that turn back to satisfy the constraints.
Approach	The motion databases that we used were unorganized except that we excluded football warming up and tackling motions unless they were desired ( figure 9 ).
Outcome	The randomized search scales linearly as a function of the database size with a very small constant.
Outcome	We have tried datasets of 50-100 motions without a noticeable change in the running time of the algorithm.
Outcome	The linearity in the running time comes from the linear increase in the number of alternative mutations at every step.
Outcome	Note that as the database size gets larger, the constant τ (Appendix A) that is used to create the edges can get lower since more motions mean that we expect to find better connections between motions, decreasing the number of edges.
Outcome	This will lead to a sublinear increase in the running time.
Outcome	The framework can work on any motion dataset: it can be created by traditional key framing, physically based modelling or motion capture.
Outcome	For example, we can take the motion data for “Woody” – who may well have been key-framed, from “Toy Story” and create new “Woody” motions automatically.
Outcome	The framework is also appli- cable to non-human motion synthesis.
Outcome	For example, this framework can be used to generate control signals for robots to achieve a particular task by generating the motion graph for previously known motion-control signal pairs.
Outcome	During the synthesis we can not only synthesize the final robot motion but also the associated control signals that achieve specific goals.
Outcome	Since the generated motions are obtained by putting pieces of motions in the dataset, the resulting motions will also carry the underlying style of the data.
Outcome	This way, we can take the motion data for one character, and produce more motions with the intrinsic style of the character.
FutureWork	During the construction of the final motion, better ways of smoothing between adjacent motions could be used to improve realism [Popovic 1999].
FutureWork	Using better post processing, motions could also be synthesized on non-uniform surfaces which the current framework cannot handle.
FutureWork	Additional post processing may involve physically based modelling to make sure the synthesized motions are also physically correct.
FutureWork	Automatic integration of higher level stylistic constraints could be incorporated into the framework, avoiding the arduous job of labelling every motion with the intrinsic style by hand.
FutureWork	By analyzing patterns in the motion dataset, we might also infer these styles or obtain higher level descriptions [Brand and Hertzmann 2001].
Outcome	The synthesized motions are strictly bound to the motions that were available in the original dataset.
FutureWork	However, it is conceivable that the motions that are very close to the dataset could also be incorporated in the synthesizable motions using learned stylistic variations.
Outcome	The integrity of the original dataset directly effects the quality of the synthesized motion.
Outcome	For example, if the incoming motion dataset does not contain any “turning left” motions, we will not be able to synthesize motions that involve “turning left”.
FutureWork	An automatic way of summarizing the portions of the “possible human motions” space that have not been explored well enough by the dataset could improve the data gathering and eventually the synthesized motions.
FutureWork	This could also serve as a palette for artists: some portions of the precomputed motion graph can be paged in and out of memory depending on the required motion.
FutureWork	For example, the animator could interactively select the motions that need to be used during the synthesis, and only the portion of the motion graph involving the desired motions could be loaded.
FutureWork	This would give animators a tool whereby they can select the set of motions to work with in advance and the new motions will be created only from the artist selected set.
FutureWork	Furthermore this encourages comprehensive re-use of motion data.
Approach	We define the torso coordinate frame to be the one where the body stands centered at origin on the xz plane and looks towards the positive z axis.
Approach	Any point p in the torso coordinate frame can be transformed to the global coordinate frame by T (s i ) + R(s i ) · p , where T (s i ) is the 3 × 1 translation of the torso and R(s i ) is the 3 × 1 rotation of the torso and R(s i ) represents the rotation matrix associated with the rotation.
Approach	We wish to have a weight on edges of the motion graph (section 3.1) that encodes the extent to which two frames can follow each other.
Approach	If the weight of an edge is too high, it is dropped from the graph.
Approach	To compute the weight of an edge, we use the difference between joint positions and velocities and the difference between the torso velocities and accelerations in the torso coordinate frame.
Approach	Let P(s i ) be a 3 × n matrix of positions of n joints for s i in torso coordinate frame.
Approach	We then define the normalizing matrices O and L in equation 3 and 4.
Approach	Then the cost function function in equation 5 is used to relate s i to t j .
Approach	Where diagonal (n + 2) × (n + 2) matrices M and T are used to weight different joints differently.
Approach	For example, position differences in feet are much more noticeable than position differences of hands because the ground provides a comparison frame.
Approach	We have found M and T matrices empirically by trying different choices.
Approach	Unfortunately, defining a universal cost metric is a hard problem.
Outcome	The metric defined above produces visually acceptable results.
Approach	Using this cost metric, we create edges from s i to t j where C(s i ,t j ) < τ .
Approach	For an edge e from s i to t j , we set cost(e) = C(s i ,t j ).
Approach	Note that an error that is visible on a short person may not be visible on an extremely large person.
Approach	Thus, in theory, the weights must be adjusted from person to person.
Approach	However, in practice, possible size variation of adult people is small enough that we used the same weights for different people without creating a visible effect.

Challenge	In this paper, we present a technique for generating animation from a variety of user-defined constraints.
Approach	We pose constraint-based motion synthesis as a maximum a posterior (MAP) problem and develop an optimization framework that generates natural motion satisfying user constraints.
Approach	The system automatically learns a statistical dynamic model from motion capture data and then enforces it as a motion prior.
Outcome	This motion prior, together with user-defined constraints, comprises a trajectory optimization problem.
Outcome	Solving this problem in the low-dimensional space yields optimal natural motion that achieves the goals specified by the user.
Outcome	We demonstrate the effectiveness of this approach by generating whole-body and facial motion from a variety of spatial-temporal constraints.
Challenge	Our objective in this paper is to design an animation system that allows users to easily create natural-looking character animation by specifying spatial-temporal constraints throughout the motion.
Challenge	For      example, a naive user might use a performance animation system to control the trajectories of the end-positions of the limbs of a character.
Challenge	A more skilled user might specify a small set of poses at key time instants.
Challenge	The system then automatically finds a motion that best satisfies those constraints.
Challenge	An ideal motion synthesis system should allow users to specify a variety of constraints either at isolated points or across the entire motion in order to accommodate users with different skill levels.
Background	One appealing solution to this problem is physically based optimization [Witkin and Kass 1988], which allows the user to specify various constraints throughout the motion and relies on optimization to compute the physically valid motion that best satisfies these constraints.
Challenge	Unfortunately, correct physics does not ensure that the motion will appear natural for characters with many degrees of freedom.
Approach	Like physically based optimization, we formulate the problem as a trajectory optimization and consider the entire motion simultaneously.
Approach	Instead of using the physical laws to generate physically correct animation, we rely on statistical models of human motion to generate a statistically plausible motion.
Approach	Our approach allows the user to generate a wide range of human body and facial animation by specifying spatial-temporal constraints throughout the motion.
Approach	The system automatically learns a statistical dynamic model from motion capture data and then enforces this model as a motion prior.
Approach	The statistical dynamic model plays a role similar to that played by the dynamics in physically based optimization because it constrains the motion to only part of the space of possible human motions.
Approach	The statistical dynamic model, however, is usually lower dimensional than the dynamics model, making the optimization more efficient, less likely to be subject to local minima, and more likely to produce natural motion.
Outcome	We demonstrate the effectiveness of this approach in two domains: human body animation and facial animation.
Outcome	We show that the system can generate natural-looking animation from key-frame constraints, key-trajectory constraints, and a combination of these two constraints.
Approach	For example, the user can generate a walking animation from a small set of key frames and foot contact constraints ( figure 1 top).
Approach	The user can also specify a small set of key trajectories for the root, hands and feet positions to generate a realistic jumping motion ( figure 1 bottom).
Approach	The user can fine tune the animation by incrementally modifying the constraints.
Approach	For example, the user can create a slightly different jumping motion by adjusting the positions of both hands at the top of the jump.
Outcome	The system can generate motions for a character whose skeletal model is markedly different from those of the subjects in the database.
Outcome	We also show that the system can use a statistical dynamic model learned from a normal walking sequence to create new motion such as walking on a slope.
Outcome	The quality of the final animation produced by our system depends on the motion priors derived from the motion capture database and the number of user-defined constraints.
Approach	We, therefore, evaluate how the database influences the final motion and how increasing or decreasing the number of user-defined constraints influences the final animation.
Approach	We also compare alternative techniques for generating animation from user-defined constraints such as linear interpolation, trajectory-based inverse kinematics, and inverse kinematics in a PCA subspace.
Challenge	In this paper, we construct statistical models from motion capture data and then combine these models with trajectory optimization to generate a motion that satisfies user-defined constraints.
Background	Consequently, we discuss related work in constraint-based trajectory optimization and data-driven animation with an emphasis on statistical models.
Background	Trajectory optimization methods, which were first introduced to the graphics community by Witkin and Kass [1988], provide a powerful framework for generating character animation from user-specified constraints, physics constraints, and an objective function that measures the performance of a generated motion.
Challenge	Extending this approach to generate natural motion for a full human character has proved to be hard because the system is high dimensional, the physics constraints make it highly nonlinear, and defining an objective function that reliably measures the naturalness of human motion is difficult.
Background	Much of the difficulty in solving this problem appears to result from the physics constraints because optimization without physics is effective for editing [Gleicher 1998].
Background	Therefore, one way to make the problem tractable is to simplify the governing physical laws.
Background	Both Liu and Popović [2002] and Abe and his colleagues [2004] showed that many dynamic effects can be preserved by enforcing patterns of linear and angular momentum during the motion.
Background	Reformulating the dynamics to avoid directly computing the torques also provides a significant performance improvement [Fang and Pollard 2003].
Background	Reducing the number of degrees of freedom to be optimized can also create tractable problems.
Background	For example, Popović and Witkin [1999] showed that significant changes to motion capture data can be made by manually reducing the degrees of freedom to those most important for the task.
Background	Safonova and her colleagues [2004] demonstrated that an efficient optimization can be achieved in a behavior-specific, low-dimensional space without simplifying the dynamics.
Background	More recently, Liu and her colleagues [2005] introduced a novel optimization framework— Nonlinear Inverse Optimization—for optimizing appropriate parameters of the objective function from a small set of motion examples and then used the estimated parameters to synthesize a new locomotion.
Approach	Our work also uses a trajectory optimization framework but replaces the physical dynamic model with a statistical dynamic model computed from a motion capture database.
Approach	Our approach is also part of an alternative set of techniques that relies on motion data to constrain the search to natural looking motions.
Background	For example, motion graphs can be used to resequence whole-body or facial motions (see, for example, [Arikan and Forsyth 2002; Kovar et al. 2002; Lee et al. 2002; Zhang et al. 2004].
Background	These systems cannot match poses or satisfy such kinematic constraints as end effector constraints unless the motion database happens to contain a motion that satisfies those constraints.
Background	Motion interpolation, on the other hand, does allow isolated constraints to be satisfied (for example, [Rose et al. 1998; Kovar and Gleicher 2004; Mukai and Kuriyama 2005]).
Background	However, interpolation across a complete behavior does not have enough degrees of freedom to allow the specification of full pose constraints or end effector constraints across multiple frames.
Background	Recently, interpolation and motion graphs have been combined to obtain some of the advantages of each approach [Safonova and Hodgins 2007].
Background	Statistical models of human motion have also been used for motion synthesis.
Background	A number of researchers have used variants of Hidden Markov Models (HMMs) to statistically represent human motion: either full-body movements [Molina Tanco and Hilton 2000; Brand and Hertzmann 2000; Galata et al. 2001] or speechdriven facial expressions [Bregler et al. 1997; Brand 1999].
Background	HMMs learned from human motion data have been used to interpolate key frames [Molina Tanco and Hilton 2000; Galata et al. 2001], synthesize a new style of motion [Brand and Hertzmann 2000], and generate facial expressions from speech signals [Bregler et al. 1997; Brand 1999].
Background	Grzeszczuk and his colleagues[1998] developed a neural network approximation of dynamics based on simulated data and use it to animate dynamic models such as fish and lunar landers.
Background	Urtasun and her colleagues[2006] learned linear motion models from pre-aligned motion data via Principal Component Analysis (PCA) and used them to track 3D human body movements from video by performing nonlinear optimization over a small sliding temporal window.
Background	Switching linear dynamic system (SLDS) have also been used to model human motion.
Background	Pavlović and his colleagues [2000] present results for human motion synthesis, classification, and visual tracking using learned SLDS models.
Background	Li and his colleagues [2002] used SLDS to synthesize and edit disco dancing motion.
Approach	Our approach is also to learn a statistical dynamic model from human motion capture data; however, the dynamic behavior of our model is controlled by a continuous control state rather than a discrete hidden state as in HMMs and SLDS.
Approach	This property led us to formulate the motion synthesis problem as a trajectory optimization problem.
Approach	More importantly, our system allows the user to specify a variety of spatial-temporal constraints such as end effector constraints throughout the motion, a capability that has not been demonstrated by previous approaches.
Background	A number of researchers have developed statistical models for human poses and used them to solve the inverse kinematics problem.
Background	Grochow and colleagues [2004] applied a global nonlinear dimensionality reduction technique, Gaussian Process Latent Variable Model, to human motion data and then used the learned statistical pose model to compute poses from a small set of user-defined constraints.
Background	Another solution for data-driven inverse kinematics is to interpolate a small set of preexisting examples using constraints.
Background	This idea has been used to compute human body poses [Rose et al. 2001] and facial expressions [Zhang et al. 2004] from kinematic constraints at a single frame.
Background	These models lack temporal information and therefore cannot be used to generate an animation from sparse constraints such as key frames.
Background	Local statistical models are sufficient if the user provides continuous control signals (the performance animation problem).
Background	Chai and colleagues [2003] presented a real-time vision-based performance animation system that transforms a small set of automatically tracked facial features into facial animation by interpolating examples in a database at run time.
Background	They also used a series of local statistical pose models constructed at run time to reconstruct full-body motion from continuous, low-dimensional control signals obtained from video cameras [Chai and Hodgins 2005].
Approach	The statistical dynamic model used in this paper was motivated by the dynamic model used for video textures by Soatto and his colleagues [2001].
Background	They showed that a sequence of images of such moving scenes as sea-waves, smoke, and whirlwinds can be modeled by second-order linear dynamic systems.
Background	They applied the learned dynamic systems to synthesize an “infinite length” texture sequence by sampling noise from a known Gaussian distribution.
Approach	We extend the model to learn an efficient and low-dimensional representation of human motion and use it to generate an animation that achieves the goal specified by the user.
Challenge	The key idea behind our approach is that motion priors learned from prerecorded motion data can be used to create natural human motion that matches constraints specified by the user.
Approach	The combination of the motion prior and the user’s constraints provides sufficient information to produce motion with a natural appearance.
Approach	The human body motion capture database (about 15 minutes) includes data of locomotion (jumping, running, walking, and hopping) and interacting with the environment (standing up/sitting down, reaching/picking up/placing an object).
Approach	The facial expression database (about 9 minutes) includes six basic facial expressions (happiness, surprise, disgust, fear, anger, sadness) and three facial movements related to everyday life (speaking, eating, and snoring).
Approach	The motion was captured with a Vicon motion capture system of 12 MX-40 cameras [Vicon Systems 2004] with 41 markers for full-body movements and 92 markers for facial expressions.
Approach	The motion was captured at 120Hz and then downsampled to 30Hz.
Approach	In facial animation, y n is the 3D positions of all vertices on the face model.
Approach	In human body animation, y n is the position and orientation of the root and the joint angles.
Approach	We preprocess the motion capture data by applying Principal Component Analysis (PCA) [Bishop 1996] to the motion capture data and obtain a reduced subspace representation for y n :
Approach	The matrix C is constructed from the eigenvectors corresponding to the largest eigenvalues of the covariance matrix of the data, and D is the mean of all example data, D = (Σ N n=1 y n )/N .
Approach	The dimensionality of the system state, d x , can be automatically determined by choosing the d x for which the singular values drop below a threshold.
Approach	The system first automatically learns a statistical dynamic model from motion capture data.
Approach	This model is then used to compute the motion prior, − ln p(H).
Approach	The user defines various forms of constraints, E, throughout the motion, which are then used to compute the likelihood term, − ln p(E|H).
Approach	The constraints could be any kinematic constraints such as position, orientation, or the distance between two points on the character.
Approach	They could be specified either at isolated points (key frames) or across the whole motion (key trajectories).
Approach	The system uses trajectory optimization to automatically find an animation H ˆ that best satisfies the userspecified constraints while matching the statistical properties of the motion capture data: H ˆ = arg min H − ln p(E|H) − ln p(H).
Approach	x n ∈ R d x and u n ∈ R d u are the system state and control input, and d u is the dimensionality of the control input u n .
Approach	This formulation is similar to the linear time-invariant control system commonly adopted in the control community [Palm 1999].
Approach	However, the matrix B is not unique because the control input u t is unknown.
Approach	Therefore, any non-singular transformation of the matrix B represents the motion because BT and T −1 u n are also consistent with the dynamic model.
Approach	To remove this ambiguity, we assume that the matrix B is an orthogonal matrix.
Approach	However, we can perform singular value decomposition (SVD) on the data matrix Z such that Z = W SV T , and then get the best possible rank d u approximation of the data matrix, factoring it into two matrices: B ˆ = W and U ˆ = SV T , where B ˆ is a d x × d u matrix and U ˆ is a d u × (T − m) matrix.
Approach	The dimensionality of the control input (d u ) can be automatically determined by choosing the d u for which the singular values drop below a threshold.
Approach	Functionally, a statistical dynamic model is similar to a physical dynamic model.
Approach	Therefore, the statistical dynamic model might achieve faster convergence and be less subject to local minima.
Approach	The number of dimensions of the control input, d u , characterizes the complexity of our dynamic model.
Approach	The walk data set is from multiple subjects and contains different styles.
Approach	The facial expression data are from the same subject and contain a variety of facial expressions such as “happy” and “sad.
Approach	” The average reconstruction error is the L 2 distance between the original test motion and the motion reconstructed from the linear time-invariant system and computed by cross-validation techniques.
Approach	We observe that the reconstruction error of the statistical model decreases as both the order of dynamic system and the number of dimensions of the control input increases.
Approach	If we choose d u as “zero” (simply dropping off the control term), our model becomes the linear dynamic model used by Soatto and colleagues [2001] and has the largest reconstruction error.
Approach	If d u is equal to the number of dimensions of the system state d x , the model can be used to represent an arbitrary motion sequence with zero error.
Approach	In practice, human motion is highly coordinated, and the dimensionality of the control input for accurate motion representation, d u , is often much lower than the dimensionality of the system state, d x .
Approach	For the examples reported here, we set the dynamic order to three and the dimensionality of control input to four for human body animation (the reconstruction error is about 0.7 degrees/joint per frame); we set the dynamic order to two and the dimensionality of control input to one for facial movement (the reconstruction error is about 0.1 mm/vertex per frame).
Approach	Finally, we discuss how to optimize motion by combining both terms: H ˆ = arg min H − ln p(E|H) − ln p(H).
Approach	Like physically based optimization [Witkin and Kass 1988], we represent the system state x t and the control signal u t independently.
Approach	For facial animation, the user can specify the positions or orientations of any points on the face, or the distance between any two points.
Approach	For whole-body animation, the user can specify the positions or orientations of any points on the body, or joint angle values for any joints.
Approach	Rather than requiring that constraints be specified in 3D, it is often more intuitive to specify where the projection of a point on the character should be located.
Approach	Therefore, the system also allows the user to specify the 2D projections of any 3D point on a user-defined screen space.
Approach	This approach could be used for rotoscoping a video, or for a single camera performance animation.
Approach	The system allows the user to sketch out the motion in greater or lesser detail.
Approach	For example, a novice user might want to control the paths of specific joints or paths over a period of time using a performance animation system while a more skilled user might prefer using key frame constraints.
Approach	Spatially, the constraints could provide either an exact configuration such as a full-body pose or a small subset of the joint angles or end-positions.
Approach	Temporally, the constraints could be instantaneous constraints for a particular frame, multiple-frame constraints, or continuous constraints over a period of time.
Approach	User-defined constraints can be linear or nonlinear.
Approach	Linear constraints can be used to define joint angle constraints in human body animation and positions in facial animation.
Approach	The most common nonlinear constraints in human body animation might be end effector constraints, for example, foot contact constraints.
Approach	In facial animation, nonlinear constraints can be used to specify the distance between two points on the face or 2D projections of 3D facial points.
Approach	The likelihood term evaluates how well the synthesized motion matches the constraints specified by the user.
Approach	A good match between the motion and the user-defined constraints results in a low energy solution.
Approach	Many motions might satisfy the user-defined constraints.
Approach	For example, when the user specifies a small set of key frames or key trajectories, the number of constraints is not sufficient to completely determine the whole motion sequence, x 1:T .
Approach	To remove ambiguities, we would like to constrain the generated motion to lie in the space of natural human motions by imposing a prior on the generated motion:
Approach	Based on the statistical dynamic equation (Equation 4), the current system state x t only depends on the previous system states x t−m:t−1 and the current control input u t .
Approach	We have the corresponding energy term E prior dynamic = − ln T t=m+1 p(x t |x t−1:t−m , u t ) ∼ −α T t=m+1 x t − i=1 m A i x t−i − Bu t 2 (12) where α is a tuning parameter.
Approach	Conceptually, the dynamic prior can be thought as dimensionality reduction of the motion in a spatialtemporal domain.
Approach	It significantly reduces the dimensionality of the motion from the space of x 1:T to the space of the initial state x 1:m and the control input u m+1:T .
Approach	The second term on the right side of Equation 11 computes the prior for the initial state, x 1:m , and control input, u m+1:T .
Approach	We assume that both the initial state, x 1:m , and the control input, u t , are independent and identically distributed.
Approach	The energy term for the second term on the right side of Equation 11 can be simplified as follows:
Approach	We model the control input (u t ) as a mixture with K component Gaussian densities [Bishop 1996]:
Approach	The function N(u t ; φ j , Λ j ) denotes the multivariate normal density function with mean φ j and covariance matrix Λ j .
Approach	The parameters of the Gaussian mixture models (π k , φ k , Λ k ) are automatically estimated using an Expectation-Maximization (EM) algorithm [Bishop 1996].
Approach	Note that we choose weak priors (static models) to model the priors for both initial states and control inputs so as not to restrict the type of motions the algorithm can generate.
Approach	After combining the user-defined constraints and the motion prior, the constraint-based motion synthesis problem becomes the following unconstrained motion optimization problem:
Approach	We follow a standard approach of representing x t and u t using cubic B-splines.
Approach	We solve the optimization problem using sequential quadratic programming (SQP) [Bazaraa et al. 1993], where each iteration solves a quadratic programming subproblem.
Approach	The Jacobian matrix and the Hessian matrix of the energy function are symbolically evaluated at each iteration.
Approach	We choose all initial values using random values between 0 and 1 except that a linear interpolation of the user-specified keyframe constraints is used for initialization.
Approach	We found that the optimization procedure always converges quickly (usually less than 100 iterations and less than 30 seconds).
Approach	Typically, the objective function values decrease rapidly in the early iterations and then level off as they approach the optimal value.
Approach	Our optimization framework can also be applied to the problem of generating human body motions for a character whose skeletal model is markedly different from the subjects in the database.
Approach	User-defined constraints for motion retargeting can either be directly computed from the source motion or specified by the user.
Approach	In our experiment, we extract foot positions from a source walking motion and then use it to generate a walking sequence for a new character.
Approach	We also add one term in the objective function that measures the difference between the source motion and retargeted motion:
Approach	We test our system by generating both human body animation and facial animation from various forms of user-defined constraints.
Approach	We also evaluate the performance of our algorithm in terms of the motion priors and user-defined constraints.
Approach	We learn the statistical model for each individual behavior and use it to generate individual behavior based on user-defined constraints.
Approach	Two kinds of constraints were used to generate most of the examples in this paper: key-frame constraints and key-trajectory constraints.
Approach	We can also combine these two constraints.
Approach	For example, a jumping motion can be created by specifying a start pose and the positions of both feet and root throughout the motion.
Outcome	The accompanying video demonstrates the effectiveness of our system for generating a number of individual behaviors, including walking, running, and jumping.
Outcome	Our behavior-specific statistical motion model is capable of generating a rich variety of actions.
Outcome	For example, we can use a small set of key frames and foot contacts to generate normal walking, climbing over an obstacle, a baby walking, and mickey-mouse style walking.
Outcome	Our system can also synthesize motion that transitions from one behavior to another by using the statistical model learned from transition data.
Outcome	In the accompanying video, we demonstrate that the user can generate a transition from walking to jumping, from walking to sitting down, and from walking to picking up an object (figure 6).
Outcome	The accompanying video also shows that the system can generate motions for characters with skeletal dimensions different from those in the database.
Outcome	We also show that we can use motion priors learned from a small sequence of a normal walking motion (about 100 frames) to create walking on a slope and walking with small steps.
Approach	The user can refine the animation by incrementally modifying the constraints.
Approach	For example, the user can create a slightly different jumping motion by adjusting the positions of both hands at the top of the jump.
Approach	The system learns a single statistical model from the whole facial motion capture database and then uses it to create facial animation with a variety of spatial-temporal constraints.
Approach	The user can generate realistic facial animation by combining sparse keyframe constraints (three key frames) and sparse trajectory constraints (one trajectory).
Approach	The user selects six points on the face and specifies the 2D projections on the screen space at three key instants.
Approach	This type of constraint could be extracted by rotoscoping.
Approach	The user can achieve detailed control over facial movement by specifying the trajectories of a small set of 3D facial points.
Approach	The user can also use trajectories of a small set of high-level facial features (the mouth width and height and the openness of the eyes) to generate facial animation.
Approach	The quality of the final animation depends on the motion priors and the user-defined constraints.
Approach	We, therefore, have designed a number of experiments to evaluate the performance of our algorithm: The importance of the motion priors.
Approach	We evaluate the importance of motion priors by comparing our method against alternative constraint-based motion synthesis methods.
Approach	The first method is a simple linear interpolation of key frames.
Approach	The second method is trajectory-based inverse kinematics that minimizes the velocity changes of the motion in the original configuration space, y t , without any priors.
Approach	The third method is a simple data-driven inverse kinematics algorithm that minimizes the velocity changes of the motion in a reduced PCA space, x t .
Approach	We compare the methods using key-frame constraints and key-trajectory constraints.
Approach	We keep the constraints constant and use a cubic spline to represent the motion.
Outcome	Without the use of the statistical dynamic model, the system can not generate natural motions unless the user specifies a very detailed set of constraints across the entire motion.
Approach	We evaluate how the database influences the final motion by keeping the user-defined constraints constant.
Approach	We have experimented with both key-frame and key-trajectory constraints.
Approach	For key-frame constraints, the user defined a sparse set of walking constraints and used them to generate walking motion from the priors learned from a number of different databases.
Approach	We compare the results for a database of general locomotion, running, hopping, jumping and walking.
Outcome	The accompanying video shows that we can generate a good walking motion with a walking database.
Outcome	The quality of the animation becomes worse when we use a large and general locomotion database to generate walking.
Outcome	As would be expected, the system fails to generate a good walking motion if the motion prior is learned from running, hopping, or jumping data.
Outcome	We have tested the creation of jumping motion from key-trajectory jumping constraints when the prior is learned from a database of jumping, general locomotion, or walking.
Outcome	Similarly, the prior from a walking database fails to generate a good jumping motion because of the mismatch between the prior and the user-defined constraints.
Approach	With an appropriate database, we compare the quality of motions generated by different numbers of constraints.
Approach	More specifically, we take one motion sequence out of the database and use it as a testing sequence.
Approach	We then compare the animations created by key frames that are spaced increasingly far apart in time.
Approach	We also compare the results by decreasing the number of key trajectories.
Outcome	The accompanying video shows that results become worse when we decrease the number of the userdefined constraints.
Outcome	For example, the numerical error increases steadily (0.94, 1.06, 1.81 degrees per joint per frame) when the number of constraints is decreased (6, 4, 2 key frames).
Outcome	We observe a noticeable foot sliding artifact on one foot when two key trajectories (root and one foot) are used to create a walking motion.
Outcome	We have presented an approach for generating both full-body movement and facial expression from spatial-temporal constraints while matching the statistical properties of a database of captured motion.
Approach	The system automatically learns a low-dimensional linear dynamic model from motion capture data and then enforces this as spatial-temporal priors to generate the motion.
Approach	The statistical dynamic equations, together with an automatically derived objective function and user-defined constraints, comprise a trajectory optimization problem.
Approach	Solving this optimization problem in the lowdimensional space yields optimal, natural motion that achieves the goals specified by the user.
Outcome	The system achieves a degree of generality beyond the motion capture data.
Outcome	For example, we have generated a motion using constraints that cannot be satisfied directly by any motion in the database and found that the quality of the reconstructed motion was acceptable.
Outcome	Our video also demonstrates that the system can generate motion for characters whose skeletal models differ significantly from those in the database.
FutureWork	However, we have not yet attempted to assess how far the user’s constraints can stray from the motions in the database before the quality of the resulting animation declines to an unacceptable level.
Outcome	This statistically based optimization approach complements a physically based optimization approach and offers a few potential advantages.
Outcome	First, using a low-dimensional statistical dynamic model for the constrained optimization might achieve faster convergence and be less subject to local minima.
Outcome	Second, our approach can generate slow and even stylized motions that have proven particularly difficult for physically based optimization.
Outcome	Third, the optimization does not require physical models.
Outcome	Building anatomically accurate physical models for facial animation or whole-body motion remains challenging.
Outcome	There are two limitations of our approach: an appropriate database must be available and the user cannot specify such dynamic constraints as ground reaction forces or character mass.
Challenge	The main focus of this paper has been an exploration of the use of prior knowledge in motion capture data to generate natural motion that best satisfies user-defined constraints.
Challenge	Another important issue for building any interactive animation system is to design an intuitive interface to specify the desired motion.
Approach	In our experiments, most of keyframe constraints were modified from example poses in the database.
Approach	Foot contact constraints were specified by the user directly.
Approach	Key trajectory constraints were extracted from a performance interface using two video cameras [Chai and Hodgins 2005].
Approach	Alternatively, the user could rely on commercial animation software such as Maya to specify constraints.
Outcome	This process is timeconsuming even for a professional artist; it is more difficult for a naive user to specify such constraints.
FutureWork	One of immediate directions for future work is, therefore, to design intuitive interfaces that allow the user to specify spatial-temporal constraints quickly and easily.

Challenge	This paper presents a method to retarget the motion of a character to another in real-time.
Approach	The technique is based on inverse rate control, which computes the changes in joint angles corresponding to the changes in end-effector position.
Approach	While tracking the multiple end-effector trajectories of the original subject or character, our on-line motion retargetting also minimizes the joint angle differences by exploiting the kinematic redundancies of the animated model.
Outcome	This method can generalize a captured motion for another anthropometry to perform slightly different motion, while preserving the original motion characteristics.
Outcome	Because the above is done in on-line, a real-time performance can be mapped to other characters.
Outcome	Moreover, if the method is used interactively during motion capture session, the feedback of retargetted motion on the screen provides more chances to get satisfactory results.
Outcome	As a by-product, our algorithm can be used to reduce measurement errors in restoring captured motion.
Outcome	The data enhancement improves the accuracy in both joint angles and end-effector positions.
Outcome	Experiments prove that our retargetting algorithm preserves the high frequency details of the original motion quite accurately.
Challenge	The dream of animating complex living creatures with pure computation (such as inverse kinematics, or dynamic control) proved impractical.
Challenge	Even though creatures are not free from physics, their motion is not a direct consequence of physics.
Background	Dynamic control can provide solutions based on simplified assumptions about human motion.
Challenge	However, the result tends to look quite mechanical.
Background	If a high quality character animation has to be produced during a short period of time, motion capture might be a most reasonable choice these days.
Challenge	The captured data itself is for a specific person in performing specific motion.
Challenge	Whenever the data needs to be reused, it has to be retar- getted to account for the differences in the anthropometry and motion.
Challenge	Therefore motion retargetting is emerging as an important technique in recent character animation.
Challenge	If the original motion characteristics are severely lost during motion retargetting, the technique loses its merit over the above pure computation approaches.
Challenge	The problem we try to solve in this paper can be summarized as: ( 1 ) finding in real-time the motion retargetted to a new character that has different anthropometric proportions, and ( 2 ) at the same time, preserving the features of the original motion during the retargetting.
Challenge	( 3 ) As a by-product, it is possible to use the above retargetting algorithm for enhancing motion capture data so that the errors in joint angles and end-effector positions are reduced.
Approach	On-line motion retargetting presented in this paper is based on inverse rate control [17] (or resolved motion rate control), which is a way to implement inverse kinematics based on Jacobian.
Approach	It computes the changes in joint angles corresponding to the changes in end-effector position.
Approach	While tracking the multiple end-effector trajectories of the original subject or character, our on-line motion retargetting imitates the joint motion of the original character by exploiting the kinematic redundancies of the animated model.
Approach	Moreover, jerky motion is prevented since the next configuration is dependent on the previous configuration in inverse rate control.
Outcome	As will be shown in later experiments, the high frequency details of the original motion, which carries important characteristics of the motion, are also well preserved by our algorithm.
Approach	The input is a stream of joint angle vectors   src of the measured subject in the source motion and another stream of the reference (or desired) end-effector positions x 1 of the animated character at discrete time ticks.
Approach	The output is a stream of joint angle vectors   des of the animated character during the destination motion at corresponding time ticks.
Approach	It explains why it is called on-line.
Approach	If the retargetting can be done in on-line, real-time performance can be mapped to another character, or the feedback of the retargetted animation can facilitate motion capture session so that satisfactory results can be obtained with fewer trials.
Approach	Since the memory required for on-line retargetting does not increase with time, our algorithm can handle an infinitely long sequence of motion.
Approach	For example, when there is a bat-swing motion, we can obtain different swing motions aiming at different hit positions by specifying x 1 t appropriately.
Outcome	As a by-product, our OMR algorithm can be used to reduce measurement errors in restoring captured motion.
Approach	For this data enhancement, we use captured position data for x 1 t even though it can be calculated from   src t by forward kinematic positioning, to recover from possible measurement errors in joint angles.
Approach	If the positioning of the pose is done from joint angles alone, the errors can accumulate as the forward kinematic positioning propagates toward the end-effector.
Approach	The end-effector position data x 1 t can be utilized to limit the above error accumulation within a certain range.
Background	Several techniques have been proposed for reusing or altering existing motions.
Background	Witkin et al’s motion warping [19] and Bruderlin et al’s motion displacement mapping [4] discuss motion editing technique based on direct manipulation of data curves.
Background	Bruderlin et al [4] and Unuma et al [11] utilized signal processing techniques for motion editing.
Background	Wiley et al [18] proposed the interpolation synthesis algorithm that chooses and combines most relevant motions from the database to produce animation with a specific positional goals.
Background	Though some of the techniques above can be used for motion retargetting problem with user’s extra efforts, they don’t specifically address the motion retargetting problem.
Background	In [3], Boulic and Thalmann presented the combined direct and inverse kinematic control technique for motion editing.
Background	The concept called coach-trainee metaphor is very similar to the motion retargetting problem formulation.
Background	The fundamental idea is to consider the joint motion of coach as a reference input to trainee motion for the secondary task exploiting the null space of the Jacobian when solving inverse kinematics.
Background	The inverse kinematic constraint is given by half-space such as plane, cylinder, or sphere.
Background	Although their approach shares the technique of utilizing the redundancy in inverse kinematic control with ours, the problem they solved is not the motion retargetting but is rather a motion correction technique since the end-effector constraint specified by half-spaces is not general to solve the motion retargetting problem.
Background	A method which is devoted to the motion retargetting problem was proposed by Gleicher [6].
Background	He used the spacetime constraint method that minimizes an objective function g x subject to the constrains of the form f x = c .
Background	The constraints can represent the ranges of parameters, or various kinds of spatial-temporal relationship among the body segments and the environment.
Background	The objective function is the time integral of the signal displacement between the source and destination motion.
Background	The global method as above can correlate frames back and forth within the whole duration and thus generally produces more smooth results compared to the local method such as our OMR technique.
Background	But the look-ahead property of the global method is effective when the constraints are imposed only at sparse key frames.
Approach	Our OMR takes continuous trajectories of constraints as input, so that it produces globally coherent motion in spite of local computation.
Approach	The global coherence is also achieved from the effort to exploit the redundancy of the system in resembling the original motion.
Approach	The local coherence of the motion comes from the fact that the adjacent frames are inter-related by the inverse rate control.
Outcome	Therefore, without significant degradation of quality, our algorithm provides much faster and interactive way of motion retargetting.
Background	Bindiganavale and Badler [2] presented a method to abstract and edit motion capture data.
Background	Their algorithm detects significant events and abstracts constraints from the motion, and imposes those constraints to other character.
Background	The constraints abstracted from the motion is solved by inverse kinematics at significant frames and then those frames are interpolated.
Background	Although the constraint abstraction is an improvement compared to the other techniques, the interpolation technique might fail to preserve the high frequency details if the key frames are sparsely spaced.
Approach	m can be 12 or 18 if we want to impose multiple end-effector constraints.
Approach	J 1 is called Jacobian and is an m n matrix that linearly relates the end effector velocity and joint angle velocity at the moment.
Approach	Given the end effector velocity, we can get joint angle velocity by inverting the Jacobian.
Approach	However, most articulated figures have kinematic redundancy and thus the inverse of Jacobian is not unique.
Approach	Some criteria can be specified to pick one that best fits for our purpose.
Approach	One of popular criteria is called the minimal norm solution         ( 4 )        where J 1 + = J 1 T J 1 J 1 T , 1 is the pseudo inverse 1 of J 1 .
Approach	Another way to utilize the redundancy of the system is to set y to the gradient , r g of a criterion function g   in Equation 5.
Approach	Then integration of Equation 5 tries to reduce the value of g   while the end-effector is made to track the given trajectory [9].
Background	Balestrino et al [1], Tsai and Orin [15], and Sciavicco and Siciliano [14, 13] proposed the closed-loop inverse kinematics (CLIK) scheme based on Jacobian pseudoinverse.
Approach	CLIK leads to zero steady state error which means that the error is exponentially convergent to zero for a fixed target position.
Approach	It can be easily shown that as the smallest eigen value of K 1 becomes large, the convergence rate increases accordingly since the error dynamics is governed by the relation e 1 + K 1 e 1 =0 .
Approach	In a continuous time formulation such as Equation 7, a large value of K 1 is desirable.
Approach	However, as will be shown below an arbitrarily large K 1 doesn’t guarantee convergence in implementing the discrete version of Equation 7.
Approach	Therefore, e 1 n should be estimated.
Approach	Below we show that any estimation based on the old values (at n , 1 , n , 2 , : : : ) requires K 1 to be I for the best tracking performance.
Approach	Suppose that we estimated e 1 n simply with e 1 n , 1 .
Approach	) But in practice, we found that instability rarely occurs at a usual sampling rate ( 30 60 Hz) in dealing with human motion.
Approach	x des 2 is the actual result of the secondary task that tries to realize the given goal x 2 .
Approach	It is proven that e 2 is ultimately bounded within a certain range and the tracking error for the primary task is not affected by the second term of Equation 15 [13].
Approach	But again, arbitrarily large K 2 is not allowed in discrete implementation.
Approach	We found that the estimation rule described below gives satisfactory results.
Background	The serial chain is not suitable for modeling creatures since underlying articulated structures contain branches.
Approach	An illustrative example is taken from human upper body, and is shown in Figure 2 .
Approach	The model consists of spine and two arms.
Approach	The waist is the root of the kinematic tree structure, and the two arms are branching at the top of the spine.
Approach	If both hands have their own goals to reach, and if inverse kinematics is solved for these cases separately, then the spine angles will differ in the solutions.
Background	In [22], Zhao and Balder solved this problem by a weighted sum of independently obtained gradients, each of which directs its corresponding end-effector to a goal position.
Background	However, the effects of different weights are not easily predictable.
Background	Depending on the weight assignment, their algorithm can fail to find an inverse kinematic solution even if all the constraints can be actually met.
Approach	Intrinsically, the problem of finding inverse kinematic solution of multiple constraints doesn’t require any weight or priority assignment: if all the end-effector constraints can be met, then it should be possible without considering weights or assigning priorities to each end-effector constraint.
Approach	Compared with Zhao and Badler’s algorithm, Jacobian based inverse rate control gives a quite simple and intuitive solution to the problem.
Approach	The only thing we have to do in order to incorporate multiple end-effector constraints is concatenating the end-effector vectors and composing the Jacobian appropriately.
Approach	Of course, the Jacobian will have many zeroes where the joint angle and the end-effector have no relation such as left elbow joint and right hand.
Approach	In inverse rate control, the above conflict of the spine angles is resolved during the computation of the pseudo inverse of the Jacobian.
Approach	In general, we can formulate the motion retargetting problem with the following task set, and can solve for   des .
Approach	Since joint angle trajectories contain important characteristics of a motion, and since the end-effector movements are already tracked by the primary task, an obvious and useful choice for the secondary task might be to imitate the joint motion of the source character.
Approach	Reasonable choices for K 1 and K 2 are I ’s in discrete implementation as stated before.
Approach	But K 1 , K 2 can be adjusted based on the dexterity measure to get consistent motion near the kinematic singularities.
Approach	A popular dexterity measure is min = max , where min and max are the minimum and maximum, respectively, among the singular values of the Jacobian.
Approach	In this case, smaller K 1 and K 2 should be used if the dexterity measure turns out to be small.
Approach	The adaptive scheme can be also useful if we apply the OMR algorithm to motion transition.
Approach	Smaller gain (e.g. K 1 = K 2 = 0 : 1 I ) will produce sluggish tracking, but produces smooth motion.
Approach	Therefore, if the animated model switches to another motion and there exists a large discrepancy at the motion boundary, smooth transition can be obtained by adjusting the gain matrix K 1 and K 2 appropriately.
Approach	Therefore another provision for enforcing stability might be to clamp the value that goes into the box of J 1 + in Figure 4 whenever it is over a certain threshold.
Approach	The provision might be effective when there is an excessively large acceleration, or when the model is fully stretched and almost no manipulative redundancy is left in the system.
Approach	(In dealing with the human motion, however, the above provision was almost never needed.
Approach	When we capture a motion, we often measure the joint angles and use forward kinematics to reconstruct the motion.
Challenge	But the method can introduce large end-effector position errors since the joint angle error near the base is amplified when it comes to the end-effector, and joint angle errors are accumulated as the forward kinematic positioning propagates toward the end-effector.
Background	Choi et al’s interpolation/regression method [5], applies inverse kinematics at sparse keyframes and the resulting joint angles are interpolated with cubic spline curves.
Background	The interpolation is combined with least square fitting so that the characteristics of the original joint angle data is preserved in the resulting motion.
Approach	The OMR algorithm described in the previous section can be used to reduce measurement errors in restoring the captured motion.
Outcome	The new method is an improvement over the above interpolation/regression method in three aspects: ( 1 ) inverse kinematics is done at every frame, which promises much closer end-effector tracking, ( 2 ) the joint angle imitation is done by exploiting redundant degrees of freedom rather than depending on the least square fit, and ( 3 ) the high frequency component of the original motion is preserved much better in the new method.
Approach	For the enhancement, we measure both joint angle and end-effector trajectories during the motion capture session.
Approach	The measured trajectories are supplied to our motion retargetting algorithm: the end-effector trajectories are supplied for x 1 , and the joint angle trajectories are supplied for   src .
Approach	Of course, the destination character has to be same with the source character, if pure data enhancement needs to be done.
Outcome	In general, our algorithm also reduces the errors in joint angle measurements.
Outcome	While the joint angle errors can accumulate in forward kinematic reconstruction, once it is processed by our OMR, the total amount of accumulated error is limited by the amount of end-effector position error.
Outcome	Moreover, the joint angle error due to the end-effector position error is distributed among all the joints.
Outcome	Therefore unless the amount of end-effector position error is excessively larger than that of joint angle errors, our OMR produces more accurate result than the unprocessed data.
Approach	Note that the above does not mean the retargetting and data enhancement should be done separately.
Approach	If a different destination character is used, the two things are actually achieved at the same time.
Outcome	This is especially useful when a real-time performance is retargetted.
Approach	In the first experiment, we show a retargetting example in which our OMR is applied to retarget a walking motion, to demonstrate that our OMR based on inverse rate control is not inferior in the quality to the retargetting based on spacetime constraints.
Approach	Major error analysis of the algorithm is given in this example.
Approach	In the second experiment, we show the retargetting of bat-swing motion.
Approach	In this experiment, the source motion (refer to the video clip #1) is a curved path walking motion which was procedurally generated by Ko’s locomotion algorithm [8].
Approach	The walker took 13 steps and produced a total of 390 frames.
Approach	The kinematic structure of the characters used for walking motion is shown in Figure 5 .
Approach	Since the lower body motion is far more important than the upper body motion in walking example, we retargetted only the lower body motion.
Approach	As shown in Figure 5 the lower body consists of pelvis, upper leg, lower leg, foot, and toes, and they are connected at the hip, knee, ankle, and ball joints.
Approach	The total degree of freedom of the lower body is 8 3 + 6 = 30 .
Approach	(All the joints were modeled by 3-DOF joints, and the base has extra 6 DOFs.
Approach	) The destination character was about 60% scaled down from the source character with non-uniform proportions.
Approach	In the retargetting, the secondary task was set to   src =   des .
Approach	To specify the primary task, we set the toe-tip of the stance leg as the base and the toe-tip of the swing leg as the end-effector.
Approach	The source character’s toe-tip trajectory was used for x 1 without any modification.
Approach	Therefore the destination character had to take relatively bigger steps considering his body size.
Approach	At the boundaries of steps the base and end-effector were switched.
Approach	It implies that there can be discontinuities at the boundary if the tracking error is large.
Outcome	The retargetted motion with the above task set is shown in the video clip #2.
Outcome	The tracking error of the swing foot was negligible and thus the produced motion was smooth at the step boundaries.
Outcome	But the pelvis motion showed non-uniform speed along the direction of progression (anterior-posterior), which wasn’t observable in the source motion.
Approach	So we constrained the transverse plane motion of the pelvis.
Approach	i.e. the pelvis was designated as another end-effector, and the x; z component of the source character’s pelvis movement was tracked in the destination motion.
Approach	(Note that the pelvis motion along y -axis should be adapted to account for the height difference).
Outcome	After adding the constraint, we could obtain a satisfactory result as shown in the video clips #3 and #4.
Outcome	Even with the extra constraints, the end-effector trajectories of the source and the destination made an accurate match.
Outcome	The comparison is shown in Figure 7 .
Outcome	The dotted curves for the source motion are not visible because they overlap exactly with the solid curves, the end-effector trajectories of the destination motion.
Approach	To show the tracking error microscopically, the area indicated with a small box near the 150th frame in Figure 7 was magnified in Figure 8 .
Outcome	The trajectories in the figure show that the tracking error is kept small where the velocity is nearly constant, but the error increases when the velocity makes sudden changes.
Outcome	The maximum error (1.0464 cm) occurred at the 128th frame where the y -coordinate (height) of the toe-tip reached its peak acceleration and this error was reduced to a negligible level at around the 135th frame as the acceleration decreased.
Approach	The step boundary was taken from low-acceleration points so that the base to end-effector switch makes a smooth transition.
Outcome	The joint angle trajectories of the left leg during the original and retargetted motion are plotted in Figure 10 .
Outcome	Only the angles around the sideways direction (medial-lateral) axes are presented in the graphs.
Outcome	The comparison shows that the amplitude of the hip angle is increased in the destination motion to cover the given step length with the relatively smaller body.
Outcome	Other than that the original joint angle pattern was quite well preserved.
Outcome	3 At the end of every step, the ball joint of the source character showed an abrupt change from a large negative value to zero.
Outcome	It corresponds to the toe-off moment when the toes take off the ground.
Outcome	After the retargetting, the sharp corner of the trajectory was well preserved.
Outcome	In general, our OMR preserves the high frequency content of the motion quite well, since inverse rate control is directed by Jacobian values.
Outcome	Big mountains or valleys are never missed.
Outcome	To recover tiny fluctuations as well, however, a high sampling rate is needed to avoid aliasing.
Outcome	If the sharp corners are undesirable, they can be prevented by adjusting the gain matrix K 2 or clamping some of the control input as stated in Section 4.
Outcome	The adjustment of K 2 does not affect the end-effector tracking performance.
Approach	In this experiment, actual performance of a bat swing motion was processed by our OMR to produce the destination motion of three different characters shown in Figure 9 .
Approach	The anthropometry of Character B is about the average.
Approach	Character A has a longer torso but shorter limbs than average, and Character C has a shorter torso but longer limbs.
Approach	Their kinematic structures are same as Figure 5 except that the torso is segmented to 5 parts and the feet are excluded.
Approach	To set the primary task, the base and end-effectors should be specified as before.
Approach	In this experiment, the pelvis was chosen as the base and two hands were chosen as the endeffectors.
Approach	Three 6-DOF sensors were used to capture those positions and orientations.
Approach	The end-effector motion was directly supplied for x 1 t without any modification.
Approach	Since all the torso segments can not be measured due to the limited number of sensors, we measured only the topmost segment.
Approach	Therefore, the five joints from the waist to the top-most torso segment had to be generated from the orientation difference between the pelvis and the top-most torso segment.
Approach	For this, the measured orientation of the topmost torso segment was added to the primary task, and zero angles for the unmeasured joints were added to the secondary task, expecting the primary task can be met with minimal joint angles along the torso.
Approach	The other sensors were used to measure the joint angles.
Approach	(Because we had only 13 sensors available, we had to give up capturing the foot motion.
Approach	) In this experiment only the upper body motion was adapted by OMR.
Approach	The lower body motion was reconstructed by applying the measured joint angles directly.
Outcome	The retargetting of the source motion to Characters A, B, C are shown in the video clips #5 ̃6, #7 ̃8, and #9 ̃10, respectively.
Outcome	The small green boxes in the video indicate the position of the end-effectors and base.
Outcome	In the video we can observe that end-effector positions are accurately tracked.
Outcome	Since the body dimensions of Character B and the real performer are similar, the retargetted motion does not contain any noticeable difference from the source motion.
Outcome	In the case of Character A, however, we can see the waist is bent to lower the hit position, and the torso is shifted forward to account for the shorter arms.
Outcome	In the case of Character C, the torso is bent backward and makes a bigger twist to account for the longer arms and shorter torso.
Outcome	Snap shots were taken during the retargetted motions to clearly demonstrate the above adaptation for the anthropometric differences and shown in Figure 11 .
Approach	Since we had no privilege to install our program to the platform equipped with a motion capture system, we had to emulate the real-time motion capture.
Approach	That is, the motion data captured at 30Hz was fed to the OMR system with the same sampling rate using a timer.
Outcome	At this sampling rate, not a single frame was lost even with the visualization included.
Approach	We used an Intergraph GX1 system (dual P-III 550, wildcat 4000) for the experiments.
Outcome	The code was not fully optimized and so the performance can be potentially improved further.
Outcome	The slower rate of the bat swing motion is due to the bigger size of the Jacobian matrix compared to the walking motion (8 30 vs. 9 42).
Outcome	As shown in the table, the OMR is fast enough to process motion capture data collected at a usual sampling rate (30 90Hz) in real-time for the models of reasonable complexity.
Outcome	This paper presented the on-line motion retargetting technique based on inverse rate control.
Outcome	The method is an improvement over the off-line retargetting based on spacetime constraints since real-time performances can be retargetted without degradation of retargetting quality.
Outcome	The OMR technique greatly helps to get more satisfactory results in motion capturing with fewer trials by giving the real-time feedback to the performer.
Outcome	Furthermore, the captured data are enhanced in both end-effector positions and joint angles by going through our OMR filter.
Outcome	One minor unsolved problem is that there is no easy way to guarantee full-proof stability of the system due to the non-linearity.
Outcome	We observed that at a very low sampling rate, and if the model goes near the kinematic singularity and thus very little manipulative redundancy is left, then the system can became unstable.
Outcome	However, experiments proved that the system never become unstable at 30Hz or higher sampling rate.
Outcome	If the source motion is available only at a low sampling rate, two remedies are recommended: ( 1 ) by interpolating the source motion curves, first produce more samples, and then use them as the input to the OMR filter, or ( 2 ) scale down the end-effector trajectory to avoid the singular configuration, or use both of ( 1 ) and ( 2 ).
Outcome	The above remedies are for an excessively bad situation.
Outcome	Our on-line motion retargetting produces satisfactory results in retargetting most human or creature motion.
Outcome	If the technique is well utilized, it can be very useful to people in character animation and game industries.

Challenge	This paper shows how statistical motion priors can be combined seamlessly with physical constraints for human motion modeling and generation.
Approach	The key idea of the approach is to learn a nonlinear probabilistic force field function from prerecorded motion data with Gaussian processes and combine it with physical constraints in a probabilistic framework.
Approach	In addition, we show how to effectively utilize the new model to generate a wide range of natural looking motions that achieve the goals specified by the users.
Outcome	Unlike previous statistical motion models, our model can generate physically realistic animations that react to external forces or changes in physical quantities of human bodies and interaction environments.
Approach	We have evaluated the performance of our system by comparing against ground truth motion data and alternative methods.
Challenge	A central goal in human motion modeling and generation is to construct a generative motion model to predict how humans move.
Challenge	The problem has attracted the attention of a large number of researchers because of both its theoretical and applied consequences.
Challenge	A generative motion model, for instance, can be used to generate realistic movement for animated human characters or constrain the solution space for modeling 3D human motion in monocular video streams.
Background	Decades of research in computer animation have explored two distinctive approaches for human motion modeling: statistical motion      modeling and physics-based motion modeling.
Challenge	Despite the efforts, accurate modeling of human motion remains a challenging task.
Background	Statistical motion models are often represented as a set of mathematical equations or functions that describe human motion using a finite number of parameters and their associated probability distributions.
Background	Statistical models are desirable for human motion representation because they can model any human movement as long as relevant motion data are available.
Challenge	A fundamental limitation is that they do not consider the dynamics that cause the motion.
Challenge	Therefore, they fail to predict human motion that reacts to external forces or changes in the physical quantities of human bodies and in the interaction environments.
Challenge	Moreover, when motion data are generalized to achieve new goals, the results are often physically implausible and thereby display noticeable visual artifacts such as unbalanced motions, foot sliding, and motion jerkiness.
Challenge	Physics-based motion models could overcome the aforementioned limitations by applying physics to modeling human movements.
Challenge	However, physical laws alone are often insufficient to generate natural human movement because a motion can be physically correct without appearing natural.
Approach	One way to address the problem is to define a global performance criterion based on either the smoothness of the movement or the minimization of needed controls or control rates (e.g., minimal muscle usage).
Challenge	These heuristics show promise for highly dynamic motions, but it remains challenging to model low-energy motion or highly stylized human actions.
Challenge	In addition, it is unclear if a single global performance objective such as minimal torque is appropriate to model heterogeneous human actions such as running→walking→jumping.
Challenge	In this paper, we show how statistical modeling techniques can be combined with physics-based modeling techniques to address the limitations of both techniques.
Challenge	Physical motion models and statistical motion models are complementary to each other as they capture different aspects of human movements.
Challenge	On the one hand, physical models can utilize statistical priors to constrain the motion to lie in the space of natural appearance and more significantly, learn an appropriate performance criterion to model natural-looking human actions.
Challenge	On the other hand, statistical motion models can rely on physical constraints to generate physically correct human motion that reacts to external forces, satisfies friction limit constraints, and respects physical quantities of human bodies or interaction environments.
Approach	By accounting for physical constraints and statistical priors simultaneously, we not only instill physical realism into statistical motion models but also extend physics-based modeling to a wide variety of human actions such as stylized walking.
Approach	The key idea of our motion modeling process is to learn nonlinear probabilistic force field functions from prerecorded motion data with Gaussian Process (GP) models and combine them with physical constraints in a probabilistic framework.
Approach	In our formulation, a force field function u = g(q, q)  ̇ maps kinematic states (joint poses q and joint velocities q)  ̇ to generalized forces (u).
Outcome	We demonstrate the power and effectiveness of our motion model in constraint-based motion generation.
Outcome	We show that we can create a natural-looking animation that reacts to changes in physical parameters such as masses or inertias of human bodies and friction properties of environments ( Figure 1(a) ) or external forces such as resistance forces ( Figure 1(b) ).
Outcome	In addition, we show that a single physically valid statistical model is sufficient to create physically realistic animation for a wide range of style variations within a particular human action such as “sneaky” walking (Figure 1(c)) or transitions between heterogeneous human actions such as running→walking→jumping ( Figure 1(d) ).
Approach	We evaluate the performance of our model by comparing with ground truth data as well as alternative techniques.
Approach	We introduce a physically valid statistical motion model that combines physical laws and statistical motion priors and use it to create physically realistic animation that achieves the goals specified by the user.
Approach	Therefore, we will focus our discussion on statistical motion modeling and physics-based motion modeling as well as their applications in constraint-based motion synthesis.
Background	Statistical models are desirable for human motion modeling and synthesis because they are often compact and can be used to generate human motions that are not in prerecorded motion data.
Background	Thus far, a wide variety of statistical motion models have been developed; their applications include inverse kinematics [Grochow et al. 2004; Chai and Hodgins 2005], human motion synthesis and editing [Li et al. 2002; Chai and Hodgins 2007; Lau et al. 2009; Min et al. 2009], human motion style interpolation and transfer [Brand and Hertzmann 2000; Ikemoto et al. 2009; Min et al. 2010], and so forth.
Background	Nonetheless, the motions generated by statistical motion models are often physically invalid because existing statistical motion models do not consider the forces that cause the motion.
Background	Another limitation is that they do not react to perturbations (e.g., external forces) or changes in physical quantities such as masses and inertias of human bodies.
Background	Physics-based motion models could overcome the limitations of statistical motion models by applying physics to modeling human movement.
Background	However, physics-based motion modeling is a mathematically ill-posed problem because there are many ways to adjust a motion so that physical laws are satisfied, and yet only a subset of motions are natural-looking.
Background	One way to address this limitation is by adopting the “minimal principle” strategy, which was first introduced to the graphics community by Witkin and Kass [1988].
Background	They postulated that an individual would determine a movement in such a way as to reduce the total muscular effort to a minimum, subject to certain constraints.
Background	Therefore, a major challenge in physics-based motion modeling is how to define an appropriate performance criterion for the “minimal principle.
Background	” Decades of research in computer animation (e.g., [Witkin and Kass 1988; Cohen 1992; Liu et al. 1994; Fang and Pollard 2003]) introduced numerous performance criteria for human motion modeling, e.g., minimal energy, minimal torque, minimal jerk, minimal joint momentum, minimal joint acceleration, or minimal torque change.
Background	These heuristics show promise for highly dynamic motions, but it remains very difficult to model low-energy motions and highly stylized human movements.
Background	A number of researchers have recently explored the potential of using prerecorded motion data to improve physics-based optimization methods, including editing motion data with the help of simplified physical models [Popović and Witkin 1999], initializing optimization with reference motion data [Sulejmanpasic and Popović 2005], learning parameters of motion styles from prerecorded motion data [Liu et al. 2005], and reducing the search space for physicsbased optimization [Safonova et al. 2004; Ye and Liu 2008].
Approach	Similar to these methods, our system utilizes both motion data and physics for human motion analysis and generation, but there are two important distinctions.
Approach	First, we rely on statistical motion models rather than a predefined global performance objective (e.g., minimal muscle usage) to reduce the ambiguity of physics-based modeling.
Approach	This enables us to extend physics-based modeling to stylistic human motions such as “sneaky walking”.
Approach	Another attraction of our model is that it learns the mapping from the kinematic states to generalized forces using Gaussian process models.
Background	Unlike reference trajectories or linear subspace models adopted in previous work, GP models are capable of modeling both stylistic variations within a particular human action and heterogeneous human behaviors.
Approach	Our research draws inspiration from the large body of literature on developing control strategies for physics-based simulation.
Approach	In particular, our nonlinear probabilistic force field functions are conceptually similar to control strategies used for physics-based simulation because both representations aim to map kinematic states to driving forces.
Background	Thus far, researchers in physics-based simulation have explored two approaches for control design, including manually designed control strategies (e.g. [Hodgins et al. 1995]) and tracking a reference trajectory while maintaining balance [Zordan and Hodgins 2002; Sok et al. 2007; Yin et al. 2007; da Silva et al. 2008; Muico et al. 2009].
Approach	However, our approach is different in that we automatically learn nonlinear probabilistic mapping functions from large sets of motion data.
Challenge	In addition, our goal is different because we aim to generate a desired animation that matches user constraints.
Background	Physics-based simulation approaches are not appropriate for our task because forward simulation techniques often do not provide accurate control over simulated motions.
Approach	Our approach uses Gaussian process to model a nonlinear probabilistic function that maps from kinematic states to generalized forces.
Background	GP and its invariants (e.g., GPLVM) have recently been applied to modeling kinematic motion for many problems in computer animation, including nonlinear dimensionality reduction for human poses [Grochow et al. 2004], motion interpolation [Mukai and Kuriyama 2005], motion editing [Ikemoto et al. 2009], and motion synthesis [Ye and Liu 2010].
Background	In particular, Ikemoto and her colleagues [2009] learned the kinematic mapping from pose information of the source motion to pose and acceleration information of the target motion and applied them to transferring a new source motion into a target motion.
Background	Ye and Liu [2010] used GPLVM to construct a second-order dynamic model for human kinematic data and used them to synthesize kinematic walking motion after a perturbation.
Approach	Our approach is different in that we focus on modeling the relationship between kinematic data and generalized forces rather than kinematic motion data itself.
Approach	We construct a physically valid statistical model that leverages both physical constraints and statistical motion priors and utilize it to generate physically realistic human motion that achieves the goals specified by the user.
Approach	Our motion model considers both Newtonian dynamics and contact mechanics for a full-body human figure.
Approach	Therefore, we describe the Newtonian dynamics equations for full-body movement and Coulomb’s friction model for computing the forces caused by the friction between the character and the interaction environment (Section 4).
Approach	We automatically extract force field priors from prerecorded motion data (Section 5).
Approach	Our force field priors are represented by a nonlinear probabilistic function u = g(q, q)  ̇ that maps the kinematic states (q, q)  ̇ to the generalized forces u.
Approach	To achieve this goal, we precompute the generalized forces u from prerecorded kinematic motion data and apply Gaussian process to modeling the force field priors embedded in training data.
Approach	We show how to combine force field priors with physics-based dynamics models seamlessly in a probabilistic framework and how to use the new motion model to generate physically realistic animation that matches user-defined constraints (Section 6).
Approach	We formulate the constraint-based motion synthesis problem in a Maximum A Posteriori (MAP) framework and introduce an efficient gradient-based optimization algorithm to find an optimal solution.
Approach	Our dynamics models approximate human motion with a set of rigid body segments.
Approach	We describe a full-body character pose with a set of independent joint coordinates q ∈ R 48 , including absolute root position and orientation, and the relative joint angles of 18 joints.
Approach	These joints are the head, thorax, upper neck, lower neck, upper back, lower back, left and right humerus, radius, wrist, femur, tibia, and metatarsal.
Approach	The Newtonian dynamics equations for full-body movement can be described using the following equation [Jazar 2007]:
Approach	The quantities M (q), C(q, q)  ̇ and h(q) are the joint space inertia matrix, centrifugal/Coriolis and gravitational forces, respectively.
Approach	The vectors τ , f c , and f e represent joint torques, contact forces, and external forces, respectively.
Approach	The vector u represent the generalized forces, which can be either calculated from kinematic data or resultant forces of join torques, contact forces, and external forces.
Approach	Human muscles generate torques about each joint, leaving global position and orientation of the body as unactuated joint coordinates.
Approach	As a result, the movement of the global position and orientation is completely determined by contact forces f c and external forces f e .
Background	During ground contact, the feet can only push but not pull on the ground.
Approach	To keep the body balanced, contact forces should not require an unreasonable amount of friction and the center of pressure must fall within the support polygon of the feet.
Approach	We use Coulomb’s friction model to compute the forces caused by the friction between the character and the environment.
Approach	A friction cone is defined to be the range of possible forces satisfying Coulomb’s function model for an object at rest.
Approach	We ensure the contact forces stay within a basis that approximates the cones with nonnegative basis coefficients.
Approach	The 4 × 1 vector e λ m represents nonnegative basis weights for the m-th contact force.
Approach	The contact force Jacobian J m (q) maps the instantaneous generalized joint velocities to the instantaneous world space cartesian velocities at the m-th contact point under the joint pose q.
Approach	Note that we remove the nonnegative coefficients constraints by representing the basis weights with exponential functions.
Approach	Enforcing Newtonian dynamics equations and friction limit constraints would allow us to generate physically correct motion that satisfies friction limit constraints.
Approach	However, physical constraints alone are insufficient to model natural-looking human movement because a motion can be physically correct without appearing natural.
Approach	Our system automatically extracts force field priors embedded in prerecorded motion data.
Approach	We generalize this concept by learning a nonlinear probabilistic force field u = g(q, q),  ̇ which maps kinematic states (q, q)  ̇ to generalized forces u.
Approach	Given an initial kinematic state (q 1 , q  ̇ 1 ) of a human figure, a force field can predict how humans move by sequentially advancing a Newtonian dynamics model over time.
Approach	Constructing force field priors from motion capture data, however, is difficult because current motion capture technologies cannot directly measure generalized forces.
Approach	Our solution is to compute generalized forces from prerecorded kinematic poses using the following Newtonian dynamics equation:
Approach	The joint velocities q  ̇ are computed as a backward difference between current and previous frames.
Approach	The joint accelerations q are computed as a central difference between previous frames, current frames, and next frames.
Approach	We have observed that the generalized forces computed from kinematic motion data are often very noisy because they are related to second derivatives of kinematic poses (see Figure 2 ).
Approach	We thus preprocess generalized force data as well as joint poses and velocities using physics-based trajectory optimization techniques.
Approach	Our approach follows the spacetime formulation in computer graphics literature [Witkin and Kass 1988; Cohen 1992].
Approach	Briefly, we minimize the deviation from prerecorded kinematic motion data as well as the sum of the squared torques.
Approach	This optimization is subject to foot-ground contact constraints, friction limit constraints, and the discretization of physics constraints determined by a finite difference scheme.
Approach	Our next task is to learn force field priors from the training data sets.
Background	A force field is a nonlinear probabilistic function u = g(q, q) that maps the kinematic state (q, q)  ̇ to the generalized forces u.
Approach	We propose to use Gaussian process model to construct a force field from the training data sets.
Approach	We choose GP model because it can efficiently model nonlinear property of the force fields and its learning process involves very few manual tuning parameters.
Approach	More specifically, our GP model learns a nonlinear probabilistic function that predicts the generalized forces based on the joint pose and joint velocity (for details, see Appendix):
Approach	̇ In our implementation, we represent the root translations in the ground plane and the rotations about the up axis at the current frame with respect to the root coordinate system at the previous frame in order to eliminate the effect of absolute positions in the ground plane and the rotations about the up axis.
Background	In practice, human motion is highly coordinated, the number of dimensions of joint poses, joint velocities, or generalized forces is often much lower than the number of dimensions of the character’ poses.
Approach	We, therefore, apply Principal Component Analysis techniques to reducing the dimensionality of both kinematic data [q n , q  ̇ n ] and generalized force data u n and employ Gaussian process to model the force fields in reduced subspaces.
Approach	We automatically determine the dimensions of subspaces by keeping 95% of the original energy.
Approach	Subspace learning not only reduces the memory space for GP modeling but also significantly speeds up the learning and evaluation process of GP models.
Approach	To simplify the visualization, we only show the top two eigen-vectors for the kinematic states (q, q)  ̇ as well as the generalized forces u.
Approach	Given an initial state (q 1 , q  ̇ 1 ), the learned force field priors pr(u|q, q)  ̇ can produce a physically realistic motion sequence by sequentially advancing a Newtonian dynamics model over time ( Figure 3(b) and Figure 3(c) ).
Approach	We now discuss how to combine force field priors with physicsbased dynamics models in a probabilistic framework and how to apply the proposed framework to generating physically realistic human motion that achieves the goals specified by the user.
Approach	We introduce a probabilistic motion model to model how humans move.
Approach	According to Bayes’ rule, we can decompose the probabilistic motion model pr(x) into the following three terms: pr(x) = pr(q 1 , q  ̇ 1 ) · pr(u t |q t , q  ̇ t ) · pr(q t+1 , q  ̇ t+1 |q t , q  ̇ t , u t ) t pr init pr f orcef ield pr physics (5) where the first term pr init represents the probabilistic density function of the initial kinematic pose and velocity.
Approach	In our experiment, we model the initial kinematic priors pr init with Gaussian mixture models.
Approach	The second term pr f orcef ield represents the force field priors described in Equation (4).
Approach	The third term pr physics measures how well the generated motion satisfies the physical constraints.
Approach	In order to evaluate the third term pr physics , we first use backward difference to compute joint velocities and use central difference to compute joint accelerations.
Approach	Based on the dynamics equation defined in Equation (1), the joint pose, joint velocities and generalized forces in the current step should completely determine the joint accelerations in the current step.
Approach	Therefore, the joint pose and velocity in the next frame are also fully determined due to finite difference approximation.
Background	In practice, as noted by other researchers [Sok et al. 2007; Muico et al. 2009], dynamics models adopted in physics-based modeling are often inconsistent with observed data because of simplified dynamics/contact models, discretization of physics constraints, and approximate modeling of physical quantities of human bodies such as masses and inertias.
Background	Accordingly, dynamics equations are often not satisfied precisely.
Approach	In our formulation, we assume Newtonian dynamics equations are disturbed by Gaussian noise of a standard deviation of σ physics : pr physics ∝ pr(q t |q t , q  ̇ t , u t ) ∝ exp − M ( q t ) q  ̈ t +C( q t , q  ̇ 2σ t )+h( 2 q t )−τ t − f c ( q t ,λ t )− f e 2 physics (7) where the standard deviation σ physics shows our confidence of physics-based dynamics models.
Approach	If the standard deviation is small, then the Gaussian probability distribution has a narrow peak, indicating high confidence in the physical constraints; similarly, a large standard deviation indicates low confidence.
Approach	Such a motion model would allow us to generate an infinite number of physically realistic motion instances.
Approach	In particular, we can sample the initial prior distribution pr init to obtain an initial state for joint poses and velocities and sequentially predict joint torques using the force field priors pr f orcef ield to advance the Newtonian dynamics model pr physics over time.
Approach	More importantly, we can employ the motion model pr(x) to generate physically realistic animation x that best matches the user’s input c.
Approach	Similar to [Chai and Hodgins 2007], the system allows the user to specify various forms of kinematic constraints throughout the motion or at isolated points in the motion.
Approach	Typically, the user can define a sparse set of key frames as well as contact constraints to generate a desired animation.
Approach	The user could also specify a small number of key trajectories to control fine details of a particular human action such as stylized walking.
Approach	The second term E prior is the prior distribution function defined by our physically valid statistical model in Equation (5).
Approach	The motion synthesis problem can now be solved by nonlinear optimization methods.
Approach	Given a sparse set of constraints c, the optimization computes joint poses, joint torques, and contact forces by minimizing the following objective function:
Approach	In our experiment, we set the weights for E c , E init , E f orcef ield and E physics to 1000, 1, 1 and 100, respectively 1 .
Approach	We choose a very large weight for the constraint term because we want to ensure the generated motion can match user constraints accurately.
Approach	The weight for the physical term is much larger than the statistical prior term because physical correctness has a higher priority than statistical consistency in our system.
Approach	Thus far, we have not discussed how to incorporate the learned force field priors into the motion optimization framework.
Approach	Note that in the force field modeling step, we performed dimensionality reduction analysis on both kinematic data and generalized joint torques and learned the force field priors in reduced subspaces.
Approach	One possible solution to incorporating the force field priors is to perform the optimization in the reduced subspaces.
Approach	We have implemented this idea and found that performing the optimization in the subspaces can hurt the generalization ability of our model and often cannot match user-specified constraints accurately.
Approach	To avoid this issue, we choose to perform the optimization in the original configuration space while imposing “soft” subspace constraints on both kinematic states and generalized forces.
Approach	Let B u and B s denote the subspace matrices for generalized forces u and kinematic states s = [q T , q  ̇ T ] T , respectively.
Approach	The second and third terms impose the “soft” subspace constraints for kinematic states and generalized forces, penalizing them as they deviate from the subspace representations.
Approach	In our experiment, we set the weights α 1 and α 2 to 10 and 10, respectively.
Approach	The combined motion models are desirable for human motion generation because they measure both statistical consistency and physical correctness of the motion.
Approach	With the physical term, our model can react to changes in physical parameters.
Approach	For example, when a character is pushed by an external force, e.g., elastic forces in resistance running, the external force in the physics term E physics (see Equation 7) will force the system to modify kinematic motion and joint torques as well as contact forces in order to satisfy Newtonian dynamics and contact mechanics.
Approach	However, without force field priors, the modified motion could be unnatural because there are many ways to adjust a motion so that physical laws are satisfied, and yet only a subset of motions are natural-looking.
Approach	With force field priors, our system pushes the modified motions towards regions of high probability density in order to be consistent with force field priors.
Approach	We used three different motion databases in our experiments, including walking (5227 frames), stylized walking (7840 frames), and locomotion databases (4571 frames).
Approach	We preprocessed the prerecorded motion data using spacetime optimization (Section 5.1).
Approach	The computational time for each data set was reported in Table 2 .
Approach	To speed up the learning and evaluation process of GP models, we applied PCA to reduce the dimensionality of training data and learned the GP model in a reduced subspace.
Approach	We automatically determined the dimension of the subspace by preserving 95% of the original energy.
Approach	The dimensions of the kinematic states ([q t , q  ̇ t ]) in three databases were 19, 22, and 19 respectively.
Approach	The dimensions of the generalized forces (u) were 8, 10, and 7 respectively.
Approach	We adopted sparse approximation strategies for Gaussian process modeling [Quinonero-Candela and Rasmussen 2005].
Approach	The GP learning times spent on the three training databases were 65 minutes, 138 minutes, and 55 minutes, respectively.
Approach	We follow a standard approach of representing q t and τ t using cubic B-splines.
Approach	We solved the optimization problem using sequential quadratic programming (SQP) [Bazaraa et al. 1993], where each iteration solves a quadratic programming subproblem.
Approach	We implemented the system with C++/Matlab and conducted the optimization with the Matlab optimization toolbox.
Approach	Each optimization often took from ten to thirty minutes to converge without code optimization (for details, see Table 1 ).
Approach	All the experiments were run on a 2.5GHz dual core computer with 3GB of RAM.
Outcome	The performance of our optimization algorithm highly depends on the initialization of the optimization.
Approach	We evaluated the force field term with respect to joint poses because we can calculate current generalized forces using current joint poses, velocities and accelerations as shown in Equation (3).
Approach	In this step, we evaluated the force field priors in terms of joint torques and contact forces: E f orcef ield (τ, λ) = − ln pr(τ + f c (q 0 , λ) + f e )|q 0 , q  ̇ 0 ).
Outcome	Each initialization step often took from less than thirty seconds to converge (for details, see Table 1 ).
Outcome	This section demonstrated the benefits of combining physical constraints and statistical motion priors for human motion generation.
Approach	In addition, we evaluated the performance of our algorithm by comparing with ground truth data and results obtained by alternative methods.
Approach	For each example in our experiments, we reported the total number of animation frames, the types and number of animation constraints, and the computational times spend on the initialization and motion synthesis step.
Outcome	The incorporation of physics into probabilistic motion models significantly improves the generalizability of statistical motion models.
Outcome	This experiment shows that the system can generate physically realistic motion that reacts to changes in physical quantities of human bodies and interaction environments, a capability that has not been demonstrated in previous statistical motion models.
Outcome	Our system can react to changes in physical quantities such as masses and inertias of human bodies.
Approach	For example, we changed the mass of the character by simulating a character wearing a 2.5 kilogram shoe.
Outcome	The accompanying video shows that the simulated character maintained balance by adapting the gait and leaning the body to the right side in order to offset the additional weigh caused by the left shoe.
Approach	In this example, the user specified the start and end poses as well as foot contacts to create an animation for resistance running ( Figure 1(b) ).
Approach	The resistance forces were determined by Hooke’s law of elasticity, ranging from zero to 450N.
Outcome	We observed that the character moved the upper body forward in order to offset the effect of resistance force.
Outcome	We can generate an animation that reacts to changes in friction properties of environments.
Approach	We can edit an animation by changing the gravity of interaction environments.
Outcome	For example, we generated “moon” walking by setting gravity at 1.62 m/s 2 .
Outcome	This experiment shows that we can extend physics-based modeling techniques to stylized walking, detailed walking variations, and heterogeneous human actions with the help of statistical motion priors.
Outcome	Such actions are often difficult or even impossible to generate with previous physics-based modeling techniques.
Outcome	Our approach can generate physically-realistic animation for highly stylized human actions.
Approach	The training data sets for stylized walking included normal walking and ten distinct walking styles.
Approach	The system constructed a single motion model from the training data sets and used it to generate various forms of stylized walking such as “sneaky” walking and “proud” walking (Figure 1(c)).
Approach	In addition to keyframes and foot contact constraints, the user specified a sparse number of key trajectories in order to control the fine details of stylized walking.
Approach	We tested the effectiveness of our algorithm for modeling a wide range of walking variations.
Approach	We learned a single generative model from a “walking” database and used it to generate a long walking sequence.
Outcome	The synthesized motion displayed a wide variety of walking variations such as walking along a straight line, walking with a sharp turn, walking with a big step, walking on a slope, climbing over an obstacle, and transitionings between different walking examples ( Figure 5 ).
Approach	Because of memory restrictions, we synthesized the whole motion sequence by sequentially computing each example from sparse constraints and stitching them into a long motion sequence.
Approach	For each example, the user specified the start and end poses of the generated motion as well as foot contact constraints throughout the whole motion sequence.
Approach	We tested the effectiveness of the physically valid statistical model on heterogeneous human actions.
Approach	We learned a single generative model from a locomotion database and used it to create a long animation sequence consisting of walking, running, jumping, and stopping, as well as their transitions (Figure 1(d)).
Approach	We assessed the quality of the generated motions by comparing with ground truth data.
Approach	We also evaluated the importance of force field priors and physical constraints for human motion generation.
Approach	We evaluated the performance of our algorithm via cross validation techniques.
Approach	More specifically, we pulled out a testing sequence in the training data, used it to extract the start and end poses and foot contact constraints, and applied the synthesis algorithm to generate motion that matches the “simulated” constraints.
Outcome	We have observed that the generated motions achieve similar quality to the ground truth motion data.
Outcome	This comparison shows the importance of force field priors for human motion generation.
Approach	We compared our system with standard physics-based optimization techniques [Witkin and Kass 1988] by dropping off both force field priors term E f orcef ield and initialization term E init in the objective function defined in Equation (10).
Approach	For a fair comparison, we added the minimal sum of squared joint torques into the objective function because optimizing the motion with the remaining terms (E c and E physics ) is ambiguous–there are an infinite number of physically correct motions that satisfy user constraints.
Approach	We also included joint torque limits into the optimization.
Outcome	With the force field priors, our system can successfully generate physically realistic stylized walking motion.
Outcome	This experiment demonstrated the importance of physical constraints to our motion model.
Approach	We dropped off the physics term in the objective function and used the remaining terms to optimize the joint poses across the entire motion sequence.
Outcome	With the physics term, the character reacted appropriately to external elastic forces by leaning the body forward to compensate for the resistance forces ( Figure 6(a) ).
Outcome	As expected, the character did not respond to external forces without the physics term ( Figure 6(b) ).
Approach	We computed the eigen-poses using the same set of training data and performed physics-based optimization in a reduced eigen-space similar to Safonova and her colleagues [2004].
Approach	The testing example was running→walking→jumping.
Approach	Unlike Safonova and her colleagues [2004], we did not manually select training data to construct a reduced subspace for human poses.
Approach	Instead, we used the entire locomotion database (4571 frames), which includes normal walking, running and jumping.
Approach	We automatically determined the dimension of the subspace (11 dimensions) by preserving 95% of energy of the training data.
Approach	To implement the subspace optimization algorithm, we formulated the problem in the spacetime framework and optimized the motion in the reduced subspace.
Approach	Briefly, we minimized the sum of squared torques and smoothness of the root and joint angle trajectories over time.
Approach	We also added a regularization term to penalize the deviation of eigen coefficients from zero.
Approach	Unlike Safonova and her colleagues [2004], we did not incorporate inverse kinematics as part of optimization in our implementation.
Approach	We evaluated the performance of the subspace optimization technique using the same set of animation constraints, including the start and end poses as well as trajectories of the head and two feet.
Outcome	For example, the walking character did not swing the right arm properly and the walking gait appeared very stiff.
Outcome	This indicates that a global subspace model for kinematic poses is not sufficient to model heterogeneous human actions.
Outcome	We have also observed that the motions generated by subspace methods often cannot accurately match the trajectory and contact constraints specified by the user; this might be due to compression errors caused by reduced subspace representation.
Outcome	In contrast, the GP-based statistical motion priors can accurately model spatial-temporal patterns in heterogeneous human actions and allow for generating physically realistic animation that matches userdefined constraints.
Outcome	We introduce a statistical motion model for human motion analysis and generation.
Outcome	Our model combines the powers of physics-based motion modeling and statistical motion modeling.
Outcome	We have demonstrated the effectiveness of the new model by generating a wide variety of physically realistic motions that achieve the goals specified by the users.
Outcome	The incorporation of physical constraints into statistical motion models ensures generalized motions are physically plausible, thereby removing noticeable visual artifacts (e.g., unbalanced motions and motion jerkiness) in an output animation.
Outcome	Moreover, it enables us to create motions that react to changes in physical parameters.
Outcome	In our experiments, we have shown that the system can generate new motions such as “resistance running”, “moon walking”, “walking on slippery surfaces”, and “walking with a heavy foot”, a capability that has never been demonstrated in any previous statistical motion synthesis methods.
Outcome	Meanwhile, the use of force field priors for human motion modeling not only ensures that generated motions are natural looking but also extends physically-based modeling techniques to stylized and heterogeneous human actions.
Outcome	For example, we have constructed a single generative model for modeling a wide variety of physically realistic walking variations such as normal walking, walking with a sharp turn, walking on a slope, walking with a big step, and climbing over an obstacle.
Outcome	We have also shown that the system can generate physically realistic motion for stylized walking such as sneaky walking and for heterogeneous human actions such as running→walking→jumping.
Outcome	Such actions are often difficult or even impossible to be synthesized by previous physics-based motion models.
Approach	We model the force field priors using Gaussian process models because GP can efficiently capture nonlinear properties of the force fields and its learning process involves very few manual tuning parameters.
Approach	However, Gaussian process needs to retain all of the training data to make predictions and therefore its computational demands grow as the square and cube respectively of the number of training examples.
Outcome	The sparse approximation strategy works well for the current size of training data sets (less than 8,000 frames) but might not scale up for use in very large data sets.
FutureWork	One possibility is to learn a probabilistic regression function for force fields using parametric statistical analysis techniques such as the mixture of experts model [Jacobs et al. 1991] or its variants [Jordan 1994].
Outcome	Another limitation of our system is that it cannot generate a motion that is very different from motion examples because our approach is data-driven.
Outcome	In addition, the system is still unable to handle arbitrary external forces because the force field priors prevent the generated motion from moving away from prerecorded motion data.
Approach	We choose to model the force field priors based on generalized forces rather than joint torques because we can conveniently compute the generalized forces from current kinematic motion capture databases (e.g., the CMU online mocap database 2 ).
Outcome	However, the learned force field priors can only predict resultant forces of join torques and contact forces.
Outcome	If both joint torque data and contact force data are available, we could construct more accurate force field priors that explicitly predict joint torques or contact forces.
FutureWork	In the future, we plan to measure ground-reaction forces with force plates and use them along with the captured kinematic motion data to compute joint torques via inverse dynamics techniques.
Approach	We formulate the constraint-based motion synthesis problem in a spacetime optimization framework.
Outcome	However, the optimization problem is high-dimensional and highly nonlinear; it might be subject to local minima.
Outcome	We found that the initialization process is critical to the success of our optimization.
Outcome	It not only speeds up the optimization process but also alleviates the local-minimum problem.
Approach	For a long sequence of animation (e.g., Figure 5 ), we need to decompose the entire optimization into a number of spacetime windows, over which subproblems can be formulated and solved using efficient nonlinear optimization techniques.
FutureWork	In the future, we plan to explore alternative techniques to address the local minimum problem.
FutureWork	One possibility is the employment of a Markov chain Monte Carlo (MCMC), which comes to its solutions by efficiently drawing samples from the posterior distribution, using a Markov chain based on the Metropolis-Hastings algorithm.
Approach	Similar to other constraint-based animation systems, our system requires the user to specify a sparse number of constraints, e.g., key frames and contact constraints, to generate a desired animation.
Challenge	However, specifying such constraints, particularly trajectory constraints and contact constraints, is not trivial for a novice user.
Approach	In our experiment, we created the 3D key frames by using our homegrown data-driven inverse kinematic system [Wei and Chai 2010a].
Approach	Trajectory and contact constraints were either directly modified from reference motion data or rotoscoped from video streams similar to the technique described by Wei and Chai [2010b].
FutureWork	In the future, we are interested in extending our system to searching the positions and timings of contact events as part of the optimization variables, thereby avoiding the necessity of contact constraints required for constraint-based motion synthesis.
Background	Gaussian processes (GP) are a powerful, non-parametric tool for regression in high-dimensional space.
Approach	A GP can be thought of as a “Gaussian over functions”.
Approach	For our application, we have y = [q, q]  ̇ and z = u.
Approach	The goal of Gaussian processes is to learn a regression function f (·) that finds the predictive output z ∗ using a testing input y ∗ .
Approach	We assume both training and testing data points are drawn from the following noisy process:
Approach	The kernel function, k(y, y ), is a measure of the “closeness” between inputs.
Approach	The term σ n 2 I introduces Gaussian noise and plays a similar role to that of in Equation (12).
Approach	Given a set of test inputs Y ∗ , one would like to find the predictive output z ∗ .
Approach	(16) A Gaussian process is fully described by its mean and covariance functions.
Approach	These equations show that the mean function for the testing output is a linear combination of the training output z, and the weight of each input is directly related to the correlation between the testing input Y ∗ and the training input Y .
Approach	Meanwhile, the uncertainty for every predictive output (i.e. covariance function) is also estimated.
Approach	In this paper, we choose the squared exponential function as our kernel function:
Approach	The diagonal matrix W contains the length scales for each input dimension.
Approach	The value of W ii is inversely proportional to the importance of the i-th input dimension.
Approach	The parameters of the kernel function θ = [W, σ f , σ n ] can be automatically learned by maximizing the log likelihood of the training outputs given the inputs: θ max = arg max θ log pr(z|Y, θ).

Outcome	We propose a layered framework for incorporating example-based skinning algorithms such as Pose Space Deformation or Shape-by-Example into an existing character animation system.
Challenge	The challenge in implementing example-based skinning in an existing system lies in the fact that it is generally believed that the interpolation of the examples is best performed before doing other skinning deformations (although there has been no analysis as to why this is the case), whereas the examples are specified by the user after the other deformations are performed.
Challenge	It is therefore necessary to invert the operation of these skinning and deformation operators.
Background	Existing systems typically allow layering of both basic skinning methods such as Skeleton Subspace Deformation (SSD) and other deformations such as lattices, etc., and commercial systems may further allow additional proprietary deformation algorithms as part of the character skinning.
Challenge	Unfortunately, understanding and accessing their various parameters can be laborious at best, and we do not have access to the algorithms in the case of commercial packages.
Background	With the help of modelling tools or capture devices, complicated 3D character models are widely used in fields of entertainment, virtual reality, medicine etc.
Background	The range of breathtaking realistic 3D models is only limited by the creativity of artists and resolution of devices.
Background	Driving 3D models in a natural and believable manner is not trivial, especially when the model is very detailed and playback of animation becomes quite heavy and time consuming.
Challenge	Each time when a frame goes wrong, a production cannot afford major revisions such as resculpting models or re-rigging skeletons.
Challenge	Therefore, providing a flexible and efficient solution to animation remains an open problem.
Background	Articulated character animation is a process of deforming the skin surface by manipulating influencing objects such as skeletons, IK, wire frames and Nurbs curves etc.
Background	Skeleton Subspace Deformation (SSD) is the predominant approach to character skinning at present.
Background	A nice review of SSD is given in [ 1 ].
Background	SSD is widely used in games, virtual reality and other realtime applications due to its ease of implementation and low cost of computing.
Background	It provides the relation between characters and their underlying skeletons.
Background	Normally this relation is defined in the rest pose, and determines how characters move according to their skeletons thereafter.
Background	Sometimes, artists will edit the geometry of characters in the rest pose to fine-tune animations.
Background	This approach is not commonly applied, however, since editing in the rest pose will influence most other poses.
Background	On the other hand SSD is also notorious for artifacts at rotating elbows and extreme poses.
Background	For those applications that require visual fidelity, such as movies, SSD serves only as a basic framework, on which lots of more complicated deformation approaches are built as a compensation.
Background	Example based skinning methods such as Pose Space Deformation (PSD) are candidates for correcting SSD limitations.
Background	Example geometric models paired with underlying skeletons in different poses are provided by artists with carefully sculpting and posing.
Background	PSD smoothly interpolates these meshes in pose space and produces visually attractive animations.
Challenge	However, although PSD may be used as a compensation to the underlying SSD, and the animator specifies the PSD examples after the SSD has been performed, it is generally believed that the examples are best interpolated in the rest pose, before the SSD has been applied.
Challenge	Therefore the action of the SSD and any other deformations must be “inverted” in order to push the example compensation before these operations.
Challenge	Besides SSD, other skinning approaches such as rigid skinning, Free Form Deformation etc. can also be applied.
Challenge	Our goal is to incorporate examplebased skinning into a system having a variety of other skinning and deformation operations, and to be able to invert these operations regardless of their nature.
Approach	Since SSD is the most representative in the family of basic skinning, we will discuss how it performs in the inverse operation of PSD scheme.
Outcome	For a simplified condition where only one joint rotation and two example poses are considered, we demonstrate this inverse strategy has a better performance than the same framework without it.
Background	Besides the geometric solutions mentioned in the previous section, physical modelling and animation is another field providing realistic character simulations.
Background	Given physical principles, this category can generate more believable animation effects compared to its geometric counterpart.
Background	But they are seldom applied to interactive applications because of the high cost of computing and complicated algorithms.
Challenge	This paper is mainly dedicated to geometric solutions.
Background	Pose Space Deformation [ 1 ] combines shape blending and Skeleton Subspace Deformation by formulating a scattered data interpolation problem over sculpted (or otherwise obtained) example poses.
Background	Character geometries in problematic poses will be re-sculpted by animators and then resulting displacement (referred as delta values in this paper) from the original geometries will be stored as “scattered data” for interpolation phase.
Background	The interpolation is performed in the pose space which consists of skeleton joints, or other potentially abstract controllers.
Background	Their values such as rotation degrees can be chosen as coordinates of the abstract pose space.
Background	After a model is posed and resculpted in different example poses, a multidimensional linear system is built by implementing an interpolation scheme using Radial Basis Functions (RBF), and the output of this system is the weights of each example pose.
Background	The final animation can be synthesized by linearly blending RBF functions with the solved weights.
Background	Related research efforts have improved the speed and power of example-based skinning.
Background	[ 2 ] incorporate linear elements into RBF to produce constant changes between examples.
Background	[ 3 ] precompute principal components of the deformation influences for individual kinematic joints instead of storing displacements for key poses, thereby enabling realtime rendering large nonlinear finite element models of human hands.
Background	[ 4 ] introduce weighted pose space deformation for deforming realistic models of human hand.
Background	The latest work [ 5 ] identifies statistically relevant bones and approximates bone transforms from example mesh animations.
Background	Using established terminology from statistical modeling, these example-based approaches can be considered as non-parametric skin deformation methods.
Background	The data needed for these methods grows with the number of examples, but arbitrary deformations can be approximated as a result.
Background	Simpler parametric skinning approaches (of which SSD is the prototype) have a fixed number of parameters; these have also seen some development in recent years [ 6 ], [ 7 ].
Background	Skinning using free form lattices [ 8 ], [ 9 ] or NURBS curves [ 10 ] instead of skeletons to drive character surface are also common practices in the entertainment production.
Approach	Our framework implements existing PSD theory and the distinction is that we insert an optimization module into the PSD pipeline by applying a unified inverse approach assuming the knowledge of basic skinning is unavailable.
Outcome	We provide detailed reasons why and how the inverse operation can improve the results.
Outcome	For a simplified case, we show that the direction of deformed vertices from inverse skinning is a linear function of joint rotation, while in the forward approach, that direction is kept as a constant.
Outcome	This demonstration provides for the first time a clear theoretical reason why inverse operation is required.
Outcome	We formulate editing geometry in rest pose as an optimization problem and propose a unified framework which can be implemented on high-end commercial packages while allowing any proprietary skinning operators to be incorporated.
Background	Skeleton Subspace Deformation (SSD) is a basic algorithm that is used to define how the character surface deforms following movements of its underlying skeletons.
Background	The main idea is introduced by [ 11 ], and is also known as soft skinning, linear blending or Single Weight Enveloping (SWE).
Background	Due to its simplicity and efficiency, SSD is widely applied to interactive applications such as games and virtual reality, and it is implemented in most commercial animation packages.
Background	A skeleton should be rigged to a character surface beforehand, roughly based on the anatomy of the character and kinetic rules.
Background	The pose in which the skeleton is rigged normally is referred to as the rest pose.
Background	The basic relationship between surfaces and skeletons is defined at the rest pose, and all motions of the character will be influenced thereafter.
Approach	If SSD is adopted to define this relation, each vertex or control point of the character surface is provided with a list of joints, that will influence it, along with the weight indicating the amount of influence.
Approach	When the character is animated, the position of a vertex in the animated pose is the result of weighted linear blending of its transformation by each associated joint.
Approach	For a vertex in rest pose v , its transformed position in pose p is v p .
Background	T pk means the kth joint’s transformation from rest pose to pose p. Readers can find details on how to compute T pk in [ 1 ].
Approach	ω k is the corresponding weight.
Approach	This weight is usually a function of distance between v r and its associated joints, and is defined when we apply SSD to the rigged character.
Approach	Rectangles represent animated sections in each of two frames and the curve shows the blended result of both frames.
Background	Since vertex transformations can be easily implemented in the graphic card, SSD is very popular in circumstances that require animating a number of characters in real time.
Approach	Some opportunities for control are provided to the animators.
Approach	When a character goes wrong in some pose, animators can adjust joint influence weights.
Approach	But the domain of adjusting one vertex in this way is strictly limited to the linear subspace formed by the vertex as transformed by joints influencing this vertex.
Background	The famous SSD problem of “collapsed elbow” is recognized in [ 1 ] as being due to the fact that deforming is limited to a linear subspace.
Background	Because of this limitation SSD cannot synthesize many parts of a character skin involving complicated joint structures.
Background	Built on the SSD scheme, the Pose Space Deformation (PSD) is proposed by [ 1 ] as a combination of SSD and shape blending providing nice solution to above mentioned problems.
Approach	In our proposed framework, this step will be replaced by an optimization routine.
Approach	We add this delta to the original character surface and then let SSD or any other skinning scheme finish the final transformation.
Approach	For a vertex v, if sculpted in N example poses, then there are N delta d i , i = 0, . . . , N − 1 corresponding to each pose x i , i = 0, . . . , N − 1.
Approach	These are converted to rest pose displacements using d i r = SSD −1 (d i ).
Approach	We adopt Gaussian Radial Basis functions to interpolate d i r .
Approach	First a N ∗ N matrix Φ is built with the (i, j)th element as φ ( x i − x j ), where x i − x j means the Euclidean distance between pose x i and pose x j , then we have a linear system:
Approach	Here W and D r are column vectors with ith element ω i and d i r respectively.
Approach	In the synthesis phase, for an intermediate pose x, we can obtain the delta d for this vertex by:
Approach	For the Gaussian function φ (x) = e − σ x 2 2 , σ is used to control the “fall-off”.
Approach	, we use Gaussian Radial Basis functions to interpolate 3 points.
Approach	The blue and green curve represent σ = 1.0 and σ = 2.0 respectively.
Approach	Other basis functions also can be candidates.
Approach	Although PSD and improved example-based schemes have been discussed in many publications [ 2 ], [ 3 ], [ 4 ], the reason why the inverse should be performed is still ambiguous.
Approach	We still study SSD as the underlying skinning, since an explicit form of basic skinning can help to simplify our task of explanation.
Approach	We call the PSD scheme without the inverse operation as “forward PSD”, and comparison to it will be used to demonstrate the superiority of the inverse method.
Approach	For N examples, a vertex v is first transformed from rest pose by SSD to positions v i , i = 0, . . . , N − 1, then animators move it to example positions to obtain delta values d i , i = 0, . . . , N − 1.
Approach	The final positions of v in example poses are v i + d i , i = 0, . . . , N − 1, and we call them target positions vt i .
Approach	The “forward PSD” approach then concludes by interpolating d i as a function of pose.
Approach	In the inverse approach we instead apply the inverse of SSD i (∗) to v i t to obtain a modified rest pose vertex v r i .
Approach	The difference of vr i and vr produces new delta value d i r , which will be the input of linear system (equation 2) introduced in the previous section.
Approach	In this step we need implement the inverse skinning operator SSD −1 .
Approach	Since SSD is a 3D transformation, SSD −1 simply is the inverse transformation matrix generated by SSD.
Approach	For the situation where other unknown skinning operations are adopted, we propose a unified framework which will be discussed in the following section.
Approach	Next we build a new delta vector Dr with ith element as d i r , and replace D in equation 2 with d i r to get a new weight vector W r .
Approach	v x represents the final position of vertex v in pose x.
Approach	Given two examples as shown in Figure 2 (a) and (b) respectively, vertex v with the position v r in the rest pose ( 0 degrees ) is sculpted to a “target position” v ti in an example pose (90 degrees).
Approach	The delta value in the first pose is zero.
Approach	Then we apply forward and inverse PSD respectively to interpolate these two poses.
Approach	For an intermediate pose x, we have two distinct deforming vertices resulting from two algorithms, as illustrated in Figure 3 , v ssd x , v x p , v x I p are the deformed positions from SSD, forward and inverse PSD in an intermediate pose x.
Approach	We use two angles α p and α I p to analyze how directions of a deformed vertex change with the pose.
Approach	In the forward case, α p is formed by the vector (v ssd x , v x p ) and the line y = Y v ssd x , where Y v x ssd is the y coordinate of v x ssd .
Approach	For two examples shown in Figure 2 (a) and (b), we have delta values d 1 = [d 1x , d 1y ] and d 2 = [d 2x , d 2y ].
Approach	Taking the model in rest pose as an example is a common practice when applying shape interpolation, since interpolating effects from other examples should not change the original model in rest pose.
Approach	Therefore, by solving above equation we have: ω 1x = φ 11 −1 d 1x + φ 12 −1 d 2x = φ 12 −1 d 2x ω 2x = φ 21 −1 d 1x + φ 22 −1 d 2x = φ 22 −1 d 2x = d 2x ω 1y = φ 11 −1 d 1y + φ 12 −1 d 2y = φ 12 −1 d 2y ω 2y = φ 21 −1 d 1y + φ 22 −1 d 2y = φ 22 −1 d 2y = d 2y where φ i −1 j is the (i, j)th element of Φ −1 , and if i = j, φ i −1 j = 1.
Approach	Then in an intermediate pose x for α p , we have tan α p = d d x y .
Approach	d y and d x are delta values in x, y coordinates computed from equation 3.
Approach	Then we take a look at α I p in the inverse case.
Approach	We transform two examples to rest pose to obtain delta values: d 1 r = [d 1x , d 1y ] = [0, 0] and d r 2 = [d 2x , d 2y ].
Approach	Then for the vertex v r = [v 0x , v 0y ], SSD θ (v r ) transforms v from rest pose to [v SSD x , v SSD y ] = [v 0x cos θ − v 0y sin θ , v 0x sin θ + v 0y cos θ ].
Approach	In an intermediate pose x, we have its corresponding rest position as v r x = [v 0x + d x , v 0y + d y ], and here the [d x , d y ] are interpolated result computing from equation 3.
Approach	We just apply the simplified SSD to v x r to obtain v I x p : v Inp x = (v 0x + d x ) cos θ − (v 0y + d y ) sin θ and v Inp y = (v 0x + d x ) sin θ + (v 0y + d y ) cos θ .
Approach	Similarly, we compute the tangent of α I p : tan α I p = − v v Inp Inp x y − − v v SSD SSD x y = − d x sin θ + d y cos θ = − tan( β + θ ) d x cos θ − d y sin θ where tan β = d y = d 2y .
Approach	Then we can see α I p = d x d 2x −( θ + β ), which is linearly proportional to the pose rotation θ .
Approach	And now we take a look at a real cylinder model with one vertex sculpted in the second pose, shown in the Figure 4 .
Approach	Forward PSD and the corresponding inverse PSD in the same poses (30, 45 and 60 degree of one rotated joint ) are illustrated respectively in Figure 5 .
Outcome	We can see that in forward case, the direction of deformed vertex always keeps the same with the example cylinder ( figure 4 ).
Outcome	For inverse PSD however, that direction is changed along with the rotation of the joint.
Outcome	The case described above is quite common in practice when animating shoulder, elbow, knee, hip-bone, neck, etc.
Outcome	All these parts would rotate from the rest pose with some angle to other poses.
Approach	On the other hand, as a matter of experience, PSD is supposed to be a method as “local” correction, which means pose space should not be extended to a whole space that has to incorporate all influenced objects.
Approach	Otherwise, large amount of unnecessary works of building examples will be required, and the distance between different poses is also meaningless.
Approach	For example how to measure the distance between differing poses such as “lying down” and “pitching”?
Approach	The above discussions assume that the basic skinning algorithm is SSD, but in many circumstances, other deformation schemes will be adopted [ 9 ], [ 10 ], most of which have been implemented in most animation packages.
Challenge	Therefore we propose a unified framework in which no explicit inverse operation is necessitated.
Approach	Given a basic skinning method supported by animation packages we can deform the original character model from rest pose to another specific pose.
Approach	To find delta d i in the rest pose: v i = SKINNING i (v r ) + d i = SKINNING i (v r + d i ) we can setup a minimization problem to minimize the function:
Approach	This function can be given to Powell’s method to find d i at the minimum of f (d ).
Approach	For each example pose P i , we have a d i , then we can apply radial basis function to d i (i = 0 . . . n − 1) in pose space to obtain ω i (i = 0 . . . n − 1).
Approach	In synthesis phase, a d x in an intermediate pose x can be computed by equation 3 based on its position x in pose space d x = ∑ n−1 i=0 ω i φ (||x − x i ||).
Approach	Then we have the final synthesis result:
Background	For a minimization problem, there are many candidate algorithms according to the form of function, knowledge of the derivative, computing capacity, and requirements for the rate of convergence, etc.
Challenge	In our situation, the function form is not explicit, and the computing burden increases with the number of example poses increases.
Approach	We will adopt Powell’s method as the solution to this minimization problem.
Background	One advantage of Powell’s classic method is that it does not need explicit computation of the function’s gradient [ 12 ].
Approach	Because we are treating the skinning operations as a “black box”, their gradient is not available, so Powell’s method is suitable.
Approach	Minimizing the function f (d ) in a particular direction is actually minimization problem of one variable, which is also called line minimization.
Background	Powell’s idea is trying to find each minimum of function f (d ) in different direction until f (d ) stops decreasing.
Background	How to choose the next direction is the main concern of Powell’s method, and it has been proved that after repeated cycles of M line minimizations on conjugate directions, the optimization will in due course converge to the minimum [ 12 ].
Approach	M is the dimensionality of the function f ().
Approach	We implement this unified approach as a Maya plug-in.
Background	In Maya, “tweaking” is a procedure adding delta values to original surface vertices before any deformations.
Background	It is actu- ally Maya’s form of rest-pose editing for their built-in deformation operators.
Approach	As presented in Figure 6 , the whole system is divided into two phases.
Approach	The first phase is to find each delta in the rest pose corresponding to each example pose.
Approach	Basic skinning provided by Maya is called in the loop of minimization scheme.
Approach	The output of the first phase, the delta in the rest pose, is input to into the second phase that is a linear system performing RBF interpolation to obtain the PSD weights.
Approach	In the synthesis process, for an intermediate pose x, a delta d x ( or d x r ) is synthesized by equation 7.
Approach	The final deformed vertex is computed by Maya skinning as in equation 10.
Approach	If the SSD transformation in equation 1 is singular, some types of inverse PSD deformation will not be possible, because any component of the desired deformation that lies in the null space of the SSD matrix will be ignored.
Approach	Although singular cases are rare (one example is a joint with 180 o rotation and equal 2 1 , 2 1 weights on the two joint frames, which is an unrealistic case of selfintersection), it is possible to handle these cases with a small rearrangement of the inverse PSD approach.
Approach	We reformulate the problem as f (y i ) = v i + w i − SKINNING i (v r + d i ) 2 + λ w i 2 where y i is a concatenated vector y i = [d i , w i ] and λ is an arbitrary small number.
Approach	The final synthesis is then v x = SKINNING(v r + d x ) + w x where w x is interpolated after SKINNING by applying the same RBF scheme as used for d x (thus, only minimal code changed are required).
Approach	The idea here is that, since w i is being minimized, it will be generally be zero, and will be non-zero only if it is not possible to obtain the desired deformation v i using SKINNING i (v r + d i ).
Approach	In the case where the SSD transform is nearsingular, the solved d i can be much large than other d k , which can result in poorly posed interpolation.
Approach	To address this case, we further modify the objective function as        f (y i ) = v i +w i −SKINNING i (v r +d i ) 2 + λ w i 2 + μ d i 2 where 0.0001 is a sufficient value for both λ and μ .
Outcome	Inverse skinning integrates SSD and shape interpolation more firmly than its forward rival.
Outcome	We demonstrate the direction of deformed vertex in inverse skinning is linearly proportional to joint rotations in a simplified example, while the forward PSD does not incorporate the direction information.
Outcome	Therefore the inverse approach presents better performance and more consistent interpolation ( Figure 7 to Figure 10 ).
Outcome	By formulating the inverse process as a minimization problem we propose a unified model not only for SSD but also for other skinning schemes, into which shape interpolation can be incorporated.
Outcome	But the minimizing process will introduce more cost.
Outcome	This cost depends on the size of deformed character, parameters of minimization methods (Powell) such as convergence precision, and the number of example poses.
Outcome	In addition the cost of the animation software must be considered (for example, the Maya API implements a run-time type interpretation system on all operations).
Outcome	The cost of the inverse operation is not critical, however, since it is a one time “setup” cost, and the compute time is insignificant compared to the human time required to sculpt the desired deformations.
Outcome	Once the linear system is solved, the synthesis is potentially realtime since no extra computing is involved in this process compared to the forward PSD.
Outcome	We implement this unified example-based approach as a Maya plugin.
Outcome	It interoperates with their closed-source “Smooth Skinning” deformation.

Challenge	The bottle-neck in most cloth simulation systems is that time steps must be small to avoid numerical instability.
Outcome	This paper describes a cloth simulation system that can stably take large time steps.
Approach	The simulation system couples a new technique for enforcing constraints on individual cloth particles with an implicit integration method.
Approach	The simulator models cloth as a triangular mesh, with internal cloth forces derived using a simple continuum formulation that supports modeling operations such as local anisotropic stretch or compression; a unified treatment of damping forces is included as well.
Approach	The implicit integration method generates a large, unbanded sparse linear system at each time step which is solved using a modified conjugate gradient method that simultaneously enforces particles’ constraints.
Approach	The constraints are always maintained exactly, independent of the number of conjugate gradient iterations, which is typically small.
Outcome	The resulting simulation system is significantly faster than previous accounts of cloth simulation systems in the literature.
Challenge	Physically-based cloth animation has been a problem of interest to the graphics community for more than a decade.
Background	Early work by Terzopoulos et al. [ 17 ] and Terzopoulos and Fleischer [ 15 , 16 ] on deformable models correctly characterized cloth simulation as a problem in deformable surfaces, and applied techniques from the mechanical engineering and finite element communities to the problem.
Background	Since then, other research groups (notably Carignan et al. [ 4 ] and Volino et al. [ 20 , 21 ]; Breen et al. [ 3 ]; and Eberhardt et al. [ 5 ]) have taken up the challenge of cloth.
Background	Although specific details vary (underlying representations, numerical solution methods, collision detection and constraint methods, etc.), there is a deep commonality amongst all the approaches: physically-based cloth simulation is formulated as a time-varying partial differential equation which, after discretization, is numerically solved as an ordinary differential equation
Outcome	In this paper, we describe a cloth simulation system that is much faster than previously reported simulation systems.
Approach	Our system’s faster performance begins with the choice of an implicit numerical integration method to solve equation (1).
Background	The reader should note that the use of implicit integration methods in cloth simulation is far from novel: initial work by Terzopoulos et al. [ 15 , 16 , 17 ] applied such methods to the problem.
Background	1 Since this time though, research on cloth simulation has generally relied on explicit numerical integration (such as Euler’s method or Runge-Kutta methods) to advance the simulation, or, in the case of of energy minimization, analogous methods such as steepest-descent [ 3 , 10 ].
Background	This is unfortunate.
Challenge	Cloth strongly resists stretching motions while being comparatively permissive in allowing bending or shearing motions.
Challenge	This results in a “stiff” underlying differential equation of motion [ 12 ].
Challenge	Explicit methods are ill-suited to solving stiff equations because they require many small steps to stably advance the simulation forward in time.
Challenge	2 In practice, the computational cost of an explicit method greatly limits the realizable resolution of the cloth.
Background	For some applications, the required spatial resolution—that is, the dimension n of the state vector x—can be quite low: a resolution of only a few hundred particles (or nodal points, depending on your formulation/terminology) can be sufficient when it comes to modeling flags or tablecloths.
Challenge	To animate clothing, which is our main concern, requires much higher spatial resolution to adequately represent realistic (or even semi-realistic) wrinkling and folding configurations.
Outcome	In this paper, we demonstrate that implicit methods for cloth overcome the performance limits inherent in explicit simulation methods.
Outcome	We describe a simulation system that uses a triangular mesh for cloth surfaces, eliminating topological restrictions of rectangular meshes, and a simple but versatile formulation of the internal cloth energy forces.
Approach	(Unlike previous metric-tensor-based formulations [ 15 , 16 , 17 , 4 ] which model some deformation energies as quartic functions of positions, we model deformation energies only as quadratic functions with suitably large scaling.
Outcome	Quadratic energy models mesh well with implicit integration’s numerical properties.
Outcome	) We also introduce a simple, unified treatment of damping forces, a subject which has been largely ignored thus far.
Approach	A key step in our simulation process is the solution of an O(n) × O(n) sparse linear system, which arises from the implicit integration method.
Background	An ADI method generates a series of tightly banded (and thus quickly solved) linear systems rather than one large sparse system.
Background	(The price, however, is that some of the forces in the system—notably between diagonally-adjacent and non-adjacent nodes involved in self-collisions—are treated explicitly, not implicitly.
Outcome	) The speed (and ease) with which our sparse linear systems can be robustly solved—even for systems involving 25,000 variables or more—has convinced us that there is no benefit to be gained from using an ADI method instead (even if ADI methods could be applied to irregular triangular meshes).
Approach	Thus, regardless of simulation size, we treat all forces as part of the implicit formulation.
Outcome	Even for extremely stiff systems, numerical stability has not been an issue for our simulator.
Approach	Much of the performance of our system stems from the development of an implicit integration formulation that handles contact and geometric constraints in a direct fashion.
Approach	) Our formulation for directly imposing and maintaining constraints is harmonious with the use of an extremely fast iterative solution algorithm—a modified version of the conjugate gradient (CG) method—to solve the O(n) × O(n) linear system generated by the implicit integrator.
Approach	Iterative methods do not in general solve linear systems exactly—they are run until the solution error drops below some tolerance threshold.
Approach	A property of our approach, however, is that the constraints are maintained exactly, regardless of the number of iterations taken by the linear solver.
Approach	Additionally, we introduce a simple method, tailored to cloth simulation, for dynamically adapting the size of time steps over the course of a simulation.
Approach	The combination of implicit integration and direct constraint satisfaction is very powerful, because this approach almost always allows us to take large steps forward.
Outcome	In general, most of our simulations require on average from two to three time steps per frame of 30 Hz animation, even for (relatively) fast moving cloth.
Outcome	The large step sizes complement the fact that the CG solver requires relatively few iterations to converge.
Outcome	For example, in simulating a 6, 000 node system, the solver takes only 50–100 iterations to solve the 18, 000 × 18, 000 linear system formed at each step.
Approach	Additionally, the running time of our simulator is remarkably insensitive to the cloth’s material properties (quite the opposite behavior of explicit methods).
Outcome	All of the above advantages translate directly into a fast running time.
Outcome	For example, we demonstrate results similar to those in Breen et al. [ 3 ] and Eberhardt et al. [ 5 ] (draping of a 2,600 node cloth) with a running time just over 2 seconds per frame on an SGI Octane R10000 195 Mhz processor.
Outcome	Similarly, we show garments (shirts, pants, skirts) exhibiting complex wrinkling and folding behavior on both key-framed and motion-captured characters.
Outcome	Representative running times include a long skirt with 4,530 nodes (8,844 triangles) on a dancing character at a cost of 10 seconds per frame, and a shirt with 6,450 nodes (12,654 triangles) with a cost varying between 8 to 14 seconds per frame, depending on the underlying character’s motion.
Background	Terzopoulos et al. [ 15 , 17 ] discretized cloth as a rectangular mesh.
Background	Energy functions were derived using a continuum formulation.
Background	This work recognized the need for damping forces; however, only a simple viscous drag force −k x was used.
Background	The linear systems result- ing from the use of implicit integration techniques were solved, for small systems, by direct methods such as Choleski factorization, or using iterative techniques such as Gauss-Seidel relaxation or conjugate gradients.
Background	(For a square √ system of n nodes, the resulting linear system has bandwidth n.
Background	In this case, banded Choleski factorization [ 6 ] requires time O(n 2 ).
Background	) As previously discussed, Terzopoulos et al. made use of an ADI method for larger cloth simulations.
Background	Carignan et al. recognized the need for damping functions which do not penalize rigidbody motions of the cloth (as simple viscous damping does) and they added a force which damps cloth stretch and shear (but not bend).
Background	Later work by the same group includes Volino et al. [ 20 ], which focuses mainly on collision detection/response and uses a triangular mesh; no mention is made of damping forces.
Background	The system uses the midpoint method (an explicit method) to advance the simulation.
Background	Thus far, the accumulated work by this group (see Volino et al. [ 21 ] for an overview) gives the only published results we know of for simulated garments on moving characters.
Background	Reported resolutions of the garments are approximately two thousand triangles per garment (roughly 1,000 nodal points) [ 21 ] with running times of several minutes per frame for each garment on an SGI R4400 150 Mhz processor.
Background	Breen et al. [ 3 ] depart completely from continuum formulations of the energy function, and describe what they call a “particlebased” approach to the problem.
Background	By making use of real-world cloth material properties (the Kawabata measuring system) they produced highly realistic static images of draped rectangular cloth meshes with reported resolutions of up to 51 × 51 nodes.
Background	The focus of this work is on static poses for cloth, as opposed to animation: thus, their simulation process is best described as energy minimization, although methods analogous to explicit methods are used.
Background	Speed was of secondary concern in this work.
Background	Refinements by Eberhardt et al. [ 5 ]—notably, the use of higher-order explicit integration methods and Maple-optimized code, as well as a dynamic, not static treatment of the problem—obtain similarly realistic results, while dropping the computational cost to approximately 20–30 minutes per frame on an SGI R8000 processor.
Background	No mention is made of damping terms.
Background	Provot [ 13 ] focuses on improving the performance of explicit methods by a post-step modification of nodal positions.
Background	He iteratively adjusts nodal positions to eliminate unwanted stretch; the convergence properties of this method are unclear.
Background	A more comprehensive discussion on cloth research can be found in the survey paper by Ng and Grimsdale [ 9 ].
Approach	Our simulator models cloth as a triangular mesh of particles.
Approach	Given a mesh of n particles, the position in world-space of the ith particle is x i ∈ IR 3 .
Approach	The geometric state of all the particles is simply x ∈ IR 3n .
Approach	The same component notation applies to forces: a force f ∈ IR 3n acting on the cloth exerts a force f i on the ith particle.
Approach	Real-world cloth is cut from flat sheets of material and tends to resist deformations away from this initial flat state (creases and pleats not withstanding).
Approach	We capture the rest state of cloth by assigning each particle an unchanging coordinate (u i , v i ) in the plane.
Approach	Collisions between cloth and solid objects are handled by preventing cloth particles from interpenetrating solid objects.
Approach	Our current implementation models solid objects as triangularly faced polyhedra.
Approach	Each face has an associated thickness and an orientation; particles found to be sufficiently near a face, and on the wrong side, are deemed to have collided with that face, and become subject to a contact constraint.
Approach	(If relative velocities are extremely high, this simple test may miss some collisions.
Approach	In this case, analytically checking for intersection between previous and current positions can guarantee that no collisions are missed.
Approach	) For cloth/cloth collisions, we detect both face-vertex collisions between cloth particles and triangles, as well as edge/edge collisions between portions of the cloth.
Approach	As in the case of solids, close proximity or actual intersection of cloth with itself initiates contact handling.
Background	The most critical forces in the system are the internal cloth forces which impart much of the cloth’s characteristic behavior.
Background	Breen et al. [ 3 ] describes the use of the Kawabata system of measurement for realistic determination of the in-plane shearing and out-of-plane bending forces in cloth.
Approach	We call these two forces the shear and bend forces.
Approach	We formulate the shear force on a per triangle basis, while the bend force is formulated on a per edge basis—between pairs of adjacent triangles.
Approach	The strongest internal force—which we call the stretch force— resists in-plane stretching or compression, and is also formulated per triangle.
Background	Under normal conditions, cloth does not stretch appreciably under its own weight.
Approach	This requires the stretch force to have a high coefficient of stiffness, and in fact, it is the stretch force that is most responsible for the stiffness of equation (1).
Background	A common practice in explicitly integrated cloth systems is to improve running time by decreasing the strength of the stretch force; however, this leads to “rubbery” or “bouncy” cloth.
Approach	Our system uses a very stiff stretch force to combat this problem, without any detrimental effects on the run-time performance.
Approach	While the shear and bend force stiffness coefficients depend on the material being simulated, the stretch coefficient is essentially the same (large) value for all simulations.
Approach	(Of course, if stretchy cloth is specifically called for, the stretch coefficient can be made smaller.
Approach	) Complementing the above three internal forces are three damping forces.
Approach	The damping forces do not dissipate energy due to other modes of motion.
Approach	Additional forces include air-drag, gravity, and user-generated generated mouse-forces (for interactive simulations).
Approach	Cloth/cloth contacts generate strong repulsive linear-spring forces between cloth particles.
Approach	Combining all forces into a net force vector f, the acceleration ẍ i of the ith particle is simply ẍ i = f i /m i , where m i is the ith particle’s mass.
Approach	(A triangle’s mass is the product of the cloth’s density and the triangle’s fixed area in the uv coordinate system.
Approach	The use of an implicit integration method, described in the next section, generates large unbanded sparse linear systems.
Approach	We solve these systems through a modified conjugate gradient (CG) iterative method, described in section 5.
Approach	CG methods exploit sparsity quite easily, since they are based solely on matrix-vector multiplies, and require only rudimentary sparse storage techniques.
Approach	The sparsity of the matrix generated by the implicit integrator is best represented in block-fashion: for a system with n particles, we deal with an n × n matrix, whose non-zero entries are represented as dense 3 × 3 matrices of scalars.
Approach	The matrix is represented as an array of n rows; each row is a linked list of the non-zero elements of that row, to accommodate possible run-time changes in the sparsity pattern, due to cloth/cloth contact.
Approach	The (dense) vectors that are multiplied against this matrix are stored simply as n element arrays of threecomponent vectors.
Approach	The overall implementation of sparsity is completely straightforward.
Approach	An individual particle’s position and velocity can be completely controlled in either one, two, or three dimensions.
Approach	Particles can thus be attached to a fixed or moving point in space, or constrained to a fixed or moving surface or curve.
Approach	Constraints are either user-defined (the time period that a constraint is active is user-controlled) or automatically generated, in the case of contact constraints between cloth and solids.
Approach	During cloth/solid contacts, the particle may be attached to the surface, depending on the magnitudes of the frictional forces required; otherwise, the particle is constrained to remain on the surface, with sliding allowed.
Approach	The constraint techniques we use on individual particles work just as well for collections of particles; thus, we could handle cloth/cloth intersections using the technique described in section 5, but the cost is potentially large.
Approach	For that reason, we have chosen to deal with cloth/cloth contacts using penalty forces: whenever a particle is near a cloth triangle or is detected to have passed through a cloth triangle, we add a stiff spring with damping to pull the particle back to the correct side of the triangle.
Approach	The implicit solver easily tolerates these stiff forces.
Approach	Given the known position x(t 0 ) and velocity x(t 0 ) of the system at time t 0 , our goal is to determine a new position x(t 0 + h) and velocity x(t 0 + h) at time t 0 + h.
Approach	To compute the new state and velocity using an implicit technique, we must first transform equation (2) into a first-order differential equation.
Approach	To simplify notation, we will define x 0 = x(t 0 ) and v 0 = v(t 0 ).
Approach	We also define x = x(t 0 + h) − x(t 0 ) and v = v(t 0 + h) − v(t 0 ).
Approach	As previously discussed, the step size h must be quite small to ensure stability when using this method.
Approach	The difference in the two methods is that the forward method’s step is based solely on conditions at time t 0 while the backward method’s step is written in terms of conditions at the terminus of the step itself.
Approach	4 The forward method requires only an evaluation of the function f but the backward method requires that we solve for values of x and v that satisfy equation (4).
Approach	Equation (4) is a nonlinear equation: rather than solve this equation exactly (which would require iteration) we apply a Taylor series expansion to f and make the firstorder approximation ∂f ∂f f(x 0 + x, v 0 + v) = f 0 + ∂x x + ∂v v.
Approach	In this equation, the derivative ∂f/∂x is evaluated for the state (x 0 , v 0 ) and similarly for ∂f/∂v.
Approach	Substituting this approximation into equation (4) yields the linear system
Approach	Taking the bottom row of equation (5) and substituting x = h(v 0 + v) yields v = hM −1 f 0 + ∂x ∂f h(v 0 + v) + ∂v ∂f v .
Approach	Given v, we trivially compute x = h(v 0 + v).
Approach	Thus, the backward Euler step consists of evaluating f 0 , ∂f/∂x and ∂f/∂v; forming the system in equation (6); solving the system for v; and then updating x and v.
Approach	We use the sparse data structures described in section 2.3 to store the linear system.
Background	Cloth’s material behavior is customarily described in terms of a scalar potential energy function E(x); the force f arising from this energy is f = −∂E/∂x.
Approach	Equation (6) requires both the vector f and the matrix ∂f/∂x.
Approach	Expressing the energy E as a single monolithic function—encompassing all aspects of the cloth’s internal behavior—and then taking derivatives is impractical, from a bookkeeping point of view.
Approach	A better approach is decompose E into a sum of sparse energy functions; that is, to write E(x) = α E α (x) where each E α depends on as few elements of x—as few particles—as possible.
Approach	However, even decomposing E into sparse energy functions is not enough.
Approach	Energy functions are an undesirable starting point because sensible damping functions cannot be derived from energy functions.
Approach	Instead, we define internal behavior by formulating a vector condition C(x) which we want to be zero, and then defining the associated energy as k C(x) T C(x) where k is a stiffness constant.
Approach	An added bonus is that starting from this vector-based energy description tends to result in a simpler, more compact, and more easily coded formulation for ∂f/∂x than proceeding from an energy function in which the structure of C has been lost.
Approach	Given a condition C(x) which we want to be zero, we associate an energy function E C with C by writing E C (x) = k 2 C(x) T C(x) where k is a stiffness constant of our choice.
Approach	Assuming that C depends on only a few particle, C gives rise to a sparse force vector f.
Approach	Recall from section 2.1 that we view the vector f in block form; each element f i is a vector in IR 3 .
Approach	Similarly, the derivative of f is also sparse.
Approach	Defining the derivative matrix K = ∂f/∂x, the nonzero entries of K are K ij for all pairs of particles i and j that C depends on.
Approach	Again, we treat K in block fashion: K ∈ IR 3n×3n , so an element K ij is a 3 × 3 matrix.
Approach	Additionally, since K ij is a second derivative—that is, K ij = ∂f i /∂x j = ∂ 2 E/∂x i ∂x j —we have K ij = K T ji so K is symmetric.
Approach	Note that since C does not depend on v, the matrix ∂f/∂v is zero.
Approach	We can now easily describe the internal forces acting on the cloth, by just writing condition functions.
Approach	Forces and their derivatives are easily derived using equations (7) and (8).
Approach	Recall that every cloth particle has a changing position x i in world space, and a fixed plane coordinate (u i , v i ).
Approach	Even though our cloth is modeled as a discrete set of points, grouped into triangles, it will be convenient to pretend momentarily that we have a single continuous function w(u, v) that maps from plane coordinates to world space.
Approach	Stretch can be measured at any point in the cloth surface by examining the derivatives w u = ∂w/∂u and w v = ∂w/∂v at that point.
Approach	The magnitude of w u describes the stretch or compression in the u direction; the material is unstretched wherever w u = 1.
Approach	Stretch in the v direction is measured by w v .
Background	(Some previous continuum formulations have modeled stretch energy along an axis as essentially (w u T w u − 1) 2 , which is a quartic function of position [ 15 , 16 , 17 , 4 ].
Approach	We find this to be needlessly stiff; worse, near the rest state, the force gradient—a quadratic function of position—is quite small, which partially negates the advantage implicit integration has in exploiting knowledge of the force gradient.
Approach	A quadratic model for energy is, numerically, a better choice.
Approach	) We apply this stretch/compression measure to a triangle as follows.
Approach	Let us consider a triangle whose vertices are particles i, j and k.
Approach	Define x 1 = x j − x i and x 2 = x k − x i .
Approach	Also, let u 1 = u j − u i , while u 2 = u k − u i and similarly for v 1 and v 2 .
Approach	We approximate w(u, v) as a linear function over each triangle; this is equivalent to saying that w u and w v are constant over each triangle.
Approach	This lets us write x 1 = w u u 1 + w v v 1 and x 2 = w u u 2 + w v v 2 .
Approach	Note that x 1 and x 2 vary during the simulation but the matrix in the above equation does not.
Approach	We can treat w u and w v as functions of x, realizing that they depend only on x i , x j and x k and using equation (9) to obtain derivatives.
Approach	Usually, we set b u = b v = 1, though we need not always do so.
Approach	In particular, if we want to slightly lengthen a garment (for example, a sleeve) in the u direction, we can increase b u , which causes w u to seek a larger value, and tends to induce wrinkles across the u direction.
Approach	Likewise, we might decrease b v near the end of a sleeve, inducing a tight cuff, as on a sweatshirt.
Approach	We have found the ability to control shrink/stretch anisotropically to be an indispensable modeling tool.
Approach	Cloth likewise resists shearing in the plane.
Approach	We can measure the extent to which cloth has sheared in a triangle by considering the inner product w u T w v .
Approach	In its rest state, this product is zero.
Approach	Since the stretch term prevents the magnitudes of w u and w v from changing overly much, we need not normalize.
Approach	By the small angle approximation, the product w u T w v is a reasonable approximation to the shear angle.
Approach	The condition for shearing is simply C(x) = aw u (x) T w v (x) with a the triangle’s area in the uv plane.
Approach	We measure bend between pairs of adjacent triangles.
Approach	The condition we write for the bend energy depends upon the four particles defining the two adjoining triangles.
Approach	If we let n 1 and n 2 denote the unit normals of the two triangles and let e be a unit vector parallel to the common edge, the angle θ between the two faces is defined by the relations sin θ = (n 1 × n 2 ) · e and cos θ = n 1 · n 2 .
Approach	We define a condition for bending by writing simply C(x) = θ which results in a force that counters bending.
Approach	This makes differentiating θ with respect to x a manageable task.
Approach	Rectangular meshes make it simple to treat bending anisotropically.
Approach	The uv coordinates associated with particles make this possible for triangular meshes as well.
Approach	Given material for which bending in the u and v directions are weighted by stiffnesses k u and k v , we can emulate this anisotropy as follows.
Approach	Let the edge between the triangles be between particles i and j, and define u = u i − u j and v = v i − v j .
Approach	The stiffness weighting for this edge should simply be k u ( u) 2 + k v ( v) 2 .
Approach	To the above forces we also add easily implemented forces such as gravity and air-drag (which is formulated on a per-triangle basis, and opposes velocities along the triangle’s normal direction).
Approach	When the simulation is fast enough to interact with, we add user-controlled “mouse” forces.
Approach	These forces and their gradients are easily derived.
Approach	The energies we have just described are functions of position only.
Approach	Robust dynamic cloth simulation, however, is critically dependent on well-chosen damping forces that are a function of both position and velocity.
Approach	For example, the strong stretch force must be accompanied by a suitably strong damping force if we are to prevent anomalous in-plane oscillations from arising between connected particles.
Approach	However, this strong damping force must confine itself solely to damping in-plane stretching/compressing motions: stretch damping should not arise due to motions that are not causing stretch or compression.
Background	Terzopoulos et al.’s [ 16 , 17 ] treatment of cloth used a simple viscous damping function which dissipated kinetic energy, independent of the type of motion.
Background	Carignan et al. [ 4 ] improved upon this somewhat, borrowing a formulation due to Platt and Barr [ 11 ]; however, their damping function—a linear function of velocity—does not match the quartic energy functions of their continuum formulation.
Approach	At an equilibrium point of E, the gradient ∂E/∂x vanishes.
Approach	Since E  ̇ = (∂E/∂x) T x, we find that E  ̇ is zero when E is at its minimum, regardless of the system’s velocity x = v.
Approach	In general, E  ̇ is always too small near the system’s rest state.
Approach	Clearly, basing the damping force on E  ̇ is not what we want to do.
Approach	We believe that the damping function should be defined not in terms of the energy E, but in terms of the condition C(x) we have been using to define energies.
Approach	The force f arising from the energy acts only in the direction ∂C(x)/∂x, and so should the damping force.
Approach	Additionally, the damping force should depend on the component of the system’s velocity in the ∂C(x)/∂x direction; in other words, the damping strength should depend on (∂C(x)/∂x) T x = C(x).
Approach	As before, d i is nonzero only for those particles that C depends on, and ∂d/∂x has the same sparsity pattern as ∂f/∂x.
Approach	Note that ∂d/∂x is not a second derivative of some function as was the case in equation (8) so we cannot expect ∂d/∂x to be symmetrical.
Approach	In equation (12), it is the term (∂C(x)/∂x i )(∂ C(x)/∂x  ̇ j ) T which breaks the symmetry.
Approach	Anticipating section 5.2, we find it expedient simply to leave this term out, thereby restoring symmetry.
Approach	This simplification is clearly not physically justifiable, but we have not observed any ill effects from this omission.
Approach	(Omitting all of equation (12), however, causes serious problems.
Approach	) Finally, equation (6) requires the derivative ∂d/∂v.
Approach	In this case, the result is symmetrical without dropping any terms.
Approach	The constraints we discuss in this section are either automatically determined by the user (such as geometric attachment constraints on a particle) or are contact constraints (generated by the system) between a solid object and a particle.
Outcome	The techniques we describe in this section could be used for multi-particle constraints; however, constraints that share particle would need to be merged.
Approach	Thus, a set of four-particle constraints (such as vertex/triangle or edge/edge contacts in the cloth) might merge to form a single constraint on arbitrarily many particles, which would be expensive to maintain.
Approach	Because of this, we handle cloth/cloth contacts with strong springs (easily dealt with, given the simulator’s underlying implicit integration base) and “position alteration,” a technique described in section 6.
Approach	At any given step of the simulation, a cloth particle is either completely unconstrained (though subject to forces), or the particle may be constrained in either one, two or three dimensions.
Approach	Given the differential nature of our formulation, it is the particle’s acceleration, or equivalently, the change in the particle’s velocity, that is constrained.
Approach	If the particle is constrained in all three dimensions, then we are explicitly setting the particle’s velocity (at the next step).
Approach	If the constraint is in two or one dimensions, we are constraining the particle’s velocity along either two or one mutually orthogonal axes.
Approach	An obvious and quite exact method for constraining a particle is to reduce the number of coordinates describing the particle’s position and velocity.
Approach	A completely constrained particle would have no coordinates, while a particle with one dimension of constraint would have two coordinates.
Approach	This is possible—but it complicates the system immensely.
Approach	If we change the number of coordinates per particle, we alter the size of the derivative matrices in equation (6), as well as the sparsity pattern (this happens when a particle changes from having no coordinates to some coordinates, or vice versa).
Approach	Given the transient nature of contact constraints between cloth and solids, this is most unappealing.
Approach	The computation of the derivative matrices’ entries is also greatly complicated, because we must now introduce extra Jacobian matrices that relate a particle’s reduced coordinates to its motion in world-space.
Approach	Finally, correct constraint-release behavior between cloth and solid objects is difficult to achieve using a reduced coordinate formulation.
Approach	Considering all of this, we immediately rejected this method of constraints.
Approach	We could constrain particles through the use of strong energy functions—essentially, stiff springs that attempt to prevent illegal particle motions.
Approach	Since our entire formulation is geared to handle stiffness, the usual objections to enforcing constraints with springs—very stiff equations—do not carry as much weight.
Approach	We tried this for a time, and found it to be a not unreasonable constraint enforcement mechanism.
Approach	However, penalty methods do not enforce constraints exactly, and they do add some additional stiffness to the system.
Approach	Since the mechanism we describe enforces constraints exactly, and adds no extra stiffness, we turned away from penalty methods except in the case of cloth/cloth interactions.
Approach	We could introduce additional constraint forces—that is, Lagrange multipliers—into our system to satisfy the constraints.
Approach	This involves augmenting the linear system of equation (6) with extra variables (the multipliers) and extra equations (the constraint conditions).
Approach	Unfortunately, this turns a positive definite system into an indefinite system, which means that iterative methods such as CG will need to square the system first, thereby doubling the running time and degrading the numerical conditionining of the linear system.
Approach	Additionally, an iterative method will generally not enforce the constraints exactly without a large number of iterations.
Approach	(A direct method for solving the augmented system would, however, avoid this problem.
Approach	) Again, the constraint method we describe steps past these difficulties, so we turned away from using Lagrange multipliers.
Approach	The idea behind our constraint enforcement mechanism is described quite simply, although the actual implementation is somewhat more complicated, to maximize performance.
Approach	A dynamic simulation usually requires knowledge of the inverse mass of objects; for example, note the appearance of M −1 , and not M in equation (6).
Approach	In the case of a single particle, we write x  ̈ i = m 1 i f i to describe a particle’s acceleration.
Approach	When inverse mass is used, it becomes trivial to enforce constraints by altering the mass.
Approach	Suppose for example that we want to keep particle i’s velocity from changing.
Approach	If we take 1/m i to be zero, we give the particle an infinite mass, making it ignore all forces exerted on it.
Approach	Complete control over a particle’s acceleration is thus taken care of by storing a value of zero for the particle’s inverse mass.
Approach	What if we wish to constrain the particle’s acceleration in only one or two dimensions?
Approach	Although we normally think of a particle’s mass as a scalar, we need not always do so.
Approach	Suppose we write ẍ i = 1/m 0 i 1/m 0 i 0 0 f i .
Approach	Now ẍ i 0 0 0 must lie in the xy plane; no acceleration in the z direction is possible.
Approach	Note than an unconstrained particle can be considered to have the 3 × 3 inverse mass matrix 1 I, with I the identity matrix.
Approach	More generally, given a unit vector p ∈ IR 3 , a particle is prevented from accelerating along p by using an inverse mass matrix 1 (I − m i pp T ); this follows from the fact that (I − pp T )p = 0.
Approach	Similarly, given two mutually orthogonal unit vectors p and q, we prevent a particle from accelerating in either the p or q direction by using the inverse mass matrix 1 (I − pp T − qq T ).
Approach	We will create a modified version W of M −1 ; W will be a block-diagonal matrix, with off-diagonal blocks being zero, and diagonal blocks defined as follows: let ndof(i) indicate the number of degrees of freedom particle i has, and let particle i’s prohibited directions be p i (if ndof(i) = 2) or p i and q i (if ndof(i) = 1) with p i and q i mutually orthogonal unit vectors.
Approach	We are not limited to constraining particles to have zero accelerations in certain directions; rather, we control exactly what the change in velocity is along the constrained directions.
Approach	For every particle i, let z i be the change in velocity we wish to enforce in the particle’s constrained direction(s).
Approach	(This implies we can choose any value of z i for a completely constrained particle, since all directions are constrained; an unconstrained particle must have z i = 0 since it has no constrained directions.
Approach	) Using W and z, we rewrite equation (6) to directly enforce constraints.
Approach	Completely constrained particles will have v i = z i , while partially constrained particles will have a v i whose component in the constrained direction(s) is equal to z i .
Approach	We initially implemented constraints using equation (14) and found that it worked exactly as advertised.
Approach	For very small test systems, we solved equation (14) using a direct method (Gaussian elimination) without any problems.
Approach	For larger systems, we planned to use the iterative, sparsity-exploiting CG method, which immediately presents us with a problem: equation (14) is not a symmetric linear system.
Approach	(For that matter, neither is equation (6) unless all particles have the same mass.
Background	) CG methods, however, require symmetric matrices.
Approach	6 We could apply a CG method to the unsymmetric matrix of equation (14) by use of the “normal equations”; but this involves multiplying the matrix of equation (14) with its transpose which doubles the cost of each iteration while squaring the condition number of the system [ 14 ]—a less than desirable plan.
Approach	We decided that using a CG method to solve the unsymmetric problem was not acceptable.
Approach	Unfortunately, we cannot apply the same transformation to equation (14), because W is singular—the filtering blocks in equation (13) are rank deficient—so we cannot multiply through by W −1 .
Approach	The solution to the problem of asymmetry is to modify the CG method so that it can operate on equation (15), while procedurally applying the constraints inherent in the matrix W at each iteration.
Approach	The modified method will need to know about the particles’ constraints and the vector z.
Approach	• For each particle i, the component of v i in the particle’s constrained direction(s) will be exactly z i (no matter how many iterations are taken).
Approach	Note that these two conditions imply that unconstrained particles have r i close to zero, while completely constrained particles have v i = z i .
Approach	Thus in the case when no particles are constrained, our modified CG method should produce the same result as the regular CG method.
Approach	The CG method (technically, the preconditioned CG method) takes a symmetric positive semi-definite matrix A, a symmetric positive definite preconditioning matrix P of the same dimension as A, a vector b and iteratively solves A v = b.
Approach	The iteration stops when b − A v is less than b where is a user-defined tolerance value.
Approach	We derive our modified conjugate gradient method by observing that the effect of the matrix W in equation (14) is to filter out velocity changes in the constrained directions.
Approach	Our idea then is to define an invariant— for all i, the component of v i in the constrained direction(s) of particle i is equal to z i —and then establish and maintain the invariant at each iteration, by defining a filtering procedure filter.
Approach	Lines 5 and 15 maintain the invariant by filtering c before adding it to v.
Approach	The unmodified conjugate gradient method establishes a stopping criterion based on b T Pb.
Approach	Since our constrained formulation ignores certain components of b, our stopping criterion should as well, so we add filtering to line 3.
Approach	The vector r measures the solution error b − A v, and should not include error due to the constraints; hence we add filtering at lines 4 and 8.
Approach	(Note that removing the calls to filter and changing line 2 to v = 0 yields the standard preconditioned conjugate gradient method.
Approach	) We use a simple preconditioner P by making P be a diagonal matrix with P ii = 1/A ii so products involving P −1 are trivially computed.
Approach	More elaborate preconditioners could be used, though we doubt there is a large speedup to be gained.
Approach	Matrix-vector products with A are of course implemented in sparse matrix-vector fashion, using the data structures defined in section 2.3.
Outcome	” Proofs about CG methods are difficult in general; in practice, our method always converges, which answers the first question.
Approach	Prior to implementing modified-pcg, we used a penalty method and applied the standard CG method to equation (15).
Approach	When we began using procedure modified-pcg, we did not notice any substantial change in the number of iterations required by the method.
Outcome	Empirically, we conclude that the two methods have similar convergence behavior.
Approach	For contact constraints (between cloth and solid objects) we need to know what the actual force of constraint is, in order to determine when to terminate a constraint.
Approach	Additionally, we need to know the constraint force actually exerted in order to model frictional forces properly.
Approach	Fortunately, it is easy to add one more step to modified-pcg to determine the constraint force.
Approach	When modified-pcg terminates, the residual error e = A v − b has the property that e i need not be close to zero if particle i is constrained.
Approach	In fact, e i is exactly the extra constraint force that must have been supplied to enforce the constraint.
Approach	Thus, we can compute constraint forces at the end of modified-pcg by performing one last matrixvector product to compute A v − b.
Approach	(The vector r in modified-pcg is equal to filter(A v − b), so the extra matrix-vector product to compute e really is necessary.
Approach	) The particles’ accelerations are inherently dependent on one another through the matrix A of equation (16).
Approach	This means that the correct approach to determing constraint release is combinatoric, as in Baraff [ 2 ].
Outcome	In practice, this has proven to work well.
Approach	Friction presents a similar problem.
Approach	When cloth contacts a solid, we lock the particle onto the surface, if the relative tangential velocity is low.
Approach	We monitor the constraint force, and if the tangential force exceeds some fraction of the normal force, we allow the particle to slide on the surface.
Approach	For high sliding velocities, we apply a dissipative tangential force, opposite the relative sliding direction, proportional to the normal force.
Background	Much has been written about collision detection for cloth; we have nothing substantial to add to the subject of collision detection per se.
Background	Cloth/cloth collisions are detected by checking pairs ( p, t) and (e 1 , e 2 ) for intersections, where p and t are a cloth particle and a cloth triangle respectively, and e 1 and e 2 are edges of cloth triangles.
Approach	Given a previous known legal state of the cloth, we postulate a linear motion for the cloth particles to the current (possibly illegal) state and check for either particle/triangle or edge/edge crossings.
Approach	To avoid O(n 2 ) comparisons, we use a coherency-based boundingbox approach [ 1 ] to cull out the majority of pairs.
Approach	When collisions between a cloth vertex and triangle, or two cloth edges are detected, we insert a strong damped spring force to push the cloth apart.
Approach	A dissipative force tangent to the contact is also applied, countering any sliding motion.
Approach	The force is not, strictly speaking, a frictional force: rather it is proportional to the slip velocity, so it is in actuality a damping force, although it reasonably emulates dynamic friction.
Approach	Applying static friction forces to cloth contacts is far more difficult, and is a problem we have not solved yet.
Approach	The forces, and their derivatives with respect to position and velocity, are of course included in equation (15).
Approach	Our system detects collisions between cloth particles and solid objects by testing each individual cloth particle against the faces of each solid object.
Approach	A solid object’s faces are grouped in a hierarchical bounding box tree, with the leaves of the tree being individual faces of the solid.
Approach	The tree is created by a simple recursive splitting along coordinate axes.
Approach	Both cloth/cloth and cloth/solid collisions give rise to the same problem whenever two contacts form.
Approach	For both types of collisions, our detection algorithm reports an intersection, and then takes action to remedy the situation: either by enforcing a constraint (cloth/solid collisions) or by adding a penalty force (cloth/cloth) collisions.
Approach	However, since our simulator proceeds in discrete steps, collisions resulting in a reasonably substantial interpenetration depth can occur between one step and the next.
Approach	Clearly, this situation needs to be remedied.
Approach	For cloth/cloth collisions, this would not appear to be a problem: the spring forces that are added work to counter the colliding velocities and then push the cloth apart.
Approach	For cloth/solid collisions, however, the situation is more complicated.
Approach	If we simply enforce a constraint which causes the colliding cloth particle to have a velocity consistent with the solid object’s velocity, and continue to enforce that constraint, the cloth particle will continue to remain embedded somewhere below the solid object’s surface.
Approach	This is unacceptable.
Approach	One solution is to use Baumgarte stabilization [ 18 ], which schedules the particle’s acceleration so that the position and velocity error of the particle with respect to the surface decay asymptotically to zero.
Approach	We experimented with this technique, but found it lacking.
Approach	In particular, a fast rise to the surface was prone to noise and “jumpiness”; this could be eliminated, but at the cost of decreasing the step size.
Approach	A slower rise to the surface caused visual artifacts.
Approach	We tried a simpler solution: when intersections occurred, rather than wait for a scheduled constraint or a penalty force to eliminate the intersection, we simply altered the positions of the cloth particles, effecting an instantaneous (and discontinuous) change in position.
Approach	While this would be problematic when using a multi-step differential equation solver which expects continuity (such as a RungeKutta method), it should not interfere with a one-step solver such as the backward Euler method.
Approach	Unfortunately, simply changing particle positions produced disastrous results.
Approach	The stretch energy term in a cloth system is extremely strong, and altering particle positions arbitrarily introduced excessively large deformation energies in an altered particle’s neighborhood.
Approach	This resulted in visibly “jumpy” behavior of the cloth in localized regions.
Approach	Despite its initial failure, the ability to make arbitrary small changes in a particle’s position continued to attract our attention.
Approach	The entire process of implicit integration can be considered to be a filtering process [ 7 ], and we postulated that a mechanism for filtering energy changes caused by displacing particles might make position alteration a viable technique.
Approach	We considered that perhaps some sort of extra implicit step could be used as a filter, but forming and solving an additional linear system at each step seemed too expensive.
Approach	Happily, we can make use of the filtering effect of implicit integration without any extra work.
Approach	Consider a particle that has collided with a solid object.
Approach	The particle’s change in velocity at each step is under our control, using the constraint techniques described in section 5.
Approach	Meanwhile, the particle’s position at the next step follows from equation (4): x i = h(v 0i + v i ) (recall that v 0i is the particle’s current velocity).
Approach	The reason that changing positions after a step has been taken doesn’t work is because the particle’s neighbors receive no advance notification of the change in position: they are confronted with the alteration at the beginning of the next step.
Approach	Having modified the top row of equation (4), we must follow this change through: using equation (17) and repeating the derivation of section 3 and the symmetric transform from section 5 yields the modified symmetric system
Approach	This modification gives us complete control over both the position and velocity of a constrained particle in just one step, without any extra computational cost.
Approach	We use this technique to bring particles quickly and stably to the surface of solid objects without creating visual artifacts or limiting the allowable step size.
Approach	We can also add correction terms to particles involved in cloth/cloth collisions.
Approach	Without a constraint on those particles’ velocities there is no guarantee that they will go exactly where we want in one step, but the ability to induce sizeable jumps in position without excessively stiff spring forces adds greatly to the stability of the simulation.
Outcome	The methods introduced in all of the previous sections usually allow us to take sizeable steps forward, without loss of stability.
Approach	Even so, there are still times when the step size must be reduced to avoid divergence.
Background	There are a large number of methods for altering the size of a time step, for both explicit and implicit integrators, but these methods tend to concentrate on the accuracy of the simulation, and not the stability.
Challenge	Our goal is animation, not engineering; thus visually pleasing results, meaning a numerically stable solution, rather than overall accuracy, is the deciding voice.
Approach	The trick is to recognize instability before you see it on your screen—by then it’s too late.
Approach	Stiffness, and thus any potential instability, arises almost completely from the strong stretch forces in the cloth.
Approach	After each implicit step, we treat the resulting x as a proposed change in the cloth’s state, and examine the stretch terms (section 4.2) for each triangle in the newly proposed state.
Approach	If any triangle undergoes a drastic change in its stretch (in either the u or v direction) we discard the proposed state, reduce the step size, and try again.
Approach	Subtlety is not required: we find that an unstable step invariably results in stretch changes that are quite large, and are thus easily detected.
Approach	Our simulation is run with a parameter that indicates the maximum allowable step size: this parameter is set by the user, and is always less than or equal to one frame.
Approach	(Most of our simulations involving human motions use a step size of 0.02 seconds.
Approach	) Whenever the simulator reduces the step size, after two successes with the reduced step size the simulator tries to increase the step size.
Approach	If the simulator fails at the larger step size, it reduces the size again, and waits for a longer period of time before retrying to increase the step size.
Approach	At its limit, the simulator will try increasing the step size every 40 steps; thus, if the user chooses too large a step, the simulator settles down to wasting only one out of every 40 steps in attempting too large a step.
Outcome	This method, though simple, has served us well.
Outcome	Unaccounted overhead of the simulation (typically about 5%) includes tasks such as geometry transformations, memory allocation, etc.
Approach	The clothes in figures 3–6 were modeled as discrete planar panels, and then topologically seamed.
Approach	The simulator was used to relax the clothing from an initial deformed state, that got the clothes around the characters, to a well-fitting state on the characters.
Approach	The b u and b v parameters (see equation (10)) were then made smaller in certain regions to produce cuffs and waistbands, or strategically increased to induce wrinkling behavior in other regions.
Approach	We also ran the simulation in figure 1 with a range of stiffnesses for the bend term.
Approach	Using the stiffness parameters in figure 1 as a reference, we ran the simulation with those bend stiffnesses multiplied by 0.1, 1.0, 10, 100 and 1,000 (for a total range of 10,000 in the stiffness).
Outcome	The variance in the running times was under 5%.
Outcome	We doubt that simulators based on explicit integration methods could make a similar claim.
Approach	Finally, we tried to estimate our simulator’s performance as a function of n, the number of cloth particles.
Approach	We ran the simulation in figure 1 with cloth resolutions of 500, 899, 2,602 (shown in figure 1 ) and 7,359 particles.
Outcome	The running times were, respectively, 0.23 seconds/frame, 0.46 seconds/frame, 2.23 seconds/frame, and 10.3 seconds/frame.
Outcome	This is slightly better than O(n 1.5 ) performance, which is in line with the convergence rates of the conjugate gradient method [ 14 ] for systems such as equation (18).

Approach	We capture the shape of moving cloth using a custom set of color markers printed on the surface of the cloth.
Outcome	The output is a sequence of triangle meshes with static connectivity and with detail at the scale of individual markers in both smooth and folded regions.
Approach	We compute markers’ coordinates in space using correspondence across multiple synchronized video cameras.
Approach	Correspondence is determined from color information in small neighborhoods and refined using a novel strain pruning process.
Approach	Final correspondence does not require neighborhood information.
Approach	We use a novel data driven hole-filling technique to fill occluded regions.
Outcome	Our results include several challenging examples: a wrinkled shirt sleeve, a dancing pair of pants, and a rag tossed onto a cup.
Outcome	Finally, we demonstrate that cloth capture is reusable by animating a pair of pants using human motion capture data.
Approach	We capture the motion of cloth using multiple video cameras and specially tailored garments.
Outcome	The resulting surface meshes have an isometric parameterization and maintain static connectivity over time.
Background	Over the course of roughly half a dozen papers on cloth capture a prevailing strategy has emerged.
Challenge	First, a pattern is printed on the cloth surface such that small regions of the pattern are unique.
Challenge	Next, correspondence is determined by matching regions across multiple views.
Challenge	The 3D location of a region is determined by intersecting rays through the corresponding observations in the image set ( figure 4 ).
Challenge	Reconstruction is done independently on a frame by frame basis and the resulting data is smoothed and interpolated.
Background	Previous work, such as [Scholz et al. 2005], yields pleasing results.
Background	Little work has been done to capture garments with folds and scenes with occlusion.
Approach	In this paper we use folding to refer to local phenomena such as wrinkles around a knee and occlusion to refer to large scale effects such as one limb blocking the view of another.
Challenge	Folds and occlusion are common, especially when dealing with real garments such as pants where limbs block interior views and cloth collects around joints.
Challenge	Both phenomena are symptoms of the same problem: views of the surface are blocked by other parts of the surface.
Challenge	However, there is a distinction in scale and different methods are required to solve each problem.
Challenge	When a surface is heavily folded, contiguous visible regions are often small and oddly shaped.
Challenge	In these regions correspondence is essential for detailed reconstruction yet can be challenging to identify.
Approach	We solve the correspondence problem both by improving the pattern printed on the surface of the cloth and by improving the method used to match regions.
Outcome	Our method gets more information per pixel than previous methods by drawing from the full colorspace instead of a small finite set of colors in the printed pattern.
Approach	Additionally, because cloth cannot stretch much before ripping, we use strain constraints to eliminate candidates in an iterative search for correspondence.
Outcome	In combination, these two modifications eliminate the need for neighborhood information in the final iteration of our algorithm.
Outcome	As a result, we determine correspondence using regions that are 25 times smaller than in previous work ( figure 6 ).
Challenge	Many regions on the surface are impossible to observe due to occlusion.
Approach	We fill these holes using reconstructions of the same surface region taken from other points in time.
Approach	We found that MeshIK ([Sumner et al. 2005]), a tool originally developed for mesh posing and animation, is appropriate for filling holes in cloth.
Approach	In fact, MeshIK is well-suited to cloth data and we use it to bind reconstruction of our pants to motion capture data.
Approach	We suggest two tools to evaluate marker-based capture systems.
Approach	The first, markers per megapixel, is a measure of efficiency in capture systems.
Challenge	Efficiency is important because camera resolution and bandwidth are expensive: the goal is to get more performance from the same level of equipment.
Outcome	This metric is designed to predict scaling as technology moves from the research lab to the professional studio.
Approach	The second tool is information theory: we look at the predictive power of different cues in a capture system.
Approach	By doing simple bit calculations, we direct our design efforts more appropriately.
Background	Previous work in cloth motion capture has focused on placing high density markers in correspondence between multiple views.
Challenge	The primary challenge is to increase marker density while correctly assigning correspondence between markers.
Approach	We suggest markers per megapixel as an appropriate metric for comparison ( figure 3 ) because it measures the method instead of the equipment.
Background	Most high density full frame-rate capture has focused on cloth, however, there has been some recent work enhancing human motion capture [Park and Hodgins 2006].
Background	These methods have far fewer markers per megapixel because they affix individual markers.
Background	When working with cloth, markers are typically painted on the surface.
Background	These markers can be broken into three categories: complex surface gradients [Pritchard and Heidrich 2003; Scholz and Magnor 2004; Hasler et al. 2006] (typically detected using SIFT descriptors [Lowe 2004]), intersecting lines [Tanie et al. 2005] and regions of constant color [Guskov and Zhukov 2002; Guskov et al. 2003; Scholz et al. 2005].
Approach	Our work falls in the third category: regions of contant color.
Approach	We evaluate previous work by examining the quality of the reconstructed cloth in still images and video.
Background	The most common errors are marker mismatches and are observable in reconstructions by local strain in the reconstructed surface.
Approach	Overall, we observe that constant color markers perform the best.
Background	[Pritchard and Heidrich 2003] used cloth with unique line drawings as markers.
Background	Their work identifies parameterization as one of the key aspects of cloth capture.
Background	They use a stereo camera to acquire 3D and SIFT descriptors to establish correspondence.
Background	These descriptors are often mismatched and require significant pruning.
Background	They introduce a rudimentary strain metric, as measured along the surface, to rule out incorrect matches.
Background	While successful, their static reconstructions show numerous correspondence errors.
Background	The real-time system described in [Guskov et al. 2003] introduces markers of constant color, resulting in significantly fewer correspondence errors than in [Pritchard and Heidrich 2003].
Background	This system uses a Kalman smoothing filter and is heavily damped.
Background	Additionally, the complexity of the color pattern limits the method to simple geometry.
Background	[Scholz et al. 2005] improve upon [Guskov et al. 2003] by creating a non-repeating grid of color markers.
Background	Each marker has five possible colors and all three by three groups are unique.
Background	This allows substantially larger sections of cloth and virtually eliminates correspondence errors.
Background	Results include a human wearing a shirt and a skirt captured using eight 1K x 1K cameras.
Background	However, the range of motion is limited to avoid occlusion (e.g., arms are always held at 90 degrees to the torso).
Background	They use thin-plate splines to fill holes.
Background	[White et al. 2005] introduce a combined strain reduction/bundle adjustment that improves the quality of the reconstruction by minimizing strain while reconstructing the 3D location of the points on the surface of the cloth.
Background	[White et al. 2006] introduce the use of silhoutte cues to improve reconstruction of difficult to observe regions.
Outcome	We make three main contributions: we improve the color pattern and matching procedure to get more information per marker, we introduce strain constraints to simplify correspondence and we create a data driven hole filling technique that splices previously captured cloth into the mesh.
Outcome	As a result, our system is capable of capturing a full range of motion with folding and occlusion.
Approach	To acquire a 3D point cloud of the cloth surface, we print a colored pattern on the cloth, sew it together, and record its motion using multiple synchronized cameras.
Approach	We then reconstruct the 3D location of surface points by detecting corresponding points in multiple views ( figure 4 ).
Challenge	Our goal is high marker density in the 3D reconstruction – especially in regions with high curvature.
Approach	To achieve this, we need markers that are both small in scale and highly discriminative.
Approach	These two goals are in tension: small markers are less discriminative.
Approach	In addition, we cannot increase camera resolution without bound because camera bandwidth becomes very expensive.
Approach	As a result, we opt for the smallest markers that we can reliably detect and we make small markers more distinctive.
Approach	We combine information from three cues to establish correspondence: marker color, neighboring markers and strain constraints in the reconstruction.
Approach	Marker color and strain constraints are more useful than neighboring markers because they place fewer requirements on local cloth geometry.
Approach	Specifically, neighboring markers are observed only when the cloth is relatively flat.
Approach	When the surface is heavily curved only small portions of the surface are visible before the cloth curves out of view.
Approach	In subsequent sections we adopt the following strategy: maximize information obtained from marker color and eliminate the information needed from neighbors.
Approach	We optimize our correspondence technique by analyzing the information provided by different cues.
Approach	In this framework we can accurately minimize the number of neighbors required for correspondence and observe folds better.
Approach	We can compare our work to previous methods using this framework ( figure 6 ).
Approach	It takes log 2 M bits to determine the identity of each observed marker on a garment with M total markers.
Approach	Because independent information adds linearly, we can compute the information needed to meet this threshold by adding information from the different cues: color, neighbors and strain.
Approach	However, structural ambiguities in the pattern subtract information lost to determine which neighbor is which.
Approach	This neighbor is one of four possible neighbors – thus it takes two bits to specify which neighbor we found (A = 2).
Approach	However, larger marker regions have the disadvantage that curvature can cause local occlusions and prevent observation of the entire region.
Approach	Our best efforts are to improve C – the number of bits from each marker observation.
Approach	We do this by picking marker color from the full colorspace instead of a small discrete set of colors.
Approach	We print a random colored pattern on the surface of cloth in an attempt to maximize the information available per pixel.
Approach	While our pattern is composed of tesselated triangles ( figure 5 ), any shape that tiles the plane will work (squares and hexagons are also natural choices).
Approach	To maximize the density of reconstructed points, we print the smallest markers that we can reliably detect.
Approach	To maximize the information contained in the color of each marker, we print colors that span the gamut of the printer-camera response, then use a gaussian color model (section 4.1).
Approach	From a system view, the printer-camera response is a sequence of lossy steps: we generate a color image on a computer, send the image to the printer, pose the cloth, and capture it with a camera.
Outcome	Our experiments suggest that loss is largely attributable to camera response because larger markers produced substantially more information.
Challenge	Illumination is also problematic and takes two forms: direct illumination on a lambertian surface and indirect illumination.
Approach	To correct for variations in direct illumination, we remove the luminosity component from our color modelling.
Approach	We do not correct for indirect illumination.
Approach	Each marker in the printed pattern has a randomly chosen color, subject to the constraint that neighboring marker colors must be dissimilar.
Approach	In the recognition stage, we detect markers by comparing colors to a known color.
Approach	These comparisons must be made in the proper color space: we photograph the surface of the printed cloth with our video cameras to minimize the effect of non-linearities in the printing process.
Approach	The goal of our acquisition pipeline is to compute correspondence using minimal neighborhoods.
Approach	We accomplish this through an iterative algorithm where we alternate between computing correspondence and pruning bad matches based on those correspondences.
Approach	After each iteration we shrink the size of the neighborhood used to match.
Approach	We start with N = 3 and end with N = 0.
Approach	In the final iteration, markers are matched using color and strain alone.
Approach	This iterative approach allows us to match without neighborhoods.
Approach	This is better than label propagation methods.
Background	As shown in figure 5 , occluding contours are both common and difficult to detect.
Approach	In contrast, our iterative approach relies on strain constraints – which require computing the distance between a point and a line, and color detection – which requires averaging color within a marker.
Approach	Both of these computations are easier than detecting occluding contours.
Approach	Our gaussian noise model has a single free parameter, the variance, which must be computed empirically for each recording setup.
Approach	This variance determines the color response for the entire setup — smaller variances mean more bits from color.
Approach	At this stage, we compute color information for each marker and eliminate hypothetical correspondences from further consideration that have large color differences.
Approach	The size of the neighborhood is chosen so that we get more than enough bits to meet our information budget (log 2 M bits – typically 11 to 13).
Outcome	Because the identity of the marker is overspecified, there are few mistakes.
Approach	This approach works from flat regions in the first iteration to foldy regions in the later iterations.
Approach	In the first iteration, we require three neighbors to make a match.
Approach	In heavily folded regions, often neighboring markers on the image do not neighbor on the surface of the cloth.
Approach	As such, these regions are not going to match.
Approach	In contrast, in the last iteration, no neighbors are necessary.
Approach	Occluding contours, which are common in heavily folded regions, no longer disrupt the matching procedure.
Approach	We use reprojection error to prune bad matches (reprojection errors average 0.3 pixels and we discard points with errors larger than 2 pixels).
Approach	The first discards reconstructed points that cause physically unrealistic strain on the surface of the mesh and the second constrains our search for correspondence.
Approach	Our strain constraint is based on the work of [Provot 1995] who noted that strain in cloth does not exceed 20% in practice.
Approach	Relaxing the constraint to distances in 3D (surface distance is always more than the distance in 3D), we can use strain to exclude possible correspondences.
Approach	Strain naturally fits in to our information theory framework: if strain excludes 87.5% of the possible correspondences, then strain has added 3 bits (because log 2 (1 − 0.875) = −3).
Approach	To find correspondence, we match each image marker to a marker in the parametric domain.
Approach	To do this, we define affinities a i, j between image marker i and parametric marker j.
Approach	Each affinity is a product over different cues.
Approach	Initially, we learned this threshold from labelled data, but we found that changing it by several orders of magnitude had little effect on our results.
Approach	Subsequently, we use the value 10 −5(N+1) where N is the number of neighbors.
Challenge	In the acquisition process, occlusion inevitably creates holes in the reconstructed mesh ( figure 8 ).
Challenge	One would like to fill these holes with real cloth.
Outcome	One of our major contributions is a data driven approach to hole filling: we fill holes with previously observed sections of cloth.
Approach	Our work differs from [Anguelov et al. 2005] because our hole filling procedure does not assume a skeleton that drives the surface and our procedure estimates a single coefficient per example.
Approach	This hole filling procedure has a number of requirements: the missing section needs to be replaced by a section with the same topology; the new section needs to obey a number of point constraints around the edge of the hole, and the splicing method should respect properties of cloth (specifically strain).
Approach	We select a reconstruction technique based on deformation gradients [Sumner and Popovic 2004].
Approach	In this approach, we fit deformation gradients for the missing section to a combination of deformation gradients in other observed sections.
Approach	Then, we reconstruct the point locations from the deformation gradients.
Approach	This procedure has a number of advantages.
Approach	First, deformation gradients naturally yield cloth like properties.
Approach	Deformation gradients are the transformation matrix between triangles in two poses of the mesh.
Approach	By penalizing elements that deviate in this matrix, we have a fairly direct penalty on large changes in scale or strain.
Background	In contrast, methods based on the Laplacian of the mesh ([Sorkine et al. 2004]) do little to penalize these strains and can show many artifacts around the edge of the mesh.
Approach	Second, deformation gradients can be converted into vertex locations by inverting a linear system, allowing us to specify vertex locations as constraints.
Background	Methods such as [Lipman et al. 2005] don’t allow vertex constraints.
Approach	We produce a mesh by forming equilateral triangles for sections of cloth that are printed with a contiguous pattern by referencing the triangle stucture of markers on the cloth.
Approach	Our recovered markers are at the center of each triangle – so we average points to get out the vertices and subsequently the original mesh.
Approach	We insert artificial points where two pieces of fabric come together.
Approach	These points are created once per garment by hand clicking on photos of the each seam.
Approach	The 3D locations of these points are recreated in each frame by averaging points near the seam.
Approach	We use occlusion free meshes from other frames to automatically interpolate holes.
Approach	For each hole in each frame, we cut out the missing region plus a ring of two triangles around the region.
Approach	We select a set of examples of the enlarged region, then use MeshIK ([Sumner et al. 2005]) to reconstruct the surface.
Background	MeshIK works by choosing a combination of deformation gradients from the examples and then solving for the missing point locations.
Approach	We use the points from the ring of known triangles around the hole as constriants in MeshIK.
Approach	The most restrictive aspect of MeshIK is that it requires example meshes without holes.
Approach	In practice, we never observe complete ex- ample meshes – each mesh is missing some triangles.
Approach	These holes appear in different places in different meshes and we create complete meshes in an iterative method.
Approach	First, we fill all holes with a naive linear algorithm (specifically, we triangulate across gaps and use barycentric coordinates to place the missing points – this gets the job done, but works poorly).
Approach	Then, we do another pass through all the data, where we replace the linear sections with sections created using MeshIK on the linearly filled data.
Approach	To downweight the linear data, we select the examples with the highest percentage of viewed points in the missing section.
Approach	These frames are then used as examples in MeshIK to hole fill in the rest of the sequence.
Approach	For the pants capture, we iteratively refine a set of 27 extreme poses which were captured specifically for filling holes.
Approach	The advantage of this apporach is that the example poses are chosen to capture the relevant degrees of freedom – yielding better results.
Approach	For the cloth toss sequence, we chose the simpler approach: iteratively refine the entire sequence.
Approach	We introduce flexibility preserving smoothing – a method similar to anisotropic diffusion [Perona and Malik 1990] that smoothes near-rigid movement without effecting flexible deformation.
Challenge	Typical temporal smoothing is dangerous because fast non-rigid movements can easily become physically implausible when blurred over time.
Challenge	However, because fast non-rigid regions of the cloth are complex, small temporal errors are often difficult to notice.
Challenge	In contrast, small errors in regions of the cloth that move rigidly are typically easy to observe.
Approach	As a result we use flexibility preserving smoothing, a procedure that smoothes rigid movement more heavily than non-rigid movement.
Approach	To do this, we take a local region around each vertex in the mesh (typically 25 points) and compute a rigid transformation to previous and subsequent frames.
Approach	Aligning the regions with this transformation, we compute the movement of the vertices in this reference frame as a proxy for rigidity.
Approach	Large variations in location indicate non-rigid movement and consequently receive little smoothing.
Approach	Smaller variations indicates rigid movement and benefit from more substantial smoothing.
Approach	We use a size adjusted gaussian to smooth in this reference frame.
Approach	Our video sequences were taken with synchronized firewire cameras (Foculus FO214C) with a capture resolution of 640 x 480 and a capture rate of 24 frames per second.
Approach	Our still captures were taken using a digital SLR camera and then downsampled to approximate available video resolutions.
Approach	We use the automated calibration technique in [White and Forsyth 2005], but any standard calibration will work ([Zhang 2002] and [Bouguet 2005] are good choices).
Approach	In the pants sequences, we used seven lights totalling 1550 Watts to illuminate the scene.
Approach	Adequate lighting is critical: from our experience fewer lights degrade performance due to harsh shadows and dim lighting causes motion blur through slower shutter speeds.
Approach	Our cloth was printed by a digital mail order fabric printing service.
Approach	On a P4 2.4 GHz machine, acquisition takes roughly 6 minutes and mesh processing 2 minutes per frame.
Approach	Code is written in MATLAB.
Outcome	Our capture results are best evaluated by looking at our video and figures 1,12,13.
Outcome	Much of the cloth is in contact with the floor and unobservable – yielding fewer bits of strain.
Outcome	In addition, the camera images were not output in a linear color space, reducing the number of color bits.
Outcome	As a result, we terminated the correspondence algorithm at N = 2.
Outcome	Our pants animation is by far the most challenging, and we analyze some of the details a little more closely.
Outcome	With an average of 2405 observed markers, there were 979 3D markers per megapixel.
Outcome	If we factor out the pixels lost to background, we get 3500 3D markers per foreground megapixel or 282 foreground pixels per recovered 3D marker.
Outcome	Our marker observations average 56 pixels per marker per image.
Outcome	This approach covers a reasonably large range of motion, but ignores cloth dynamics.
Approach	The largest challenge is that captured cloth meshes contain only points on the cloth surface, so we do not know joint locations.
Approach	Instead, we insert proxy points for knee and hip joints in each of our basis meshes.
Approach	These points are then connected to a small set of nearby triangles in the original mesh.
Approach	For each frame of animation we set the proxy points’ locations according to joint angles in the skeletal mocap data.
Approach	The resulting transformed joints are used as constraint points in MeshIK, which produces the final output meshes.
Outcome	Using our MATLAB implementation of MeshIK, this process takes around 5-10 seconds per frame.
Approach	We use the same 27 bases poses for MeshIK based reconstruction.
Approach	In order for a small basis to adequately express a full range of motion, each basis pose must be an extreme configuration.
Approach	For simple objects such as a cylinder, a small bend (for example) is sufficient to extrapolate to a larger bend [Sumner et al. 2005].
Approach	However, for pants the relationship is more complex: the fact that no folding occurs in a small bend does not imply that folding will be absent in a larger bend.
Approach	Conversely, if a decent amount of folding occurs in a small bend, we do not expect extreme folds in a corresponding larger bend.
Outcome	As a result, MeshIK is most useful when a basis is carefully chosen to prevent extrapolation artifacts.
Outcome	One drawback to our approach is the loss of secondary kinematic motion, such as the sway of loose cloth.
Outcome	Because MeshIK does not use velocity information, the resulting animation appears damped.
Outcome	We have brought cloth capture from constrained laboratory examples to real settings by providing robust methods for dealing with occlusion and folding.
Outcome	Like human motion capture, this tool requires significant engineering effort.
Outcome	Camera setup and calibration are time consuming and the equipment is costly.
Outcome	However, once these obstacles have been overcome, capturing large amounts of data is relatively easy.
Outcome	So that other researchers can benefit from our work, we are releasing our capture data at http://www.ryanmwhite.com/data.
Outcome	In our video, we show some of the uses of this data, including editing using [Kircher and Garland 2006] and posing using [Sumner et al. 2005].
FutureWork	Future work in cloth capture should involve more cameras, higher resolution (leading to smaller denser markers), different garments and different materials.
FutureWork	We plan to pursue more tools to edit and repurpose captured data.
Background	Simulation and image based rendering both provide methods to generate animation of cloth (a limited simulation list includes [House and Breen 2000; Terzopoulos et al. 1987; Choi and Ko 2002; Bridson et al. 2003; Baraff et al. 2003] and a limited image based rendering list includes [Bradley et al. 2005; White and Forsyth 2006; Lin and Liu 2006; Scholz and Magnor 2006]).
Background	These methods have several advantages: simulation gives significant user control and produces higher resolution meshes while image based rendering techniques produce more accurate illumination.
Challenge	However, capturing large amounts of data is far easier than simulating large amounts of data and provides more control than image based rendering.
Challenge	Common simulation complaints include long computation times, significant parameter tweaking and tangling.
Outcome	In contrast, capture is relatively quick (our code is 8 minutes per frame in MATLAB); parameters are set by selecting the type of cloth [Bhat et al. 2003] and tangling is relatively uncommon.
Outcome	Cloth capture makes it easy to capture large amounts of cloth, including fast light cloths that create instabilities in simulation.
Outcome	An added attraction of cloth capture is that complex interaction between the cloth and the body is recorded without complicated human models.
Approach	We do some pre-processing to get marker locations and connectivity from raw images.
Background	We recommend readers unfamiliar with these techniques refer to [Forsyth and Ponce 2002].
Approach	We start by converting each image to HSV, disregarding the luminosity (V) and using polar coordinates to compute distances in hue and saturation.
Approach	To detect markers, our code looks for uniformly colored blobs in two stages: first regions are built by growing neighborhoods based on similarity between pixels.
Approach	This method is sensitive to image noise and can produce oversized regions when the color boundaries are smoothed.
Approach	The second stage takes the center of mass of each blob from the first stage, computes the mean color and grows a region based on distance to the mean color (it is computationally intractable to use this as the first stage of the blob detection).
Approach	The process is iterated for increasing thresholds on the affinity value in the first stage, using the portions of the image where detection failed in previous stages.
Approach	Finally, blobs are thresholded based on size.
Approach	Next, we need to determine the neighborhood relationships.
Approach	For each marker, we construct a covariate neighborhood (a fitted ellipse) and vote for links to the three closest markers with similar covariate neighborhoods.
Approach	This measures distances appropriately in parts of the scene where the cloth is receding from view and discourages links between markers with wildly different tilts.
Approach	All links that receive two votes (one from either side) are kept while the rest are discarded.
Approach	Links that bridge markers with conflicting color information are also discarded (typically on internal silhouettes).
Background	For more reading on information theory, consult [Cover and Thomas 1991].
Approach	Our analysis is based on the information entropy definition: H(X) = − ∑ n i=1 p(x i ) · log 2 x i .
Background	For [Scholz et al. 2005], the equation in section 3.1 is reduced to I = 9 ∗ C − A because they use 8 neighbors and no strain constraints.
Background	They use 5 colors which, without errors, yields C = log 2 5 bits per marker.
Background	They cite an error rate of five to ten percent.
Background	As a result, they recover anywhere from 1.65 to 2.04 bits per marker.
Approach	In our comparison, we use C = 1.93 bits for color information from their method (five percent error, with equal probabilities for all remaining choices).
Approach	Note that this is effectively less than four colors!
Approach	Second, we compute structural ambiguities in their method which account for uncertainty in observations.
Approach	The orientation of the surface is unknown, yielding four possible directions, or two bits of structural ambiguity.
Background	Second, in their paper, they say that oblique views cause another bit of uncertainty.
Background	As a result A = 3 bits.
Approach	For our work, C is an empirical observation.
Outcome	Depending on the lighting and camera configuration, we get anywhere from 5 to 7 bits.
Approach	We use the conservative estimate of C = 5 bits per marker.
Approach	Second, our mesh is triangular and there are three possible neighborhood rotations, yielding A = log 2 3 = 1.59 bits of structural ambiguity.
Approach	When neighborhoods are not used, there is no structural ambiguity.
Outcome	Strain information is difficult to compute and depends on the geometry of the surface and the orientation of the camera.
Outcome	In most cases, we observe more than 9 bits of strain information.

Challenge	In this paper we show how to incorporate effects of wind fields in cloth animations.
Approach	We discuss two different approaches to model force fields describing air motion and show how these models can be augmented to exhibit interaction with deformable thin objects such as textiles.
Approach	The first model is based on the Navier-Stokes equations, while the second method extends simple particle tracing methods by the effect of lee.
Outcome	In each case, we present a method for simulating the interaction of cloth movements with the wind field.
Outcome	Both methods have been integrated in an existing cloth simulation system, and we compare their respective advantages and disadvantages.
Challenge	While the simulation of wind is an area of vast interest in aerodynamic engineering, computational fluid dynamics (CFD), and animation/visualisation of fluids in computer graphics, it has been a rather abandoned subject in simulation of deformable objects such as cloth simulation.
Challenge	This is mostly due to the fact that conventional CFD applications require enormous computational power.
Challenge	However, aerodynamic effects are obviously capable of enhancing the realism of an animated scene and thus are an important part of a cloth simulation system.
Challenge	For example, air resistance is a vital component which cannot be neglected if realistic animation is desired [ BTH + 03 ].
Challenge	In this work we discuss two different approaches to      model force fields describing air motion and show how these forces can be applied to generate aerodynamic effects on textiles.
Challenge	The first method is based on modelling air flows with the Navier-Stokes equations.
Approach	With this model, the effect of wind fields on smoke has already been investigated [FSJ01], and in this paper we extend this approach to wind effects on textiles.
Challenge	However, the solution of the sophisticated NavierStokes equations is not desired and not necessary in all situations where wind effects shall be integrated into cloth simulations.
Outcome	For this case, we present a much simpler model based on tracing wind particles that move along a global force field.
Approach	During the simulation, the wind field is evaluated for each wind particle at its current position.
Approach	The so determined flow field is used to compute the wind force which is added to the forces that act on the textiles.
Approach	By detecting collisions between the wind particles and objects in the scene, we are able to simulate the important effect of lee even with this straightforward method.
Challenge	Of course, both approaches have different characteristics and aim at different applications for wind simulation.
Outcome	In this work, we compare the models’ advantages and disadvantages and show practical results of the described methods.
Background	Models for fluid dynamics can be essentially subdivided into two categories.
Background	Simple models which are commonly used in most computer graphics applications describe the wind flow by predefined flow functions.
Background	Here, global functions are defined to model the velocity of wind.
Background	Either special flow primitives can be combined [ WH91 ; LDG96 ; Li00 ] or visually pleasing functions introducing random turbulence [ SF92 ; SF93 ; Sta97 ] are taken into account to model even complex wind scenes.
Background	Many models use this method to move objects in the wind field through the scene [ Ree83 ; Sim90 ; WH91; BLM95 ].
Background	In addition, physically based fluid dynamics solving equations of motions with particle methods were presented recently [ IK03 ].
Background	However, fixed flow functions lack interaction with the user or objects in the scene.
Background	Hence, with increasing computer power, computer graphics concentrates on physically more accurate simulations.
Background	In many fields the Navier-Stokes equations are the standard mathematical formulation to model fluid dynamics.
Background	A vast literature exists on how to solve these equations numerically.
Background	CFD are applied in this field for engineering tasks with a high degree of quality requirements.
Background	Unfortunately, it is quite difficult to apply these algorithms in computer graphics due to enormous calculation times.
Background	Hence, faster fluid solvers were investigated for computer graphics applications.
Background	Kajiya et al. [ KvH84 ], Yaeger et al. [ YU86 ], and Gamito et al. [ GLG95 ] worked on fluid dynamics solvers in two dimensions, and many improvements and variants followed [ CdVLHM97 ; KM90 ].
Background	Foster and Metaxas [ FM96 ; FM97 ], and Griebel et al. [ GDN98 ] presented a solver for the fully three dimensional Navier-Stokes equations.
Background	Due to explicit integration methods very small step sizes had to be used.
Background	To enable faster simulations, a solution with an unconditionally stable solver was introduced by Stam [Sta99 ] and further extended in [ FSJ01 ; Sta01 ; Sta03 ].
Background	Modelling interaction of fluids with solid objects has been investigated by Takahashi et al. [ TFK + 03 ] and Génevaux et al. [ GHD03 ].
Background	Recently, Wei et al. [ WZF + 03 ] presented an interesting approach to simulate lightweight objects like soap bubbles and feathers in a wind flow using a Lattice Boltzmann Model extended with a subgrid model.
Background	For interaction of highly deformable objects and especially cloth-like objects only few models have been investigated.
Background	Simple models consist in the calculation of lift and drag forces from the surrounding velocity field [SF92; Pro95; KCC + 00; KCCL01].
Background	More complex interaction models calculate the wind force by a panel method [LDG96; Li00] introducing local vortices.
Outcome	In this work, we show how recent results in fluid dynamics for computer graphics can be exploited to simulate interaction of wind flows with textiles.
Outcome	Moreover, we extend the more straightforward approach of global wind field functions by the effect of lee.
Approach	To incorporate wind effects in a physically based animation we have to apply additional external forces in the dynamical model of the deformable objects.
Approach	Hence, given a wind flow represented by a velocity field in the scene we calculate the forces which are exerted on the simulated objects.
Approach	The wind force acting on objects in an air stream is decomposed into two components: the lift force F L and the drag force F D (see figure 1 ).
Approach	The direction of the drag force F D is diametral to the relative velocity v rel = v object − u, where v object is the object’s velocity and u is the velocity field of the wind.
Approach	Note that in the case of a windless situation, i.e. u = 0, we still have air resistance for moving objects.
Approach	The drag force per face is then given by F i,D = 2 1 C D ρ|v i,rel | 2 A · ( n i · v i,rel ) · (− v i,rel ) ,        where C D is the specific air resistance coefficient, ρ the density of air, A is the area of the corresponding face, and v i,rel the unit relative velocity vector of the face.
Approach	The direction of the lift force, which is perpendicular to v i,rel and lies in the plane spanned by v i,rel and n i , is given by u i = ( n i × v i,rel ) × v i,rel .
Approach	Then the lift force is calculated as F i,L = 1 2 C L ρ|v i,rel | 2 A cos θ · u i , where C L is the lift force coefficient, and θ is the angle between v i,rel and the actual face.
Approach	The first model is based on the work of Stam [Sta97] and calculates the numerical solution of the Navier-Stokes equation with a semi-Lagrangian approach.
Approach	This model is extended to interaction of the wind flow with textiles.
Approach	The second model employs precomputed wind flows and particle tracing methods.
Approach	This approach is much easier to implement and can be added to existing simulation modules without additional computational cost.
Challenge	The numerical algorithms used in CFD to solve these equations are designed for physical accuracy for engineering applications and are expensive in computation.
Approach	But in our case where this precision is not necessary simplifications can be made which greatly reduce the computation costs as described by Stam [Sta03].
Approach	Since the arising wind velocities are clearly below the speed of sound, compressibility effects are negligible, and the wind is modelled as an incompressible constant density fluid.
Approach	Here, u describes the (three-dimensional) velocity field, ν is the kinematic viscosity of the fluid, ρ its density, p the pressure in the wind field, and f accounts for external forces.
Approach	The first equation states that the velocity field should be incompressible while the second one describes the evolution of a velocity field over time.
Approach	The first term on the right hand side reflects the change of velocity due to advection, while the second expression accounts for any external force f and acceleration caused by the local pressure gradient ∇p and by viscous drag depending on ν.
Approach	To solve these equations numerically they first have to be discretised.
Approach	For this, the computational domain is diced up into equally sized cubes forming a grid as described in section 4.2.2, and sample values of velocity and pressure are defined at the cell centres.
Background	Foster and Metaxas [FM96] use a finite difference approximation for the discretisation of the operators in equation (4.2).
Background	Then they update the cell’s velocities according to the divergence value computed in each direction, respectively, using an explicit integration scheme.
Approach	Since time steps in explicit computations usually need to be very small, we follow Stam [Sta99] who proposes an implicit integration scheme, which allows stable simulations with large time steps.
Approach	While the linear terms in equation (4.2) are straightforward to solve implicitly, the term −(u · ∇)u is nonlinear and deserves special attention.
Approach	Here, a different approach based on the method of characteristics is used to solve the advection equation.
Approach	Equation (4.2) does not provide a divergent-free velocity field.
Approach	Therefore, the divergence of each cell in the grid has to be projected to zero using the Helmholtz-Hodge decomposition [Sta03].
Background	The major advantage of Navier-Stokes based approaches consists in the fact that the evolution of the wind flow over time is calculated.
Approach	It enables us to model global effects like convection and diffusion on a physical basis.
Outcome	We present a model to exploit these wind models for calculating the interaction of deformable objects with the air flow by a boundary condition method.
Background	As already stated by Stam [Sta03] “a velocity field of its own isn’t really visually interesting until it starts moving objects [...
Background	That means in particular that all objects in the scene interact with the fluid present in it, i.e. in our case clothes with the wind.
Background	On the one hand the wind deforms the objects which on the other hand change the wind flow.
Approach	To describe the above situation by a physical model we require the Neumann boundary condition ∂u =0 ∂n to be satisfied for the wind flow u at any boundary point of an object with normal n.
Background	Rigid objects like walls will influence the fluid field but will not be affected by fluid forces themselves.
Background	Deformable objects like cloth are supposed to both experience fluid forces and itself influence the fluid flow.
Approach	This in fact is a major difficulty.
Approach	Consider a point p b on the boundary of a deformable object in the scene.
Approach	Let u(p b ) be the corresponding wind velocity at that point and n be its normal.
Approach	On the one hand, we want the Neumann boundary condition u(p b ) · n = 0 to be satisfied.
Approach	On the other hand, the wind velocity orthogonal to the object’s surface is just what causes the aerodynamic forces.
Approach	Without further remedial action setting the boundary according to the Neumann condition would mean that the fluid will not exert forces on the objects.
Approach	Here we propose a method which meets both requirements.
Approach	For every deformable object the velocity value of the surrounding wind field for every vertex of the representing mesh is tracked.
Approach	The wind velocity at the vertex positions of the object is recorded.
Approach	Additionally, the normals of these vertices are stored.
Approach	Then, the aerodynamic forces as described in section 3 are calculated.
Approach	Finally, for every marked cell in the scene the previously stored normals are averaged in one space cell which are used to update the velocity at the cell to satisfy the Neumann boundary condition.
Approach	Thus, the boundary conditions are met and yet aerodynamic forces are obtained.
Approach	A different issue is how to deal with the inside of (rigid) objects.
Approach	The method to set boundary conditions as described above does not account for the interior of objects.
Approach	Thus, a nonzero velocity could be mistakenly assigned to cells lying inside an object.
Approach	To avoid this situation, the path of the wind flow is checked for object intersection, whereby the collision detection of the cloth simulation system provides a simple method to deal with this issue [MKE03].
Approach	To define a wind scene we first built up the air flow by simple primitives such as parallel directed wind fields, vortices, etc.
Approach	We then use a par- ticle tracing method in the defined wind field to determine the effect of lee by detecting windless areas.
Outcome	This method is very easy to implement and yields very plausible and nicely looking results.
Approach	A simple approach to generate complex air flows is to define a wind field by mathematical functions which assign to each point in space a unique velocity value.
Approach	One drawback of this model is that it cannot handle objects exhibiting complex boundaries.
Background	The approach to model solid objects in the scene taken by Wejchert et al. consists in placing a wind source using a mirror principle in order to extinguish the air flow at the boundary of the object.
Background	While this works for simple objects this approach is not feasible at all with deformable objects like textiles.
Approach	Another more serious drawback of this model for our application consists in the lack of interaction with objects.
Approach	The wind flow defined by the primitives will not react on objects in the scene which means for example that tissues in the lee of other objects will be affected by the wind flow as well.
Approach	However, this method can be combined with the aerodynamic model described in section 3 to give nice and fast results as will be shown in section 5.
Approach	To solve the described problems we propose a model which combines the simple global wind flow techniques with a particle tracing method.
Approach	Here, particles are moved along the wind field to determine the effect of objects in the scene.
Approach	This model divides the scene into parallelepiped cells.
Background	There are two common approaches to discretising the continuous velocity field defined in space: one can either choose the midpoint of a cell [Sta99] or its six faces [FM96] to define the field.
Approach	As usual, values between the defining points of the grid are interpolated using trilinear functions.
Approach	The basic idea of the particle tracing method is to trace wind particles through a field w = i w i defined by linear superposition of wind sources corresponding to flow primitives with respective velocity fields w i .
Approach	The field w does not account for lee effects caused by objects in the flow.
Approach	Therefore we compute the wind field u containing these effects as follows.
Approach	The wind particles are emitted into the velocity field w i of the corresponding wind source which is defined on a grid.
Approach	The specific emission intervals and amounts depend on the properties of the flow sources.
Approach	In every time step each particle in a wind gust moves along its velocity field w i defined by the corresponding wind source.
Background	Notice that the movement of the particles in a wind gust is only affected by the wind source they belong to.
Background	The global superposition of all wind sources has no effect on these particles.
Approach	To calculate the wind particles’ positions we used the explicit Euler integration scheme.
Approach	For a wind particle at position p t and time t this results in a path s(p t , p t+∆t ), where p t+∆t denotes the position after time step ∆t according to p t+∆t = p t + w i (p t , ∆t) .
Approach	As a particle moves along its path in space, all grid cells colliding with the path are updated with the velocity of the associated wind source with respect to the position of the particle.
Approach	The particle might cross several grid cells on its way during a single time step.
Approach	If this is the case, the path of the particle has to be subdivided into parts not exceeding the size of a grid cell.
Approach	This path is then tested for collisions with the objects in the scene.
Approach	The velocity field u is then computed as for each grid cell separately, where w i are all those wind sources whose particles have reached the cell.
Approach	The wind force effective on objects in the scene is then computed from the velocity field u.
Approach	Since u is determined using the wind particles, every point p that could not be reached by any wind particle will hold zero velocity even if w may hold a nonzero velocity.
Approach	Thus, this method solves the problems described in section 4.2.1.
Approach	Note that the somewhat tempting simplification of tagging each cell to either have wind in it or not is not valid.
Approach	Imagine the simple scene in which there are two directional wind sources with opposite wind directions.
Approach	Let them further have equal velocity magnitude and no distance attenuation.
Approach	If we now place a solid object in between these two sources a rather undesired effect would occur using this simplification: on both sides of the solid object all cells would be tagged as having wind.
Approach	But evaluating the wind field at every cell we would obtain a zero velocity.
Approach	This is due to the extinguishing effect of the superposition of the two wind sources.
Approach	Therefore, it is crucial for the particles to have the associated velocity of their wind source and not just the velocity resulting from the global superposition of all wind sources.
Outcome	For physically accurate simulations based on the common method in fluid dynamics the model introduced by Stam produces realistic effects which global wind field models can never achieve.
Outcome	It produces nice swirls and vortices derived from dynamical characteristics of the fluid.
Outcome	However implementing the fluid solver is quite complex and using a high grid resolution is computationally expensive.
Outcome	Hence, the global wind field model is better suited for an easy to implement tool which is easy to adapt to specific situations.
Background	Particle systems are very common in the simulation engines and most functionality can be adapted to integrate the proposed wind model.
Outcome	Even with this straightforward approach, nice, realistic looking results can be achieved which is illustrated in the next section.
Approach	We implemented the wind models described in sections 4.1 and 4.2 in a cloth animation system that employs a fast finite element method to simulate the drape of textiles with measured material properties [EKS03].
Approach	For collision detection (between deformable objects, rigid objects, and wind particles) we use k-DOP hierarchies as described in [MKE03].
Approach	We used the particle tracing method described in section 4.2 to model the effects of a directional wind field on the flag.
Approach	Two flags are exposed to a wind field, but the wind is blocked by a wall, so one of the flags is not affected by the wind.
Approach	To show the improved realism when simulating lee effects, we let the the wind act on all polygons of the shirt on the right (no lee effect).
Outcome	For the shirt on the left we used the Particle Tracing Method to simulate lee effects which, we think, gives more realistic results (see also the accompanying video).
Outcome	We presented two models for including advanced wind effects into cloth simulation systems.
Approach	The first concentrates on physically accurate computations using a semi-Lagrangian approach to solve the Navier-Stokes equations, the second model incorporates a particle tracing method for global wind fields.
Outcome	As illustrated in the previous section both methods produce realistic looking results which are capable of enhancing the realism of computer animations.
Outcome	While the first model has a wider range of applications, the second one provides an easy method which still delivers realistic effects such as air resistance and lee.
Outcome	All methods described in this work should be easy to extend to three-dimensional deformable objects.
Outcome	All the methods apply the same except for simple changes.
Outcome	Since three-dimensional objects define an inner and outer part, the adaption of the face normals in equation (3.1) is not necessary.
Outcome	Moreover, in the wind field computation care has to be taken that no wind field is present in the object.
Outcome	Here, the same method as described for rigid objects (section 4.2.2) can be applied.

Challenge	Many textiles do not noticeably stretch under their own weight.
Challenge	Unfortunately, for better performance many cloth solvers disregard this fact.
Outcome	We propose a method to obtain very low strain along the warp and weft direction using Constrained Lagrangian Mechanics and a novel fast projection method.
Outcome	The resulting algorithm acts as a velocity filter that easily integrates into existing simulation code.
Background	Our eyes are very sensitive to the behavior of fabrics, to the extent that we can identify the kind of fabric simply from its shape and motion [Griffiths and Kulke 2002].
Background	One important fact is that most fabrics do not stretch under their own weight.
Challenge	Unfortunately, for many popular cloth solvers, a reduction of permissible stretching is synonymous with degradation in performance: for tractable simulation times one may settle for an unrealistic 10% or more strain (compare 1% and 10%, Figure 1 ).
Outcome	Our work alleviates this problem by introducing a numerical solver that excels at timestepping quasi-inextensible surfaces (stretching below 1%).
Approach	The solver builds on a framework of Constrained Lagrangian Mechanics (CLM) [Marsden 1999].
Background	Warp and weft, the perpendicular sets of strands that make up a textile, are prohibited from stretching by enforcing constraint equations, not by integrating spring forces.
Outcome	We present numerical evidence supporting the observation that a constraint-based method is inherently well-suited to operate in the quasi-inextensible regime.
Background	In contrast, for this regime spring-based methods are known to experience a range of difficulties, leading to the adoption of various strain limiting [Provot 1995] and strain rate limiting algorithms.
Background	We are motivated by the work of Bridson et al. [2002], who viewed strain limiting as one of multiple velocity filtering passes (another being collision handling).
Outcome	The velocity filter paradigm enables the design of modular systems with mix-and-match flexibility.
Outcome	We prove that the implicit method’s nonlinear equations correspond to a minimization problem (§4.2): this result motivates a fast projection method for enforcing inextensibility (§4.3).
Outcome	We describe an implementation of fast projection as a simple and efficient velocity filter, as part of a framework that decouples timestepping, inextensibility, and collision passes (§4.4).
Outcome	Consequently, the fast projection method easily incorporates with a code’s existing bending, damping, and collision models, to yield accelerated performance (§5).
Background	For brevity, we review work on stretch resistance; for broad surveys on cloth simulation see [House and Breen 2000; Choi and Ko 2005].
Background	The most general approach is to treat cloth as an elastic material [Terzopoulos et al. 1987; Breen et al. 1994; Eberhardt et al. 1996; Baraff and Witkin 1998; Choi and Ko 2002].
Background	To reduce visible stretching, elastic models typically adopt large elastic moduli or stiff springs, degrading numerical stability [Hauth et al. 2003].
Background	To address the stiffness of the resulting differential equations, Baraff and Witkin [1998] proposed implicit integration, allowing for large, stable timesteps; adaptive timestepping was required to prevent over-stretching.
Background	Eberhardt [2000] and Boxerman et al. [2003] adopted implicit-explicit (IMEX) formulations, which treat only a subset of forces implicitly.
Approach	Our method is closely related to the IMEX approach, in the sense that stretching forces are singled out for special treatment.
Background	These works, and many of their sequels, improved performance by allowing some perceptible stretch of the fabric.
Background	In the quasiinextensible regime, however, implicit methods encounter numerical limitations [Volino and Magnenat-Thalmann 2001; Boxerman 2003; Hauth et al. 2003]: the condition number of the implicit system grows with the elastic material stiffness, forcing iterative solvers to perform many iterations; additionally, timestepping algorithms such as Backward Euler and BDF2 introduce undesirable numerical damping when the system is stiff [Boxerman 2003].
Background	Given a stiff differential equation, an alternative to implicit integration is to reduce the stiff component and reformulate it as a constraint [Hairer et al. 2002].
Background	In the smooth setting, the penalty-force and constraint-based approaches are equivalent in the limit of an infinitely stiff penalty term [Bercovier and Pat 1984].
Background	While simple to implement, this approach suffers from poor convergence since each displacement may stretch other incident springs.
Background	Therefore, Provot’s method is used in cases where tight tolerances are not required, e.g., [Desbrun et al. 1999; Meyer et al. 2001; Fuhrmann et al. 2003].
Background	Bridson et al. [2002; 2003] used Provot’s approach in conjunction with strain rate limiting, bounding the rate of change of spring length per timestep to 10% of the current length.
Background	Müller et al. [2006] used a non-linear Gauss-Seidel approach to enforce inextensibility on each constraint separately.
Background	Bridson et al. observed that iterative strain limiting algorithms behave essentially as Jacobi or Gauss-Seidel solvers.
Background	In this light, it is not surprising that for finely-discretized quasi-inextensible fabrics, iterative constraint enforcement requires a prohibitive number of iterations (see §5).
Background	The Lagrange multiplier approach alleviates the difficulties associated with poor numerical conditioning and artificial damping.
Background	House et al. later encountered difficulties in handling collision response within the proposed framework [2000].
Approach	By building on the velocity-filter paradigm, our method handles both inextensibility and complex collisions.
Background	House et al. formulated constraints as in [Witkin et al. 1990], which is subject to numerical drift that may be exacerbated by the discontinuities introduced during collision response.
Background	Drift may be attenuated using constraint-restoring springs, but the authors reported difficulty in adjusting the spring coefficients.
Background	We postulate that one reason for their difficulties with drift was consequent to the linearization of the constraint equation, which permitted higher order errors to accumulate over time.
Approach	Our method does not linearize the constraint equations, and therefore it is not subject to drift.
Background	Recently, Tsiknis [2006] proposed triangle-based strain limiting together with a global stitching step for stable constraint enforcement.
Background	Hong et al. [2005] used a linearized implicit formulation in order to improve stability of constrained dynamics.
Background	This allowed for larger timesteps and reduced the need for springs to maintain the cloth on the constraint manifold.
Background	Both of these approaches enforce inextensibility only for strain exceeding 10%.
Background	In summary, when the tolerance for stretching is very small, modeling stretch response with spring-based or strain-limiting approaches is costly and even intractable; constraint-based methods present a promising alternative.
Background	Woven fabrics are not a continuous material, rather they are a complex mechanical network of interleaving yarn [Breen et al. 1994].
Background	Since the constituent yarn is often quasi-inextensible, the material’s warp and weft directions do not stretch perceptibly.
Background	In imposing inextensibility on all edges of a triangle mesh, one quickly runs into parasitic stiffness in the bending modes, or locking [Zienkiewicz and Taylor 1989], since locally-convex regions of a triangle mesh are rigid under isometry.
Approach	Instead, we consider warpweft aligned quadrilateral meshes with a sparse number of triangles (quad-dominant meshes).
Approach	Subtracting constraints from positional DOFs leaves nearly zero DOFs for a triangulation.
Approach	In the case of a quadrangulation, O(n) DOFs remain, and we see that in a flat configuration they correspond to the normal direction at each vertex.
Approach	Furthermore, under general mesh positions, the constraints are linearly independent, with a full-rank Jacobian treatable by a direct solver (§4).
Approach	Since shearing modes excite only a mechanical interaction of warp and weft, and not a stretching of yarn, fabric does indeed shear perceptibly.
Approach	Therefore, we model shear using non-stiff stretch springs applied on both diagonals of each quad.
Approach	The complete model of in-plane deformation is compatible with an existing code’s quador triangle-based treatment of bending and collisions.
Approach	With this simple formulation of inextensibility constraints in place, what is needed is an efficient method for enforcing constraints.
Approach	Given a quadrilateral mesh with n vertices and m edges, the numerical integration algorithm for constrained dynamics can be developed directly from the augmented Lagrange equation [Marsden 1999], L(x, v) = 1 v T Mv −V (x) − C(x) T λ , 2 where x(t) is the time-varying 3n-vector of vertex positions, v(t) = x(t) is its time derivative, M is the 3n × 3n mass matrix, and V (x) is the stored energy (e.g., bending, shear, and gravity).
Approach	C(x) is the m-vector of constraints, with the i th entry corresponding to the violation of inextensibility of the i th edge, as computed by (1); λ is the m-vector of Lagrange multipliers.
Approach	The term −∇C(x) T λ may be viewed as the constraint-maintaining force, where the factors −∇C(x) T and λ determine the direction and scaling for the force, respectively.
Approach	∇C(x) is a rectangular matrix whose dimensions are m × 3n.
Approach	For simulation, we must discretize (3) and (4) in time using one of various schemes, each with benefits and drawbacks.
Approach	One may choose differing explicit or implicit schemes for the potential and the constraint forces (similarly, potential forces are split and separately discretized in [Ascher et al. 1997]).
Background	One widely-used family of discretizations includes SHAKE and RATTLE, which extend the (unconstrained) Verlet scheme [Hairer et al. 2002] by considering a constraint force direction, −∇C(x) T , evaluated at the beginning of the timestep.
Approach	Unfortunately, enforcing length-preserving constraints with SHAKE fails for four common geometric configurations, which we refer to as (Q1)–(Q4) and depict in Figure 2 .
Approach	This figure is a reproduction from [Barth et al. 1994], which discusses these drawbacks in SHAKE but does not offer a solution.
Approach	If the constraint direction, −∇C(x) T , is evaluated at the beginning of the timestep, x n , as in SHAKE, then no scaling, λ , of the constraint direction yields a satisfied end-of-timestep constraint, C(x n+1 ) = 0.
Approach	Numerically, for (Q2)–(Q4) this observation manifests as a singular Jacobian in Newton’s method.
Approach	These four cases correspond to rapid change in edge length or orientation; in practice, they occur often.
Approach	Consider evaluating the constraint direction, −∇C(x) T , at the end of the timestep.
Approach	We observe (and prove in Appendix A) that this resolves (Q1), (Q2) and (Q4); (Q3) remains, but is automatically remedied by decreasing the timestep.
Approach	Consider the ICD timestep, which treats potential forces explicitly 1 : v n+1 = v n − hM −1 ∇V (x n ) + ∇C(x n+1 ) T λ n+1 , x n+1 = x n + hv n+1 , C(x n+1 ) = 0 .
Approach	Define x 0 n+1 =x n +hv n −h 2 M −1 ∇V (x n ), i.e., x n+1 0 is the position at the end of an unconstrained timestep; define δ x n+1 = x n+1 − x 0 n+1 , i.e., δ x n+1 is the correction of the unconstrained step.
Approach	Next, eliminate v n+1 by rewriting the above system as two equations, F( δ x n+1 , λ n+1 ) = 0 and C(x n+1 ) = 0, in the free variables δ x n+1 and λ n+1 , keeping in mind that x n+1 is a linear function in δ x n+1 , and defining F( δ x n+1 , λ n+1 ) = δ x n+1 + h 2 M −1 ∇C(x n+1 ) T λ n+1 .
Approach	F( δ x n+1 , λ n+1 ) and C(x n+1 ) are the residuals of the discretization of (3) and (4), respectively.
Approach	C measures the deviation from the constraint manifold (in our case, the extensibility of the material).
Approach	To implement ICD, we solve for the roots of F and C up to a desired tolerance using Newton’s method.
Approach	Solving for an ICD step is costly, because there are many unknowns (≈ 5n), and each Newton step requires the solution of an indefinite linear system, whose matrix is costly to assemble.
Approach	In §4.3, we develop an approximation to ICD that addresses these drawbacks without sacrificing constraint accuracy or robustness.
Approach	Consider for a moment an alternative approach to constrained integration in two steps: (a) step forward only the potential forces to arrive at the unconstrained position, x n+1 0 ; (b) enforce the constraints by projecting onto the constraint manifold M = {x n+1 |C(x n+1 ) = 0}.
Background	Methods of this form are known as manifold-projection methods [Hairer et al. 2002].
Approach	To define a specific method, we must choose a projection operator.
Approach	In the method we refer to as SAP, we write the projection of the unconstrained point onto the constraint manifold as x n+1 0 + δ x n+1 , so that the projected point extremizes the objective function W ( δ x n+1 , λ n+1 ) = 1 ( δ x n+1 ) T M( δ x n+1 ) + C(x n+1 ) T λ n+1 , 2h 2 with respect to the free variables δ x n+1 and λ n+1 .
Approach	Simply put, we choose the point on the constraint manifold closest to x n+1 0 .
Approach	To define closest, we need a measure of distance.
Approach	Take M as the physical mass matrix (usually arising from a finite-basis representation of x and a surface mass density).
Approach	Then the choice ( δ x n+1 ) T M( δ x n+1 ) corresponds to the L 2 norm of the mass-weighted displacement of the mesh as it moves from x 0 n+1 to x n+1 .
Approach	We use · to denote the Euclidean norm in R 3 .
Approach	We can interpret these roots from the SAP view as follows: C(x n+1 ) = 0 corresponds to finding some point on the constraint manifold.
Approach	C(x n+1 ) = 0 with F( δ x n+1 , λ n+1 ) = 0 corresponds to finding the closest point on the constraint manifold.
Approach	To solve SAP, one might extremize W ( δ x n+1 , λ n+1 ) using Newton’s method: each iteration would improve upon a guess for the shortest step, δ x n+1 that projects x n+1 0 onto the constraint manifold.
Approach	Fast projection starts at x n+1 0 , and takes a sequence of steps, δ x n+1 j , j = 1, 2, . . ., toward the constraint manifold, with each step as short as possible.
Approach	Therefore, we omit the superscripts (n + 1), which refer to time, in order to emphasize the subscripts, j, which refer to a specific iteration of fast projection, e.g., we write the input position, x n+1 0 , as x 0 , and progressively closer approximations to the constrained position as x 1 , x 2 , .
Approach	Formally, the ( j + 1) th step of fast projection, x j+1 = x j + δ x j+1 , extremizes the objective function        W ( δ x j+1 , δ λ j+1 ) = 2h 1 2 ( δ x j+1 ) T M( δ x j+1 ) + C(x j+1 ) T δ λ j+1 ,        with respect to the step increment, δ x j+1 , and the auxiliary variable δ λ j+1 .
Approach	Substituting (5) into (6), we eliminate δ x j+1 and solve a linear system in δ λ j+1 :
Approach	Since the linear system matrix involves M −1 , the assembly of this system is most efficient for diagonal (e.g., lumped) mass matrices.
Approach	Finally, we compute the increment (5) to obtain x j+1 = x j + δ x j+1 .
Approach	As with ICD/SAP, a fast projection step requires a linear solve.
Approach	However, fast projection’s system, (7), is smaller (≈ 2n × 2n compared to ≈ 5n × 5n), positive definite (compared to indefinite) and sparser.
Approach	As a result it is considerably cheaper to evaluate, assemble, and solve than its ICD/SAP counterpart.
Approach	Fast projection finds a manifold point, x n+1 , that is close, but not closest, to the unconstrained point, x 0 n+1 .
Approach	Referring to the Corollary, we conclude that fast projection exactly solves C = 0 while it approximates F = 0.
Approach	One important question is whether the fast projection’s error in F is acceptable.
Approach	Compare a sequence of fast projection iterations to ICD/SAP’s sequence of Newton iterations.
Outcome	The first iteration of these methods is identical.
Outcome	At the end of this first iteration, F, C ∈ O(h 2 ).
Outcome	Additional fast projection iterations seek C → 0, and since C ∈ O(h 2 ), increments in x are O(h 2 ), therefore F remains in O(h 2 ).
Approach	Observe that F ∈ O(h 2 ) is considered acceptable in many contexts, e.g., [Baraff and Witkin 1998; Choi and Ko 2002] halt the Newton process after a single iteration.
Approach	To verify this claim, we measured F throughout the ballet dancer sequence.
Outcome	As recorded in Figure 3 , the first iteration of the fast projection method eliminates first-order error.
Outcome	The remaining iterations perturb F only to higher-order (often decreasing the error further).
Approach	We implement fast projection as a velocity filter, enabling easy integration into our existing cloth simulation system; refer to Algorithm 1.
Approach	Step 3 requires solving a sparse symmetric positive definite linear system; we use the PARDISO [Schenk and Gärtner 2006] solver.
Approach	Each row of ∇C(x n+1 j ) corresponds to one edge, and is computed using (2).
Approach	The right-hand side, C(x n+1 j ), is given by (1).
Approach	We describe several experiments comparing various stretchenforcement methods.
Approach	All timings are with reference to a single process on a 2.66GHz Intel Core 2 Duo.
Approach	We observe the scaling of computational cost as a function of (a) permissible strain and (b) mesh resolution.
Approach	The physical setup consists of a chain pinned at the top node and released to free fall under gravity.
Approach	The simple 1D chain resists stretching, but not bending.
Approach	In this didactic example, timings refer to MATLAB’s (sparse) direct solver.
Outcome	Our method shows asymptotically better performance as permissible strain vanishes (see Figure 4a ).
Outcome	Likewise, our algorithm exhibits favorable performance as mesh resolution increases (see Figure 4b ).
Outcome	Using 80 vertices and 1% strain, the fast projection method achieves a 25× speedup.
Outcome	Note that there exists considerable difficulty in setting spring coefficients a priori to satisfy a given strain limit.
Outcome	For settings more pragmatic than a simple chain, such as the following draping experiment, we are unable (despite considerable effort) to set spring coefficients that achieve a prescribed small strain.
Outcome	This explains why spring methods are often treated with strain-limiting procedures.
Approach	We evaluate how the spatial discretization and permissible strain affect performance of these four algorithms.
Approach	The setup consists of draping a cloth over a polygonal model of a sphere.
Approach	We measure strain before the collision reaction pass.
Approach	For the strain limiting algorithms (both Jacobi and Gauss-Siedel), we iterate until strain is in the permissible range.
Approach	With GaussSiedel, we apply a random permutation to reduce bias resulting from the particular edge ordering.
Approach	For SHAKE, we use the acceleration suggested in [Barth et al. 1994] to rebuild the matrix once per step or when it fails to converge.
Outcome	As a consequence, the algorithm requires extremely small timesteps to converge, but each timestep is relatively inexpensive, as matrix re-assembly and re-factoring is infrequent.
Outcome	ICD is able to use larger timesteps than SHAKE and still converge, however, since each timestep is substantially more expensive than a SHAKE step, the overall time is higher.
Outcome	All CLM methods scale equally well, asymptotically better than the strain limiting approach, with the fast projection being the fastest.
Outcome	As we refine the resolution, and allow strain of 1% ( Figure 5b ), the fast projection method outperforms the other methods.
Approach	Our experiments focus on measuring the performance of enforcing inextensibility using CLM compared to strain limiting and stiff springs.
Outcome	In addition to the direct benefit of fast projection on computation times, further benefits can be reaped from the resulting inextensibility.
Background	For example, the work of Bergou et al. [2006] assumes inextensibility in order to accelerate bending computation.
Outcome	In adopting the velocity-filtering viewpoint, we gain speed, simplicity, and software modularity—all key to a practical and maintainable implementation.
Outcome	However, this comes at a theoretical cost: there is no longer an efficient way to perfectly enforce both ideal inextensibility and ideal collision handling, since one filter must execute before the other, and both ideals correspond to sharp constraints.
Outcome	To enforce both perfectly would require combining them in a single pass, an elegant and exciting prospect from the standpoint of theory, but one which is likely to introduce considerable complexity and convergence challenges.
Outcome	Practically, we observe that this drawback does not cause artifacts in our simulation, for several reasons: first, we execute collision-handling last, to avoid glaring collision artifacts, yet we assert that empirically our strain remains negligible, as required.
Outcome	Second, unlike constraint-enforcement approaches such as [Witkin et al. 1990], the inextensibility filter does not assume that the constraint is maintained at the beginning of the timestep and errors are not accumulated during the simulation.
Outcome	The consequent numerical difficulties are then addressed by a combination of (a) relaxing realism by allowing 10% strain, and (b) adopting simple iterative strain and strain-rate algorithms that have poor convergence behavior.
Outcome	With Constrained Lagrangian Mechanics as our alternative point of departure, we demonstrate a straightforward filter, with good convergence behavior, for enforcing inextensibility.
Outcome	We provide one immediate and pragmatic approach to fast and realistic fabric simulation using CLM, and we hope that it will spur a renaissance of activity along this direction.
Approach	We briefly explain why ICD and fast projection (FP) are not troubled by configurations (Q1), (Q2), and (Q4), and are resilient to (Q3).
Background	Facts about the behavior of SHAKE are taken from [Barth et al. 1994].
Approach	Q1 SHAKE’s force ∇C(x n ) T λ n+1 cannot reduce the single edge’s length back to l; our force ∇C(x n+1 j ) T λ n+1 can reduce that edge’s length back to l.
Approach	Q2 ∇C(x n+1 j ) and ∇C(x n ) T are both full-rank, yet SHAKE fails since ∇C(x n+1 j )M −1 ∇C(x n ) T is singular; FP uses ∇C(x n+1 j )M −1 ∇C(x n+1 j ) T , and ICD uses ∇C(x n+1 j )D∇C(x n+1 j ) T , where D is a symmetric full-rank matrix; in both cases this product is not singular.
Approach	Q3 ICD and FP may fail if ∇C(x n+1 j ) is rank-deficient; for sufficiently small timestep, h, this case is always avoidable.
Approach	Q4 ∇C(x n ) is rank-deficient, so SHAKE fails; ICD and FP do not use ∇C(x n ).

Challenge	Good character animation requires convincing skin deformations including subtleties and details like muscle bulges.
Background	Such effects are typically created in commercial animation packages which provide very general and powerful tools.
Challenge	While these systems are convenient and flexible for artists, the generality often leads to characters that are slow to compute or that require a substantial amount of memory and thus cannot be used in interactive systems.
Challenge	Instead, interactive systems restrict artists to a specific character deformation model which is fast and memory efficient but is notoriously difficult to author and can suffer from many deformation artifacts.
Outcome	This paper presents an automated framework that allows character artists to use the full complement of tools in high-end systems to create characters for interactive systems.
Approach	Our method starts with an arbitrarily rigged character in an animation system.
Approach	A set of examples is exported, consisting of skeleton configurations paired with the deformed geometry as static meshes.
Approach	Using these examples, we fit the parameters of a deformation model that best approximates the original data yet remains fast to compute and compact in memory.
Challenge	To be believable, animated characters must deform in plausible ways as they move.
Challenge	It is possible to accomplish this by having an artist sculpt an entire character mesh by hand for every frame of an animation sequence, but this is impractical.
Challenge	Instead, animators typi- cally manipulate an underlying hierarchical skeleton.
Background	The character mesh geometry must then be attached to the underlying skeleton so that as the skeleton deforms, the mesh also deforms appropriately.
Background	This attachment of model geometry to an underlying skeleton is called a “skin” and can be viewed as a function that maps from the skeletal parameters to a deformation field.
Background	There are two fundamental aspects of skin creation—authoring and computation.
Background	Skin authoring refers to how artists use tool sets to describe the behavior of skin geometry as the skeleton moves.
Background	Skin computation refers to the method by which the deformed mesh geometry is evaluated for display at some skeleton configuration.
Background	For high-end applications, the authoring methods drive skin creation while for interactive systems, computation methods dominate.
Challenge	For high-end applications such as film, the visual fidelity of characters is paramount, so artists require flexibility and control in skin authoring.
Background	Hence, there are many different ways to create characters using commercial tools.
Background	One technique involves modeling skin substructure such as muscles and tendons to drive the skin geometry [Wilhelms and Gelder 1997; Scheepers et al. 1997].
Background	Many deformers which drive skins by linking their control points to the skeletal parameters with custom expressions or scripts are also available.
Background	Some examples include FFD lattices [Sederberg and Parry 1986] or Wires [Singh and Fiume 1998].
Background	High-end characters often use a combination of these techniques—different tools are appropriate for different parts of the character.
Background	This generality and control means that the computation aspect of high-end characters is highly customizable, tightly coupled to authoring, and potentially unbounded.
Background	In fact, high-end tools allow authors to continually develop new skin computation models through custom scripts, expressions and complex deformers.
Background	In contrast, interactive systems require fast computation and small memory size for characters.
Background	Thus, the character computation model is fixed and artists must restrict their tool set to author characters in direct support of it.
Background	The most common skin computation model in games and interactive systems goes by many names including SSD, enveloping, smooth skinning, and linear blend skinning.
Background	This technique assigns a set of influencing joints and blending weights to each vertex in the character.
Background	The skin is computed by transforming each vertex by a weighted combination of the joints’ local coordinate frames.
Background	While fast to evaluate and compact in memory, this method is notorious not only for its authoring difficulty, but also for its undesirable deformation artifacts.
Background	However, this method is widely used since these characters can be used with arbitrary amounts of animation data and can be posed at runtime.
Background	A different character computation mechanism previously used in interactive systems is called mesh animation.
Background	Mesh animation works by storing a large number of deformed models as static meshes—one for each frame of animation.
Background	These static models are then either displayed directly or are linearly interpolated at runtime.
Background	Mesh animation is interesting since it decouples skin authoring from runtime skin computation, allowing artists to use any tools they want to author characters.
Background	Unfortunately mesh animation is only appropriate when the required animation sequences are short and are known a priori.
Background	As games and interactive applications use larger amounts of animation, storing every frame becomes prohibitive.
Background	This technique is also incapable of generating new poses at runtime; for example, to place the character’s hand exactly on a door knob or to make footfalls land precisely on stairs.
Background	Due to these limitations, mesh animation is losing popularity.
Outcome	In this paper, we present an automated method to build character skins that are fast to compute and compactly represented from a set of examples.
Outcome	This technique allows artists to use any skin authoring tools they like while producing characters that meet the performance demands and work with the computation models used in interactive systems.
Outcome	We present a framework for extending linear blend skinning that allows us to capture these detailed skin deformations.
Outcome	We show how we can fit the parameters of our skinning model using a sampling of an arbitrarily rigged character’s deformations.
Approach	Building a skin with our system involves two major steps.
Approach	We begin with a character rigged in an animation package such as Maya.
Approach	We then sample this character’s skin deformations by exporting the character’s geometry in several poses.
Approach	Next we fit the parameters of our underlying skinning model using this sampled data.
Approach	We wish to obtain a good sampling of the character’s skin deformations to fit our underlying model with.
Approach	To do this, we pose the character to exercise all the joints fully and include its extreme poses.
Approach	This step does not require a trained animator since these poses are only intended to exercise the degrees of freedom of the character and need not correspond to a realistic motion.
Approach	Once this is done, the poses are sampled regularly at k times.
Approach	This sampling can be very simple to obtain from the user’s perspective—in our case, users must simply invoke a script we have implemented in Maya.
Approach	Each sample consists of the skeleton configuration and the corresponding deformed skin geometry as a static mesh.
Approach	We call a paired skeleton configuration and static mesh an example.
Approach	Using this set of examples, our system first determines the set of joints that should influence each vertex, and then solves a bilinear least-squares problem to fit the parameters of the underlying skinning model.
Approach	As mentioned earlier, the skinning model we use is an extension of the standard linear blend skinning model.
Approach	Our extension adds extra joints to the character that are simply related to the existing joints.
Approach	These new joints are designed in such a way to capture richer deformations than the standard linear blend skinning model.
Approach	Our system is configured to add these extra joints automatically to characters, but we allow users to fine tune the specific set of extra joints if they wish.
Background	Character skin deformations are fundamental to character animation and have been addressed for some time in the literature.
Background	Catmull [1972] introduced one of the first skeleton-driven techniques—rigid skinning to a hierarchically structured articulated figure.
Background	A 2D skeletal bilinear deformation method was presented by Burtnyk and Wein [1976].
Background	An early 3D skeleton-driven technique that went beyond rigid skinning was presented by MagnenatThalmann, et al. [1988].
Background	Their technique used custom programmed algorithms to deform character meshes based on the nature of particular joints.
Background	More recently, novel skinning methods that start with a simple skin and use sparse data interpolation to correct errors between it and a set of examples have been introduced.
Background	Three examples, Pose Space Deformation, Shape by Example, and EigenSkin [Lewis et al. 2000; Sloan et al. 2001; Kry et al. 2002] use radial basis interpolation of corrections to linear blend skins.
Background	Another recent work applies these techniques to range scan data [Allen et al. 2002].
Background	These techniques are similar to ours in that they take examples as input.
Background	The results of these approaches are quite good, and unlike our technique, they can handle skin deformations that depend on abstract parameters rather than only skeleton configurations.
Background	However, these methods are not appropriate for interactive characters since they require storing potentially large amounts of example data for runtime interpolation.
Approach	In contrast, our method discards all example data after the fitting process so the size of our runtime structures does not scale with the number of inputs.
Background	Other authors have used physical simulation for interactive deformations, especially secondary animation [James and Pai 2002; Capell et al. 2002].
Approach	Our method cannot capture these secondary deformations directly; however, a technique such as DyRT [James and Pai 2002] can be applied to the characters we generate to add secondary animation.
Background	There has been some recent work on fitting skinning models.
Background	One method solves for joint centers and vertex weights for a scanned arm [Nebel and Sibiryakov 2002] but the Multi-Weight Enveloping technique [Wang and Phillips 2002], or MWE, is most similar to our approach.
Background	MWE extends linear blend skinning by giving each vertex one weight to each coefficient of each influencing joint’s transformation matrix instead of one weight per influencing joint.
Background	They then find these weights by solving a linear leastsquares problem using a set of examples as input.
Background	While on the surface Multi-Weight Enveloping and our technique seem very similar, they are in fact different in a fundamental way.
Approach	Both MWE and our technique use an extension of linear blend skinning as an underlying deformation model.
Background	However, MWE extends linear blend skinning by adding more vertex weights to the model while in contrast, our method adds more joints.
Background	MWE uses a large number of weights per vertex (12 per influencing joint).
Background	This introduces the possibility of rank deficient matrices in the least-squares solutions [Wang and Phillips 2002], especially since the matrix coefficients are usually highly correlated.
Background	This can lead to overfitting, which MWE must take measures to avoid.
Approach	In contrast, since the number of weights per vertex in one of our skins remains relatively small (1 per influencing joint) and our extra joints are explicitly designed to be very different from existing joints, our technique requires no special provisions to avoid overfitting.
Outcome	Even so, our method can detect and handle small amounts of overfitting if it occurs as explained in Section 5.2.
Approach	Another consequence of having one weight per entry in the joint transformation matrices is that MWE skins are not as easily accelerated by graphics hardware as skins created using our method.
Approach	Finally, since our skins are computed in the same manner as linear blend skins, existing software infrastructure can make use of them with little or no changes.
Background	The traditional interactive skinning model goes by many names.
Background	Lewis et. al call it Skeleton Subspace Deformation or SSD, Maya calls it “smooth skinning” and we call it linear blend skinning.
Background	This technique is widely used for interactive applications.
Background	An excellent description of this method is found in Lewis et al. [2000].
Background	The linear blend skinning algorithm works by first placing a hierarchical skeleton inside a static model of a character, typically in some neutral pose.
Background	This initial character pose is referred to as “dress pose”.
Background	Then, each vertex is assigned a set of influencing joints and a blending weight for each influence.
Background	Computing the deformation in some pose involves rigidly transforming each dress pose vertex by all of its influencing joints.
Background	Then the blending weights are used to combine these rigidly transformed positions.
Background	(Taken together, M i,d −1 v d represents the location of v d in the local coordinate frame of the ith influence.
Background	) Note that a deformed vertex position in the dress pose configuration c = d is the same as the provided dress pose vertex ( v d = v d ) if the weights are affine.
Background	This skinning algorithm is notorious for its failings.
Background	It cannot represent complex deformations and suffers from characteristic artifacts such as the “candy-wrapper” collapse effect on wrists and collapsing around bending joints as shown in Figure 2 .
Background	The artifacts occur because vertices are transformed by linearly interpolated matrices.
Background	If the interpolated matrices are dissimilar as in a rotation of nearly 180 degrees, the interpolated transformation is degenerate, so the geometry must collapse.
Background	In addition to these deformation problems, linear blend skins are very difficult to author [Lewis et al. 2000].
Background	Despite its failings, this skinning algorithm is very fast and widely supported by commercial applications so it remains popular especially in games and virtual environments.
Challenge	The linear blend skinning model is not sufficient to capture deformations well as shown in Figure 3 .
Challenge	The problem in this particular case is that as the twist approaches 180 degrees, the linearly blended matrix becomes degenerate and collapses the skin geometry.
Challenge	Linearly blended transformations tend to collapse the more different they are.
Challenge	The resulting loss of volume can also be observed around hinge joints such as the knee and elbow as shown in Figure 2 .
Challenge	We observe that we can help avoid the collapse problem by avoiding blending transformations that are so dissimilar.
Approach	We can accomplish this by adding extra transformations that properly interpolates without collapsing.
Approach	In the case of the twisting wrists, we can add an extra joint that interpolates the rotation angle correctly and does not collapse.
Background	In fact, artists sometimes do this by hand to help avoid wrist collapses.
Approach	More generally, we observe that any deformation effect could be obtained by adding joints that deform appropriately to capture that deformation effect.
Approach	For example, to capture muscle bulges, we can add joints that scale up when the muscle should bulge, and scale down when the muscle relaxes.
Approach	For wrinkles, we could add several joints that move and scale in concert to capture the wrinkles.
Approach	Unfortunately, adding so many extra joints is impractical.
Approach	First, adding such a large number of joints would severely impact the performance of our resulting skins.
Approach	Worse, even if we could find these transformations for the input examples, it is unclear how to determine the general relationships of these transformations to the skeletal parameters in all poses.
Approach	Without knowledge of this relationship, our scheme would only be able to reproduce the input frames and would not work well in new poses.
Approach	Instead, we extend the traditional linear blend skinning model by adding a relatively small number of joints that are simply related to the original skeletal parameters and fit using them.
Approach	We choose these extra joints by both examining the places where the standard linear blend model fails and by examining extra character deformations that we would like to capture.
Approach	We then add joints that we believe will help resolve these artifacts.
Approach	Finally, we fit the parameters of our skinning model using this extended skeleton.
Approach	The key to our success is that since vertices choose weighted sums of transformations, if any linear scaling of an added joint is beneficial it may be used.
Approach	Thus the additional joints need not be exact.
Approach	We emphasize that this is a framework for obtaining better deformations and the joints we choose to add are based on our observations of characters.
Approach	Different characters with different deformations may require a different set of additional joints.
Approach	However, once some set of these joints is determined, the skin may be solved using our fitting algorithm without change.
Outcome	To help solve the collapsing geometry problem, our system can automatically add joints that properly interpolate rotations without collapsing.
Approach	This is done by examining the rotation of a joint relative to the dress pose and computing the new joint as the halfway spherical linear interpolation [Shoemake 1985] of this rotation, located at the same position in space.
Approach	More joints with evenly distributed interpolation parameters could be added to sample this rotation space even better; however, in our experience just a single interpolated rotation is sufficient.
Challenge	Another type of effect not easily captured by the simple linear blend model is bulging and denting of skins caused by muscles, tendons, or other substructure.
Challenge	These particular effects cannot be captured since the joints employed in animating a character do not typically scale up and down as would be necessary to approximate these effects.
Approach	We have observed that for many characters, the substructure deformation effects from muscles and tendons are often simply related to the angles between joints.
Approach	For example, a bicep bulge is small when the elbow is near full extension while the bugle is large when the elbow is near full flexion.
Approach	The effect is similar for other muscles in the body.
Approach	To capture these effects, our system can add several joints that scale up and down based on the angle between particular joints.
Approach	We add these scaling joints as follows.
Approach	First we choose a joint in the original skeleton that will drive the scaling parameters of the new joints.
Approach	Once this driver is chosen, there are two sets of joints that we add.
Approach	The first set is “upstream” of the driver and lies in the middle of the bone connecting the driver to its parent, the second set is “downstream” and lies in the middle of the bones connecting the driver to its children.
Approach	All upstream joints are oriented in the same way, with one axis aligned with the bone as shown in Figure 6 .
Approach	We use four upstream joints.
Approach	Two of them scale up about two axes orthogonal to the bone and a corresponding pair scale down about the two axes orthogonal to the bone.
Approach	The scale parameters of these joints are set based on the angle of the bone connecting the driver to its parent and the bone connecting the driver to its child.
Approach	If the driver has multiple children, a vector that is the sum of the bones connecting the driver to its children is used to measure the angle.
Approach	Downstream joints are similar.
Approach	We use four downstream joints on each bone connecting the driver to its children that scale just as the upstream joints do.
Approach	The scale parameters are computed as follows.
Approach	For joints that scale up, the scale parameter s is s = 1 + k b 1 · b 2 + 1 2 b 1 b 2 where b 1 and b 2 are the bone vectors used to measure the angle at the driver joint and k is the maximum scale factor when the angle between b 1 and b 2 is zero.
Approach	For joints that scale down, the scale parameter is simply s −1 .
Approach	The value for k may be chosen by the user but in our experience, we have found that 8 works well for our examples.
Approach	Again, since vertices may take any scaling of these new joints, a conservative large value is fine.
Approach	For example, if a vertex in fact needed a joint that scaled by 2 instead of 8, it could be assigned a weight of 4 1 .
Approach	Once our system has augmented the input skeleton, we use a fitting procedure to set the parameters of the underlying skinning model to match the example data well.
Approach	As mentioned earlier, the input to the fitting process is a set of examples.
Approach	An example is simply a static character mesh paired with a skeleton.
Approach	This static mesh is deformed according to the skeleton configuration, but it is not attached to the skeleton in any way.
Approach	For our results, our examples were generated by exporting rigged objects from Maya, but they could have been sculpted by hand or come from another program.
Approach	A linear blend skin computes a deformed vertex as described earlier in Equation 1.
Approach	Examining this skinning model, only the M i are predetermined.
Approach	These are the coordinate frames associated with all the joints in the character.
Approach	That means for each vertex, we are able to choose the set of influencing joints, influence weights (w i ) and the dress pose vertex position (v d ).
Approach	We would like to choose the influence sets, weights and dress pose vertex positions that best approximate the examples and generalize well to new poses.
Approach	We determine influence sets first for several reasons.
Approach	Ideally, the influence sets would fall out naturally from the weight solving procedure (irrelevant joints would have a weight of zero) but this does not happen in practice because our samplings are necessarily not exhaustive.
Approach	Also, the more joints that a vertex depends on, the slower the skin can be to compute and current hardware only supports a limited number of influences per vertex.
Approach	Thus, we would like to select a small set of good influences.
Approach	Also, choosing the influence sets appropriately lets us bound the size of the problems we must solve to determine the weights as discussed in Section 5.2.
Approach	This makes the solving process faster.
Background	In most recent research, influence set determination has been left to users [Lewis et al. 2000; Wang and Phillips 2002; Sloan et al. 2001].
Background	The task is typically accomplished by “painting” the regions of influence for each joint over the mesh.
Background	While less difficult than painting the weights themselves [Lewis et al. 2000], it is a tedious process.
Approach	In contrast, our system automatically determines the influence sets for each vertex using a heuristic algorithm.
Approach	We observe that vertices in a character skin typically transform nearly rigidly with respect to some joint.
Approach	For instance, vertices on the forearm roughly follow the forearm.
Approach	We believe that for most characters, their skin is most heavily influenced by those joints that they are bound to.
Approach	Even though a point on the bicep is not truly rigid as an arm moves (due to muscle bulge), we believe that these points remain mostly rigidly attached to the upper arm, and therefore should be influenced by it.
Approach	Using this observation, we measure how rigidly a vertex transforms with every joint over all examples and use the most rigidly transforming joints for the influence set.
Approach	For a single vertex, a rigidity score for a joint is computed as follows.
Approach	For each example, the local coordinate position of the vertex is computed as M i,e −1 v e where M i,e is the coordinate frame associated with the ith joint in the eth example and v e is the global coordinate position of the vertex on the eth example.
Approach	The collection of these local coordinate positions over all examples forms a point cloud as shown in Figure 7 .
Approach	The more compact this point cloud, the more rigid we believe the vertex-joint relationship to be.
Approach	We measure the compactness of this point cloud by taking its diameter (the maximum distance between any two points in the cloud).
Approach	We have found that the simple O(n 2 ) algorithm that compares each point to every other to be fast enough for our purposes but this diameter may be computed more quickly.
Approach	An O(n log n) time algorithm is possible.
Background	See [Malandain and Boissonnat 2002] for faster methods.
Approach	Once the compactness measures for all joints are computed for a vertex, the smallest k are chosen as the influence set for that vertex.
Approach	It may be tempting to use a threshold scheme to choose influence sets but we have found this problematic.
Approach	It is unclear how to pick a good threshold because as the rigidity scores get larger, they become less meaningful.
Approach	For instance, it may happen as an artifact of the particular input examples that points on the left shoulder move much more rigidly relative to the right leg rather than the left leg but both choices make no sense for influences.
Approach	Since larger rigidity scores are not particularly meaningful, it is nearly impossible to pick a meaningful threshold value.
Approach	As in other linear blend skinning systems, influence sets need only be determined conservatively [Wang and Phillips 2002] so we allow users to choose k if desired.
Approach	In our experience, we have found that between three and eight influences works well, depending on the complexity of the character.
Approach	Once the influence sets have been determined, only the weights and dress pose vertex positions remain (w i and v d ).
Approach	We would like to find the best vertices and weights that minimize the least-squares difference between the skin and the examples at all the example skeleton configurations.
Approach	That is        n 2 min ∑ v e i − v e i i=1        for all examples where v e i is the input vertex position from the ith example and v e i is the deformed vertex computed by the skinning model at the ith example configuration.
Approach	We use an alternation technique to solve the optimization.
Approach	This works by first fixing the first variable and solving a linear least-squares problem to find the second, then fixing the second and solving a linear leastsquares problem for the first.
Approach	This process is then repeated until it converges.
Background	This technique is commonly used and is described in [Freeman and Tenenbaum 1997].
Approach	We start by solving for weights since we have no good guess for them but we know that the initial dress pose vertices are ideal.
Approach	Next we hold the weights fixed and solve for vertex positions.
Approach	This process typically converges after one or two iterations.
Outcome	As mentioned in Section 2, we have found that since we are solving for a small numbers of weights using large numbers of examples, our systems are often well conditioned and do not suffer from overfitting if the input data is well sampled.
Outcome	Thus we do not have to take special precautions to avoid overfitting as in [Wang and Phillips 2002], although we include tests for robustness.
Approach	For clarity, we present the matrices we solve via least-squares in block form.
Approach	First we introduce some notation: T i,e = M i,e M i,d −1 .
Approach	In order to ensure that the resulting weights are affine, we set w 1 = 1 − ∑ i=2 n w i , and solve for w 2 through w n .
Approach	We solve these least-squares problems using the singular value decomposition.
Approach	This lets us detect when our matrices are rank deficient, leading to overfitting.
Approach	We detect this by comparing the ratio of the largest singular value to the smallest, and issuing a warning if there are any singular values below some fraction of this ratio.
Approach	To recover, we zero these singular values and continue with the fitting process.
Approach	If overfitting is a problem, provisions such as those taken in [Wang and Phillips 2002] could also be used.
Approach	However, in all the examples in this paper, no singular values were zeroed.
Approach	It is not only important for the geometry in a skin approximation to be accurate, but also important for normals to be well approximated.
Approach	If they are not, lighting calculations will not produce good results.
Approach	We assume that normals are specified per vertex.
Approach	It may seem that just transforming a dress pose normal by the inverse transpose of the corresponding vertex’s transformation matrix would be correct.
Approach	Instead we have single points that are computed independently.
Approach	Computing the normals in this manner can give undesirable results when the blended transformations are not pure rotations.
Approach	This alleviates the need for a general inversion operation.
Background	In EigenSkin [Kry et al. 2002], normals are treated as second skinning problem and are computed independently.
Approach	In our system, we take the model used in existing systems as in Equation 2 and include normals in our optimization process.
Approach	To do this, we simply add more terms to the objective function to include the differences between normal vectors.
Approach	We allow users to scale normals if they wish to change their relative influence on the least-squares solution.
Challenge	The simple linear blend skinning model commonly used in video games and other interactive applications is very fast and compact but cannot capture the high quality deformations that make convincing characters.
Outcome	Our framework for extending the linear blend model allows us to capture much more interesting deformations while retaining its efficiency.
Outcome	The most egregious deformation problems of linear blend skinning are solved by our approach.
Outcome	Collapsing and interpenetrations around hinge joints are also fixed using our method as shown in Figure 5 .
Outcome	In addition to solving these problems with linear blend skinning, our extension framework can capture other more subtle and detailed deformations required for convincing characters.
Outcome	While the particular extra joints we have chosen to add to our characters may not be capable of capturing the full deformation for any character, different extra joints that do capture the desired deformations may be added and solved using our technique.
Approach	To demonstrate that our technique can be used on more than just simple arms and legs, Figure 9 shows a rigged upper body and its approximation by our system.
Outcome	This figure also shows this character in new poses from an animation sequence, demonstrating that our resulting skins generalize well to new poses.
Outcome	Our solution procedure is generally very fast.
Outcome	None of the examples shown here took more than five minutes to solve on a modern personal computer.
Outcome	The slowest was the upper body model which has more than 6000 vertices, 50 examples, and 5 influences per vertex.
Outcome	The computation time for each vertex depends on the number of influences and the number of examples.
Outcome	Also, since each vertex is solved independently, our algorithm is trivial to parallelize.
Outcome	The ability to generate compactly represented, fast to evaluate, high quality skin approximations from a set of examples is very useful.
Challenge	Applications range from building characters for video games and virtual environments to high-end animation previewing.
Background	Many current interactive systems such as video games only support linear blend skinned characters.
Challenge	Aside from the deformation problems associated with using this model, authoring these skins is notoriously difficult.
Challenge	Determining the blending weights and influence sets is left to the skin author to set directly.
Challenge	None of the more intuitive or useful deformer primitives provided by animation systems may be used.
Outcome	Using our method, character authors may use any tools they like to author characters.
Outcome	All our system requires is a set of examples which is used to compute the appropriate influence sets and blending weights automatically.
Outcome	This frees the author from setting them manually.
Outcome	It is important to note that since our characters are a straightforward extension to linear blend skinning, many existing interactive systems already have the software infrastructure to sup- port them.
Outcome	In addition, since our skins are computed in the same manner as existing linear blend skins, they are already accelerated by current graphics hardware.
Outcome	Another application of our system is to map a character originally attached to one skeleton onto a different underlying skeleton.
Outcome	We call this process skin retargeting.
Outcome	Skin retargeting is useful if a particular interactive system requires characters to have a specific skeleton.
Outcome	For instance, a video game may have an optimized engine for characters with a particular skeleton topology.
Outcome	Ordinarily, if a character was created for a different skeleton, the character would have to be re-rigged manually to work on the new skeleton topology.
Outcome	However, this can be accomplished much more easily with our system.
Outcome	One just exports a set of example meshes deformed by the original skeleton but paired with corresponding poses of the new skeleton.
Outcome	Our system sees this as any other set of data and solves for the proper influence sets and blending weights.
Outcome	Another application of our technique is targeted at high-end animation.
Background	High-end characters often have such complex deformations that they cannot be computed interactively.
Background	Thus, animators typically work with low fidelity versions that only roughly suggest the actual shape of the character.
Outcome	Using our method, interactive characters could be built that allow animators to interact with much better approximations of the deformed characters.
Outcome	In this paper, we have presented a method for building fast to evaluate, compact representations that produce accurate approximations of deforming characters.
Outcome	The characters may be rigged using any available tool since our system only requires static deformed meshes paired with skeletal configurations as input.
Outcome	While our technique works well for a wide variety of character skins, it has limitations.
Outcome	For instance, character deformations in our model are only driven by the skeleton’s joint parameters.
Outcome	Our method cannot capture deformations that are driven by abstract parameters such as “happiness” as in [Lewis et al. 2000; Sloan et al. 2001].
Outcome	Our system also cannot accurately reproduce deformations that are not representable as linear combinations of the transformations expressed in our skeletons.
Outcome	For instance, the scaling joints presented in this paper can only fully capture deformations that are well approximated by a scaling that is linearly related to the cosine of the angle between two bones.
Outcome	This assumption may be violated by a character whose muscle bulges only when its arm is fully bent.
Outcome	The scaling joints also assume that only the angle between joints is important, so bending the shoulder forward is treated the same as bending it up.
Outcome	Even though not all deformations can be captured using the extra joints presented here, new joints may be added to capture any important deformation, and our influence set and vertex weight solving framework may be applied without change.
Outcome	Despite these limitations, our method produces high-quality yet fast and compact skinned characters that work with existing game engines, graphics hardware and other runtime systems.

Background	Back and Forth Error Compensation and Correction (BFECC) was recently developed for interface computation by using the level set method.
Challenge	We show that it can be applied to reduce dissipation and diffusion encountered in various advection steps in fluid simulation such as velocity, smoke density and image advections.
Outcome	BFECC can be implemented easily on top of the first order upwinding or semi-Lagrangian integration of advection equations, while providing second order accuracy both in space and time.
Outcome	When applied to level set evolution, BFECC reduces volume loss significantly.
Approach	We combine these techniques with variable density projection and show that they yield a realistic animations of two-phase flows.
Outcome	We demonstrate the benefits of this approach on the image advection and on the simulation of smoke, of bubbles in water, and of a highly dynamic interaction between water, a solid, and air.
Challenge	Simulation of incompressible fluid involves several computation steps including diffusion, advection and pressure projection.
Background	Advection steps transport some quantities from one region to another along the fluid’s velocity field.
Challenge	In this paper, we explore four forms of advection encountered in fluid simulation: velocity, smoke density, image and level set advections.
Challenge	Velocity advection transports the velocity field along the velocity itself.
Approach	This step is always needed in nonsteady flow simulation based on Navier-Stokes equation.
Challenge	Smoke density advection transports smoke along the velocity field.
Challenge	Sometimes, we may want to advect a colored image, which may be considered as colored smoke.
Approach	We call this process image advection.
Challenge	When one uses a level set method [OS88] to simulate a free surface or a two-phase flow, for example a water surface simulation, the level set must be transported as well.
Approach	We call it level set advection.
Challenge	Those advection steps can be computed by an upwind or a semi-Lagrangian method.
Background	The latter is often preferred due to its stability for large time step.
Background	The first order semi-Lagrangian method is popular in computer animation because of its simplicity.
Background	However, the first order semiLagrangian contains a significant amount of numerical diffusion and dissipation.
Background	In velocity advection, it yields damped fluid motion.
Background	In smoke density advection, it leads to a premature dilution of smoke, and is not able to simulate pure advec- tion.
Background	Therefore, higher order schemes, such as WENO or CIP [ TFK ∗ 03 ], are desired.
Outcome	We show that the implementation complexity of these schemes may be easily avoided by adding a very simple Back and Forth Error Compensation and Correction (BFECC) to an existing first order semiLagrangian schemes, thus improving its space and time accuracy to second order.
Outcome	We show that this approach reduces velocity damping and smoke density dilution and demonstrate its benefits on the four forms of advections discussed previously.
Background	BFECC was recently proposed in [DL03, DL04] as a level set interface computation method.
Background	As is mentioned in [ELF05], high order methods may not prevent volume loss much.
Background	However, the authors of [DL03] combined BFECC with their simple redistancing technique and applied it to the Zalesak’s problem, showing significantly reduced the volume loss.
Approach	We, however, use BFECC and the simple redistancing for level set advection of various fluid simulations and show that sufficiently realistic fluid animation can be obtained.
Approach	It would be interesting to apply this to the level set advection part of the particle level set method [ELF05] for more demanding simulation.
Background	The stability problems in the earlier works such as [ FM96 ] were successfully remedied in [ Sta99 ] by introducing the pressure projection scheme to enforce incompressibility of the fluid and the semi-Lagrangian treatment of the advection term in the Navier-Stoke equation.
Background	This solution is popular for the simulation of incompressible Fluids, such as smoke [ FSJ01 ] and also for more challenging free surface flows [ FF01 , EMF02 ].
Background	The semi-Lagrangian velocity advection [Sta99] comes with built-in dissipation, i.e., the velocity is dissipated quickly since the linear interpolation in the first order semiLagrangian produces large error.
Background	While higher order interpolation can solve the problem, it involves more neighboring grid point values and increases the complexity, particularly when non-uniform mesh structures are used.
Background	In [FSJ01], vorticity is added to generate small scale fluid rolling motion.
Background	Recently, [ SSK05 ] addressed this built-in dissipation by enhancing advection itself.
Background	They adopted the CIP [ TFK ∗ 03 ] method that increases the order of accuracy in space by introducing the derivatives of velocity to build a sub-cell velocity profile.
Background	A nice feature of this CIP method is that it is local in the sense that only the grid point values of one cell are used in order to update a point value.
Background	However, in this CIP method, all components of velocity and their partial derivatives should be advected, increasing the implementation complexity and computation time, especially in 3D.
Background	It is also worth noting that CIP has higher order accuracy in space only.
Background	Therefore high order integration of characteristics is also necessary.
Background	In contrast, BFECC is easier to implement and exhibits second order accuracy both in space and time and is local during each of its operational steps.
Background	Song et al [ SSK05 ] focused on applying CIP to generate more dynamic water surface behavior.
Background	However, we believe that having less dissipative and diffusive advection provides significant benefits in smoke simulations as well.
Background	In contrast, when BFECC is used, the smoke keeps full brightness throughout the simulation as is shown in the last five images.
Background	The introduction of the level set method to fluid animation in [ FF01 ] allowed realistic simulation of fluids with complex free surfaces.
Background	The problem left here was the volume loss in the level set method and the solution, known as the particle level set method, proposed subsequently in [ EMF02 ], turned out to be very successful in volume preservation.
Background	The two phase fluid solver using variable density projection has been broadly studied in mathematics and fluid mechanics [ SSO94 , OKBG00 , HKLS04 ].
Background	It has been used in graphics applications by [ HK03 ], where the authors simulated air bubbles rising and merging and by [TFK ∗ 03, SSK05], where splash style interactions between water surface and air are studied.
Approach	We follow the operator splitting steps proposed in [Sta99] except for the advection step, where we use BFECC and for the projection step for which we use the variable density pressure projection.
Approach	We use the standard staggered grid [FSJ01].
Approach	Suppose all terms in (1) except for − ρ 1 ∇P are treated and let the velocity obtained so far be u.
Approach	̃ The final step is applying the variable density pressure projection step to enforce the continuity equation ∇ · u = 0, i.e, solving the equation ∇ · ∆t ρ ∇P = ∇ · u.
Approach	̃ Its first order discretization is ∆x ∆t 2 P i, ρ j − i− P 2 1 i−1, , j j + P i, ρ j − i+ P 1 2 i+1, , j j + P i, ρ j − i, j− P i, 2 1 j−1 + P i, ρ j − i, j+ P i, 2 1 j+1 1 = ∆x u  ̃ i+ 2 1 , j − u  ̃ i− 2 1 , j + v  ̃ i, j+ 1 2 − v  ̃ i, j− 1 2 .
Approach	(2) We assume ∆x = ∆y here and through the rest of the presentation.
Approach	The extension to 3D is straightforward and hence omitted.
Approach	This first order approximation is identical to [ SSK05 ] and higher order formulations can be found in [ ABS96 , SAB ∗ 99 ].
Approach	Obviously, if ρ is constant, we have the pressure projection ∆t ρ ∇ 2 P = ∇ · u introduced in [ Sta99 ].
Approach	We also include a simple implementation of surface tension similar to [ SAB ∗ 99 ].
Approach	Since we want to apply it to various advections, we use φ to denote a quantity that is advected and reserve the symbol φ for the level set function through the presentation of this paper.
Approach	If the advection step L(·, ·) is exact, the first two forward and backward steps should return the value exactly the same as the original one, i.e., φ n = φ  ̄ .
Approach	Then the first two forward and backward steps will produce error 2e, i.e., φ  ̄ = φ n + 2e.
Approach	Therefore, the error can be computed as e = − 1 2 ( φ n − φ  ̄ ).
Approach	We subtract this error e before the final forward advection step.
Approach	Then the equation (5) becomes φ n+1 = L(u, φ n − e).
Approach	This step will add an additional e, which will be cancelled by the subtracted amount −e.
Approach	This method is proven to be second order accurate both in space and time [DL03, DL04].
Approach	First let the function SingleStep(u, v, φ n , φ n+1 ) implement upwind or semiLagrangian integration of the scalar field φ , which can be the velocity components u,v,w, the smoke density, RGB colors of an image or the level set function φ .
Approach	Then BFECC is implemented as:        SingleStep(u, v, φ n , φ  ̃ ) SingleStep(−u, −v, φ  ̃ , φ  ̄ ) φ  ̃ := φ n + ( φ n − φ  ̄ )/2 SingleStep(u, v, φ  ̃ , φ n+1 )
Approach	We can use (5) to implement the velocity advection step in solving the Navier-Stokes Equation.
Approach	In this case, φ becomes u, v and w.
Outcome	We show that BFECC can improve the damping in the first order semi-Lagrangian implementation of velocity advection, which is a well known drawback of [Sta99].
Approach	For multiphase flow, this BFECC needs to be turned off near the interface to prevent velocities of different fluids with different densities from being mixed, which creates momentum changes.
Approach	We simply turn BFECC off, i.e., use the first order semi-Lagrangian, for the grid points where | φ | < 5∆x.
Approach	We also turn it off near the boundary.
Approach	Notice that reducing velocity dissipation is equally important in the entire fluid domain, not only near the interface.
Approach	In other words, turning BFECC off near the interface has little effect since it is still turned on in most of the fluid domain.
Outcome	As is shown in Fig. 2 , applying BFECC adds details in smoke motion.
Approach	Notice that these details cannot be obtained from the vorticity confinement method [FSJ01], which only adds small scale rolling motions.
Approach	We also performed the same test in a coarser grid of 100×40.
Outcome	In this case, the flow did not fluctuate at all around the obstacles with the first order semi-Lagrangian advection.
Outcome	However, when BFECC was added, the flow fluctuated as in the refined grid.
Outcome	We conclude that BFECC creates a physically correct fluctuations in a coarser grid.
Outcome	Velocity advection can also be important when rigid bodies are involved.
Approach	We also apply BFECC to the advection of smoke density for the smoke simulation.
Approach	As is shown in [DL03], BFECC is linearly stable in l 2 sense, i.e., ||a|| l 2 = ∑ |a i j | 2 is bounded, when the velocity field is constant, where a is the smoke density.
Approach	However, density values a i j can become negative or greater than 1.0 for some grid points.
Approach	In our simulation, this problem was not significant and we simply clamped those values to stay in [0, 1].
Approach	To measure the diffusion/dissipation amount, we design a test problem similar to Zalesak’s problem.
Approach	Instead of the notched disk, we place a color image and rotate it 360 degree and then compare it with the original image as is shown in Fig. 5 .
Outcome	As is shown in (d), the dissipation of the color is significantly reduced with BFECC.
Outcome	During the advection, the image is also diffused to neighboring region, even though it is not visible.
Approach	To visualize the diffusion amount, we plot background pixels as blue to show the region where the image has been diffused into.
Outcome	As is shown in (d), the color of the object is little diffused into neighboring region when BFECC is used.
Outcome	Also notice that the size of the image looks smaller and its position is noticeably different from the original location in (c), which is again fixed in (d) where BFECC is used.
Outcome	The computation time was 0.156 sec (without BFECC) and 0.36 sec (with BFECC) per frame on a 3GHz Pentuim4.
Background	Advection is often used for scientific visualization, especially for various forms of flow visualization.
Background	For example, [JEH02] uses semi-Lagrangian advection of dye to visualize the vector field. 
Background	[Wei04] applied level set method to advect dye without diffusion.
Background	Only one dye color is allowed and the dye cannot be diffused at all.
Background	Also level set implementation is needed.
Approach	In contrast, BFECC is trivial to implement and provides advection of fully colored pattern of dye, if necessary.
Outcome	As is shown in Fig. 3 , the dissipation/diffusion is very small.
FutureWork	Thus, we believe that it can be used in flow visualization as well.
FutureWork	This remains as a future work.
Approach	Even though, BFECC still has some volume loss in fluid simulation, especially for small droplets or thin filaments, it is still interesting to show how BFECC performs in the fluid simulation since it is trivial to implement and fast.
Approach	When we use the BFECC for level set advection, i.e., φ = φ , redistancing is needed to keep the level set function as a signed distance function.
Approach	This equation can be solved by applying first order upwinding in discretizing the term w · ∇φ .
Approach	An alternative is the semi-Lagrangian style integration, i.e., φ n+1 = φ n (x − w∆ τ ) + sgn( φ n )∆ τ , where x is the location of each grid point.
Approach	Hence, φ n (x − w∆ τ ) is the φ value of previous location.
Approach	When these integration formulae for (6) are combined with BFECC, the redistancing tends to spoil good φ values computed from the second order accurate BFECC.
Approach	This leads to the idea of turning redistancing off near the interface to keep good φ values there.
Approach	The conditions to turn off redistancing is provided in [DL03], where the significant enhancement were shown for the Zalesak’s problem.
Approach	This simple redistancing is crucial in preserving volume [DL03].
Approach	It is also easy to implement since it simply requires to perform redistancing at the points where at least one of the following two conditions are met.
Approach	• When the grid point is not close to the interface, i.e., when φ i, j has the same sign with its eight neighbors.
Approach	• When the slope is sufficiently high, i.e., when | φ i, j − φ i±1, j | or | φ i, j − φ i, j±1 | ≥ 1.1∆x.
Approach	We test BFECC in different fluid simulations.
Approach	We simulate air-water and olive oil-air interactions.
Approach	Water is rendered as bluish surface and olive oil is rendered in yellowish color.
Approach	We use PovRay ( http://povray.org ) to render images.
Approach	The cup is released upside down near the water surface.
Outcome	Due to its weight, the cup sinks deep into water but it soon rise again because of the air in it.
Outcome	However, in the top, we turned BFECC off for velocity advection and hence the water became dissipative, preventing the cup from tumbling.
Outcome	In the bottom, we use BFECC for velocity advection, where the velocity dissipation is small and hence the cup can tumble 180 degree.
Outcome	This example indicates that reducing velocity dissipation could be important in simulating fluid and rigid body interaction.
Approach	We implement the rigid fluid method [CMT04] to simulate rigid body and fluid interaction in Fig. 1 and 7.
Approach	We use multiple pressure projections to address the seeping problem mentioned in [CMT04].
Outcome	The computation time varies in situations such as the complexity of fluid motions.
Outcome	In simple bubble rising situation without rigid body, it took a few seconds per time step using a 50 3 mesh.
Outcome	The cup example in Fig. 7 has multiple pressure projections and it took about 30 to 130 seconds per time step on a 70 3 grid.
Outcome	We have shown that the BFECC scheme can be used to improve the simulation of fluids.
Outcome	Once the simple first order upwinding or semi-Lagrangian steps for velocity, smoke density, image or level set advections are implemented, BFECC can be added with a trivial amount of code.
Outcome	We show that this simple extension yields significant enhancements in reducing diffusion and dissipation in velocity, smoke, image advection and in preserving volume under various situations including two-phase flows and rigid bodies.

Outcome	This paper presents a system for rapid editing of highly dynamic motion capture data.
Outcome	At the heart of this system is an optimization algorithm that can transform the captured motion so that it satisfies high-level user constraints while enforcing that the linear and angular momentum of the motion remain physically plausible.
Outcome	Unlike most previous approaches to motion editing, our algorithm does not require pose specification or model reduction, and the user only need specify high-level changes to the input motion.
Approach	To preserve the dynamic behavior of the input motion, we introduce a spline-based parameterization that matches the linear and angular momentum patterns of the motion capture data.
Approach	Because our algorithm enables rapid convergence by presenting a good initial state of the optimization, the user can efficiently generate a large number of realistic motions from a single input motion.
Approach	The algorithm can then populate the dynamic space of motions by simple interpolation, effectively parameterizing the space of realistic motions.
Outcome	We show how this framework can be used to produce an effective interface for rapid creation of dynamic animations, as well as to drive the dynamic motion of a character in real-time.
Challenge	Despite great advances in recent years, creating effective tools for synthesis of realistic human motion remains an open problem in computer animation.
Challenge	This is particularly true for synthesis of highly dynamic character motion such as running, leaping, jumping and other athletic and acrobatic maneuvers that frequently occur in feature special effects and video games.
Challenge	Synthesizing such motions can be challenging because any physical inaccuracies in these motions are particularly noticeable.
Background	Both spacetime optimization and controller synthesis approaches have been proposed for direct synthesis of dynamic character motion.
Background	Although these methods do satisfy physical laws, they tend to appear overly smooth and at times robotic.
Challenge	Furthermore, these methods do not provide interactive control, often requiring considerable offline processing time before the animation sequence is generated.
Challenge	In addition, it is difficult to achieve a graceful degradation of realism for the purpose of greater control.
Background	In contrast to direct synthesis, methods based on adaptation of motion capture data produce highly realistic motion, especially in the neighborhood of captured motion samples.
Background	They also run at interactive speeds, as they employ data interpolation techniques.
Background	Unfortunately, these methods require a large number of motion samples.
Background	If the animator wants to interactively control a specific parameter of the animation such as the landing foot position in a particular acrobatic stunt, the need for a large dataset is particularly pronounced: the interpolation techniques would require an already existing family of motion sequences where the only difference in motion is the landing foot position.
Challenge	Gathering such a datataset is not only laborious, but it also requires that the captured family of motions is similar in all other respects (e.g. other landing points, initial and final state, overall style) — an aspect that is quite hard to reproduce by real actors.
Challenge	In fact, the process of generating such parameterized motions is the most challenging aspect of data acquisition for video game production [Buc].
Challenge	In addition, the animators often wish to create non-realistic motions that defy the laws of physics, a space where motion capture simply fails to provide any samples.
Approach	We take the approach to acquiring similar motions is to adapt a single motion sequence several times to synthesize a family of motions that preserve physics constraints.
Approach	Motions created in this manner can satisfy an animator’s exact specifications with a minimum of deviation from the initial motion sequence.
Challenge	Ideally, we would like to use a minimal source of motion data, perhaps a single captured movement, to create a wide range of additional motions.
Background	Recently a number of dynamic motion adaptation methods have been proposed [PW99, ZH99, TSK02, SP04, SHP04], and the work presented in this paper falls into this category.
Challenge	In this paper, we describe the momentum-based motion editing technique.
Outcome	In contrast to the existing methods, our proposed framework is particularly robust to large-scale motion modifications.
Outcome	For example, we can adapt a forward leaping movement, to a collection of leaping movement in different directions including a backward leap, or a 360 ◦ leaping spin.
Outcome	Using our motion editing framework, we show how a family of dynamic movements can be synthesized based on the animator’s needs for interactive control.
Approach	Because our family of motions samples the space widely, satisfies exact constraints, and otherwise deviates minimally from the original source sequence, we can use simple interpolation techniques to allow real-time exploration of this synthetic motion space.
Outcome	We describe a number of real-time animation tools that can be constructed using these synthetic motion families, such as interactive displacement of constraints (e.g. varying foot landing position), as well as inverse control examples such as the determination of the natural volleyball spike that would hit the ball arriving at a specific position in space.
Outcome	In addition, we describe how the same synthetic sampling/interpolation approach can be used to develop realtime controllers for leaping character motion, all synthesized from a single motion-captured leap.
Background	Recent research in computer animation focused on techniques for remapping existing data to given specifications of a new scenario.
Approach	In this paper, we build on the research in both physicsand interpolation-based motion editing methods.
Background	Optimal trajectory methods introduced by Witkin and Kass [WK88] provide a powerful framework for enforcing dynamic constraints while searching for the most favorable motion judged by the objective function.
Background	The dependency on the initial point has been somewhat alleviated by starting out with the captured motion sequence.
Background	Popović and Witkin in 1999 developed a first method that transforms motion capture data while preserving physical properties [PW99].
Background	They found solutions by performing optimizations on the reduced character model.
Background	More recently, editing motion capture data based on spacetime optimization has become a popular strategy for producing realistic character animations [RGBC96, SP04, SHP04].
Background	These methods provide control for modifying data while retaining physically plausible properties of captured motion by restricting the optimization space with additional kinematic constraints (e.g. [RGBC96]), or by solving within the PCA-reduced space of motions [SHP04].
Background	It has recently been shown that relying on simplifications of dynamic constraints is not necessary if proper scaling and estimation of joint angles, torques, and Lagrange multipliers are provided [SP04].
Approach	Our work uses a similar spacetime optimization framework.
Approach	In contrast to other approaches, we formulate significantly simpler momentum constraints on a complex character model, without solving for muscle forces explicitly, similar to [LP02].
Approach	Since we do not compute internal torques for joints, scaling and convergence issues are less critical in our optimization framework.
Approach	Our physics-based motion editing approach is based on the momentum constraints introduced by Liu and Popović [LP02].
Background	In that work, momentum constraints were used for synthesis of highly dynamic motion from simple animations that did not contain sufficient information to synthesize the full motion.
Background	As a result, transition poses had to be introduced to further restrict the optimization space.
Background	There are two main advantages of momentum constraints over the full dynamics constraints.
Approach	First, since dynamic constraints are reduced to only global momentum patterns, we are solving for a much smaller set of unknowns, and over a much “better behaved” set of constraints.
Approach	This allows us to find solutions quickly.
Approach	Also, in our experience, these constraints do not suffer from many local minima, thus enabling us to find solutions significantly further away from the original motion.
Background	The second advantage of momentum constraints is that they encode more about the natural motion than just physical correctness.
Background	For example in natural motion, passive elements such as tendons and ligaments store and release energy during ballistic motion.
Background	To model this with a full dynamic system, one would have to include a complex muscle model.
Background	Momentum constraints effectively record the aggregate effect of the natural torque usage and energy storage/release in a specific momentum pattern.
Background	This additional information embedded within the momentum constraints ensures that adapted motion is not just physically correct, but that it also constrains the motion within the momentum exchange patterns observed in nature.
Approach	In contrast to the original paper that introduced momentum constraints, our method applies momentum constraints directly on the motion capture data.
Approach	Our algorithm does not require any additional pose constraints at the transition points between flight and ground phases.
Approach	Furthermore, we introduce a novel spline-based representation for the momentum patterns that can be used to intrinsically enforce the similarity between the resultant motion and the input motion.
Background	Instead of formulating a physics-based optimization, dynamic filtering is an efficient alternative for motion editing of smaller amplitude.
Background	Per-frame based frameworks largely reduce the computation time, providing an interactive editing interface to the user [TSK02, SKG03].
Background	Unfortunately, the per-frame approach means that animators can modify the spatial position of constraints, but not their position in time.
Background	Tak et al. applied Kalman filter to estimate an optimal pose for the current frame subject to the given constraints.
Background	The result of the estimation is then rectified by least-square-fit to ensure a physically sound motion [TSK02].
Background	Shin et al. approximated the adjustment made to the original motion capture data by correcting the momentum of the character during flight and using the balance constraints on the ground [SKG03].
Approach	In general, these methods are geared toward the local modification compared to the overall motion, such as improving the balance, whereas our approach is able to handle global changes of the motion such as transforming a forward jump to a 360 ◦ backward spin jump.
Background	Another branch of dynamic filtering employs dynamic tracking [ZH99, PR01].
Background	These methods combine motion capture data and dynamic simulation to retain human-like details from the data while presenting interaction with the environment.
Background	These methods produce motions that do not deviate significantly from the input motion, relying on the existence of captured motion that is similar to what the user intends to do.
Background	Straightforward interpolation of joint angles usually fails to preserve physical realism from the original data.
Background	However, many methods have shown that small modification of the motion can be easily done by linear interpolation of joint angles [BW95, WP95, WH97].
Background	Combining interpolation with kinematics constraints, Gleicher adapted original motion to a new character while maintaining environmental constraints such as foot contacts on the floor [Gle98].
Background	A more sophisticated interpolation was presented using radial basis functions to blend motion sequences with various inverse-kinematic goals [RSC01] or different style [RCB98].
Background	Unfortunately, data acquisition and post-processing for these methods present a significant challenge since motion sequences need to be carefully crafted so that they contain the same content yet different in style.
Approach	Our approach only requires one single motion capture sequence as the seed.
Approach	This seed is used to generate a family of motion sequences that parameterize the dynamic space.
Background	Lee and Shin presented a multi-level B-spline representation by which they transform existing motion to satisfy desired constraints adaptively through direct manipulation [LS99].
Background	Using B-spline representation, the motion edits can be limited to user-specified frequency bands, providing a more effective optimization framework.
Approach	Our work adapts the idea of using spline-based representation to constrain the search of the optimization.
Approach	We model the momentum curves by a B-spline representation which are fitted to the original motion so that the search space in the optimization is limited to solutions that have similar dynamic behavior of the original motion.
Approach	Our system is based on an optimization algorithm that can transform the captured motion to satisfy high-level user constraints while preserving physical realism.
Approach	As input, the system takes a single motion capture sequence and the userspecified modification.
Approach	We describe the algorithm in three separate components: Motion pre-fitting, optimization, and interpolation (see Figure 1 ).
Approach	The pre-fitting optimizes a set of coefficients used to model momentum curves so that they are constrained to the similar shapes of the original motion.
Approach	The system then formulates a spacetime optimization that solves for a new motion, where both high-level physical constraints and the user specification are met.
Approach	With a family of such optimized motions that parameterize certain dynamic space, we can apply a simple linear interpolation to generate arbitrary new motion within the dynamic space in real-time.
Approach	Our algorithm adapts the momentum-based constraints [LP02] for the task of motion editing.
Approach	Instead of filling in missing data, motion editing must solve the converse problem of preserving the original data while still satisfying animator-imposed constraints.
Approach	There is no need for keyframing of any kind because the motion already starts in a good initial state.
Approach	Any underlying physical model employed by the system must be flexible enough to precisely describe the initial state of the motion and, at the same time, rigid enough to maintain a semblance of the original motion throughout the editing process.
Approach	At the heart of our algorithm is a set of full-body angular and linear momentum curves.
Approach	These curves constrain the edited motion to the realm of physical realism without the need to simulate expensive dynamical properties such as joint torques and contact forces.
Approach	The momentum curves are parameterized by a set of coefficients that are pre-solved to closely match the input motion.
Approach	The advantage of this approach is twofold.
Approach	First, a good initial state of the momentum coefficients results in rapid convergence of the optimization.
Approach	Second, the coefficients that control the shape of the curves can be fixed throughout the editing process, effectively performing a biased search for similar motions in the momentum space.
Approach	After the motion is captured using an optical system and processed to fit the character’s skeletal structure, we employ the constraint detection technique described in [LP02] to partition the motion into ground-contact and flight stages.
Approach	Since the the animator may at times wish to produce physically impossible jumps that are not constrained to the earth’s gravity, and because the sampling rate varies for each input motion sequence, we also need to determine the time interval between two animation frames.
Approach	Gravity and time step are directly related because we can equivalently choose to find the right gravitational constant that makes the motion realistic for a given unit time step.
Approach	During free-fall stages, the linear momentum is only affected by gravity and the angular momentum remains constant.
Approach	When the body is in contact with external forces, the momentum curves can no longer be represented by a simple set of linear equations.
Approach	Instead, we represent the momentum curves with a 3rd-order non-uniform B-splines for their flexibility and convenient knot based parameterization.
Approach	In our spline representation, the first and last knots have duplicity 4 to ensure interpolation of the end points (see [FvDFH92]).
Approach	A defining characteristic of motion is the shape and magnitude of its momentum curve (see Figure 2 ).
Approach	In the case of our spline representation, the control points determine the magnitude of the curve and the spacing of the knots influence the shape.
Approach	We note that this formulation can capture a greater variability of momentum patterns than the previously used hardwired patterns [LP02].
Approach	This is especially important when dealing with motion capture data due to wide range of different maneuvers possible in the real world.
Approach	In other words, we perform a least-squares regression over the momentum curve in the ground stage, while maintaining C 1 continuity through the transitions to the flight stages.
Approach	There are few exceptions to the problem described above.
Approach	When there is no adjacent flight stage, we remove the constraint corresponding to v i from the statement of the problem.
Approach	Also, the constraint corresponding to v 0 is entirely removed when pre-fitting the vertical linear momentum curve since the transition from a free-fall stage to a ground stage is typically dominated by impulsive forces, which are not C 1 continuous in the vertical momentum component.
Approach	As in [LP02] we model motion as an optimal dynamic process with a set of realistic constraints.
Approach	In general terms, our condition for optimality is that the output motion be both as smooth, and as similar, to the original motion as possible.
Approach	Constraints on the solution ensure that the character’s limb do not bend unnaturally, that the character’s feet do not pass through the ground, and that the character’s full-body momentum curve follows the path of the pre-fit momentum splines.
Approach	The degrees of freedom to be optimized are contained in Q G, where Q is the set of joint angles through time describing the motion and G is the set of the control points controlling the momentum splines.
Approach	In the initial state of the optimization, Q is a good initial guess at the target motion formed by linearly interpolating the original motion between user specified translations and orientations, and G contains the pre-fit momentum coefficients.
Approach	In addition to the constraints and objectives used in [LP02], we also introduce a similarity objective and a pseudo balance objective as described in the following sections.
Approach	The similarity objective is intended to keep the optimized motion as similar to the original as possible.
Approach	We formulate this objective as the squared distance between the original vector of DOFs, Q init , and the solution vector, Q. Each joint DOF is scaled by its natural bound.
Approach	The energy function we wish to minimize is then, E s (Q) = (Q init − Q) 2
Approach	Since we do not model the specific human preference to stay out of extreme leaning movements that in real life can often cause foot slipping on the ground, there are some instances when the resulting motion would leave the character unnaturally leaning without a means of support.
Approach	To pull the optimized solution away from these unstable regions, we include a pseudo balance objective.
Approach	The objective we use attempts to minimize the squared distance between the COM, C(t) of model in the first time-step, t 0 , and last timestep, t f , of the initial and final ground stages of the motion.
Approach	For interior ground stages, we instead minimize the distance between the COM of the model in the middle frame of the stage, C(t m ), and the COM of the linearly interpolated input motion, C orig (t m ), in the same frame.
Approach	To summarize, the unknowns of our system, Q and G, are the character DOFs and the control points for the momentum splines.
Approach	Note that spline knots are omitted to maintain the similar momentum pattern of the original motion.
Approach	The optimization enforces two types of constraints: environment constraints, K e , such as feet positions on the ground, and momentum constraints, K m .
Approach	The following spacetime formulation finds the unknowns Q and G that minimize the objective function while satisfying all the constraints: min Q,G E s (Q) + E b (Q) subject to K K e m (Q) (Q, G) = = 0 0
Approach	Our system provides several high level motion specification tools so that the animator never has to think of editing in terms of constrained optimization.
Approach	First, motions are automatically partitioned into alternating flight and ground stages.
Approach	Alternatively, the user can manually adjust the partitioning to make corrections.
Approach	Next, the user manipulates ground stages with the mouse to translate their position and turns a dial to change the orientations as desired.
Approach	The system treats these specifications as offsets from the original state of a ground stage.
Approach	In other words, given the original translation, q T , and original orientation, θ, of the ground stage, the user specifies offsets ∆q T and ∆θ.
Approach	The new translation and rotation of the ground stage is then altered to be q T + ∆q T and θ + ∆θ, respectively.
Approach	To form a good initial guess at the solution for the frames of the flight stages, the system linearly interpolates the offsets of the adjacent ground stages over each time step of the flight stage.
Outcome	The resulting motion is a crude approximation of the final result, but provides a good initial state for the spacetime optimization.
Approach	The animator can also change the height of the trajectory in a flight stage by interactively shaping a visualization of the trajectory.
Approach	This is particularly useful when creating non-realistic motion that defies gravity, as will be explained below.
Approach	Once the user is satisfied with the edits, the optimization process takes between 1 to 5 minutes per motion.
Approach	Alternatively, several motions can be generated together in a batch mode.
Approach	The technique constructs an output motion in real-time by performing a simple weighted average over the DOFs values from a set of sample motions.
Approach	A family of motions can be populated from the input motion by systematically varying the position and orientation of one or more ground stages and then performing a sequence of similar optimization.
Approach	We provide a user interface for the three most useful types of motion families(see Figure 3 ).
Approach	The first type varies the translation of a ground stage along a line, the second type varies the translation of the ground stage along a 2 dimensional grid, and the third type varies both the translation and orientation of the ground stage along a semi-circle such that the orientation of the character is consistently aligned along the normal vector of the arc.
Approach	The size of the sample space as well as the density at which it is sampled can both be adjusted as necessary.
Approach	Other types of motion families can be easily added.
Approach	Once a motion family is populated, we are able to generate arbitrary intermediary motions by blending the nearest 2 n samples, where n is the number of dimensions in the parameterized space.
Approach	We chose to use a simple linear blending method for several reasons.
Approach	First and foremost, the algorithm is very fast and well suited to any application where the output motion must be generated “on the fly”.
Approach	Since motion families are produced offline, they can be as densely populated as necessary to increase the accuracy of the interpolation.
Approach	Second, since the members of a motion family are produced by the same optimization setup, varying only in specific dimensions (e.g. landing positions, height, orientation, etc), it is often the case that they blend very well and need not be sampled very densely at all.
Outcome	In our results section, 9 samples is the most we ever required to adequately sample the dynamic space of a motion.
Approach	Although foot glide is among the most troublesome artifacts for most motion blending techniques, we find that it is imperceptible for both the line and grid motion families.
Approach	However, when the global orientation and the translation of the motion are interpolated simultaneously, as is the case in the circle motion family, a very miniscule amount of foot glide becomes perceptible.
Approach	A simple fix is to apply a per-frame inverse kinematic (IK) solver to slightly adjust the lower body to satisfy the positional constraints on each foot.
Approach	Solving IK on the lower body not only has the effect of planting the foot firmly on the ground without changing the overall looks of the motion, but is also light-weight enough to converge in real-time, as the motion is being displayed.
Background	In many applications the most important aspect to control is the position and time at which the character makes contact with an object in the environment.
Approach	Consider the example of a soccer header motion, where it is required that the character’s head always makes contact with the soccer ball at the correct moment in time.
Approach	Starting from a single input motion we can generate an arbitrary header by creating a grid motion family that varies the translation of the landing stage.
Approach	The joint configuration at each time-step in the output motion is then defined as a vector function q(x, y,t) of the landing position, (x, y), and the time-step, t.
Approach	If we denote the position of the character’s head by the function h(q), the problem of finding the motion that constrains the characters head to ball position p c at time t c , is reduced to that of finding values (x, y) such that p c = h(q(x, y,t c )).
Approach	This is, in turn, analogous to minimizing the energy function E(x, y) = (p c − h(q(x, y,t c ))) 2 , which can be solved efficiently by a simple gradient descent method.
Approach	The gradients are computed using finite differences.
Approach	One caveat is that q is actually a piecewise function that performs a bi-linear interpolation of the 4 nearest sample motions.
Approach	When one sample motion is replaced by another in the set of 4, q ceases to be C 1 continuous, causing convergence problems with the gradient descent method.
Approach	A simple solution is to replace the linear blending functions f (x) = x and g(x) = (x − 1) with smooth in/out functions such as f (x) = sin 2 (x) and g(x) = cos 2 (x), thereby maintaining C 1 continuity through the transitions.
Outcome	One advantage of our motion generation algorithm is that it provides for a wide range of physically plausible animations in real-time.
Approach	To demonstrate the full benefit of this approach, we have created a video game interface where the user controls the trajectory of a jumping character with a multi-directional control pad (see Figure 6 ).
Approach	We start with a motion capture sequence of a character making two consecutive jumps.
Approach	The interesting aspect of this motion is that the character must exhibit foresight in the motion of the first jump, so that the correct contact forces can be generate in the intermediate ground stage, to create the necessary momentum for the second jump.
Approach	Our approach inherits the same key benefit from spacetime, but allow us generate motions in realtime.
Approach	In this demonstration we wish to control the horizontal translation vectors of the first and second jumps, d 1 and d 2 , respectively.
Approach	First we generate a motion family by varying both the first and last ground stages along a 3x3 grid.
Approach	The entire motion family then consists of 81 optimal motions resulting from permuting the 9 possible starting positions with 9 possible ending positions.
Approach	This is necessary in order to sample the entire range of possible ground stage transitions between the two jumps.
Approach	We are then able to populate the space between sampled motions by linearly interpolating the nearest neighbor optimal solutions.
Approach	In this case, we have 4 dimensions in our sample space corresponding to the values of d 1 and d 2 , making for a total of 2 4 (or 16) nearest neighbor motions.
Approach	Therefore, we can express the output motion as vector function q(d 1 , d 2 ), whenever d 1 and d 2 are within the bounds of the sample space.
Approach	To make our demonstration even more interesting, we chain our jumping motion end to end, such that it continuously loops upon itself.
Approach	This is done by blending the second flight stage of the first motion, q a (d a1 , d a2 ), into the first flight stage of the second motion,q b (d b1 , d b2 ).
Approach	In order to make the blending work, we simply require that d a2 = d b1 .
Approach	In order words, we require the length and direction of the blended jumps be the same.
Outcome	The end result is an interactive jumping simulation where the user controls the direction that the character jumps and then sees the motion carried out in a physically plausible manner.
Approach	Due to the foresight discussed earlier, the character must always have prior knowledge of the next two directions it will jump.
Outcome	This causes some lag time between when the user specifies a direction and when that motion will occur, but this is only natural given the deterministic nature of the ballistic motion.
Approach	The motion sequences in our demonstration were captured at 120 frames per second using an optical motion capture system.
Approach	The character is composed of 18 rigid links and 43 degrees of freedom.
Approach	S0(3) rotations are expressed in exponential map representation.
Approach	The mass distribution of the model is an appropriately scaled version of the population average as obtained from [dL96].
Approach	We used SNOPT [GSM96], a nonlinearly-constrained optimization package, for solving spacetime optimization, as well as for pre-fitting the momentum curves.
Approach	Most edits shown in the accompanying video clips were done in less than 1 minute.
Outcome	The optimization process for each motion took on the order of 2 to 4 minutes to fully converge on a 2Ghz Pentium 4 machine (see Table 1 ).
Outcome	Our system provides a set of UI tools to help the user rapidly specify modifications to existing motions.
Approach	In a hopping example, the animator interactively manipulates the position, height, and orientation of each ground stage.
Approach	The character must cover a longer distance, reach a greater height and assume a new orientation in the modified hopping motion, so she must lower her center of mass, lean farther to the right, and pivot slightly in preparation for the take-off.
Outcome	Despite these changes, the resultant motion remains stylistically similar to the original.
Approach	To show that our system is capable of making drastic changes from the original motion, we edited the same hopping motion to exhibit a 360 ◦ spin followed by a 180 ◦ spin in the opposite direction(see Figure 5 ).
Approach	In order to demonstrate real-time motion interpolation we modified a motion with two consecutive leaps.
Approach	We let the user control the landing and take-off positions along an evenly spaced grid to generate a set of parameterized motions.
Approach	Since the interpolation can be performed in real-time, we are able to generate a jumping motion with arbitrary takeoff and landing positions within the parameterized space in an interactive fashion.
Approach	Another example shows a soccer header motion observed to miss its target.
Approach	First, we correct the motion by increasing the height of the jump to meet the ball at the point of contact.
Approach	Next, we use our editing algorithm to generate a motion family parameterized over the space of the landing position of the motion.
Approach	By interpolating between the optimal motions, we are able to generate arbitrary intermediary motions where the character contacts the ball at any location within the sampled space, in real-time.
Approach	A more intuitive way to edit motion capture data with arbitrary positional constraints is to use our real-time inverse control mechanism.
Approach	In the volleyball slam example, the user interactively specifies the position of the character’s hand in mid-flight.
Outcome	Our system immediately determined the correct linear interpolation of 4 nearest neighbor samples to meet the positional constraint on the hand.
Outcome	The brightness of the sample motions on the floor indicates the weights associated with each sample.
Approach	We used 9 sampled motions which are all edits of the same input sequence.
Outcome	The demonstration shows various slam motions being generated in real-time by using the trajectory of the volleyball to guide the character’s motion.
Outcome	Our system can also be used to create a class of nonrealistic motions that allow the character to exhibit superhuman strength and to defy the laws of physics.
Approach	Consider an example where we wish to edit a jumping motion to reach a higher mid-point in the same time span as the the original motion.
Approach	The first observation to make is that this is physically impossible without altering the gravitational constant, which dictates the maximum rate at which the character returns to the ground from the height of the jump.
Approach	In our system it is easy to alter the gravitational constant in one or more ground stages.
Approach	Still, the character must gain the momentum required to achieve the specified height on takeoff and, subsequently, absorb the same amount of momentum on landing.
Approach	This requires a super-human muscle strength, but since we do not directly model muscle forces, and we place no limits on their magnitude, our system can easily handle these imaginary circumstances.
Background	From the animators perspective, editing non-realistic motion is the same as editing any other motion.
Approach	To increase the height of a flight stage, the animator simply manipulates a visualization of the trajectory of the motion in the flight stage to the required height, and then specifies whether the system should change gravity or, alternatively, the total time in the flight stage.
Approach	If the animator chooses to leave the gravity unaltered, the system increases the length of the time-step in each frame of the flight stage and then continues the editing process as normal.
Outcome	In one example, we edited a forward jump into a 2-meter-long backward jump (see Figure 7 ).
Approach	This work builds on the research in both physics-based motion synthesis and interpolation-based motion editing approaches.
Outcome	In this paper we suggest that using physics-based adaptation to create motion samples for the purpose of data interpolation is perhaps a "sweetspot" between these two approaches.
Outcome	Once the dataset is created, this paradigm allows animators to interactively edit the realistic dynamic motion.
Outcome	The primary contribution of this work is a new momentum-based method for adaptation of ballistic character movement.
Outcome	In contrast to previous dynamic-based adaptation methods, our framework can produce an wide range of motions that are significantly different from the original motion.
Outcome	Our method does not require model reduction, or a reduced motion space.
Outcome	Because we do not solve for the generalized forces for each joint angle, our method is also significantly faster than other physics-based transformation methods.
Outcome	This speed allows us to create a large number of motions within a reasonable time.
Outcome	Once the family of parameterized motion samples has been generated, we describe an interactive framework where the animator can explore the space of realistic motions.
Outcome	We also show how the same framework can be adapted for inverse control.
Outcome	Finally, we show how real-time data-driven controllers for realistic human motion can be constructed from a single motion capture sequence.
Outcome	Naturally, our framework does not handle all realistic character motions.
Outcome	It specifically applies to highly-dynamic motions with ballistic stages.
Outcome	We suspect that momentumbased approach would not be well suited for less energetic motions such as walking.
Outcome	Furthermore, the number of samples required is exponentially proportional to the number of dimensions, thus the current framework is hindered by the offline computation of a large dataset.
Outcome	There are several ways to facilitate the computation by taking advantage of the fact that we are solving a sequence of very similar problems.
FutureWork	A more intelligent sampling strategy is essential for generalizing our approach to a multi-dimensional dynamic space.
Outcome	Because our model does not account for realistic muscle strength, and friction during ground contact there are some extreme cases which do not produce realistic motion.
FutureWork	Adding heuristics such as balance during contact can to a large extent eliminate these problems.

Challenge	An ambitious goal in the area of physics-based computer animation is the creation of virtual actors that autonomously synthesize realistic human motions and possess a broad repertoire of lifelike motor skills.
Challenge	To this end, the control of dynamic, anthropomorphic figures subject to gravity and contact forces remains a difficult open problem.
Challenge	We propose a framework for composing controllers in order to enhance the motor abilities of such figures.
Outcome	A key contribution of our composition framework is an explicit model of the “pre-conditions” under which motor controllers are expected to function properly.
Approach	We demonstrate controller composition with pre-conditions determined not only manually, but also automatically based on Support Vector Machine (SVM) learning theory.
Approach	We evaluate our composition framework using a family of controllers capable of synthesizing basic actions such as balance, protective stepping when balance is disturbed, protective arm reactions when falling, and multiple ways of standing up after a fall.
Outcome	We furthermore demonstrate these basic controllers working in conjunction with more dynamic motor skills within a prototype virtual stuntperson.
Outcome	Our composition framework promises to enable the community of physics-based animation practitioners to easily exchange motor controllers and integrate them into dynamic characters.
Challenge	Despite the considerable history of progress in animating virtual humans [ 3 , 7 ], physics-based animated characters with a large repertoire of motor skills have so far been elusive.
Background	This may seem surprising in view of the recent successes in implementing a slew of specialist controllers capable of realistically synthesizing the complex dynamics of running, diving, and various gymnastic maneuvers [ 16 ].
Background	While a divide-and-conquer strategy is clearly prudent in coping with the enormous variety of controlled motions that humans and other animals may perform, little effort has been directed at how the resulting control solutions may be integrated to yield composite controllers with significantly broader functionalities.
Challenge	For example, if researcher A creates a walking controller for a dynamic character while researcher B creates a running controller for the same articulated model, it would be beneficial if they could share their controllers (perhaps through an e-mail exchange) and easily create a composite controller enabling the character to both walk and run.
Challenge	This is a difficult problem, but its resolution would help pave the way towards controller libraries for dynamic animation which communities of practitioners could utilize and to which they could contribute.
Challenge	In this paper, we propose a simple yet effective framework for composing specialist controllers into more general and capable control systems for dynamic characters.
Approach	In our framework, individual controllers are black boxes encapsulating control knowledge that is possibly gleaned from the biomechanics literature, derived from the robotics control literature, or developed specifically for animation control.
Approach	Individual controllers must be able to determine two things: (1) a controller should be able to determine whether or not it can take the dynamic character from its current state to some desired goal state, and (2) an active controller should be able to determine whether it is operating nominally, whether it has succeeded, or whether it has failed.
Approach	Any controller that can answer these queries may be added to a pool of controllers managed by a supervisor controller whose goal is to resolve more complex control tasks.
Outcome	An important technical contribution within our controller composition framework is an explicit model of pre-conditions.
Approach	Preconditions characterize those regions of the dynamic figure’s state space within which an individual controller is able to successfully carry out its mission.
Approach	Initially, we demonstrate the successful composition of controllers based on manually determined pre-conditions.
Approach	We then proceed to investigate the question of whether pre-conditions can be determined automatically.
Approach	We devise a promising solution which employs Support Vector Machine (SVM) learning theory.
Approach	Our novel application of this technique learns appropriate pre-conditions through the repeated sampling of individual controller behavior in operation.
Approach	As a testbed of our techniques, we are developing a physicallysimulated animated character capable of a large repertoire of motor skills.
Outcome	An obvious application of such a character is the creation of a virtual stuntperson: the dynamic nature of typical stunts makes them dangerous to perform, but also makes them an attractive candidate for the use of physics-based animation.
Challenge	The open challenge here lies in developing appropriate control strategies for specific actions and ways of integrating them into a coherent whole.
Challenge	In this paper, we demonstrate families of composable controllers for articulated skeletons whose physical parameters reflect anthropometric data consistent with a fully-fleshed adult male.
Approach	One family of controllers is for a 37 degree-of-freedom (DOF) 3D articulated skeleton, while a second family of controllers has been developed for a comparable 16 DOF 2D articulated skeleton.
Approach	While the 3D skeleton illustrates the ultimate promise of the technique, the easier control associated with the 2D skeleton allows for more rapid prototyping of larger families of controllers and more careful analysis of their operation.
Challenge	As has been recognized in the robotics literature, the control of broad skilled repertoires of motion remains very much an open problem even for 2D articulated figures.
Outcome	The upright balancing dynamic figure is pushed backwards by an external force; its arms react protectively to cushion the impact with the ground; the figure comes to rest in a supine position; it rolls over to a prone position, pushes itself up on all fours, and rises to its feet; finally it balances upright once again.
Outcome	A subsequent disturbance will elicit similar though by no means identical autonomous behavior, because the initial conditions and external forces will usually not be exactly the same.
Outcome	Control sequences of such intricacy for fully dynamic articulated figures are unprecedented in the physics-based animation literature.
Challenge	The simulation and animation of human characters is a challenging problem in many respects.
Challenge	Comprehensive solutions must aspire to distill and integrate knowledge from biomechanics, robotics, control, and animation.
Challenge	Models for human motion must also meet a particularly high standard, given our familiarity with what the results should look like.
Challenge	Not surprisingly, a divide-and-conquer strategy is evident in most approaches, focusing efforts on reproducing particular motions in order to yield a tractable problem and to allow for comparative analysis.
Background	The biomechanics literature is a useful source of predictive models for specific motions, typically based on experimental data supplemented by careful analysis.
Background	These models target applications such as medical diagnosis, the understanding and treatment of motor control problems, the analysis of accidents and disabilities, and high-performance athletics.
Background	Computer simulation is becoming an increasingly useful tool in this domain as the motion models evolve to become more complex and comprehensive [ 26 , 27 , 29 ].
Background	Given the challenge of achieving high-fidelity motion models for individual motions, there have been fewer efforts towards integrated solutions applicable to multiple motions.
Background	Reference [ 26 ] is one such example.
Background	Robotics research has made remarkable progress in the successful design of a variety of legged robots [ 28 ] and, more recently, bipedal robots with anthropomorphic aspirations [ 23 ].
Background	Despite their limited motion repertoires and rather deliberate movements, these robotic systems are truly engineering marvels.
Background	The work in [ 1 ] provides a good summary of behavioral architectures explored in the context of robotics.
Background	A 3 DOF ball-juggling robot is described in [ 6 ] which uses a theory of behavior composition, although the practicality of extending the method to high-DOF dynamic models of human motions is unclear.
Background	Computer animation is to a large extent unencumbered by the exacting fidelity requirements of biomechanical models and the mechanical limitations of robotic systems.
Background	This has spawned a great variety of kinematic and dynamic models for character motion [ 3 , 4 , 7 ].
Background	While motion capture solutions based on blending and warping techniques may give satisfactory results for such tasks in the short term, controller based approaches reveal more about the physics, planning, and control of such motions and they therefore serve as a basis for more general solutions.
Background	Dynamically simulated characters were first proposed over 15 years ago [ 2 , 34 ] and since then have progressed in sophistication in a variety of directions.
Background	Controllers have been successfully designed for specific human motions such as walking, running, vaulting, cycling, etc. [ 16 , 22 , 35 ].
Challenge	Dynamically simulated articulated characters equipped with an integrated, wide-ranging repertoire of motor skills currently remain an unachieved goal.
Background	Some positive steps in this direction are evident, however.
Background	Examples include an integrated repertoire of motor controllers for biomechanically animated fish [ 30 ], a methodology for controller design and integration applicable to simple figures [ 32 ], a demonstration of successful integration for selected diving and gymnastic motions [ 35 ], and adapting a controller designed for one character to work on another character [ 17 ].
Background	The work of Wooten [ 35 ] is the most relevant as an example of a sequence of successive transitions between several controllers for human motions such as leaping, tumbling, landing, and balancing.
Background	Transitions are realized by including the end state of some controllers in the starting states of other controllers.
Background	This currently remains ambitious work in progress.
Challenge	Our work is aimed at creating dynamic human characters with broadly integrated action repertoires.
Approach	Unlike previous work focusing on specific athletic movements, our methodology is to begin with a core set of simple actions, including balancing, small steps, falling reactions, recovery from falls, standing up from a chair, and others.
Approach	In the present paper, we do not cover in any appreciable detail the design of individual controllers to effect such basic actions.
Outcome	1 Rather, our contribution here is a framework for composing individual controllers, however they may be designed, into more capable control systems for dynamic characters.
Outcome	Our pre-condition learning algorithm adds to the growing body of learning algorithms that have been successfully applied in the context of computer animation in recent years [ 14 , 15 ].
Approach	In our controller composition framework, we consider individual controllers as black boxes which are managed by a simple supervisor controller.
Approach	When no controller is active, the supervisor polls the pool of controllers, querying each whether it can handle the transition of the dynamic character from its current state to the desired goal state.
Approach	Individual controllers return an integer confidence/suitability score when queried in order to bid on becoming the active controller.
Approach	In our implementation, controllers that can perform a sensible action given the current state of the character return an integer in the range 1⁄2 1⁄21⁄4 , while those that can handle the current state as well as guarantee a transition to the desired state, return an integer in the range 1⁄21⁄4 3⁄41⁄4 .
Approach	Lastly, a value of 1⁄4 means that a controller is unsuited for the current state.
Approach	The controller that returns the highest score becomes active.
Approach	While this scoring scheme potentially allows for a nuanced evaluation of the controller suitability in terms of criteria such as probability of success or energy used, our current controllers resort to a simpler scheme.
Approach	This consists of a binary success/failure evaluation multiplied by a weighting factor assigned to each controller that serves to establish a relative preference ordering.
Approach	It does not appreciably burden the controller design task.
Approach	Each controller can be as primitive or as sophisticated as its designer wishes.
Approach	A controller within the pool of available controllers can be as simple as a constant force, or as complex as a structured hierarchy of multiple levels of control abstraction.
Approach	For example, as more controllers are added to the system, we may wish to group all the walking and running controllers together into a cluster that can be treated as one encapsulated controller.
Approach	Regardless of the encapsulation, our composition method requires controllers to define pre-conditions, post-conditions and expected performance.
Approach	Pre-conditions are a set of conditions over the state of the character and the environment.
Approach	If these conditions are met then the controller can operate and possibly enable the character to satisfy the post-conditions.
Approach	Assuming that the pre-conditions were met, the post-conditions define a range of states for the final state of the character after the execution of the controller.
Approach	In other words the controller realizes a mapping between a domain of input states to a range of output states for the character.
Approach	Because of unexpected changes in the environment, this mapping may not always succeed, which motivates the notion of expected performance.
Approach	The controller should be able to evaluate its performance in order to detect failure at any point during its operation.
Approach	To do this, the controller must at all times have knowledge of the current and expected state of the character or the environment.
Approach	Defining the pre-conditions, post-conditions, and expected performance for complex characters, motions, and environments is not a straightforward task.
Approach	However, we believe that the effort required to generate these specifications is a fair and necessary price to pay to achieve the benefits of composability.
Approach	Controllers that adhere to these specifications can form a pool of available controllers managed by the supervising controller.
Approach	The position and velocity of the center of mass are denoted as and respectively.
Approach	The base of support of a figure (often called the support polygon) is denoted as Ë .
Approach	It is represented by a polygon that surrounds the foot or feet that are in contact with the ground at any given time.
Approach	In general, pre-conditions are relationships and constraints involving several different parameters.
Approach	Most of our controllers can operate within a small region of the state space which we denote Ê  ́ Õ μ .
Approach	These include the contact points between the character and the ground, as well as the normal of the ground and the amount of friction at the contact points.
Approach	Usually, this is indicated by the relative position and velocity between the figure’s center of mass and the base of support.
Approach	Typically, if the projection of along the gravity vector does not intersect the base of support Ë , the figure is considered to be unbalanced.
Approach	We denote the balance conditions as  ́ Ë μ .
Approach	Successful operation of a controller brings the character from an initial state, as defined by the pre-conditions, to a desired state or a desired region Ê  ́ Õ Ó μ in the state space.
Approach	In general, however, the post-conditions are different from the pre-conditions.
Approach	For example, while a pre-condition for a falling controller requires that the center of mass be moving, the postconditions require that the center of mass be at rest.
Approach	Our framework permits the automatic selection of the appropriate controller based on the information provided by the controllers themselves.
Approach	Only the individual controllers can detect whether they are operating normally or whether failure is imminent.
Approach	Failure in our case means that the controller cannot meet its post-conditions Ç .
Approach	The controller may fail because of a sudden change in the environment or because of badly designed pre-conditions.
Approach	The sooner a controller can detect failure the sooner another more appropriate controller can take over.
Approach	This is important for making a character behave naturally.
Approach	For example, the character should not attempt to continue a walking gait if it has lost its balance and it is falling.
Approach	In our implementation, the expected performance consists of expressions similar to those of the pre-conditions È .
Approach	In particular if the controller successfully completes its task in the time interval Ø 1⁄2 , Ø 3⁄4 , then  ́ Ø 1⁄2 μ 3⁄4È and  ́ Ø 3⁄4 μ 3⁄4Ç .
Approach	Transitions between controllers are not explicitly modeled as they would be in a finite state machine.
Approach	They occur implicitly in response to the evolution of the motion over time, as the system state traverses the “regions-of-competency” of the various controllers.
Approach	Nevertheless, given that most controllers are designed for specific situations, typical patterns of controller activation occur.
Approach	For example, the controllers and transitions used in achieving the motion shown in Fig. 1 is given by balance fall default rollover prone-tostanding balance.
Approach	For example, the prone-to-standing fall transition can occur if the figure is given a sufficiently strong push while rising.
Approach	Most of the transitions which are not shown but are still practically feasible are of this nature, dealing with falling behaviors.
Approach	Note that the fall controller always responds to the specific direction of the current fall.
Approach	Any transition involves one controller being deactivated and another being activated.
Approach	A controller can become deactivated (and thereby elicit a transition) for one of three reasons.
Approach	First, it may relinquish control by declaring success upon reaching its postcondition, as is the case for a standup controller which has successfully returned the character to a standing position.
Approach	Second, user intervention may elicit a transition.
Approach	The controllers designed for sitting or balanced standing will retain control until intervention by a user (or by a higher level planner) forces a desired transition.
Approach	Thus, when the 2D character is balanced a user-driven process must choose among the next plausible actions, namely one of sit, walk, or dive (see Fig. 4 ).
Approach	Third, a controller may detect failure, as will be the case for unpredictable events such as a push or an unforeseen obstacle causing the character to trip.
Approach	The transitions in Figs. 3 and 4 are labelled according to the type of controller deactivations which typically elicit the given transition patterns.
Approach	We note that our framework is designed to work in interactive settings.
Approach	As such, controllers typically start with slightly different initial conditions each time they are invoked, the user can interact with the character at any time, and generally there are no guarantees that the controller will reach the same end state each time it operates.
Approach	As a result, the transition graph is dynamic in structure.
Challenge	For controllers associated with complex dynamic characters, determining the exact region of the state space and the general conditions that determine success or failure of the controller is in general a non-trivial matter.
Approach	The manual approach allows designers to incorporate their knowledge within controllers, whereas the automatic approach is based on machine learning techniques.
Background	For certain cases, suitable pre-conditions for specific controllers may be found in the biomechanics literature [ 8 , 25 ].
Background	For example Pai and Patton [ 25 ] present a comprehensive study of balance in the sagittal plane and identify the conditions under which a human can compensate for postural disturbances and maintain balance without stepping.
Background	For certain other cases, the pre-conditions are trivially defined by the desired motion itself.
Background	Certain controllers function as intermediate stages between other controllers.
Challenge	In any case, the designer of a controller presumably understands the way the controller operates, and thus is able to provide high level conditions on its success or failure.
Challenge	For example, the designer of a walking controller knows if the controller can operate when the walking surface has minimal friction properties.
Challenge	Also, human motion is shaped by notions such as comfort, and only the designer can take this into account.
Challenge	For example, if a person is pushed while standing he/she might take a protective step because it may be more comfortable to do so instead of maintaining an inverted pendulum balancing strategy.
Background	Similarly, the way people react to slipping and imbalance and the protective behaviors they employ are largely age dependent.
Approach	In this section, we introduce an automatic, machine learning approach to determining pre-conditions, which is based on systematically sampling the performance of controllers.
Approach	Our method uses a machine learning algorithm attributed to Vapnik [ 33 ] known as Support Vector Machines (SVMs), which has recently attracted much attention, since in most cases the performance of SVMs matches or exceeds that of competing methods.
Background	SVMs are a method for fitting functions to sets of labeled training data.
Background	The functions can be general regression functions or they can be classification functions.
Approach	In our application, we use simple classification functions with binary outputs which encode the success or failure of a controller.
Background	Burges [ 5 ] provides an excellent tutorial on SVMs.
Approach	Mathematically, we are given Ð observations, each consisting of an dimensional vector Ü 3⁄4 1⁄2 Ð and the associated “truth” Ý 3⁄4   1⁄2 1⁄2 provided by a trusted source.
Approach	Here, Ý 1⁄2 labels a positive example—in our application, the observed success of a controller applied when the dynamic figure is in state Ü — while Ý   1⁄2 labels a negative example—the failure of the controller applied to state Ü .
Approach	The set of observations Ü Ý is called the training set.
Approach	The SVM is a machine whose task is to learn the mapping Ü Ý from a training set.
Approach	The SVM is defined by functional mappings of the form Ü  ́ Ü « μ , where « are parameters.
Approach	A particular choice of « generates a “trained” SVM.
Approach	In a trained SVM, the sign of the decision function  ́ Ü μ represents the class assigned to a test data point Ü .
Approach	In our application, a properly trained SVM predicts if a controller will succeed (  ́ Ü μ 1⁄4 ) or fail (  ́ Ü μ 1⁄4 ) on a given state Ü of the dynamic character.
Approach	How does one train an SVM?
Approach	In the simplest case of a linear SVM with separable training data, there exists a decision boundary separating positive from negative examples which takes the form of a “separating hyperplane” in .
Approach	The SVM training algorithm computes the separating hyperplane with the largest margin · ·   , where · (   ) is the shortest distance from the separating hyperplane to the closest positive (negative) example.
Approach	SVM training requires the solution of a quadratic programming optimization problem involving a Lagrange multiplier « for every datapoint in the training set.
Approach	Those datapoints in the solution with corresponding « 1⁄4 are called support vectors.
Approach	The support vectors are critical elements of the training set.
Approach	They lie closest to the separating hyperplane.
Approach	If other observations in the training set are moved (subject to certain restrictions) or removed and SVM training is repeated, the same separating hyperplane will result.
Approach	To use a trained SVM, we simply determine on which side of the decision boundary a given test data point Ü lies and assign the corresponding class label to that point.
Approach	The linear SVM is easily generalized to nonseparable training data.
Approach	Furthermore, it is straightforward to generalize the theory to encompass nonlinear SVMs for which the decision boundaries are no longer hyperplanes (i.e., the decision function are no longer linear functions of the data).
Approach	The trick, in principle, is to map the data to some higher (possibly infinite) dimensional space in which the linear theory can be applied.
Approach	This is easily done by introducing kernel functions Ã  ́ Ü Ü μ , such as the polynomial kernel Ã (RBF)  ́ Ü Ý kernel μ  ́ Ü Ã ¡  ́ Ü Ý · Ý μ 1⁄2μ Ô , ÜÔ ́ or the   Ü Gaussian   Ý 3⁄4 3⁄4 or 3⁄4 μ radial .
Approach	To apply the SVM technique to the problem of determining controller pre-conditions, we train a nonlinear SVM classifier to predict the success or failure of a controller for an arbitrary starting state.
Approach	Thus, the trained SVM demarcates the boundary of regions in the figure’s state space wherein the controller can successfully do its job.
Approach	Training sets comprising examples Ü Ý are generated by repeatedly starting the dynamic figure at a stochasticallygenerated initial state Ü , numerically simulating the dynamics of the figure under the influence of the controller in question, and setting Ý ·1⁄2 if the controller succeeds or Ý   1⁄2 if it fails.
Approach	The distribution of the stochastically-generated initial states is of some importance.
Approach	The sample points should ideally be located close to the boundaries which demarcate the acceptable precondition region of state-space.
Approach	However, these boundaries are in fact the unknowns we wish to determine and thus we must resort to a more uniform sampling strategy.
Approach	Unfortunately, the high dimensionality of the state-space precludes regular sampling.
Approach	A shortduration simulation (typically 0.3s) is then carried out from this initial state while a randomized perturbation process is executed.
Approach	This currently consists of applying an external force of random (but bounded) magnitude and random direction to the center-of-mass of the pelvis.
Approach	Simultaneously, the character’s joints are perturbed in a stochastic fashion by setting randomized offset target angles for the joints and using the character’s PD joint controllers to drive the joints towards these perturbed positions.
Approach	While the perturbation strategy is admittedly ad-hoc, we have found it to be effective in sampling the pre-condition space, as is validated by the online use of the learned pre-condition models.
Approach	We employ T. Joachims’ SVM Ð Ø software which is available on the WWW [ 21 ].
Approach	The software can accommodate large training sets comprising tens of thousands of observations and it efficiently handles many thousands of support vectors.
Approach	It includes standard kernel functions and permits the definition of new ones.
Approach	It incorporates a fast training algorithm which proceeds by solving a sequence of optimization problems lower-bounding the solution using a form of local search.
Approach	It includes two efficient estimation methods for error rate and precision/recall.
Approach	The SVM training phase can take hours in our application, but this is done off-line.
Approach	For example, on a 733 MHz PIII computer, the SVM training time for a training set of 8,013 observations is 2,789 seconds using the polynomial kernel, 2,109 seconds using the linear kernel, and 211 seconds using the radial kernel.
Approach	For a training set of 11,020 observations, the training time is 8,676 seconds using the polynomial kernel, 3,593 seconds using the linear kernel, and 486 seconds using the radial kernel.
Approach	Once trained, the SVM classifier can provide answers on-line in milliseconds.
Approach	We compared the performance of the SVM algorithm to that of a nearest neighbor (NN) classifier [ 9 ].
Outcome	Given a training set, the nearest neighbor classifier returns for an arbitrary state Ü the same succeed/fail label as the label for that observation in the training set that is closest to Ü .
Outcome	NN classifiers should perform particularly well in cases where the feasible area in the state space is highly fragmented and localized.
Outcome	Note that the NN method requires zero training time, but that it provides an answer in Ç  ́ Ò μ time where Ò is size of the training set.
Approach	To compute accuracy rates, we trained the SVM and NN pre-condition learning algorithms using randomly sampled observations collected from each of the controllers.
Approach	Then we generated test sets of novel observations and compared their true success/fail status against that predicted by the trained NN and SVM pre-conditions to obtain the accuracy percentages listed in the rightmost two columns of the table.
Outcome	The results show that the SVM algorithm consistently outperforms the NN classifier.
Approach	For the results shown in the table, the SVM algorithm employed polynomial kernel functions.
Outcome	We ran a similar set of experiments using Gaussian RBF kernel functions, but the accuracies were consistently lower than those obtained with polynomial kernel functions.
Approach	Our control composition framework is implemented within DANCE , a portable, extensible object-oriented modeling and animation system [ 24 ].
Background	2 DANCE provides a platform that researchers can use to implement animation and control techniques with minimal design and implementation overhead.
Background	The core of the system supports four base classes, Systems, Simulators, Actuators and Geometries which are loadable as plug-ins in accordance with simple APIs.
Background	Articulated objects are a System subclass that support skeleton hierarchies.
Background	They have kinematic properties and, usually, fully dynamic physical properties as well.
Approach	Our virtual actors, which will be described shortly, are dynamic articulated objects implemented as Systems within DANCE .
Approach	An actuator is a generic concept that includes anything that can exert forces or, in general, interact in any way with systems or other actuators.
Approach	For example, gravity, the ground, the collision mechanism, the supervisor controller and individual controllers are implemented as actuators.
Background	DANCE places no restrictions on the complexity of the controllers.
Background	Simulators compute the equations of motion of all the dynamic characters and other systems in DANCE .
Background	DANCE offers built in support for SD/FAST, a commercial system which produces optimized simulation code [ 18 ].
Approach	Our simulators are automatically produced by SD/FAST from description files.
Approach	They use Kane’s method for computing articulated dynamics and a fourth order explicit Runge-Kutta time integrator for numerically simulating the motions.
Approach	Actuators and simulators are implemented as DANCE plug-ins.
Approach	This allows the user to dynamically load controllers and simulators at runtime.
Approach	In addition, researchers can exchange, simulators, and controllers in the form of dynamically linked pieces of code.
Approach	Object collisions (including self collisions) are handled by the Collision actuator.
Approach	This actuator works on pairs of objects.
Approach	The DANCE API allows it to work with objects that have different simulators.
Approach	Collision detection is based on a library that uses oriented bounding boxes [ 13 ].
Approach	Collision resolution uses a penalty method that corrects geometry interpenetration using spring-and-damper forces.
Approach	As with all penalty methods, it can make the system stiff, but it has performed well in our experiments to date.
Approach	The red arrows indicate the joint positions and axes of rotational degrees of freedom (DOFs) which are also presented in the table.
Approach	The 3D skeleton model has 37 DOFs, six of which correspond to the global translation and rotation parameters.
Approach	The dynamic properties of both models, such as mass and moments of inertia, are taken from the biomechanics literature and correspond to a fullyfleshed adult male.
Approach	The models are equipped with natural limits both on the motion of the joints and the strength of their muscles.
Approach	However, DANCE has no built in muscle model and does not enforce the limits automatically.
Approach	Users can implement the model they prefer and include code to enforce the limits of the model.
Approach	Our plug-in control scheme uses rotational spring-and-damper forces for control and enforces the limits on the joints with exponential springs.
Approach	Most of the controllers for our virtual stuntperson are based on pose control, which has often been used both for articulated objects [ 31 ] and soft objects [ 11 ].
Background	Pose control is based on cyclic or acyclic finite state machines with time transitions between the states.
Background	Each state of the controller can be static or depend on feedback parameters.
Approach	For some of our controllers, we use continuous control, in the sense that the control parameters are tightly coupled with some of the feedback sensors.
Approach	The balance controllers are an example of this.
Approach	We designed several controllers based in part on experimental studies of how humans detect loss of balance [ 25 ] and analysis of protective and falling behaviors [ 8 ].
Approach	The resulting parameterized controllers have been enhanced with appropriate pre-conditions, post-conditions, and expected performance and have been integrated using an arbitration-based supervising controller.
Approach	Each controller has full access to the internal data structures of DANCE including all the information associated with any character or object in the system.
Approach	This allows the controllers to define arbitrary sensors that keep track of necessary information such as state parameters for feedback loops and the state of the environment.
Approach	For efficiency, the supervisor controller calculates a number of common sensor values that are available to all the controllers.
Approach	Many controller transitions in the control framework happen autonomously, such as taking a protective step in response to losing balance.
Approach	However, other actions are initiated in a voluntary fashion.
Approach	For example, a standing character can do any of (1) remain standing using the balance controller, (2) sit-down, (3) walk, and (4) dive.
Approach	Currently, the user directs these voluntary motions by interactively entering command strings to the supervisor controller which, in turn, directly increases the suitability score of the designated controller and forces the arbitration process to be invoked to select a new active controller.
Approach	The control of voluntary motions could equivalently be delegated to a high-level planner, although this kind of planning is beyond the scope of our work at present.
Outcome	At the heart of our prototype system is a composite controller that is capable of handling a large number of everyday tasks, such as walking, balancing, bending, falling, and sitting.
Approach	In addition, we present brief descriptions of the controllers involved in producing several stunt actions.
Outcome	While the given controller descriptions are for the 3D character, the equivalent 2D controllers are very similar.
Approach	We began our implementation with the simple tasks of standing, recovering balance when pushed, and falling.
Approach	An autonomous human agent should be able to balance, standing naturally in place.
Approach	Should loss of balance occur, the character ought to react naturally either with a restoring motion or with a protective falling behavior depending on which action is appropriate in each case.
Outcome	Affording a dynamic articulated figure with natural reactions to loss of balance or impending falls is an essential step towards believable autonomous characters.
Approach	A balance controller is responsible for maintaining a natural standing posture.
Approach	This controller is based on an inverted pendulum model [ 12 ], using the ankles to control the body sway.
Outcome	Despite the fact that the body of the character is not as rigid as the inverted pendulum hypothesis suggests, the approximation works well in practice.
Approach	An animated character should attempt to maintain balance in response to external disturbances by shifting its weight, taking a step or bending at the waist.
Approach	If the character cannot maintain balance, it must then resort to a falling behavior.
Background	The manner in which people fall depends on a number of factors such as their physique, their age and their training.
Background	For example, the work in [ 19 ] shows that, during a fall, the elderly are more likely to impact their hip first as compared to younger adults falling under the same conditions.
Approach	Our fall controller is designed with the average adult in mind.
Approach	Its main action is thus to absorb the shock of the impact using mostly the hands.
Approach	The pre-conditions of the fall controller are defined in accordance with those of the balance controller.
Approach	Situations that are beyond the capabilities of the latter should be handled by the fall controller.
Outcome	Our implementation of the fall controller can handle falls in any direction, responding in different ways to falls in different directions.
Background	Sitting down in a chair and rising from a chair are common everyday tasks.
Approach	We have implemented a controller that can do both depending on the instructions of the animator.
Approach	Apart from the command string supplied by the user, the pre-conditions are either a balanced upright posture or a balanced sitting posture.
Approach	The postconditions are similarly defined.
Background	Getting up off the ground is a surprisingly difficult motion to simulate.
Background	It involves rapid changes of the contact points and significant shifting of the figure’s weight.
Background	In addition, the frictional properties of the ground model can influence the motion.
Approach	The pre-conditions for this controller are straightforward.
Approach	The character must be lying with its back flat on the ground, within some tolerance.
Approach	The post-conditions are that the character should be on its feet with its center of mass within the support polygon.
Approach	Then it would be up to another controller to take over and bring the character from a crouching position to a standing one.
Background	When lying on their back, some people may choose to roll-over to a prone position before attempting to stand.
Approach	We have implemented a roll-over controller that can emulate this action.
Approach	The pre-conditions of the roll-over controller require a supine posture, and no movement of the center of mass.
Approach	The postconditions of the roll controller are fairly simple and they include any prone position for which the character is extended and fairly straight; i.e., no crossing of legs or arms, etc.
Approach	When lying face-down, the pre-conditions can be fairly relaxed.
Approach	Our controller assumes that is has the time to change the state of the character to one from which it knows how to rise.
Approach	As long as the figure is not lying on its arms and the ground is relatively flat it will attempt to get up.
Approach	The post-conditions are chosen such that they satisfy the pre-conditions of the balance controller.
Approach	Apart from everyday actions, we want our dynamic character to be able to do a variety of other voluntary actions dictated by the animator.
Approach	Such actions can potentially include vigorous and/or physically dangerous actions.
Challenge	It is our hope that if a large number of researchers contribute controllers the character can eventually be used as a virtual stuntperson.
Background	The kip is an athletic motion often seen in martial arts films and is depicted in Fig. 9 .
Approach	The controller is based on a pose controller whose pre-conditions include a variation of supine positions.
Approach	As before, the first part of the controller makes sure that the character assumes a position suitable for performing the kip.
Approach	The larger part of the motion is ballistic, which focuses the control mainly at the kick off and landing phases.
Approach	The last part of the controller applies continuous control to bring the stuntman to an erect position from which the balance controller can take over.
Approach	The character can be instructed to lunge forward and upward at a takeoff angle controlled by the user.
Approach	When the hands contact the ground a front-roll is attempted.
Approach	The pre-conditions of this controller are defined be an upright position and little movement of the center of mass.
Approach	We have also experimented with a multiple character scenario, with one character tackling another, Fig. 11 .
Approach	While the timing of the tackle is scripted, it illustrates the capability of the system to cope with a pair of interacting characters, each equipped with its own supervisory controller.
Outcome	We have produced two relatively long animation sequences that demonstrate the potential of the our framework.
Approach	The sequence for the 3D skeleton model presented in Fig. 1 involves controllers whose pre-conditions are provided analytically by the designer.
Approach	Such conditions tend to define square regions within the space defined by the parameters involved.
Outcome	Despite their simple form, such pre-conditions can generally work well as is demonstrated by the intricacy of the animation produced.
FutureWork	We expect to investigate the application of SVM-learned pre-conditions to the 3D model in the future.
Approach	A second animation sequence with the 2D terminator model (see Fig. 12 ) makes use of a set of controllers having a mix of analytic and learned pre-conditions.
Approach	The sequence of controllers that generated the animation was: balance sit lean-forward rise balance walk step-to-stand balance dive default kneel kneel to stand balance step-forward step-tostand balance step-back step-to-stand balance fall default.
Approach	The analytical pre-conditions prune large parts of the state space and the svm-classifier provides a more accurate success/failure prediction within the remaining region.
Outcome	During the animation sequence, the svm-classifier correctly refined the analytical answer in several cases.
Approach	Most of the computational burden in our approach lies in the numerical simulation of the equations of motion.
Outcome	The computations associated with the controllers and our composition framework are negligible in comparison.
Outcome	In general, the 2D model simulates in real time, while the 3D model runs between 5 and 9 times slower than real time on a 733 MHz Pentium III system.
Challenge	The challenges of physics-based controller design plus the technical obstacles that researchers face when attempting to share their algorithms has hindered progress in the important area of physicsbased character animation.
Outcome	This paper has presented a methodology for ameliorating the problem with a framework which facilitates the exchange and composition of controllers.
Outcome	Our framework has been implemented within a freely available system for modeling and animating articulated characters.
Outcome	To our knowledge, our system is the first to demonstrate a dynamic anthoropomorphic character with controlled reactions to disturbances or falls in any direction, as well as the ability to pick itself up off the ground in several ways, among other controlled motions.
Outcome	We hope that our system will foster collective efforts among numerous practitioners that will eventually result in complex composite controllers capable of synthesizing a full spectrum of human-like motor behaviors.
FutureWork	Given the enormous challenge of building controllers capable of large repertoires of dynamic human-like motion, it is inevitable that the work presented in this paper is incomplete in many ways.
FutureWork	Published control methods for 3D walking, running, and stair climbing make obvious candidates for integration into our system.
FutureWork	Coping with variable terrain and dynamic environments are dimensions of added complexity that should provide work for years to come.
FutureWork	Automatic parameterization of controllers to variations in character dimensions and mass is a necessary step for having solutions adaptable to a variety of characters.
FutureWork	Deriving controllers from motion-capture data is an exciting but difficult prospect, although some progress is already being made in this area.
FutureWork	Other methods of “teaching” skills to a dynamic character also warrant investigation.
FutureWork	Finally, intelligently integrating controllers which affect only subsets of DOFs needs to be addressed in order to allow for the parallel execution of controllers.
Approach	The articulated body must be in a balanced upright position, the velocity and acceleration of the center of mass should not exceed certain threshold values as explained in [ 25 ], and both feet must maintain contact with the ground at all times.
Approach	The controller can tolerate small perturbations of the posture and the velocity/acceleration of the center of mass by stiffening the ankle joints.
Approach	For larger accelerations of the center of mass, the controller actively actuates the ankle joint to reduce the acceleration of the center of mass.
Approach	The post-conditions are similar to the pre-conditions.

Challenge	Local mass conservation prevents small scale details of the free surface from disappearing, a problem that plagues many previous approaches, while global mass conservation ensures that the total volume of the liquid does not decrease over time.
Outcome	Our method handles moving solid boundaries as well as cells that are partially filled with solids.
Outcome	Due to its stability, it allows the use of large time steps which makes it suitable for both off-line and real-time applications.
Approach	We achieve this by using density based surface tracking with a novel, unconditionally stable, conservative advection scheme and a novel interface sharpening method.
Approach	While our approach conserves mass, volume loss is still possible but only temporarily.
Approach	With constant mass, local volume loss causes a local increase of the density used for surface tracking which we detect and correct over time.
Outcome	We also propose a density post-processing method to reveal sub-grid details of the liquid surface.
Outcome	We show the effectiveness of the proposed method in several practical examples all running either at interactive rates or in real-time.
Challenge	Tracking the free surface of a liquid is an important and challenging problem.
Background	For an overview of existing methods we recommend the class notes of Wojtan et al. [WMFB11].
Background	The most popular approach is to advect a scalar field with the fluid and define the liquid surface to be one of the isosurfaces.
Background	The main advantage of this class of methods is that they handle topological changes implicitly in contrast to mesh-based tracking methods.
Background	Until recently, the level set method was the method of choice in graphics.
Background	Here, the signed distance field is used as the scalar field with the zeroiso-surface as the liquid surface.
Challenge	A well known drawback of the level set method is that volume is lost both globally and locally.
Challenge	With global volume loss the water level decreases over time while local volume loss causes small detail such as thin sheets and droplets to disappear.
Challenge	A way to alleviate this problem is to introduce Lagrangian components such as particles [FF01], [EMF02] or triangle meshes [BGOS05].
Challenge	Even though these methods reduce volume loss, they cannot guarantee complete volume conservation.
Challenge	Moreover, Lagrangian components add significant run-time cost and complicate the implementation significantly, especially for GPUs.
Background	As an alternative to the signed distance field, [MMTD07] in- troduced the idea of using a density field as the scalar field for surface tracking with the liquid surface being the 0.5 isosurface.
Background	This density field is not to be mistaken for the density field of the liquid.
Background	In incompressible fluid simulations, the fluid-density is 1 everywhere and therefore not stored.
Approach	So in what follows, we use the symbol ρ for the surface density.
Approach	We chose to use surface density instead of the signed distance field because there are advection methods that strictly conserve quantities like density such as the one proposed by [LAF11].
Approach	Their advection method is unconditionally stable and fully conservative.
Approach	With this approach, the overall mass defined by the surface density is conserved.
Approach	Since the surface density can deviate from 1 temporarily, the overall volume may vary over time though.
Approach	However, in contrast to the level set method where such variations go unnoticed, volume deviations are reflected in the density field.
Outcome	In this paper we propose several methods to preserve volume both globally and locally using the information stored in the density field.
Challenge	Ideally, the surface density has the form of a step function at the liquid-air interface.
Challenge	Over time, however, the initially sharp boundary blurs out due to numerical diffusion.
Background	Therefore, [MMTD07] apply a sharpening filter at each time step which conserves mass globally but not locally.
Outcome	We propose a new sharpening method which conserves mass both locally and globally.
Background	3D Eulerian liquid simulation was introduced to computer graphics by Foster and Metaxas [FM96] who used a finite difference approach to solve the governing equations.
Background	Later Foster and Fedkiw [FF01] employed the semi-Lagrangian method introduced by Stam [Sta99] to solve the advection term and the level set method and particles to track liquid surface.
Background	Enright et al. [EMF02] devised the Particle Level Set (PLS) method which uses particles on both sides of liquid-air interface to reduce volume loss.
Background	Since then, many methods have been proposed to further improve the accuracy of Eulerian surface tracking.
Background	Various approaches have been proposed to track the liquid domain more faithfully.
Background	[BGOS05] used a triangle mesh representation in connection with a level set grid, [HK10] augmented the level set grid with quadrature points.
Background	Grid-less methods work with Lagrangian elements only such as particles [ZB05], [APKG07] or [YT10], triangles meshes [M 09],  ̈ [BB09] and [WTGT10].
Challenge	In this paper we focus on fluid mass and volume conservation.
Background	A popular way to compensate volume gain or loss is to modify the divergence of the velocity field as proposed in [FOA03].
Background	This technique was extended and used for con∗ serving volume of bubbles [KLL 07], highly deformable objects [ISF07] and liquids [MMTD07].
Background	The problem of loss of liquid mass and momentum has also been addressed by proposing elaborate advection methods such as BFECC [KLLR05], modified MacCormack ∗ [SFK 08], derivatives advection [KSK08] and conservative semi-Lagrangian advection [LGF11], [LAF11].
Background	As an alternative to level-set, the fluid domain can be tracked with a Volume-of-Fluid (VOF) approach [HN81] where the volume fraction of fluid in each cell is evolved over time.
Background	With proper care, VOF can be made mass conserving.
Challenge	However, despite several improvements in subsequent works such [PP04], [AGDJ08], reconstructing surface normal and curvature from VOF is still difficult.
Background	Sussman and Puckett [SP00] proposes coupled Level Set and Volume-ofFluid (CLVOF) which track the fluid interface with both representations, where VOF is used for re-initializing the Level Set.
Background	The surface can then be extracted from the Level Set.
Background	CLVOF is extended to handle multiple interfaces in [KPyNS10].
Background	The downside of CLVOF is the need to use two representations which can be quite computationally intensive.
Background	An alternative to VOF is to track a smeared-out surface density and keep it relatively sharp with a sharpening operation.
Background	This method was introduced to computer graphics by Mullen et al. [MMTD07].
Approach	Our fluid domain tracking approach builds upon this work and make it conserve mass both locally and globally.
Background	Apart from the Eulerian formulation we use, there are many alternative models to simulate 3D liquids such as the LatticeBoltzmann method [TR04] and [TR09], approaches based on the discrete sin-cosine transform [LR09] or particle based ∗ methods such as [MCG03], [PTB 03], [APKG07], [SP09], and [SG11].
Approach	The equations are solved in the domain specified by a surface density field ρ [MMTD07], in the region where ρ > 0.5.
Approach	The interaction of the liquid with the environment is handled by considering the appropriate Dirichlet and Neumann boundary conditions.
Approach	We discretize the simulation domain using a regular staggered grid [HW65].
Approach	The x, y and z components of fluid velocity u = (u, v, w) are stored at the center of the faces perpendicular to the x, y and z axis, respectively.
Approach	The scalar pressure p and the density ρ are stored at cell centers following [MMTD07].
Approach	Our time integration scheme is summarized in Algorithm 1.
Approach	The overall structure is the same as the one proposed in [MMTD07] with our novel modifications to the advection, sharpening and pressure incompressibility enforcement steps.
Approach	Then, we advect the surface density field and sharpen it.
Approach	After this we advect the velocity field and take external forces into account.
Approach	Finally, we enforce incompressibility by making the velocity field divergence free.
Approach	To extrapolate the velocities from inside the liquid into the surrounding air we use the scheme described in [CM11b], i.e. we apply the method of [JRW07] to derive the velocities a few grid cells away from the interface and then extrapolate based on a hierarchy of grids to obtain velocities far away from the surface.
Approach	We advect ρ using our unconditionally stable conservative advection method which we derived from the method proposed by Lentine et al. in [LGF11] and [LAF11] and improved in terms of computational cost.
Background	Lentine et al. [LGF11] modified the semi-Lagrangian advection scheme to conserve mass by ensuring that each cell distributes all its mass of the current time step among some cells at the next time step.
Approach	Let A be the matrix of the discretized advection operator such that ρ n+1 = Aρ n , where ρ n and ρ n+1 are the density in the current and the next time step respectively.
Approach	Let w ij − (and w + ij ) represent the fraction of value that cell i gives to cell j which is found by backward (and forward) tracing and computing the tri-linear interpolation weights.
Approach	The entries of A in the standard semi-Lagrangian advection is hence A i j = w − ji .
Approach	Then, β j = ∑ i A i j is the fraction of mass from cell j that gets advected.
Approach	To ensure that mass is conserved, A needs to be modified such that all the β j are 1.
Background	Lentine et al. [LGF11] achieve this by first iterating through all cells j with β j > 1 and re-scaling all A i j to A i j /β j .
Background	In a second step they iterate through all cells j with β j < 1 and forward trace the velocity field to adding the weights (1 − β j ) by distributing them among the A k j , where k are the cells reached by forward tracing and tri-linear interpolation.
Background	At this point, all the β j are 1, i.e. A is mass conserving.
Background	This method works well for compressible flow on fine grids.
Background	However, as discussed in [LAF11], the scheme produces artifacts when used for incompressible flow on coarser grids.
Approach	The problem is due to the clamping of the β j by re-scaling which limits the amount of density that reaches certain cells.
Approach	An indicator of this amount are the γ i = ∑ j A i j .
Background	The traditional semi-Lagrangian method ensures that all the γ i are 1 while the β j are arbitrary.
Background	In contrast, the scheme described above ensures that all the β j are 1, while the γ i are arbitrary.
Background	Lentine et al. [LAF11] propose a method to ensure the β j are all 1 while the γ i stay close to 1.
Background	To this end they keep track of the cumulative γ i over time as separate variables.
Approach	The matrix A is computed by performing multiple forward and backward traces as follows: 1.
Approach	Advect γ i using the backward semi-Lagrangian method (set to 1 in the first time step).
Approach	Compute A by performing a backward tracing step as before, i.e. A i j = w − ji .
Approach	Scale A by the γ i , i.e. A i j A i j /γ i .
Approach	Compute the β j from A. 5.
Approach	Forward trace the velocity field to add the weights (1 − β j ) to A for all cells j where β j < 1 by distributing them among the A k j , where k are the cells reached by forward tracing and tri-linear interpolation as before, i.e. A k j += (1 − β j )w + jk .
Approach	Compute the new γ i from the updated matrix A. 7.
Approach	Scale A by the γ i , i.e. A i j ← A i j /γ i .
Approach	Re-compute the β j from the updated matrix A. 9.
Approach	Clamp the β j to 1 by re-scaling A i j ← A i j /β j .
Approach	Re-compute the γ i from the updated A. 11.
Approach	Evaluate ρ n+1 = Aρ n .
Approach	At this point, all the β j are 1 but the γ i might still deviate from 1.
Background	To bring them even closer to 1 Lentine et al. apply a diffusion step on ρ n+1 and the γ i .
Background	They iterate through all the cells dimension-by-dimension.
Approach	If, for two neighboring cells i and j, γ j > γ i , they move ρ j (γ j − γ i )/2γ j from cell j to cell i and set both γ j and γ i to γ j +γ 2 i .
Approach	If γ j < γ i , the flow happens in the opposite direction.
Approach	This process is repeated 1 to 7 times per time step.
Approach	Note that these diffusion iterations do not affect the β j , so they remain 1.
Approach	Implementing the method described above on a GPU would require 5 scatter passes per iteration in steps 4, 6, 8, 10, and 11.
Approach	Scattering is expensive on GPU’s because it either requires atomic operations or a prefix-scan.
Approach	We propose a modification of this method.
Approach	The basic idea is to reorder the forward tracing and the re-scaling steps to simplify the calculations.
Approach	The resulting discrete conservative advection operator is not the same as the one computed with the original scheme.
Approach	However, both are just approximations to the doubly-stochastic matrix (all rowand column sums are one) closest to the original discrete advection operator.
Approach	While the visual results are of similar quality as shown in Figure 2 and the accompanying video, our simplification reduces the number of scatter passes from 5 to 3.
Approach	Another advantage of our new scheme is that A does not need to be stored explicitly because the order of the operations allow for updating ρ n+1 , β and γ directly.
Approach	Not storing A explicitly is possible in the original scheme as well but it would complicate the process considerably and would require even more scatter operations.
Approach	Here is our modified scheme: 1.
Approach	Advect γ i using the semi-Lagrangian method (set to 1 in the first time step).
Approach	Initialize β ← 0.
Approach	Add the weights γ i to β by distributing them among the β l , where l are the cells reached by backward tracing and tri-linear interpolation, i.e. β l += w − li γ i .
Approach	Evaluate ρ n+1 from ρ n and γ from γ by backward tracing and tri-linear interpolation from cells l but this time scale the weights by max(1,β γ i l ) , i.e. ρ n+1 i += ∑ l max(1,β γ i l ) w − li ρ n l ) 5.
Approach	γ ← γ .
Approach	(This can be done in-place during the previous step).
Approach	For each cell j whose β j < 1, add ρ n j (1 − β j ) to ρ n+1 by distributing the value among the ρ n+1 k , where k are the cells reached by the forward tracing and tri-linear interpolation, i.e. ρ k n+1 += ρ n j (1 − β j )w + jk .
Approach	Similarly, for each cell j whose β j < 1, add (1 − β j ) to γ by distributing the value among the γ k , where k are the cells reached by the forward tracing and tri-linear interpolation, i.e. γ k n+1 += γ n j (1 − β j )w + jk .
Approach	These two steps can be done concurrently.
Approach	Apply diffusion as in the original approach.
Approach	This modified method only requires 3 scatter passes in the steps 3, 6, and 7.
Approach	As demonstrated in Table 1 , our method keeps γ in a similar range to that of [LAF11], while [LGF11] has a much larger range, resulting in visible compressibility artifacts.
Approach	The technique above guarantees that mass is conserved.
Approach	However, the density field smooths out over time blurring the 0.5 iso-contour with the effect that we can no longer track the movement of the liquid surface accurately.
Approach	We solve this problem by manipulating ρ to sharpen the interface.
Approach	The parameter τ controls the maximum difference in density between two adjacent cells, which we set to 0.4 as in [MMTD07].
Approach	This yields the following density correction:
Approach	This update sharpens the interface.
Approach	However, it does not conserve mass.
Background	Mullen et al. [MMTD07] modify it to conserve mass by summing up the mass change due to this update across all cells.
Background	Then they distribute a fraction of the total mass change back to each cell based on a local area measure.
Background	This successfully conserves mass globally.
Background	One artifact of this approach is that mass moves far, potentially across the entire simulation domain.
Background	This problem can be reduced by re-distributing mass only within connected regions as pro∗ posed by [KLL 07].
Background	However, even with this technique, local mass loss can still occur due to moving mass away from small features resulting in the disappearance of small surface details.
Background	The mass conserving sharpening method of [MMTD07] transfers the mass from the liquid balls to the pool causing them to disappear mid-air.
Approach	We propose a novel method to conserve mass during the sharpening phase that conserves mass both locally and globally.
Approach	In the first line we make sure that ρ ≥ 0 at the next time step.
Approach	We also clamp small positive densities to zero so that we do not have to apply the sharpening operator to this cell at the next time step, thus reducing computation cost.
Approach	In the second line we make sure that cells with ρ > 0.5 are not modified.
Approach	This way mass only moves from the air side to the liquid side.
Approach	Then we update ρ i using this modified ∆ρ i in Equation 16.
Approach	We then add back −∆ρ i by using Algorithm 2.
Approach	TraceAlongField determines where to put the lost mass.
Approach	It starts from the cell center and follows the gradient field of the density ρ until it reaches the 0.5 iso-contour.
Approach	The tracing stops if a predefined distance D∆x is reached or if it crosses a solid boundary.
Approach	This is done using multiple forward Euler sub-steps.
Approach	ScatterValue deposits −∆ρ i to nearby grid points using tri-linear weights.
Approach	If a grid point is in a solid we set the corresponding weight to zero and re-normalize the weights.
Approach	We use values of D between 1.1 to 3.1 in all of our examples.
Approach	So far, the method does not take solid fraction and solid velocity into account.
Approach	We use u s = (u s , v s , w s ) for the solid velocity and V i for the fraction of non-solid matter, i.e. fluid and f f f air in cell i.
Approach	The scalars V i+( 1 ,0,0) , V i+(0, 1 ,0) , and V i+(0,0, 1 ) 2 2 2 represent the fraction of non-solid area of the positive x, y, and z faces respectively.
Approach	During the simulation, the value of ρ i can become larger than V i in some cells which is a non-valid state.
Approach	We handle the situation differently depending on whether the cell is partially solid (V i < 1) or completely non-solid (V i = 1).
Approach	If the cell is partially solid, we first compute the excess density d = ρ i − V i .
Approach	When then follow the gradient of the solid signed distance function away from the solid for a distance of S∆x and scatter d to nearby grid points.
Approach	After this we subtract d from ρ i .
Approach	This method keeps ρ i ≤ V i in most cells near solid boundary and guarantees ρ i = 0 inside the solid.
Approach	We use S = 1 in all of our examples.
Approach	With this choice excess density gets removed from solid quickly enough to not cause visual artifacts.
Approach	The case where V i = 1 is handled in the incompressibility enforcement step described in the next section.
Approach	To enforce incompressibility, we first compute the pressure using a variational framework [BBB07] and then use the pressure gradient to make velocity field divergence free.
Approach	The tricky part in our case is to determine the fraction of liquid in each cell.
Approach	This fraction is used to decide whether a cell is included in the linear pressure solve.
Approach	It is also needed in the ghost fluid method [ENGF03] to accurately handle the liquid-air boundary.
Approach	However, we cannot directly use ρ because a cell with V < 0.5 will likely have ρ < 0.5 causing the solver to treat it erroneously as air.
Approach	Notice that cells that are completely solid (V = 0) have ρ = 0.
Approach	We then extrapolate ρ from cells that have V > 0 to adjacent cells with V = 0 so they are included in the linear system.
Approach	For the ghost fluid method, we also need a signed distance function near the free surface.
Approach	We approximate this field by defining φ i = −(ρ i − 0.5)∆x and use the method of [CM11a] to compute the coefficients of linear system for pressure projection.
Approach	To handle the cells with ρ i > 1 (whether or not V = 1 or V < 1), we add min(λ(ρ i −1),η) to the divergence, where we ∆x use λ = 0.5 and η = 1 in all our examples.
Approach	This artificial divergence pushes the excess density away from the cells whose ρ > 1.
Background	Mullen et al. [MMTD07] also added this term to the divergence but with λ = 1 and η = ∞ which can cause stability problems when ρ is much larger than 1.
Approach	A scenario in which this happens is when liquid flows very fast towards a solid boundary and gets reflected due to our method for removing excess density from the solid.
Approach	Adding additional divergence is important because in our case, ρ > 1 results in visual volume loss.
Approach	With the method described above, this problem gets gradually corrected over time.
Approach	We solve for the pressure p with the multigrid method of [CM11a] which enforces separating solid boundary conditions.
Approach	Finally, we use the pressure field to make the velocity field divergence free.
Approach	For rendering, we extract the triangle mesh of the 0.5 isocontour of ρ using the marching cubes method [LC87].
Background	This approach is typically used in level-set based liquid simulations as well to extract the zero contour of the signed distance field [EMF02].
Approach	The surface density ρ contains small scale details that are not captured by the 0.5 iso-contour.
Approach	Here, the regions where 0 < ρ < 0.5 represent features such as small splashes and thin sheets that are too small to be captured with the grid resolution used.
Approach	In the level-set approach, these features are destroyed by the redistancing step.
Approach	To bring out these small scale details in surface rendering, we propose a post processing method.
Approach	An important observation is that regions in which 0 < ρ < 0.5 do not necessarily represent small scale features.
Approach	They also exist on the air side of the surface of large liquid regions.
Approach	In the latter case, we want to leave ρ unchanged but in the former we want to scale up ρ so that the features appear in the 0.5 iso-surface.
Approach	To this end, we define an additional function γ i = 2 min(ρ i , 0.5) and define the regions in which ρ needs to be scaled up as the regions where γ ≤ 0.5.
Approach	So far, the two cases above are not distinguished.
Approach	However, this can be achieved by applying a Gaussian blur filter to γ.
Approach	Now, since γ > 0.5 inside liquid, those values spread across the interface and cause γ to raise toward 1.
Approach	In contrast, since γ < 0.5 everywhere inside small scale features, blurring will still result in γ being small.
Approach	We then define ρ i = min(max(γ ρ i i ,θ),1) and extract the liquid surface as the 0.5 iso-surface of this modified density field.
Approach	We used σ = 2∆x for the Gaussian blur filter and θ = 0.01 in this example.
FutureWork	A way to improve the results further would be to apply thinning to the parts of the surface that come from region with ρ < 0.5 in order to compensate for the density up-scaling.
FutureWork	This is part of our future work.
Approach	We implemented our method using CUDA and ran the simulations on an NVIDIA GTX 680.
Approach	For all the examples we used a time step size of 1/30s, ∆x = 0.05m, gravity 10m/s 2 and D = 2.1.
Approach	Density post-processing was turned off unless otherwise stated.
Approach	Our code run at interactive rates in all examples.
Outcome	Parameter tuning to get visually appealing results did not take much time.
Approach	We compared our method with the particle level set (PLS) approach [EMF02].
Outcome	Our method conserves the liquid’s mass as expected and prevents the water level from decreasing.
Outcome	In contrast, with PLS, most of the liquid disappears in the course of the simulation due to the large time step size used.
Approach	We used the PLS implementation of [MF] and set the number of particles per cell to 64.
Outcome	The jet has a very fast flow rate and generates fast moving liquid splashes and sheets.
Outcome	These are difficult cases for level set approaches while our method handles them without any problem.
Outcome	With our approach we were able to create, for the first time, a 3d water demo that is both simulated and ray-traced in real time.
Outcome	We achieved a frame rate of over 30fps with two GPUs, one for simulation and one for ray-tracing.
Outcome	These examples demonstrate the ability of our method to simulate liquid in a non-axis aligned moving container.
Outcome	One way coupling with fast moving solids is shown in Figure 11 and the accompanying video.
Outcome	Several solid objects move at high speed across the tank sloshing the liquid up to the air.
Outcome	Our method conserves mass and prevents volume loss in this difficult case as well.
Approach	We computed the mass and the volume enclosed by the 0.5 iso-contour of the liquid over time in various examples.
Approach	The total mass is computed by integrating ρ over the whole simulation grid.
Approach	To measure the volume we used marching cubes to extract the 0.5 contour triangle mesh of ρ and determined the enclosed volume.
Outcome	Our method conserves mass in all examples and generally keeps the volume close to the true liquid volume.
Outcome	However, there are several situations where our method loses volume visually.
Outcome	One such case is when a liquid ball hits the ground and spreads out until it becomes thinner than the grid spacing.
Outcome	Even though the density values are nonzero, marching cubes does not generate surface meshes in those regions.
Outcome	Another case is when the ratio of surface area to volume is large.
Outcome	In this case, there are large regions with ρ < 0.5 that do not contribute to the volume because the 0.5 iso-contour is empty.
Outcome	However, in contrast to PLS, when such features join the main body of water again, they correctly contribute to its volume so that the global level remains constant.
Outcome	We proposed a method for simulating liquids that conserves mass and is effective in keeping the volume defined by the 0.5 iso-contour close to constant.
Outcome	We have demonstrated the strength of our technique in various scenarios.
Outcome	The method has its limitations as well.
Outcome	First, although our sharpening scheme ensures that the ρ = 0.5 interface is sharp, it does not modify regions where ρ > 0.5.
Outcome	It could theoretically be possible that the region with ρ slightly above 0.5 expands so that the volume defined by the 0.5 iso-contour grows by a factor of two while keeping its original mass.
FutureWork	An alternative to our sharpening method is to perform antidiffusion step [SHA11], which is an interesting avenue for future work.
Outcome	Another limitation is the possibility of losing local volume temporarily as discussed in the previous section.
Outcome	The density post processing method we proposed is an effective way to alleviate this effect.
Outcome	Even though our method cannot guarantee complete volume conservation at all times, it reduces this problem significantly in comparison to all the previous methods we have investigated.

Outcome	This paper presents a system that uses computational fluid dynamics to produce smoke, water, and other effects for traditionallyanimated films.
Outcome	The system was used in over twenty scenes in the animated feature film The Prince of Egypt.
Approach	Animators use images and animation sequences to drive two-dimensional numerical simulations of the time-dependent compressible Navier-Stokes equations.
Approach	For instance, images can be used to initialize temperature fields which cause dynamic buoyancy-driven vortices to evolve.
Outcome	In addition to being image-driven, the system is unique in allowing for compressibility of the fluid, and in its use of partial differential equations for texture mapping.
Background	Compared to computer graphics, the equations of fluid motion and solution methods for them have a long history.
Background	Equations expressing conservation of mass, momentum, and energy, often referred to as the Navier-Stokes equations, have been around since the early 1800’s.
Background	Sir Horace Lamb’s Hydrodynamics [ 11 ], from 1932, is still regarded as one of the best sources for fundamental theorems, equations, and solutions in fluid mechanics.
Background	The equations of motion cannot be solved analytically, except in simplified situations, and therefore need to be solved numerically.
Background	Numerical integration methods for systems of equations predate the modern computer as well, and John von Neumann envisioned using the computer to solve the equations of motion for weather prediction in the 1940’s.
Background	Today, the use of computers to solve the Navier-Stokes equations is widespread, with descriptions of particular models and their solutions filling the pages of journals such as Journal of Fluid Mechanics and Journal of the Atmospheric Sciences.
Background	Although computational fluid dynamics is a fairly mature subject, the emphasis so far has been on accurately simulating physical situations for scientific purposes, rather than creating images and animations as the end goal, which has different concerns and motivations.
Background	One simple example of this is the use of artificial compressibility, employed in the equation set presented in section 3, as a means of speeding up the calculations.
Background	For scientific work, the non-physical compressibility effects introduced need to be rigorously justified, whereas for the creation of imagery and animation, the guiding standard is how the images look.
Challenge	When the emphasis is on the look of the final images, there are new sets of concerns about how to control and modify the simulation dynamics, and what and how to render.
Background	These concerns move us into the territory of computer graphics, with the highly practical production environment driving the process forward.
Background	Previous work in the graphics literature [ 2 , 4 , 6 , 7 , 9 , 12 , 13 , 14 , 16 , 19 ] has modeled various aspects of fluid behavior with an emphasis on efficiency and controllability issues.
Background	Some of this work makes use of existing velocity fields or allows users to create their own in a variety of ways, rather than have a simulation determine the velocity field.
Approach	The emphasis in this paper is on the use of the full NavierStokes equations to solve for the dynamic velocity and temperature fields numerically.
Background	Kass and Miller [ 9 ] solve the shallow water equations, which reduce the Navier-Stokes equations down to solving for an evolving height field for the surface of a shallow body of liquid.
Background	Yaeger, Upson, and Myers [ 19 ], used two-dimensional timedependent vorticity equations to model the atmosphere of Jupiter.
Background	The strongest advocacy for use of the full Navier-Stokes equations so far in the graphics literature is from Foster and Metaxas [ 7 ], who solve the three-dimensional equations of motion to model smoke.
Background	There may be no right or wrong answer as to what level of physical modeling is appropriate, in general, but there is usually a decision making process based on the imagery needed to guide this choice.
Background	Creative control and the level of realism desired are two of the main concerns.
Background	The decision making process is well illustrated in [ 19 ], where the end goal, creating animations of Jupiter’s atmosphere for the film 2010, guided aspects from the equations being solved to their final rendering method.
Approach	This paper is of that same style, describing a system built at DreamWorks to support the use of fluid dynamics simulations in the creation of special effects for the animated feature film The Prince of Egypt.
Outcome	Some of the unique features of the system described in this paper include: a compressible version of the equations of motion; the use of images and animations for controlling the dynamics; fast accurate texture mapping features; and finally, a complete production system.
Outcome	The compressible formulation, unlike any in the graphics literature, allows for the modeling of compressible effects, such as shock waves, and also provides a mechanism for speeding up flow calculations by an order of magnitude or more.
Outcome	Another unique feature of the system is the use of images and animations as input devices, which allows animators to control initial conditions, source terms, and movable internal boundaries in an easy and flexible way.
Outcome	The inclusion of texture mapping differential equations, another new concept developed here, makes it possible to precalculate particle paths on a fixed grid which can be used in a straight-forward manner at render time.
Outcome	The system also provides fast turn around time.
Outcome	Fourth order accuracy allows animators to use coarser grids, thus saving time.
Outcome	The use of two-dimensional simulations, the compressible formulation, and coarser grids, results in fast, useful simulations.
Outcome	Simulations performed on a 100 by 100 grid are detailed enough for film work and can be calculated at a rate of one frame per second.
Outcome	Additional production components make the overall process efficient for the animator.
Background	Computer graphics simulations of fluid behavior are in demand in filmmaking for depicting gases, liquids, smoke, dust, fire, and other natural phenomena.
Background	Methods for creating these simulations vary widely, depending on the requirements for realism, controllability, rendering style, and complexity.
Approach	The system employs techniques from both the scientific and computer graphics communities in order to be both efficient and accessible to animators.
Background	Of the many ways of incorporating simulation into the creation of fluids animations, one end of the spectrum in a traditional animation environment is to use no simulation at all, and draw every frame of the animation.
Background	This approach gives a wide range of flexibility and control, but is a tedious process with realistic limits on the complexity that can be achieved.
Background	At the other extreme, there are many advantages to numerically solving the full equations of motion for fluids, usually referred to as the Navier-Stokes equations, to create an- imations of fluid behavior.
Background	With simple user set-ups, the physically accurate equations take over, generating lots of high quality animation, rich in complexity and guaranteed realistic motion.
Outcome	The fluid inside the letters is colder and more dense than the surrounding fluid, causing it to sink.
Outcome	This is typical of the type of simulation that was used to generate smoke for The Prince of Egypt, where contours of temperature were rendered from a simulation driven by buoyant instabilities.
Approach	In addition, arbitrary forcing functions, or source terms, would be desirable to make many more situations possible, even those without any physical justification.
Approach	Users should have easy access to setting up the various flow situations.
Approach	Ideally, animators would control many aspects of the simulation dynamics and be able to incorporate the results into the final scene in a variety of ways.
Approach	The system should be able to make use of other scene elements, produce scene elements in the most convenient formats, and should be part of an efficient work flow.
Approach	A wide variety of rendering styles increases the expressive power of scene elements and their interpretation.
Approach	The equation set used was derived for a meteorology application, the study of clouds [ 10 , 18 ].
Approach	Along with the equation of state, which is an equation for one thermodynamic quantity as a function of two others, this forms a complete description of the fluid, i.e. the velocity and thermodynamic state of the fluid at any point.
Approach	Given appropriate initial conditions and boundary conditions, the equations can be used to advance the solution forward in time.
Approach	At the boundaries, a well-posed problem can be formed by specifying information for all the variables except the pressure, where the solution needs to be calculated [ 8 ].
Approach	Not only does this mean that compressibility effects can be modeled, but the equations can be solved much faster.
Approach	When an incompressible formulation is used, there is an elliptical partial differential equation involved, corresponding to an “infinite” speed of propagation of pressure waves.
Approach	This typically translates into solving a large matrix equation, usually by iterative techniques, to ensure the pressure field is consistent with the velocity field.
Approach	This is usually a time consuming part of the solution method and does not scale well as grid resolution is increased.
Approach	Using the compressible formulation means that calculation times for each time step are essentially linear in the number of grid points.
Approach	In summary, conservation of mass is expressed in the compressible equations by the mathematical statement that changes in density for a parcel of fluid are the result of divergence in the velocity field.
Approach	The equations being used here do not make that assumption and buoyancyeffects dominate the dynamics in most of the examples presented.
Approach	For instance, a situation of having a colder fluid on top of a hotter fluid is not necessarily an unstable arrangement, due to the stratified hydrostatic pressure in the atmosphere.
Background	This concept is defined in most meteorology texts [ 3 ].
Approach	These forcing functions can be analytical functions of the other variables, such as coriolis or buoyancy terms, or can come from other sources, such as images and animations.
Approach	These terms have many interpretations, from molecular diffusion, to turbulence modeling, to numerical stability devices.
Approach	Most ODE solvers (ordinary differential equation), including the fourth order Runge-Kutta scheme employed here, require some level of diffusion to avoid nonlinear instabilities.
Approach	Equations are derived for including texture mapping information, so that particle trajectories don’t need to be computed via integration later.
Approach	The equations being solved are essentially those in [ 10 ].
Approach	The subgrid scale model is replaced by diffusion terms with constant diffusion coefficients, and the rain processes and coriolis terms are neglected.
Approach	Also, the coefficient for the sound speed is multiplied by a constant, introducing artificial compressibility, so that the time step requirement is less severe.
Approach	The primary variables being advanced forward in time are u; v; and w , which are the velocity components in the x;y; and z directions, respectively, the pressure perturbation variable, , defined in equation 9, and the potential temperature,   , defined in equation 8.
Approach	The meteorology convention of using z as the up direction is used here.
Approach	Base state variables, denoted by overbars, are time-invariant functions of z , the vertical coordinate.
Approach	A two-dimensional version of the above equations can be derived by assuming that in one of the horizontal directions there is no flow and no change in any of the variables.
Approach	Taking y to be the flowless direction, equation 2 is no longer needed, and simplifications are made to equation 4 and to the material derivative and Laplacian operators to account for zero derivatives in the y direction.
Approach	In addition to the basic equations of fluid motion, equations can be appended to the system which may or may not have feedback into the basic equations.
Approach	Equation 11 is the prototypical passive scalar equation, which models an arbitrary scalar being advected along with the fluid, and optionally diffusing through the non-negative diffusion coefficient .
Background	(11)          Derivations of the equations of motion from first principles can be found in many textbooks for the interested reader [ 3 , 11 , 15 , 17 ].
Approach	A convenient way to record the flow field history is through the dynamic evolution of texture map information.
Approach	The idea is to initialize passive scalar variables with the original positions of the fluid parcels.
Approach	These variables would obey equation 11, and let you know the original location of the parcel at any stage in the simulation, at the fixed grid locations.
Approach	This Eulerian description is particularly useful in the rendering phase, since the texture mapping coordinate information is evenly spaced in the output image space.
Approach	Suppose we are running a two-dimensional simulation on a recttal angular texture domain map of variable, physical x dimensions , with initial L x condition by L z .
Approach	Define x x; a horizonz; 0 = x=L z x; x and z; 0 a vertical = z=L z texture .
Approach	If both map of variable, these variables z , with obey initial equation condition 11, texture then at map a later coordinates time, t , at x time x; z;t t =0 and for z the x; parcel z;t will at location contain x; the z at time t , that is, they tell where the parcel of fluid “came from.
Approach	The solution method for solving the system of equations is the fourth order Runge-Kutta scheme, using fourth order centered finite differencing for spatial derivatives on a regular grid with equal grid spacing.
Approach	At boundary points and one point away, one-sided differencing is used.
Approach	The advective terms are those not involving partial derivatives with respect to time.
Approach	The equations will now look like equation 14 where the prime in equation 14 denotes differentiation with respect to time.
Approach	The right hand side of the equations become f y .
Approach	The solution vector is initialized with values at the regularly spaced grid locations, then advanced forward in time according to the time integration scheme.
Approach	This involves evaluating the function f y at each of the grid points, making use of the solution vector in a stencil of grid points surrounding the grid point being evaluated.
Approach	First and second derivative terms are replaced by their fourth order finite difference approximations, which can be found in [ 1 ].
Approach	The overall method is globally fourth order accurate in space and time, provided that the initial conditions, boundary conditions, and forcing functions are sufficiently smooth.
Approach	The fourth order accuracy is not required for production purposes, but the effort in achieving this added accuracy is not significant, and the increased accuracy allows for the use of coarser grids.
Approach	For instance, comparing Runge-Kutta fourth order with Euler’s method, four function evaluations per time step are required for Runge-Kutta compared with one for Euler, but this is almost offset by the time steps which can be 2.82 times larger, according to equation 15.
Approach	The time step limitation for stability for the advection problem, i.e. negligible diffusion, is          (15)          where t is the time step, x is the grid spacing, n is the number of space dimensions, c is the speed of the fastest moving wave in the system, and m is a factor that accounts for the spatial differencing method.
Approach	For fourth order centered first derivatives, this factor turns out to be 1.372, compared with 1.0 for second order centered first derivatives.
Background	Numerical methods for fluid dynamics can be found in a variety of places [ 5 , 8 ], and an extensive book list and summary of available codes can be found at http://chemengineer.miningco.com/msub74.htm .
Background	In a traditional animation studio, most artwork and animation is two dimensional; the illusion of depth comes from the drawn or painted perspective, along with the camera moves and techniques available in the compositing software.
Approach	Many simulation and rendering techniques were used in the visual development stage of the film.
Approach	Test animation resulted from three-dimensional simulations with temperature being visualized via volume rendering, two-dimensional simulations creating velocity fields used for line integral convolution of source imagery, as well as other techniques.
Outcome	By far, the biggest success was twodimensional simulations of buoyant instabilities, where the temperature field was visualized as smoke.
Approach	The plan was to use this technique to create “magical smoke” for the sequence Playing with the Big Boys, and the process was streamlined with this in mind.
Approach	The components described in sections 4.2-4.4 were built to support two-dimensional simulations which use images and animations as input.
Approach	The simulations output information at regular intervals which is later used in the compositor for rendering.
Outcome	Some of the advantages of these decisions are described below.
Outcome	The top element was scaled and had animating transforms to match to the motion of one of the magician’s hands.
Outcome	The lower element had an animating transform to react to the sliding of one of his feet.
Approach	Individual layers allow artists to make independent decisions for colors, opacities, rendering parameters, and transforms.
Outcome	Some of the lower resolution final elements used in the film were created in under two minutes, and even the highest resolution simulations could be set up using the information gathered in simulations taking only a few minutes.
Approach	Deferred rendering means that no rendering decisions need to be made at simulation time, and no simulation time is required at render time.
Approach	Artists choose rendering parameters later, e.g. to alter final timing or to animate contour levels that make the smoke slowly dissipate.
Approach	At render time, a library of potentially useful simulations is already built up, and rendering involves little more than appropriate resampling (see section 4.4).
Approach	Although the code is capable of handling more general situations, such as analytically defined forcing functions, gravitational fields, and diffusion coefficients, only a subset of the functionality is available via the user interface.
Approach	Images define the initial conditions for velocity and temperature.
Approach	Scalar variables on the interface aid the software in interpreting the images, e.g. assigning values to the black and white limits of the images.
Approach	Similarly, images and animations are employed to apply forcing terms to the momentum and energy equations.
Approach	In addition, two images are used to optionally assign profiles to the horizontal velocity and the temperature as functions of z .
Approach	This makes it easy to set up shear flows and stratified layers of density.
Approach	Using the simulation starting interface, animators can set other parameters such as the resolution, boundary condition types, output frequency, etc., and can monitor simulations in the viewer described below.
Approach	If a simulation is evolving unsatisfactorily, an animator can quickly restart it using modified images or parameter settings.
Approach	Before the simulation is run, the system performs a preprocessing step on the images, essentially resampling them and slightly smoothing them for the appropriate simulation resolution, and enforcing periodic conditions if needed.
Approach	It also calculates the initial pressure field from the temperature field, ensuring that the hydrostatic relationship is satisfied for vertical columns of fluid.
Approach	As the simulations are running, or afterward, animators can preview and optionally render the results to disk via the interface shown in figure 6 .
Approach	This previewer is a simple mapping of the temperature values to the luminance of the black and white images.
Approach	More rendering options described below are available in the compositor.
Approach	The compositor is a graph-based system (DAG) where rendering operations are “nodes” in the graph.
Approach	Values outside the linear range are clamped to “clear” or “solid.
Approach	” One node maps the results of simulations done on a rectangle with periodic sides onto a circle, as in middle of figure 8, and the other renders the rectangular temperature field.
Approach	All of the parameters, such as the timing and threshold values, have animation curves.
Approach	The rendering process involves reading the data from disk at the simulation resolution and performing resampling with a two-pass, one-dimensional cubic convolution kernel.
Approach	It is important to do periodic extensions before resampling to avoid seams at the periodic boundaries, and to do thresholding after resampling to avoid stair-step effects for magnification near the threshold values.
Approach	Inputs to this node are an image to be distorted, a simulation number, a reference time, and a current time.
Approach	The image is distorted based on the flow field evolution between the reference time and the current time, using the texture mapping data for those two times.
Approach	A single smearing uses one static flow field and a time range for the integration, provided by the user.
Approach	Each output pixel receives its color from the colors visited along a flow integration path passing through the output pixel between the two specified times.
Approach	The example times quoted below are for a single processor SGI O2 with R10K floating point chip and processor chip.
Approach	Calculation times are given for simulation time steps.
Approach	Unless the grid is extremely large, structures moving by one grid point corresponds to a reasonable speed for an animation.
Approach	For render times, the quote is for producing 640 by 480 images.
Approach	In the first example, an image defines the initial temperature distribution and drives the dynamics of the simulation.
Approach	The lettering in “SI99RAPH” is colder than the surrounding fluid, which causes it to sink.
Approach	Conservation of mass dictates that there be areas of return flow as the cold fluid sinks, creating vortices.
Approach	There is enough variation in the initial distribution such that the nonlinear equations result in pleasing graphic shapes and interesting dynamics.
Approach	This simulation was run on a 400 by 300 grid, with periodic sides.
Outcome	Calculation time between time steps is 19.8 seconds, which include the texture mapping calculations.
Outcome	Render time for frames such as figure 1 is 3.16 seconds per frame.
Approach	As described in section 3.2.1, texture mapping information can be calculated along with the simulation to provide rendering information.
Approach	Particle advection through the dynamically evolving velocity field is thus precalculated, eliminating the need to calculate particle trajectories at render time.
Outcome	An average render time for distortions such as those depicted in figure 2 is 9.8 seconds per frame.
Approach	The second example simulates heat being introduced at the bottom of the domain creating “magical smoke” (see figure 7 ).
Approach	The initial temperature distribution is a random noise pattern with an overall average temperature which is essentially constant except in a narrow layer near the bottom, where it is hotter.
Approach	The only images that are not scaled by zero, are the images used to define the unstable profile and the random perturbations in the initial temperature.
Approach	The simulation is performed on a 960 by 321 grid, with the rendering aspect ratio adjusted to make the shapes look taller and thinner than the actual simulation, which would otherwise promote rising plumes with essentially round circulation patterns.
Outcome	One time step calculation takes 36.3 seconds, and one rendered frame such as at the top of figure 7 takes 4.7 seconds to render.
Approach	In figure 8 , “magical blood” is created by a simulation driven by a random forcing function in the temperature equation, defined by one of the input images.
Outcome	Using the circular rendering option and a periodic simulation domain creates a seamless texture mapping with the appearance of blood emanating from the center of the bowl.
Outcome	The final composite shows the circular shape being repositioned in perspective, registered to the bowl.
Approach	Everything can be defined and rendered in one pass within the compositing package, including the animating perspective transformation.
Approach	The simulation resolution is 150 by 151.
Outcome	Time step calculation time is 2.7 seconds per time step and rendering time is 1.57 seconds per frame.
Outcome	This paper presents a complete production system which enables animators to access the beauty and realism embodied in the physically accurate equations of motion, the Navier-Stokes equations.
Outcome	With this system, animators can express themselves by controlling the simulation dynamics through a familiar user interface—the use of images and animations.
Outcome	Texture mapping features allow deferred rendering of flow distortions, with no need to recompute particle trajectories through a time-evolving velocity field.
Outcome	A compressible formulation and two-dimensional simulations allow for quick turnaround time in the creative cycle of creating/modifying simulations and applying the results within the compositor to the final scene.
Outcome	While this production system emphasizes the needs of a traditional animation environment, many of the concepts apply outside this context as well.
Outcome	All of the equations, including the texture mapping equations, extend to three dimensions.
Outcome	One of the most useful ideas presented here for three-dimensional simulations is the implementation of an artificial speed of sound through the compressible formulation of the equations.
Background	Atmospheric researchers often use the compressible formulation because of its computational advantages over the incompressible formulation, even when using the actual speed of sound for pressure waves.
Outcome	For computer graphics purposes, an artificial speed of sound of an order of magnitude less than the actual one is often justified, and provides a mechanism for dramatic speed increases.

Background	The most widely used skeletal animation algorithm, linear blend skinning, is also known as skeleton subspace deformation, vertex blending, or enveloping.
Challenge	It runs in real-time even on a low-end hardware but it is also notorious for its failures, such as the collapsing-joints artifacts.
Outcome	We present a new algorithm which removes these shortcomings while maintaining almost the same time and memory complexity as the linear blend skinning.
Outcome	Unlike other approaches, our method works with exactly the same input data as the popular linear version.
Outcome	This minimizes the cost of upgrade from linear to spherical blend skinning in many existing applications: the data structures and models need no change at all.
Challenge	The paper discusses also theoretical properties of rotation interpolation, essential to spherical blend skinning.
Challenge	Real-time animation of deformable objects is always a compromise between visual fidelity and computation complexity.
Challenge	Other aspects are quite important as well, for example the amount of artists work necessary to design the model.
Background	Therefore, there exist many algorithms for modeling deformable objects in the literature.
Background	They differ by the intended area of application and generality of allowed models.
Approach	We focus on the real-time animation systems in this paper.
Background	Its most popular representative, known generally as the skeletal animation, is based on simple but versatile structure.
Background	It consists of joints, given by their position and orientation.
Background	The segments connecting the joints are conveniently interpreted as bones.
Background	The skeleton is, formally speaking, a tree whose nodes are identified with the joints and edges with the bones.
Background	The only displayed element is a skin, a 3D polygonal mesh, usually equipped with normal and texture data.
Background	Although the terminology is adopted from the virtual humanoid modeling, the skeletal animation is not limited to character animation – it can be applied to a wide range of soft objects, including imaginary (cartoon) creatures, plants, furniture, etc.
Background	This is an apparent advantage over complex systems which rely on explicit anatomy.
Background	The skeleton simplifies the animation task considerably: instead of animating each vertex individually, it is sufficient to manipulate the skeleton, and the skin deforms automatically.
Background	The skeletal animation in general does not specify how exactly the skeleton posture should be propagated to the skin.
Background	However, there is an established standard used in majority of real-time 3D applications.
Background	It comes by many names, all relating to the same algorithm: linear blend skinning (LBS), skeleton subspace deformation, vertex blending, enveloping, or simply skinning.
Background	Basically, this algorithm blends between rigidly transformed vertices using vertex weights, which denote the amount of influence of individual joints.
Challenge	Although LBS is very fast and advantageous to graphics hardware, it suffers from inherent artifacts, known as ”collapsing joints”, ”twisting elbow problem” or a ”candy-wrapper artifact”.
Challenge	In general, the mesh deformed by LBS loses volume as the joint rotation increases.
Background	An early contribution concerning the animation of deformable objects is [Magnenat-Thalmann et al. 1988], which considers the movement of a human hand.
Background	First 3D characters used in numerous computer games were animated by simple, often unpublished algorithms.
Background	Later on, the basic principles of LBS were described by the game development community [Lander 1998; Lander 1999].
Background	The artifacts of LBS were discovered soon [Weber 2000].
Background	An improvement based on addition of auxiliary joints has been also proposed in [Weber 2000].
Challenge	Although this reduces the artifacts, the skin to joints relationship must be re-designed after joint addition.
Background	The number and location of the additional joints remains questionable.
Challenge	Another problem is how the movement of the original skeleton should be propagated into the augmented one.
Background	More formal articles consider skin deformation as an interpolation problem, such as [Lewis et al. 2000].
Background	They use radial basis functions to interpolate between example skins with different shapes.
Background	Similar method is presented in [Sloan et al. 2001] and [Kry et al. 2002].
Background	The latter de-correlates the deformation displacements using principal component analysis, which reduces the memory requirements considerably.
Background	The advantage of example based methods is that they capture the designed shape, including effects like muscle bulging.
Background	The drawback is the necessity of acquiring the example skins.
Background	An interesting generalization of LBS is called multi-weight enveloping [Wang and Phillips 2002].
Background	It introduces more parameters and therefore greater flexibility to the deformation algorithm.
Background	Instead of one weight per influence (joint) as in LBS, the multiweight enveloping uses twelve.
Background	These numerous parameters are derived from examples using the least squares optimization.
Background	The disadvantage is obvious: while the LBS models can be weighted manually by artists [Steed 2002], this is questionable with multiweight enveloping.
Background	Tools that help animators to design the vertex weights are described in [Mohr et al. 2003].
Background	This article is interesting also from the theoretical point of view, because it describes how to explore the space of all possible LBS deformations.
Background	Another deformation algorithm [Bloomenthal 2002] uses a complex auxiliary structure – a medial.
Background	An idea similar to spherical blend skinning (SBS) is bones blending proposed by [Kavan and Zára ˇ 2003].
Background	However, bones blending is limited to vertices attached to only two joints.
Background	In addition, it requires hand-tuning of special parameters.
Background	Another algorithm removes the LBS artifacts by adding additional joints, and computes the vertex weights automatically using examples [Mohr and Gleicher 2003].
Background	A recent skin deformation algorithm presented in [Magnenat-Thalmann et al. 2004] seems to give results competitive to SBS, although it is based on a different mathematical fundament [Alexa 2002].
Background	However, this method is considerably slower than LBS and therefore [Magnenat-Thalmann et al. 2004] recommends to use rather the standard LBS if the joint rotations are small.
Background	To conclude, there are many methods correcting the problems of LBS, but none of them is superior to LBS in all aspects.
Background	As a result, the linear blend skinning is still widely used in many applications, in spite of the artifacts.
Challenge	We observed that the artifacts of LBS are caused by the straightforward, linear interpolation of vertex positions.
Challenge	Intuitively, a linear blending is not suitable to capture deformations induced by skeleton, because their nature is rather spherical.
Approach	Our basic idea is to change the interpolation domain: we interpolate transformations itself instead of transformed vertex positions.
Approach	Because we consider transformations consisting of a translation and rotation, we suggest to use a quaternion representation.
Challenge	The transition to non-linear interpolation domain is not elementary.
Challenge	In order to achieve our goal, we cope with two main problems: determination of the center of rotation, and interpolation of multiple quaternions.
Challenge	The first problem follows from the fact that the choice of the center of rotation influences the result of interpolation considerably.
Outcome	We show how to compute a convenient center of rotation in real-time.
Challenge	The second problem is simple in the case of two quaternions [Shoemake 1985], but gets considerably harder for more than two rotations [Buss and Fillmore 2001; Park et al. 2002; Alexa 2002].
Approach	Because the previous methods are not efficient enough for our purpose, we use a simple linear quaternion averaging.
Outcome	We justify both theoretically and experimentally that this solution is appropriate for our task (and probably for many others).
Outcome	Resolving those problems, we obtain a skin animation algorithm that deforms the mesh in much more plausible way then LBS.
Outcome	Because we change only the interpolation domain and not the input data, our program works with exactly the same models as LBS.
Outcome	The proposed algorithm improves a deformed shape even of models that have been designed and carefully tuned for LBS.
Outcome	Considering the high speed and low memory demands of SBS, it provides an attractive alternative to classic LBS.
Approach	Let us denote matrices by capital letters, while vectors and quaternions by bold.
Approach	Vectors are considered column vectors, therefore a multiplication of vector v by matrix M is written as Mv.
Approach	We do not introduce a different notation for the R 3 vectors and their homogeneous R 4 counterparts with last coordinate equal to 1.
Approach	The same convention is used for matrices.
Approach	We denote the dot product of two vectors v 1 , v 2 as (v 1 , v 2 ) and the norm v 1 as a shortcut for (v 1 , v 1 ).
Background	The input to LBS consists of a polygonal mesh representing the digital skin, a skeleton, and vertex weights for every vertex of the skin.
Background	The polygonal mesh and the skeleton are designed in a reference position, e.g. virtual characters are often posed in the da Vinci posture [Steed 2002].
Approach	Let us label the joints by integer numbers, assigning zero to the root.
Approach	Each joint in the reference posture is associated with a homogeneous matrix, describing its position and orientation in the world coordinate system.
Approach	For j-th joint, we denote this matrix by A j , like ”absolute” (or reference) position.
Approach	This matrix is computed by multiplying all the transformations of individual joints in the chain from root to joint j.
Approach	To compute the shape of the deformed skin, we need yet another set of matrices, describing the position and orientation of joints in the actual, animated posture.
Approach	We call them F j , standing for the ”final” placement of joint j.
Approach	Matrices F j are computed in a similar way as the absolute matrices, but including the actual rotation of each joint in the chain (we do not consider translating and scaling joints).
Approach	The most simple skin deformation algorithm computes v = F j A −1 j v where v is a vertex in the reference skin associated with joint j and v is its position in the deformed mesh.
Approach	The interpretation is following: the first matrix A −1 j transforms v to the position with joint j’s coordinate system aligned to the world coordinate system.
Approach	The following transformation F j returns the vertex to its current position induced by the animated skeleton.
Approach	Because these transformations usually occur together, we define the ”complete” matrix C j = F j A −1 j .
Background	Some older computer games animated characters in this way, even though it does not produce nice, smooth deformations.
Approach	The linear blend skinning allows assignment of one vertex to multiple bones.
Approach	Assume that vertex v is attached to joints j 1 , . . . , j n with weights w 1 , . . . , w n .
Approach	The weights are coefficients of a convex combination, i.e. non-negative and ∑ n i=1 w i = 1.
Approach	The weight w i represents the amount of influence of joint j i .
Approach	For example if n = 2 then vertex v lies on the line segment connecting C j 1 v and C j 2 v.
Approach	The actual position on the segment is given by weight w 1 (or w 2 , because w 1 +w 2 = 1).
Approach	As explained in the next section, the SBS works on a circular arc instead of segment, see Figure 1 .
Approach	If the joint rotations are large, the LBS produces non-natural deformations.
Approach	In the extremal case of rotation by 180 degrees, the skin can collapse to a single point.
Approach	It is the notorious ”candy-wrapper” artifact, which is demonstrated in Figure 2 .
Approach	The right shoulder of the model is twisted by 180 degrees, while the left shoulder is left in the reference pose.
Approach	To understand why this undesirable effect occurs, it is sufficient to re-arrange the equation (1)
Approach	This formula is less efficient, because it blends matrices instead of vectors, but gives us a valuable insight.
Approach	It is well known that the component-wise interpolation of matrices produces odd results: it does not preserve the orthogonality of the rotational part of the matrix.
Approach	In some situations, it does not preserve even the rank of the interpolated matrices.
Challenge	This is exactly what happens in the ”candywrapper” problem: the single point the skin collapses to is a result of transformation by a singular matrix.
Challenge	A similar defect is visible also in the proximity of the singular configuration.
Challenge	Although the matrix is regular, it involves a non-uniform scaling and skewing, which is responsible for the loss of volume of the deformed skin even for small rotations.
Challenge	Instead of trying to correct the bad results of LBS, we propose to change the interpolation method in (2).
Approach	We focus on the interpolation of rotations – the linear interpolation of the translation part of C j i matrices is all right.
Approach	An established interpolation of two rotations is spherical linear interpolation (SLERP) [Shoemake 1985].
Approach	Its key of success is the use of quaternions to represent rotations.
Approach	Unfortunately, it is not possible to simply replace matrices C j i in (2) with corresponding pairs quaternion-translation.
Approach	One of the problems is that the linear interpolation of quaternions is not equivalent to SLERP.
Approach	However, this is not the most serious difficulty, and we address it in section 4.1.
Challenge	The more important problem is to compute a convenient center of the interpolated rotations.
Challenge	We show that this is really an important problem on an example of human arm.
Approach	Consider that the arm geometry is influenced by two joints j 1 and j 2 , such that j 1 is a parent of j 2 , as in Figure 1 .
Approach	The transformation of the whole mesh by C j 1 is illustrated in the top row of Figure 3 and the transformation of the same geometry by C j 2 in the bottom row (note that the results are identical in both columns of these rows).
Approach	The rows in the middle show the progress of interpolation between C j 1 to C j 2 .
Approach	The only difference between the two columns in Figure 3 is in the choice of the center of rotation.
Approach	In the left column, the rotation center r c is set to the translation part of matrix A j 2 (the position of joint j 2 in the reference posture).
Approach	Note that C j 1 r c = C j 2 r c , therefore also the transformed rotation center is constant during the interpolation.
Approach	In the right column of the figure, the rotation center r c is set to the translation part of A j 1 .
Approach	Because C j 1 r c = C j 2 r c , the transformed rotation center is linearly interpolated from C j 1 r c to C j 2 r c .
Approach	By comparison with the starting mesh (drawn gray in each frame), it is obvious that the center of rotation choice in the left column is much more advantageous.
Approach	In this case, the interpolation of every single point is a circular arc (as in Figure 1), whereas a disturbing drift is inherent to any other choice of rotation center (such as r c ).
Approach	Unfortunately, the condition of zero translation cannot be always satisfied, typically for more than two influencing joints.
Approach	But even if the vertex is attached to only two joints k and l that are not neighbours of each other, some translation may be inevitable.
Approach	For example consider that there is no relative rotation between C k and C l , but there is a relative translation induced by the joints in the chain between k and l.
Approach	Clearly no choice of the center of rotation can avoid this translation, because the rotation is identity.
Approach	Anyway, it is possible to define the rotation center as the point whose transformations by associated matrices are as close as possible.
Approach	This minimizes the drift and works even if the vertex is assigned to n joints j 1 , . . . , j n .
Approach	In general, we cannot make any assumptions about the rank of matrix D, which can vary from 0 to 3 (consider for example n = 2 and C j 1 = C j 2 ).
Approach	We search the optimal solution r c in the least-squares sense.
Approach	If there are multiple solutions giving the minimal Dr c − e , the r c with the minimal norm is chosen.
Approach	This can be done in a robust way using the singular value decomposition (SVD), followed by computation of pseudo-inverse matrix.
Approach	To perform these computations, we use the LAPACK software [Anderson et al. 1999].
Approach	Even though LAPACK routines are efficient, computation of the center of rotation per each vertex would not result in a real-time algorithm.
Approach	Fortunately, the center of rotation depends only on the transformations of the joints j 1 , . . . , j n and not the vertex itself.
Approach	Therefore, if we encounter another vertex assigned to the same set of joints j 1 , . . . , j n , we can re-use the center of rotation computed formerly (cached).
Approach	Moreover, if there is only one, or two neighboring joints that influence the vertex, we can determine the center of rotation precisely (as indicated in the beginning of this section) and omit the SVD computation at all.
Approach	It turns out that the number of different non-trivial joint sets, and therefore the number of running the SVD, is surprisingly small for common models – about several tens.
Approach	This enables the real-time performance.
Background	As mentioned in the introduction, the interpolation of multiple rotations has already received some attention [Buss and Fillmore 2001; Park et al. 2002] as well as interpolation of multiple general transformations [Alexa 2002].
Background	Unfortunately, all these methods are substantially slower then the simple linear interpolation used in LBS.
Challenge	Since our goal is an algorithm with comparable time complexity as LBS, we propose an approximate but fast linear quaternion blending.
Approach	For the case of two rotations, we compare our method with the established SLERP.
Approach	Recall that a rotation around axis a (unit length vector) with angle 2 α corresponds to quaternion q = cos α + a sin α .
Approach	However, this correspondence is not unique, because both quaternions q and −q represent the same rotation.
Approach	The SLERP of two unit quaternions p, q assumes that their dot product (p, q) ≥ 0.
Approach	If the dot product (p, q) < 0, we use −p instead of p, which is possible because both p and −p represent the same rotation.
Approach	The SLERP of p, q with interpolation parameter t ∈ 0, 1 is given by the following formula, see for example [Eberly 2001].
Approach	The difference to SLERP is obvious: QLERP interpolates along the shortest segment, and then projects to arc, which does not result in the uniform interpolation of the arc.
Approach	In spite of this, we claim that QLERP is sufficient for our task.
Approach	In order to justify this statement, we face an interesting question by itself: how big can be the difference between QLERP and SLERP for the same input rotations?
Approach	For SLERP, we denote this quaternion as r s (t).
Approach	The quaternion 1 represents the identity (zero angle rotation).
Approach	From the definition of quaternion multiplication it can be seen that the real part of p ∗ q equals (p, q) = cos θ .
Approach	Since p ∗ q is a unit quaternion, we can express it as p ∗ q = cos θ + u sin θ for some axis of rotation u.
Approach	If we substitute this into equation (5), we obtain sin((1 − t) θ ) + sin(t θ ) cos θ r s (t) = sin θ + u sin(t θ ) which means that the direction of the axis u is independent on t.
Approach	Let us examine the rotation r l (t) following p in QLERP: r l (t) = p ∗ l(t; p, q) = (1 (1 − − t)1 t)p + + tp tq ∗ q = (1 − t + t cos θ ) t sin θ = + u (1 − t)p + tq (1 − t)p + tq which shows that the axis of rotation has the same direction.
Approach	We can conclude with an important property: the SLERP can be written as pr s (t) and QLERP as pr l (t), where the rotations r s (t) and r l (t) have the same axis.
Approach	Moreover, this axis is constant, i.e. independent on the interpolation parameter t.
Approach	It follows that the only difference between QLERP and SLERP is in the angle of rotations r s (t) and r l (t).
Approach	Note that both r s (t) and r l (t) have a form of linear combination of quaternions 1 and p ∗ q.
Approach	It means that the results of both r s (t) and r l (t) always end up in certain 2D subspace of R 4 .
Approach	We can restrict our attention to this subspace (the linear hull of 1 and p ∗ q).
Approach	Since SLERP assumes cos θ = (p, q) ≥ 0, the angle θ cannot exceed π /2.
Approach	To obtain an upper bound of the maximal difference in the angle, we consider the extremal case with θ = π /2, depicted in Figure 4 .
Approach	The angle α (t) on the picture can be computed by atan, and β (t) by simple linear interpolation of the right angle, which yields the difference function t π d(t) = α (t) − β (t) = atan − t 1 − t 2 It remains to find the extremes of d(t) on the interval 0, 1 .
Approach	The elementary mathematical analysis discovers the global extremes in points 1/2 ± (1/ π − 1/4).
Approach	The absolute value of d(t) in these points is approximately 0.071 radians (4.07 degrees).
Approach	As mentioned in the introduction of this section the angle of rotation is twice the angle inclined by quaternions.
Approach	To conclude: both SLERP and QLERP interpolate by multiplying the first quaternion with a rotation with the same, fixed axis.
Approach	The difference between SLERP and QLERP is only in the angle of this rotation, and is strictly less then 0.143 radians (8.15 degrees) for any interpolation parameter t ∈ 0, 1 .
Approach	This is an upper bound; practical results are much smaller and could hardly cause an observable defect in the deformed skin.
Approach	The big advantage of QLERP is that it can be easily generalized to interpolate multiple rotations – it suffices to make a convex combination and re-normalization of multiple quaternions.
Approach	Now we have prepared all the ingredients to describe how the SBS algorithm works.
Approach	The task is to transform a vertex v influenced by joints j 1 , . . . , j n with convex weights W = (w 1 , . . . , w n ) to its position v in the animated skin.
Approach	In order to obtain an appealing deformation, it is necessary to respect the computed center of rotation r c .
Approach	To achieve this, we extend the QLERP scheme to homogeneous matrices C j i .
Approach	First, the rotation submatrices C rot j i are converted to quaternions q j i .
Approach	One of them, for example q j 1 , is chosen as pivot.
Approach	If (q j 1 , q j i ) < 0 for any i = 2, . . . , n, we replace q j i with −q j i (by analogy to SLERP).
Approach	In order to change the center of rotation from the origin to r c , we define a homogeneous matrix        T = 0 I T r 1 c (7)        where I is a 3 × 3 identity matrix.
Approach	Note that the shift of the center of rotation does not influence the interpolated rotation – it manifests only in the translation part.
Approach	The desired transformation of vertex v is v = T q(W ; T −1 C j 1 T, . . . , T −1 C j n T )T −1 v
Approach	The equation (9) has to be evaluated once per each vertex, and therefore should be as efficient as possible.
Approach	The basic optimization is to pre-compute the quaternions q j i , because they do not depend on the actual vertex – only on the joint’s transformation, similarly as the rotation centers r c .
Approach	Nonetheless, QLERP has to be executed for each vertex, since weights w 1 , . . . , w n can vary.
Approach	In order to challenge the speed of LBS, we apply a following trick.
Approach	The vertex v can be represented by a quaternion with zero real part.
Approach	In this representation, its rotation by quaternion q can be expressed as q vq ∗ , which is a quaternion with zero real part as well [Eberly 2001].
Approach	Therefore, we can compute the Q matrix from (9) as Q = (s,s) Q and save the sqrt operation.
Approach	Some attention must be paid because standard routines for quaternion to matrix conversion assume a unit-length quaternion.
Approach	First, if we substitute r c in place of v, no rotation occurs, which means that r c is indeed a center of rotation.
Approach	Second, if n = 2 and C j 1 r c = C j 2 r c (as in the beginning of section 4), the translation part becomes w 1 C j 1 r c + w 2 C j 2 r c = (w 1 + w 2 )C j 1 r c = C j 1 r c which is independent of interpolation parameters (weights), i.e. the translation during interpolation is constant indeed.
Approach	Third, the equation (9) is nothing but a generalization of LBS to an arbitrary method of rotation interpolation.
Approach	The choice of QLERP is not important for (9), the matrix Q can be replaced by matrix resulting from any other interpolation scheme, such as [Buss and Fillmore 2001].
Approach	If we substitute Q = ∑ w i C rot j i , i.e. a simple linear combination of rotation matrices, we obtain v = Q(v − r c ) + ∑ w i C j i r c = ∑ w i C rot j i v − ∑ w i C rot j i r c + ∑ w i C rot j i r c + ∑ w i C tr j i = ∑ w i C rot j i v + ∑ w i C tr j i = ∑ w i C j i v which is exactly the LBS equation (1).
Approach	This also shows that LBS is a special case, which is independent of the center of rotation.
Approach	The whole algorithm can be summarized in the following steps:
Approach	We tested the SBS algorithm on three models, see Figure 5 and Table 1.
Approach	We compare the shape of the deformed skin on the model of woman, because human eye is most sensitive to the deformations of human body.
Outcome	Another example has been presented already in Figure 2 .
Outcome	For small deformations, both algorithms produce similar results, as in the second row of Figure 6 (although a small loss of volume is noticeable even there).
Outcome	It is remarkable that the results of SBS are better even though the models have been optimised to work with the LBS algorithm.
Outcome	The performance of both algorithms is compared in Table 2 .
Outcome	The measured value is an average time in milliseconds necessary to deform one model on a 2.5GHz Athlon PC (rendering time not included).
Outcome	Put in another way, it is exactly the number of singular-value decompositions performed by the SBS algorithm.
Outcome	This number participates considerably on the difference between times for LBS and SBS.
Outcome	Theoretically, the number of different non-trivial joint sets could be very high.
Outcome	Fortunately, this number is surprisingly small in practice, because the joint influences tend to be local (e.g. it is unlikely to find vertices influenced by both left and right wrist).
Outcome	The additional memory needed for SBS is dominated by caching the computed centers of rotation.
Outcome	However, this amount of memory is negligible, considering the number of different non-trivial joint sets.
Approach	In order to test the accuracy of QLERP, we experimented with spherical weighted averages presented in [Buss and Fillmore 2001].
Outcome	The algorithm proposed in [Buss and Fillmore 2001] behaves like SLERP for the case of two rotations (in contrast to QLERP, which only approximates SLERP results).
Outcome	On the one hand, the difference in the deformed skin was barely observable, according to the results from section 4.1.
Outcome	On the other hand, the increase in the execution time was quite substantial.
Outcome	For the woman model, the time increased from original 4.54ms to 22.74ms.
Outcome	This only confirmed our choice of QLERP.
Outcome	The proposed skin deformation system is by no means perfect; it cannot compete with complex, layered models.
Outcome	However, the SBS algorithm offers reasonable price for elimination of the notorious LBS artifacts.
Outcome	The time and memory complexity of both algorithms is comparable.
Outcome	The overhead of replacing an existing LBS implementation by SBS is minimal, because the input data, as well as the internal data structures, are the same.
Outcome	In contrast to other methods, the SBS does not need any additional information, such as the example skins.
FutureWork	The presented algorithm opens many questions and suggests several directions of future work.
Outcome	First of all, we worked only with vertex weights optimised for LBS.
Outcome	These weights are designed to suppress the LBS artifacts, even though they cannot remove them.
FutureWork	It would be interesting to find out how much can be the SBS results improved by a set of weights especially designed for SBS.
FutureWork	In order to accomplish this, a tool to explore the space of SBS deformations would help considerably.
FutureWork	This tool has been presented for LBS in [Mohr et al. 2003], but the situation of SBS is somewhat more complex, because our interpolation method is non-linear.
FutureWork	Similarly, it would be possible to estimate the SBS vertex weights from examples, as was done for LBS in [Mohr and Gleicher 2003].
FutureWork	This could also cover additional effects like muscle bulging.
Approach	In this appendix we derive the formula (9), which describes the interpolation of rotations with respect to r c – a custom center of rotation.
Approach	Let us denote by K the coordinate system with origin in r c and identical basis vectors as the world coordinate system.
Approach	Then        the matrix T (7) can be interpreted as a transformation from K to the world coordinate system.
Approach	We can express this matrix with respect to the world coordinate system easily T q(W ; T −1 C j 1 T, . . . , T −1 C j n T )T −1 which is exactly the formula (8).
Approach	Recall that the matrix C j i has structure C j i = C 0 rot j T i C 1 tr j i        which enables us to write out T −1 C j i T = C 0 rot j T i C j i r c 1 − r c        as can be simply verified.
Approach	Please note that the change of the coordinate system did not influence the rotation part C rot j i at all.
Approach	Therefore the result of QLERP will be, according to equation (6)        q(W ; T −1 C j 1 T, . . . , T −1 C j n T ) = 0 Q T −r c + ∑ i=1 n 1 w i C j i r c        where Q stands for the interpolation of pure rotations, computed as indicated in section 4.2.
Approach	Using T −1 v = v − r c and T x = x + r c , we see that v = T q(W ; T −1 C j 1 T, . . . , T −1 C j n T )T −1 v = T 0 Q T −r c + ∑ i=1 n 1 w i C j i r c v − 1 r c n = Q(v − r c ) + ∑ w i C j i r c i=1        is true for any vector v.
Approach	This is exactly the equation (9).

Outcome	Pose space deformation generalizes and improves upon both shape interpolation and common skeleton-driven deformation techniques.
Challenge	This deformation approach proceeds from the observation that several types of deformation can be uniformly represented as mappings from a pose space, defined by either an underlying skeleton or a more abstract system of parameters, to displacements in the object local coordinate frames.
Approach	Once this uniform representation is identified, previously disparate deformation types can be accomplished within a single unified approach.
Outcome	The advantages of this algorithm include improved expressive power and direct manipulation of the desired shapes yet the performance associated with traditional shape interpolation is achievable.
Outcome	Appropriate applications include animation of facial and body deformation for entertainment, telepresence, computer gaming, and other applications where direct sculpting of deformations is desired or where real-time synthesis of a deforming model is required.
Background	Free form deformation has been approached from several distinct perspectives.
Background	As an abstract and general problem, good methods have been obtained both using the well known technique that bears this name [ 32 , 12 , 17 ] and other kinematic surface deformation techniques, and with physical models that simulate the time evolution of a membrane or solid.
Background	The animation of human and creature skin deformation is arguably the most common and important application of free form deformation in computer graphics.
Background	While such creature animation can be considered a special case of general free form deformation, its importance and difficulty have lead researchers to propose a number of domain-specific algorithms that will be reviewed in Section 2.
Challenge	The problem of realistic facial animation is being actively and successfully addressed by image-based and hybrid techniques.
Challenge	These techniques are not yet suitable for all applications, however: while a purely image-based approach can achieve very realistic images, this advantage may be lost if one needs to introduce geometry and surface reflectance in order to re-light characters to match preexisting or dynamically computed environments.
Challenge	Film and entertainment applications require fanciful creatures that fall outside the scope of image-based approaches.
Background	Some of the most impressive examples of geometry-based (as opposed to image-based) human and creature animation have been obtained in the entertainment industry.
Background	These efforts traditionally use shape interpolation for facial animation and a standard but variously-named algorithm that we will term skeleton subspace deformation (SSD) for basic body deformation [ 25 , 9 ].
Challenge	While shape interpolation is well-liked by production animators, it is not suitable for skeleton-driven deformation.
Challenge	On the other hand SSD produces characteristic defects and is notoriously difficult to control.
Challenge	These issues, which will be detailed in the next section, lead us to look for a more general approach to surface deformation.
Challenge	New creature topologies should be accommodated without programming or considerable setup efforts.
Challenge	• It should be possible to specify arbitrary desired deformations at arbitrary points in the parameter space, with smooth interpolation of the deformation between these points.
Challenge	• The system should allow direct manipulation of the desired deformations [ 33 ].
Challenge	• The locality of deformation should be controllable, both spatially and in the skeleton’s configuration space (pose space).
Challenge	• In addition, we target a conventional animator-controlled work process rather than an approach based on automatic simulation.
Challenge	As such we require that animators be able to visualize the interaction of a reasonably high-resolution model with an environment in real time (with ‘high resolution’ defined in accord with current expectations).
Challenge	Real time synthesis is also required for applications such as avatars and computer games.
Outcome	Our solution, termed pose space deformation, provides a uniform and expressive approach to both facial skin deformation and skeleton-driven deformation.
Outcome	It addresses the previously mentioned drawbacks of shape interpolation and SSD while retaining the simplicity and performance associated with these techniques.
Background	Recent research has delivered significant improvements in many areas of character animation, including surface representation, model capture, performance capture, and hybrid (partially image-based) rendering approaches.
Background	Continuous deformation of a character skin was first addressed in Parke’s pioneering facial animation work [ 26 ].
Background	In this work, control vertices were deformed by custom algorithmic implementation of carefully selected high-level parameters (‘raise-upper-lip’, etc.).
Background	Komatsu [ 13 ] and Magnenat-Thalmann et. al. [ 23 ] demonstrated human body deformation driven by an underlying skeleton.
Background	The region and shape of deformation is algorithmically defined in each of these approaches.
Background	Magnenat-Thalmann et. al. developed algorithms for each of the various joints in the hand.
Background	The discussion in Komatsu focuses on the elbow and shows how the skin crease on the acute side can be obtained by a suitable algorithmic manipulation of the surface control vertices.
Background	The algorithms in this early work do not suffer the ‘collapsing elbow’ characteristic of the SSD algorithm (below).
Background	On the other hand, the algorithms are specific to particular types of joints and are perhaps too simple to portray the complexity and individual variability of real anatomy.
Background	The short film Tony de Peltrie [ 3 ] popularized the use of shape interpolation for facial animation.
Background	Forsey [ 11 ] describes a characteroriented deformation scheme in which the bending of a smooth surface can be controlled by anchoring levels of a multi-resolution spline surface to the underlying skeleton.
Background	These efforts are distinguished from the previous purely algorithmic approaches in giving the modeler control of and responsibility for the deformation.
Background	The specification and animation of surface deformation remains an active area of investigation [ 17 , 10 ].
Background	The Wires technique [ 22 ] is one interesting recent contribution; this approach is notable in providing a direct manipulation interface in a form immediately familiar to sculptors (armatures).
Background	Chadwick, Haumann, and Parent [ 7 ] introduced a multi-layered and physically inspired approach to skin deformation.
Background	In their model a free-form deformation abstractly represents underlying body tissues and mediates skin movement.
Background	Chadwick et. al. demonstrated expressive three-dimensional cartoon characters but deformation of a realistic character was not shown.
Background	Other researchers have investigated modeling the underlying body tissues in greater depth [ 27 , 24 , 8 , 35 ].
Background	Most recently, several groups have undertaken ambitious efforts to produce anatomically inspired multi-layered models of animals and humans with considerable verisimilitude.
Background	Nedel and Thalmann [ 19 ] simulate the surface deformation of muscles using spring mesh dynamics; a modeled skin cross section is reshaped by a ray-casting procedure that finds the maximum displacement of the underlying tissue.
Background	Several papers by Wilhelms and coworkers have shown anatomically representative human and animal models.
Background	In Wilhelms and Van Gelder [ 36 ] several classes of muscles are algorithmically modeled with attention to volume conservation; skin is a spring mesh anchored to underlying tissue or bone in appropriate areas.
Background	Scheepers et. al. [ 31 ] produced convincing representations of muscles as well as preliminary but promising skin deformation.
Background	In recent years character animation has moved beyond being a research topic and sophisticated deforming characters routinely appear in films and on television.
Background	Arguably the most common practice in character animation (as reflected in commercial software, animation books and courses, and some custom software) is founded on the twin techniques of shape interpolation and SSD [ 18 , 9 ].
Background	Shape interpolation (also called shape blending and multi-target morphing) is probably the most widely used approach to skin deformation for facial animation [ 3 , 18 , 9 ].
Background	Surface control vertices are simply an animated linear combination (not necessarily convex, i.e., individual weights can be greater than one or less than zero) of the corresponding vertices on a number of key shapes S k : k=0 w k S k 
Background	A variation of this technique uses a single base shape S 0 and a number of delta shapes, S 0 + k=1 w k (S k − S 0 ).
Background	By writing the delta shape form as (1 − 1 w k )S 0 + 1 w k S k it is clear that the space of achievable shapes is identical in both variations.
Background	1 An attractive feature of shape interpolation is that the desired expressions can be directly specified by sculpting.
Challenge	Given the popularity and effectiveness of this simple approach, it would be desirable to employ it on regions of the body other than the face.
Challenge	The blending of rigid shapes is inconsistent with regions of the body that are bending under the action of an underlying skeleton, however.
Challenge	Of course the key shapes could be deformed to the moving articulated figure using some other algorithm, but this defeats the purpose of proposing shape interpolation as the means of obtaining the deformation in question.
Challenge	Shape interpolation also has some drawbacks for its intended role of facial animation.
Challenge	For one, the interpolation is not always smooth.
Challenge	Consider interpolating from a smile (shape A) to a neutral pose (B) and then to a frown (C).
Background	In practice animators object to the linear nature of the interpolation [ 34 ] and have sometimes compensated by sculpting new key shapes as often as every three to five frames [ 38 ].
Background	This simple algorithm has been repeatedly conceived and appears in commercial software packages under several rather uninformative names such as skinning, enveloping, etc.
Background	The algorithm is unpublished but is subsumed by more general published schemes such as [ 23 ].
Approach	The position of a control vertex p on the deforming surface of an articulated object lies in the subspace defined by the rigid transformations of that point by some number of relevant skeletal coordinate frames ( Figure 1 ).
Approach	This may be notated          p = w k L k (p) p (in more detail) p = w k L δ k L k 0 −1 L p 0 p          where L p 0 is the transform from the surface containing p to the world coordinate system, L 0 k is the transform from the stationary skeletal frame k to the world system (L 0 k −1 L 0 p together represent p in the coordinate system of skeletal frame k), and L δ k expresses the moving skeletal frame k in the world system.
Approach	The deformation is controlled by the user through the weights w k .
Background	SSD is fairly versatile.
Background	For example, secondary animation effects such as muscle bulging and swelling of the chest can be achieved by variably weighting the surface to an abstract “bone” whose translation or scale is manually animated.
Background	The first major shortcoming of SSD results directly from the fact that the deformation is restricted to the indicated subspace.
Challenge	In common situations such as shoulders and elbows the desired deformation does not lie in this subspace, hence no amount of adjusting the algorithm weights will produce good results.
Challenge	This fact leads to considerable frustration by users of the algorithm – the character of the deformation changes as the weights are changed, sometimes sustaining the incorrect assumption that some combination of weights will produce good results.
Challenge	In fact, the SSD algorithm can be easily identified in animations by its characteristic ‘collapsing joint’ defect (Figures 1, 2).
Challenge	This problem is extreme in the case of simulating the twist of a human forearm (the pose taken in turning a door handle, Figure 3).
Challenge	In this case the subspace basis consists of surface points rigidly transformed by the forearm frame (no axis rotation) and the wrist frame (axis rotation).
Challenge	With a rotation of 180 degrees this line crosses the axis of the arm, i.e., the forearm collapses entirely as the SSD weights transition at some point from the forearm to wrist frames.
Challenge	A second difficulty with SSD is that, unlike shape interpolation, it does not permit direct manipulation; artists instead directly or indirectly edit the meshes of weights w k (for each control vertex on a surface there is one weight per skeletal frame that affects the vertex).
Challenge	SSD algorithms consequently have the reputation for being tedious and difficult to control.
Challenge	Artists with a poor understanding of the underlying algorithm have difficulty distinguishing between results that can be further improved by adjusting weights and results that cannot be improved since the desired result lies outside the achievable subspace, resulting in the impression of unpredictability (“sometimes adjusting the weights helps, sometimes it doesn’t”).
Background	In some cases the SSD defects can be manually corrected using FFDs and other techniques, and one could consider a scheme whereby these fixes are procedurally invoked as the skeleton articulates.
Challenge	But although FFDs work well (and have a direct manipulation algorithm [ 12 ]) the layered FFDs do not reduce the difficulty in adjusting the underlying SSD.
Outcome	The algorithm introduced in the subsequent sections removes the need for such layered fix-it approaches and permits direct specification of the desired deformations.
Background	Several published algorithms and commercial packages combine aspects of skeleton-driven deformation and shape interpolation in ways that anticipate our approach.
Background	In the pioneering work of Burtnyk and Wein, two dimensional characters were animated using a polygonal rubber sheet that afforded both skeletal and local deformation control [ 6 ].
Background	Van Overveld described a two-dimensional animation system in which animation is controlled by a skeleton and character deformation is driven from this skeleton through a scattered interpolation [ 20 ].
Background	This work is similar in spirit to ours but differs in that it used the image plane as a global interpolation domain rather than introducing a pose space.
Background	Litwinowicz and Williams’s system [ 16 ] is also a precedent and introduced sophisticated scattered interpolation (again in the image domain).
Background	Several papers consider animation (and indeed image synthesis in general) as a special case of neural net learning and interpolation/extrapolation [ 14 , 15 , 21 ].
Background	While this viewpoint is valid, in practice it is perhaps excessively general, for example, a skeleton is merely learned rather than being an intrinsic part of the model.
Background	While employed at Industrial Light and Magic the first author of the present paper developed a system that attempted to blend shape interpolation and SSD algorithms; a small portion of it remains in use in their well known Caricature animation system.
Background	Drawbacks of this work included both a complicated dependence on the details of SSD and its overall conception as a “correction” to SSD.
Background	Some commercial packages allow blending between two sculpted deformations as a function of a single-joint rotation, thereby combining shape interpolation and skeleton-driven deformation in a limited but useful setting.
Background	The depth of simulation is a prevalent issue in computer graphics, albeit one that is not always consciously considered.
Background	Early approaches to animation were purely kinematic; an emphasis on physically based modeling appeared in the literature later.
Background	Recent sophisticated approaches allow a hybrid of animator-controlled and physically governed animation as needed.
Background	In rendering we perhaps see the opposite trend – much of the literature a decade ago focused on ever deeper simulations of reality, whereas ‘shallower’ imagebased approaches are attracting attention at present.
Background	Similarly, in character deformation both deep and shallow approaches have their place.
Background	Deep models promise universally accurate simulation, and the importance of representing humans justifies the needed effort.
Background	The authors of these approaches acknowledge that producing anatomically plausible models is a daunting task, however.
Background	Pose space deformation is a shallow, purely kinematic approach to deformation (i.e. without reference to underlying forces, mass, volume), and it has consequent disadvantages.
Background	In particular, accuracy is reliant on the modeler/animator rather than being guaranteed by the simulation.
Outcome	On the other hand, our algorithm has clear advantages with respect to simplicity and generality, direct manipulation, real-time synthesis, and other criteria listed in the introduction.
Challenge	We also wish to directly sculpt the desired deformation at various points in the parameter space, rather than working in a more abstract space such as the coefficients on various coordinate frames as required by the SSD algorithm.
Approach	A scattered data interpolation method is required because deformations will be sculpted at arbitrary (rather than regularly spaced) poses.
Approach	Since this interpolation is central to our application (the results of the interpolation will be directly visible in the animating deformation), we will consider the available scattered interpolation approaches before settling on a candidate.
Background	Shepard’s method [ 1 , 2 ] is a frequently employed scattered data interpolation scheme in computer graphics.
Background	(This is singular at the data points x k and should computed as (||x − x k + ) −p ).
Approach	With p > 1 the interpolation surface is once differentiable.
Background	Unfortunately this simple scheme has some potentially undesirable properties.
Background	Far from the data the weights will be approximately the same, d(∞) ˆ = w ∞ d k /w ∞ 1 = d k /N , i.e. the interpolated surface converges to the average of the data values.
Background	A serious drawback for some applications is that the derivative of the surface is zero at the data points ( Figure 4 ).
Background	Radial basis functions [ 28 , 29 ] have become a popular choice for scattered interpolation.
Background	The interpolant is a linear combination of nonlinear functions of distance from the data points:
Background	If N values of d are available then the weights can be easily solved by a linear system; this can be derived either by least squares fit or by subspace projection.
Approach	Taking the latter approach, we reconsider the available data points as a single point d in an N dimensional space, and consider φ k () = φ( x j − x k ) as the kth basis vector.
Approach	Any nonlinear function φ() will interpolate the data, including odd choices such as φ(x) = x (which is nonlinear since x = x − x k is the argument), provided that the columns of Φ are independent.
Approach	On the other hand a smooth φ() will result in a smooth interpolant (a weighted sum of continuous functions is continuous).
Background	In fact radial basis functions have a universal convergence property similar to Fourier series, though the convergence definition is different.
Approach	The preceding description maps a k-dimensional input space (arbitrary k) to a one dimensional range, i.e., it is the k-dimensional version of a height field.
Approach	Surfaces can of course be interpolated by allowing different combinations of the same basis functions in different dimensions, i.e., vector valued w k .
Approach	The distance can be generalized to Mahalanobis distance (effectively rotating and stretching the basis function) [ 4 ].
Background	Various visual reconstruction schemes can be adapted for scattered data interpolation.
Approach	In these schemes the interpolated or approximated surface is found as the minimum of a functional such as where the first term penalizes deviation of the surface d ˆ from the available data d and the second regularizing term votes for surface smoothness e.g. by integrating the squared second derivative of the surface.
Approach	With small λ many of these schemes can serve as scattered data interpolants; reference [ 5 ] is a good introduction to these approaches.
Approach	In some of the most powerful formulations of scattered interpolation the regularizer is considered to hold everywhere except at an unknown set of edges – this is the piecewise-smooth prior desirable in image reconstruction.
Approach	Since the unknown edges may exist (or not exist) at any location in the domain, all combinations of possible edge locations must be considered and the interpolation cost is prima facie exponential in the surface resolution.
Approach	The crux of our approach is the identification of an appropriate space for defining deformations.
Approach	As discussed above, the interpolation domain is (a subset of) the pose space of an articulated character, or equivalently the space defined by some set of parameters such as facial controls.
Approach	In concept the range of the interpolation function could simply be the desired movement of the surface control vertices.
Approach	To make the job easier for the interpolation we instead interpolate the desired deviation of a surface vertex (expressed in the local frame) from its initially computed position (the rigidly transformed position in the case of an articulated model).
Approach	Thus the deforming surface is defined by p + δ with p moved rigidly by the skeleton or other underlying system, and where configuration is the configuration of the set of joints or parameters controlled by the animator.
Approach	Our scheme can be bootstrapped on top of an existing software system: the model is posed as desired and the desired surface at that pose is sculpted.
Approach	Our algorithm computes the difference between the initial and resculpted model at that pose.
Approach	This ‘deformation’ is associated with the joints or other parameters that have moved from their default positions to create the particular pose.
Approach	One or more deformations will then be interpolated in this subspace using a scattered data approach.
Approach	We now have enough criteria to select a particular interpolation scheme.
Approach	Although it would be desirable to allow deformations to change both continuously and discontinuously with respect to the pose space, creature deformations that are discontinuous with respect to pose seem unlikely.
Approach	As such the expensive energy functional and non-convex schemes are not necessary.
Approach	In addition we want δ to approach zero away from the data, and the width of this falloff should be selectable.
Approach	Together these comments support φ k (x) = exp( −( x−x 2σ 2 k ) 2 ) as one possible choice of radial basis ( Figure 5 ).
Approach	Gaussian radial basis functions are reputed to be well behaved and our experience supports this judgement.
Background	Gaussian radial basis functions with adjustable placement and σ are discussed in the neural net literature and optimizing over these parameters is possible.
Approach	This issue does not arise in our application, however, since the animator decides where in the parameter space to sculpt a pose (effectively deciding the basis function placement).
Approach	The falloff σ is also specified explicitly by the animator, as described below.
Approach	A pose is defined as the configuration of any pose controls (joints or abstract manipulators) that have changed from their default values.
Approach	An abstract manipulator is a UI control or arbitrary piece of geometry whose movement will control the interpolation of some deformation, such as a muscle bulge or a desired facial attribute such as “happiness.
Approach	” A self-relative configuration of the controls is actually considered, for example, an elbow involves two skeletal frames but only one joint angle.
Approach	The pose space is the space spanned by the variations of these controls.
Approach	If n = 2 pose controls are active and each has three degrees of freedom then a 3(n − 1) pose space is defined, and the particular position of the controls defines a point in that space.
Approach	The artist first positions some set of pose controls and then sculpts a deformation for that pose.
Approach	The artist also assigns a falloff (Gaussian σ), either as a symmetric radius across all controls or to each control individually (axis stretched falloff).
Approach	Any control vertices that have moved from their rest position are found.
Approach	This is done in the local coordinate frame, i.e., rigid body articulated motion results in zero δ.
Approach	The δ values for the deformed vertices are computed (again in the local coordinate system) and they are saved in a database together with their corresponding location in a pose space.
Approach	(At the boundary of several surface patches there may be shared vertices that need to be coincident to maintain surface continuity.
Approach	Unlike some SSD implementations interpolation in pose space by definition cannot separate such vertices).
Approach	When several such deformations have been saved (or when the artist is ready to try animating) it is necessary to solve the interpolation problem.
Approach	For each control vertex that was moved during sculpting there are now one or more δ values at points in the pose space.
Approach	Note that the dimension of the pose space can vary across vertices, for example, a particular vertex might be modified in three sculpted deformations but a neighboring vertex might have been modified in only two deformations.
Approach	The interpolation is done independently for each control vertex (but see additional details below); in our experience using patch surfaces this has not been problematic.
Approach	Singular Φ T Φ is interpreted as a user error; in practice this has turned out to be the result of saving new deformations without moving any pose controls rather than a result of actual numerical problems.
Approach	The model is now moved to an arbitrary pose.
Approach	The location in pose space is determined from the concatenated relative degrees of freedom of the pose controls (simply interpreted as independent dimensions).
Approach	At this point the model interpolates through the previously defined deformation(s).
Approach	The most recently defined deformation may extend too far (or not far enough) in pose space, however.
Background	There is a rich literature of schemes for optimizing radial basis parameters including σ [ 4 ].
Background	On the other hand, animators consider detailed control of the animation to be part of their craft and are quite happy to have interpolation parameters exposed to them.
Approach	We have found that this potentially abstract parameter is comprehensible so long as it is possible to explore the effect of different values.
Approach	At a minimum axis-aligned scaling of the falloff should be available; we have not experimented with Mahalanobis rotation of the basis.
Approach	Based on the evaluation the artist may decide to sculpt additional poses as needed to achieve the desired motion.
Approach	A detail that was omitted previously will now be mentioned: when a deformed vertex is found the associated pose space is determined as described above.
Approach	If there are previous deformations of this vertex in the same pose space then the new deformation is simply another point to interpolate.
Approach	The new deformation’s pose space may, however, be different from the previous spaces associated with the vertex!
Approach	In such a case a new pose space is started, and the δ is computed as a delta from the previous layered PSD synthesis rather than from the base model.
Approach	This ensures that the previous deformations are interpolated while allowing the artist complete freedom in determining the extent of the deformation and the associated pose controls.
Approach	While there is an issue of commutativity, in our experience artists consider this iterative layered refinement to be a natural process.
Approach	This is a well known issue; well behaved transformations are fundamental and are hopefully addressed early in the development of any character animation system.
Approach	With n poses three matrices of size n must be inverted for each surface control vertex.
Outcome	Typically n will be between 1 and 10, say, so this cost is small.
Outcome	Also it is incurred at a convenient time – during setup (as a pose is saved) rather than during synthesis.
Approach	For synthesis, the basis function φ(x) can be implemented by interpolated table lookup and the sqrt required in the Euclidean distance can be composed with φ(x) in the table.
Challenge	An articulated model such as a human will typically have a number of different deformation subspaces, each with one or several deformations; the deformations in different subspaces may overlap spatially e.g. to simulate the influence of different muscles.
Approach	The deformations needed for an elbow, for example, will be interpolated in the one-dimensional subspace defined by the elbow joint angle.
Approach	Deformations in a shoulder area will need to consider two or more degrees of freedom.
Approach	The neck/chest/leg blend area of many quadrupeds is a more complex case – the motion of the skin surface in these regions may depend on the relative configuration of several leg bones as well as the rib cage and possibly the neck region of the spine.
Outcome	PSD handles all these cases simply and uniformly.
Outcome	The application of PSD to facial animation is best described by comparison with shape interpolation (SI).
Outcome	• In both approaches a set of key shapes (or delta shapes) are sculpted.
Outcome	The same set of shapes can be used in both approaches.
Outcome	• Whereas shape interpolation is (despite the name) a superposition of a set of shapes, PSD interpolates among these shapes.
Outcome	• The animator’s task in PSD is to choose the interpolation path (and adjust interpolation parameters such as falloff if desired).
Outcome	In practice this has been considered the major difficulty in applying SI when high quality animation demands large numbers of basis shapes [ 38 ].
Outcome	• In shape interpolation the key shapes and the animation parameter space are one and the same – the keys define the axes of the animation parameter space.
Outcome	In PSD the key shapes are positioned as desired in a space of desired dimensionality.
Outcome	One can assign each shape in PSD to a separate dimension, exactly as with SI.
Outcome	On the other hand, PSD allows one to sculpt intermediate expressions (half-smile) and situate them half-way along the relevant (full-smile) axis.
Outcome	Similarly a sculpted pose that represents the simultaneous activation of several parameters (e.g. happy but surprised, or smiling with a wink) can simply be saved at the appropriate location in the pose space.
Outcome	Psychological research has shown that human facial expressions are largely described by two “emotional” axes [ 30 ] ( Figure 6 ); this two-dimensional space would be a convenient high-level pose space for controlling facial animation.
Outcome	• The PSD interpolation is smooth if so desired.
Outcome	To illustrate these comments consider Figure 7 , which abstractly represents both SI and PSD with an identical set of expressions (neutral, half-smile, full-smile, frown).
Outcome	In the SI side of the diagram expressions are arranged as independent (but not orthogonal) dimensions as required by SI.
Outcome	In the PSD diagram the expressions are situated in an expression space having a happy-unhappy axis; a second axis (arousal) and an expression (delighted) on that axis are added to show a multidimensional space.
Outcome	As illustrated, a PSD path from neutral to half-smile to full-smile is monotonic, as might be expected; the motion of a surface point over this interpolation is also smooth.
Approach	Additional “dimensions” of deformation can be added at any time by adding a new parameter and associating additional poses with the movement of this parameter.
Approach	For example, a limb can be modeled in a particular pose both in an unloaded state and with muscles sculpted to express carrying a heavy load.
Approach	The ‘heavy’ pose can be associated with the ‘on’ state of an abstract parameter (e.g. an isolated bone moved into the vertical position); light and heavy loads can then be controlled by flipping this switch.
Approach	Similarly one can imagine setting up a dial that causes the character to morph; this would of course require a significant set of additional deformation poses.
Outcome	Pose space deformation is not the last word in surface deformation for character animation; high quality anatomically based models are certainly preferable.
Outcome	Nevertheless both anatomically based and purely kinematic models have their place.
Background	In the current computer animation culture animators generally practice their craft by direct and exhaustive specification of the desired motion combined with quick evaluation using real-time playback.
Background	Deeper simulation approaches intrinsically take away some of this control, and animators often argue (rightly or not) that automated processes are inferior or will not produce a human feel.
Challenge	The performance of current anatomically based models prohibits animation preview and other real-time applications such as telepresence and gaming (one published result is several orders of magnitude slower than real time), and the effort needed to produce an anatomically accurate model is not always justified, nor even appropriate if the model is of a fanciful creature whose surface appearance may be inconsistent with any plausible internal anatomy in any case.
Outcome	PSD unifies and improves upon two techniques that have been common graphics practice for more than a decade.
Outcome	This relatively simple algorithm uniformly handles a variety of deformation situations ranging from a simple elbow to secondary animation.
Outcome	The setup cost of the algorithm is insignificant, and the synthesis cost is only slightly more than that of shape interpolation, so real-time synthesis is possible at effective resolutions on current hardware.
Outcome	We expect that this algorithm will be a useful complement to current techniques.

Challenge	We introduce an Eulerian liquid simulation framework based on the Voronoi diagram of a potentially unorganized collection of pressure samples.
Approach	Constructing the simulation mesh in this way allows us to place samples anywhere in the computational domain; we exploit this by choosing samples that accurately capture the geometry and topology of the liquid surface.
Outcome	When combined with highresolution explicit surface tracking this allows us to simulate nearly arbitrarily thin features, while eliminating noise and other artifacts that arise when there is a resolution mismatch between the simulation and the surface—and allowing a precise inclusion of surface tension based directly on and at the same resolution as the surface mesh.
Challenge	One of the most visually compelling aspects of liquids is the variety of complex thin sheets and droplets that arise during splashing.
Challenge	However, these remain among the most difficult features to simulate plausibly and accurately with existing techniques.
Challenge	Such detailed behaviour is extremely computationally expensive to resolve because of the tremendous grid resolution required for both the fluid solver and the surface tracking mechanism.
Background	Recent advances in explicit surface tracking with triangle meshes [Wojtan et al. 2009; Brochu and Bridson 2009; Müller 2009] have made feasible the geometric representation and manipulation of small features, without the loss of detail exhibited by implicit surface methods.
Challenge	However, when the surface is coupled to a standard Eulerian simulator, the liquid volume must first be resampled onto the simulation mesh or grid to provide geometric information for boundary conditions.
Challenge	As this resampling process typically destroys small details, they are invisible to the fluid solver and cannot be advanced appropriately.
Challenge	This can lead to a variety of visible artifacts including lingering surface noise, liquid behaving as if it were connected when it is not (and vice versa), and thin features simply halting in mid-air because the simulator fails to see them [Bargteil et al. 2006; Kim et al. 2009].
Challenge	When combined with surface tension forces, noisy sub-mesh details can also severely hamper stability if they are not artificially smoothed out.
Challenge	We will address these problems by constructing a simulator that “sees” every detail in the explicit liquid surface.
Approach	We carefully generate pressure sample points near the liquid surface, build a Voronoi simulation mesh from these points and a background lattice, and apply a ghost fluid/finite volume pressure discretization which captures the precise position of the liquid interface.
Approach	We couple this with a semi-Lagrangian advection scheme and a new approach to surface tension, arriving at a complete liquid simulator.
Outcome	In summary, our key contribution is coupling an explicit surface tracker to a Voronoi-based liquid simulator with: • a pressure sample placement strategy that captures the complete liquid surface geometry, • an accurate surface tension model combining mesh-based curvature estimates and ghost fluid boundary conditions, • embedded free surface and solid boundary conditions adapted to Voronoi cells, avoiding the need for more onerous conforming tetrahedral mesh generation, • and a new velocity interpolant over unstructured meshes.
Outcome	The practical benefits of such a system include: • improved animation of detailed liquid features, including very thin sheets, tendrils and droplets, • elimination of noise in explicit surface tracking without nonphysical smoothing, • more detailed and less damped surface tension effects, • and faster semi-Lagrangian advection on unstructured meshes without increased dissipation.
Background	Unstructured and semi-structured meshes have a long history in computational fluid dynamics, and have gained traction in computer animation as well.
Background	An important reason for their popularity is that careful control of mesh geometry can simplify the discretization or improve accuracy.
Background	For example, conforming the simulation mesh to solid walls makes the no-flow boundary condition trivial, and adaptivity can be easily introduced by grading mesh elements as desired.
Background	Past work in graphics has extensively explored finite volume methods for tetrahedral meshes [Feldman et al. 2005a; Feldman et al. 2005b; Klingner et al. 2006; Chentanez et al. 2006; Elcott et al. 2007; Wendt et al. 2007; Chentanez et al. 2007], and now many of the features of standard grid-based solvers are supported on tetrahedra, including free surfaces and implicit coupling to dynamic solids.
Background	Batty et al. [2010] augmented this approach with embedded boundaries [Enright et al. 2003; Batty et al. 2007], improving free surface accuracy and reducing remeshing complexity.
Approach	Our method extends these advantages to Voronoi meshes.
Background	In a related approach, Sin et al. [2009] developed a particle method which solves a finite volume pressure projection on the Voronoi diagram of the liquid particles.
Background	An advantage of this approach is that the pressure degrees of freedom are directly tied to the number of particles, so there can never be a resolution mismatch between surface geometry and simulator.
Approach	This idea motivates our work.
Background	Franklin & Lee [2010] subdivide polyhedra into tetrahedra for interpolation similar to our method, but our method is simpler due to use of the Voronoi diagram.
Background	Implicit surfaces have long been used to capture liquid geometry in animation; this family of schemes includes level set (LS) methods [Enright et al. 2002a], volume-of-fluid (VOF) [Mihalef et al. 2006; Mullen et al. 2007], and semi-Lagrangian contouring (SLC) [Bargteil et al. 2006].
Background	Implicit approaches naturally yield smooth surfaces and seamlessly handle topological change.
Background	However, the resolution of the underlying grid imposes a severe limit on the smallest representable feature, beyond which geometry either vanishes (LS, SLC) or artificially coalesces into grid-scale “flotsam and jetsam” (VOF).
Background	Ensuring temporal coherence and avoiding visual artifacts due to the use of regular grids can also be problematic.
Background	The shortcomings of implicit schemes have spurred interest in explicit methods, i.e. “front tracking” [Glimm et al. 1998].
Background	Here the surface is represented explicitly as a triangle mesh, whose vertices are moved with the fluid velocity field.
Background	The greatest challenge is handling topological change, due to mesh tangling that may occur during merging and splitting.
Background	One solution is to determine problematic regions, switch to an implicit surface to repair the tangles there, then stitch back in a new consistent mesh patch [Du et al. 2006; Wojtan et al. 2009].
Background	Müller [2009] takes a similar grid-based approach to untangling, rebuilding a consistent mesh using marching-cubeslike stencils.
Background	Unfortunately these methods still are subject, in complex regions, to a resolution limited by the voxel grid.
Background	Another approach is to work strictly on the triangle mesh itself, using “mesh surgery” for repairs.
Background	While this is difficult in general, Brochu & Bridson [2009] recently showed that the problem can be simplified using ideas from cloth animation, enforcing the invariant that the surface remain intersection-free.
Background	Topological operations are only allowed when safe, while robust collision processing is used as a last resort to avoid tangles, i.e. the surface is minimally perturbed to avoid problems.
Approach	We use this method in the presented examples, though note that other front tracking methods could easily be used instead—for example, recent work by Campen & Kobbelt [2010] suggests that the need for collision processing could be obviated with exact Boolean operations.
Approach	A prime focus of our work is matching the surface mesh resolution to that of the liquid solver.
Background	Most level set-based solvers use one level set sample per pressure grid cell, conservatively avoiding resolution inconsistencies (e.g. [Foster and Fedkiw 2001; Enright et al. 2002b]).
Background	Goktekin et al. [2004] experimented with a doubleresolution level set, trading better volume conservation for other artifacts.
Background	Bargteil et al. [2006] similarly coupled an octree contouring method to a uniform grid fluid solver and explicitly discussed potential artifacts due to resolution mismatch, such as erroneously preserving surface noise and the solver interpreting disconnected fluid regions as connected.
Background	Kim et al. [2009] coupled a high resolution particle level set to a low resolution ghost fluid-based liquid solver, but ensured that pressure projection captured all liquid geometry by resampling an inflated level set at the pressure grid resolution—however, this can exacerbate other artifacts, since liquid components behave as if half a cell-width larger than they appear.
Background	Kim et al. also introduced extra surface smoothing to prevent retention of small-scale noise.
Background	Mismatched resolutions have been found useful for deformable solids, particularly as surface details are expected to generally persist, unlike in liquids.
Background	For example, Wojtan & Turk [2008] used a surface mesh coupled to a lower resolution finite element solver; forcing the simulation mesh to have the same topology, if not resolution, as the embedded surface mesh may improve realism [Teran et al. 2005; Nesme et al. 2009].
Background	Approaches to surface tension generally fall into two categories: those which apply surface tension as a body force in a region around the interface via smeared delta functions [Brackbill et al. 1992; Hong and Kim 2003; Zheng et al. 2006; Wojtan et al. 2009], and those which apply surface tension discontinuously at the interface, typically as a boundary condition in the pressure projection step.
Background	The latter is exemplified by the ghost fluid method and related approaches [Enright et al. 2003; Hong and Kim 2005; Hong et al. 2007], and has been shown to provide more realistic results.
Background	Surface tension models can also be compared in terms of how the force itself is approximated.
Background	In level set schemes, finite differences are often used to estimate mean curvature, though this can be quite inaccurate without careful modification (e.g. [Shin 2007]) and cannot capture small details.
Background	If a surface mesh is available, a more accurate approach is either to use mesh-based curvature operators (e.g. [Meyer et al. 2002b]), or as proposed recently, to model a physical tension directly in the surface mesh geometry [Perot and Nallapati 2003; Brochu 2006; Wojtan and Turk 2008].
Approach	We take the best of each, computing an accurate force from the surface mesh and incorporating it precisely at the surface with the ghost fluid method.
Approach	We also remedy a shortcoming of existing mesh-based approaches: that surface details below the simulation resolution add energy but cannot be correctly evolved by the solver; without correct feedback from the physics this noise tends to worsen and destroy stability.
Background	Wojtan & Turk [2008] handle this with Laplacian smoothing to eliminate small features: note, however, this non-physical operation is dissipative rather than conservative.
Approach	By instead combining our surface tension model with a geometry-aware sampling, we ensure all relevant details are properly resolved.
Outcome	This yields accurate and comparatively stable surface tension effects without artificial smoothing.
Approach	We simulate inviscid liquids with semi-Lagrangian advection and an embedded-boundary finite volume pressure projection.
Approach	We generally follow the tetrahedral scheme of Batty et al. [2010] with modifications to use specially designed Voronoi meshes instead.
Approach	Like Sin et al. [2009], we place pressure samples on the vertices of a Delaunay tetrahedral mesh, corresponding to the sites of the dual Voronoi diagram (figures 3(a) and 3(b)).
Approach	Normal components of velocity lie on the faces of the Voronoi cells, so that the velocity sample is parallel to the line segment connecting the pressure samples in the Delaunay mesh.
Approach	This configuration requires a slightly different velocity reconstruction compared to previous methods, but semi-Lagrangian advection is otherwise straightforward.
Approach	For front tracking, we used Brochu & Bridson’s El Topo code [2009], in particular using its triangle mesh surface to determine the location of pressure samples for our Voronoi simulation mesh.
Background	Purely explicit front tracking algorithms generally use mesh refinement and coarsening to maintain a high quality discretization as the surface deforms.
Background	El Topo uses a sequence of edge subdivision, collapse and flipping operations, combined with null-space Laplacian smoothing.
Approach	While these operations change mesh connectivity, they are designed to be geometry-preserving.
Approach	For example, the smoothing moves vertices only in the null space of the local quadric metric tensor [Garland and Heckbert 1997], as suggested by Jiao [2007].
Approach	If the vertex lies on a locally smooth patch it is moved in the plane tangent to the surface, but if on a ridge or corner it is moved only along this line.
Approach	Therefore, sharp features are preserved, allowing the present paper’s algorithm to handle them physically.
Approach	The solver runs through the following stages each time step: 1.
Approach	Advect the explicit surface with 2.
Approach	Generate a new simulation mesh as the Voronoi diagram of a lattice with extra samples near the liquid surface (section 5).
Approach	Advect velocities onto the new mesh with semi-Lagrangian advection (section 6).
Approach	Add external forces—typically just gravity.
Approach	Solve for the embedded-boundary pressure projection on the Voronoi mesh, including surface tension forces (section 4).
Approach	We use finite volumes on a Voronoi mesh for the pressure projection step, similar to Sin et al. [2009].
Approach	However, rather than applying boundary conditions as they describe, we adapt the embedded boundary methods of Batty et al. [2010] to Voronoi meshes.
Approach	Conveniently, the duality/orthogonality relationship between Voronoi and Delaunay meshes lets the accuracy benefits of the method carry over.
Approach	We solve the resulting symmetric positive definite linear system using incomplete Cholesky-preconditioned conjugate gradients.
Approach	To enforce embedded solid boundary conditions, we need to estimate the partial unobstructed area of each element face ( figure 3(d) ).
Background	Batty et al. [2010] used marching triangles cases for computing tetrahedra face fractions from signed distance values on the vertices.
Background	However, in the Voronoi setting, the faces are arbitrary convex planar polygons rather than triangles.
Approach	To handle this, we temporarily place an extra vertex at the face centroid, and use it to triangulate the face.
Approach	We then use signed distance estimates at the vertices to compute each sub-triangle’s partial area, and sum them to determine the partial area for the complete face.
Approach	The embedded (ghost fluid) free surface condition uses signed distance estimates at pressure samples to estimate the surface position; these are now located at Voronoi sites rather than tetrahedra circumcenters, but the method is otherwise unchanged ( figure 3(c) ).
Approach	A slight improvement can be achieved by casting rays to find the exact position of the surface mesh between pressure samples.
Approach	In some cases this is much more accurate than the estimate derived from signed distances, but in practice we found it made minimal visual difference.
Approach	To actually compute the liquid signed distance field on the tetrahedral mesh, we compute exact geometric distance for a narrow band of tetrahedra near the surface, then use a graph- based propagation of closest triangle indices to roughly fill in the rest of the mesh.
Approach	This family of redistancing schemes is described by Bridson [2008], and is easily adapted to tetrahedra.
Approach	To incorporate surface tension, we follow Enright et al. [2003] in setting the free surface pressure p fs = p air + γκ fs , where p air is the constant air pressure, γ is the surface tension coefficient and κ fs is the mean curvature of the surface.
Approach	Rather than using level set finite differences, we compute curvature directly from the surface mesh to accurately capture high-frequency features.
Approach	We chose the operator of Meyer et al. [2002b] because it provides high quality estimates using just the one-ring of triangles surrounding each vertex, but others could work too.
Approach	Curvature is evaluated at the intersection point between the the triangle mesh surface and the line joining an interior pressure sample to an exterior one.
Approach	Often this intersection point will coincide with a surface mesh vertex due to our choice of sampling scheme; where it does not, we use simple linear interpolation between the vertices of the surface triangle mesh.
Approach	This method appears highly accurate, and leads to much less damping than that of Wojtan et al. [2009].
Background	An advantage of a Voronoi-based discretization is the freedom to explicitly choose pressure sample locations, which is critical for accurate ghost fluid free surface conditions as the signed distance at these samples communicate the surface geometry to the solver.
Approach	We can visualize the solver’s “knowledge” by contouring this level set: figures 5 and 6 illustrate how uniform sampling may fail.
Approach	Careful pressure sample placement with respect to the surface helps in three important ways.
Approach	First, we can inform the solver of all local geometric extrema, allowing the physics to act upon them correctly.
Approach	This eliminates the accumulation of erroneous surface noise without requiring non-physical smoothing; this is especially vital for surface tension where spurious noise affects the curvature estimates and induces disastrously large yet futile compensating velocities that destabilize the simulation.
Approach	Second, we can ensure that the solver sees the correct surface topology so that the physics responds to merging or splitting only when the surface mesh itself merges or splits.
Approach	Lastly, grid-scale features often disappear and reappear in regular grid sampling, from the perspective of the solver, as the surface translates through the grid.
Approach	By specifically placing points inside such small features, we ensure they cannot be missed.
Background	However, this scales poorly since many of the extra samples yield little benefit, while incurring memory and computational overhead.
Background	Furthermore, there remains no guarantee that features below the smallest grid cell size will be captured.
Approach	By choosing sample points to precisely capture the geometry rather than naıvely increasing sample density, we can guarantee sampling of features which would require potentially orders of magnitude more samples with pure adaptive lattices.
Approach	This is considerably more difficult than non-conforming Delaunay tetrahedralization, and generally requires more Steiner points, worse-shaped tetrahedra, and/or the loss of the Delaunay property.
Approach	Since our method uses embedded boundary conditions, we do not require conforming elements.
Background	(Note that this advantage is shared by the method of Batty et al. [2010].
Approach	) Moreover, the position of pressure samples plays a more important role in free surface conditions than the position of element faces.
Approach	As accuracy requires that tetrahedral schemes store pressures at circumcenters [Klingner et al. 2006; Batty et al. 2010], and since circumcenters often lie outside their associated tetrahedra, even filling a thin feature with conforming tetrahedra provides no guarantee that its interior will be sampled at all.
Approach	We begin by choosing a characteristic length scale for the simulation, ∆x, and configure El Topo to try to maintain triangle edge 1 3 lengths in the range [ 2 ∆x, 2 ∆x].
Approach	To resolve all surface details with our volumetric mesh, we need to place pressure samples so that they capture the surface’s local geometric extrema, i.e. around surface mesh vertices.
Approach	In particular, we try to ensure that one edge of the Delaunay triangulation passes through each surface vertex, with one sample inside and one outside.
Approach	Therefore we take the inward and outward normal at each surface vertex (averaged from the incident surface triangles), and attempt to place a pressure sample 1 a short distance along each.
Approach	We placed outward samples at 2 ∆x 1 and inner samples at 4 ∆x, though other ratios would work as well.
Approach	As a result, surface mesh normal directions will often align exactly with a velocity sample in the simulation mesh; this lends additional accuracy to the vertex’s normal motion, and to the incorporation of the normal force due to surface tension calculated at the vertex.
Approach	This placement may miss very thin sheets or other fine structures: to robustly sample such features, we check line segments of length ∆x from each surface vertex in both offset directions for intersection with the rest of the surface mesh.
Approach	If we find any triangle closer than ∆x, we store the distance d to the closest intersection, and use d in place of ∆x in the offset distance calculations above (see figure 7 ).
Approach	We further reject new pressure samples which are too close to an existing sample by some epsilon, which would cause a very short edge in the final mesh.
Approach	If the distance between the surface vertex and the first intersection 1 is below some threshold (e.g. 20 ∆x) at which we consider the two surfaces to have effectively collided, and the proposed sample is an air sample, we also discard it.
Approach	This is necessary because the divergence constraint is not enforced on air cells, so they can act as liquid sinks [Losasso et al. 2006] and destroy liquid volume until the geometry finally merges.
Approach	Unfortunately, merging in this scenario can often take several time steps to resolve because the interpolated velocity in the air gap still averages to zero, thereby preventing surface geometry from actually intersecting and flagging a collision.
Approach	By not placing a sample point in these very small gaps, our simulator treats the two liquid bodies as merged and prevents volume loss; the geometric merge is usually then processed within a few timesteps.
Approach	(With regular sampling, merging will depend on where grid points happen to fall with respect to the surface; hence the physics can respond as if merged when the surfaces are still as much as ∆x apart, as in figure 9 .
Approach	This generates non-physical air bubbles which linger for many timesteps before they self-collide and are eliminated.
Approach	) After placing the surface-adapted pressure samples, we complete the sampling of the domain by adding regularly-spaced points from a BCC lattice with cell size 2∆x, again rejecting samples which fall too near existing samples—of course, a graded octree or any other strategy could also be used to fill the domain.
Approach	All samples are then run through a Delaunay mesh generator such as TetGen [Si 2006].
FutureWork	Further experimentation with relative mesh spacing parameters could yield improved results.
Background	Velocity interpolation methods for unstructured meshes typically proceed in two steps [Klingner et al. 2006; Elcott et al. 2007; Batty et al. 2010].
Background	First, a full velocity vector is reconstructed at selected mesh locations using a least-squares fit to the nearby velocity components.
Background	Then barycentric or generalized barycentric interpolation between those locations interpolates velocity over the full domain.
Background	Given such an interpolant, advection of velocities and geometry is straightforward.
Approach	We follow this general framework, with two modifications.
Background	In previous work, face normal components on tetrahedra were used to reconstruct velocities at circumcenters (Voronoi vertices).
Approach	In our configuration, velocity components instead lie along the tetrahedra edges (Voronoi faces) so we perform the least squares fit on this data instead.
Approach	We could then apply the usual generalized barycentric interpolant over Voronoi cells, but this is expensive [Chentanez et al. 2007] and requires special case handling to avoid degeneracies [Meyer et al. 2002a].
Approach	A simple and fast alternative discussed by Klingner et al. and Chentanez et al. is to first interpolate velocities to Voronoi sites (tetrahedra vertices) and apply standard (and fast) barycentric interpolation over each tetrahedron.
Approach	However, the interpolation onto tetrahedra vertices discards any local extrema at the Voronoi vertices, thereby severely over-smoothing the velocity field in practice, damping out interesting flow behavior.
Approach	Rather than discard extrema at Voronoi vertices, we use a slightly refined tetrahedral mesh that includes them.
Approach	We conceptually tetrahedralize the Voronoi cells themselves by placing additional vertices at Voronoi face centroids and Voronoi sites (see figure 10 ).
Approach	Velocities for each of these new points need to be computed; while previous work used the generalized barycentric interpolant for this transfer step, we found that simply averaging the velocities of the surrounding ring or cell of Voronoi vertices is quicker and equally effective.
Approach	For maximum fidelity at the face centroids, we also replace the normal component of the averaged full velocity with the exact normal component already stored at the face.
Approach	Simple and efficient barycentric interpolations can then be applied on the resulting smaller tetrahedra.
Approach	Because the sharper, more accurate velocities at the Voronoi vertices are retained and merely augmented with additional data, this is far less dissipative, yielding results that closely match generalized barycentric interpolation (see figure 11 ).
Approach	Lastly, note that reconstructions should only use face velocities which were assigned valid data by the pressure projection, and thus we can only reconstruct reasonable velocities inside the fluid.
Approach	We therefore extrapolate velocities outwards from the fluid using a breadth-first graph propagation: each unknown point in a layer is set by averaging all adjacent known points from previous layers, repeating until we have a sufficiently large band of velocities surrounding the surface.
Approach	This simple method, suggested in the context of cloth-fluid coupling by [Guendelman et al. 2005], sufficed for all our animations.
Approach	In summary, the steps of our interpolation scheme are: 1.
Approach	Reconstruct full velocity vectors at Voronoi vertices using least squares.
Approach	Assign full velocity vectors to Voronoi sites and faces using simple averaging from neighboring vertices.
Approach	Subdivide the Voronoi cells into sub-tetrahedra using the sites and face centroids (see figure 10 ).
Approach	Apply a simple graph-based extrapolation of velocities to fill in velocities near the liquid.
Approach	To interpolate at a point, locate the sub-tetrahedron containing the point and apply basic barycentric interpolation from its four associated data points (i.e. one site, one face centroid, and two Voronoi vertices).
Approach	One potential issue, not unique to our method, is that despite enforcing a lower bound on the distance between pressure samples, our unstructured sampling can cause sliver tetrahedra in the unmodified Delaunay tetrahedralization.
Approach	While we found this posed little problem for the pressure projection, it can cause the least squares velocity reconstructions to be ill-conditioned due to nearly co-planar face normals.
Approach	This can be readily resolved by requesting that the mesh generator add Steiner points to enforce fairly lax quality bounds; because our embedded pressure projection does not require the mesh generator to match boundaries, this is relatively inexpensive and effective.
Approach	If mesh quality cannot be improved sufficiently, using additional nearby velocity samples in the reconstruction can ameliorate this at the cost of a smoother result.
Background	The issues that arise from regular, non-geometry-aware pressure sampling are common and consistent across Cartesian grids, octrees, Voronoi meshes, and tetrahedral meshes.
Approach	We will therefore use Voronoi meshes throughout, and simply compare our geometryaware sampling against naıve regular sampling.
Outcome	In contrast, regular samples cannot fully capture the initial surface perturbation, so it cannot be rectified.
Outcome	Though the ghost fluid method on regular samples does detect some differences in surface height, this actually exacerbates the problem because noisy sub-mesh details will appear to the simulator as rapid discontinuous changes in surface position over time, inducing noisy responses in the fluid velocity.
Outcome	For example, a surface with two disjoint volumes of liquid may appear to the solver as one volume, resulting in a premature response.
Outcome	With regular sampling, the droplet begins to influence the static liquid before the surfaces are actually joined.
Outcome	Because our adaptively-placed samples match the topology of the surface tracker, they easily correct this spurious motion.
Outcome	Thin sheets rapidly develop as the fluid spreads out across the floor.
Outcome	With regular pressure samples, sheets of this kind often end up between samples, effectively disappearing from the solver.
Outcome	Our sampling ensures that almost arbitrarily thin sheets of liquid remain visible to the solver, and as such, interesting rippling and splashing motion still occurs.
Outcome	Our method also resolves thin sheets and small surface details generated by large splashes, as shown in figure 1 .
Approach	To counteract gradual volume drift, we do add a corrective motion-in-the-normaldirection [Brochu 2006; Müller 2009], which further aids in pre- serving thin sheets.
Outcome	Although we are using only first-order semi-Lagrangian advection, the liquid motion remains lively and active throughout.
Outcome	We suspect that because our method retains sharp wave peaks and splashes rather than continually eroding them, their extra kinetic and gravitational potential energy is retained in the simulation, accounting for this reduced dissipation.
Outcome	All figures are averages per frame and all timings are in seconds.
Outcome	These simulations used no more than 320K tetrahedra each, whereas recent tetrahedra-based free surface methods used up to 4 times more tetrahedra to achieve a similar level of detail.
Outcome	Rather than quickly collapsing into a sphere, a cascade of detailed capillary waves propagate along the surface, causing it to oscillate rapidly.
Outcome	It initially inverts almost completely into an octahedron (the geometric dual of a cube), and continues to oscillate for many subsequent frames.
Approach	To illustrate the benefits of our sampling approach in the context of surface tension, we launch an identical simulation using the same time steps on a regular mesh.
Outcome	Because this mesh cannot respond and correct high frequency sub-mesh details present in the curvature estimates, the simulation becomes unstable almost immediately.
Outcome	Applying an excessively strict timestep restriction only brings the simulation to a halt as the surface noise introduces increasingly sharp features.
Approach	Inspired by an example from the work of Wojtan & Turk [2008], we run another zero gravity simulation on a rectangular block (see figure 11 ).
Outcome	Because our simulation does not use diffusive Laplacian mesh smoothing and applies accurate mesh-based surface tension forces discontinuously at the interface, we retain substantially greater detail in the resulting capillary wave motion.
Approach	We revisit our surface tension block example to compare different interpolation schemes.
Outcome	As seen in figure 11 , our barycentric method is substantially less damped than the naıve barycentric interpolation approach, and matches the more complex generalized barycentric interpolant.
FutureWork	Our implementation is not heavily optimized, and we defer various potential performance gains to future work.
FutureWork	Obvious optimizations include: reducing the number of tetrahedra through smarter sampling, improving the broad phase algorithm for point-location queries, and streamlining the construction of mesh data structures.
Outcome	More fundamentally, our Voronoi simulator is in many ways dual to a tetrahedral scheme, and for a given mesh the number of velocity samples is identical; we believe that approximately comparable costs are therefore reasonable to expect.
Outcome	The main contribution of this paper is the coupling of simulation elements to an existing explicit surface tracking method, and not the explicit surface tracking itself.
Outcome	Therefore, not all artifacts due to surface tracking are addressed.
Outcome	For example, El Topo delays handling some very difficult collisions for a few timesteps until the topological operations can be safely processed, which occasionally yields visible lingering surface noise.
Outcome	(Reducing the time step size can help by introducing fewer and simpler collisions, and more aggressive simplification can also be enabled by tuning the volume change tolerance that El Topo uses to decide whether to accept a given simplification.
Outcome	) Likewise, despite the use of featurepreserving mesh improvement, some popping artifacts due to onthe-fly remeshing are still visible in our animations.
Approach	We chose El Topo because its resolution is not constrained to a regular grid and it is therefore able to showcase very thin features; nevertheless our method could adapt to any of the front tracking methods mentioned in section 2.2.
Approach	Surface tension was only used for examples in subsections 7.2 and 7.3.
Approach	Our goal in many of the other examples was to highlight the ability to track thin sheets, whereas surface tension would break these sheets into droplets.
Outcome	Moreover, explicit surface tension schemes, such as the ghost-fluid-based method used in this paper, 3 suffer from a stringent O(∆x 2 ) time step restriction for stability, which is particularly costly when small scale capillary waves are not erroneously damped out.
FutureWork	Pursuing a more efficient, fully implicit surface tension model is a promising future direction.
Outcome	We have shown that with careful placement of pressure samples, our Voronoi mesh-based fluid solver makes it possible for explicit surface tracking to achieve its full potential in capturing small scale liquid features.
Outcome	In addition, we adapted embedded boundary pressure projection techniques to Voronoi meshes, introduced a simple improvement to barycentric velocity interpolation for Voronoi/Delaunay meshes, and extended the ghost fluid surface tension model with mesh-based curvature in order to capture complex capillary waves with minimal damping.
FutureWork	Several directions for future work remain.
FutureWork	For example, it may be possible to enhance our sampling scheme in various ways, perhaps by exploiting curvature adaptivity, topological information, or measures of vorticity and velocity variation.
FutureWork	Likewise, improvements to front tracking would be welcome, such as curvature-driven adaptivity, or greater robustness and efficiency.
FutureWork	Lastly, many common extensions to basic inviscid liquid simulation rely on regular grids, and would need to be adapted to accomodate our approach.

Outcome	This paper describes a method to simulate realistic wrinkles on clothes without fine mesh and large computational overheads.
Background	Cloth has very little in-plane deformations, as most of the deformations come from buckling.
Background	This can be looked at as area conservation property of cloth.
Approach	The area conservation formulation of the method modulates the user defined wrinkle pattern, based on deformation of individual triangle.
Outcome	The methodology facilitates use of small in-plane deformation stiffnesses and a coarse mesh for the numerical simulation, this makes cloth simulation fast and robust.
Outcome	Moreover, the ability to design wrinkles (even on generalized deformable models) makes this method versatile for synthetic image generation.
Outcome	The method inspired from cloth wrinkling problem, being geometric in nature, can be extended to other wrinkling phenomena.
Background	Wrinkles add life to garments in fashion.
Challenge	In order to capture realistic wrinkles on a real-life garment, from a mere geometric point of view, the number of triangles required can be easily upto a hundred thousand.
Challenge	Such a large number of triangles put cloth simulation off from interactive speeds, even with adaptive time steps, introduced recently [ 1 ].
Challenge	Apart from simulation time, the large triangle count increases the rendering time and the cost significantly.
Challenge	In order to avoid these, one can increase fineness of triangles only in the potential regions where wrinkling might occur.
Challenge	This is very well possible due to advances in the triangulation and interactive systems developed [ 2 , 7 , 8 , 13 ].
Challenge	Even then, a significant problem remains: how to estimate the regions and the orientations of wrinkles.
Background	Cloth has very large in-plane deformation stiffnesses compared to its ability to bend and shear.
Challenge	This gives rise to very stiff equations of motion.
Background	The problem of solving stiff equations is successfully dealt with by the use of an implicit method for numerical integration by Baraff et al[ 1 ].
Challenge	Here, though the problem of stiff equations has been tackled, it has been the strong motivation for the authors behind developing the methodology specifically for wrinkles.
Challenge	Even if one wishes to have a fine triangular mesh, using robust and fast numerical solvers and having patience for long computations, it is not guaranteed that the wrinkles will be satisfactory.
Background	Accurate and fast collision detection methods[ 12 ], constraint methods[ 5 , 6 ] and good deformable models[ 6 , 9 , 10 ] have proved to give quality cloth animation.
Challenge	However, real-life wrinkling is a complex phenomenon.
Challenge	It is characterized by frictional forces (especially between body and cloth) which are difficult to model.
Background	Collision response methods and friction models developed so far have been rather simple for such a complex problem and robust numerics too.
Approach	We take a geometric and texture based approach to wrinkling.
Approach	As it is difficult to physically simulate real life wrinkles, the user designs them interactively as a bump map on a coarse mesh cloth/garment.
Approach	It is then animated by modulating it as per cloth deformation.
Approach	The key theme is conservation of cloth area.
Background	The work is continuation of earlier work [ 11 ].
Background	Other attempts to model wrinkles include those by Gotoda et al [ 3 , 4 ] and Wu et al [ 14 ].
Challenge	We would like to animate the cloth using coarse triangular mesh (typically a few thousand triangles per garment), for the reasons mentioned in the Introduction.
Background	Real cloth has very little in-plane deformation as most of the deformations come from buckling.
Challenge	For the coarse mesh, setting high metric (in-plane deformation) stiffnesses will not work properly.
Background	Real cloth would wrinkle to this deformation (see typical wrinkles in Figure 3A ).
Background	Consider an edge of a triangle, as shown in Figure 3B .
Background	In reality, the compression forces will buckle the edge as shown by dotted line.
Background	As the bending stiffness of the cloth is small, the buckled edge exerts small forces on the vertices.
Challenge	However, in the coarse mesh situation, the buckled edge is approximated by a straight line between the vertices.
Challenge	Consequently, the real life buckling is attributed to the compression of the edge.
Approach	If we assume a high metric stiffness associated to this compression, the corresponding forces on the vertices will be high.
Challenge	This is in contrast with real cloth situation.
Approach	Thus, to animate the cloth realistically with a coarse mesh, we need to set small metric stiffnesses.
Approach	This allows otherwise possible wrinkling/buckling which is embedded in the deformation of triangle.
Approach	Very little in-plane deformations can be looked at as area conservation property of cloth.
Challenge	We propose to capture gross cloth movements and deformations using a coarse mesh and the fine deformations (wrinkles) using a bump map (or a displacement map).
Approach	Let us assume the wrinkle pattern is given by the user.
Approach	We will try to modulate the amplitude of the wrinkle pattern such that, though there is a change in the area of a triangle (with the displacement map), it is invariant after applying the modulated displacement map.
Approach	The method is inspired by the area conservation property, even though Section 3.3 points out that the empiricism introduced later does not actually conserve the area.
Approach	First, let us state what serves as an input to the algorithm.
Approach	We start with a user defined wrinkle pattern, which is given in the form of a texture and an initial undeformed triangular mesh in 3D space.
Approach	This mesh may represent a garment or another deformable model.
Approach	The wrinkle pattern is bump or displacement mapped onto the initial mesh by the user.
Approach	Thus, we obtain a static wrinkled garment.
Approach	Note that the texture mapping coordinates do not change throughout the computations described below.
Approach	By introducing a fixed scale for the displacement or bump map on a mesh triangle, we obtain a function which, we call the wrinkle function.
Approach	Using these inputs in step 1 (refer to Figure 5 ), the algorithm computes a set of four parameters termed wrinkling coefficients for each triangle of the mesh.
Approach	The initial mesh serves as an input to a simulation engine, which in the context of cloth simulation would be the physical model with a numerical solver.
Approach	The mesh that is the output by the simulation engine will be the deformed mesh.
Approach	This deformed mesh is then further processed by the proposed algorithm.
Approach	For each triangle, we compute the deformation transformation that relates the corresponding triangle of the initial and the deformed mesh.
Approach	Using this deformation transformation and the already computed wrinkling coefficients, we compute the modulation factors.
Approach	These modulation factors are used to compute a modulation map which modulates the wrinkle pattern.
Approach	The modulated wrinkle pattern, which reflects the response of the wrinkled surface to the deformation of the underlying coarse triangular mesh, is used for the rendering.
Approach	In the course of animation, as the simulation engine recalculates the deformed mesh, the procedure described above is iterated.
Approach	However, note that the wrinkling coefficients need not to be recalculated during the animation.
Approach	They are constant with respect to the animation process.
Approach	They depend only on the initial wrinkle pattern, the initial mesh and the mapping coordinates.
Approach	The deformation of the triangle can be described by a general 4D homogeneous coordinate transformation.
Approach	However, the rotational and translational parts of the transformation are irrelevant to the derivation of the algorithm.
Approach	We introduce a local rectangular right handed two dimensional coordinate system, which is defined by choosing any edge of the triangle as the x axis ( refer to Figure 5 ).
Approach	Hence, x, y denote the local coordinates of the initial triangle and x , y that of the deformed triangle .
Approach	The matrix elements a and d represent scaling in the x and y direction respectively, whereas b describes a shear.
Approach	We define the wrinkle function f (x, y) as the function in the coordinate system xy that results from mapping the wrinkle pattern onto the initial triangular mesh.
Approach	Further we require f (x, y) to be continuous and that its first partial derivatives exist and also be continuous.
Approach	Note that this is a purely geometric requirement.
Approach	One might think of several different approaches to meet this requirement.
Approach	Our approach realizes overall area conservation by achieving area conservation on a per triangle basis of the mesh.
Approach	We parameterize the area of the deformed triangle by h, that scales f (x , y ) on each triangle of the mesh.
Approach	This is an equation for h, which we call modulation factor.
Approach	The constants C 1 , C 2 , C 3 , C 4 are here after referred as wrinkling coefficients.
Approach	The wrinkling coefficients on the other hand, are computationally expensive.
Approach	However, as one can see from equation 11 in Appendix A, they depend only on quantities that are known prior to entering the animation loop and can therefore be calculated once at the beginning.
Approach	• As we have pointed out in the discussion so far, we have derived an algorithm that is based on the area conservation property.
Approach	Here we explain the role played by the area conservation property in our work.
Outcome	From a mathematical point of view, it is clear that we have presented a solution within the approximation of small deformations.
Approach	There are several possibilities to deal with this restriction.
Approach	One could decide to restrict the simulations to small deformations where the approximation is valid and/or take into account the higher order terms in the series expansion to extend the range of validity of the approximation.
Approach	Instead, we propose a pragmatic approach.
Approach	This frees us conceptually from the “burden of mathematical correctness”.
Approach	This is because, we are more concerned with the visual results of the animation, rather than precise area conservation.
Approach	Moreover, the deformations during cloth simulation are moderate in general.
Approach	Hence, higher order terms in the expansion may become significant but not predominant.
Approach	The modulation factor h is a function of the deformation of triangle and has value around one.
Approach	If the triangle is net compressed, h will be greater than one.
Approach	For the elongation, it will be less than one.
Approach	One can scale, translate and clip it to introduce a finer control required for the animation.
Approach	Note that this transformation of the modulation factor no longer satisfies the area conservation property.
Approach	• Another very important property of our algorithm is that it is local.
Approach	By local, we mean that wrinkling effects caused by deformations are confined to the deformed areas.
Approach	This is crucial to obtain realistic wrinkling.
Approach	For example, a garment wrinkles around the shoulder of an animated character as she lifts her arm, while it is stretched on the corresponding side.
Approach	Locality is introduced in our algorithm by working on a per triangle basis.
Approach	The size of the mesh triangles actually governs the extension of local wrinkling effects.
Approach	• Wrinkling coefficients are sensitive to the wrinkle function and therefore to the wrinkle patterns.
Approach	Wrinkling coefficients for two different patterns on the same triangle will generally differ.
Approach	Therefore, the same deformation applied to a triangle will yield two different modulation factors (one for each pattern).
Approach	Each pattern, for instance, features a “principal wrinkling direction”.
Approach	Assume that the wrinkling patterns are orthogonal to each other.
Approach	Then, a deformation in the orthogonal direction of one pattern will result in a smaller modulation factor as compared to a modulation factor for the other pattern.
Approach	In other words, the direction of the deformation “favors one pattern over the other”.
Approach	This property can be used for developing multi-fold wrinkling techniques.
Approach	The numerical computation of the formulation is trivial.
Approach	For the numerical integrals of the wrinkling coefficients, we use adaptive sampling in the triangular domain to give a fixed user defined error.
Approach	The following issues are worth mentioning about the implementation.
Approach	The wrinkle function and the wrinkle pattern, though referred to as the same entity, they differ in implementation.
Approach	The wrinkle pattern is gray scale texture image defining the bump map.
Approach	The user defines an overall normalization factor for the texture to map wrinkle pattern to wrinkle function.
Approach	The normalization factor is important as the formulation assumes real distances for the bump map (or more precisely the displacement map).
Approach	The factor should be some fraction of the overall dimensions of the average triangle of the mesh.
Approach	The wrinkle function is a continuous real valued function, which is a spline approximation of the normalized texture as described in next item.
Approach	The wrinkling coefficient computation involves partial derivatives of wrinkle function f (x, y) with respect to (x, y).
Approach	For the reasonable numerical accuracy and stability, the wrinkling pattern needs to be smooth.
Approach	We fit a spline function to the pattern to smooth out any discontinuities in the input.
Approach	In addition to this, the user is advised to blur the pattern.
Approach	As stated in the formulation (Appendix A), solution to equation 4 exists if the input pattern is not constant.
Approach	As the pattern is user defined, one needs to watch for the invalidity of the solution (constant C 4 in equation 5 turn out to be zero) and therefore eliminates it.
Approach	In this case, we define the modulation factor to be one.
Approach	The modulation factor varies significantly across triangles.
Approach	If we treat a constant modulation factor for a triangle (see Figure 6), wrinkles appear patchy and one can distinctly see the triangular granules.
Approach	To avoid this, the modulation factors are linearly interpolated across triangles to give smooth Modulation Map ( Figure 6 ).
Approach	The user is given additional control for the animation by transforming the modulation map by a scale factor, clip, and bias.
Approach	The final bump/displacement map is the product of the modulation map and the wrinkling pattern.
Challenge	Animating a single wrinkle pattern is not satisfactory (particularly for cloth).
Background	In real-life, the wrinkles are not mere modulations of a fixed wrinkle pattern.
Background	Rather, the pattern changes according to the deformation.
Approach	Hence, we would like to apply the technique using multiple wrinkle patterns.
Approach	As stated in Section 3.3, two different wrinkle patterns give different wrinkling coefficients for the same triangle geometry.
Approach	Hence, for the same deformation of the triangle, corresponding to each pattern, the modulation factors will be different.
Approach	It all depends on how the wrinkle pattern is oriented with respect to the deformation direction.
Approach	If a pattern is orthogonal to the deformation direction (as compared to the other), corresponding modulation factor will be small.
Approach	In other words, the direction of the deformation favors one pattern over the other.
Approach	To illustrate this, let us consider simple cloth animation as shown in the Figure 7 .
Approach	In Stage 1 cloth is undeformed.
Approach	It is then stretched to the bottom left corner (Stage 2).
Approach	Comes back to the neutral position (Stage 3) and finally in Stage 4, stretches to the bottom right corner.
Approach	We would like to apply multiple wrinkle patterns for this animation.
Approach	For simplicity of the discussion, we consider only two wrinkle patterns, though the methodology is developed for multiple patterns.
Approach	The wrinkle patterns chosen are orthogonal to each other as shown in Figure 8 .
Approach	As the marked triangle undergoes a series of deformations (Figure 7, Stages 1-4), it may compute different values for the modulation factor for each of the wrinkle patterns ( Figure 8 ).
Approach	These two modulation factors are then plotted against each other in Figure 9 .
Approach	For Stages 1 & 3 both the modulation factors are 1 as cloth is undeformed.
Approach	However, for Stages 2 & 4 the modulation factors differ significantly, depending upon the direction of the deformation.
Approach	The relatively small modulation factor (say M F 1 is smaller for Stage 2) indicates that the corresponding wrinkle pattern is well oriented towards the direction of the deformation.
Approach	We choose this pattern for wrinkling for the deformation.
Approach	This selective application of the wrinkle pattern (along with its modulation) will give a change of one pattern to the other as the deformation direction changes.
Approach	However, in the animation a sudden switch of the pattern is not temporally coherent and is visually quite disturbing.
Approach	To avoid this sudden switch of pattern, we introduce a user definable variance around the mean value of the wrinkling coefficients, which defines a transition zone.
Approach	There will be a smooth transition between wrinkling patterns in this zone.
Approach	We employ a wrinkling pattern weight function as shown in Figure 11 to achieve the smooth transition.
Approach	This is in fact a simple power function with an appropriate scaling and clipping.
Approach	If M F 1 is much smaller than M F 2 (stage 1 in Figure 7 ), M F 1 will be smaller than (1 − variance)(M F 1 + M F 2 )/2 and M F 2 will be bigger than (1 + variance)(M F 1 + M F 2 )/2.
Approach	This gives maximum weight (W 1 = 1,W 2 = 0) to pattern 1.
Approach	In the transition zone, when M F 1 and M F 2 are comparable, the two patterns will be blended smoothly.
Approach	The user definable power n is representative of the tightness of the transition and n = ∞ is a sudden switch of pattern.
Approach	Note that for lower left triangles in Stage 2 of the animation, both wrinkle patterns get blended.
Approach	On the other hand, for lower right triangle in Stage 2, the deformation direction favors one pattern clearly.
Approach	Until now, the Geometric Wrinkle formulation is developed keeping in mind a general deformable model.
Approach	The garment is animated using a coarse mesh and low metric stiffnesses for the reasons explained in section 2.
Approach	Though the user can design the wrinkles according to her wish, it is worthwhile to study the strain patterns in the garment.
Approach	This is because, inappropriately placed wrinkles in the region where there is no deformation will not animate satisfactorily.
Approach	In addition, the pattern should be orthogonal to the deformations in general, as explained in section 4.1.
Approach	Dark triangles are triangles with compression and depict the regions where wrinkles might appear.
Approach	Based on such strain patterns (corresponding to two distinct frames of the garment animation in Figure 12 ), two wrinkling patterns are designed as shown in the Figure 14 .
Approach	The patterns have distinct wrinkles and additional irregularities to smooth out the sharp appearance of wrinkles.
Approach	Each pattern represents a distinct direction of deformation.
Approach	Note that they are considerably orthogonal.
Outcome	It is interesting to see the smooth switch of the wrinkling patterns in the animation because of multi-fold wrinkling.
Outcome	The frames on the left side correspond to the animation without Geometric Wrinkles.
Outcome	Note that, there are very few wrinkles in the second figure as there is very little deformation of the mesh.
Outcome	The first figure shows the modulation of the wrinkles as per the deformation.
Outcome	As the calculations of the wrinkling coefficients are done on a per triangle basis, the computational time is linear with respect to number of triangles.
Outcome	Typically, it takes 5 minutes per thousand triangles on a MIPS R10000 200 MHz processor.
Outcome	Once the wrinkling coefficients are computed, the time spent on modulating wrinkle pattern is negligible compared to rendering time.
Outcome	In fact, for small meshes (upto a hundred polygons) the modulation of wrinkle pattern can be real time (20 fps).
Outcome	We have developed a fast and versatile method for animating realistic wrinkles, which is geometric in nature.
Outcome	Hence, it can be applied to general deformable models such as cloth.
FutureWork	We would like to extend the method by automatically creating wrinkle patterns from the strain pattern, which is currently a time consuming task.
Approach	Now let us perform a series expansion of equation 9 in the transformation parameters and the modulation factor.
Approach	For small deformations around the identity transformation and h = 1, a first order expansion represents a good approximation for the value of the surface area over a deformed triangle.
Approach	We call these expansion coefficients wrinkling coefficients.
Approach	C 1 , C 2 , C 3 , C 4 relate changes in the parameters a , b , d , h to changes of the area of the wrinkle function on the triangle.

Challenge	Cloth simulations are notoriously difficult to tune due to the many parameters that must be adjusted to achieve the look of a particular fabric.
Outcome	In this paper, we present an algorithm for estimating the parameters of a cloth simulation from video data of real fabric.
Approach	A perceptually motivated metric based on matching between folds is used to compare video of real cloth with simulation.
Approach	This metric compares two video sequences of cloth and returns a number that measures the differences in their folds.
Approach	Simulated annealing is used to minimize the frame by frame error between the metric for a given simulation and the real-world footage.
Approach	To estimate all the cloth parameters, we identify simple static and dynamic calibration experiments that use small swatches of the fabric.
Approach	To demonstrate the power of this approach, we use our algorithm to find the parameters for four different fabrics.
Outcome	We show the match between the video footage and simulated motion on the calibration experiments, on new video sequences for the swatches, and on a simulation of a full skirt.
Background	Several recent major movie releases have demonstrated that the motion of clothing adds greatly to the appearance of a virtual character.
Background	This effect is particularly compelling for scenes that include both real and synthetic actors such as those with Yoda and Anakin Skywalker in Episode II: Attack of the Clones.
Background	In such scenes, the virtual clothing must move and be rendered so that it blends in seamlessly with the motion and appearance of the real clothing in the scene.
Background	Realistic virtual clothing is possible now because of recent advances in cloth simulation techniques 4 , 9 , 5 , 37 , 6 .
Background	The motion of fabric is determined by resistance to bending, stretching, shearing, external forces, aerodynamic effects, friction, and collisions.
Challenge	Although with the right set of parameters good simulators produce very realistic looking motion, choosing parameters that will provide a particular appearance remains a time consuming task that requires the computation and viewing of many forward simulations.
Challenge	Some parameters can be chosen based on the animator’s intuition about the fabric—a knit fabric is more stretchy than a woven fabric such as linen, for example.
Challenge	But not all the parameters of a cloth simulator are intuitive or map directly to measurements that can made by a system such as the Kawabata system 22 .
Approach	In our paper, we address this problem by using optimization to automatically determine these parameters from a sequence of video frames of the fabrics under consideration.
Approach	The parameters are optimized on a set of static shots and motion clips of a small swatch of a particular fabric and then tested on a simulation of a full skirt made from that fabric.
Approach	We designed the swatch tests to span the space of behaviors that we expect to see in the final sequences of motion with the skirt so that all parameters can be tuned appropriately.
Approach	We use simulated annealing for the optimization step with an optimization function that assesses the extent to which the folds in the simulated and physical fabric match.
Approach	This match is evaluated by means of a shape metric that uses projected light to detect surface orientation in real and simulated fabrics.
Approach	The metric is tuned to be most sensitive along folds and to discount planar regions.
Outcome	We use the system to find the parameters for four different fabrics.
Outcome	We show the match between the video footage and the simulated motion on the calibration experiments, on new video sequences for the swatches, and on a simulation of a full skirt as shown in the image on the previous page.
Background	Cloth modeling has a long history, dating back to work in the textile community from the mid-1930s by Peirce 27 .
Background	Work on cloth modeling in computer graphics has focused on developing dynamic simulation techniques that are both realistic and fast.
Background	Baraff and Witkin describe a cloth model that uses stiff springs with implicit time integration 4 .
Background	This model was subsequently adapted to reduce the over-damping due to implicit integration 9 .
Background	Explicit time integration approaches 18 use weaker springs for stretching and shearing, often explicitly limiting the amount of stretching 29 , 6 .
Background	Choi and Ko introduced a bending energy model that more accurately captures the fine creases and bends of cloth 9 .
Background	Lahey provides a comprehensive overview of cloth hysteresis models from the perspective of computational fabric mechanics 23 .
Background	Extensive work has also been done on modeling collisions and friction.
Background	Cloth self-collision is handled either by untangling the cloth 37 , 39 , 3 or by preemptively avoiding collisions 30 , 20 , 6 .
Background	Various potential field methods have been used for general collision detection and response 33 , 32 .
Background	Despite this large body of work on cloth simulation models, little work has appeared in the computer graphics literature on estimating the parameters of these models so that they match the behavior of real fabrics.
Background	Cloth parameter estimation has been studied in the textile community (for an overview, see Breen and colleagues 17 ), but such methods have not yet enjoyed wide-spread use in the computer graphics community.
Background	An important exception is the work by Breen 5 who used the Kawabata system 22 to measure bending, shearing, and tensile parameters by subjecting a swatch of fabric to a series of mechanical tests and measuring the force needed to deform it into a standard set of shapes.
Background	Although the Kawabata system can provide accurate measurements, these measurements are problematic for computer graphics cloth simulation problems for two reasons.
Background	First, there might not be a direct and simple mapping between the parameters for a particular cloth model and the Kawabata parameters.
Background	Second, the Kawabata system does not measure dynamic cloth parameters, e.g. air drag or damping, which are of key importance for moving cloth.
Background	One promising approach for modeling cloth parameters is to automatically search for parameters that match real, observed cloth.
Background	Jojic and Huang fit parameters of a particlebased cloth model to fit a range scan of real cloth in a static rest configuration, draped over a sphere 21 .
Background	More challenging still, they attacked the problem of measuring the 3D geometry of an object from the resting shape of a piece of cloth draped over it, a problem that we do not consider in this paper.
Background	However, Jojic and Huang did not treat the problem of measuring dynamic parameters or demonstrate accurate results across a range of fabric types.
Background	More distantly related are techniques for computing the geometry of cloth from images.
Background	Coarse estimates of the time-varying geometry of cloth can be computed using traditional stereo matching techniques by using two or more cameras and treating each time instant independently (see Scharstein and Szeliski 31 for an overview).
Background	More accurate results may be obtained by projecting structured light patterns on the cloth (see Zhang et al. 40 for an overview).
Background	Rather than computing shape at every time instant independent from the next, it can be advantageous to integrate images over time to improve accuracy.
Background	Two examples of promising work along these lines are Carceroni and Kutulakos 8 and Torresani et al. 34 ; both studies demonstrated reconstructions of moving cloth.
Approach	Because our framework for estimating cloth simulation parameters is independent of the cloth model, we can, in principle, select a specific model that meets a set of criteria such as accuracy or simulation speed.
Approach	Our choice of a cloth model was guided by two principles, realism and practicality.
Approach	We wanted to use a model that was sophisticated enough to capture the detailed dynamic behavior found in real fabrics but still straightforward to implement.
Approach	Because our intention was to apply the learned cloth model parameters to arbitrary garments with varying triangle resolution, it was also important that the cloth parameters correctly scale to varying resolutions of cloth.
Approach	We used the model described by Baraff and Witkin as the basis for our cloth simulator 4 .
Approach	This model has sufficient richness to produce a wide variety of cloth behaviors.
Approach	The underlying meshing is triangular, making clothing modelling easier.
Approach	More importantly, its input parameters are independent of meshing, so that parameters recovered on one mesh (the test swatch) can safely be transferred to another (the skirt).
Background	While nonlinear models such as the buckling behavior of Choi and Ko 9 could potentially capture more realistic details of cloth, there is no straightforward way to scale the parameters of these models to meshes of varying resolutions.
Outcome	We expect that future application of our parameterestimation framework to other scale-invariant cloth models will provide even more realistic results.
Background	The model developed by Baraff and Witkin formulates the energy of a particular triangle in terms of so-called condition functions C(x) such that the total potential energy associated with the system is given by E u = k s C(x)C T (x) ( 1 ) 2 where k s is a stiffness coefficient associated with the particular condition function.
Approach	We thus associate a stiffness coefficient k s and a damping coefficient k d with each of the C(x).
Background	In their paper, Baraff and Witkin describe a set of C(x) consisting of an in-plane stretch term, an in-plane shear term, and an out-of-plane bending term, giving a total of six parameters we can use to tune the internal cloth model.
Approach	We note, however, that (as they allude to in footnote 5) energy should scale linearly with triangle area to ensure scale independence.
Approach	In the course of running our experiments, we discovered that a linear drag model such as that used in previous cloth work 4 , 9 was not able to capture dynamic aspects of cloth.
Approach	In order to add additional air-drag degrees of freedom to our cloth model without resorting to fully modeling aerodynamics 25 , we developed a simple nonlinear alternative.
Approach	To calculate the drag force on a triangle, we decompose the average velocity on the face into two components, one normal to the surface (v N ) and one tangential (v T ).
Approach	Total drag force is then a linear function of tangential velocity and a quadratic function of normal velocity, with an additional term k f that controls the degree of nonlinearity,        f drag = −a 1 + k N k |v f |v N | N 2 | 2 |v v N N | + k T v T where a is the area of the given triangle.
Approach	The linear term        is merely Stokes’s law 1 ; the quadratic term matches better the experimental behavior of macroscopic bodies in low Reynold’s number flow 14 .
Approach	The addition of the |v N | 2 term in the denominator which makes the force asymptotic as v N → ∞ was partially motivated by the observed phenomenon of drag crisis 14 , where under certain circumstances the drag can actually drop at the onset of turbulence 1 .
Approach	The optimizer is free to eliminate this behavior or other terms of this equation by setting the corresponding parameters to zero.
Approach	Initially, we used a first-order implicit Euler time integration scheme similar to the one described by Baraff and Witkin 4 .
Outcome	Unfortunately, we found that implicit integration introduced damping which could not be eliminated by optimizing cloth parameters.
Outcome	We had more success in matching realistic cloth motions by using higher-order explicit methods.
Approach	The results in this paper all use an adaptive 4thorder accurate Runge-Kutta methods with embedded error estimation 2 .
Approach	While this method offers the advantages of familiarity and automatic bounding of error, it is rather slow, and recent work suggests that using 2nd-order backward differences 9 or Newmark schemes 7 may be a better choice.
Approach	For collision handling, we use a model similar to Bridson and colleagues 6 which combines repulsion forces with impulses to robustly prevent all collisions before they occur.
Outcome	However, separating repulsion forces from the cloth internal dynamics and applying them outside the Runge-Kutta solver affected stability and resulted in visible artifacts.
Approach	Instead, we apply repulsion forces inside the solver loop, so that the solver’s own internal error estimation can remove these artifacts.
Outcome	The drawback of this technique is speed, because the system must check for collisions every time it evaluates the state derivatives (as opposed to once every collision timestep as in Bridson et al. 6 ).
Approach	To achieve acceptable performance, we used a number of collision culling algorithms, including hybrid top-down/bottom-up update 24 , fast triangle reject tests 26 , and a curvature-based criterion for rejecting self-collisions that was first introduced by Volino and Thalmann 38 and later refined by Provot 30 .
Approach	We use a perceptually motivated metric to compare the motion of cloth in simulation with a video sequence of real fabric motion.
Approach	Our algorithm compares the two sequences frame by frame and computes an average error across the entire sequence.
Background	Real fabrics exhibit a wide variety of motion ranging from soft and flowing (satin) to stiff (linen).
Outcome	Our metric captures the complex dynamics of cloth motion and also helps to distinguish between different fabrics.
Background	Researchers in computational neurobiology hypothesize that the human perceptual system is sensitive to moving edges in video 11 , 12 , 36 .
Background	Studies have shown that the receptive fields of simple cells in the macaque cortex act as edge or line detectors, responding to oriented edges or lines in natural scenes 19 , 35 , 10 .
Background	In cloth, these edges correspond to folds, which are regions of high variation in shape.
Approach	Hence, our perceptually motivated metric for cloth compares two video sequences, one from simulation and one from the real world, and returns a number that measures the differences in their folds.
Approach	The metric also penalizes the silhouette mismatch between the two sequences.
Background	Haddon and Forsyth 15 , 16 describe a learning approach for detecting and grouping folds (and grooves) in images of fabrics.
Background	Their technique can handle lighting effects caused by diffuse inter-reflections in cloth.
Background	However, most fabrics have very complicated reflectance properties.
Approach	In our experiments, we normalize the effects of lighting and material reflectance by projecting a structured light pattern of horizontal stripes onto the fabric.
Approach	From the light-striped video sequence, we compute the dominant orientation for each edge pixel by convolving it with a steerable filter bank 13 .
Approach	In our implementation, we use the G2/H2 quadrature pair with kernel size 12 as the basis filters.
Approach	We convolve the image with the filter bank, compute the filter coefficient responses, blur the coefficients using a gaussian kernel, and compute the dominant orientation from these coefficients.
Approach	We define the resulting orientation image as an angle map, shown in Fig. 1 .
Approach	The angle map, which measures the local orientation of the projected pattern, has a constant value when the surface is planar and varies at folds.
Approach	We threshold the gradient of the angle map to get a gradient mask M k for each frame of video ( Fig. 1 ).
Approach	The gradient mask is non-zero at regions of high gradients, corresponding to folds, and zero at planar regions.
Approach	We preprocess the input video sequence to compute the angle map at each frame.
Approach	Similarly, in simulation, we render the cloth shape using the current parameter values and project the same striped pattern, to get a striped simulation sequence.
Approach	We compute the angle map at every frame in simulation from this sequence.
Approach	We then compute the SSD of the angle values for all overlapping points in the two angle maps.
Approach	We pre-multiply this difference with the gradient mask, which helps to emphasize the differences in fold regions over planar regions ( Fig. 2 ).
Approach	We sum the error across all frames to compute the overall error across the entire sequence.
Approach	The error at any particular frame k along the sequence is S x S y E k f old = ∑ ∑ M k (i, j) · (θ real k (i, j) − θ sim k (i, j)) 2 ( 5 ) i=0 j=0 where (S x , S y ) is the size of the angle maps and θ real , θ sim are the angle values from real and simulation angle maps respectively.
Approach	This penalty is proportional to the difference between the two silhouettes, i.e., the number of mismatched pixels.
Approach	S x S y E k silh = ∑ ∑ | A k real (i, j) − A k sim (i, j) | ( 6 ) i=0 j=0 where 1, inside silhouette A k (i, j) = 0, otherwise ( 7 ) The total error in frame k is E k = E k f old + αE k silh ( 8 ) where α is a user-defined weight that controls the relative contribution of the two terms.
Approach	We used a value of 0.1 for α in our experiments.
Approach	The error across the entire sequence of length N frames is given by N E = ∑ E k ( 9 ) k=1
Approach	We use optimization to estimate the parameters of the cloth simulator from video.
Approach	Before we describe the details of the optimizer, we look at the error space of the angle map metric, which gives us useful insight about the parameters of the system.
Approach	To generate this error map, we compared the angle map from one frame in video with several angle maps in simulation.
Approach	From the figure, it is evident that the error space is fairly noisy, with many local minima, motivating the need for a global optimization technique.
Approach	In addition to the parameter values, we estimate the relative importance of each parameter for a given experiment by performing a perturbation analysis at the solution point.
Approach	The importance or sensitivity of a parameter p depends on its local gradient ∂E ∂p ; it relates a small change in parameter value to a change in the error value.
Approach	Instead of computing the gradient, we robustly compute the variability of the param∂p eters, defined as ∂E .
Approach	To compute the variability, we perturb each parameter of the simulator individually up to ±0.20% of its value, compute the error and fit a quadratic to the data ( Fig. 4 ).
Approach	From the quadratic, the variability is computed as the change in parameter values that results in a 1% change in the error.
Approach	Parameters with low variability have high sensitivity and are estimated reliably for a given experiment.
Approach	We use simulated annealing to find the parameters that minimize the error function given in eq.
Approach	Simulated annealing initially explores the space in a semi-random fashion and eventually takes downhill steps.
Approach	The likelihood that it will take a step in a direction that is not locally optimal is a function of the temperature ( Fig. 5 ).
Approach	We chose to use the continuous simulated annealing method presented in Press et al. 28 , which combines the Metropolis algorithm with the downhill simplex method for continuous n-variable optimization.
Approach	We found it useful to reset the simplex with the current best solution when the temperature reduces by a factor of 3.
Approach	Prior to optimization, we perform an exhaustive search for each fabric, where we choose four values for each cloth parameter across its entire range.
Approach	This corresponds to a very coarse sampling of the parameter space.
Approach	We simulate the fabric for all points in this coarse set and compute the error for each point by comparing against the real fabric.
Approach	We initialize the optimizer with the point corresponding to the minimum error.
Approach	We have found that this strategy allows the optimizer to locate a good minimum of the space.
Approach	We designed a few simple experiments to capture the dynamics of the different types of fabrics and the air/cloth interaction.
Approach	The experiments are easy to perform, capture, and repeat; yet they demonstrate the complex dynamics of cloth motion.
Approach	The parameters obtained from the simple experiments were used to simulate skirts and other complex fabric motions.
Approach	In essence, our experiments were designed to be a calibration setup for estimating the static and dynamic parameters of a cloth simulator.
Approach	We perform two estimation experiments for each fabric, a static test and waving test.
Approach	We used four types of fabrics: linen, fleece, satin and knit.
Approach	These fabrics exhibit a wide range of static and dynamic behavior and span a large range of real fabrics.
Approach	We perform the static and waving tests on a small swatch of each fabric.
Approach	In the static test, the two top corners of the fabric are held stationary, and the fabric is allowed to sag under gravity.
Approach	For a fixed separation between the top corners, different fabrics attain different static shapes as shown in Fig. 6 .
Approach	The static test give a good estimate for the static stiffness and bend parameters.
Approach	In the waving test, one of the top corners of the fabric is fixed and the other corner is moved back and forth ( Fig. 7 ).
Approach	The waving motion of fabrics in simulation is affected by their dynamic parameters.
Outcome	We see from the accompanying videos that real fabrics exhibit a wide range of interesting motions.
Outcome	Different fabrics also exhibit different types of motion for the same input excitation.
Approach	We designed the waving motion to roughly match the types of motion occurring in real garments such as skirts.
Approach	This gives reasonable estimates for cloth parameters while avoiding the need to optimize directly on complex fabric geometries (e.g. skirts) involving many collisions.
Approach	We measured the mass and dimensions of the fabrics.
Approach	We also accurately measure the position of the two top corners using a Vicon motion capture system.
Approach	We compute the projection matrices for the camera and projector using a calibration grid comprising of several motion capture markers.
Approach	We performed two trials per experiment, each with slightly different initial conditions and optimized on the first 50 frames of video in each trial.
Outcome	Each trial took approximately 50 hours to converge on a 2.8GHz Intel Xeon processor (approximately 600 iterations of simulated annealing).
Approach	For this reason, we started the optimizations on the two trials (per fabric) with the same initial guess and chose parameters (optimized) that minimized the total error on the two trials.
Approach	We perform optimization on two trials for each fabric; the results are shown in Fig. 8 and Fig. 9 .
Approach	The two trials have different separation distances between the top corners.
Approach	For each fabric, we optimize for six parameters: stiffness and damping parameters for stretch, shear, and bend.
Approach	The air drag parameters were fixed for this experiment to the mid point of their range of values.
Approach	The initial values for the two trials are obtained from a coarse exhaustive search (four values per parameter).
Outcome	However, there is a significant disparity in the final optimized values from the two trials.
Approach	In order to understand this disparity, we performed a set of optimizations (on a single fabric) with very similar initial values.
Outcome	From the table, we see that the final error values are very close.
Outcome	We get consistent estimates for parameters that have lower variability (e.g., bend, stretch).
Outcome	Parameters with high variability are estimated poorly, because their values do not contribute sufficiently to the error.
Outcome	This result is consistent with our intuition that static tests cannot be used to estimate dynamic parameters like stretch and shear damping or air drag and motivates the waving test, which excites both the static and waving parameters.
Approach	We optimize for nine parameters in the waving test: the six cloth stiffness and damping parameters and three air drag parameters ( Fig. 10 ).
Approach	As with the static test, we initialize the static parameters in this test from a coarse exhaustive search.
Approach	The dynamic parameters were initialized using a random guess.
Approach	We optimized on the first 50 frames of the sequence.
Outcome	The final values of the parameters from the two trials differ in part because the variability of the parameters is still fairly high ( Fig. 11 ).
Outcome	Different motions or larger sequence might further reduce the variability of the parameters.
Approach	We choose the parameter set that minimizes the sum of the error from the two trials.
Outcome	For instance, in the following example of fleece waving, we choose the parameters from experiment 2.
FutureWork	However, we believe that a more general solution for parameter identification using our framework is to simultaneously optimize across multiple trials of different experiments.
Outcome	These two figures show the progress of the optimization and indicate that the minimum corresponds to a visually compelling match.
Approach	We compare each of the four optimized angle maps from simulation (corresponding to the four fabrics) with the four angle maps computed from video.
Outcome	We see that each fabric in simulation has a minimum error when compared to its counterpart in reality.
Approach	We evaluated the parameters obtained from optimization on longer sequences (150 frames).
Approach	We also validated the estimated parameters on a long sequence actuated by a robot ( Fig. 15 ).
Approach	We used a a Mitsubishi PA-10 robot arm to move the corner point along a simple sinusoidal trajectory, thereby ensuring that we had the same input motion across different fabrics.
Approach	Finally, we used the optimized parameters to simulate a skipping motion of a human actor wearing a skirt ( Fig. 16 ).
Approach	Here, the actor repeats the same skipping motion (approximately) for the four different skirts.
Approach	We used data from a full body optical motion capture of the actor performing the same skipping motion (in another trial) to drive the character for the cloth simulation.
Outcome	The results show that the parameters obtained from our optimization approach approximately capture the static shape and dynamic properties of skirts of different materials.
Outcome	This paper describes an optimization framework for identifying the simulation parameters of cloth from video.
Outcome	We captured the behavior of small swatches of fabric using a set of dynamic and static tests and demonstrated that the optimizer could identify appropriate simulation parameters from those tests.
Outcome	These parameters produced four distinct and recognizable fabrics when applied to a more complex simulation of a skirt as it was driven by motion capture data from a human figure.
Outcome	The cloth model was not the main focus of this research, yet in early versions of the system it was often the bottleneck in achieving appealing results.
Outcome	To match a video sequence accurately, the cloth physics model as well as the collision algorithms must be chosen carefully.
Outcome	Instabilities in the collision handling will cause perceptible quivering in the motion of cloth.
Outcome	Similarly, extra damping introduced by the integration method makes crisp folds impossible to match.
Approach	The parameters must also be independent of the resolution of the mesh so that they can be identified on low resolution swatches and applied to higher resolution garments.
Background	Progress is being made in these areas, however, and cloth models are continually improving.
Background	For example, Bridson et al. 7 introduces a scale-independent bend model with encouraging results.
Outcome	Our cloth model does not diverge significantly from previous models discussed in the literature.
Outcome	Our only major addition was a simple nonlinearity we introduced into the drag model.
Outcome	Hence, our approach should generalize to any parametrized cloth model that produces a sufficiently rich set of physically realistic motions.
Outcome	Although the skirt is far more complex than the swatches that were used to determine the parameters, it is not as complex as many garments, for example, a form-fitting pair of pants or a tailored blazer.
Outcome	For more complex garments, choosing the parameters via optimization on small, flat swatches may not be sufficient because the shape of the garment is determined by darts, pleats and by the interplay of different fabrics (wool, lining, and interfacing, for example).
Outcome	More complex garments may require the hand design of additional tests that mimic particular behaviors or elements of the garment in isolation.
Outcome	Moreover, the model might need extra parameters to handle anisotropic effects, hysteresis and coupling effects (stretching along one direction causing shrinking in the other direction), all of which would need specialized tests.
Approach	En route to the metric used in the experiments described here, we tried a number of other metrics: comparing the overlap of the silhouettes, the distance function between silhouette edges, and using information from internal edges marked on the fabric.
Outcome	The metric that measures folds and silhouettes, in concert with the projector for the light stripes, proved to be a simple and effective metric that far outperformed our earlier attempts.
Outcome	The space of possible metrics is vast, of course, but one class of metrics that we did not experiment with are statistical metrics that compute a function of the shape of the fabric across time rather than evaluating the match on a frame-by-frame basis.
Approach	The experiments with the swatches were carefully controlled to have initial conditions for the simulation that matched those seen in the video.
Approach	If instead, we were to optimize on more complicated garments, then such tight control of the initial conditions is unlikely and a statistical metric might be preferable.
Outcome	Such a metric might, for example, compute the average number of folds across a time sequence rather than looking for a fold to appear at a particular location on the swatch.
FutureWork	Our hope is that this work will promote a more rigorous evaluation of various cloth models, especially with respect to how accurately they match reality, and perhaps lead to creation of a standardized set of benchmarks for cloth simulation models.

Challenge	We present a technique for automatically synthesizing walking and running controllers for physically-simulated 3D humanoid characters.
Approach	The sagittal hip, knee, and ankle degrees-of-freedom are actuated using a set of eight Hill-type musculotendon models in each leg, with biologically-motivated control laws.
Approach	The parameters of these control laws are set by an optimization procedure that satisfies a number of locomotion task terms while minimizing a biological model of metabolic energy expenditure.
Outcome	We show that the use of biologically-based actuators and objectives measurably increases the realism of gaits generated by locomotion controllers that operate without the use of motion capture data, and that metabolic energy expenditure provides a simple and unifying measurement of effort that can be used for both walking and running control optimization.
Background	The development of physics-based locomotion controllers de novo, independent from stock motion data, has been a long-standing objective in computer graphics research and has seen resurgence in recent years.
Challenge	Despite impressive progress, the gaits produced by existing controllers fall short of the natural appearance of human locomotion.
Challenge	For example, physics-based walking controllers that do not rely on motion capture data commonly produce walking motion with exaggerated hip flexion which appears more crouched and less fluid than typical human walking.
Challenge	One likely cause of these differences is the control force generation mechanism.
Background	Biological control systems output neural excitation signals, which then generate musculotendon forces that lead to joint torques.
Challenge	The mapping from excitation to torque is highly complex due to variable moment arms, biarticular muscles, and the dependence of musculotendon forces on fiber length and contraction velocity [Zajac 1989].
Background	On the other hand, state-of-the-art bipedal locomotion control methods directly output joint torques, which ignore constraints and energetic costs imposed by muscle anatomy and physiology.
Challenge	Consequently, to accomplish a motion task, controllers often employ torque patterns that are inefficient or even impossible for humans.
Challenge	These biologically implausible torque patterns diminish the naturalness of the resulting gaits.
Challenge	The goal of our work is to enhance the realism of locomotion gaits exhibited by physically-simulated humanoids without dependence on motion capture data.
Approach	To this end, we augment the jointactuated humanoid model with a set of Hill-type musculotendon units (MTUs).
Approach	These musculotendon units generate torques for the most important degrees-of-freedom (DOFs) during locomotion— the sagittal plane hip, knee, and ankle DOFs.
Approach	To actuate these muscles, we define biologically-motivated control functions that map the current state of the body (joint angles, muscle fiber lengths, etc.) to excitation signals.
Approach	The parameters of these functions are optimized to yield gaits that move the character forward without falling down.
Challenge	While many sets of parameters are capable of achieving this task, the quality of the resulting motion varies significantly among them.
Approach	To produce gaits that have a high degree of realism, we employ an objective based on minimization of metabolic energy expenditure, thus choosing the most effortless gait that achieves the task [Alexander 2003].
Background	In living humans and animals, metabolic energy expenditure can be estimated by oxygen consumption.
Challenge	In contrast, it is less clear how metabolic energy expenditure should be modeled for simulated characters.
Background	A common substitute is the sum of squared joint torques [Schultz and Mombaur 2010], which does not account for the different effort levels required to generate torques in different joints, directions, and body configurations.
Background	More nuanced objectives can be learned from inverse optimization [Liu et al. 2005], but are dependent on training data.
Background	Our use of biologically-based actuators enables the estimation of metabolic energy expenditure based on the internal state of the MTUs [Anderson 1999].
Outcome	The result is a locomotion control optimization procedure that minimizes a physiologically-based objective within a parameter space restricted to biologically plausible torque patterns.
Approach	We demonstrate the presented approach by optimizing locomotion controllers for a wide range of speeds.
Approach	For quantitative evaluation, we collected experimental ground truth data from 20 human subjects walking and running at eight speeds on an instrumented treadmill.
Approach	Much like human locomotion, our controllers utilize significant ankle torque and generate smooth torque trajectories.
Outcome	The resulting gaits match human ground truth to a greater extent than state-of-the-art walking controllers that do not rely on motion capture data.
Outcome	Furthermore, we show that by simply changing the initialization and target velocity, the same optimization procedure leads to running controllers.
Background	Animation researchers have been interested in the control of locomotion for 3D humanoid characters for almost 20 years [Hodgins et al. 1995; Laszlo et al. 1996; Faloutsos et al. 2001].
Background	One important recent contribution is SIMBICON [Yin et al. 2007], a remarkably robust 3D humanoid locomotion controller based on the balance control of Raibert and Hodgins [1991].
Background	A num- ber of projects have since focused on expanding the controller repertoire for simulated bipeds [Jain et al. 2009; Coros et al. 2010; de Lasa et al. 2010] and on locomotion in complex environments [Mordatch et al. 2010; Wu and Popović 2010].
Background	At the same time, efforts have been made to make the synthesized motions more human-like, or “natural.
Background	” As discussed by Wang et al. [2009], the original SIMBICON-style controllers tend to produce gaits lacking hip extension with a constant foot orientation.
Background	Knee angles lack flexion during swing, but lack extension at heelstrike.
Background	More recent controllers improve motions by designing better target trajectories in joint or feature space [Coros et al. 2009; Coros et al. 2010; de Lasa et al. 2010].
Background	While more human-like ankle motions have been produced, differences in the hip and knee angles persist ( Figure 6a ).
Challenge	Perhaps more importantly, controllers relying on hand-tuned trajectories cannot be easily used to investigate how the control strategies change with respect to new constraints.
Challenge	For example, how would the character’s motion style change given a physical disability?
Challenge	Can we synthesize appropriate gaits for older or younger characters?
Background	Impressive results have also been achieved by controllers based on tracking motion capture data [da Silva et al. 2008; Muico et al. 2009; Kwon and Hodgins 2010; Lee et al. 2010; Ye and Liu 2010].
Challenge	However, as with methods that tune joint trajectories or controller parameters by hand, motion capture driven controllers have a limited ability to predict changes in gait.
Background	Alternatively, de novo controller optimization has been used to capture features of human walking [Wang et al. 2009; Wang et al. 2010].
Background	While these methods were shown to produce gaits for a variety of characters and environmental conditions, they do not employ realistic effort measures or biologicallyplausible control torques.
Background	The resulting torque patterns are highly unnatural ( Figure 6b ), leading to artifacts such as excessive plantarflexion and sharp changes in kinematics ( Figure 6a ).
Approach	In contrast, our approach is to actuate key DOFs using Hill-type MTUs and to measure effort based on metabolic energy expenditure.
Outcome	We demonstrate significantly more human-like kinematic and torque trajectories and show that the same control parameterization and effort objective produce both walking and running.
Background	While locomotion controllers discussed above all operate on joint-actuated models, musculoskeletal models have also been investigated in computer graphics.
Background	Such models have been used in facial animation [Waters 1987; Lee et al. 1995; Sifakis et al. 2005], simulation of the human hand [Sueda et al. 2008], neck [Lee and Terzopoulos 2006], torso [Zordan et al. 2006], and the complete upper body [Lee et al. 2009].
Background	Hase et al. [2003] optimize a CPG-based (central pattern generator) locomotion controller [Taga 1995] for 3D musculoskeletal models without tendon or activation dynamics, but their results were not compared to human kinematic and dynamic gait patterns.
Background	Moreover, full musculoskeletal models are significantly more difficult to construct than joint-actuated models.
Outcome	Our work demonstrates that measurable increase in locomotion realism can be produced by employing musculotendon actuators for a small subset of the body DOFs.
Background	In the biomechanics literature, abstract planar models have been used to study high-level principles of human locomotion.
Background	For example, energy minimization has been suggested as the criterion for humans in determining step length given walking speed [Kuo 2001], as well as in selecting between walking and running [Srinivasan and Ruina 2006].
Background	The spring-loaded inverted pendulum (SLIP) model [Blickhan 1989] has been used as a basis for predicting center-of-mass (COM) movements of human runners [Full and Koditschek 1999].
Background	However, in the absence of knee joints, these models cannot be used to simulate accurate gait pat- terns.
Background	Using a 2D model with knees and musculotendon actuators, Geyer and Herr [2010] showed that patterns of human walking can be generated by a set of simple control laws motivated by muscle reflexes, which inspired our work.
Outcome	We show how their basic ideas can be embedded in a 3D humanoid model and extended to running.
Background	Similar 2D models have been used for gait prediction [Ackermann and van den Bogert 2010], and to generate human-like responses to disturbances [Murai and Yamane 2011].
Background	Simulation studies on detailed 3D musculoskeletal models have been employed to understand muscle functions during locomotion tasks [Anderson and Pandy 2001; Liu et al. 2008; Hamner et al. 2010].
Background	In particular, Anderson and Pandy [2001] showed that human-like lower body motor patterns can be found by minimizing metabolic energy expenditure per distance travelled, and we adopt their proposed model of metabolic energy in our work.
Background	However, these biomechanical simulations only recovered muscle activation trajectories, and did not produce locomotion controllers that can function beyond the duration of input data.
Background	Finally, our work is complementary of the recent work of Jain and Liu [2011], who showed that simulating soft tissue deformation at contact sites could lead to more robust and realistic character motion.
Outcome	We demonstrate how musculotendon actuators, biologicallymotivated control laws, and a more realistic effort term can be used to produce more human-like locomotion gaits.
Approach	Our 3D humanoid model has 30 joint DOFs and mass distributions approximating a 180 cm, 70 kg male [Wang et al. 2010].
Approach	From the original model, we adjust the lower-body joint locations and mass distributions to better match human data [Hamner et al. 2010].
Approach	We use cylinders to approximate the heel and ball of the foot, which allows for some amount of foot rolling after heel-strike.
Approach	Unlike previous work, where the model is actuated by setting torques to all joints, we use a model that is partially actuated by Hill-type MTUs ( Figure 1 ).
Approach	Specifically, control torques for the hip, knee, and ankle joint DOFs in the sagittal plane—key DOFs for gait analysis [Perry and Burnfield 2010]—are exclusively generated by eight MTUs in each leg.
Approach	In addition, soft joint limit torques as defined by Geyer and Herr [2010] are applied to these DOFs.
Approach	The hip joint is extended by the gluteal muscles (GLU) and flexed by the hip flexor muscles (HFL), while the knee joint is extended by the vasti (VAS).
Approach	The tibialis anterior (TA) and the soleus (SOL) generate dorsiflexion and plantarflexion torques at the ankle, respectively.
Approach	The biarticular MTUs ( Figure 1c ) supply torques to two joints simultaneously.
Approach	We include the hamstring (HAM), which extends the hip and flexes the knee, the rectus femoris (RF), which flexes the hip and extends the knee, and the gastrocnemius (GAS), which flexes the knee and plantarflexes the ankle.
Approach	The choice of muscles is based on the planar model proposed by Geyer and Herr [2010].
Approach	We have added the rectus femoris since we found that it improves the walking knee flexion profile during swing when compared to human data.
Approach	We employ a Hill-type model [Zajac 1989], where each MTU consists of three elements: contractile, parallel-elastic, and serialelastic.
Approach	Conceptually, the contractile element (CE) models muscle fibers that can actively generate force (F CE ) depending on the current activation level (a).
Approach	The parallel-elastic element (PE) models passive forces (F PE ) generated by the muscle fibers, while the serial-elastic element (SE) models the tendon.
Approach	In particular, given the length and velocity of CE (l CE , v CE ), as well as the current muscle activation level (a), we can compute the MTU force (F MTU ) as follows: F MTU = F CE + F PE , F CE = aF 0 f l ( ̃ l CE )f v ( v CE ), where  ̃ l CE = l CE /l opt and v CE = v CE /l opt .
Approach	F 0 and l opt are musclespecific maximum isometric force and optimal fiber length parameters.
Approach	f l and f v are the force-length and force-velocity curves (Figure 3).
Approach	The computation of F PE and the analytic forms of f l and f v are described in the supplemental material.
Approach	Intuitively, f l models the fact that muscles can generate force more efficiently near l opt , and f v captures how the muscle loses its ability to generate force as the contraction velocity increases [Zajac 1989].
Approach	As to be discussed in Section 4.1, the nonlinearity introduced by these relations is crucial for how simple control laws for muscle excitation can lead to complex force and torque trajectories.
Approach	The controller outputs neural excitation signals (u), which are converted to muscle activations (a).
Approach	The conversion does not occur instantaneously and is referred to as activation dynamics.
Approach	The dynamics is modeled by a first-order differential equation [Zajac 1989; Geyer et al. 2003], which can be integrated by a t+1 = 100h(u t − a t ) + a t , where h is the stepsize (1/2400 s) and a t and u t are the muscle activation and excitation values at the t-th timestep.
Approach	A step-response graph for the activation dynamics, as well as details on the l CE and v CE computations (contraction dynamics) are given in the supplemental material.
Approach	The joint torques generated by a given MTU is a function of the current body configuration.
Approach	A simple variable moment arm model is assumed for MTUs attached to the knee or ankle: τ = r j cos(θ − φ j M )F MTU , where θ is the current knee or ankle angle in the sagittal plane, and r j is the maximum MTU-joint moment arm, which occurs at the joint angle φ j M .
Approach	MTUs attached to the hip are assumed to have a constant moment arm: τ = r j F MTU .
Approach	The total lower extremity joint torques in the sagittal plane are obtained by summing over contributions from all relevant muscles:
Approach	The main part of our control algorithm consists of functions that determine muscle excitation values for each of the lower body MTUs, which actuate the hip, knee, and ankle DOFs in the sagittal plane.
Approach	For the upper body and the remaining DOFs in the lower body, we rely on a pose-graph controller [Yin et al. 2007].
Approach	Our control laws for the actuators are based on the muscle-reflex controller introduced by Geyer and Herr [2010].
Approach	Two different sets of control laws apply for each muscle, depending on whether the leg is in stance or swing phase (i.e., foot is on the ground or not).
Approach	We further define a swing initiation state within the stance phase, and a stance preparation state within the swing phase, where control laws for a subset of MTUs are modified ( Figure 4 ).
Approach	The control laws map time-delayed features of the body to muscle excitation signals.
Approach	The time-delay (∆t) models the time for neural signal propagation, set to 5 ms for MTUs connected to the hip, 20 ms for MTUs connected to the ankle, 10 ms for the VAS and ground contact [Geyer and Herr 2010].
Approach	Body features include MTU force, fiber length, joint angle, and segment orientation.
Approach	Depending on the input feature, three different mappings are defined: positive force feedback, positive length feedback, and muscle-driven proportional derivative (PD) control.
Approach	These mappings serve as building blocks for the control laws, and we discuss each in turn in this section.
Approach	Given MTU m, the positive force feedback law is defined as u F m = G m F  ̃ m MTU (t − ∆t m ),          where F  ̃ m MTU (t − ∆t m ) is the MTU force normalized by F m 0 with a time-delay of ∆t m .
Approach	The only free parameter is a positive gain constant G m , which is different for each MTU.
Approach	Note that F  ̃ m MTU cannot increase indefinitely since the muscle’s force generation capacity depends nonlinearly on the length and contraction velocity of the muscle fiber.
Approach	As F  ̃ m MTU starts to decrease due to muscle physiology, u F m starts to decrease as well.
Approach	The force feedback is the main source of activation to the SOL, GAS, and VAS muscles during the stance phase.
Approach	We can see that u GAS F produces a positive feedback during mid-stance, when the muscle activation does not produce a significant change in muscle fiber length, as the foot is planted on the ground.
Approach	As the heel loses ground contact in late stance, the same muscle activation rapidly shortens the fiber length, which reduces force output and the activation through u F GAS .
Approach	Positive length feedback is defined as          u m L = G m  ̃ l m CE (t − ∆t m ) − H m , + where  ̃ l m CE (t − ∆t m ) is the length of the muscle fiber normalized by the l m opt with a time-delay of ∆t m .
Approach	G m and H m are free positive parameters and {} ± means only positive or negative values (0 otherwise).
Approach	The positive length feedback effectively models a stretch reflex, which activates the muscle when the fiber is stretched beyond a fixed length.
Approach	u L m is most useful during the swing phase, as the TA must be activated to dorsiflex so that toe-stubbing can be avoided.
Approach	In addition, the HFL relies on length feedback to generate hip flexion torque during early swing, especially during running.
Approach	We also define a muscle-driven PD control law with respect to an angular feature θ as where K m , D m , θ m are free parameters of the PD-controller.
Approach	The braces sign is positive if torque generated by m is in the opposing direction of θ—e.g., if m is the hip extensor and θ is the hip flexion angle—and negative otherwise.
Approach	Much like the standard torquebased PD-controller, the muscle-driven PD control aims to adjust θ towards the target angle θ m while damping its velocity.
Approach	However, unlike the standard PD-controller, muscles can only activate after a time-delay and each muscle can only generate forces to rotate the angular DOF in one direction.
Approach	The PD-control laws are employed by the hip muscles during the stance phase to maintain the global upper body orientation, as well as during stance preparation to prepare for ground contact.
Approach	Each muscle has an initial constant excitation, or pre-stimulation value p m .
Approach	These values are initialized close to zero, but are then optimized.
Approach	The SOL and GAS both rely on positive force feedback and are the main sources of torque during walking.
Approach	The TA ensures foot clearance during swing using a length feedback (u L TA ), but the activation is suppressed during stance in proportion to the current force generated from SOL.
Approach	The suppression allows the generated TA activation patterns to better match human data during locomotion.
Approach	The force feedback on the VAS creates a strong knee extension torque following ground contact, but excitation is suppressed when the knee flexion angle (θ k ) is extended below an offset (θ k off ) with an extension velocity ( θ  ̇ k < 0).
Approach	The suppression prevents hyperextension of the knee during mid-stance.
Approach	Using muscle-driven PD control laws, the HAM, GLU, and HFL are responsible for maintaining the global orientation of the upper body (Θ), defined as the vector between the COM of the upper body and the COM of the pelvis projected onto the sagittal plane.
Approach	During double stance, these control laws are only active for the leading leg, denoted as u Θ m lead .
Approach	Two main differences between our stance phase control laws compared to Geyer and Herr [2010] lie in how the swing initiation state functions.
Approach	First, for running we found it necessary to enter into swing initiation using the d  ̃ > d  ̃ SI condition, rather than just wait for double stance.
Approach	Second, we found it unnecessary to modulate the muscle-driven PD-control laws in the hip by ground reaction forces.
Approach	Instead, the responsibility to maintain upper body orientation is always assigned to the lead leg.
Approach	Much like in the stance phase, each muscle has an initial constant excitation value (q m ).
Approach	The leg motion relies significantly on passive dynamics during the swing phase [Collins et al. 2005], as most muscles are only excited at low levels.
Approach	The main exceptions are the TA, which maintains the length feedback (u L TA ) to avoid toestubbing, and the HAM, which is activated at late swing phase to prevent the knee from being overextended before landing.
Approach	The HFL introduces a hip flexion torque through a length feedback, which is suppressed when the HAM is stretched in during late swing.
Approach	The amount of excitation in the HFL also depends on the value of upper body lean at the beginning of the swing phase (Θ lto ): the further the upper body leans forward compared to the reference lean angle (Θ d ), the more excitation is supplied from the HFL during the swing phase.
Approach	Note that Θ d is the same as the target angle in u Θ HFL .
Approach	The GLU, HFL, and VAS work to guide the hip and knee joints toward a desired pose to prepare for ground contact: u VAS = q VAS + u VAS θ k , u GLU = q GLU + u θ GLU h , u HFL = q HFL + u θ HFL h .
Approach	A single desired hip target angle (θ h ) is adjusted according to the SIMBICON balance feedback law [Yin et al. 2007] and is shared by both the GLU and HFL.
Approach	We found the addition of the stance preparation state to be important for discovering running gaits.
Approach	The balance feedback law allows robust control strategies to be found in difficult environments (e.g., being pushed by random forces).
Approach	The rest of the DOFs are controlled using standard joint-space PDcontrollers with state-dependent parameters.
Approach	Following Wang et al. [2010], the target features for the ankle and hip joints in the coronal plane are the global foot and pelvis orientations, respectively.
Approach	The coronal swing hip target angles follow the same feedback law as θ h .
Approach	Additionally, we set the toe joint to be a spring with spring constant of 30 Nm/rad, target angle 0, and no damping.
Approach	Unlike in previous work, where a gait cycle is broken down into four states, only two are needed (triggered by left/right foot-strike) since DOFs with the most complex activities are actuated by muscles.
Approach	Our upper body control also largely follows Wang et al. [2010], with the exception that the target feature of our back joint in the coronal plane is the global orientation of the torso instead of the local joint angle between the torso and the pelvis.
Approach	This global target allows our model to better keep the head upright during locomotion.
Approach	We fix the spring and damper constants for all arm joints to 30 Nm/rad and 3 Nms/rad, respectively, with target angles set to 0.
Approach	We found that more human-like arm swing can be generated by relating the elbow and shoulder target angles as θ s l = α arm θ h l − θ h r + βθ e d and φ l s = γθ e d , where θ s l and φ l s are the shoulder angles in the sagittal and transverse planes, respectively; θ h l and θ h r are the current left and right sagittal hip angles; θ e d is the desired elbow angle, β, γ are constants chosen based on human motion data (see supplemental material), and α arm is a scale constant that determines the magnitude of the arm swing.
Approach	This formulation captures the tendency to rotate the shoulder backwards and inwards while bending the elbow.
Approach	The scale constant and the desired elbow angle are among the parameters set by optimization, as described in the next section.
Approach	The control algorithm specified in Section 4 has a large number of parameters, which we set by optimization [Wang et al. 2010].
Approach	More specifically, each of the u m F , u m L , and u m θ laws have one, two, and three parameters, respectively.
Approach	There are 56 parameters in total (30 stance, 26 swing) for the MTU control laws.
Approach	For the upper body and the non-sagittal DOFs in the lower body, we optimize the PDcontrol parameters (spring-damper constants, target angle, balance feedback) for all joints except for arms, where only a target elbow angle and a swing scale parameter are optimized (Section 4.4).
Approach	When combined with 33 free parameters describing the initial state of the simulation, 124 parameters (w) fully define a simulated motion {s 1 . . . s T } over T timesteps.
Approach	We optimize control parameters and the initial state using Covariance Matrix Adaptation (CMA) [Hansen 2006], with stepsize σ = 0.005 and 50 samples per iteration.
Approach	The optimization aims to maximize the following return function: T R (w) = r(s t ) − w e J effort .
Approach	The reward is defined as the negative sum of a number of task terms (i.e., r(s t ) = − i K i (s t )), which can be thought of as high-priority goals that the controller must satisfy while minimizing effort.
Approach	In practice, these terms are weighed more heavily than the effort term.
Approach	The tasks include moving the COM forward at a target velocity while not falling down for 10 seconds, and maintaining head stability and upper body orientation.
Approach	The task terms are based on Wang et al. [2010] and are defined in the supplemental material.
Approach	Note that unlike in previous work, we did not need to include human-like speed to step-length ratio and minimal angular momentum about the COM as task terms.
Outcome	The main contribution to our effort measurement is the total rate of metabolic energy expenditure ( E)  ̇ over all MTUs.
Approach	To quantify E,  ̇ we implement a model described by Anderson [1999], which is later expanded by Bhargava et al. [2004].
Approach	The rate of metabolic energy expenditure for a given muscle can be modeled as the sum of heat released and mechanical work done by the muscle: E  ̇ = A  ̇ + M  ̇ + S  ̇ + W,  ̇ where A  ̇ is the muscle activation heat rate, M  ̇ is the muscle maintenance heat rate, S  ̇ is the muscle shortening heat rate, and W  ̇ is the positive mechanical work rate.
Approach	The muscle activation heat rate models the rate of energy that is converted to heat by a muscle given a certain level of activation, and is a function of both the mass of the muscle and the excitation signal.
Approach	The maintenance heat rate similarly models the heat rate for the muscle to maintain contraction at a certain level, and depends additionally on the current fiber length.
Approach	Specifically, A  ̇ = mass · f A (u) and M  ̇ = mass · g(  ̃ l CE )f M (a), where mass is the muscle mass and  ̃ l CE is the normalized muscle fiber length.
Approach	The forms of f A , f M , and g are described in the supplemental material.
Approach	The dependence on muscle mass captures the fact that while larger muscles are generally capable of generating more force, they are also more costly to use.
Approach	The difference is that F MTU is the net force (both active and passive) produced in the MTU, while F CE is only the active force.
Approach	Let E  ̇ m,t denote the rate of metabolic energy expenditure computed for MTU m at timestep t.
Approach	We define the average rate of metabolic expenditure due to MTUs as where B  ̇ is the basal metabolic energy rate, set to 1.51 times body mass [Anderson 1999].
Approach	M is the set of all sixteen muscles defined in the model.
Approach	Additionally, torques generated by the PD-controllers in the rest of the DOFs are penalized by the average sum of torque squared objective: T 1 2 J R = τ j,t , T t=1 j∈Q r where Q r is the set of all joint DOFs except for the sagittal hips, knees, and ankles.
Approach	We similarly define J L to penalize the average sum of squared soft joint limit torques for the hip, knee, and ankle joints, specified in Geyer and Herr [2010].
Approach	The overall effort of a particular motion is defined as J effort = w M J M + w R J R + w L J L , a weighted sum between the terms.
Approach	We empirically set w M = 100, w R = 1, and w L = 0.5 for all experiments.
Approach	The simulations were implemented using Open Dynamics Engine (ODE) with a frequency of 2400 Hz.
Approach	We simulate for T = 24000 timesteps (10 s) in each evaluation.
Approach	The optimization is terminated after 3000 iterations, which takes approximately 10 hours using 50 compute cores on a cluster of Dell PowerEdge 1950 servers.
Approach	An optimized controller can be simulated at interactive rates using standard hardware.
Approach	We initialize walking parameters of the MTU control laws based on hand-tuned values for 2D walking from Geyer and Herr [2010].
Approach	For running, we double the initial gain parameters of GAS and SOL, and initialize θ e d to set the elbow in a bent position.
Approach	The precise initialization values are provided in the supplemental material.
Approach	Human joint moment (torque) curves during locomotion can be computed from motion capture and ground reaction force data.
Outcome	In this work we are particularly interested in comparing our results to the mean and standard deviation curves for the sagittal hip, knee, and ankle joints for multiple subjects over multiple walking and running speeds.
Background	While such data for walking is readily available [Perry and Burnfield 2010], only scattered data are available for running [Novacheck 1998; Yokozawa et al. 2007; Hamner et al. 2010].
Approach	Instead, we acquired our own ground truth data using an instrumented treadmill with 20 subjects.
Approach	This data is available from http://graphics.stanford.edu/projects/bio-locomotion .
Approach	We acquired kinematics and dynamics data for a range of walking and running speeds (from 1.0 m/s to 5.0 m/s).
Approach	The supplemental material includes angle and moment plots for all speeds, as well as details on our data collection.
Outcome	Comparing the mean curves for walking speeds from 1.0 m/s to 1.75 m/s, we found that the range of hip angles in our subjects during walking increased by approx◦ imately 10 , while the location of maximum ankle plantarflexion shifted slightly earlier in the gait cycle.
Outcome	More pronounced differences are present between running data at different speeds.
Outcome	The hip ◦ angle range and maximum knee flexion both increased by 30 as running speed increased from 2.0 m/s to 5.0 m/s, while locations of both the maximum hip extension and ankle plantarflexion shifted earlier by 5% and 10%, respectively.
Outcome	Both the hip and ankle torque outputs increased with speed, though the ankle torque curves did not differ significantly between 4.0 m/s and 5.0 m/s.
Approach	We first optimized for a normal walking controller (referred to below as nwalk) with a target velocity of 1.25 m/s, which is approx- imately the human self-selected walking speed.
Approach	Initializing with the normal controller, we then optimized for a 1.0 m/s slow walk controller (swalk) and a 1.5 m/s fast walk controller (fwalk).
Approach	A 1.75 m/s very fast walk controller (vfwalk) is optimized by initializing from fwalk.
Outcome	Supplemental figures indicate that our kinematic patterns generally agree with data over a range of speeds and especially at lower speeds.
Outcome	Two main discrepancies are the timing of knee flexion during stance, and ankle dorsiflexion before heel-strike.
Outcome	For higher speeds, the maximum knee flexion angle is lower than human data, and the location of maximum ankle plantarflexion occurs earlier in the gait cycle.
Outcome	All angle and moment curves shown are averaged over multiple cycles.
Outcome	Note that we found time-delays to be important for generating human-like motion given our control model.
Outcome	Optimizing without activation dynamics and with ∆t m = 0 for all MTUs results in a solution where ankle torques build up too quickly in the stance phase, leading to shorter step-lengths compared to human data.
Outcome	A major artifact from all of the previous works is the lack of hip extension during mid-gait, which does not occur in our result.
Background	The feature-based controller of Mordatch et al. [2010] is robust and flexible, but their basic walking gait shows an obvious crouch.
Outcome	Our result also exhibits a range of knee motion more similar to humans compared to previous works.
Outcome	However, all four controllers show excessive dorsiflexion before heel-strike.
Outcome	An important advantage of optimization over hand-tuning is the ability to create controllers based on high-level objectives such as walking speed.
Outcome	As demonstrated in supplemental material, our controllers generate more human-like gaits compared to optimized controllers from Wang et al. [2010] at faster walking speeds (Wang10f, Wang10vf ) as well.
Outcome	An obvious artifact of all controllers from Wang et al. [2010] is the excessive plantarflexion in the early swing phase, which is not present in our result.
Background	1 Examining differences in torque generation, we can see that the controller presented by Coros et al. [2009] does not employ a human-like torque distribution between the joints ( Figure 6b ).
Background	In particular, as was the case in SIMBICON [Yin et al. 2007], the gait is largely hip-driven, as can be seen by the large hip torques and small ankle torques compared to human data.
Background	In turn, controllers from Wang et al. [2010] generated larger amounts of ankle torque by optimizing for a human-like torque ratio, but did not come close to matching the shapes of human torque data.
Outcome	Note that our work does not exhibit unnatural torque spikes due to state switching that are present in the previous works.
Approach	We compute the mean standard score against human data over 100 evenly spaced points on the curves.
Outcome	Note that our results show the lowest average standard score for all speeds.
Approach	We evaluate the metabolic energy expenditure objective described in Section 5 against the simple sum of squared torques objective, by redefining where Q s is the set of sagittal hip, knee, and ankle DOFs (with w M = 5).
Approach	Controllers optimized for each of the two objectives (nwalk, min torque) are demonstrated in the accompanying video.
Approach	For this comparison, we use a target speed of 1.25 m/s, which is the same as nwalk.
Outcome	The gait resulting from torque minimization exhibits too much knee flexion during the swing phase and too much dorsiflexion before heel-strike.
Outcome	Since the foot is a relatively light link, the actual magnitude of the dorsiflexion torque is not large even when the TA is fully activated, therefore it does not incur a large penalty in the torque objective.
Outcome	In contrast, the metabolic energy objective captures the fact that activating and maintaining contraction of TA generates significant heat and should therefore be discouraged.
Outcome	Note that unlike dorsiflexion torques, large ankle plantarflexion torques can be generated with relative ease.
Outcome	Simply increasing the penalty on ankle torques does not account for the effort difference between generating torques in different directions.
Approach	A simple objective that could approximate effort given a musculoskeletal model is the sum of squared muscle activations, which is commonly used in static optimization—a technique for recovering activations given motion capture and force plate data [Anderson 1999].
Outcome	However, as demonstrated in the accompanying video, this objective also does not lead to faithful walking kinematics.
Approach	Here we define where M is the set of MTUs, and a m,t is the activation level of MTU m at timestep t (with w M = 60000).
Outcome	In the gait produced by the controller that minimizes this objective (min act), activations from the GAS/SOL are significantly lowered, while activations from VAS are increased.
Outcome	While the total amount of activations is reduced, the resulting gait walks in a crouch and relies heavily on the knee.
Outcome	Controllers optimized using the torque and activation objectives both exhibit large errors compared to nwalk, especially at the ankle joint.
Outcome	While noticeable kinematic differences are seen in the gaits produced by different objectives, the torque curves are smooth due to the muscle model and the control parameterization.
Background	The plantarflexors (GAS and SOL) are largely responsible for forward propulsion in normal walking [Liu et al. 2008].
Outcome	We found that weakening the GAS and SOL to a quarter of their original strength, while keeping all other objectives identical (target speed 1.25 m/s), results in a mild crouch gait characterized by excessive knee flexion (see accompanying video).
Outcome	Our result suggests that under the condition of weakened plantarflexors, the mild crouch gait may be metabolically efficient compared to other gait choices.
Background	The crouch gait is commonly found in cerebral palsy patients, and weakness in the plantarflexors is one of many factors thought to contribute to the gait abnormality [Steele et al. 2010].
Background	Knee hyperextension, another common gait abnormality, causes patients to vault the body forward over the extended stance limb, and can result from hamstring lengthening surgery in cerebral palsy patients [Kay et al. 2002].
Outcome	In the accompanying video, we show that our optimization indeed results in a mild hyperextension gait after weakening HAM to a quarter of its original strength, with a mini◦ mum knee flexion angle of 2 .
Outcome	Note that the same angle for the gait ◦ generated by nwalk is 9 .
Outcome	Another cause of knee hyperextension is weakened quadriceps, which can be simulated by weakening the VAS in our model.
Outcome	We found that weakening the VAS to one-tenth of its original strength leads to a motion similar to quadriceps avoidance gait, which is seen in patients with quadriceps weakness and anterior cruciate ligament (ACL) deficiency [Timoney et al. 1993].
Outcome	Our controller architecture and objective function is not limited or specific to walking alone.
Outcome	By simply changing the target velocity and initialization (changing the initial velocity from 1.3 m/s to 3.05 m/s, doubling the initial force feedback gains for GAS and SOL, and bending the elbow), the same procedure yields running controllers, without any modifications to the control parameterization.
Background	In contrast, previous optimization-based control synthesis methods required including torque ratios specific to walking as part of the objective [Wang et al. 2009] or adding spring elements for running [Wu and Popović 2010].
Approach	Our unified approach to both walking and running is consistent with the view that humans select between walking and running by minimizing energy at different speeds [Srinivasan and Ruina 2006].
Approach	We compare running motions generated by our controller at 4.0 m/s with human running data in Figure 7 .
Outcome	Our running kinematic results do not match human data as well as walking, though the basic features of the curves are still present.
Outcome	A main discrepancy is that our hip and knee joints both reach maximum extension earlier than human running data.
Outcome	Similar to our walking results, our knee joint flexes less during the stance phase compared to humans.
Outcome	Our maximum knee flexion is also lower than human data.
Outcome	Our knee extension torque reaches maximum earlier than human data, which can cause the knee to extend too quickly during the stance phase.
Outcome	On the other hand, our plantarflexion torques have a lower peak than human data, resulting in a strategy that relies on the knees more than the ankles.
Outcome	In the supplemental material and the video, we include results for running at speeds ranging from 3.0 m/s to 5.0 m/s.
Outcome	The faster running results are optimized sequentially in 0.5 m/s increments (e.g., 4.0 m/s initialized from 3.5 m/s).
Outcome	As the target velocity increases, finding a satisfactory local minimum appears more difficult.
Approach	We use 100 samples per iteration and a 0.25 m/s optimization increment for speeds over 4.0 m/s.
Challenge	In this work, we have chosen to focus on reproducing humanlike kinematics and torque trajectories.
Outcome	Likely due to our modeling of human-like torque generation and activation delays, our controllers cannot tolerate nearly as much external force as recently developed controllers for purely joint-actuated characters [Mordatch et al. 2010; Wang et al. 2010].
Outcome	However, we can still follow Wang et al. [2010] and optimize explicitly for controllers that can deal with external forces.
Approach	In particular, we optimized controllers that can tolerate 100 N, 0.4 s pushes to the torso.
Outcome	These controllers chose to walk in a stiff crouch gait, with lowered COM and a constantly dorsiflexed ankle to ensure foot clearance (see accompanying video).
Outcome	Note that 100 N is approximately the weight of a 10 kg object, a significant push to a human.
Background	Comparatively, the corresponding 100 N controller presented by Wang et al. [2010], who did not model biological torque generation constraints, did not employ a gait that is significantly different from the undisturbed baseline controller.
Approach	We also optimized for a 4.0 m/s running controller tolerant of 50 N, 0.4 s pushes, as shown in the video.
Outcome	We have presented a biologically-motivated control parameterization that can be used to automatically generate 3D human-like walking and running controllers of different speeds.
Approach	Controllers are optimized to satisfy a set of high-level task terms while minimizing an effort term based on modeling the rate of metabolic energy expenditure.
Approach	Notably, walking and running emerge from the same optimization process simply by changing the target velocity and initialization.
Outcome	Through comparisons to kinematic and torque data of human walking, we show that our results adopt a human-like torque generation strategy while producing kinematic data significantly closer to humans than previous work.
Outcome	Our work demonstrates the importance of modeling constraints on torque generation due to muscle physiology, both in restricting the space of possible torque trajectories and in providing a realistic model of effort.
Approach	We chose to focus on generating human-like locomotion in a straight line and on flat ground.
FutureWork	A natural extension is to investigate whether our control parameterization and effort term can be combined with the popular task-space controllers [Coros et al. 2010; de Lasa et al. 2010; Wu and Popović 2010] and higher-level planning [Coros et al. 2009; Mordatch et al. 2010] to create humanlike motions on uneven terrains [Wu and Popović 2010] or obstacle courses [Mordatch et al. 2010; Ye and Liu 2010]—scenarios that have only been addressed using purely joint-actuated characters.
FutureWork	Finally, an exciting area for future work is to automatically synthesize locomotion controllers for more detailed, fully muscle-actuated human models [Weinstein et al. 2008; Lee et al. 2009].
Outcome	As we have touched on in Section 6.2, our approach can be used to develop predictive biomechanical models to investigate the effects of muscle and control properties on gait.
FutureWork	However, more scientific validation of our simulation results is needed before we can conclude that our results apply to real humans.
FutureWork	One clear aspect for improvement is to adopt a more physically-accurate simulation engine [Sherman et al. 2011], as ODE “emphasizes speed and stability over physical accuracy” [Smith 2006].
FutureWork	More accurate simulations and detailed models present additional computational challenges both in simulation speed and in parameter optimization, but are crucial for potential scientific and medical applications.

Challenge	Optimization is a promising way to generate new animations from a minimal amount of input data.
Challenge	Physically based optimization techniques, however, are difficult to scale to complex animated characters, in part because evaluating and differentiating physical quantities becomes prohibitively slow.
Background	Traditional approaches often require optimizing or constraining parameters involving joint torques; obtaining first derivatives for these parameters is generally an O(D 2 ) process, where D is the number of degrees of freedom of the character.
Approach	In this paper, we describe a set of objective functions and constraints that lead to linear time analytical first derivatives.
Outcome	The surprising finding is that this set includes constraints on physical validity, such as ground contact constraints.
Outcome	Considering only constraints and objective functions that lead to linear time first derivatives results in fast per-iteration computation times and an optimization problem that appears to scale well to more complex characters.
Outcome	We show that qualities such as squash-and-stretch that are expected from physically based optimization result from our approach.
Outcome	Our animation system is particularly useful for synthesizing highly dynamic motions, and we show examples of swinging and leaping motions for characters having from 7 to 22 degrees of freedom.
Background	One appealing vision in animation is that the animator should be able to create and edit motion by defining and adjusting a small number of keyframes and constraints—and that the resulting motion should remain optimal in some way.
Background	An optimization approach to animation has proven useful for editing human motion capture data, refining a “sketched” version of an animation, and for creating entirely new motions for simple characters or short segments.
Challenge	Several challenges remain, however, to achieving fast, flexible, and realistic optimization of human motion.
Challenge	One challenge is incorporating physics into an interactive animation system.
Challenge	Physical validity is important, however, in situations such as those shown in Figure 1 .
Challenge	Kinematic optimization alone is unlikely to capture the coordination of different parts of the body that is required to perform this task, such as the preparatory back swing, the tuck, or the motion of the legs to drive the character upward that is shown in the bottom row of the figure.
Outcome	This paper presents an approach to physically based optimization that is efficient and appears to scale well to more complex characters.
Approach	We use a standard problem formulation—iteratively adjust character motion to meet animator constraints and minimize an objective function.
Approach	Our approach is based on restricting the definition of this optimization problem to constraints and objective functions that can be differentiated in time linear in the degrees of freedom of the character.
Approach	The motivation for this approach is that solution techniques for nonlinear constrained optimization problems (e.g. SQP) typically require either analytical or numerical derivatives.
Approach	Obtaining these derivatives is a computational bottleneck, and complex derivatives can lead to poor optimization performance and problems with local minima.
Background	Kinematic optimization [Gleicher 1997], which has been shown to be successful for complex characters, depends on constraints and objective functions for which first derivatives can be computed in linear time.
Outcome	We have found that constraints on physics that can be derived from the aggregate force and torque applied to the character can also be differentiated in linear time.
Outcome	This set includes most common constraints required for physically correct animation, such as conserving linear and angular momentum during flight, ensuring that ground contact forces can be explained by foot placement, constraining torque applied about an axis (e.g. the high bar in Figure 1 ), and limiting the coefficient of friction at any contact with the environment.
Background	Linear time derivatives for physics constraints do not result from direct differentiation of the equations of motion in either the Newton-Euler or the Lagrangian formulation; in either case, symbolic differentiation would result in a quadratic time algorithm.
Outcome	In this paper, we describe how the Newton-Euler equations of motion can be rewritten to allow first derivatives of aggregate forces and torques to be computed in linear time.
Outcome	We note that it is not possible to compute derivatives for torques at all of the characters joints in linear time.
Challenge	Intuitively, quadratic time is required because motion at any joint affects torque at all joints.
Approach	As a result, typical objective functions such as minimizing the sum of squared joint torques are excluded from our restricted problem setup.
Outcome	Our results suggest, however, that physics constraints and a kinematic measure of smooth motion such as minimizing the sum of squared joint accelerations are sufficient to capture dynamic effects such as squashand-stretch and tucking for faster rotation, as shown in Figure 1 .
Approach	While animator constraints such as key poses or an objective based on proximity to a reference motion can easily be incorporated into the system, no motion capture data is used in our examples, and user-supplied constraints are minimal (e.g., see Figure 7 ).
Outcome	The characteristics of the final motions fall out of the requirements of physical validity, a simple kinematic optimization function, and timing values selected for each phase of the motion.
Background	Constrained optimization techniques were introduced to the graphics community by Witkin and Kass [1988], who created a variety of animations involving a jumping Luxo lamp from simple descriptions including start pose, end pose, and a physically based objective function.
Background	Optimization approaches with physically based objective functions have proven difficult to extend to complex articulated characters, however, and much research has been focused on this problem.
Background	Cohen and his colleagues [Cohen 1992] [Liu et al. 1994] introduced techniques to give the user more control, including an ability to focus on windows in time, and employed a hierarchical wavelet description to allow incremental changes to affect the motion at different time scales.
Background	In his dissertation, Liu [1996] also describes how symbolic differentiation of the equations of motion can be made efficient (although still quadratic time) by cleverly aggregating terms.
Background	Grzeszczuk, Terzopoulos, and Hinton [1998] developed a neural network approximation of dynamics so that gradient search could be performed on this neural network, resulting in faster convergence to a solution.
Background	The mix of animator control and physics present in Witkin and Kass [1988] has been expanded upon in interactive techniques developed to control physical simulations of rigid bodies [Popović et al. 2000], and a number of researchers have shown that the freefall portion of a dive can be efficiently optimized for a simplified character [Liu and Cohen 1994][Crawford 1998][Albro et al. 2000], as can motions such as weight lifting and pushups [Lo and Metaxas 1999].
Background	Optimal control techniques, introduced to the graphics community by Brotman and Netravali [1988], have been used with success by Pandy and Anderson [2000] for simulating human lower body motions such as optimal height jumping and walking.
Background	Running times were far from interactive, but show that optimization techniques can produce realistic motion for systems of human-level complexity.
Background	Preexisting motion data can simplify the optimization process.
Background	Full scale human motion can be optimized when closely spaced keyframes are available [Liu and Cohen 1995] or when only transitions between existing motion segments are required [Rose et al. 1996].
Background	Popović and Witkin [1999] have shown that significant changes to motion capture data can be made by optimizing with a physically based objective function when the character is reduced to the degrees of freedom most important for the task.
Background	When physics does not dominate the motion, kinematic techniques can give the animator interactive control for motion editing (e.g., [Gleicher 1997] [Lee and Shin 1999] [Arikan and Forsyth 2002]).
Background	The idea of physically valid motion has appeared in both graphics and robotics.
Background	Dynamic filters have been developed for processing motion capture data for physical correctness [Yamane and Nakamura 2000] [Dasgupta and Nakamura 1999] [Pollard and Reitsma 2001].
Background	Physics constraints have been used to plan biped walking motions, exploiting the idea that dynamic equilibrium can be maintained by ensuring that the zero moment point (ZMP)—the point on the ground at which ground reaction moments about horizontal axes are zero—lies within the support polygon of the feet [Vukobratović 1970] [Takanishi et al. 1985] [Nagasaka et al. 1999].
Background	Similar ideas have also been developed in graphics by [Ko and Badler 1996], who bend the torso of a character to reduce torques at the desired ZMP, and [van de Panne 1997] who ensure that reasonable forces are available to accelerate the center of mass without creating angular acceleration.
Background	Liu and Popović [2002] show that some dynamic effects can be preserved by enforcing patterns of linear and angular momentum, which does not require computation of dynamic parameters such as contact forces and joint torques.
Outcome	We add to this body of work the insight that it is possible to incorporate constraints on physics as efficiently as constraints on kinematic parameters and an O(D) algorithm for computing first derivatives of a broad range of physics constraints for improved performance in a optimization context.
Background	Constrained optimization has been shown to be a very powerful approach for obtaining appealing dynamic motions from a minimal amount of input information.
Background	The user adjusts the problem description in the form of keyframes, constraints, and objectives; an optimizer computes an optimal animation given this problem description; and the process repeats until the user obtains a final animation ( Figure 2 ).
Approach	We use cubic B-splines as basis functions and follow the standard approach of enforcing constraints at a fixed set of points in time (t i ).
Approach	Enforcing physics constraints or minimizing a dynamic property such as sum squared joint torques requires an inverse dynamics computation at each time t i .
Background	Although the inverse dynamics computation is relatively expensive, many efficient algorithms exist, and the process is well known to require time linear in the number of degrees of freedom of the character.
Approach	However, typical choices for the numerical optimizer in Figure 2 also require derivatives of the constraints and objective function.
Background	For example, the sequential quadratic programming algorithm used in [Witkin and Kass 1988] makes use of first derivatives of the constraints (the constraint Jacobian) and both first and second derivatives of the objective function (the Jacobian and the Hessian).
Approach	This paper describes how a broad range of physics constraints can be expressed based on aggregate forces and torques applied to the character, and how expressing physics constraints in this way allows us to compute the constraint Jacobian in linear time (Section 4).
Approach	We used an objective function that enforces smooth motion, with a linear time Jacobian computation and a constant Hessian.
Outcome	With this objective function and our linear time algorithm for computing the constraint Jacobian, we are able to show that physically based optimization can be performed for a 22 degree of freedom character at interactive speeds.
Approach	Constraints that enforce physical validity can be formulated as linear equality or inequality constraints on aggregate force.
Approach	The aggregate force is a representation of all external forces and torques (excluding gravity) that would have to be applied to the character root to explain the character’s motion.
Approach	We classify the physics constraints for the motions in our examples into the categories of flight, bar contact, and ground contact.
Approach	One way of enforcing correct physics during flight is to ensure that the aggregate momentum of the body remains constant throughout the flight phase.
Approach	Unfortunately, the constraint Jacobian that results from constraining momenta is denser than necessary as the control points that determine take-off affect all constraint equations governing the flight phase.
Approach	A more elegant solution is to restrict illegal forces during flight.
Approach	During flight, no forces, with the exception of gravity, may be derived from the environment.
Approach	Let the aggregate force be denoted by f 0 .
Approach	(In the spatial notation used here, f 0 contains both linear forces and torques.
Approach	) The flight constraint is thus f 0 = 0.
Approach	When the character is swinging on a high bar or monkey bars, the amount of torque that can be applied about the bar axis is constrained.
Approach	Aggregate force is translated to a constraint point c as follows:
Background	During ground contact, the feet can only push, not pull on the ground, contact forces should not require an unreasonable amount of friction, and the center of pressure must fall within the support polygon of the feet.
Approach	These effects can be modeled with equations that constrain the linear and angular forces separately.
Approach	We constrain the linear force using Coulomb’s contact model.
Background	Coulomb’s model dictates that the linear reaction force must fall within a friction cone oriented along the contact normal with angular half-width tan −1 μ , where μ is the coefficient of friction.
Approach	The magnitude of the normal force can be constrained as follows:
Approach	Contact torques are constrained by geometrically confining the center of pressure to the support area.
Approach	Let T x and T y be orthogonal vectors spanning the rectangular support, and let δ x and δ y be the distances from c to the edge of the support along along T x and T y respectively.
Approach	The torques about T x and T y may be constrained as:
Approach	Once all physics constraints have been expressed as constraints on aggregate force, computing derivatives on the physics constraints becomes a problem of differentiating aggregate force with respect to the free parameters of the problem.
Approach	At any time t, character position q, velocity q,  ̇ and acceleration q  ̈ are known.
Approach	The derivative of interest can be expressed in terms of q, q,  ̇ and q  ̈ using the chain rule:
Approach	The term ∂ f 0 / ∂ q, which we will refer to as the force Jacobian, is the most difficult term in this expression.
Approach	The main point of the paragraphs below is to show how the force Jacobian can be computed efficiently.
Outcome	1 We show that straightforward analytical computation of the force Jacobian would require time quadratic in the number of degrees of freedom of the character.
Approach	However, if joint torques are not required, then this value and first derivatives for constraints based on this value can be computed in linear time.
Outcome	To our knowledge, our paper is the first to present a linear time algorithm for computing the force Jacobian for an articulated character or robot.
Approach	Our argument and implementation is constructed around a NewtonEuler formulation of inverse dynamics.
Approach	We use spatial notation as in Featherstone [1987] for conciseness.
Approach	Spatial notation involves 6-dimensional vectors, 6x6 coordinate transformations, and 6x6 inertia tensors.
Approach	It combines linear and angular quantities such as force and torque or linear and angular velocity into single vectors, as shown in Equations 1 through 3.
Approach	Efficiently computing ∂ f 0 / ∂ q, the force Jacobian, requires efficiently computing ∂ p 0 / ∂ q, the momentum Jacobian, because aggregate force f 0 is the time derivative of aggregate momentum p 0 .
Approach	We begin with a discussion of the momentum equations and present an argument that the momentum Jacobian can be computed in linear time.
Approach	The usual way to compute aggregate momentum is to formulate the following recursion:
Approach	Velocities v i are propagated from base to leaf, and momentum p i is propagated from leaf to base.
Approach	Parameter q i appears in the coordinate transforms X i i+1 and X i+1 i , and so every v j for j > i depends on q i , and every p j for j ≥ 0 depends on q i .
Approach	Unrolling the recursion to collect terms for ∂ p 0 / ∂ q i requires O(D) time.
Approach	There are D terms q i , and this approach will lead to an O(D 2 ) computation for the momentum Jacobian.
Approach	There is no clever way to simplify the calculation by aggregating terms when it is presented in this form.
Approach	We observe that rewriting the recursion solves this dilemma:
Approach	The key thing to notice here is that p ∗ i is expressed as a function of v i , which is a local variable at link i.
Approach	As a result, only propagation from leaf to base is required, and each parameter q j does not affect terms computed for joints j + 1 and beyond ( Figure 4 ).
Approach	Also note that p ∗ i is in general not equal to p i if i = 0.
Approach	A term superscripted with an asterix should be treated only as an intermediary quantity, unless its subscript is zero in which case it is the desired aggregate result.
Approach	A linear time expression for the momentum Jacobian can be derived in a straightforward manner based on this form of the recursion.
Approach	Aggregate momentum p 0 and the momentum Jacobian are exactly the same in both formulations.
Approach	This equation has the properties we are looking for.
Approach	Velocity v i and acceleration a i are local to link i, and terms are propagated from leaf to base only.
Approach	Note that as with aggregate momentum, f ∗ i is in general different from the actual joint force f i if i = 0.
Approach	Numerically the partial derivatives are identical.
Approach	The articulated model is a serial chain ranging from 3 to 50 links.
Approach	As expected, the proposed method is linear in the degrees of freedom, while direct differentiation shows quadratic growth.
Approach	It is also observed that despite overheads in computing aggregate intermediate terms, the linear time method shows a computational advantage with as few as 5 degrees of freedom.
Challenge	One possible reason is that there is a cost to this approach that may be higher for robotics applications than for graphics applications.
Approach	In a standard Newton-Euler formulation, force parameter f i (Equation 17) contains all of the joint force information for joint i, in particular forces in the actuated directions of motion (joint torques).
Background	In robotics, this information must be computed because it corresponds to signals sent to the motors of the robot.
Background	It must in general also be part of optimization routines, because en- ergy consumption and joint torque limits are of particular concern when operating a robot, and none of the joints can be ignored.
Approach	In contrast, we argue that for animation of human motion, many of the effects we expect to see in physically based optimization do not depend on joint torques.
Challenge	We believe that physical correctness and optimization functions enforcing smooth motion are sufficient to obtain many natural characteristics of human motion.
Challenge	If some torques (e.g. torques at the hip joints) are found to be important, it seems quite certain that many others (e.g. torques at the fingers) can be ignored for many motions.
Approach	If a subset of K torques are required, it is straightforward to extend our approach to measure torques at these joints in O(KD) time.
Approach	One traditional approach is to use the integral of the sum of squared joint torques to produce a motion that approximately minimizes energy expenditure:
Approach	This function is expensive because computing its gradient requires O(D 2 ) work.
Approach	Adopting this function would negate our effort in constructing efficient physics constraints.
Approach	An objective function that we have found to work well is to minimize the integral of the sum of squared, weighted joint accelerations:
Approach	For example, the weight for the left-knee during a left-legged support is the entire body mass minus the left lowerleg.
Approach	Parameters q  ̈ i do not include translational or rotational acceleration of the character root.
Approach	Note that the analytical Hessian for this objective function is constant, symmetric, positive definite, and band-diagonal.
Approach	Where a reference motion q R (t) is available, a simple objective function with low cost is to simply minimize the distance from the reference motion:
Approach	This objective function is similar to the one used in Gleicher [1997].
Approach	Other objective functions we have attempted include an integral of squared contact forces:
Approach	The Jacobian of this function is computable in linear time; our physics constraints are based upon it.
Approach	Gaits generated using this function have a certain ‘tip-toe’ quality to them, as the function minimizes the amount of reaction force derived from the contacts.
Approach	Minimizing contact jerk (the time derivative of force) can be achieved using forward differences:
Outcome	Note the looser tuck and the higher flight trajectory in the 0.8s motion.
Outcome	The initial motion (shown in the top row of Figure 6) appears very unstable at landing.
Outcome	The character would fall over.
Outcome	This effect is eliminated in the optimization by enforcing the physics constraints of ground contact.
Outcome	Details of the optimization setup are in Figure 7 .
Outcome	All timing information is for a 750 MHz Pentium 3 computer.
Outcome	No touch-up was done on the results.
Outcome	In particular, the geometry of the monkey bars and the pegs was not modeled.
Outcome	In these examples, notice the swinging of the legs and arms, as well as body roll, pitch, and yaw.
Outcome	All of these effects are obtained as a result of the optimization process.
Outcome	In these examples, the initial motion is rigid translation of the entire character.
Challenge	Our goal was to require a minimal amount of information from the animator.
Approach	To set up these examples, we used 15-30 control points per degree of freedom.
Outcome	We found that a number of time slices (for constraint evaluation) equal to the number of control points produced good results and did not need to adjust this value for individual motions.
Outcome	Finer time slices would overly constrain the system, and sparser time slices allowed too much freedom for error.
Approach	Each motion was set up using a constraint configuration file containing the information listed in the tables.
Approach	In general, the initial motion was determined directly from constraints, with no additional user input, using linear interpolation between constrained poses.
Approach	The exception was initial control points for the character root in the first example, which were set to create the overall body rotation required for the backflip.
Approach	To automatically compute initial motion in a constrained pose, all joints are set at zero angle, the character is in a vertical posture, and the relevant end effector is placed at a user-specified point (e.g. hand at a specific point on the monkey bars).
Approach	The vertical ”zero posture” had arms up for the bar swings, legs out for the monkey bars, and arms down for the ground motions.
Approach	The high bar final pose was the only pose provided as a constraint in these examples.
Approach	To empirically test the advantage of our method for fast derivative computation, we ran the peg example (bottom row of Figure 6) 5 times, each time with the identical setup except that a different technique was used to compute all required first derivatives.
Approach	Two implementation issues were especially important for achieving the results described in this paper.
Approach	First, we note that if the basis functions have local influence, the vector and matrix quantities computed during optimization are very sparse.
Approach	We use the publicly-available Lancelot optimization package [Conn et al. 1992] where sparsity is accounted for by groupseparability.
Approach	Second, we outline the issue of rerooting.
Approach	Implementing any inverse dynamics algorithm requires selecting a character root.
Approach	An ability to move the effective root to different parts of the character is very convenient.
Approach	In the swing example of Figure 1 , it may be convenient to root the character at the hands for the swing, at the center of mass for flight, and at the feet for landing.
Background	In a Newton-Euler inverse dynamics formulation, rerooting is typically done by changing parent / child relationships, which requires inverting joint angles and transforms at each joint and altering the flow of dynamic terms from leaves to root.
Approach	Both of these changes complicate the problem description presented to the optimizer.
Approach	The effective root can be relocated more easily, however, by leaving the actual root and the flow of the dynamics computation fixed and computing velocities and accelerations at the root to maintain the desired constraint.
Outcome	This paper contributes to physically based optimization by defining and exploring a restricted class of optimization problems where physics constraints are included and first derivatives of constraints and objective functions can be computed in linear time.
Outcome	The fact that first derivatives can be computed in linear time instead of quadratic time suggests that our problem is simpler than previous physically based approaches and similar in complexity to very successful kinematic approaches such as minimizing distance to a reference motion.
Outcome	We suspect that our solution landscape will be smoother than previous physically based optimization approaches, making it feasible to handle more complex characters.
Outcome	When the optimization does not converge, we can usually trace it back to the problem setup.
Outcome	Sometimes it is due to overconstrained equations (setup error).
Outcome	But often it is due to overly restrictive parameters, such as friction coefficients, joint limits, poor selection of timings, etc.
Approach	At present, timings are set by the user and their values need to be reasonable (e.g., the character cannot leap too far in too short a time).
Outcome	Any optimization technique that makes use of local derivatives has potential problems with local minima.
Outcome	Our experience, however, was that as long as an expected motion sequence could be thought of as motion about some neutral position, then when the character was started in that neutral position there was no problem descending toward the expected minimum.
Outcome	We were able to create a jumping Luxo and highly dynamic human motions with good success.
Outcome	For less dynamic activities, our system would require additional input; physics constraints plus smooth motion would not in general produce the desired results.
Outcome	” Given this problem definition, our system would identify a static pose near the initial guess where the projection of the center of mass is in support area.
Approach	Additional information would be required to fill in the details of the standing motion.
Approach	For activities where joint torque limits are important, this torque information must be taken into account to produce good results.
Outcome	An extreme example of this situation is the passive swing of a multilink chain.
Outcome	Minimizing accelerations while maintaining physics constraints would produce a result that was valid for the body as a whole but would require non-zero torques at the joints—no whipping motion would be seen.
Outcome	Minimizing sum squared torques would produce the desired results.
Outcome	(Of course, truly passive motion can be created much more easily using forward dynamic simulation.
Outcome	) More commonly, a limited set of torques or energy terms may be important.
Outcome	For example, the peg running motion appears very athletic because it would require high torques at the knee and hip joints.
Outcome	When physical parameters at certain joints are identified as important, our method can be extended to provide and differentiate these parameters for any K joints with running times of O(KD), reaching the expected bound of O(D 2 ) when all joint torques are required.
FutureWork	An interesting research problem is to determine automatically when torques at a given joint should be considered.
Outcome	Running on flat ground shows a combination of difficulties.
FutureWork	To make this motion appear more natural, we would need to consider proper timing for the running stride, a more accurate foot model, torques at some of the joints, and perhaps also aspects of style that are not driven by physics or energy.
Outcome	Complexity in the number of degrees of freedom of the character is not the only concern in physically based optimization.
Outcome	The number of free parameters of the optimization problem also grows linearly with total time allotted for the animation.
Background	We have not yet attempted any long motion sequences, but we note that Liu, Gortler, and Cohen [Liu et al. 1994] have shown that time complexity can be effectively managed in an optimization context, in part because the influence of any one parameter is localized in time.
Approach	It is interesting to compare our approach to that of Liu and Popović [2002].
Background	Their paper describes the power of patterns (e.g., momentum patterns) in creating desirable animation effects, and their approach could be adapted easily to obtain linear time performance by rewriting the momentum equations as described in Section 4.2 of this paper.
FutureWork	The idea of dynamic patterns is an exciting one.
FutureWork	However, relying on momentum patterns without computing interaction forces between the character and the environment may result in problems with certain types of physics constraints (e.g., keeping forces within a friction cone) when the initial motion is not favorable.
Outcome	In the present paper, we show that it is possible to optimize motion with physics constraints in an efficient manner, so that reasonable friction conditions, for example, can be easily enforced.
Outcome	We believe the combination of correct physics and knowledge of natural dynamic patterns of human motion such as momentum or movement of the center of pressure in the roll of the foot on the ground could be very powerful.
Outcome	Finally, we would like to emphasize that the main advantage of our approach may be as part of a more complete animation system.
Outcome	Our vision is that the ability to enforce physics constraints efficiently should be just one of the tools available to the animator.
FutureWork	Details of the desired motion could be fleshed out using motion capture data, procedural techniques, keyframes, and/or objective functions appropriate to the specific task.
Outcome	We have shown that physics constraints can be enforced in an efficient manner.
FutureWork	Incorporating physics constraints into traditionally kinematic animation approaches is one direction of future work.
Approach	For rotational joints, joint axis s i is represented as follows:
Approach	Both terms are expressed in the body i local frame, and the superscript on s i indicates that the spatial vector is expressed in body i local frame coordinates.
Approach	We represent multiple degree of freedom joints as sequences of single degree of freedom joints, connected by massless and inertialess bodies.
Approach	Spatial force also combines linear and angular quantities:
Approach	Spatial transform X i j takes spatial quantities from frame i to frame j:
Approach	Spatial inertia represents both body mass and rotational inertia:
Approach	Where superscripted with an asterix (e.g., I ∗ i ) the quantity represents aggregated information accumulated from L to i.
Approach	The equations of motion of a serial multibody chain are compactly expressed in recursive form as follows:
Approach	The Newton-Euler equations propagate quantities in two directions.
Approach	Compute:
Approach	I ∗ 0 and p ∗ 0 are the aggregate inertia and momentum of the entire body, and p ∗ 0 is equal to p 0 computed from the previous NewtonEuler recursive equations.
Approach	However, p ∗ i is in general not equal to p i where i = 0 and should only be used as an intermediary quantity in computing the aggregates.
Approach	As before, f ∗ i is in general not equal to f i where i = 0.
Approach	The Jacobian may be constructed in time linear in the number of degrees of freedom as follows.
Approach	All partial derivatives are expressed in frame i.
Approach	Suppose we wish to place the effective root of the character at the point on body i that is located at point r in body i coordinates.
Approach	We wish this point to have linear velocity b r,des and linear acceleration b  ̇ r,des , expressed in the world coordinate frame.
Approach	The current velocity of body i in the body i frame is v i .
Approach	In Equation 51, v b r is the linear velocity of the effective root expressed in world coordinates.
Approach	This velocity should be b r,des .
Approach	To obtain the correct velocity at the effective root, simply add the desired correction (b r,des − v b r ) to the reference frame velocity:
Approach	The adjustment to a 0 is derived using similar reasoning.
Approach	When these changes are made, the actual character root can remain at the pelvis, for example, while the effective root is moved from hand to pelvis to foot or other bodies as needed.
Approach	The effective root can even be set to the center of mass to obtain correct ballistic motion during flight.
Approach	Derivatives of all equations with respect to parameters describing the motion can be computed in O(D) time.

Outcome	This paper describes a technique for animating the behavior of viscoelastic fluids, such as mucus, liquid soap, pudding, toothpaste, or clay, that exhibit a combination of both fluid and solid characteristics.
Approach	The technique builds upon prior Eulerian methods for animating incompressible fluids with free surfaces by including additional elastic terms in the basic Navier-Stokes equations.
Approach	The elastic terms are computed by integrating and advecting strain-rate throughout the fluid.
Approach	Transition from elastic resistance to viscous flow is controlled by von Mises’s yield condition, and subsequent behavior is then governed by a quasi-linear plasticity model.
Background	Often referred to as viscoelastic fluids, these materials initially respond to strain elastically like a solid, but when subjected to increasingly large stresses they flow like a fluid.
Background	A tremendous variety of materials exhibit this type of behavior, and a few common examples include: mucus, egg white, dough, gelatin, unset cement, liquid acrylic, toothpaste, gels, clay, and liquid soap.
Background	Like a solid, these materials can bounce and jiggle, but they will also flow like a fluid.
Background	For some of these materials, such as egg white or clay, the combination of elastic and fluid behavior is quite apparent.
Background	For others, such as liquid soap, the elastic behavior manifests less obviously as predominately fluid behavior that differs subtly from that of a simply viscous fluid.
Approach	The technique we present builds on prior Eulerian methods for animating incompressible fluids with free surfaces.
Background	As evidenced by their widespread use, these methods can efficiently produce results that are realistic enough for applications in the demanding visual effects industry.
Approach	Our method computes viscoelastic fluid behavior by supplementing the basic Navier-Stokes equations with additional terms for elastic body forces.
Approach	These elastic terms require computing the material strain throughout the fluid.
Approach	Because the fluid simulations do not make use of an explicit reference configuration, strain is computed by integrating strain-rate and advecting the results.
Background	The transition from elastic resistance to viscous flow is controlled by von Mises’s yield condition, and subsequent behavior is then governed by a quasi-linear plasticity model.
Background	While the mechanics describing the behaviors exhibited by solids and fluids may seem distinct, they are actually quite similar.
Background	First, both resist changes to their volume.
Background	The physical reasons for why they conserve volume may differ, but the mathematical expressions capturing the behaviors are essentially the same.
Background	Furthermore, many fluid methods assume incompressibility and most solid methods assume that volume changes will be negligible.
Background	Second, the internal damping force for a solid and the viscous force for a fluid are not just similar, they are identical.
Challenge	The key difference between an ideal solid and an ideal fluid is the presence or absence of an elastic term that attempts to restore the material to its original shape.
Background	The continuous variable that spans the space between solid and fluid materials is this limit on how much stress can be tolerated before flow occurs.
Background	Other properties such as damping/viscosity, density, and elastic stiffness are largely orthogonal.
Background	When the elastic limit is set to a high value, the material behaves like a solid, when it is zero the material behaves like a fluid, and intermediate values correspond to materials like mucus, liquid soap, toothpaste, or clay.
Background	These intermediate materials are often referred to as viscoelastic fluids or as elastoplastic solids, depending on whether their behavior is closer to that of an ideal fluid or ideal solid.
Background	In the field of computer graphics, the technique described in [Carlson et al., 2002] is perhaps closest in intent to the method we describe here.
Background	Like us, they were interested in modeling materials with properties intermediate between solids and fluids using an Eulerian grid-based fluid simulation method.
Background	However, they opt to map the continuum between fluids and solids to varying viscosity.
Background	In their system a solid is simply a fluid with very high viscosity.
Background	This approach ignores the elastic behavior demonstrated by many materials.
Background	Nevertheless, they do generate nice results for highly viscous fluids, and they describe an implicit integration method for coping with stability issues arising from very high viscosities.
Background	Other graphics researchers have used particle-based methods for modeling highly viscous fluids and for modeling fluids with some form of elasticity.
Background	In [Terzopoulos et al., 1989] the authors modeled melting thermoelastic materials.
Background	The particles exerted cohesive, viscous, and volume-preserving forces on their neighbors.
Background	While solid, each particle was connected to a fixed set of neighbors using elastic springs.
Background	As the material would become more fluid-like, the springs would weaken, and eventually disappear.
Background	By varying the elastic properties of the materials, this method could model a range of behaviors, but without plasticity, it could not model materials, like clay, that flow into a new configuration and then resist changes from that configuration.
Background	Similar approaches using different particle formulations have appeared in [Desbrun and Gascuel, 1995], [Desbrun and Cani, 1996], [Cani and Desbrun, 1997], and [Stora et al., 1999].
Background	The method appearing in [Desbrun and Gascuel, 1995] used elastic forces with dynamically determined neighbors to allow behavior that is similar to plastic flow.
Background	Perhaps the greatest limitation on the level of realism achievable by these particle methods was the relatively small number of particles used.
Background	However, as processor speeds have increased, particle-based methods have been able to achieve increasingly impressive results.
Background	Compelling real-time results for modestly sized systems appear in [Müller et al., 2003], and [Premo ze et al., 2003] demonstrates off-line results that are comparable to the current best grid-based methods.
Background	Although both of these recent methods focus on strictly liquid behavior, they could be extended along lines similar to what we propose here.
Background	Some methods for modeling solids have dealt with limited amounts of plastic flow.
Background	Both [Terzopoulos and Fleischer, 1988a] and [Terzopoulos and Fleischer, 1988b] describe transition to plastic flow based on von Mises’s yield condition, and [O’Brien et al., 2002] used a similar plasticity model for ductile fracture behavior.
Approach	We use the same yield condition of von Mises, but we do not assume that plastic flow occurs instantaneously.
Approach	Instead we use a more complex model that accommodates phenomena such as creep.
Background	Additionally, these prior methods used Lagrangian meshes with largely fixed topology, and so they would have encountered “tangling” difficulties, such as inverting elements, for large amounts of plastic flow.
Background	Another, rather interesting, approach to combining solid and fluid behaviors appears in [Nixon and Lobb, 2002].
Background	They surround a fluid simulation with an elastic membrane.
Background	The result is an object that behaves somewhat like a water balloon.
Approach	Our work builds directly on previous grid-based, Eulerian methods for animating fluids with free surfaces.
Background	Details on these methods can be found in [Foster and Metaxas, 1996], [Stam, 1999], [Foster and Fedkiw, 2001], and [Enright et al., 2002].
Approach	In particular, our work essentially extends [Enright et al., 2002] to include the behavior of viscoelastic fluids.
Background	Outside the graphics field, viscoelastic materials have been studied extensively.
Background	We refer the reader to the texts [Fung, 1965], [Han and Reddy, 1999], and [ Bird et al., 1987 ] for detailed descriptions of several different models for viscoelastic and elastoplastic materials.
Approach	The general approaches we use for introducing elastic forces into the Navier-Stokes equations, and integrating and advecting strain are not completely novel.
Background	Some recent examples of fluid simulation outside the graphics literature that involve elastic forces include [Gerritsma, 1996], [Tomé et al., 2002], and [ Bonito et al., 2003 ].
Background	A detailed analysis of two-dimensional simulations of viscoelastic fluids on staggered rectilinear grids appears in [Gerritsma, 1996].
Background	The three-dimensional method we use for storing rank-two tensor quantities on a staggered grid is a generalization of their two-dimensional method.
Background	In [ Bonito et al., 2003 ] a combination of rectilinear grids and finite elements are used with a volume-of-fluid method to model three-dimensional fluids with elastic properties.
Background	They do not include plasticity and they store all quantities at cell centers.
Background	The marker-andcell based method in [Tomé et al., 2002] is another example solving viscoelastic free-surface flows.
Background	They address issues relating to elastic-stress based boundary conditions at rigidbody and free-surfaces.
Background	Although they use a staggered grid for the velocity field, they still store their tensor values at cell centers.
Approach	The framework we use for fluid simulation is based on the method described in [Enright et al., 2002].
Approach	This framework consists of two primary components which work together to produce useful results.
Approach	The first is a rectilinear grid that stores the values that define the fluid’s state.
Approach	The values on the grid change as forces act on the fluid, and they also change as the fluid moves through the space delineated by the grid.
Approach	The second component is a function whose levelset at zero locates the boundaries of the fluid.
Approach	The function is represented using a combination of particles and values defined on a second rectilinear grid.
Approach	The particles and grid values evolve based on the motion of the fluid.
Approach	A full description of this type of system is beyond the scope of this paper, so we focus on the changes we make to accommodate viscoelastic behavior.
Background	We suggest the following references for a more complete description of this simulation methodology: [Foster and Metaxas, 1996], [Stam, 1999], [Foster and Fedkiw, 2001], and [Enright et al., 2002].
Approach	Behavior of the viscoelastic fluid is governed by a modified version of the Navier-Stokes equations that includes an additional term for elastic stress.
Approach	The symbol denotes the vector of difT ferential operators = [∂/∂x, ∂/∂y, ∂/∂z] , and we have implicitly assumed that μ v and μ e are constant throughout the material.
Approach	By omitting elastic and viscous terms relating to dilation, we have also assumed that the fluid is incompressible.
Approach	This condition is enforced by adjusting the pressure field at each integration step.
Approach	Additionally, we do not use the first term of Equation (1) (the advection term) directly.
Approach	Instead, we use a semi-Lagrangian method to advect field values.
Background	We refer the reader to [Stam, 1999] and [Foster and Fedkiw, 2001] for a discussion on efficiently modeling the above equations.
Approach	The fourth term of Equation (1) computes acceleration due to elastic forces and it requires knowing the elastic strain throughout the fluid.
Approach	If we had an explicit deformation function then we could use its spatial derivatives to compute strain.
Approach	However, with the Eulerian formulation we are using there is no deformation function available.
Approach	Furthermore, the large deformation and flow experienced by the material makes tracking deformation impractical.
Approach	Instead we compute strain by integrating strain-rate.
Approach	Because we do not wish to model a perfectly elastic material, we also require rules concerning how the elastic strain changes due to plastic yielding.
Approach	We first separate the total strain into an elastic and a plastic component so that          Tot Elc Plc = + .
Approach	(Outside this section we denote elastic strain as simply .
Approach	Similarly, the plastic strain is given by integrating plastic flow.
Approach	We use von Mises’s criterion for determining when plastic flow should occur.
Approach	So long as the magnitude (Frobenius norm) of the strain deviation remains below the yield point, γ, no plastic flow occurs.
Approach	When the limit is exceeded, flow occurs at a rate proportional to the amount the limit has been exceeded by.
Approach	Note that Equation (9) does not take into account the movement of the material through space.
Approach	Like velocity or any other fluid property, the elastic strain must be advected with the fluid.
Approach	We use the same semi-Lagrangian advection scheme that we use for the fluid velocities, and we update the elastic strain using Equation (9) after our advection step.
Approach	However in addition to scalars (e.g. pressure) and rank-one tensors (e.g. velocity), we also need to store the elastic strain, a rank-two tensor, on the simulation grid.
Approach	Just as velocity components are stored separately on faces, the different components of the strain tensor are stored at different locations.
Approach	The diagonal entries are stored at the cell centers.
Approach	The off-diagonal entries are stored at the center of edges perpendicular to the component directions.
Approach	For example, the xy components are stored on the edges parallel to the z axis.
Approach	This approach is a generalization of the 2D method described in [Gerritsma, 1996], and they describe its merits in detail.
Approach	We use a particle-level-set method for tracking the fluid’s free surface as described in [Enright et al., 2002], but with the substantially faster, though less accurate, method detailed in [Enright et al., 2004].
Approach	The authors note that the method is susceptible to volume loss, and we found this behavior to be problematic for some of our examples that involve fixed, small amounts of fluid.
Approach	We were able to ameliorate this problem somewhat by using a level-set grid with twice the fluid grid’s resolution, and that is staggered with respect to the fluid grid.
Approach	This scheme places level-set grid centers on the cell centers, face centers, edge centers, and nodes of the fluid grid.
Approach	In addition to helping to prevent volume loss by locating level-set values where velocity boundary constraints are enforced, the higher resolution also benefits the rendered surfaces.
Approach	We have implemented this method for modeling viscoelastic behavior and used it to generate several example animations.
Approach	Most of these examples were selected to illustrate some interesting aspect of viscoelastic fluid behavior.
Outcome	The motion of the pure fluid example differs substantially from the viscoelastic examples.
Outcome	Additionally, the surfaces of the viscoelastic examples retain evidence of the impact even after motion has stopped.
Outcome	Again, the behavior of simple and viscoelastic fluids differ substantially.
Outcome	A simply viscous fluid would merely flow out to fill the container.
Outcome	The examples with high yield strain, i.e. large γ, behave like deformable solids and bounce.
Outcome	When the spheres collide, their level-set surfaces merge so that they adhere.
Outcome	The fluid retains its momentum, generating the resulting spinning and stretching motion.
Outcome	Close examination shows that the spheres slightly anticipate their collision.
Outcome	This error occurs because the surfaces begin to interact through shared ghost cells.
Approach	All of the images were rendered with a standard Newtoniteration based ray marching algorithm implemented in the open source renderer Pixie developed by Okan Arikan.
FutureWork	While ray marching produces nice results we think they might be improved using the method described in [Heckbert, 1987].
Outcome	Some of our examples suffer from noticeable volume loss.
Outcome	This occurs because, while the particle level-set method does a nice job modeling moderately thick volumes of fluids, very thin surfaces, or strands, still have a tendency to vanish.
Outcome	These effects are particularly noticeable visually when the fluid is moving in orderly fashion, as opposed to splashing about chaotically.
Outcome	It is difficult to say if this behavior is a deficiency in our implementation or a limitation of the surface tracking method.
Outcome	The speed of this simulation method is approximately the same with and without the addition of elastic forces.
Outcome	For example, one of the falling cube examples on a 40 3 grid requires about half an hour of computation per second of animation on a single 3 GHz Pentium 4 processor.
Approach	We are using an explicit integration method for the viscous and elastic forces, so very high viscous or elastic coefficients would probably cause stability problems and force smaller time steps.
FutureWork	If it became an issue, that difficulty could be ameliorated somewhat with an implicit integration scheme.
Outcome	The material can be made to adhere to or slip off of boundary surfaces by adjusting the velocity or pressure constraints enforced along closed boundaries.
Outcome	However, in our current implementation all fluids will stick to each other because different surface components merge when they collide.
Outcome	For the fluids we show in our examples, this behavior is a desirable feature.
Outcome	However, for non-sticky materials, like cold gelatin, it would be undesirable.
FutureWork	To a large extent, our method for incorporating elastoplastic terms does not depend on the underlying fluid simulation method, and one could easily adapt the method to other fluid simulation techniques such as smoothed-particle hydrodynamics.
Outcome	Furthermore, we found that once we already had a working fluid simulation, adding the elastoplastic terms was fairly easy.
Outcome	Finally, we note that while the method we present can model a wide range of phenomena, many real materials can demonstrate behaviors not captured by this model.
Background	Biological fluids, such as blood, can exhibit many interesting effects that arise from their microscopic structure.
Outcome	Even relatively simple polymer suspensions can demonstrate behavior that can only be roughly captured with this model.

Outcome	We present an algorithm for the simulation of incompressible fluid phenomena that is computationally efficient and leads to visually convincing simulations with far fewer degrees of freedom than existing approaches.
Approach	Rather than using an Eulerian grid or Lagrangian elements, we represent vorticity and velocity using a basis of global functions defined over the entire simulation domain.
Outcome	We show that choosing Laplacian eigenfunctions for this basis provides benefits, including correspondence with spatial scales of vorticity and precise energy control at each scale.
Approach	We perform Galerkin projection of the Navier-Stokes equations to derive a time evolution equation in the space of basis coefficients.
Outcome	Our method admits closed form solutions on simple domains but can also be implemented efficiently on arbitrary meshes.
Background	Fluid motion is naturally captivating.
Background	Over the years, it has piqued the imagination and curiosity of artists, mathematicians and scientists.
Background	The fascination with fluid motion is exemplified by its long history in the computer graphics literature.
Background	Early work focused on obtaining motion that is visually interesting and convincing.
Background	More recent physically based techniques rely primarily on numerical approximation of the Navier-Stokes equations.
Background	Computer simulation of a model necessitates a finite representation of its spatial quantities.
Background	Grid-based techniques are the most common approach.
Challenge	However, they suffer from high computational complexity, due to the general requirement at each simulation step to solve a system of equations whose size is proportional to the number of grid elements in the domain.
Background	Lagrangian techniques, such as mass particles, removes the dependence on the simulation domain.
Challenge	That said, the computation of pressure and other fluid quantities are expensive and approximations lead to noticeable violations of incompressibility.
Background	Vorticity primitives, including particles and filaments, are very effective at simulating smoke in inviscid media but have difficulties modelling diffusion and handling boundary conditions.
Background	Model reduction is a data-driven approach that exploits a precomputed set of example simulations to obtain a low dimensional representation for fluid motion.
Challenge	While this technique is very efficient at run-time, it suffers from significant costs for precomputation and storage, and is dependent on the performance of an existing simulator or other mechanism to obtain ground-truth data.
Challenge	We propose an algorithm for the interactive simulation of fluid motion that avoids many of the shortcomings of existing techniques.
Approach	We employ a representation of fluid velocity and vorticity in a finite dimensional basis of Laplacian eigenfunctions.
Outcome	The resulting velocity basis fields are divergence free and respect boundary conditions, so that these constraints are enforced automatically without the need for additional computation.
Approach	Our algorithm can be formulated as Galerkin projection of the vorticity form of the Navier-Stokes equations onto Laplacian eigenfunctions defined over the simulation domain.
Approach	The resulting finite dimensional form of the equations describes the time evolution of the basis coefficients.
Approach	We precompute the non-linear advection terms between pairs of basis functions and store the result as structure coefficients in a set of matrices.
Approach	Viscosity and external forces are incorporated using linear terms, and the basis function coefficients are hence updated using a simple matrix-vector equation.
Approach	Laplacian eigenfunctions form an orthogonal basis, allowing one to easily compute the energy of the fluid.
Approach	Additionally, Laplacian eigenfunctions of increasing eigenvalue magnitude have a natural visual correspondence with decreasing scales of vorticity.
Approach	Coupled with orthogonality, the correspondence allows precise control of a fluid’s turbulent spectrum through adjustment of basis coefficients.
Approach	With Laplacian eigenfunctions the viscosity can be simulated accurately through a simple exponential decay of basis coefficients, but also allows arbitrary user-controlled or automatic adjustment of the spectrum to achieve a desired effect.
Approach	For some practically important simulation domains such as a 2-D plane and 3-D rectangular cavity, Laplacian eigenfunctions have closed form expressions, allowing fully analytic simulation.
Approach	In these cases, no mesh is required to store the fluid’s velocity.
Approach	Instead, a velocity can be precisely evaluated at any spatial coordinate without the need for interpolation.
Approach	Furthermore, closed form expressions allow symbolic evaluation of the precomputed advection operator, making this process fast and exact.
Approach	However, our method is not limited to these domains, and we present a formulation on structured and irregular meshes using discrete exterior calculus, in which velocity and vorticity basis fields are eigenvectors of a discrete Laplacian operator.
Approach	Additionally, our method supports the interaction of immersed moving obstacles and buoyancy through projection of forces to the velocity basis fields.
Outcome	Our method allows considerable flexibility in choosing the basis dimensionality.
Outcome	Even simulations with few degrees of freedom provide visually convincing results, avoiding the artifacts common to very low-dimensional representations in Eulerian or Lagrangian simulations.
Outcome	In this respect, our method provides a principled means of dimensionality reduction of the Navier-Stokes fluid equations.
Outcome	However, our method is not data-driven as seen in current model reduction techniques and hence avoids the need for an existing fluid simulator or pre-existing data.
Outcome	We believe our algorithm and choice of basis provides an exciting avenue and will be an important complement to the methods in the literature.
Background	Incompressible fluid dynamics is a vast subject.
Background	We survey some relevant work from geometric mechanics, computational fluid dynamics (CFD) and the computer graphics literature.
Background	Euler’s equations describing the dynamics of a rotating rigid body date from the 18th century.
Background	In 1901, Poincaré [1901] showed that by considering various group manifolds as the configuration space, Euler’s equation could apply generally to a class of physical systems.
Background	For example, in the case of a rotating rigid body the group is the rotation group SO(3).
Background	Arnold [1966] showed that an ideal incompressible fluid is described similarly as geodesic motion on SDiff, the Lie group of volume preserving diffeomorphisms.
Background	The notion of structure coefficients to describe the interaction of Lie algebra basis elements of these groups is directly related to the precomputed coefficient matrices used in our method.
Background	Many of these concepts are summarized by Marsden and Ratiu [1999].
Background	Representing vorticity using Laplacian eigenfunctions dates back at least to Yudovich [1963], who used this method to prove existence and uniqueness theorems for the two dimensional NavierStokes equations.
Background	More recently, Agrachev et al. [2005] used vorticity Laplacian eigenfunctions to prove theorems in the mathematical control literature.
Approach	This paper was our inspiration for investigating a Laplacian eigenfunction representation of vorticity as a practical means of fluid simulation in computer graphics applications.
Background	In the 1950’s, Silberman presented a fluid simulation algorithm for the earth’s atmosphere in a basis of spherical harmonics, which are Laplacian eigenfunctions on the surface of a sphere [Silberman 1954].
Background	This basis was applied to the vorticity stream function fluid equations in two dimensions, and the advection operator was evaluated symbolically.
Background	This method has come to be known in the CFD literature as the interaction coefficient method.
Background	Outside of atmospheric sciences, it is not widely used due to poor scaling for large basis dimensionality.
Background	Such performance considerations were the motivation for the development of spectral methods as pioneered by Orszag [Orszag 1969].
Background	Spectral methods are characterized by the use of a fast transform allowing efficient calculation of advection in the spatial domain, thereby avoiding convolution sums in the spectral domain.
Background	They are often used to study homogeneous turbulence [Orszag and Patterson 1972; Rogallo et al. 1981].
Background	Fourier series or Chebyshev polynomials are commonly employed, as spectral methods are limited to bases admitting a fast transform.
Approach	Our method is most analogous to the interaction coefficient method of [Silberman 1954], although we consider arbitrary domains.
Background	On arbitrary domains, Laplacian eigenfunctions do not in general admit a fast transform and hence do not share the inherent theoretical performance of a spectral method.
Background	However, Laplacian eigenfunctions have many other benefits as we describe in Section 3.
Background	Furthermore, theoretical performance scaling is less critical for the applications we consider and we show that visually detailed simulations are attainable at low cost.
Background	Divergence free finite element methods (DFFEM) employ bases of discrete divergence free velocity fields to solve fluid equations in a space that satisfies mass continuity a priori [Gustafson and Hartman 1983].
Approach	Our method is similar in this respect.
Background	However, in contrast to DFFEM, for some simple domains Laplacian eigenfunctions do not require a discrete mesh.
Background	Also, to our knowledge no basis employed in DFFEM exhibits all of the advantageous proper- ties of Laplacian eigenfunctions, including orthogonality, stationarity with respect to Navier-Stokes equations, global support, and correspondence with spatial scales of vorticity.
Background	Fluid simulation methods in the computer graphics literature belong to roughly four categories: grid-based, mass particles, vortex elements and model reduction.
Background	Grid-based techniques for simulating the 3-D Navier-Stokes equations were introduced by Foster and Metaxas [1996] but were unstable due to the use of explicit integrators.
Background	Stam developed an unconditionally stable integration scheme using semi-Lagrangian advection and an implicit integrator [Stam 1999].
Background	However, the result produces artificial viscosity which dampens vortices prematurely, and requires an iterative linear solver to solve for a pressure field to enforce incompressibility.
Background	Works aimed at mitigating or minimizing artificial diffusion include vorticity confinement [Fedkiw et al. 2001] and high order advection schemes [Selle et al. 2008].
Background	To improve the performance of the iterative pressure solver, use of adaptive grids [Losasso et al. 2004] and hierarchical coarse grids for projection [Lentine et al. 2010] have been proposed.
Background	Stam [2002] used the 2-D Fourier transform of a velocity field to perform fast pressure projection, but this method is limited to simple domains and boundary conditions, and still dissipates energy.
Background	Bridson presented a simple means to generate procedural divergence free flows through the curl of a vector potential stream function [Bridson et al. 2007] but this work did not address physical dynamics.
Background	Elcott presented a method that preserves circulation on simplicial meshes, but does not preserve energy [Elcott et al. 2007].
Background	Mullen et al. developed a fluid integrator capable of perfect energy preservation or desired viscosity independent of grid-resolution [Mullen et al. 2009], but this method is complex and requires a solution to a non-linear system at each timestep.
Background	Hybrid particle-grid methods such as FLIP [Zhu and Bridson 2005] are effective in eliminating numerical diffusion, but still require a grid to enforce incompressibility.
Background	Common to all these stable grid-based techniques previously mentioned is the need to solve a system of equations at each time integration step, the size of which is proportional to the number of grid elements.
Approach	In contrast, the performance of our method is independent of the domain or grid resolution.
Approach	In fact, for typical domains such as a 2-D rectangle or 3-D rectangular cavity, the global basis functions we employ have closed form expressions, removing the need for a velocity grid representation entirely.
Approach	Our method allows controllable viscosity, and supports general domains through a formulation on discrete meshes.
Background	Particle methods track a fluid’s mass through Lagrangian elements.
Background	Smoothed particle hydrodynamics (SPH) was introduced to graphics by Desbrun and Gascuel [1996] and used subsequently to simulate water [Müller et al. 2003; Adams et al. 2007].
Background	Enforcing incompressibility in SPH methods is computationally expensive, making them impractical for a large number of particles.
Approach	Our method satisfies incompressibility automatically as it operates directly in a space of divergence free fields.
Background	Vortex methods use Lagrangian elements such as particles or filaments to track vorticity, and advect these elements through the fluid’s velocity [Gamito et al. 1995; Park and Kim 2005; Angelidis et al. 2006; Weißmann and Pinkall 2010].
Background	A formulation using vorticity guarantees incompressibility, but the reconstruction of the velocity field is computationally expensive, typically involving the Biot-Savart formula.
Approach	We also use a vorticity formulation, hence requiring no explicit enforcement of the incompressibility constraint.
Approach	However, we use a superposition of global basis functions allowing the representation of arbitrary vorticity fields, whereas Lagrangian elements are limited to vorticity concentrated at points or on curves.
Approach	Additionally, choosing Laplacian eigenfunctions as a basis allows the velocity field to be recovered trivially, removing the need for complicated and expensive reconstruction.
Background	Gupta and Narasimhan represented fluid velocity in a basis of Legendre polynomials allowing analytic evaluation of differential operators [Gupta and Narasimhan 2007].
Background	However, only boxboundary conditions were considered and the velocity basis fields are not strictly divergence free hence requiring a pressure projection step to enforce incompressibility.
Background	Model reduction has been applied to fluid simulation by Treuille et al. [2006].
Background	This technique chooses a reduced velocity basis defined on a mesh through observation of an existing fluid simulator.
Background	The resulting run-time performance is fast, but the precomputation time and memory requirements are large.
Background	Furthermore, it is unclear how well this technique generalizes to arbitrary flows, as behavior is limited to the examples present in training.
Approach	Our method can be used directly as a means of dimensionality reduction through choice of the basis dimension N , but it differs from current approaches in many respects.
Approach	We choose an appropriate velocity basis a priori instead of relying on observation of an existing fluid simulator.
Background	Up to a desired scale of vorticity, Laplacian eigenfunctions form a complete basis for divergence free fields.
Background	Adding basis functions increases the coverage in a well defined way.
Background	In contrast, a data driven basis can only approximate flows that are in some sense “close” to those observed in training, and there is no guarantee that additional training data will substantially increase the span of the resulting PCA basis.
Approach	Our basis has a natural correspondence with spatial scales of vorticity that is lacking in [Treuille et al. 2006].
Background	Finally, Laplacian eigenfunctions have closed form expressions for some simple domains, in which case the precomputation time and memory requirements are vastly reduced in comparison.
Approach	When acting on divergence free fields, the vector Laplacian reduces to ∆ = −curl 2 .
Approach	The eigenfunctions of the Laplacian operator ∆ are domain dependent.
Approach	The vector fields Φ k are Laplacian eigenfunctions with eigenvalues λ k = −(k 1 2 + k 2 2 ).
Approach	We will continue to use the square domain as a concrete, illustrative example throughout the text, although closed form expressions also exist for many other domains including a 3-D rectangular prism [de Witt 2010], a disc, the surface of a sphere, or a planar region with a wrap around boundary condition.
Approach	For our simulation method, we also require the vorticity field ω = curl (u) and a vorticity basis {φ k } with φ k = curl Φ k .
Approach	One can verify that the φ k are also Laplacian eigenfunctions of the domain.
Approach	However, as u and ω are orthogonal, the vorticity basis functions have only a normal component at the boundary, and hence satisfy ∆φ k = λ k φ k
Approach	We summarize some additional interesting and useful properties of our basis.
Background	In general, reconstructing a velocity field from a vorticity field is computationally expensive, typically involving the use of the Biot-Savart Law [Angelidis et al. 2006; Weißmann and Pinkall 2010].
Approach	A further important observation is that due to linearity of the curl operator, the expansion of the vorticity ω in the φ i basis shares the same coefficients as the expansion of the velocity u in the Φ k basis          N N N ω = curl u = curl ω i Φ i = ω i curl Φ i = ω i φ i .
Approach	i i i          This is notable since a single coefficient vector w = [ω 1 ω 2 . . . ω N ] uniquely identifies both the fluid’s velocity u and its vorticity ω.
Approach	Either field can be easily reconstructed from the basis coefficients ω i .
Approach	Laplacian eigenfunctions on a domain form an orthogonal set.
Approach	The total energy of a signal expressed in an orthogonal basis is the sum of the squares of its coefficients by Parseval’s identity.
Approach	As shown in Figure 4 , larger eigenvalues of the Laplacian correspond to fields with smaller vortices.
Approach	Basis coefficients can be interpreted as a discrete spatial spectrum of the fluid with higher “frequencies” corresponding to smaller scales of vorticity.
Background	This notion has been previously applied by Stam and Fiume using a Fourier basis to generate procedural stochastic turbulence [Stam and Fiume 1993].
Approach	A decomposition into a spectrum of vorticity is important for at least two reasons.
Approach	First, because computations require our basis to be finite, this ordered structure provides a principle by which to select the finite set.
Approach	In choosing to truncate the spectrum at some finite N , the error we incur is well defined: we lose the ability to simulate vortices smaller than a given scale.
Approach	Second, combined with orthogonality, our basis delivers a means of controlling the energy at different scales of vorticity by adjusting the magnitude of the basis coefficients.
Approach	We use this property in Section 4 to accurately model viscous energy decay.
Approach	It could also be used to initialize or arbitrarily change a fluid’s turbulent spectrum.
Approach	For some simple domains, the basis fields have closed form expressions.
Approach	This allows the velocity to be evaluated at any spatial coordinate without the need for a voxelized grid or interpolation.
Approach	A grid may still be used for visualization, for example to track density or subsample the velocity from the closed form expressions to accelerate particle advection.
Approach	However, this grid is independent of the simulation, and its resolution may be changed without changing the performance or behavior of the underling simulation.
Approach	Although the benefits of closed form expressions are limited to simple geometries, a 2-D rectangle and 3D rectangular cavity both represent typical simulation domains.
Background	A fluid’s velocity field will change continuously over time according to physical laws.
Approach	In our basis representation, this can be described by the continuous change of the coefficient vector w.
Approach	For notational convenience, we choose Adv(·, ·) to represent the advection term, which is defined as Adv(u, ω) := curl (ω × u).
Approach	The Adv(Φ i , φ j ) terms represent the nonlinear advection of basis fields.
Approach	As will be detailed in Section 6, we precompute these terms and the vorticity basis coefficients of the result are stored in a set of matrices C k .
Approach	Because φ k are Laplacian eigenfunctions, the viscous term becomes ν i ∆ω k φ k = ν k λ k ω k φ k .
Approach	The effect of viscosity on each basis coefficient is hence described by the linear first order differential equation ω  ̇ k = νλ k ω k which conveniently has the closed form solution ω  ̇ k (t) = ω k (0)e νλ k t .
Approach	This says that the magnitude of each basis coefficient decays with a time constant equal to the eigenvalue, which is physically correct, as small vortices dissipate faster than large vortices.
Approach	The contribution to ω  ̇ k is then ω  ̇ k = f k .
Background	However, for computer graphics applications speed and energy stability are important requirements.
Approach	We first describe our preferred integration scheme that meets these two requirements, and then discuss other available techniques.
Approach	Our basis is orthogonal allowing kinetic energy to be calculated as a sum of squared coefficients.
Approach	Additionally, orthogonality implies that surfaces of constant energy in the Euclidean space of coefficients are spheres.
Approach	An inviscid fluid preserves kinetic energy, and should trace out a path on such a sphere.
Approach	We choose a fast explicit integrator (such as forward Euler or Runge-Kutta method) to first perform an unconstrained timestep, followed by renormalization to enforce the energy constraint as depicted in Figure 6 .
Background	Renormalizing to preserve the kinetic energy is a technique available in any fluid simulation method and is not particular to our approach.
Background	However, when employing grid based velocity fields it is often undesirable as it can lead to visual artifacts.
Approach	We have not observed such artifacts, possibly because our basis fields are globally supported and energy is never dissipated locally through a pressure projection step as for example in [Stam 1999].
Approach	The effect of viscosity and projected forces will change the kinetic energy, so these terms are integrated following the energy renormalization.
Approach	Physical viscosity is achieved by decaying each coefficient exponentially as described in Section 4.
Approach	Computation is dominated by the evaluation of matrix vector products, making the run time complexity O(z), where z is the total number of non-zero entries in all the {C k } combined.
Approach	In general, {C k } are dense and z is O(N 3 ), leading to a computational complexity similar to that of [Treuille et al. 2006].
Approach	Differentiating this expression produces closed form expressions for time derivatives of arbitrary order.
Approach	These can be useful for alternate integration schemes to improve accuracy or allow time reversibility.
Approach	However, considering that stability has already been enforced it may not be a concern for graphics applications.
Approach	Greater accuracy could also be easily achieved through high order explicit schemes using a small timestep.
Approach	A final integration scheme that is theoretically interesting involves the calculation of an N dimensional rotation matrix R, which, when applied to the coefficient vector w, constrains its motion exactly to the constant energy N -sphere.
Approach	This approximates the true geodesic motion of the Euler fluid equations near the current state.
Approach	The position vector ω and the tangent vector ω  ̇ span an N −1 dimensional rotation plane that uniquely identifies an N ×N skew symmetric matrix ξ.
Approach	This matrix g is an element of so(N ), the Lie algebra of the N -dimensional rotation group SO(N ).
Approach	Multiplying by ∆t and exponentiating the matrix yields the N × N rotation matrix R = exp(∆tξ).
Approach	This method is more expensive than explicit integration with renormalization, and we have found that in comparison it offers very little gain in accuracy for small timesteps.
Approach	However, it is of interest because it preserves the geometric viewpoint of a fluid as a high dimensional rotation group, and provides a more rigorous way of enforcing energy preservation compared to the renormalization correction step.
Approach	The operator Adv(u, ω) := curl (ω × u) represents the advection of a fluid’s vorticity by its velocity field.
Approach	It has many equivalent expressions, including the the Lie derivative L u ω, or the JacobiLie bracket of vector fields −[u, ω], Adv(Φ i , φ j ) := L Φ i φ j = −[Φ i , φ j ] = curl (φ j × Φ i ).
Approach	In our context, all the preceding expressions are equivalent, and any can be used to evaluate the advection of pairs of basis fields.
Approach	For discrete domains, it can be approximated numerically on a mesh as described in Section 8.
Approach	For every pair of basis functions we evaluate the advection operator and express the result in the finite φ k basis.
Approach	The basis coefficients of this projection are the structure coefficients that form the {C k } matrices and satisfy Adv(Φ i , φ j ) = C k [i, j]φ k .
Approach	k The Laplacian eigenfunction basis is closed under the Jacobi-Lie bracket.
Approach	Hence, we expect the result to factor perfectly into a linear combination of vorticity basis functions.
Approach	For simulation, our basis must necessarily be finite dimensional.
Approach	Despite closure, the advection operator may produce coefficients beyond the chosen finite bandlimit N which cannot be stored.
Approach	This is unavoidable, as the nonlinear advection operator necessitates products of functions.
Approach	Considering for example the Fourier basis, the multiplication of two N bandlimited functions is in general bandlimited by 2N .
Approach	Physically this represents the cascading of energy to ever higher scales of turbulence.
Approach	Projecting the result of the advection operator to our finite dimensional basis amounts to truncating the coefficients beyond the bandlimit N .
Approach	However, this truncation is physically motivated, since in a real fluid the vortices will eventually reach a small enough scale and dissipate quickly through viscosity.
Approach	A pseudo-code listing of the precomputation procedure is shown in Algorithm 2.
Approach	Because the Jacobi-Lie bracket and vector cross product are anti-symmetric operators, the structure coefficient matrices have the property 1 1 C k [i, j] = − C k [j, i].
Approach	λ i λ j The antisymmetry reflects an important property of the our basis functions.
Approach	The self advection Adv(Φ k , φ k ) of a vorticity basis field φ k by its velocity Φ k is identically zero, and hence u  ̇ = 0, meaning that each velocity basis field is a stationary flow.
Approach	This is analogous to the stable rotation of a rigid body about a principal axis [Arnold 1966].
Approach	To illustrate the preceding discussion, the evaluation of the structure coefficients in closed form for a 2-D rectangle is provided in Appendix A as an example.
Approach	As discussed in Section 4, external forces can be incorporated by projecting f to the velocity basis basis f i = f , Φ i .
Approach	The inner product for vector valued f and Φ i is defined by the summation of dot product of vectors at every point x within the domain f , Φ i = f (x) · Φ i (x).
Approach	x We make use of external forces to allow immersed moving obstacles and to incorporate a simple buoyancy model.
Approach	The eigenfunctions of the Laplacian operator are defined by their domain and boundary conditions, making the velocity and vorticity basis fields domain dependent.
Approach	Static irregular boundaries and obstacles are supported in our method through precomputation on general meshes as will be discussed in Section 8.
Approach	However, moving obstacles change the shape and boundary conditions of the domain dynamically, and hence require special consideration.
Approach	Our goal is to satisfy the internal boundary conditions of immersed objects at all times.
Approach	This requirement can be simply stated: in addition to remaining divergence free, the fluid velocity at an object’s boundary should be equal to the normal component of the boundary’s velocity.
Approach	This satisfies the free-slip condition when the object is at rest, and equates normal components of the fluid and boundary velocity when the object is in motion.
Approach	Our solution is as follows.
Approach	At each time-step we project the difference from the desired normal component onto the velocity basis Φ k and subtract the result from the current state vector w.
Approach	The result is a divergence free field that best satisfies the desired boundary conditions.
Approach	Note that this method is not perfect, as the projected forces only approximate the desired forces to the extent that the basis fields can resolve them.
Approach	In other words, to handle obstacles with small spatial features, one must increase N to use basis functions of a sufficiently high spatial frequency.
Outcome	However, for coarse objects, we have found this method to provide reasonable accuracy, and it is efficient enough to perform interactively without requiring precomputation.
Background	Treuille et al. [2006] also correct the normal velocity component through projection to a divergence free field, and our technique is similar in this respect.
Background	However, in their case an additional set of fields they name the boundary basis are employed that are chosen based on the object’s geometry to best correct for normal velocity components.
Background	The boundary basis allows the free-slip constraint to be more accurately enforced in the vicinity of the boundary, but adds substantially to memory and precomputation expense.
Background	It also does nothing to improve the quality of object-fluid interaction since the underlying simulation basis, to which the boundary basis must be numerically projected, remains unchanged.
Approach	In contrast, our basis fields exhibit a spectrum of spatial scales (akin to a Fourier Series) allowing some guarantee of resolving obstacle features with similar length scales.
Approach	Although our method does not perfectly resolve the boundary, it avoids the use of multiple bases for simulation and boundaries as well as the associated expensive precomputation and memory requirements.
Approach	In some of our examples we incorporate a simple buoyancy model.
Approach	Smoke density or particle density are subsampled onto a grid.
Approach	Buoyancy forces at each grid centre are calculated through the Boussinesq approximation.
Approach	These forces are projected to the velocity basis through pointwise multiplication.
Background	Simple geometries admit basis fields with closed form expressions.
Approach	However, our method also supports discrete domains defined on a mesh.
Approach	For this, we require a set of basis fields defined on the mesh that are eigenfunctions of a discrete Laplacian operator, as well as a means to precompute their advection numerically.
Background	Discrete exterior calculus (DEC) provides a principled means of describing operators and quantities on simplicial meshes [Desbrun et al. 2005].
Background	It has been applied to fluid simulation in previous work, and we use a discrete formulation on tetrahedral meshes analogous to [Mullen et al. 2009; Elcott et al. 2007].
Approach	Regular voxel meshes are also supported as a special case of this discretization.
Approach	Through DEC we define the discrete Laplacian operator ∆ = −curl 2 = −d ∗ d∗ which has a representation as a sparse, symmetric matrix.
Approach	We compute the eigendecomposition of this matrix to produce the discrete velocity and vorticity basis fields.
Approach	The velocity basis fields satisfy a free slip boundary condition and are divergence free, due to constraints imposed implicitly through the Laplacian operator matrix.
Approach	For example, to enforce a free-slip velocity boundary condition, we omit (set to zero) the rows of the discrete Laplacian ∆ that calculate velocity flux on boundary faces.
Approach	Defined as above, ∆ admits only divergence free solutions in its eigendecomposition.
Approach	Examples of basis fields for a tetrahedral mesh are shown in Figure 9 .
Approach	We also employ DEC to approximate the advection operator Adv(·, ·) using appropriate discretizations.
Approach	This evaluation is similar to that employed in [Mullen et al. 2009].
Approach	Other than the discrete representation and computations described above, the rest of our fluid simulation method remains the same.
Approach	The operation and performance of the time integration scheme described in Section 5 does not change, since it operates only with the basis coefficients.
Approach	However, additional expenses in the case of meshed domains include the storage of discrete basis fields, and the reconstruction of the velocity field through summation.
Outcome	As we show in Section 9, these costs are reasonable for typical operating parameters, but can become large for simulations employing very fine meshes and large basis dimensionality.
Approach	All experiments were performed on a single CPU core.
Approach	Time integration was performed using an explicit fourth order Runge Kutta method.
Outcome	Closed form domains are limited in their boundaries, but have notable advantages in terms of runtimes, precomputation and memory requirements.
Outcome	For examples including external forces (such as buoyancy or moving obstacles), the cost of projecting the forces on to the basis is noted.
Outcome	This cost is proportional to the mesh resolution and the number of basis fields.
Approach	In the case of the bunny, a subsampled 16 3 density grid is used for the buoyancy force calculations.
Approach	For discrete meshes, velocity field reconstruction requires summation of stored basis fields.
Approach	This is proportional to the mesh resolution and the dimension of the basis.
Approach	On closed form domains, there are two alternatives for velocity reconstruction.
Approach	The basis fields may be pre-evaluated on a mesh and stored, just as in the discrete case.
Approach	Alternatively, they may be computed on demand.
Approach	Closed form evaluation is proportional to the number of basis functions and the number of advected quantities.
Outcome	Each alternative has its strengths.
Outcome	Caching the basis fields uses memory, but saves computation when many quantities are being advected through the field (density or millions of particles).
Outcome	If only a few particles need to be advected (leaves in wind, for example), then evaluating closed form expressions is accurate and fast and does not have additional memory requirements.
Outcome	A comparison to the stable fluids algorithm is included as a rough qualitative validation.
Outcome	We demonstrate flow on some simple tetrahedral meshes; however we chose a structured voxelized grid for the bunny example only to facilitate implementation.
Outcome	A robust tetrahedral mesh implementation would have similar performance characteristics and alleviate the boundary “stair case” artifacts.
Outcome	The effects of basis dimensionality are illustrated through the bunny example.
Outcome	Modes with small eigenvalue capture the low frequency motion of the fluid.
Outcome	Notably, the bunny’s ears do not begin to be resolved until after the 64th mode.
Approach	In addition to using the bottom of the spectrum to capture the large scale motion, one may choose additional modes from much higher parts of the spectrum to incorporate smaller scales.
Outcome	This demonstrates the benefit of a basis that exhibits a spectrum of scales.
Outcome	Note that these high frequency modes interact and decay physically, in contrast to other post-processing turbulence models.
Outcome	Our method is most applicable to gaseous phenomena and situations when the domain is entirely filled by fluid.
Outcome	Currently it is not readily adaptable to typical liquid simulations that require a constantly changing fluid domain with a free surface.
Outcome	We have shown that interesting dynamics can be captured in a reasonably sized basis dimension and simulated interactively.
Outcome	However, various issues prevent it from scaling well to very large basis dimension or grid resolutions.
Outcome	For irregular domains, the runtime is in general O(N 3 ).
Outcome	For discrete meshes, the cost of reconstructing the velocity field and projecting external forces grows linearly with the basis dimension and mesh resolution.
Outcome	Many of these issues are not present for domains with closed form expressions.
Outcome	However, in this case the shape of the boundary is limited.
Outcome	Also, when advecting many particles or projecting many forces the velocity basis fields must still be cached as the cost of closed form evaluations become prohibitive.
Outcome	We believe our method has potential to be exploited for the expressive control of fluid phenomena.
Outcome	We have shown how to continuously change the basis coefficients to simulate the physical motion of a fluid.
Outcome	However, any smooth curve through coefficient space, physical or not, may be perceived as “fluid-like” as it represents a continuously changing volume preserving flow that respects all boundary conditions.
Outcome	In addition to constructing completely arbitrary flows, perturbing existing physical paths offers a means to deviate from physics while quantifying this deviation.
Outcome	Due to orthogonality of the basis and its correspondence with vorticity of varying scales, we have a unique mechanism for spectral energy control.
FutureWork	This could be used to implement timevarying filters to amplify or attenuate parts of the spectrum, such as achieving crescendos of turbulence or gradual calming.
Outcome	Again, we have a means of quantifying the deviation from non-physical energy behavior, as we have shown how to decay the spectrum according to physical viscosity.
Background	Space-time control for fluids has been attempted previously in [Treuille et al. 2003; McNamara et al. 2004; Fattal and Lischinski 2004].
Background	Many of these methods can be expensive because the optimization scales sharply with the size of the grid, making them impractical for interesting domains.
Background	A low dimensional basis offers a good setting to implement control policies that would be intractable in higher dimensions as demonstrated for example by Barbi c et al. [Barbi c et al. 2009].
FutureWork	Our method’s availability of closed form expressions for time derivatives could also prove useful in optimization algorithms.
Outcome	Our method is fast enough to be interactive, and is very memory efficient and well formulated on rectangular domains due to the available closed form expressions.
FutureWork	This makes it particularly attractive for use in image based settings such as painting applications that simulate fluid phenomena, as we briefly demonstrate in the video.
FutureWork	Additional potential uses in this vein include texture synthesis and non-photorealistic rendering.
FutureWork	Boundaries of moving obstacles are handled only approximately and could benefit from alternate methods.
FutureWork	We have presented a fast and stable integration scheme; however, additional time integrators could be explored, particularly symmetric integrators to allow time reversibility as was achieved in [Mullen et al. 2009].
FutureWork	Time reversibility could prove useful in fluid control applications, as was demonstrated for rigid bodies by Twigg and James [2008].
Outcome	We have evaluated the advection operator symbolically for closed form expressions on rectangular 2-D and 3-D domains.
FutureWork	The same could be done for additional geometries, such as a 2-D disk or a spherical surface.
FutureWork	Also, different boundary conditions (for example, a wrap-around boundary condition) remain to be considered, which could prove useful for tilings of fluid simulation domains [Wicke et al. 2009].
Outcome	Divergence free fields have many potential uses besides simulating natural phenomena.
Background	Fluid motion describes the optimal transport in an incompressible medium, and can be used to quantify volume preserving deformations.
Outcome	This has uses in image analysis and shape deformation.
FutureWork	We plan to consider how the unique properties of our method could be exploited in these fields.
FutureWork	In particular, the elegant formulation on rectangular domains could make it useful for medical image registration.
FutureWork	Additionally, the availability of closed form expressions and flexibility in choosing the basis dimension make it an accurate and tractable model for optimization methods.
FutureWork	This could be useful for the inverse modelling of real fluid flows for the purpose of parameter estimation, for example to estimate viscosity from sampled velocity measurements.
Outcome	We have presented a fluid simulation method that uses eigenfunctions of the vector Laplacian as bases.
Outcome	We have described many of its unique properties and its use as a practical means of fluid simulation for computer graphics.
Outcome	The orthogonality of the basis functions and their correspondence to a spectrum of vorticity scales enables energy control at varying turbulent scales.
Outcome	We have used this property to enforce stability of integrators and simulate physical viscosity.
Outcome	Flexibility in choosing basis dimensionality and the ability to integrate directly in a space of basis coefficients permits computational efficiency, enabling interactive performance.
Outcome	The existence of closed form solutions for simple domains allows symbolic evaluation of the advection operator and the ability to sparsely evaluate velocities on demand.
Outcome	We have demonstrated some of the useful properties of our method, but many exciting avenues remain to be explored.
FutureWork	We plan to investigate its use for the the expressive control of fluid motion, such as spectral energy control and space time optimization.
FutureWork	We also believe there is potential for our method to be exploited in other research areas such as medical imaging and inverse flow modelling.
Approach	We evaluate Adv(Φ i , φ j ) = curl (φ j × Φ i ) recalling that i, j are vector wave numbers i = (i 1 , i 2 ), j = (j 1 , j 2 ) and the eigenvalues λ i = −(i 2 1 + i 2 2 ).
Approach	This simplifies to 1 Adv(Φ i , φ j ) = i 1 j 2 cos(i 1 x) cos(j 2 y) sin(j 1 x) sin(i 2 y) λ i 1 − i 2 j 1 cos(j 1 x) cos(i 2 y) sin(i 1 x) sin(j 2 y) a z .
Approach	The resulting coefficients are stored in the {C k } matrices 1 C i 1 +j 1 ,i 2 +j 2 [i, j] = − 4(i 1 2 + i 2 2 ) (i 1 j 2 − i 2 j 1 ) 1 C i 1 +j 1 ,i 2 −j 2 [i, j] = 4(i 1 2 + i 2 2 ) (i 1 j 2 + i 2 j 1 ) 1 C i 1 −j 1 ,i 2 +j 2 [i, j] = − 4(i 1 2 + i 2 2 ) (i 1 j 2 + i 2 j 1 ) 1 C i 1 −j 1 ,i 2 −j 2 [i, j] = 4(i 1 2 − i 2 2 ) (i 1 j 2 − i 2 j 1 ).
Approach	This result demonstrates closure of the advection operator.
Approach	The indices i, j are meant figuratively, as they represent tuples of integers.
Approach	A suitable re-mapping from (i 1 , i 2 ) and (j 1 , j 2 ) to positive integers is necessary in an implementation.
Approach	When outside of the storable finite range, they are discarded as described previously.
Approach	Note the sums of indices i 1 + j 1 and i 2 + j 2 , which reflect the doubling in bandlimit due to multiplication of sinusoidal functions.

Outcome	We present a method that allows such a mapping to be defined by example, given that the control specification is recorded motion.
Approach	Our method begins by building a database of semantically meaningful instances of the mapping, each of which is represented by synchronized segments of control and target motion.
Approach	A dynamic programming algorithm can then be used to interpret an input control specification in terms of mapping instances.
Approach	This interpretation induces a sequence of target segments from the database, which is concatenated to create the appropriate target motion.
Approach	We evaluate our method on two examples of indirect control.
Approach	In the first, we synthesize a walking human character that follows a sampled trajectory.
Approach	In the second, we generate a synthetic partner for a dancer whose motion is acquired through motion capture.
Challenge	Authoring human motion is difficult for computer animators, as humans are exceptionally sensitive to the slightest of errors.
Challenge	This process involves an animator providing a control specification which is mapped to a target motion by some means.
Background	In traditional keyframe animation, for instance, the keyframes are the control specification, and the target motion is achieved through spline interpolation.
Background	Due to advances in data acquisition technology and computational power, techniques have been developed that allow desired target motion to be specified using a human performance.
Background	This is natural for traditional keyframe animators, who often use recorded or live human motion for reference.
Background	Motion capture is the most direct method to map performances to animated humans, as it is essentially an identity mapping.
Background	However, a generalization of this approach to allow for more indirect mappings creates an array of fantastic possibilities, such as mapping voice signals to facial motion [Bra99] or gestural actions to animated reactions [JP99].
Challenge	Indirect mappings, however, must still be encoded in some way.
Challenge	Manually, this can be an exceptionally challenging task requiring detailed, domain-specific knowledge.
Challenge	Consider a partner dance scenario in which an animator wishes to con-      trol a follower using the captured motion of a leader.
Challenge	The mapping from leader to follower motion must minimally encode a significant amount of knowledge about the structure of the dance; this knowledge, unfortunately, would be out of reach to an animator who is not a skilled dancer.
Challenge	Indeed, it would still be difficult for a skilled dancer to state the precise mapping.
Challenge	Human dancers learn their skills by observation and practice; our objective is to emulate this process on a computer for situations, such as partner dance, when the control specification takes the form of one dancer’s motion.
Approach	To learn indirect mappings, we adopt a memory-based approach which implicitly encodes the desired mapping using a database of semantically meaningful example instances.
Approach	These instances store segments of synchronized control and target motion, which provide examples of how the mapping should be applied to input control motions.
Approach	In partner dance, an instance might contain an example control motion of a leader pushing his or her partner forward.
Approach	The corresponding example target motion would be that of the follower, taking a step backward in response.
Approach	A new input control motion can be interpreted as a sequence of rigidly transformed and temporally stretched control segments from the mapping database.
Approach	Through the mapping instances, a given interpretation also corresponds to a sequence of target segments that can be assembled to form a target motion.
Approach	We use dynamic programming to select a sequence that balances the quality of interpretation with the continuity of the induced target motion.
Approach	Various postprocessing techniques can be then be applied to smooth and adjust the desired target motion.
Approach	Our approach is evaluated on two applications.
Outcome	In the first, we demonstrate its ability to map low-dimensional input to high-dimensional motion by controlling walk motion from mouse trajectories.
Outcome	In the second, we highlight our method’s capability to handle complex, stylized mappings by controlling a dance follower with the motion of a dance leader.
Background	Performance-driven animation, or computer puppetry, derives its broad appeal from its ability to map human performances automatically to animated characters [Stu98].
Background	While these mappings can be as simple as a direct copy of joint angles, the ability to discover more complex mappings gives the approach a tremendous amount of power and flexibility.
Background	In online techniques [JP99], computational speed and instantaneous results are of paramount importance; offline techniques [Bra99] allow quality and global optimality to take precedence.
Approach	Our method falls into the latter category.
Background	Complex mappings often defy purely physical or mathematical encodings.
Background	As a result, many methods assume that mappings are described by parametric probabilistic models [Bra99, DB01, DYP03, JP99].
Background	An advantage of these techniques is their ability to generalize to a variety of inputs.
Challenge	However, this comes at a price: statistical learning often necessitates large volumes of training data or severe restrictions on model complexity.
Challenge	For certain applications, this is a worthwhile tradeoff, but for others, it can result in impractically long training times or loss of important detail.
Approach	A memory-based approach like ours does not suffer from these disadvantages.
Approach	An important benefit of this design choice is the ability to use segments, rather than frames, as the primitive unit of motion.
Approach	This allows for explicit preservation of higherlevel motion semantics.
Background	Kim et al. demonstrate that a semantically guided segmentation of rhythmic motion allows for highly realistic motion synthesis, even using simple transition models [KPS03].
Background	Although this work, like ours, uses partner dance for evaluation, it does not address the problem of generating a follower given the motion of a leader.
Approach	In the segment modeling domain, we consider our method most similar to that of Pullen and Bregler [PB02].
Background	While Pullen and Bregler’s method was shown to be an effective solution for the chosen application of texturing keyframed motion, its applicability to our problem is limited by several factors.
Background	First, their method assumes no spatial dependencies between the control (keyframed curves) and the target (textured motion).
Background	Second, there is no enforcement of motion continuity, other than a heuristic for consecutively observed segments.
Approach	Our approach generates target motion segments that are amenable to simple blending.
Background	Finally, their method assumes that the input motion can be presegmented analogously to the examples, which is achieved in their work by observing sign changes in velocity.
Background	One could extend this approach for rhythmic motions using the automated approach of Kim et al. [ KPS03 ].
Challenge	In the general case, however, a control motion may not admit any intuitive presegmentation.
Challenge	One may wish, for instance, to generate walk motion from a constant-velocity trajectory.
Approach	Our method requires no presegmentation; moreover, it produces a semantically guided segmentation as part of the optimization.
Approach	In this context, our algorithm could be viewed as an extension of speech recognition methods that use connected word models [ RJ93 ].
Background	Arikan et al. describe an example-based approach to synthesizing human motion that satisfies sparse temporal annotation and pose constraints [ AFO03 ].
Background	Although their work differs from ours in intent, they also employ a dynamic programming algorithm that optimizes a weighted combination of interpretation and motion continuity.
Approach	Our formulation differs in two subtle but important ways.
Approach	First, our notion of continuity is dependent on the interpretation; that is, the continuity between two motion segments is undefined until a candidate interpretation specifies a coordinate frame for comparison.
Background	Second, their objective function is defined over frames instead of segments.
Background	As a result, they must use coarse-to-fine iterations of their dynamic programming algorithm to gain the temporal consistency that is intrinsic to our segment-based approach.
Background	Other related methods based on motion capture clip rearrangement include work by Kovar et al. [ KGP02 ], Lee et al. [ LCR ∗ 02 ], and Arikan and Forsyth [ AF02 ].
Background	Although these do not aim to discover control by example, they have nevertheless provided inspiration for our work.
Background	An additional distinction is that these methods do not use continuous control from human performance and focus on sparser specifications such as keyframes and nontemporal paths.
Approach	Our method is not designed to handle such control specifications and therefore should be viewed as an alternative to these approaches, rather than a replacement.
Background	Many motion rearrangement techniques are derived from previous work in texture synthesis.
Approach	Here, we consider our work most similar in intent to image analogies [ HJO ∗ 01 ].
Background	This method, given an unfiltered and filtered version of the same image, applies an analogous filter to a novel image.
Approach	Our method, given a set of synchronized control and target motions, applies an analogous mapping to a new input control motion.
Background	Image analogies was shown to be an elegant method with applications such as texture transfer, textureby-numbers, and super-resolution.
Challenge	It is our hope that our method will have the same versatility for motion.
Outcome	Our dance evaluation suggests an alternative view of our method as one of interaction modeling.
Background	In this domain, tech- niques have been developed that specify the mappings between character motions with explicit models of character interaction.
Background	Adaptive autonomous characters have used rules to exhibit complex flocking, herding, and locomotory behaviors [Rey87, TT94].
Background	Approaches to explicit interaction modeling have included layered architectures [BG95], procedural descriptions [PG96], and even cognitive models [FTT99].
Outcome	In this context, our work might be viewed as a competency module that enhances the skills of characters to enable their participation in complex interactive performances.
Approach	For human motion, we use skeletal joint positions, since this representation provides a more intuitive space than joint angle representations for comparing poses [KGP02].
Approach	Furthermore, point cloud representations allow for generalization to control motions without skeletal representations, such as mouse input.
Approach	The examples are divided into control segments a 1 , . . . , a N and target segments b 1 , . . . , b N , where a i and b i are synchronized motions that together represent a primitive semantic instance of the mapping.
Approach	Our dance motions are segmented into two-beat rhythm units, since they are a basic unit of interaction for the specific type of dance (Lindy Hop), as shown in Figure 1 .
Approach	Our walk motions, on the other hand, are segmented according to gait cycles.
Approach	In both cases, we use manual transcription, since each example motion must only be segmented once.
Approach	Methods exist to automate this process if desired.
Approach	Dance motion could be segmented using motion beat analysis [KPS03].
Approach	More general motions could be segmented using annotation [AFO03] or curve clustering [CGMS03].
Approach	Given a control motion x with T frames, our goal is to generate an appropriate target motion.
Approach	This is achieved by selecting a sequence of appropriate target segments from the database.
Approach	To make the database motions more flexible, we allow each selected target segment to be spatially transformed and uniformly stretched in time.
Approach	The proper selection of segments can be achieved using an efficient dynamic programming algorithm.
Approach	Before developing our general algorithm, we address the simpler problem of interpreting the input as a single control segment from the database.
Approach	We quantify the similarity of the input motion x and a control segment a s with a distance function:
Approach	Here, a T s represents the control segment a s , uniformly stretched in time to T frames, and M(x, a s T ) is a rigid transformation that optimally aligns x and a s T :
Approach	This optimization is the solution to the Procrustes problem, which has several efficient numerical solutions [ELF97].
Approach	Since our example dance and walk motions only differ by ground translation and vertical rotation, our implementation uses a closed form solution [KGP02].
Approach	To compute the optimal interpretation, we determine the segment a s ∗ that is most similar to the input motion:
Approach	The index s ∗ also identifies, by construction of the database, an appropriate target b s ∗ for both the control segment a s ∗ and the input motion x.
Approach	The stretch T completes the specification of the optimal interpretation, M(x, a T s ∗ )a T s ∗ , and the optimal target, M(x, a T s ∗ )b T s ∗ .
Approach	The optimal target may not precisely satisfy desired physical or kinematic constraints.
Approach	However, given a descriptive database, it can provide a good approximation which can be adjusted appropriately during postprocessing.
Approach	In practice, we limit the allowed amount of uniform time stretch by a constant factor since the distance metric does not distinguish between motions of varying speed.
Approach	A dancer that pushes his partner slowly, for instance, will elicit quite a different response if he pushes quickly.
Approach	Limiting the amount of stretch also has the practical benefit of reducing the search space of our general algorithm, which we will now describe.
Approach	In general, we must handle the case where the optimal control and target consist of a sequence of segments.
Approach	We can specify this sequence analogously to the single segment case by the number of segments L ∗ , the segment indices s ∗ 1 , . . . , s ∗ L , and the segment durations d 1 ∗ , . . . , d L ∗ .
Approach	As in the single segment case, the distance metric D evaluates the interpretation quality of each segment in the sequence.
Approach	However, the quality of the interpretation alone does not account for the continuity of the target motion, as shown in Figure 3 .
Approach	To offset this problem, we introduce a function which measures the continuity between segments v and w:
Approach	Here, α and ω represent the head and tail functions, which respectively extract the positions of the first and last frame of a segment.
Approach	One could also use more frames to measure higher-order continuity if desired.
Approach	Given a sequence specification L, s 1 , . . . , s L , and d 1 , . . . , d L , we define a scoring function that accounts for both the quality of interpretation and the continuity of the target:
Approach	Here, x i is the subinterval of the input that is implied by the segment durations d 1 , . . . , d i .
Approach	These in turn induce the transformations M i ≡ M(x i , a d s i i ).
Approach	The user-specified constant k defines the balance of interpretation and continuity.
Approach	The optimal substructure property of the score function, as defined by the following recurrence, can be used to find a globally optimal solution using dynamic programming:
Approach	Here, x d,t represents the subsequence of input frames starting at frame t − d and ending at frame t, which in turn induces the alignment matrix M s,d,t ≡ M(x d,t , a d s ).
Approach	Q s,d [t] is defined as the score of the optimization on the subsequence x t,t , given that the last segment is indexed by s and stretched to duration d.
Approach	By minimizing Q s,d [T ] over all s and d, we can compute the score of the optimal sequence specification and recover it by backtracking.
Approach	To solve the recurrence efficiently, values of Q are stored in a two-dimensional array.
Approach	Cells in this array are indexed by the time t on one axis and by all legal combinations of s and d on the other (recall from Section 4.1 that the amount of allowed stretch is limited).
Approach	First, all legal values of Q s,d [d] are initialized according to the base case given in Equation 7, and all other array cells are set to infinity.
Approach	The algorithm proceeds by iterating forward through time.
Approach	At each time t, all non-infinite cells are located and scores are conditionally propagated forward in time according to Equation 6.
Approach	More specifically, suppose that we are currently processing the array cell Q r,c [t].
Approach	For each legal combination of s and d, the candidate value z is computed:
Approach	If the value in the array cell Q s,d [t + d] is greater than z, we set it to z and store a backpointer to cell Q r,c [t].
Approach	By continuing this process, the entire array is filled.
Approach	Since the indexing of each cell encodes a segment identifier and duration, the optimal sequence specification can be recovered by following backpointers from the best score at time T .
Approach	At each time t, O(P) noninfinite cells are processed, where P is the number of legal combinations of s and d.
Approach	Since processing an individual cell is an O(P) operation, the total asymptotic time complexity of the algorithm is O(P 2 T ).
Approach	To increase its efficiency, we apply several heuristic optimizations.
Approach	Rather than process all O(P) noninfinite cells at each time t, we only process cells with scores less than min s,d Q s,d [t] + w, where w is a user-specified constant.
Approach	This technique is known as beam search, and w is known as the beam width.
Approach	This is motivated by the fact that cells with worse scores are unlikely to be on the optimal backtracking path, and thus can be pruned from the search.
Approach	Since the time complexity of the algorithm scales quadratically with the database size, this leads to inefficiency when the number of instances is large.
Approach	To resolve this issue, redundant instances are eliminated using complete-linkage clustering [DHS00].
Approach	For this, the distances between instances is defined by Equation 1.
Approach	The advantage of complete-linkage clustering over other methods (such as k-means) is that it explicitly limits the distance of any two instances in a cluster by a user-defined threshold.
Approach	After clusters are formed, a representative instance is chosen at random from each cluster to remain in the database, and all other instances are discarded.
Approach	An additional benefit of this process is that it helps beam search; since clustering reduces ambiguity in interpretation, a larger proportion of search paths can be pruned.
Background	High sampling rates are common for systems such as motion capture, but they are generally unnecessary for interpreting the input control motion.
Approach	By downsampling motions by a user-chosen constant, we can effectively reduce the length of the input sequence.
Approach	However, the resulting optimal sequence specification will also be at the lower frame rate, and it is generally desirable to have it at the frame rate of the original input.
Background	Simple upsampling often introduces slight but undesirable temporal errors.
Approach	To remedy this, we run a highly constrained version of our dynamic programming algorithm that only adjusts the durations appropriately.
Approach	Constraints can be easily encoded by making appropriate cells in the Q array illegal.
Approach	For instance, we can force the result to contain a certain target segment b s at some time t by disallowing any processing on cells Q r,c [u], where r = s and u − c ≤ t ≤ u.
Outcome	As described in Section 4, the output of our optimization is a specification of an appropriate target motion in terms of target segments in a database.
Outcome	Specifically, it provides a sequence of target segment indices s ∗ 1 , . . . , s L and durations d 1 ∗ , . . . , d L ∗ .
Approach	The corresponding target segments can be copied from the database, stretched, transformed by the induced matrices M ∗ 1 , . . . , M ∗ L , and concatenated.
Approach	The result is a moving point cloud that approximates the desired result.
Approach	Of course, the same selections, stretches, and transformations can just as easily be applied to the source motions that generated the point cloud.
Outcome	From the perspective of motion synthesis, the main problem with our approach is that the raw result will generally contain some kinematic errors.
Outcome	In our dance example, footplant and handhold constraints are never explicitly enforced.
Outcome	For such constraints, existing methods can be applied to postprocess the data [KSG02], but such methods often require some amount of manual constraint annotation.
Approach	Like similar motion clip rearrangement techniques, we can propagate constraints by example.
Approach	In other words, each example instance can be annotated with constraints that can be transferred to the target motion.
Approach	This is demonstrated by our propagation of handhold constraints, shown in Figure 4 .
Challenge	We do not aim to introduce novel solutions for motion blending or constraint satisfaction.
Challenge	Instead, our goal is to provide motion that is amenable to postprocessing with these approaches.
Outcome	To demonstrate our method’s capabilities in this regard, we show that it can generate realistic and compelling motion, even with extremely simple postprocessing.
Outcome	Our results, shown in the following section and in our accompanying video, are filtered with a basic smoothing operation that linearly adjusts motion curves to match across segment boundaries.
Approach	We evaluate our technique with two examples.
Approach	In the first, we animate a realistic walking human from time-sampled mouse movement.
Approach	Walk motions, however, do not show the full ability of our technique to discover complex mappings.
Approach	To better demonstrate this aspect, we apply our method to a partner dance called Lindy Hop.
Approach	Specifically, we use the complex motion of the dance leader to drive the motion of the follower.
Approach	In the following sections, all human motions were acquired in a motion capture studio and standard commercial tools were used to estimate joint positions [Vic03].
Approach	For the point cloud representation of body motion, we used only the positions of the hands and feet, as we found that these endeffectors were sufficient to evaluate interpretation and continuity in both evaluations.
Approach	To generate the motion, we applied the resulting sequence specification to the source motion and used basic smoothing.
Approach	All timings were performed on a workstation with dual 2.4 Ghz Intel Xeon processors.
Approach	Where applicable, we state the clock times for the dynamic programming algorithm (Section 4.3), upsampling (Section 4.4), and postprocessing (Section 5).
Approach	The continuity constant, defined in Section 4.2, and the stretch limit were chosen experimentally.
Approach	We acquired 2 minutes of motion captured walk footage at 30 Hz.
Approach	The subject was directed to walk within the capture area with random changes in direction and speed.
Approach	We artificially constructed a synchronized example control motion by projecting the positions of the hip joints onto the floor and normalizing their distance.
Approach	As stated previously, the target motions were represented by end-effector positions.
Approach	The walk footage was transcribed manually according to the gait cycle.
Approach	More specifically, a segmentation point was manually placed at each footplant.
Approach	From this process, we created 200 segments, which we reduced to 70 using clustering.
Approach	In our tests, we downsampled these motions to 10 Hz and allowed each segment to be stretched ±0.2 seconds.
Approach	Our first evaluation involved creating control motions from new walk motions that were not in the database.
Approach	As before, we projected the hip joints onto the ground and normalized their distance.
Approach	We ran our algorithm on these control motions and compared our results to the original source motions.
Outcome	Experimentally, we found that larger values of the continuity constant were more effective.
Outcome	For short walks, the generated motion was highly realistic.
Outcome	The frequency of the generated gait cycle nearly matched the frequency of the source, but phase differed.
Outcome	In more concrete terms, the generated motion might choose to start on the left foot, whereas the original source motion might start on the right.
Outcome	This was expected, as the control signals did not encode any phase information.
Outcome	For longer walks, however, we were surprised to discover that the generated motions often kept in nearly perfect phase with the source.
Outcome	The reason for this was that the subject preferred to make sharp turns with the same footwork pattern.
Outcome	These served as synchronizing signals which were propagated throughout the generated gait cycle due to the global optimization.
Approach	In our timing tests, we used a 57 second control motion.
Approach	We first ran the algorithm without the beam search optimiza- tion.
Outcome	The dynamic programming algorithm took 12.5 seconds, upsampling from 10 Hz to 30 Hz took 0.4 seconds, and postprocessing took 1.1 seconds.
Outcome	With the beam search optimization on, we were able to reduce the clock time of the algorithm to 1.2 seconds (47 seconds of input processed per second of clock time) while retaining visually perfect results.
Outcome	The upsampling and postprocessing times remained the same.
Approach	We ran the algorithm on shorter and longer inputs and experimentally confirmed the asymptotic linear dependency of running time on input length, described in Section 4.4.
Approach	In our second evaluation, we built an interface that allowed users to draw paths using mouse input, as shown in Figure 5 .
Approach	The position of the mouse pointer was sampled at 30 Hz, and Frenet frames were used to generate a control motion.
Outcome	For a wide variety of user inputs, our method was capable of generating highly realistic walking motion.
Outcome	Since the timing of the path was important, we found that users required minor training to understand the concept of performing a path instead of drawing it.
Outcome	It was often tempting, for instance, to rapidly move the mouse to draw a straight line.
Outcome	This would correspond to a impossibly fast run, well beyond the capabilities of a human.
Approach	To resolve these issues, our interface allows a user to overlay the playback of an existing motion on the drawing canvas to get a sense of speed.
Approach	Furthermore, it provides options to smooth the trajectory spatially and temporally.
Outcome	The speed of the algorithm allows for rapid feedback.
Approach	Our choice of partner dance as a demonstration was primarily motivated by the complexity of its style and mappings.
Approach	From a small segmented set of example instances, we generate a follower’s motion to accompany a leader’s motion.
Approach	Generating partner dance motion would be a difficult trial for both physical methods, which would yield underdetermined systems, and statistical methods, which would typically require a very large database in place of our small segmented one.
Approach	Swing dance also allows for a more principled evaluation of our results than most types of motion, since the performance of the algorithm at generating valid mappings can be evaluated independently of style considerations or subjective judgments of motion quality.
Background	Lindy Hop is a subgenre of swing dance that, at a basic level, can be described as a state machine.
Approach	A dance couple moves between four basic stances: open (◦), closed (•), open crosshand (◦), and closed crosshand (•).
Approach	Open and closed refer to whether the couple is apart or in embrace, respectively.
Approach	Crosshand refers to the case when the leader and follower hold right hands (we could also refer to it as a handshake).
Approach	Basic Lindy Hop motions switch between these four stances by means of transitions: an inside turn ( ), when the follower spins towards the leader, an outside turn ( ), when the follower spins away from the leader, and a simple step (→).
Approach	At the end of each transition, the dancers may also change their handhold to instantly transition between crosshand states (◦, •) and non-crosshand states (◦, •).
Approach	Each of these transitions occurs over four beats of music, which are assembled from two-beat segments; this was our motivation for performing two-beat segmentation, as described in Section 3.
Background	Skilled Lindy Hop dancers use a greater variety of moves, ranging from more complex transitions such as double outside turns to complex aerial maneuvers.
Approach	We did not include the entire range of motions.
Approach	Instead, we constructed a smaller database with seven basic 8-beat dance patterns that every Lindy Hop dancer knows (shown in the first column of Table 1 ).
Approach	We constructed the motion database from a set of 12 short dances, each containing the seven basic 8-beat patterns, giving a total of 5 minutes of motion.
Approach	These dances were segmented into 364 two-beat mapping instances, with lengths varying from approximately 0.6 seconds to 1 second due to different music.
Approach	For our evaluations, we captured three longer test dances (approximately 2-3 minutes each) in which the dancers were instructed to improvise with the transitions and stances included in the database.
Approach	Their improvisations led to dances which included thirteen new 8-beat patterns not found in the database (shown in the last column of Table 1 ) as well as some repeats of patterns in the database.
Approach	These test dances spanned a tempo range from about 120 beats per minute to about 190 beats per minute.
Approach	We used the motion of the leader to control a synthetic follower, which was then compared with the actual follower.
Outcome	Visually, the results exhibited the fluidity, grace, and style of the original dancer.
Outcome	Some footskate and handhold violations are visible because we wanted to show the output in its almost raw form, with smoothing applied only for visual coherence.
Outcome	In a direct comparison with the actual follower motions, we found that the synthetic follower matched very well in closed stances.
Outcome	In open stances, the follower was much freer to include stylistic variations, so the generated motions often differed visually from the actual motions.
Outcome	Additionally, the synthesized dancers almost always kept in perfect rhythm with the leader.
Outcome	Our algorithm ably recreated the semantics of the leader to follower mapping, even for novel patterns.
Outcome	When the algorithm encountered a pattern that was not in the database (one of 14 such patterns shown in Table 1 ), it was able to correctly reconstruct the novel sequence by rearranging the two-beat segments.
Outcome	Of the 91 patterns (21 unique) in our three test dances, the synthetic dancer matched the pattern of the actual dancer in all but 5 cases, one of which is shown in Figure 6.
Outcome	When the algorithm did differ from the real dancer in the composition of the pattern, the leader and follower still executed a valid Lindy Hop pattern.
Outcome	In these misinterpreted instances, the leader’s motion is quite similar across two different follower patterns.
Outcome	To disambiguate these, we might add information to the control signal, such as forceplate readings, or we might accept these rare mismatches because they are in fact valid mappings.
Outcome	Furthermore, all 5 mismatched patterns differed by a single two-beat segment, so, of 91 × 4 = 364 two-beat segments in the test dances, the algorithm misinterpreted the signal in 5 cases for an error rate of less than 2%.
Outcome	For all our evaluations and timing tests, we reduced the size of the database from 364 to 168 with clustering, downsampled to 7.5 Hz, and allowed a segment stretch of ±0.15 seconds.
Outcome	We cite our efficiency figures for generating, from leader motion only, a particular 150 second dance motion.
Outcome	Without beam search, the dynamic programming algorithm ran for 78 seconds, 2 seconds were spent on upsampling, and 26 seconds were spent on postprocessing.
Outcome	With beam search enabled with modest parameters, we were able to drive the runtime of the dynamic programming to 10 seconds while maintaining excellent visual and semantic results.
Outcome	As with our walk motion evaluation, we found that clock times scaled linearly with the length of the input.
Outcome	We have presented a method for example-based performance control of human motion.
Approach	Our dynamic programming algorithm uses segments of motion along with an objective function that accounts for both the quality of control interpretation and the continuity of the target motion to generate visually and semantically correct motions.
Approach	The semantic accuracy of the generated motion was evaluated in the setting of partner dance, where the follower’s motion is generated from the leader’s motion.
Outcome	The algorithm generated semantically correct partner motion even from test sequences of leader motions that did not appear in the training set.
Outcome	Our dynamic programming algorithm performs a global optimization, which precludes the local decisions that are required for online applications.
Outcome	However, we demonstrate in our evaluations that it can compute results significantly faster than input motion can be recorded, thus making it suitable for rapid-feedback motion authoring applications.
Outcome	We believe that segmental approaches like ours hold great promise for real-time performance-driven animation, and consider it a promising area of future research.
Approach	To preserve spatial dependencies in mappings, we apply rigid transformations to optimally align control segments with input control motions.
Outcome	Target segments inherit these transformations.
Outcome	This approach is effective for our applications or whenever the control signal indicates appropriate spatial and temporal cues.
Outcome	It is also possible to select other transformations for applications outside the domain of human motion control.
Outcome	For instance, allowing arbitrary homogeneous transformations in two dimensions might form an alternative segmental solution to the curve analogies prob- lem [HOCS02].
Outcome	Eliminating transformations entirely might also be appropriate for applications such as synthesis of facial motion from speech signals [Bra99].
Outcome	We have shown that our segment similarity metric is effective for our experiments.
Outcome	However, we acknowledge the fact that other metrics may be more appropriate for different types of motion and believe that it is a promising direction for future research.
Approach	In the process of generating target motion, our dynamic programming algorithm performs a semantically guided segmentation of the input control motion.
Approach	The entire process, however, relies on the availability of semantically segmented examples.
Approach	For our evaluations, we were able to perform this segmentation manually by tapping a key in response to the rhythm of music or the gait pattern of a walk cycle.
Outcome	While specific methods exist to automate this segmentation for the cases of dance and walk, a more general method is desirable.
Outcome	For this, we could begin with a few manually segmented examples and grow the set of example instances by iterative application of our algorithm.
Background	This approach would be similar in spirit to the semiautomatic SVM-based annotation approach of Arikan et al. [AFO03].
Outcome	The annotation propagation we describe above suggests that our method could be used for interpretation rather than control.
Outcome	Paralleling our automatic annotation of handholds, it is possible to annotate any new control motion given a set of labeled example instances.
Outcome	This could be used to transcribe the motion into a symbolic representation, such as the one used in this paper, or even Laban notation [Hut73].
Outcome	Such a representation could then be analyzed or summarized using natural language processing techniques.

Challenge	Choosing the adequate method should be done with full knowledge of the advantages and weaknesses of the main techniques.
Outcome	This paper presents a quantitative comparison of the efficiency of the most common integration techniques used for cloth simulation, and raises the key considerations for optimal implementations depending on the practical kind of simulation problematic.
Challenge	The correct choice of the simulation method and its implementation is a very important issue in the design of an efficient cloth simulation system.
Background	Among the available methods, there are finite elements methods [ EIS 96 ], continuum mechanics [ TER 87 ] or particle systems [ BRE 94 ].
Approach	We will focus on the latter, which has shown to bring the best compromise between accuracy and speed for highly deformable objects such as cloth [ VOL 95 ] [ VOL 97 ].
Background	A particle system represents the mechanical system as a set of punctual masses.
Background	The cloth surface shape is represented by the geometry between neighboring particles.
Background	The mechanical behavior is represented as interaction forces between the particles, which depend on the relative position and speed of the particles, measuring deformation and deformation speed.
Background	Various models exist for this representation, which rank from the simple spring-mass representation (spring forces between particle couples depending on the distance between the particles) to accurate surface or volume models (involving complex interactions between several neighboring particles).
Background	The laws ruling these interactions also rank from linear to highly nonlinear involving discontinuities and hysteretic curves.
Background	The evolution of the system is computed numerically from these equations that form a large and sparse ordinary differential equation system, which, through adequate modeling, is also first-order.
Background	This numerical system has to be integrated numerically, for finally obtaining the evolution of the mechanical system along time, usually as a sequence of successive positions of the object along regular time intervals.
Challenge	The aim of this study is not to describe the implementation of these methods, which has already been carried out extensively in [ EBE 96 ] [ VOL 97 ] [ BAR 98 ] [ VOL 00 ], and with some adaptations in [ DES 99 ] [ EBE 00 ] [ KAN 00 ].
Challenge	It rather intends to evaluate quantitatively the performance of the main integration methods in terms of speed and accuracy.
Approach	Using a “typical” cloth object made of a common fabric material, we compare the computation speed and accuracy of each integration methods depending several simulation contexts, giving the reader an overview of the performance he can expect from each method.
Challenge	The choice of the adequate integration method has to be carried out using various considerations related to the kind of problem to be simulated.
Background	The literature is abundant about various integration methods which aim to solve linear systems of first-order ordinary differential equations [ PRE 92 ].
Challenge	One can easily turn the second-order systems relating dynamical mechanical systems into first-order systems by constructing a state vector defined by the concatenation of position and speed states of the system, such as to fit the requirements of any of these algorithms.
Approach	We shall restrict our consideration to three different methods which explore the range of these classes, and which seem to fit the best the requirements set for cloth simulation problems, in terms of implementation simplicity and efficiency for particle systems using large numbers of particles that interact sparsely and with a constant topology.
Background	It requires two mechanical derivations per iteration and returns a second-order accurate solution relative to the time step.
Background	It also requires two storages of the state vector.
Approach	We preferred this method to the still simpler first-order Euler method, because of the obvious gains of accuracy and stability which, despite the additional mechanical evaluation, makes it largely more efficient.
Approach	We implemented this method for garment simulation in [ VOL 95 ].
Background	It requires five mechanical derivations per iteration, as well as five storages of the state vector.
Background	This method is supposed to provide high accuracy, which increases significantly as the time step is reduced.
Background	This method was experimented in [ EBE 96 ] and [ VOL 97 ].
Background	It requires one mechanical evaluation and the resolution of a sparse linear system per iteration, as well as one storage of the system state additionally to those required for the system resolution algorithm.
Background	This method is supposed to provide approximate results that are not subject to numerical instability as the time step is increased.
Approach	We implemented this method combined with a Conjugate Gradient algorithm using linear system matrix products computed on the fly, as described in [ VOL 00 ], and thus able to take into account the anisotropy and nonlinearities of the mechanical model as the actual Hessian matric is used for each current state of the mechanical system.
Background	No initial matrix setup is required, suppressing also the need of separating linear and nonlinear components as discussed in [ EBE 00 ].
Approach	We have also carried out some preliminary tests with the Rosenbrook method, which is an implicit implementation of a fourth-order Runge-Kutta method.
Background	It is supposed to combine the stability of implicit methods with the accuracy of high-order methods.
Outcome	We implemented this method using the algorithm described in [ PRE 92 ], but preliminary experiments have shown very deceptive results, and the gain of accuracy did not compensate the large calculations required for each iteration, whereas increased instability problems did not allow time steps much larger than those used for good accuracy with backward Euler.
Approach	We did not consider in our tests the methods aimed toward simplifications which might highly approximate and degrade the dynamic behavior of deformable models, such as implicit integration with precomputed inverse matrices [ DES 99 ] which involves high simplification and linrarization of the Hessian matrix and which also becomes very unpractical for large matrix sizes (the inverse of a sparse matrix is not necessarily sparse).
Outcome	We simulated such algorithm using accurate resolution on an accordingly approximated constant matrix, and we found that these approximations produced more simulation errors (on dynamic behavior of wrinkles and motion damping particularly) than producing a quick and rough linear system solution using a reduced number of Conjugate Gradient iterations with an accurate matrix.
Background	Even more drastic simplifications [ KAN 00 ] reduce the matrices to their diagonal component.
Approach	Bending is also implemented, but not taken into account in this study.
Approach	The base element of this simulation is a triangle of the mesh describing the surface, and the elasticity laws are computed as interactions between the three vertices of a triangle reflecting all the mechanical behavior curves which, for this study, are restricted to be linear.
Approach	This model is one of the simplest that a cloth simulation application would use.
Approach	The implementation also supports collision detection and response, which were disabled for these tests.
Approach	An object-oriented framework written in C++ integrate all these technologies into a single application allowing simulation of cloth objects of any shape with specified parameters.
Approach	The application is run on a SGI Octane having a 200 MHz R100000 processor, and enough memory for working without swapping.
Approach	Performance timings are done on the mechanical computation only, and do not take into account display and data structure management.
Background	Performance is a key issue in choosing the adequate integration method, as cloth simulation usually involves very large mechanical systems described by a huge number of variables, and the numerical resolution of the system is therefore critical to the total computation time.
Approach	This depends on the complexity of the method, and also related to the number of times the forces of the system have to de derived from the system state using the laws of mechanics.
Approach	Accuracy increases along with time step reduction as better as the method is high-order.
Approach	These factors describe our investigation field in the following sections.
Background	The total computation time is the time required for computing one iteration times the number of iterations.
Approach	Our first investigation is to evaluate the iteration computation time for each of these methods.
Approach	For these measurements, we have simulated a square of fabric with a given discretization both with the accurate and simplified models, using the Midpoint, the RungeKutta and the Backward Euler methods, with 1, 2, 4, 8 iterations in the Conjugate Gradient algorithm for the latter, and measured computation time (Fig.1).
Outcome	With one iteration only, it is barely worse than the very simple explicit Midpoint method.
Approach	Our implementation, described in [ VOL 00 ] does not explicitly construct the matrix of the system to be resolved by the Conjugate Gradient, but computes “on the fly” the product of this matrix with vectors when needed by the Conjugate Gradient algorithm.
Outcome	This gives a very efficient implementation when using a low number of Conjugate Gradient iterations (no heavy preprocessing for building the matrix), which is often sufficient for most applications.
Approach	These tests will help us to choose the method that gives the best compromise between accuracy and computation speed, as discussed in the next section.
Approach	For measuring accuracy and numerical stability of the algorithms, we need to set up a “standard” material on which the experiments are carried out, as well as the rules allowing to extrapolate the results to any material of different size and parameters.
Approach	In the scope of our study, we restrict the experimentation to linear metric elasticity of an isotropic cloth material, described by a Young modulus E and a surface density d.
Approach	For the simulation, the surface square is discretized into elements which roughly have the length l, and the computation is carried out with time steps of size t.
Approach	We checked experimentally with our implementation that any scaling of a simulation along distance, time and mass which leaves K unchanged does not change anything to the simulation result.
Approach	A typical cloth simulation problem could involve a cotton fabric cloth surface, which typically have a density d = 0.1 kg.m -2 and a Young modulus E = 2 0 N .
Approach	Given a discretization into elements averaging one centimeter and a simulation time step of ten milliseconds, the condition coefficient of the problem computed with (1) is K = 2 0 0 .
Approach	It is possible to define similar coefficients related to bending and viscosity modulus.
Approach	The corresponding K coefficients are respectively multiplied by additional l -2 and t factors.
Approach	In simulations that consider simultaneously all these forms of mechanical behaviors, the dominant K coefficient rules the “numerical difficulty” of the problem.
Approach	In such kind of simulation, the interest is to reproduce exactly the motion of a cloth object along time, the accuracy of its evolution being the key of the realism of an animation involving simulated cloth.
Approach	When using implicit methods, we perform a preconditioning of the system state variables of the linear system to be resolved using the inverse square root of the mass of the corresponding particle.
Approach	This allows the iterations of the Conjugate Gradient algorithm to distribute the resolution numerical errors as evenly as possible between the particles, so that to obtain for instance a fall speed that does not depend on the mass of the particle.
Approach	We measure the time it takes for this fabric piece to fall a height of 1 m .
Approach	Without any additional external forces considered (no aerodynamic interactions), we expect this to happen in a constant time of 0.45 s.
Outcome	Several interesting facts arise from this experiment.
Outcome	As a matter of numerical stability, the Midpoint method supports K values up to almost 3 whereas the RungeKutta method supports K values up to almost 100.
Outcome	This indicates that with Runge-Kutta, it is possible to use simulation time steps which are almost six times larger than with Midpoint.
Outcome	Given the fact that a Runge-Kutta iteration takes only three times more computation than a Midpoint iteration (Fig.1), the Runge-Kutta method seems to be computationally two times more efficient than the Midpoint method.
Outcome	As a matter of simulation accuracy, both Midpoint and Runge-Kutta seem to preserve accuracy correctly within their range of numerical stability.
Outcome	While the implicit Euler method seems stable for any K value, its accuracy is however very degraded by high K values and reduced numbers of Conjugate Gradient iterations.
Outcome	More precisely, we see that accuracy is well preserved with one Conjugate Gradient iteration up to a K value of 4, and increasing the iteration number n times also increases the K value n 2 times for the same accuracy.
Outcome	From this, we can see that the Inverse Euler method needs at least four Conjugate Gradient iterations to reach the accuracy of the Runge-Kutta method.
Outcome	We also see that similar requirement of accuracy bring the two methods in parity in terms of computation time (Fig.1).
Approach	However, it should be noted that the experiment was carried out using a uniformly discretized mesh, and uniform mechanical parameters.
Outcome	Real-world simulations do not have this regularity, and numerical instability with explicit methods occur in the stiffest regions of the mesh, which, even if they are marginal in the whole mechanical system, may totally “explode” and destroy the simulation and therefore will rule the size of the largest time step possible.
Approach	With implicit methods, the resulting inaccuracies may be unnoticed when taking a time step adapted to the average stiffness.
Outcome	Anyhow, this experiment shows clearly that when accurate reproduction of dynamic motion is required, it is not possible to increase the time step of implicit methods as much as desired, as this cause very noticeable inaccuracy as weak forces will be “neglected” relatively to stiff forces.
Outcome	While this is not an issue for draping problems where only the final state is desired, this aspect has to be taken into account when accurate reproduction of the whole evolution is wanted.
Approach	Considering a simulation involving elements n times smaller, maintaining accuracy and stability (preserving K constant in formula (1)) would require a time step n times smaller, and therefore n times as many iterations for simulating the mechanical system along a constant duration.
Approach	Given the fact that there are also n 2 times more elements to handle, the total computation time is finally multiplied by a drastic n 3 (even n 4 if curvature stiffness rule the simulation accuracy).
Outcome	While this factor is what cause explicit methods to become so inefficient with refined discretizations as this scaling has to be strictly observed for preventing instability, implicit methods are a bit more tolerant if only “visual” accuracy matters, accuracy which is not related to the size of the elements.
Background	Draping is another context of simulation, where only the final static equilibrium state of the mechanical system is to be computed.
Approach	Here, the interest is to converge to the equilibrium state as quickly as possible, with minimum computation charge.
Approach	As the full evolution of the cloth along time is not an interest, accuracy can be traded away for computation speed.
Approach	From the dynamic study described above, implicit methods should be quite strong on this point, as they do not suffer from numerical instability, and allow large time steps to be used at the expense of dynamic accuracy which can here be neglected.
Approach	Without any damping, we expect that in its first oscillation, the fabric reach a roughly vertical position after slightly more than half a second.
Approach	Our purpose is here to find the computation time necessary to obtain the fabric in its vertical position.
Approach	For this, we count the number of computation iterations necessary for obtaining the fabric in its vertical position in its first oscillation, not being interested by the realism of this motion (Fig.5).
Outcome	Our first finding is that the explicit methods seem quite not adapted for draping.
Outcome	The backward Euler method is robust enough to handle the problem without instability for any time step.
Outcome	However, we see that larger time steps do not proportionally translate into fewer steps for performing the draping.
Outcome	As the time step becomes larger, and as the corresponding K coefficient exceeds the theoretical limit observed in the previous section, we quickly observe a “saturation” of the number of iterations to a constant which seems to be inversely proportional to the number of Conjugate Gradient iterations that were performed.
Outcome	From this it is clear that when K exceeds the dynamic accuracy limit of a given implicit integration method, the time step does not really reflect a time interval anymore.
Approach	In such case, the implicit method will only evaluate an approximation of the rest state of the mechanical system by linear extrapolation from the Hessian matrix, whose accuracy depends on the number of Conjugate Gradient iterations that were used to resolve the corresponding linear system.
Background	Most mechanical simulations work with numerical equations that are not linear.
Background	For instance, the strain-stress relation describing elasticity may actually be complex curves, which furthermore may take into account timedependent and hysteretic behaviors.
Background	* During the simulation, the orientation of the mechanical elements change, and this modifies the expressions of the mechanical laws in the world coordinates.
Background	While rarely causing numeric “explosions” as with explicit methods, nonlinearity may disrupt the stability of simulations integrated with implicit models with large disturbing vibrations, particularly when using large time steps that cause iterations to converge to the equilibrium state of the mechanical objects rather than simulating accurately their mechanical behavior.
Background	This can for instance be observed when simulating stretched flat surfaces without curvature forces.
Background	The reason for that is that the hypothetical equilibrium state is derived from the knowledge of the Hessian matrix, which relates the firstorder evolution of the forces as the deformations change.
Approach	Nonlinearity causes this matrix to change between the successive iterations, and this evaluation to be inaccurate, despite high system resolution accuracy that can be reached with numerous Conjugate Gradient iterations.
Approach	The solution for this is to approximate the Hessian matrix for taking into account the changes that may be observed from the change of the system state between successive iterations.
Approach	While an underestimation of de derivatives may lead to an equilibrium state valuation too far from the current state, and by this cause instability, an overestimation of the derivatives will place this evaluation nearer to the current state, therefore stabilizing the simulation, at the expense of extra numerical damping and slow convergence.
Approach	This is particularly true for drastic linearisations as for example used in [ DES 99 ].
Approach	Knowledge of the expected state changes between successive time steps are required to perform this approximation correctly.
Approach	With nonlinear mechanical behavior, one solution is to take the steepest parts of the curves as derivatives, whereas for the element orientation problem, isotropic derivatives considering force evolution equally in any directions may be considered.
Outcome	However, the more drastic these approximations are, the less accurate the simulation will be for dynamic simulations, and the slower the simulation will converge for draping problems.
Background	A nice solution described in [ EBE 00 ], which makes sense when efficiency relies on the use of a constant Hessian matrix, is to perform the implicit resolution on a linear constant approximation, and to simulate the nonlinear and variable component, unlikely to cause stiffness problems, using an explicit method.
Approach	In order to test the efficiency of our model in the context of garment animation, the algorithms have been integrated in a 3D design framework allowing the management of complex garment objects in interaction with animated virtual characters.
Approach	This integration has been carried out in the form of a 3DStudio Max plugin (Fig.6), running on a 500 MHz PentiumIII PC.
Approach	We have simulated a 2000 Polygon garment made of the cotton material described in Section 3.
Approach	The mesh elements are roughly five centimeters in size, and therefore the resulting condition coefficient K is roughly 8 with a simulation time step of 10 milliseconds.
Approach	This is a draping problem involving to obtain a rest position of the garment as quickly as possible.
Approach	The dynamical motion of the cloth is important here.
Outcome	The garment assembly and seaming operations could be performed almost four times faster with the Backward Euler (2 minutes) than with Runge-Kutta (8 minutes), knowing that collision detection and response account for more than the half of the computation time, and actually limits the time step size when contact starts between the cloth and the body.
Outcome	For the dynamical animation, comparable accuracy could be obtained between Runge-Kutta and Backward Euler using eight iterations of the Conjugate Gradient, which gave similar computation times.
Background	Recent literature has emphasized on the relevance of implicit methods for cloth simulation.
Outcome	The implicit Euler method seems effectively a good candidate for most situations involving cloth simulation, because of the robustness resulting from not being prone to numerical instability.
Approach	This is particularly true when simulating very heterogeneous mechanical systems (elements of various sizes and various mechanical properties) where, using explicit models, the most critical elements would rule the time step size for all the simulation.
Outcome	Contrary the perception of the implicit model iteration being slow because of the linear system resolution it involves, the inverse Euler iteration often proves to be faster than the explicit Runge-Kutta method of higher order, if an adequate approximate linear system resolution is implemented.
Approach	A limited number of Conjugate Gradient iterations seems suitable for this.
Outcome	Furthermore, while increasing the time step seems not limited by instability with implicit methods, it should be kept in mind that this is still done at the expense of accuracy of the whole simulation.
Outcome	The number of iterations should also be set sensitively to the stiffness of the mechanical problem, for limiting the potential inaccuracies that become particularly visible when an accurate simulation of a dynamical system is wanted.
Outcome	There is an obvious advantage of using implicit methods, and particularly the inverse Euler method, for draping problems where quick convergence to a rest position is required quickly.
Outcome	Our test have shown that the inverse Euler method allow to perform a draping problem almost ten times as fast as with the Runge-Kutta method.
Outcome	While not exactly reproducing real mechanical behavior, the simulation with large time steps provides a quite efficient convergence to equilibrium, and the numerical errors quite often act as extra damping, removing the need of adding them explicitly to the model.
Outcome	For dynamic problems where accurate evolution of the mechanical system along time is needed, the advantage of implicit methods is less obvious.
Outcome	Their stability gives a false sense of efficiency, allowing obtaining quickly a result by “cheating” on the time step size.
Outcome	These artifacts are still augmented by the approximations made to the Hessian matrix, possibly in the purpose of reducing instability, while excessive reduction of the Conjugate Gradient iterations produce additional inaccuracy and slow convergence.
Outcome	It seems that there is still some benefit in using the Backward Euler method than any other explicit method for dynamic simulations thanks to the reduced time it takes to compute one iteration, which also only requires one derivation of the particle forces from the state of the system.
Outcome	Our tests have shown a roughly doubled speed for the accuracy corresponding to the limit of stability of the Runge-Kutta method.
Outcome	We got substantial improvements through the implementation of the implicit Midpoint method [ VOL 00 ], which however had the drawback of increasing the numerical instability problem, forcing additional use of isotropic force gradients, at the expense of accuracy.
Outcome	The explicit methods have still their interest, and should be reserved for simulations requiring high accuracy and particularly those where involving low mechanical damping and where mechanical energy conservation is important.
Outcome	Instability concerns will force parameters and time step size to ensure good accuracy for the simulation of all particles of the discrete mechanical representation, and therefore for the entire mechanical object.
Outcome	This may however require prohibitive computation times for very stiff and discretized models.
Outcome	The 5th-order Runge-Kutta method das proven to be a good solution [ EBE 96 ] [ VOL 97 ], because of its high accuracy, and because it furthermore provides integration error evaluation, which is a very good hint to the very sensitive problem of optimal time step size determination.
Outcome	The simpler Midpoint method may have some interest only in very particular cases involving very loose materials with rough discretization, or when numerous fast iterations with small time steps are required for other reasons (high motion sampling, collision detection, very discontinuous models).
Outcome	All these considerations should be carefully taken into account when designing a mechanical simulation engine, as they are the keys to efficient simulation, and therefore complex models that, for garment simulation, express fully visual experience of real fashion models.
FutureWork	We intend to pursue our investigations for dealing with damping in a more accurate way.
FutureWork	This still remains an important issue to dynamic realism of cloth simulation models, which has to take into account viscosity, the dissipative effect of hysteretic behavior, as well as collision damping and friction.
FutureWork	The integration methods have to be tuned to take precisely these effects into account.

Background	The skeleton driven skinning technique is still the most popular method for animating deformable human and creature characters.
Challenge	Albeit an industry de facto due to its computational performance and intuitiveness, it suffers from problems like collapsing elbow and candy wrapper joint.
Challenge	To remedy these problems, one needs to formulate the non-linear relationship between the skeleton and the skin shape of a character properly, which however proves mathematically very challenging.
Approach	Placing additional joints where the skin bends increases the sampling rate and is an ad hoc way of approximating this non-linear relationship.
Challenge	In this paper, we propose a method that is able to accommodate the inherent non-linear relationships between the movement of the skeleton and the skin shape.
Approach	We use the so-called curve skeletons along with the joint-based skeletons to animate the skin shape.
Outcome	Since the deformation follows the tangent of the curve skeleton and also due to higher sampling rates received from the curve points, collapsing skin and other undesirable skin deformation problems are avoided.
Outcome	The curve skeleton retains the advantages of the current skeleton driven skinning.
Outcome	It is easy to use and allows full control over the animation process.
Outcome	As a further enhancement, it is also fairly simple to build realistic muscle and fat bulge effect.
Outcome	A practical implementation in the form of a Maya plug-in is created to demonstrate the viability of the technique.
Background	A realistic and visually accurate character animation necessitates proper skin deformation of the character models.
Background	Skin deformation owes a large part to proper rigging of the characters.
Background	The virtual skeleton forms the interface by which the animator can pose or animate the characters.
Background	The joint-based skeleton has been very popular in the animation industry for many years and has nearly become a de facto standard.
Background	Other technologies like inverse kinematics, forward kinematics, motion capture etc. are built on this hierarchical system of joints.
Background	It is plain to see why the joint-based skeleton system is thoroughly integrated into the current production pipeline in animation.
Background	Where visual fidelity is of the utmost importance, with respect to film quality animation, a combination of techniques including muscle simulation is used to achieve the realistic best in mesh deformation.
Background	The attachment of mesh geometry to the underlying skeleton rig is called ‘skinning’ and this can be understood as a function mapping of the skeleton parameters to a deformation field.
Background	1 One of the common skinning methods in interactive systems is known by the following nomenclatures: sub-space deformation (SSD), smooth skinning, linear blend skinning and enveloping.
Background	The process followed by this technique is to assign influence joints and blend weights to each vertex of the character.
Background	Transforming the vertex by a weighted combination of the joints local coordinate frames completes skin computation.
Challenge	But in spite of computational performance and ease of use, the joint skeleton skinning is not without its share of problems, particularly where skin deformation is concerned.
Challenge	Unusual deformation artifacts appear in the skin while deforming.
Challenge	Some of the commonly seen problems in joint-based skinning during deformation are: candy wrapper effect during twist deformation and collapsing joints, which would create a rubber-tube like effect.
Challenge	There are certain solutions to circumvent these problems (which we will examine later in the paper) but they have their own drawbacks.
Background	Nevertheless, the joint-based system is popular owing to its interactivity and use of minimal animation data.
Background	More importantly, it is almost an integral part of the current animation workflow and animators are reluctant to abandon their familiar production practice.
Background	The relationship between a skeleton and the skin shape is highly non-linear.
Challenge	The problems of joint-based skeleton skinning mentioned above, in essence arises from under-sampling.
Challenge	The transformations of the two related joints are too far from each other.
Challenge	And with that low-rate sampling they fail to give a good approximation of the deformed skin surface.
Outcome	In this paper, we introduce a novel method called curve skeleton skinning, to overcome the persisting drawbacks of joint skeleton skinning.
Challenge	The basic idea is to represent the relationship between the skeletal movements and the skin deformation in a non-linear continuous fashion.
Approach	Since a lot of contemporary animation technology is built upon the hierarchical joint-skeleton based system, it is not wise to entirely replace the current practice.
Approach	What we propose to do is to enhance the current joint skinning system using the curve skeleton skinning and retain the current animation production pattern that the animators are familiar with.
Approach	While the joint skeleton is a discrete centre line representation of an object, the curve skeleton offers a continuous skeletal representation.
Approach	Thus a character will have two skeletons: the ordinary joint skeleton and a curve skeleton.
Approach	The curve skeleton being continuous gives the maximum sampling rate and provides skin deformation transformation without any artifacts.
Challenge	In addition, we will demonstrate how the curve skeleton technique can drive muscle-based systems to achieve realistic muscle deformation during animation.
Outcome	Using our technique, the animator is able to work without digressing from the familiarity of the current joint-based system, but at the same time achieves maximum visual realism in terms of skin deformation.
Background	What needs pointing out is that the term curve skeleton has been used for other applications, such as virtual navigation, reduced-model formulation, visualization improvement, surface reconstruction and it was defined as ‘a 1D subset of the medial surface of a 3D object.
Challenge	’ 2 Despite some similarity, it should not be confused with what we are presenting in this paper.
Challenge	One should neither confuse this with the inverse kinematics (IK) spline handle tool provided by the animation package Maya.
Challenge	Despite their seeming similarity, they are in essence very different techniques.
Background	Mesh deformations due to skeletal joint influence have undergone significant improvements in the recent years.
Background	Some of the normal deformation techniques like free form deformations (FFDs) or lattices can be used in skin deformation techniques.
Background	Singh and Kokkevis 3 demonstrate this in their paper.
Background	They use surface-oriented FFDs for skinning.
Background	An interactive deformation technique for complex geometric objects using curves or wires is detailed in Reference [ 4 ].
Background	There are basically two main approaches to modeling skin deformations, namely, anatomy-based approach and skin-shape based approach (e.g., example-based skinning).
Background	The anatomical approach derives its name from its implementation using anatomical models of muscles and skeletons and other relevant interior structures.
Background	These modules undergo deformation when the body moves and a skin simulation and collision detection algorithm is run which would realistically deform the skin where and whenever it is required.
Background	Reference [ 5 ] details a technique of efficient muscle shape deformation using the anatomical skin deformation technique.
Background	Reference [ 5 ] resorts to the creation of a muscle model, which is categorized into two layers: an action line and a surface mesh.
Background	Basically, the action line is the mechanism that drives the deformation.
Background	They also implement attractive and repulsive force fields in the form of ellipsoid metaballs to stabilize the action line.
Background	Simulation of complex dynamics and performing complex collisions and also providing a visually realistic output form the main strength of the anatomical approach.
Background	Incorporating physical properties of anatomy structures can potentially improve realism.
Background	Physics can be used either at the muscle level 6 or used to help character rigging.
Background	7 Reference [ 8 ] presents another approach to deformation using an elastic surface layer model.
Background	It uses a layered structure of anatomical parts from the inside out, skeleton->bone->fat->skin.
Background	The surface is discretized and finite differencing techniques are used to evolve the deformation through time.
Background	The drawback comes in the form of computation expense.
Background	The anatomy-based approach is therefore used mainly in high-quality film visual effects where anatomical accuracy is a must for believable computer generated characters.
Background	The example-based approach forms a suitable alternative where computational expenses are to be minimized.
Background	This method takes an interpolative approach to deformation.
Background	An artist models certain key poses of the characters where a correlation is maintained for the degrees of freedom, in this case, it would be the joint positions or rotational angles.
Background	New poses are interpolated from these key poses.
Background	A modified least square fitting technique is used to compute the weights of the deformation and the subsequent generalization of skin movement to other animated poses.
Background	In Reference [ 9 ] the algorithm is trained in a statistical manner so that deformation computation for an arbitrary animated pose can be done.
Background	They use a technique called multiweight enveloping in place of single-weight enveloping for better deformation.
Background	Reference [ 10 ] also implements an example-based approach to deforming meshes by using radial basis functions to supply the interpolation weights and also for shape interpolation.
Background	A variation of example-based approach where key example poses are derived from arbitrary unrelated examples is detailed in Reference [ 11 ] where a range scan is used.
Background	Thus example-based approaches have the advantage over anatomical approaches by being computationally faster and also due to the fact that creating example poses are much easier compared to creating detailed anatomically correct models.
Background	Most of the described techniques are built upon the existing hierarchical skeletal joint system and modify 10 or even create 9,12 new weight calculations to rectify any sort of physical artifacts in the skin deformation.
Background	The example-based approach relies on key sample poses to derive a generalization of deformation, and this becomes a major disadvantage, as this in itself is an expensive and time-consuming process.
Background	It is not desirable to create many examples and train the system.
Approach	Our approach builds upon the existing system using the curve skeleton for a continuous sampling of the skin surface thereby facilitating skin deformations devoid of geometry artifacts.
Approach	Since our technique falls in between the two approaches, seamless integration with the two is also possible and becomes its strong advantages.
Background	A relevant technique to ours is the sweep-based skinning.
Background	13 The body of a character is segmented with a large number of sweep planes which will be transformed by the joint skeleton.
Background	These planes are used to guide the transformation of every skin point during animation.
Approach	With our method, the skin surface does not need to be approximated by sweep surfaces.
Approach	It will be deformed directly by the underlying curve skeleton, leading to a simpler process.
Challenge	Skeleton and skin relationship in the present production pipeline is strictly linear, whereas observation of the various geometry artifacts like candy wrapper and collapsing joints intuitively point to the fact that linear blending or skeletal space deformation falls short in accurately depicting skin deformations because of their non-linear nature.
Background	This non-linear nature is explored in Reference [ 12 ] where a spherical blending is proposed.
Background	Only the translation factor is most commonly used for the skin vertices and the rotation factor is not considered.
Background	It is our knowledge that the problem reduces after weight painting only when the joint influence fall-off follows a curve pattern.
Background	Wang and Philips 9 introduce a multiweight technique to eliminate this problem in a normal joint-based skeleton skinning.
Background	However, this requires the generation of a large number of pre-modeled examples in the first place.
Background	The solution to the collapsing joints problem, which is to place additional joints 1,14 (placing additional joints is basically bringing a curve nature to the joint chain) near the main joint, has the added problems of: (1) creating a new joint in the hierarchy; (2) joint connections have to be done again to connect the new joint in the existing chain; and (3) painting of weights have to be adjusted to accommodate the new joint.
Approach	With our curve skeleton technique, the curve serves as a duplicated skeleton to the actual underlying joint skeleton.
Approach	Effectively any point on the curve can be considered as a joint.
Approach	In other words, the skeleton is equipped with an infinite number of joints, which will influence the skin deformation.
Outcome	The curve nature of the skeleton makes it easier to manipulate it with a great order of flexibility.
Outcome	The idea to use a curve skeleton side by side with the traditional joint skeleton is conceptually simple and functionally efficient giving realistic skin deformations even under extreme mesh duress.
Outcome	Our curve skeleton technique takes full advantage of the nonlinearity of the skeleton-skin relationship.
Approach	The curve skeleton can be generated in two ways depending on what the animator supplied in the first place.
Approach	If the animator supplies a skin model and a skeleton model in the traditional manner, the curve skeleton generation is easy.
Approach	If on the other hand, the animator supplies only a 3D surface model (not a voxelized representation), the generation of the skeleton becomes slightly more complex in that an additional step is required.
Approach	A temporary copy of the surface model can be created (during runtime) and voxelized.
Approach	Once voxelized, a curve skeleton is created using the repulsive force field function.
Approach	15 Then the temporary mesh can be deleted and the skeleton can be used with the original surface model.
Approach	The whole structure of a curve skeleton may involve several curves, which depend on the topology of the original joint skeleton.
Approach	In a linear linkage the centre of the joint gives the first control point (CP) of the curve.
Approach	Then one Bone_CP each is inserted on the opposite sides of the Joint_CP ( Figure 1a ).
Approach	Both Bone_CPs have floating positions along the two neighbouring bones, its position being constrained by the angle between the two bones.
Approach	The reason for the floating position is to eliminate the selfintersection of the skin mesh ( Figure 1 -a1).
Approach	Before we can predict the exact movement of the Bone_CP, first we should estimate the approximate distance d from the skin surface to the relevant link of the skeleton.
Approach	The condition for non-self-intersection is to check if the local radius of curvature r at the joint is not less than d.
Approach	If we analyse the curve function, we can extract the exact expression from the position of Bone_CP, but because the distance d is only an approximate result, it may not fit exactly in the animation.
Approach	So here the floating position of the Bone_CP is left to the animator to define interactively ( Figure 1 -a2).
Approach	By providing the animator with more parameters, which he/she can tweak, we grant flexibility and freedom to adjust the animation.
Approach	One curve is generated.
Approach	In anatomical areas like the hip ( Figure 1b ), a fork exists in the joint chain.
Approach	Hence, three curves are generated, two curves starting from the central link to the two limbs linkage (in the example) and one curve linking the two links.
Approach	In the neck area, a cross exists in the joint chain.
Approach	Although it appears to have four links, we only need to generate two curves for the curve skeleton, as seen in Figure 1(c) .
Approach	As can be seen from the above classification, for a human character, we will use a maximum of three curves for each joint.
Approach	In most cases, one curve is sufficient.
Approach	In our method, the parameter t on the curve plays an important role in the deformation.
Approach	We use B-splines to represent the curve skeleton.
Approach	Similar to the joint-based skeleton, each point on the curve in a curve skeleton has a local frame (similar to a Frenet frame) defining the space transformation sampled at that point.
Approach	This local frame is a function of the parameter t of the curve point.
Approach	These points normally form the curve segment endings.
Approach	They can be easily found from the curve definition.
Approach	If the centre is lying on the curve, the deformed skin will move out from underneath the skeleton.
Approach	The underlying structures like muscles or bones will be exposed.
Approach	So here the centre of the local frame is translated on to the original skeleton shown in Figure 2b .
Approach	When the bone twists around its local x-axis, it will not have any effect on the associated curve skeleton.
Approach	This is not acceptable.
Approach	In order to remedy this problem, here on the curve skeleton we define two extra attributes, twist angle and twist distribution.
Approach	The twist angle can be easily queried from the associated joint.
Approach	The rotation angle is for the curve ending.
Approach	For each point on the curve, we still need a twist distribution to define how the curve twists along its path.
Approach	Normally it is not evenly distributed as can be seen from the twist of a forearm.
Approach	In order to perform even distribution of twisting, we provide the animator with the freedom to control how the curve twists by manipulating the distribution curve.
Approach	The distribution curve ( Figure 3a ) is very much like the animation curves in Maya.
Approach	Here the twist angle is distributed along the distribution curve so that the twisting is smooth and natural.
Approach	The process of skin binding is to transform each skin surface point hx,y,zi at the binding pose to the local frame coordinate system hi, t, u, di, where i is the index to the specified curve segment, t is the parameter along that curve segment, u is the rotation angle around the x-axis from the y-axis, d is the distance from the local frame centre.
Approach	Actually the triple parameter ht, u, di may be considered as being expressed in a cylindrical coordinate system.
Approach	The values ht, u, di can be easily computed if we can settle the associated curve segment.
Approach	Thus the challenging part of the work is to find the associated curve segment, and assign the weighting parameter for each curve segment—skin binding.
Background	There is a lot of work 16 associated with the traditional joint-based method, like the containment-binding algorithm, point-to-line mapping, Delaunay tetrahedralization.
Approach	The relevant default weight factors w i of a skin point for the ith curve segment is determined by the distance between the skin point concerned with the relevant curve segments.
Approach	If a skin point is related with only one curve, which represents the majority of cases, the weight factor is always 1.
Approach	For those skin points associated with two curve segments, the default weights are proportional to the distances to the relevant curve segments, that is, the further away a skin point is from the curve segment, the smaller the weight is.
Approach	This is also the case for any skin points associated with three curve segments.
Approach	In all cases, the summation of the weights are constrained to one, P w i 1⁄4 1.
Approach	The animator will have freedom to edit the weighting factors in the same way as the smooth skinning.
Approach	Given that we have a maximum of only three curve segments for each skin point, weight assignment for a skin point is simpler than the traditional smooth skinning method and the computation for skin deformation is computationally cheaper.
Approach	Smooth skinning usually involves three weights for each skin point and in many cases there could be as many as five weights.
Approach	This is worsened if additional joints are placed in order to remedy the unpleasant artefacts.
Approach	The more the joints, the trickier it is to determine the weight distribution.
Outcome	With our curved skeleton, this problem will almost certainly not arise.
Approach	Once the skin is bound with the curve skeleton, deforming the skin is pretty straightforward.
Approach	The local coordinates of each skin surface point are transformed with the associated local frame to obtain the new position in the world coordinate system.
Approach	So the new point P, is defined by X P 1⁄4 w i M ði;tÞ P Lðu;dÞ (3) i where w i is the weight for the specific curve segment i, M (i,t) is the new transformation matrix at the parameter t position along the curve segment i.
Approach	As discussed earlier, we use on average a smaller number of weights.
Approach	This leads to a smaller number of summation terms needed for the calculation of the deformed skin points (see Equation (3)).
Outcome	As a result, our computation speed is at the same order, but is slightly faster than that of the traditional smooth skinning technique.
Approach	So far, we have discussed how to realistically skin a character without taking into account the anatomical structures.
Background	But muscles will give an added layer of realism to the deformation, especially in regions where the skin is visibly influenced by the underneath muscles.
Outcome	With our curve skeleton technique, muscle deformation can be fully integrated where the muscles are driven and animated by our curve skeletons.
Background	One of the best third party muscle simulation systems available called muscleTK 17 deforms the muscle using the so-called action lines.
Background	The action line is basically a curve, which defines the direction of deformation.
Background	But the disadvantage is that the action line has to be manually animated each frame during animation.
Approach	Using the proposed curve skeleton, we can realistically deform not only the skin directly (as explained earlier), but also the muscles, in a unified manner.
Approach	Effectively, each action line is deformed by a curve skeleton, and the action line in turn deforms the muscle.
Outcome	Therefore, we can achieve sophisticated muscle deformations without the tediousness of animating the action lines manually every frame.
Approach	When the effect of a muscle bending around the joint or the bone is required, we can first transform the control points (CP) of the action line from world space to the associated curve skeleton local frame.
Approach	These CPs will then be transformed with the curve skeleton, resulting in the muscle bending around the joint or bone being automatically created ( Figure 3b ).
Background	Maya is the most widely used 3D animation package in the industry.
Background	In order for scalability and increasing the feature base of Maya, Autodesk has provided Maya APIs for developers to expand the functionality of Maya.
Approach	From an interface point of view, the artist basically works with normal edit point (EP) curve tools to generate the curves according to his/her wish.
Approach	Once the curve is selected and the plug-in activated, the curves become the skeleton for the skin mesh.
Approach	Internally, the curve cluster is bound to the joint skeleton so that any movement of the joints affects the curvature of the curve.
Approach	The local transformations of the curve points are applied to the skin mesh vertices thereby generating deformations on the skin.
Background	Skin deformation is closely linked with the movement of the skeleton of a character.
Challenge	It is understandable that the relationship between both is highly non-linear, which poses a challenge if the relationship is to be modeled mathematically correctly.
Background	Existing skeletondriven techniques regard it as a much-simplified linear problem, which however, has resulted in unrealistic skin deformation in certain regions of the character body.
Outcome	In this paper we have presented a technique, known as the curve skeleton based skinning, by considering it as a proper non-linear problem.
Outcome	The main advantage of this technique is its consistency with the current animation production practice and the ability to overcome the undesirable drawbacks of skeleton-driven skinning.
Outcome	From the algorithmic point of view, the technique reduces a level of complexity in the skinning and deformation.
Outcome	By layering the curve skeleton on top of the existing joint skeleton, we allow the animator to work conventionally (as in a joint-based system) and yet receive good results.
Outcome	Through a combination of existing practices and newly designed ones, we have successfully created a fusion, which maximizes the efficiency of surface deformation during animation.
Outcome	For an articulated character, we use no more than three weights for any skin point.
Outcome	In fact, for the majority of cases, there is only one weight, which is 1, to be is used.
Outcome	In comparison with the traditional smooth skinning technique that usually requires on average 3–5 weights, our computation speed is faster.
Outcome	One should not confuse the curve skeleton technique with the inverse kinematics (IK) spline handle tool provided by the animation package Maya.
Background	Despite their seeming similarity, the objective of the Maya IK spline handle tool is to control the joint positions using a spline.
Background	Skin deformation is achieved using the traditional smooth skinning technique.
Approach	Our curve skeleton is controlled by the joints of a character.
Approach	The skin is directly deformed by the curve skeleton.
Outcome	The Maya plug-in implementation of the curve skeleton technique has given satisfactory results.
Outcome	One of the main advantages of the curve skeleton skin deformation technique is that, the curve skeleton needs not necessarily be placed on the underlying joint skeleton.
Outcome	With a slight modification utilizing a linear mapping of curve points to the joint skeleton, the plug-in can make use of a displaced curve skeleton which would be useful for subtle deformation on anatomical areas like the armpits.
Outcome	Our current implementation allows both skin and muscle deformation to be modeled within a unified framework.
FutureWork	As future work, we will further improve the skinning realism by adding the fat effect.
Background	Fat usually deposits between the skin and the muscles.
Background	Effective realism occurs when the skin actually slides over the fat.
Background	This is especially true in the areas near joints where acute deformation happens.
Background	Turner and Thalmann 8 defines the fat layer as a thickness specified at each point on the skin surface and make use of reaction constraints to push the skin the required distance out from the underlying layers.
Background	Yang and Zhang 18 devises a fast method for simulating fat in which a fat bulge distribution function is described.
Background	They have used a geometric method instead of resorting to a physical simulation method, and gives convincing results without the computational expense of physical simulation.
FutureWork	With a small modification, the fat bulge effect can be made even in a curve skeleton-based skinning.
FutureWork	The function can be defined under the local frame of the curve skeleton.
Outcome	In the present context, since the skeleton is a curve, distribution and deformation can be linked with the tangent angle at a given number of curve points around the joints.
Background	As fat is largely incompressible, when a joint bends, flesh between the adjacent bones will be squeezed, producing bulges immediately near the joint and at the sides.
FutureWork	Using curve tangents will provide for an accurate distribution in any given time frame because of the integrated results from the sample multiple curve points.

Challenge	We present a technique which allows subtle nonlinear quasi-static deformations of articulated characters to be compactly approximated by data-dependent eigenbases which are optimized for real time rendering on commodity graphics hardware.
Outcome	The method extends the common Skeletal-Subspace Deformation (SSD) technique to provide efficient approximations of the complex deformation behaviours exhibited in simulated, measured, and artist-drawn characters.
Approach	Instead of storing displacements for key poses (which may be numerous), we precompute principal components of the deformation influences for individual kinematic joints, and so construct error-optimal eigenbases describing each joint’s deformation subspace.
Approach	Pose-dependent deformations are then expressed in terms of these reduced eigenbases, allowing precomputed coefficients of the eigenbasis to be interpolated at run time.
Approach	Vertex program hardware can then efficiently render nonlinear skin deformations using a small number of eigendisplacements stored in graphics hardware.
Outcome	We refer to the final resulting character skinning construct as the model’s EigenSkin.
Outcome	Animation results are presented for a very large nonlinear finite element model of a human hand rendered in real time at minimal cost to the main CPU.
Background	Significant work has occurred in graphics for deforming articulated characters using geometric methods [Magnenat-Thalmann et al. 1988; Singh and Kokkevis 2000; Lewis et al. 2000] and physicallybased methods [Wilhelms and van Gelder 1997; Scheepers et al. 1997; Gourret et al. 1989].
Background	Despite this, most character animation in interactive applications, such as video games, is based on a geometric skeletal deformation technique commonly referred to as linear blending, or matrix palette skinning, or Skeletal-Subspace Deformation (SSD), in which vertex locations are weighted averages of points in several coordinate frames (see [Magnenat-Thalmann et al. 1988; Magnenat-Thalmann and Thalmann 1991]).
Background	One alternative is to store a large database of character poses, and interpolate between them [Maestri 1999].
Background	While these approaches give animators great control over character deformation, they have the disadvantage of requiring a potentially very large number of poses for animation, and also lack an underlying kinematic model.
Background	Nevertheless, such approaches are common, especially for facial animation [Parke et al. 1996].
Background	A hybrid approach which effectively combines SSD and morphing, is the work of Lewis et al. who introduced “Pose Space Deformations” (PSD) [Lewis et al. 2000] to overcome the limitations of linear transform blending while retaining a kinematic approach.
Background	Starting with a (simple) SSD model, they then store vertex displacement offsets between the SSD surface and various character poses.
Background	At run time, the character may be simulated by mapping interpolated displacements onto the underlying SSD character model, thereby providing a kinematic deformation model which also has artist-drawn poses.
Background	While this is a big improvement over character morphing, and sufficiently interactive for animators, storing surface displacements for each pose in a large pose space is a memory inefficient approach for hardware applications.
Background	Similar to PSD, Sloan et al. show a more efficient method of interpolating an articulated figure using example shapes scattered in an abstract space [Sloan et al. 2001].
Background	The abstract space consists of dimensions describing global properties of the shape, such as age and gender, but also includes dimensions used to describe configuration, such as the amount of bend at an elbow.
Background	Like our method, interpolation occurs in the rest pose before SSD is applied, however, the interpolation involves blending over all of the example shapes for every vertex.
Background	This becomes inefficient and difficult to map to hardware with the large number of examples required for a highly articulated figure since the independence of abstract space dimensions is not taken into account (e.g., bend in left elbow and bend in right elbow).
Challenge	In addition to character poses created by 3D artists, we also wish to efficiently render deformation behaviour computed using physically-based and reality-based deformable models.
Background	Such models have been widely used [Terzopoulos and Fleischer 1988; Terzopoulos and Witkin 1988; Metaxas and Terzopoulos 1992; CaniGascuel 1998; O’Brien and Hodgins 1999; Pai et al. 2001; Allen et al. 2002], although most approaches are not intended for real time (hardware) rendering.
Background	Recently, approaches for fast simulation of physical dynamic volumetric deformations have appeared [Zhuang and Canny 1999; Debunne et al. 2001; Picinbono et al. 2001] for interactive applications, such as surgical simulation.
Background	Our interest is more closely related to quasi-static deformation, for which fast deformation techniques also exist [Cotin et al. 1999; James and Pai 1999] but are unfortunately restricted to small deformations unlike those associated with articulated characters (although see [James and Pai 2002b]).
Background	More closely related to character animation is anatomically based modeling of physical deformable models [Wilhelms and van Gelder 1997]; examples include musculature [Chen and Zeltzer 1992; Scheepers et al. 1997] and faces [Lee et al. 1995].
Background	We note that a large class of pose-dependent quasi-static deformations can be described using the EigenSkin approach, largely independent of their origin, whether artist-drawn, measured, or anatomically based physical models.
Background	For example, pose-space parameterization of nonhysteretic cloth on articulated characters has recently been considered [Herman 2001], and could be optimized for hardware rendering using the techniques presented herein.
Background	Finally, the use of reduced eigenbasis representations for highdimensional models has a long history in science, with foundations on Principal Component Analysis and Karhunen-Loeve theory [Jolliffe 1986; Hyvarinen et al. 2001].
Background	Related deformation topics include a morphable model for face synthesis [Blanz and Vetter 1999], modal analysis for dynamic vibrations [Pentland and Williams July 1989 ; James and Pai 2002a], decomposition of static deformations [Bookstein 1989], and recognition applications in computer vision, e.g., face recognition [Turk and Pentland 1991].
Outcome	We introduce a method for extending SSD that enhances its range of modeling capabilities at very little cost, and in a manner optimized for real time graphics hardware.
Outcome	EigenSkin constitutes an error-optimal set of eigenbases for approximating the original deformation model, for a given amount of per-vertex displacement memory.
Outcome	We illustrate our method by rendering a very large finite element model (which took several hundred hours to compute) at interactive rates on a PC with negligible cost to the main CPU.
Outcome	Using commodity graphics hardware, EigenSkin enables the simulation of subtle nonlinear surface deformations of geometrically complex models at little more than the cost of rendering.
Challenge	Rendering of complex physical deformation models for character animation remains a significant hurdle for interactive applications, but one that has been largely overcome for off-line animation.
Background	Currently, most real time character animation, e.g., for video games, is done using a very common linear transform blending technique called (among other things) Skeletal-Subspace Deformation (SSD) [Magnenat-Thalmann et al. 1988].
Background	It is extremely popular for its simplicity and plausibility, and is also widely supported by graphics hardware accelerators.
Background	While methods have been proposed to address this and have been effectively employed by the motion picture industry [Lewis et al. 2000], due to memory and graphics hardware constraints nearly all video game character animation is still done using traditional SSD.
Challenge	In this paper, we present a practical technique which overcomes all aforementioned SSD problems, and can be achieved using a memory-efficient linear correction to the traditional SSD method.
Outcome	The resulting EigenSkin construct allows subtle character deformations for skin and clothing, such as those derived from highly realistic artist-drawn poses, measurements from the real world, or laboriously computed anatomically and physically-based models.
Outcome	The deformations can be compactly represented in an efficient datadependent basis and rendered in real time using vertex shaders in commodity graphics hardware, e.g., see [Lindholm et al. 2001].
Approach	Our approach is to start with an artist’s SSD approximation of the character in question, as well as with geometry corresponding to particular key poses not well approximated by SSD.
Approach	Vertex displacements between a given pose and the SSD model are mapped back to the neutral character pose, providing a displacement field pose correction.
Approach	Instead of storing these displacement fields for each key pose and then interpolating between them at runtime, as in Pose Space Deformation (PSD) [Lewis et al. 2000], we use Principal Component Analysis (PCA) to construct an error-optimal eigendisplacement basis for representing this potentially large set of pose corrections.
Approach	However, we do not simply use PCA on the displacement field defined over the entire surface, since this would lead to a large number of important basis functions and be inefficient for hardware rendering.
Approach	Instead, we decompose the model into locally supported domains learned from the influence of individual joints on the displacement fields (described in detail in Section 2.2).
Outcome	The resulting memory sensitive set of locally supported eigendisplacement basis functions constitutes the EigenSkin approximation, and is well suited to rendering in graphics hardware.
Approach	Although the process is shown for displacements, it applies similarly to the construction of linear normal corrections, allowing EigenSkin to correct SSD for both shape and shading.
Approach	We compute our SSD bone weights as a function of vertex bone distances in the neutral pose.
Approach	This yields reasonable bone weights which change smoothly over the mesh.
Approach	Filtering may be required to force each bone’s weights to zero at the edges of its influence to prevent discontinuities.
FutureWork	In principle, the weights can be computed to optimize the quality of the EigenSkin correction, and this is a topic of future research.
Approach	Let P be the set of indices of observed poses with 0 ∈ P representing the rest pose and let the observed vertex positions and bone transforms for pose p ∈ P be denoted as v p and T p , respectively.
Approach	If the deformations vary smoothly over pose space, then interpolated displacements provide a good approximation of deformations at configurations between observations.
Approach	To make our hardware implementation possible, we exploit the observation that localized changes to the configuration of an articulated character often result in local deformations.
Background	This independence occurs in most articulated characters, and certainly exists in realistic human hands.
Background	Bending a single joint in one finger, though difficult without bending any other joints, does not cause noticeable deformations in the other fingers.
Approach	Likewise, bending one finger of our finite element hand model does not cause noticeable deformations in the others (see Figure 4 ).
Approach	Although the finite element model deformations resulting from a change to a single joint are global, the displacement magnitudes are imperceptible at vertices that are far from the joint.
Approach	We refer to the set of vertices significantly affected by a joint motion as the joint support.
Approach	Note that the joint supports depend on the SSD weights and in general they do not correspond to the sets of vertices influenced by bone transforms.
Approach	To find the support of a joint we compute the deformations that result from moving the joint to different positions in its full range of motion while keeping all other joints fixed to the rest pose position.
Approach	The set of vertices having a displacement larger than a given threshold in any of these computed poses then becomes the support of this joint.
Approach	For example, in our case we used four percent of the maximum observed displacement (we will see that memory constraints also play a large part).
Approach	Note that we consider only single joint perturbations due to the high dimensionality of our hand model’s configuration space.
Approach	Nevertheless, we can still approximate linear coupling effects since we let the joint supports overlap.
Approach	For notational convenience, suppose the articulated figure has a tree structure, i.e., does not have loops, such as for humanoids, and joints are denoted by the index of the adjacent bone furthest from the root of the hierarchy.
Approach	Denoting 0 ∈ B as the root, joints have nonzero index.
Approach	Let P j ⊂ P be the set of pose indices used to compute the support for joint j and let S j be the set of vertex indices in the joint support.
Approach	Furthermore, let J i be the set of joints whose supports contain vertex i.
Approach	That is, J i = { j|i ∈ S j } ⊂ B\{0}.
Background	Although the pose displacements computed for independently perturbed joints may be used as a basis for describing displacements of new configurations, significant redundancy exists in the pose displacements, e.g., skin bulging in similar directions.
Approach	Principal Component Analysis (PCA) of joint support displacements yields an orthogonal displacement basis, which we term eigendisplacements.
Approach	As guaranteed by PCA, adding successive corrections with the eigendisplacement basis provides approximations which are better in a formal, least squares, sense [Golub and van Loan 1996].
Approach	Computing principal components with the Euclidean norm is equivalent to computing the singular value decomposition (in the case of a square symmetric matrix it is equivalent to eigenanalysis).
Approach	For each joint j we construct a rectangular matrix, A j , of size 3|S j | × |P j |, whose columns consist of the x,y, and z components of the vertex displacements on the joint support.
Approach	In the singular value decomposition, A j = U j D j V T j , the matrix U j has the same size as A j and consists of columns of eigendisplacements for support j in the same block column format that was used to build A j .
Approach	The singular values, in the diagonal matrix D j , identify the importance that each eigendisplacement has in reproducing the observed poses (they relate to the proportion of variation explained by each principal component).
Approach	Note that the matrix V j and the singular values combine to gives the coordinates of our observed displacements in the eigendisplacement basis.
Approach	We denote u ˆ jk the eigendisplacement i of vertex i in the basis of support j with importance k where k goes from 1 (the principal component) up to |P j |.
Approach	At this point we can truncate each eigendisplacement basis expansion knowing that the error will be minimized in the least squares sense.
Approach	The hardware limits the size of each truncated basis set as there is a limited amount of per vertex data memory in which we can send the eigendisplacements to the EigenSkin vertex program (see Section 2.5).
Approach	Letting n j < |P j | be the size of the truncated basis set of joint support j, this constraint can be written as max n j |J i | ≤ maximum possible displacements.
Approach	i Instead of choosing each n j individually, we take an equal number of eigendisplacements from each support.
Approach	These coordinates are computed to interpolate between observed displacements, as shown below.
Approach	Note that Equation 2 provides a powerful model for shape deformation (see, in particular, [James and Pai 2002a]).
Approach	As an articulated character moves between observed configurations, its shape should interpolate the observed poses.
Approach	To do this we interpolate the eigendisplacement coordinates of the observed configurations.
Approach	For the truncated set of eigendisplacements at each support, we need the coordinates in the truncated basis which give displacements closest to the observed displacements.
Approach	Conveniently, the least squares solution for any number of eigendisplacements, n j , is available from the singular value decomposition computed in Section 2.3.
Approach	This leads us to the problem of computing the eigendisplacement coordinates for arbitrary configurations.
Background	Radial basis functions [Powell 1987] (RBF) are a common choice for interpolating scattered data, and have been used by Lewis et al. [Lewis et al. 2000] for pose space deformation and by Sloan et al. [Sloan et al. 2001] for shape interpolation with articulated figures.
Approach	Our interpolation is one dimensional since all our observations involved perturbations of individual joints.
Approach	Although we could use a simpler interpolant, we also choose RBFs because they extend easily to the higher dimensional domains needed to let EigenSkin capture nonlinear multi-joint coupling effects (a subject of future work).
Approach	We use Gaussian interpolation shape functions, φ (r) = exp(−r/r 0 ).
Approach	In our one dimensional case, the α jk only depend on the distance of joint j from its settings in poses P j .
Approach	For revolute joints, we can easily compute the distance, r, by comparing the joint angles directly.
Approach	For joints with more than one rotational degree of freedom, we compute distance as the angle in the axis-angle representation of the joint’s rotation matrix.
Approach	Ideally, with a large number of observed joint perturbations per support we would interpolate using fewer interpolation basis functions ( φ ) than observations.
Approach	In the case of our hand model, however, we only have approximately half a dozen pose perturbations for each joint degree of freedom (for a total of approximately 120 poses).
Approach	This justifies our use of interpolation basis functions since the total cost of constructing and evaluating the RBF interpolant for half a dozen poses is negligible.
Background	Modern vertex programming hardware (e.g., [Lindholm et al. 2001]) is ideally suited to performing the per-vertex weighted linear superposition of eigendisplacements (contained in the large brackets of Equation 2) performed prior to the SSD weighted transformation.
Background	Depending on the number of eigendisplacements used, the weighted eigendisplacement vector accumulations are about as costly as the weighted transform matrix-vector multiplyaccumulate operations.
Background	Current vertex programs limit per vertex data to 16 4-tuples of floats.
Approach	In our implementation we impose a limit of 10 eigendisplacements per vertex (or 5 eigendisplacements and 5 normal corrections), which still leaves room for texture coordinates after specifying the vertex position, normal, colour, and bone weights.
Approach	Notice that this limit is not hard since careful choices and packing of per vertex data permit more than 10 of the 16 available tuples to be allocated for EigenSkin data.
Approach	If a vertex is in many supports then the number of eigendisplacements renderable by current hardware may be too severely restricted.
Approach	In this case it is useful to smoothly mask the support groups to smaller regions, otherwise fewer eigendisplacements must be used.
Approach	To illustrate our EigenSkin method, we have constructed a finite element model of the human hand (see Figure 6 ) which exhibits subtle nonlinear skin deformations.
Approach	The surface skin model and matching skeleton are based on Loop subdivision [Loop 1987] of a hand mesh exported from Curious Labs Poser [Curious Labs Inc.
Approach	A finite element mesh containing 11,171 high-order 10-node tetrahedral elements was generated using NETGEN [Schoberl 1997] (and subsequent simplification).
Approach	The hand was moved into various poses by applying position constraints to vertices adjacent to the rigid bones, and computing the resulting tissue deformation using geometrically nonlinear static finite element analyses [Zienkiewicz 1977] with (a modified version of) the CalculiX program [Dhondt and Wittig].
Approach	Approximately half a dozen poses were computed for each joint degree of freedom to estimate the locally supported joint eigendisplacements, and 25 additional poses were computed for validation.
Approach	Finite element analyses were performed on a cluster of modern workstations and consumed several hundred CPU hours.
Outcome	Despite these limitations, the model reasonably describes bulk tissue deformations and was sufficient to illustrate our method.
Outcome	As shown in Figure 7 , the eigendisplacement approximations of the hand model produce a clear improvement over the traditional SSD algorithm.
Outcome	Even with only five leading eigendisplacements, the EigenSkin approximation is essentially indistinguishable from the original FEM model.
Approach	Our interactive simulation uses a CyberGlove [Immersion Corporation] input device to interactively drive our EigenSkin hand model, while graphical feedback is rendered using OpenGL and a GeForce3 graphics card.
Approach	Radial basis function interpolation of the pose-space data is performed on the main CPU, with eigendisplacement amplitudes and bone transforms set as input parameters to the EigenSkin vertex programs which are compiled as static display lists.
Outcome	Currently, our unoptimized implementation renders the EigenSkinned hand model only slightly slower than the traditional SSD model.
Outcome	A large 55,904 triangle hand model renders at 47 frames per second (FPS), while a coarser 13,976 triangle model achieves 181 FPS.
Outcome	Our results confirm that the EigenSkin method is an effective tool for character skinning when compressed hardware renderable approximations are required for an articulated character’s nonlinear quasi-static deformations.
Outcome	EigenSkin works best when SSD corrections are localized, providing independence between different parts of the mesh, and are stable (i.e., corrections vary slowly over posespace), allowing accurate and efficient interpolation.
Outcome	We assume that an initial SSD model is provided and then show how the EigenSkin corrections are beneficial.
FutureWork	However, an alternate approach involves optimizing bone weights to allow better EigenSkin approximations of the displacements and normals.
FutureWork	While good eigendisplacement bases can often be constructed using displacements resulting from single joint motions, in practice it is desirable to allow general pose sets and to recover nonlinear joint-joint coupling phenomena.

Challenge	We present a method for animating characters automatically.
Approach	Given a static character mesh and a generic skeleton, our method adapts the skeleton to the character and attaches it to the surface, allowing skeletal motion data to animate the character.
Outcome	Because a single skeleton can be used with a wide range of characters, our method, in conjunction with a library of motions for a few skeletons, enables a user-friendly animation system for novices and children.
Outcome	Our prototype implementation, called Pinocchio, typically takes under a minute to rig a character on a modern midrange PC.
Background	Modeling in 3D is becoming much easier than before.
Background	User-friendly systems such as Teddy [Igarashi et al. 1999] and Cosmic Blobs ( http://www.cosmicblobs.com/) have made the creation of 3D characters accessible to novices and children.
Challenge	Bringing these static shapes to life, however, is still not easy.
Background	In a conventional skeletal animation package, the user must rig the character manually.
Background	This requires placing the skeleton joints inside the character and specifying which parts of the surface are attached to which bone.
Challenge	The tedium of this process makes simple character animation more difficult than it could be.
Challenge	We envision a system that eliminates this tedium to make animation more accessible for children, educators, researchers, and other non-expert animators.
Challenge	For example, a child should be able to model a unicorn, click the “Quadruped Gallop” button, and watch the unicorn start galloping.
Approach	To support this functionality, we need a method (as shown in Figure 1 ) that takes a character, a skeleton, and a motion of that skeleton as input, and outputs the moving character.
Background	The missing portion is the rigging: motion transfer has been addressed in prior work [Gleicher 2001].
Approach	Our algorithm consists of two main steps: skeleton embedding and skin attachment.
Approach	Skeleton embedding computes the joint positions of the skeleton inside the character by minimizing a penalty function.
Approach	To make the optimization problem computationally feasible, we first embed the skeleton into a discretization of the character’s interior and then refine this embedding using continuous optimization.
Approach	The skin attachment is computed by assigning bone weights based on the proximity of the embedded bones smoothed by a diffusion equilibrium equation over the character’s surface.
Approach	Our design decisions relied on three criteria, which we also used to evaluate our system:
Challenge	A key design challenge is constructing a penalty function that penalizes undesirable embeddings and generalizes well to new characters.
Approach	For this, we designed a maximum-margin supervised learning method to combine a set of hand-constructed penalty functions.
Approach	To ensure an honest evaluation and avoid overfitting, we tested our algorithm on 16 characters that we did not see or use during development.
Outcome	Our algorithm computed a good rig for all but 3 of these characters.
Outcome	For each of the remaining cases, one joint placement hint corrected the problem.
Approach	We simplify the problem by making the following assumptions.
Approach	The character mesh must be the boundary of a connected volume.
Approach	The character must be given in approximately the same orientation and pose as the skeleton.
Approach	Lastly, the character must be proportioned roughly like the given skeleton.
Approach	• An A ∗ -like heuristic to accelerate the search for an optimal skeleton embedding over an exponential search space (Section 3.4).
Approach	• Use of Laplace’s diffusion equation to generate weights for attaching mesh vertices to the skeleton using linear blend skinning (Section 4).
Approach	This method could also be useful in existing 3D packages.
Outcome	Our prototype system, called Pinocchio, rigs the given character using our algorithm.
Outcome	It then transfers a motion to the character using online motion retargetting [Choi and Ko 2000] to eliminate footskate by constraining the feet trajectories of the character to the feet trajectories of the given motion.
Background	Recent exceptions include Motion Doodles [Thorne et al. 2004] as well as the work of Igarashi et al. on spatial keyframing [2005b] and as-rigid-as-possible shape manipulation [2005a].
Background	These approaches focus on simplifying animation control, rather than simplifying the definition of the articulation of the character.
Background	In particular, a spatial keyframing system expects an articulated character as input, and as-rigid-as-possible shape manipulation, besides being 2D, relies on the constraints to provide articulation information.
Background	The Motion Doodles system has the ability to infer the articulation of a 2D character, but their approach relies on very strong assumptions about how the character is presented.
Background	A few approaches to the skeleton extraction problem are representative.
Background	Teichmann and Teller [1998] extract a skeleton by simplifying the Voronoi skeleton with a small amount of user assistance.
Background	Liu et al. [2003] use repulsive force fields to find a skeleton.
Background	In their paper, Katz and Tal [2003] describe a surface partitioning algorithm and suggest skeleton extraction as an application.
Background	The technique in Wade [2000] is most similar to our own: like us, they approximate the medial surface by finding discontinuities in the distance field, but they use it to construct a skeleton tree.
Challenge	For the purpose of automatically animating a character, however, skeleton embedding is much more suitable than extraction.
Challenge	For example, the user may have motion data for a quadruped skeleton, but for a complicated quadruped character, the extracted skeleton is likely to have a different topology.
Background	The anatomically appropriate skeleton generation by Wade [2000] ameliorates this problem by techniques such as identifying appendages and fitting appendage templates, but the overall topology of the resulting skeleton may still vary.
Background	For example, for the character in Figure 1 , ears may be mistaken for arms.
Background	Another advantage of embedding over extraction is that the given skeleton provides information about the expected structure of the character, which may be difficult to obtain from just the geometry.
Challenge	So although we could use an existing skeleton extraction algorithm and embed our skeleton into the extracted one, the results would likely be undesirable.
Challenge	For example, the legs of the character in Figure 1 would be too short if a skeleton extraction algorithm were used.
Background	Most of the work has been focused on human models, making use of human anatomy specifics, e.g. [Moccozet et al. 2004].
Background	For segmenting and animating simple 3D models of characters and inanimate objects, Anderson et al. [2000] fit voxel-based volumetric templates to the data.
Background	Teichmann and Teller [1998] propose a spring-based method.
Background	Unfortunately, at present, these methods are unsuitable for real-time animation of even moderate size meshes.
Background	Because of its simplicity and efficiency (and simple GPU implementation), and despite its quality shortcomings, linear blend skinning (LBS), also known as skeleton subspace deformation, remains the most popular method used in practice.
Background	Most real-time skinning work, e.g. [Kry et al. 2002; Wang et al. 2007], has focused on improving on LBS by inferring the character articulation from multiple example meshes.
Challenge	However, such techniques are unsuitable for our problem because we only have a single mesh.
Challenge	Instead, we must infer articulation by using the given skeleton as an encoding of the likely modes of deformation, not just as an animation control structure.
Challenge	To our knowledge, the problem of finding bone weights for LBS from a single mesh and a skeleton has not been sufficiently addressed in the literature.
Background	Previous methods are either mesh resolution dependent [Katz and Tal 2003] or the weights do not vary smoothly along the surface [Wade 2000], causing artifacts on highresolution meshes.
Background	Some commercial packages use proprietary methods to assign default weights.
Background	For example, Autodesk Maya 7 assigns weights based solely on the vertex proximity to the bone, ignoring the mesh structure, which results in serious artifacts when the mesh intersects the Voronoi diagram faces between logically distant bones.
Background	Skeleton embedding resizes and positions the given skeleton to fit inside the character.
Challenge	This can be formulated as an optimization problem: “compute the joint positions such that the resulting skeleton fits inside the character as nicely as possible and looks like the given skeleton as much as possible.
Challenge	” For a skeleton with s joints (by “joints,” we mean vertices of the skeleton tree, including leaves), this is a 3s-dimensional problem with a complicated objective function.
Challenge	Solving such a problem directly using continuous optimization is infeasible.
Approach	Pinocchio therefore discretizes the problem by constructing a graph whose vertices represent potential joint positions and whose edges are potential bone segments.
Challenge	This is challenging because the graph must have few vertices and edges, and yet capture all potential bone paths within the character.
Approach	The graph is constructed by packing spheres centered on the approximate medial surface into the character and by connecting sphere centers with graph edges.
Approach	Pinocchio then finds the optimal embedding of the skeleton into this graph with respect to a discrete penalty function.
Approach	It uses the discrete solution as a starting point for continuous optimization.
Approach	To help with optimization, the given skeleton can have a little extra information in the form of joint attributes: for example, joints that should be approximately symmetric should be marked as such; also some joints can be marked as “feet,” indicating that they should be placed near the bottom of the character.
Approach	We describe the attributes Pinocchio uses in a supplemental document[Baran and Popović 2007a].
Approach	These attributes are specific to the skeleton but are independent of the character shape and do not reduce the generality of the skeletons.
Approach	Before any other computation, Pinocchio rescales the character to fit inside an axis-aligned unit cube.
Approach	As a result, all of the tolerances are relative to the size of the character.
Approach	It constructs a kd-tree to evaluate the exact signed distance to the surface from an arbitrary point.
Approach	It then constructs the distance field from the top down, starting with a single octree cell and splitting a cell until the exact distance is within a tolerance τ of the interpolated distance.
Approach	We found that τ = 0.003 provides a good compromise between accuracy and efficiency for our purposes.
Approach	Because only negative distances (i.e. from points inside the character) are important, Pinocchio does not split cells that are guaranteed not to intersect the character’s interior.
Approach	The medial surface is the set of C 1 discontinuities of the distance field.
Approach	Within a single cell of our octree, the interpolated distance field is guaranteed to be C 1 , so it is necessary to look at only the cell boundaries.
Approach	Pinocchio therefore traverses the octree and for each cell, looks at a grid (of spacing τ ) of points on each face of the cell.
Approach	It then computes the gradient vectors for the cells adjacent to each grid point—if the angle between two of them is 120 ◦ or greater, it adds the point to the medial surface sample.
Approach	We impose the 120 ◦ condition because we do not want the “noisy” parts of the medial surface—we want the points where skeleton joints are likely to lie.
Approach	For the same reason, Pinocchio filters out the sampled points that are too close to the character surface (within 2τ ).
Background	Wade discusses a similar condition in Chapter 4 of his thesis [2000].
Approach	Then it processes these points in order and if a point is outside all previously added spheres, adds the sphere centered at that point whose radius is the distance to the surface.
Approach	In other words, the largest spheres are added first, and no sphere contains the center of another sphere ( Figure 3 ).
Approach	In fact, this step typically takes less than 1% of the time of the entire algorithm.
Approach	Pinocchio adds an edge between two sphere centers if the spheres intersect.
Approach	We would also like to add edges between spheres that do not intersect if that edge is well inside the surface and if that edge is “essential.
Approach	” For example, the neck and left shoulder spheres of the character in Figure 3 are disjoint, but there should still be an edge between them.
Approach	The precise condition Pinocchio uses is that the distance from any point of the edge to the surface must be at least half of the radius of the smaller sphere, and the closest sphere centers to the midpoint of the edge must be the edge endpoints.
Approach	The latter condition is equivalent to the requirement that additional edges must be in the Gabriel graph of the sphere centers (see e.g. [Jaromczyk and Toussaint 1992]).
Approach	While other conditions can be formulated, we found that the Gabriel graph provides a good balance between sparsity and connectedness.
Approach	Pinocchio precomputes the shortest paths between all pairs of vertices in this graph to speed up penalty function evaluation.
Approach	The discretization stage constructs a geometric graph into which Pinocchio needs to embed the given skeleton in an optimal way.
Approach	The skeleton is given as a rooted tree on s joints.
Approach	To reduce the degrees of freedom, for the discrete embedding, Pinocchio works with a reduced skeleton, in which all bone chains have been merged (all degree two joints, such as knees, eliminated), as shown in Figure 5 .
Approach	The reduced skeleton thus has only r joints.
Approach	This works because once Pinocchio knows where the endpoints of a bone chain are in V , it can compute the intermediate joints by taking the shortest path between the endpoints and splitting it in accordance with the proportions of the unreduced skeleton.
Approach	For the humanoid skeleton we use, for example, s = 18, but r = 7; without a reduced skeleton, the optimization problem would typically be intractable.
Approach	Therefore, the discrete skeleton embedding problem is to find the embedding of the reduced skeleton into G, represented by an rtuple v = (v 1 , . . . , v r ) of vertices in V , which minimizes a penalty function f (v) that is designed to penalize differences in the embedded skeleton from the given skeleton.
Approach	The discrete penalty function has great impact on the generality and quality of the results.
Approach	A good embedding should have the proportions, bone orientations, and size similar to the given skeleton.
Approach	The paths representing the bone chains should be disjoint, if possible.
Approach	Joints of the skeleton may be marked as “feet,” in which case they should be close to the bottom of the character.
Approach	Designing a penalty function that satisfies all of these requirements simultaneously is difficult.
Approach	Instead we found it easier to design penalties independently and then rely on learning a proper weighting for a global penalty that combines each term.
Approach	Pinocchio uses k = 9 basis penalty functions constructed by hand.
Approach	They penalize short bones, improper orientation between joints, length differences in bones marked symmetric, bone chains sharing vertices, feet away from the bottom, zero-length bone chains, improper orientation of bones, degree-one joints not embedded at extreme vertices, and joints far along bone-chains but close in the graph [Baran and Popović 2007a].
Approach	We determine the weights Γ = (γ 1 , . . . , γ k ) semi-automatically via a new maximum margin approach inspired by support vector machines.
Approach	Suppose that for a single character, we have several example embeddings, each marked “good” or “bad”.
Approach	The basis penalty functions assign a feature vector b(v) = (b 1 (v), . . . , b k (v)) to each example embedding v.
Approach	Let p 1 , . . . , p m be the k-dimensional feature vectors of the good embeddings and let q 1 , . . . , q n be the feature vectors of the bad embeddings.
Background	See Burges [1998] for a much more complete tutorial.
Approach	If our goal were to automatically classify new embeddings into “good” and “bad” ones, we could use a support vector machine to learn a maximum margin linear classifier.
Approach	In its simplest form, a support vector machine finds the hyperplane that separates the p i ’s from the q i ’s and is as far away from them as possible.
Approach	More precisely, if Γ is a k-dimensional vector with Γ = 1, the classification margin of the best hyperplane normal to Γ is 1 2 ` min n i=1 Γ T q i − max m i=1 Γ T p i  ́ .
Approach	Recalling that the total penalty of an embedding v is Γ T b(v), we can think of the maximum margin Γ as the one that best distinguishes between the best “bad” embedding and the worst “good” embedding in the training set.
Approach	In our case, however, we do not need to classify embeddings, but rather find a Γ such that the embedding with the lowest penalty f (v) = Γ T b(v) is likely to be good.
Approach	To this end, we want Γ to distinguish between the best “bad” embedding and the best “good” embedding, as illustrated in Figure 6 .
Approach	We therefore wish to maximize the optimization margin (subject to Γ = 1), which we define as: n m min Γ T q i − min Γ T p i .
Approach	The key difference is that structured classification requires an explicit loss function (in our case, the knowledge of the quality of all possible skeleton embeddings for each character in the training set), whereas our approach only makes use of the loss function on the training labels and allows for the possibility of multiple correct labels.
Approach	This possibility of multiple correct skeleton embeddings prevented us from formulating our margin maximization problem as a convex optimization problem.
Approach	However, multiple correct skeleton embeddings are necessary for our problem in cases such as the hand joint being embedded into different fingers.
Approach	However, an approximately optimal Γ is acceptable, and the search space dimension is sufficiently low (9 in our case) that it is feasible to use a continuous optimization method.
Approach	We use the Nelder-Mead method [Nelder and Mead 1965] starting from random Γ’s.
Approach	We start with a cube [0, 1] k , pick random normalized Γ’s, and run Nelder-Mead from each of them.
Approach	We then take the best Γ, use a slightly smaller cube around it, and repeat.
Approach	To create our training set of embeddings, we pick a training set of characters, manually choose Γ, and use it to construct skeleton embeddings of the characters.
Approach	For every character with a bad embedding, we manually tweak Γ until a good embedding is produced.
Approach	We then find the maximum margin Γ as described above and use this new Γ to construct new skeleton embeddings.
Approach	We manually classify the embeddings that we have not previously seen, augment our training set with them, and repeat the process.
Approach	For training, we used 62 different characters (Cosmic Blobs models, free models from the web, scanned models, and Teddy models), and Γ was stable with about 400 embeddings.
Approach	The weights we learned resulted in good embeddings for all of the characters in our training set; we could not accomplish this by manually tuning the weights.
Approach	Examining the optimization results and the extremal embeddings also helped us design better basis penalty functions.
Approach	Although this process of finding the weights is labor-intensive, it only needs to be done once.
Outcome	According to our tests, if the basis functions are carefully chosen, the overall penalty function generalizes well to both new characters and new skeletons.
Outcome	Therefore, a novice user will be able to use the system, and more advanced users will be able to design new skeletons without having to learn new weights.
Approach	However, if it is easy to estimate a good lower bound on f from a partial embedding (of the first few joints), it is possible to use a branch-and-bound method.
Approach	Pinocchio uses this idea: it maintains a priority queue of partial embeddings ordered by their lower bound estimates.
Approach	At every step, it takes the best partial embedding from the queue, extends it in all possible ways with the next joint, and pushes the results back on the queue.
Approach	The first full embedding extracted is guaranteed to be the optimal one.
Approach	This is essentially the A* algorithm on the tree of possible embeddings.
Approach	To speed up the process and conserve memory, if a partial embedding has a very high lower bound, it is rejected immediately and not inserted into the queue.
Approach	We considered adapting an approximate graph matching algorithm, like [Gold and Rangarajan 1996], which would work much faster and enable more complicated reduced skeletons.
Approach	The joints of the skeleton are given in order, which induces an order on the joints of the reduced skeleton.
Approach	Referring to the joints by their indices (starting with the root at index 1), we define the parent function p R on the reduced skeleton, such that p R (i) (for 1 < i ≤ r) is the index of the parent of joint i.
Approach	We require that the order in which the joints are given respects the parent relationship, i.e. p R (i) < i.
Approach	Our penalty function (f ) can be expressed as the sum of independent functions of bone chain endpoints (f i ’s) and a term (f D ) that incorporates the dependence between different joint positions.
Approach	The dependence between joints that have not been embedded can be ignored to obtain a lower bound on f .
Approach	Because of this lower bound estimate, the order in which joints are embedded is very important to the performance of the optimization algorithm.
Approach	High degree joints should be embedded first because they result in more terms in the rightmost sum of the lower bound, leading to a more accurate lower bound.
Approach	For example, our biped skeleton has only two joints of degree greater than two, so after Pinocchio has embedded them, the lower bound estimate includes f i terms for all of the bone chains.
Approach	In such cases it is possible for the user to provide manual hints in the form of constraints for reduced skeleton joints.
Approach	For example, such a hint might be that the left hand of the skeleton should be embedded at a particular vertex in G (or at one of several vertices).
Approach	Embeddings that do not satisfy the constraints are simply not considered by the algorithm.
Approach	Pinocchio takes the optimal embedding of the reduced skeleton found by discrete optimization and reinserts the degree-two joints by splitting the shortest paths in G in proportion to the given skeleton.
Approach	The resulting skeleton embedding should have the general shape we are looking for, but typically, it will not fit nicely inside the character.
Approach	Also, smaller bones are likely to be incorrectly oriented because they were not important enough to influence the discrete optimization.
Approach	Embedding refinement corrects these problems by minimizing a new continuous penalty function ( Figure 7 ).
Approach	For the continuous optimization, we represent the embedding of the skeleton as an s-tuple of joint positions (q 1 , . . . , q s ) in R 3 .
Approach	Because we are dealing with an unreduced skeleton, and discrete optimization has already found the correct general shape, the penalty function can be much simpler than the discrete penalty function.
Approach	The continuous penalty function g that Pinocchio tries to minimize is the sum of penalty functions over the bones plus an asymmetry penalty: where p S is the parent function for the unreduced skeleton (analogous to p R ).
Approach	Each g i penalizes bones that do not fit inside the surface nicely, bones that are too short, and bones that are oriented differently from the given skeleton: g i = α S g i S + α L g i L + α O g i O .
Approach	Unlike the discrete case, we choose the α’s by hand because there are only four of them [Baran and Popović 2007a].
Approach	Any continuous optimization technique [Gill et al. 1989] should produce good results.
Approach	Pinocchio uses a gradient descent method that takes advantage of the fact that there are relatively few interactions.
Approach	As a subroutine, it uses a step-doubling line search: starting from a given point (in R 3s ), it takes steps in the given optimization direction, doubling step length until the penalty function increases.
Approach	Pinocchio intersperses a line search in the gradient direction with line searches in the gradient direction projected onto individual bones.
Approach	Repeating the process 10 times is usually sufficient for convergence.
Approach	The character and the embedded skeleton are disconnected until skin attachment specifies how to apply deformations of the skeleton to the character mesh.
Approach	Although we could make use of one of the various mesh editing techniques for the actual mesh deformation, we choose to focus on the standard linear blend skinning (LBS) method because of its widespread use.
Approach	If v j is the position of vertex j, T i is the transformation of the i th bone, and w j i is the weight of the i th bone for vertex j, LBS gives the position of the transformed vertex j as P i w j i T i (v j ).
Approach	The attachment problem is finding bone weights w i for the vertices—how much each bone transform affects each vertex.
Approach	There are several properties we desire of the weights.
Approach	First of all, they should not depend on the mesh resolution.
Approach	Second, for the results to look good, the weights need to vary smoothly along the surface.
Approach	Finally, to avoid folding artifacts, the width of a transition between two bones meeting at a joint should be roughly proportional to the distance from the joint to the surface.
Approach	Although a scheme that assigns bone weights purely based on proximity to bones can be made to satisfy these properties, such schemes will often fail because they ignore the character’s geometry: for example, part of the torso may become attached to an arm.
Approach	Instead, we use the analogy to heat equilibrium to find the weights.
Approach	Suppose we treat the character volume as an insulated heat-conducting body and force the temperature of bone i to be 1 while keeping the temperature of all of the other bones at 0.
Approach	Then we can take the equilibrium temperature at each vertex on the surface as the weight of bone i at that vertex.
Approach	Solving for heat equilibrium over a volume would require tessellating the volume and would be slow.
Approach	Therefore, for simplicity, Pinocchio solves for equilibrium over the surface only, but at some vertices, it adds the heat transferred from the nearest bone.
Approach	It uses the precomputed distance field to determine whether a line segment is entirely contained in the character volume.
Approach	For c ≈ 0.22, this method gives weights with similar transitions to those computed by finding the equilibrium over the volume.
Approach	Pinocchio uses c = 1 (corresponding to anisotropic heat diffusion) because the results look more natural.
Approach	When k bones are equidistant from vertex j, heat contributions from all of them are used: p j is 1/k for all of them, and H jj = kc/d(j) 2 .
Approach	Equation (1) is a sparse linear system, and the left hand side matrix −∆ + H does not depend on i, the bone we are interested in.
Approach	Thus we can factor the system once and back-substitute to find the weights for each bone.
Background	Botsch et al. [2005] show how to use a sparse Cholesky solver to compute the factorization for this kind of system.
Approach	Pinocchio uses the TAUCS [Toledo 2003] library for this computation.
Approach	Note also that the weights w i sum to 1 for each vertex: if we sum (1) over i, we get (−∆ + H) P i w i = H · 1, which yields P i w i = 1.
Approach	It is possible to speed up this method slightly by finding vertices that are unambiguously attached to a single bone and forcing their weight to 1.
Background	An earlier variant of our algorithm did this, but the improvement was negligible, and this introduced occasional artifacts.
Approach	We evaluate Pinocchio with respect to the three criteria stated in the introduction: generality, quality, and performance.
Approach	To ensure an objective evaluation, we use inputs that were not used during development.
Approach	To this end, once the development was complete, we tested Pinocchio on 16 biped Cosmic Blobs models that we had not previously tried.
Outcome	The skeleton was correctly embedded into 13 of these models (81% success).
Outcome	For Models 7, 10 and 13, a hint for a single joint was sufficient to produce a good embedding.
Outcome	These tests demonstrate the range of proportions that our method can tolerate: we have a well-proportioned human (Models 1–4, 8), large arms and tiny legs (6; in 10, this causes problems), and large legs and small arms (15; in 13, the small arms cause problems).
Outcome	For other characters we tested, skeletons were almost always correctly embedded into well-proportioned characters whose pose matched the given skeleton.
Outcome	Pinocchio was even able to transfer a biped walk onto a human hand, a cat on its hind legs, and a donut.
Outcome	Characters with extremely thin limbs often fail because the the graph we extract is disconnected.
Outcome	Reducing τ , however, hurts performance.
Outcome	• Degree 2 joints such as knees and elbows are often positioned incorrectly within a limb.
Outcome	We do not know of a reliable way to identify the right locations for them: on some characters they are thicker than the rest of the limb, and on others they are thinner.
Outcome	Although most of our tests were done with the biped skeleton, we have also used other skeletons for other characters ( Figure 10 ).
Outcome	Our video [Baran and Popović 2007b] demonstrates the quality of the animation produced by Pinocchio.
Outcome	The quality problems of our attachment are a combination of the deficiencies of our automated weights generation as well as those inherent in LBS.
Outcome	A common class of problems is caused by Pinocchio being oblivious to the material out of which the character is made: the animation of both a dress and a knight’s armor has an unrealistic, rubbery quality.
Outcome	Other problems occur at difficult areas, such as hips and the shoulder/neck region, where hand-tuned weights could be made superior to those found by our algorithm.
Outcome	Table 1 shows the fastest and slowest timings of Pinocchio rigging the 16 models discussed in Section 5.1 on a 1.73 MHz Intel Core Duo with 1GB of RAM.
Outcome	Pinocchio is single-threaded so only one core was used.
Outcome	We did not run timing tests on denser models because someone wishing to create real-time animation is likely to keep the triangle count low.
Outcome	Also, because of our volume-based approach, once the distance field has been computed, subsequent discretization and embedding steps do not depend on the given mesh size.
Outcome	Embedding refinement takes about 1.2 seconds for all of these models, and the discrete optimization consumes the rest of the embedding time.
Outcome	We have presented the first method for automatically rigging an unfamiliar character for skeletal animation.
Outcome	We have shown that using this method, Pinocchio can animate a wide range of characters.
Outcome	We also believe that some of our techniques, such as finding LBS weights and using examples to learn the weights of a linear combination of penalty functions, can be useful in other contexts.
FutureWork	We have several ideas for improving Pinocchio that we have not yet tried.
FutureWork	Discretization could be improved by packing ellipsoids instead of spheres.
FutureWork	Although this is more difficult, we believe it would greatly reduce the size of the graph, resulting in faster and higher quality discrete embeddings.
FutureWork	Animation quality can be improved with a better skinning model [Kavan and Zára ˇ 2005] (although possibly at the cost of performance).
FutureWork	One approach would be to use a technique [Wang et al. 2007] that corrects LBS errors by using example meshes, which we could synthesize using slower, but more accurate deformation techniques.
FutureWork	A more involved approach would be automatically building a tetrahedral mesh around the embedded skeleton and applying the dynamic deformation method of Capell et al. [2002].
FutureWork	Combining retargetting with joint limits should eliminate some artifacts in the motion.
FutureWork	A better retargetting scheme could be used to make animations more physically plausible and prevent global self-intersections.
FutureWork	Finally, it would be nice to eliminate the assumption that the character must have a well-defined interior.
FutureWork	Beyond Pinocchio’s current capabilities, an interesting problem is dealing with hand animation to give animated characters the ability to grasp objects, type, or speak sign language.
FutureWork	The variety of types of hands makes this challenging (see, for example, Models 13, 5, 14, and 11 in Figure 9 ).
FutureWork	Automatically rigging characters for facial animation is even more difficult, but a solution requiring a small amount of user assistance may succeed.
FutureWork	Combined with a system for motion synthesis [Arikan et al. 2003], this would allow users to begin interacting with their creations.

Outcome	A data-driven approach for real-time processing of clothes, particularly suitable for simulating dresses worn by virtual characters, is proposed.
Approach	It starts, prior to realtime simulation, by analyzing cloth behavior in relation to the underlying skeleton movement from a pre-simulated sequence of the cloth obtained using any high quality offline simulators.
Challenge	The idea is to use this analysis to find an optimal combination of physics-based simulation and geometric approximation of the simulator; potentially colliding regions are defined on the cloth such that they will hold true for the skeleton movement that closely matches that of pre-simulated sequence.
Outcome	At runtime, using these analyses, our simulation process provides both visually pleasing results and performance, as long as the motion of the character remains sufficiently close to the original sequence used for the pre-computation.
Outcome	The key contributions of this paper are (1) efficient collision handling that prunes out potentially colliding objects by using the off-line simulation sequence as examples; (2) data-driven fix-up process for the coarse mesh simulation that deduces the gross behavior of the cloth; and (3) geometric approximation of the fine mesh deformation, responsible for details in the shape of the cloth such as wrinkles.
Background	The problem of simulating the behavior of clothes is one subject the graphics community has been grappling with since almost two decades ago [19] [21].
Challenge	Relatively little emphasis has been placed on the separate problem of how to achieve real-time performance in simulating cloth.
Background	A number of strategies have been suggested, such as using simplifying assumptions for the physics model and/or collision detection [ 7 ] [12].
Background	A recent work by James et al. [10] suggests a different approach by adopting a data-driven method.
Background	These techniques do not suffice, however, when simulating fully dressed virtual characters in real-time, leaving the topic unexplored.
Outcome	We present a data-driven method for simulating clothes worn by 3D characters in real-time.
Approach	To effectively optimize the physics-based deformation, which is the bottleneck of the simulation, we use a coarse representation of the cloth mesh to drive the gross behavior in simulation.
Challenge	We consider that the gross cloth behavior is driven mainly by two separable contributions: the skeleton-driven movement of the character and the mechanical properties of the cloth.
Background	This consideration was partly inspired by the hybrid real-time simulation method proposed in Cordier et al. [ 5 ], where a hybrid deformation method is used to combine dynamic surfaces with Skeleton-Driven Deformation (SDD).
Outcome	Unlike that method, however, our method exhibits significantly more efficient and realistic behavior.
Approach	This effect is achieved by focusing on the analysis of cloth movements in relation to its associated skin surface, and adopting a learning strategy.
Approach	The idea is to use the analysis of the presimulated sequence to identify the region largely explained by joint movement and to replace the physics based simulation with geometric methods wherever possible.
Approach	Second, we use the pre-simulated sequence to approximate the dynamic behavior of the coarse mesh geometrically wherever possible.
Approach	Finally, fine details such as wrinkles are also simulated in a data-driven manner, by using the pre-simulated cloth sequence as examples.
Outcome	Subsequently, real-time animation of fully dressed human could be generated, which would be suitable for applications such as games where visual plausibility is more important than accuracy.
Background	Probably the most common technique for simulating the physical properties of clothes is the particle system.
Background	Simulation process is broken down into calculating the internal forces and solving the system of Partial Differential Equations (PDE).
Background	The latter point has attracted much interest in the field of real-time applications, since it requires high computation power.
Background	The explicit Euler method [ 2 ] has been one of the first numerical solvers.
Background	Unfortunately, this method is notorious for its instability when using large time steps and stiff equations.
Background	Several improvements have been proposed to reduce instability, such as the Verlet integration [11] and the explicit Euler combined with inverse dynamics [17] [20].
Background	Unfortunately, the simulation quality is sacrificed in favor of computation speed, due to the approximations employed in these models.
Background	The implicit Euler method presented by Baraff et al. [ 2 ] performs the computation not by using the derivative at the current time, but the predicted derivative at the next time step.
Background	Unlike explicit Euler integration, the implicit Euler method offers higher stability while using large time-steps and clothes with stiff mechanical properties.
Background	Desbrun et al [ 7 ] proposed solving the linear system with a precomputed inverse matrix.
Background	Kang et al. [12] proposed further optimization with a direct update formula for the positions and velocities of the cloth vertices.
Background	As indicated by the authors, these methods are not intended to provide a physically-correct cloth animation.
Approach	Our approach to that problem is a data-driven mass-spring system: the simulation is corrected with a set of functions built from the pre-simulated animation.
Approach	By doing so, we bring the deformation of the mass-spring system closer to the original cloth behavior.
Background	Another approach to fast garment deformations is the hybrid approach.
Background	They aim for a neat combination of physically based deformation and geometric deformation.
Background	Cordier et al. [ 5 ] proposed to segment the cloth into pieces and simulate these by different algorithms, depending on how they lie on the body surface and whether they adhere to it or flow over it.
Background	Others have noted that wrinkle deformation is geometric in nature and therefore can be computed with a geometric method.
Background	Wrinkles can be generated either by tessellating the cloth mesh [12] or rendering details on texture using bump mapping [9].
Challenge	The main difficulty is defining a fold function that can simulate all kinds of wrinkle patterns.
Challenge	Moreover, determining the location and shape of wrinkles is left to CG artists.
Outcome	One of our contributions is a geometric wrinkling method that is “trained” by using a pre-simulated cloth sequence, rather than relying on users.
Challenge	Collision detection is usually one of the bottlenecks in real-time animation.
Challenge	The problem is particularly acute in the case of clothes because these objects are highly deformable.
Background	Several algorithms have been proposed to process robustly collisions in cloth simulation [21] [22] without reaching real-time performance.
Background	Some other methods exploit graphics hardware to compute collisions on bump maps [20]; others use implicit surfaces to check collisions on the body [18], or voxel trees, which partition the space hierarchically [14].
Background	Using frame coherency to reduce computation cost has been explored by Zhang et al [23].
Approach	In this work, we propose a data-driven collision detection method; we use the pre-simulated sequence to localize the collision checks to neighboring cloth regions that have high probability to collide.
Background	The idea of building an interpolator from examples or pre-simulated data has proven to be a valuable tool in a variety of areas of CG, e.g. for modeling a variety of human body shapes and for motion synthesis.
Background	The basic idea is to build an interpolation space filled with a set of pairs of input parameters and the targeted graphical objects.
Challenge	Cloth animation depends on a high number of parameters and therefore a data-driven approach is difficult to adapt.
Background	Very recently, James et al. [10] resented such an approach, where physics-based deformation and collision detection are both handled in a unified framework.
Background	By blending of pre-computed orbits rather than using a mass-spring system, previous unseen results could be achieved, such as garments with stiff mechanical properties in real-time.
Background	However, they show little degrees of freedom (DoF) to the clothes under simulation; Instead of resorting to a data-driven approach for the entire simulation, we seek a neat combination of a data-driven approach with the mass-spring system.
Outcome	Unlike previous works, our simulator allows a much higher degree of interaction, as it is often needed in animating clothes on moving characters.
Background	The history of research on real-time cloth is relatively recent.
Background	Researchers have concentrated mainly on two aspects of real-time cloth animation: simulating the physical properties of garments and collision handling.
Challenge	The primary focus of this paper is the development of a fast cloth simulator for real-time applications.
Challenge	Dynamic simulation of complex deformable models, however, can easily involve thousands of degrees of freedom.
Challenge	For example, a physics-based simulator would require several minutes to compute one frame of a cloth model worn by a character.
Challenge	Simulating large models directly would therefore be computationally impractical.
Approach	Our simulator is based on two levels of deformation: the first deduces the gross cloth behavior by working on a coarse mesh with a physics-based approach whereas the second generates wrinkles on a fine mesh with a geometric method.
Approach	The coarse mesh is generated by simplifying the original cloth mesh through segmentation.
Approach	The reason for this choice is to lower the computation time; geometric methods are in general much faster than physically-based ones [9].
Challenge	When observing the behavior of garment worn by a character, there are considerable correlations between the body motion and the movement of the garment.
Challenge	These correlations are especially clear for some clothes like tight shirts and trousers.
Approach	In our method we take advantage of these relationships to reduce the computation load on the mass-spring system and collision detection.
Approach	We first construct the cloth-to-joint relation by analyzing a presimulated sequence of the cloth to be animated.
Approach	We then reduce the number of vertices to be physically simulated by identifying the garment regions in which the shape follows that of the underlying skin.
Approach	The cloth-to-joint relation enables us also to optimize collision detection by restricting the collision check to a small area around each vertex of the coarse mesh.
Approach	Finally, we use the cloth shape of a pre-simulated cloth sequence to correct the physicsbased simulation of the coarse mesh in order to match the original cloth behavior more closely.
Approach	The pre-processing stage involves generating the coarse mesh, computing the cloth-to-joint relation, and constructing the collision hulls and the interpolation functions for data-driven coarse mesh deformation and wrinkle animation.
Approach	Collisions are handled by collision hulls the position of which is computed by our SDD.
Approach	The final mesh is then obtained using the winkle shape interpolator and the computed geometry of the coarse mesh.
Background	The skeleton-driven deformation (SDD), a classical method for the basic skin deformation is perhaps the most widely used technique in 3D character animation.
Background	This method works first by assigning a set of joints with weights to each vertex in the character.
Background	The location of a vertex is then calculated by a weighted combination of the transformation of the influencing joints.
Approach	Although developing a new SDD method is not our main goal, the way the skin deforms is important in our framework since natural looking cloth shape also requires natural skin shape.
Approach	There are two requirements which the method should fulfill for this particular use: first, it must overcome the undesirable effect of vertex collapse as shown in Figure 3(a) .
Approach	Second, the method must provide an easy way to compute the local coordinate system for each skin vertex.
Approach	This is necessary as we want to compute the deformation of the cloth surface in relation to the skin surface.
Approach	We found that the classical SDD can be greatly improved by replacing the linear combination of the matrices by the matrix operator defined by Alexa [ 1 ].
Approach	Note that the operator is not continuous.
Approach	It is not defined for a rotation of 2π radians between the matrices to be blended.
Approach	In practice, such case is rare; in general, the largest angle range does not exceed π radians.
Approach	Due to the computational expenses of solving the full numerical system of the physics-based deformation, we seek simplifications by constructing a coarse mesh representation of the garment.
Approach	The coarse mesh is used to deduce the gross behavior of the cloth in a data-driven manner, based on the input pre-simulated sequence.
Approach	We begin by constructing a coarse representation of the given cloth model that will drive the gross behavior of the simulated garment.
Approach	(2) A coarse mesh representation is obtained by combining a set of vertices in a patch into a single mass point located at the center.
Approach	The generation of a patch starts by finding a vertex that has not yet been attributed to a patch that is already generated.
Approach	The patch is then grown by adding neighboring vertices one after the other.
Approach	To select a new vertex into the current patch, we evaluate each neighboring vertex that has not been already assigned to a patch, using a penalty function.
Approach	To enforce the regularity of coarse mesh, which is one condition for obtaining efficient deformation with the mass-spring system [21], we consider two following components.
Approach	• Minimizing the "shape factor": Square Root (Surface Area)/Contour Length.
Approach	The objective is to obtain "well-shaped patches", patches that have a circular shape.
Approach	This component gives a cost that increases with the surface area of the patch.
Approach	By modifying the significance of this component, we can easily control the number of vertices to be simulated with the physically-based deformation (see Figure 4 ).
Approach	The vertex with the lowest cost is selected.
Approach	When the lowest cost exceeds a threshold, the construction of the patch is completed.
Approach	We proceed until no vertices can be found to start a new patch.
Approach	Deciding a good granularity in the coarse mesh is hand-tuned, so that a neat compromise between the simulation quality and the computation load is found.
Approach	We have found that best simulations are obtained when patch area covers one or two cloth wrinkles.
Approach	Note that that each patch is associated with a vertex on the coarse mesh.
Approach	We denote the vector position of a vertex P as XP, and the vector position of its neighbors as X N R 3n (n: number of neighbors of P).
Approach	Next we carry out cloth-to-skin (or body) attachment through skin fitting, by which the skinning data on the cloth mesh are approximated in such a way that the skinning-driven cloth shape best fits the simulated cloth shape throughout the whole pre-simulated sequence.
Approach	The basic idea is to use the pre-simulated results as examples and find the error-minimizing skin data through optimization.
Approach	An optimization approach, such as the one presented by Mohr et al [15], could be adopted here.
Approach	In our case, however, our SDD method is non-linear and therefore the linear regression as adopted by Mohr et al is not beneficial.
Approach	Function minimization techniques such as Powell’s method [16] can deal with non-linear functions.
Background	Performance is slightly slower, but only pre-processing performance is affected and not runtime performance.
Approach	Notably, the floating regions (colored in red in Figure 5(d) ) are attached to the root of the character, as shown in Figure 5(b) ; this is contributable to the fact that these regions are large in volume and they rarely collide with limbs during the walk motion.
Outcome	The residual values of the fitting provide useful information on how the garments behave in relation to the body.
Approach	Intuitively, floating garments such as a skirt, cloth patches may collide with several joints; collisions need to be computed on these regions.
Approach	On the other hand, the local movements of some cloth patches (like underwear) are negligible and these patches can be considered as being attached rigidly to the skeleton.
Approach	In our approach, three regions are identified from the residual values of the skin fitting process ( Figure 5(d) ): those that potentially interact with several joints, those that are loosely attached to the skeleton and those that are rigidly attached to the skeleton.
Approach	The threshold values are chosen in a way that the coarse mesh deformation remains sufficiently close to the pre-simulated sequence.
Approach	For example, a false assignment of loose region into tight region would produce elongated deformations instead of slipping garment over the skin, and therefore generate an overly deformed coarse mesh, which is beyond the training data of the wrinkle generator.
Approach	Similarly, a false assignment of region 3 into region 2 would result in the garment crossing the legs.
Approach	In practice, values of 0.5 cm and 4.0 cm are used to identify tight regions and floating regions, respectively.
Approach	The deformation of tight regions is directly computed with the SDD (line 2 and 6 on Figure 6 ).
Approach	The use of SDD for these regions makes it possible to reduce the number of mass points even further.
Approach	Therefore, an additional collision check is required to handle the interaction of the clothes with the whole body skeleton.
Approach	A list of potentially colliding body patches is defined by selecting those that approach within a certain distance of the floating regions during the pre-simulated cloth sequence.
Approach	Apart from the position, our SDD computes the local transformation matrix of the vertices, the simulator to be optimized at least for the two following points: limiting collision checks to a small area around the vertices, and the geometric wrinkling which is processed in the SDD local coordinate system.
Approach	At each frame of the simulation, we compute the coarse mesh by a mass-spring system with the implicit Euler numerical solver [ 2 ].
Approach	The simulation run on the coarse mesh hardly reproduces the gross movement of the original cloth because the initial mesh has been significantly simplified (from 4000 to a few dozen vertices) and the topology has been modified.
Approach	Moreover, unlike the simulator used for the pre-simulated cloth sequence, the simplified mass-spring model does not accurately simulate the bending and shearing properties of the fabrics [21].
Approach	We approach the problem by modifying the behavior of the mass-spring system through a fix-up process (similar to [14]) where the position and velocity of the coarse mesh vertices are modified in order to maintain the cloth shape as close as possible to the original one ( Figure 7 ).
Approach	Ideally, the local shape (e.g. position of the vertices in relation to their neighbors) should be a blend of those of the pre-simulated animation.
Approach	This is achieved by constructing a set of functions of local shape deformation.
Approach	Post-correction is accomplished with a function that evaluates the "ideal" position of the vertex given the position of its neighbors connected by the edges.
Approach	For each vertex, we construct an interpolating function F Post by using a set of (X N,Pre-simulated , X P,Pre-simulated ) pairs extracted from each frame of the pre-simulated sequence, where X N ∈R 3 (n: number of neighbors of P) denotes the position of the neighbors and X N ∈R 3n the position of the vertex in question.
Approach	Given a position of neighbors X N,Input as input, the interpolation computes the corresponding X P by a weighted summation of the X P,pre-simulated values, each weight being computed from the Euclidian distance between X N,Input and all the X N,Presimulated values.
Outcome	The computation cost of this interpolator grows as the number of pre-simulated frames increases.
Approach	We wish to keep the computation cost constant regardless of the duration of the pre-simulated sequence.
Approach	A common solution is to construct a lookup table filled with values pre-simulated by the interpolator on grid sampling.
Approach	In order to reduce the memory usage of the lookup table, the dimension of XN,Pre-simulated was reduced prior to the construction of the interpolator, by Principal Component Analysis [16].
Approach	The first three principal components, which describe 95 % of the average variability of the data, are used.
Approach	The positions of the vertices are corrected after every simulation loop.
Approach	The velocity is updated as well.
Approach	Its new value is set to the sum of the original velocity and the velocity due to the modification of the vertex position (line 11 on Figure 9 ).
Approach	To prune unnecessary collision tests, we pre-compute what we term “collision hulls” that exploit the skin-tocloth relation obtained from the pre-simulated sequence.
Approach	These are built once at the beginning of the simulation (prior to the runtime simulation) after the SDD has been computed on the coarse mesh, using the pre-simulated sequence.
Approach	At each pre-simulated frame, we calculate the difference between the SDD motion model and the presimulated cloth model in the local coordinate system of the SDD.
Approach	After a sweep, we get a set of points that cover the path a patch takes during the simulation.
Approach	The smallest convex hull that contains all these points is generated for every patch using the “Quickhull” algorithm presented by Barber et al [ 3 ].
Approach	Given enough variation and range of character motion, we expect these hulls to cover the allowable positions of corresponding cloth patches during the runtime simulation.
Approach	By using collision hulls, collision tests are restricted to a small area around the patch; the overall computation can be significantly reduced in comparison to classical collision detection methods in which collisions are computed between the whole skin and cloth surface.
Approach	Note that the collision hulls are generated for loose and floating garment regions only.
Approach	The collision hulls of tight regions are small enough to be approximated by a single point.
Approach	Collision handling at runtime consists of correcting the position of coarse mesh vertices after every simulation step so that they remain inside their respective hulls.
Approach	We used constrained dynamics [22] to handle the collision response (i.e. modification of position and velocity in response to collision detection) at line 15.
Approach	The real-time computation of global cloth movements is obtained with a mass-spring system together with the collision response and post-correction described above.
Challenge	Again, the main challenge here is obtaining the highest possible realism while maintaining acceptable computation load, in order to meet the real-time requirements.
Background	As recognized in earlier works [9] [13], wrinkles can be efficiently animated with a geometric method as they are geometric in nature.
Approach	Unlike previous methods, however, our wrinkling function is not hand-drawn, nor geometrically approximated, but rather trained from on the analysis of the pre-simulated sequence.
Approach	In this work, we choose to represent the wrinkle displacement in the local coordinate system used for SDD.
Approach	This makes our wrinkle parameterization invariant of all joints of higher hierarchy than the currently influencing joint.
Background	Several techniques exist for shape interpolation using examples, such as Radial Basis Functions or parametric interpolation.
Approach	We have used linear interpolation in which coefficients are defined by multi-linear regression on the pre-simulated animation, since it provides satisfactory results at a very low computation cost.
Approach	For every vertex x in a patch, the interpolator function takes the associated mass point in the coarse mesh, and its neighbors as input.
Approach	The values α, α P and α N are the interpolation coefficients.
Approach	They are defined by multi-linear regression on a set of pairs (positions of coarse mesh vertices, fine mesh vertices) extracted from the pre-simulated cloth sequence.
Approach	X P and X N are respectively the position of the vertex x and its neighbors; they are all expressed in the SDD coordinate system of x.
Approach	Despite its simplicity, linear interpolation works fairly well provided a sufficient number of pre-simulated frames for the multi-linear regression.
Approach	A condition of a good working interpolator is that the input (i.e. position of the coarse mesh vertices) should be within the range of the pre-simulated data.
Approach	In other word, the wrinkle interpolator can only work for the input range for which it has been trained.
Approach	This condition is maintained thank to the data-driven post-correction (see Section 5.3).
Approach	This also keeps the smoothness of the boundaries between patches.
Approach	We measure and validate the proposed real-time cloth simulation method along three criteria: the variety of clothes to be simulated, the computation speed and the range of body motion in the pre-simulated cloth sequence.
Approach	Pre-simulated sequences obtained by the cloth simulator of Volino et al [21] were used in our preprocessing.
Approach	We used our framework to different types of clothes, as shown on the demonstration video.
Approach	• The “evening” dress ( Figure 14 ) is chosen to demonstrate our wrinkle interpolator on large garment regions.
Approach	• The “cocktail” dress ( Figure 18 ) is a relatively complex model; the bottom is composed of two layers of tissues and has folds made of large number of vertices, inducing many self collisions.
Approach	• The “Jeans” outfit is a good example of a model where the SDD based geometric approximation can reduce the number of mass points substantially by simulating only a few regions that contribute significantly to the dynamic behavior.
Outcome	Our simulator behaves fairly well on a wide variety of clothes, including those with highly stiff mechanical properties.
Outcome	Moreover, performance will increase due to the fact that the smallest number of triangles will be processed for the real-time rendering.
Outcome	However, the method may introduce flaws in simulation for some tight clothes, due to the approximate handling of collision detection.
Outcome	For some body movements, the skin surface may slightly intersect the cloth surface.
Outcome	Similarly, the same problem may arise for self-collisions on clothes.
Approach	The deletion of the skin triangles covered by the garment surface can partially correct this drawback.
Outcome	Note that the cloth simulation is also restricted to clothes worn on bodies.
Outcome	While offering high computation speed, the cloth simulator cannot handle some cloth movements such as those appearing during dressing or undressing.
Outcome	More generally, the clothes are unable to interact with objects other than those that have been taken into consideration during the pre-processing phase.
Approach	The list of objects that can potentially interact with clothes and the way these objects interact are defined at the preprocessing stage and cannot be changed during the realtime simulation.
FutureWork	Finding a method to update the list of possible interacting objects automatically could be a subject for future research.
Outcome	The pre-processing of all the cloth models took less than 10 minutes.
Outcome	All examples run in real-time at approximately 25 to 50 frames per second (fps), with the coarse mesh deformation process taking about 75 % of the total CPU time.
Outcome	As expected, the duration of the pre- simulated sequence is not a factor of the runtime computation speed.
Outcome	In practice, the performance lowers down at a low rate as the complexity of the collision hulls increases, which tends to be governed by the number of pre-simulated frames (see Section 5.3).
Outcome	As expected, the quality of the simulation depends on the number and variety of examples – the pre-simulated sequence in our case.
Approach	To show that the simulator faithfully recreates the cloth movement used for training, we compared the real-time simulation with the presimulated one in the first video.
Outcome	The character walks at a normal pace without any fast movements.
Outcome	In the second video, different body movements from those of the training were supplied as input to our realtime simulator and the results are compared with the ones generated with a high quality simulator.
Outcome	To measure the simulation quality, we compared our simulation results with the pre-simulated sequence, using a deformation metric.
Outcome	It measures the still shape and movement by the sum of edge length difference and the mass velocity difference over the cloth mesh.
Outcome	The best quality is achieved when the range of the body motion in the presimulated sequence is approximately 30 % larger than the one used in the real-time simulation.
Outcome	Our simulator works well for interpolation (i.e. joint angles within the range of those of the pre-simulated sequence) but often fails for extrapolation.
Outcome	The main reason for this limitation is collision detection, which does not allow the clothes to have different locations on the body from those calculated in the pre-simulated sequence; this makes the clothes being attached rigidly to the skeleton.
Outcome	With less than 70 pre-simulated frames, the real-time simulation loses its quality.
Background	The recent advent of cloth simulation techniques has matured enough to produce highly realistic cloth movements on animated characters.
Challenge	However, real-time simulation has been largely unexplored until now.
Outcome	This paper presents the first report of a practical and efficient method for handling real-time simulation almost automatically.
Outcome	We used our framework to produce visually pleasing motion of a wide range of clothes.
Approach	Both the mass-spring system and collision detection have been rewritten to take advantage of the pre-simulated sequence of the clothes to be animated.
Outcome	Consequently, our cloth simulator is able to construct a model for real-time animation without user intervention and can deal with different types of clothes from tight to floating with low computation consumption.
FutureWork	There are many interesting avenues for future work.
FutureWork	First, the approach could be extended to simulating other physics-based models such as hair and fluid.
FutureWork	We also believe that the work on collision hulls is promising.
FutureWork	The current mesh model of collision hulls could be replaced by implicit surfaces or voxel maps.
FutureWork	Therefore, for a cloth vertex, it could be possible to compute several collisions hulls in relation to different objects in the scene and to compute their intersection for real-time collision detection.
FutureWork	By doing so, it may be possible to process collisions on a higher number of objects while maintaining low computation cost.
FutureWork	We also believe that the precision of the collision detection could be improved by replacing the convex shape by a surface to follows more closely the trajectories of the vertices.

Challenge	While such vertex-parallel computation is often done on the GPU vertex processors, further parallelism can potentially be obtained by using the fragment processors.
Challenge	In this paper, we develop a parallel deformation method using the GPU fragment processors.
Approach	Joint weights for each vertex are automatically calculated from sample poses, thereby reducing manual effort and enhancing the quality of WPSD as well as SSD (Skeletal Subspace Deformation).
Outcome	We show sufficient speed-up of SSD, PSD (Pose Space Deformation) and WPSD to make them suitable for real-time applications.
Background	Skinning is an important part of realistic articulated body animation and is an important topic of computer graphics and animation.
Background	Generally, skinning can be categorized into algorithmic, physically-based, and example-based methods.
Challenge	Although widely used, simple algorithmic skinning schemes cannot capture the complexity and subtlety of real skin deformation, and revised approaches will be required to increase character animation realism.
Background	Physically-based skinning is based on the biomechanics of skin deformation arising from the motions of muscles and tendons.
Challenge	Although this approach can generate physically accurate simulations of each layer, it is not at present suitable for real time applications such as gaming due to the large computation required.
Background	Example-based methods capture some of the complexity of real skin deformation by interpolating scanned or sculpted examples of the desired skin shape in various poses.
Background	Al-      though this requires gathering a sufficient number of samples and some pre-calculation, example-based methods can potentially be used in real-time applications due to their relatively simple real-time computation.
Background	Weighted pose space deformation (WPSD) is an example based skinning method that generates high quality skinning with a limited number of sample poses [KM04].
Background	Although it can generate an accurate skinning, it requires more computation than the original pose space deformation (PSD) [LCF00], since joint distances are computed independently for each vertex.
Background	As such, this method has not been suitable for real-time applications.
Background	Furthermore, both WPSD and SSD require joint weights for each vertex, and accurate joint weights are required to achieve good results.
Challenge	However, the weights are usually manually generated by artists, which requires effort and great skill in the case of a complex skeletal system such as the human hand.
Challenge	In this paper, we present a parallel WPSD algorithm (including automatic determination of joint weights) suitable for SIMD architectures such as current GPUs.
Approach	The joint	  weights for each vertex are automatically computed from the sample poses.
Approach	This can enhance the skinning quality not only of SSD but also WPSD, since both methods require accurate joint weight values.
Approach	The deformation required in WPSD and SSD is independent for each vertex and this per-vertex computation can be parallelized in a SIMD architecture.
Background	The GPU is a general SIMD architecture having one-sided (unidirectional) communication to texture memory.
Approach	We demonstrate our parallel WPSD method using GPU fragment processors.
Approach	In our experiments, we can speed up SSD, PSD, as well as WPSD to around 20 times faster than on the CPU (from 1.2FPS to 25FPS speed-up of WPSD on a detailed model having 22836 triangles with 11574 vertices) using a modern graphics card, thus making WPSD a feasible real-time skinning solution for various applications including games, virtual reality, and other real-time simulations.
Background	Many commercial software packages generate skin deformation arising from joint movement using a method known as (linear blend) skinning, Skeletal Subspace Deformation (SSD), enveloping, etc., based in part on work published by Thalmann et al. [MTLT88].
Background	SSD is based on the weighted blending of affine transformations of each joint and used in many real-time applications due to its simple and fast computation.
Background	However, it also exhibits some well known artifacts such as skin that collapses around the joints at increasing bend angles, and a variety of solutions for these problems have been published [Web00, WP02, MTG03, KZ05].
Background	Recently, example-based methods [LCF00, SRC01, ACP02, KJP02, KM04] have permitted more complex skinning effects such as muscle bulges and major wrinkles, while also addressing the artifacts of simple algorithmic schemes.
Background	In these methods, a number of provided (scanned or sculpted) samples of the desired skin shape are simply interpolated based on the creature’s pose (and possibly additional abstract control “dimensions”).
Background	These example-based methods can also be considered as a non-parametric approach to skin deformation.
Background	In common with non-parametric sampling methods in texture synthesis (and more generally in statistical regression), the amount of memory for these methods grows with the number of training samples, but arbitrary distributions can be approximated.
Background	Some of the most impressive example-based results to date are those of Kurihara and Miyata’s hand model derived from medical images [KM04].
Background	Since acquiring 3D medical images is relatively expensive, they developed weighted pose space deformation (WPSD) to generate proper skinning from a limited number of pose samples.
Background	They modify the distance between poses using the joint weights of each vertex to provide a more appropriate distance measure for skinning.
Background	Although the joint weights for each vertex are important data for SSD and WPSD calculations, they have traditionally been manually generated by skilled artists.
Background	Least-squares based vertex weight estimation was shown in the skinning methods [WP02, MTG03].
Background	James et al. describe mesh based skinning including estimation of bone parameters and vertex weights for each bone [JT05].
Background	In their paper, the vertex weights of each joint are calculated by NNLS (non-negative least squares) and we derive a similar approach to calculate weights for SSD and WPSD.
Background	In recent years, since the performance of GPUs has been improving more rapidly than that of CPUs, and GPUs have many processing units serving as a SIMD parallel architecture, many algorithms have been accelerated by GPU programming [LHK ∗ 04, PF05, GPG].
Background	Deformation and skinning algorithms can also be enhanced by GPUs and several papers have profited from this [JP02, KJP02, BK05, JT05].
Background	However, in previous research, since vertex information cannot be accessed in the fragment program, GPU-based vertex deformation is usually performed by vertex programs.
Challenge	In this paper, we develop a parallel WPSD method using the fragment processors to gain greater parallelism and performance.
Background	Person-specific data modeling and its deformation is also an interesting topic in realistic articulated body simulation.
Background	Rhee et al. described human hand modeling from surface anatomy of the person [RNL06].
Background	Anguelov et al. developed shape completion and animation of people, derived from the set of range scan data and example based deformation in pose and shape space [ASK ∗ 05].
Background	Physically inspired skinning should be also recognized as another important area of articulated body animation.
Background	However, we entrust the review of the subject to the recent related papers [AHS03, CBC ∗ 05, PCLS05, SNF05].
Approach	In skeletal subspace deformation the displacement D(p a ) is omitted and the target surface is calculated by SSD as a blend of affine transforms of v 0 [section 3.1].
Approach	Skinning methods related to PSD use the displacement of an arbitrary pose D(p a ), calculated by interpolation in pose space [section 3.2].
Approach	SSD [MTLT88] is based on the weighted blending of an affine transformation of each joint by equation 2.
Approach	The weight w j can be assigned by the artist to control deformation and usually ∑ n j=1 joint (w j ) = 1.0.
Background	This simple algorithm is used in many commercial graphics packages and real-time rendering applications but shows several limitations, because the deformation of this method is restricted to the subspace of the affine transformation of the joints [LCF00].
Approach	If we have a sufficient set of examples to describe the movement of an articulated object, we can interpolate displacement in “pose space” [LCF00].
Approach	Each sample pose consists of sample skin geometry and the related joint skeleton, and a vector containing the joint angles represents the pose.
Approach	Note that the inverse here is of the weighted sum of affine transforms.
Approach	After defining the displacement of each pose, the displacement at an arbitrary pose can be calculated by RBF (Radial Basis Function) [LCF00] or normalized radial basis function [KM04] interpolation of the example poses’ displacements.
Approach	The weight r k (p a ) is calculated using normalized RBFs and is used in equation 4 to calculate the displacement d a of a vertex in an arbitrary pose p a :
Background	WPSD is developed by Kurihara et al. [KM04] to deform their example-based human hand model derived from medical images.
Approach	In equation 7, since the γ k is the difference of n joint dimensional joint vectors of related poses, every vertex in the pose p k has same distance γ k resulting in the same weight r k (p a ) in every vertex of the pose p k .
Approach	Furthermore, because each element of the joint vector equally contributes to the distance calculation, two vectors having a same value but different order generate same pose distance.
Approach	For example, three different joint vectors p 1 = (θ, 0, 0), p 2 = (0, θ, 0), p 3 = (0, 0, θ) have same distance between them and it can cause unexpected results in PSD.
Background	In WPSD [KM04], Kurihara et al. modify the distance definition between poses using joint weight of each vertex i to give proper weight to each element of a joint vector,
Approach	From this definition, a more accurate pose distance is obtained and it generates better skinning in arbitrary poses, especially when the poses are far from the examples.
Background	The joint weights of each vertex are important to generate accurate skinning in SSD (equation 2) as well as in WPSD (equation 8).
Background	In many applications, the weights are manually generated by skilled artists and it is hard to generate accurate values when a number of joints are involved in deforming a region.
Approach	In this paper, we automatically calculate the joint weights of each vertex from the sample poses to enhance the accuracy of the weight value.
Outcome	This results in better skinning and reduces the elaborate manual work required to create weight maps.
Approach	>From equation 11, we can calculate w from the given value of v and A to reduce the error of this equation.
Approach	We use the non-negative least square (NNLS) method to solve this problem and it determines positive weight values minimizing error in equation 10.
Approach	The calculated weight vector w is normalized to satisfy ∑ n j=1 joint w j = 1.0.
Approach	In order to avoid a singular matrix A, the number of poses should be greater or equal to the number of overall DOF (Degree Of Freedom) of the joint vector (each joint has 3 DOF), and the sample poses should be sufficiently different.
Approach	James et al. used a similar approach to estimate vertex weights in each joint [JT05] and we demonstrate their efforts in our skinning method.
Background	Skinning deformations vary across vertices.
Background	In SSD and WPSD, this per-vertex computation is independent for each vertex and can be parallelized by a SIMD parallel architecture.
Outcome	We developed a parallel skinning algorithm for SSD and WPSD that is suitable to GPUs having a SIMD architecture with one-side communication to texture memory.
Approach	The computation cost of the SSD skinning algorithm is O(n vertex × n joint ) from equations 1, 2, PSD is O(n vertex × n joint × n pose ) from equations 1, 2, 4, and WPSD is O(n vertex × n joint × n pose × n pose × n pose ) from equations 1, 2, 4, 5, 6.
Approach	Where, computation cost of original PSD is defined by equation 1, 2, 4, since r i is same in all vertices and d i can be pre-calculated.
Approach	The number of joints n joint and poses n pose can be reduced to the smaller numbers using the method developed by Kry et al. [KJP02], as will be discussed in section 5.2.1 with efforts to reduce texture memory space.
Background	In previous research, the Eigenskin method based on PSD was developed using GPU vertex programming [KJP02].
Approach	The vertex program uses a relatively small number of slow processing units compared with the fragment processors, and the per-vertex computation cost of the original PSD is O(n joint × n pose ).
Outcome	Therefore WPSD, having higher pervertex computation cost O(n joint × n pose × n pose × n pose ), can clearly benefit from parallel computation on fragment processors.
Approach	We developed parallel skinning using the GPU fragment processors and demonstrate our method using three rendering passes.
Approach	In order to minimize real-time computation, we separate possible pre-calculation steps and save the results into texture memory using texture maps.
Approach	Because the value in the texture memory is not changed in the successive deformation, it can be pre-computed and stored in the read-only texture memory.
Approach	In the first and second pass, per-vertex deformation is calculated in the fragment program and the results are stored in texture maps using the FBO (Frame Buffer Object) extension [Gre05].
Approach	These texture maps are bound to the geometry of the rest pose with their texture coordinates.
Approach	In the third pass, each vertex in the rest pose is changed by the deformed vertex stored in the output texture generated in the first and second passes using vertex texture fetch.
Background	The fragment processors cannot access vertex information.
Approach	Instead, we can use texture memory to send data to the fragment program.
Approach	Information needed in the fragment program is packed into texture maps and stored into texture memory.
Approach	Geometry information from the rest pose is stored into two RGB texture maps, a vertex texture T v and normal texture T n ; each has size n vertex × 3.
Approach	These textures represent parameter v 0 in equation 2 and each 3D element (x, y, z) is stored into the (r, g, b) value of a texel [ Figure 2 ].
Background	In general, the distribution of skinning effects in an articulated body is local to several joints [MMT97,KJP02], even in a region as complicated as a hand.
Background	For example, deformations arising from the PIP (Proximal Interphalangeal) joint of index finger do not propagate to the other fingers, and deformation on the middle phalanx of index finger is only affected by the movement of PIP and DIP(Distal phalanx) joints.
Approach	From this observation, we can reduce joint weight storage from the actual number of joint n joint to a smaller number of “principal joints” n  ̃ joint selected by sorting on the weight value.
Approach	We threshold n  ̃ joint at four in our tests with an additional four elements to hold the related joint index.
Approach	As a result, we can save the joint weights of entire geometry in two RGBA textures T w1 , T w2 each with size n vertex × 4(rgba) and store the entire information required for SSD [equation 2] in four textures T v , T n , T w1 , and T w2 .
Approach	The displacement values calculated by equation 3 can be stored in n pose displacement textures; n pose is the number of sample poses.
Approach	In case of complex joint structures and a large DOF model, we need many sample poses to calculate accurate joint weights and PSD deformation.
Approach	However, since the joint weights can be pre-calculated, we can reduce the number of sample poses needed in real-time PSD computation.
Background	PCA (Principal Component Analysis) of pose space can yield an orthogonal basis called “ Eigendisplacement ” [KJP02].
Approach	If we reduce the size of pose space from n pose to n  ̃ pose “principal poses” ( n  ̃ pose < n pose ), we can reduce the number of displacement textures.
Approach	In our paper, we set n  ̃ pose as eight in our experiment and save displacements of all poses into a RGB texture T d having size n vertex × 8( n  ̃ pose ) × 3(rgb).
Approach	Therefore, from the two important observations of “principal joints” and “principal poses”, the original computation cost for SSD, PSD, and WPSD discussed in section 5.1 can be reduced using n  ̃ joint and n  ̃ pose rather than n joint and n pose .
Approach	In the original PSD, since the weight r i in equation 4 is the same at every vertex, we do not need to calculate this value in the GPU.
Approach	Since the size of this value is just n  ̃ pose , we can simply pass them to the GPU as parameters without generating a texture map.
Approach	Therefore, we store all the information needed to calculate the original PSD at this point.
Approach	In order to reduce real-time computation, we pre-calculate T j in equation 2 and λ in equation 5 and store them into another one channel texture T x having size n  ̃ pose × ( n  ̃ pose + n  ̃ joint × 3(x, y, z)).
Approach	As a result, we store all the variables required to calculate WPSD, PSD, and SSD in six texture maps: T v , T n , T w1 , T w2 , T d , and T x .
Approach	The values in the texture maps are stored in the texture memory at setup time, since they are not changed during the deformation process.
Background	In current graphic card architectures, data transfer from CPU to GPU is slow compared with memory access within the GPU.
Outcome	Although, we cannot access vertex data in the fragment program, the efficiency of parallel computation on a fragment program is higher, since the fragment processor has more processing units and each of them has more computation power than a vertex processor.
Approach	The fragment processing system is a general SIMD architecture using fragment streams as input data; each fragment is assigned to a fragment processor to calculate its final color value independently and in parallel.
Approach	We developed a parallel WPSD algorithms using the fragment processors to enhance the extent of parallel computation.
Approach	Geometry information like vertex positions and normals are stored in texture maps T v and T n as described in section 5.2.1 and the vertex information is referred in the fragment processors to calculate final color values.
Approach	In order to assign each vertex value stored in a texture map to a fragment, we bind the geometry texture T v or T n to a quad and render it using an orthographic camera having the same width and height as the quad.
Approach	Furthermore, since the viewport is set to the same resolution as the textures, each fragment is exactly matched with each texel holding the vertex information, and we can access each vertex using the texture coordinates of the fragment; vertex weights and displacements stored in the texture maps can also be accessed by similar methods.
Background	A similar idea was developed in [PBMH02] to calculate ray tracing in a fragment program and is used in GPGPU (General Purpose computation on GPUs) applications [GPG, LHK ∗ 04, PF05].
Background	The FBO (Frame Buffer Object) extension [Gre05] supports rendering into an attached texture.
Background	This saves memory and time, since there is no copy operation from frame buffer to texture buffer.
Approach	We implemented our WPSD algorithm using the fragment program with the FBO extension to store the result directly into texture maps accessed by vertex program in the next pass.
Approach	We implemented GPU deformation using three rendering passes, and the basic architecture is described in figure 3 .
Approach	In the first pass, we parallelize per-vertex deformation using GPU fragment processors.
Approach	The data required to calculate this deformation is stored in the textures as described in section 5.2.1 and the deformation for each vertex is calculated in a fragment processor.
Approach	In a given arbitrary pose defined by a joint vector, SSD is computed by equation 2 using texture maps T v , T w1 , T w2 and T x ; refer to the texture map notation in section 5.2.1.
Approach	PSD is computed by equation 4 using T d , T x , after calculating r k (p a ) by equation 6.
Approach	In the second pass we calculate and store normal deformation with a similar method as in the first pass, and the results are stored in the texture map T n ′ .
Approach	In the third pass, using a vertex program, each vertex of the rest pose is transformed to the final deformed position using the information from the texture maps computed in the previous two passes.
Approach	In order to access related texture information in each vertex, we created texture coordinates of each texel in pre-processing and used them in the vertex program.
Approach	Specifically, the two texture maps, T v ′ and T n ′ that are generated in the first and second passes are accessed in the vertex program using the texture coordinate of the current vertex.
Approach	Alternatively, multiple render targets (MRTs) can combine the first and second pass, and vertex buffer objects (VBOs) could be used to render the deformed results back to the vertex array [OPE, GPG, LHK ∗ 04].
Approach	We tested our methods using upper arm models consisting of four joints (collar, shoulder, elbow, and wrist).
Approach	Each has three DOF and the wrist is the end joint having no DOF.
Approach	Three different resolution meshes are used to test the performance of GPU parallel computation: the high-resolution model has 91460 triangles with 46036 vertices, the midresolution model has 22836 triangles with 11574 vertices, and the low-resolution model has 5762 triangles with 2972 vertices [ Figure 4 ].
Approach	Note that these models are considerably more detailed than those used in current games, so the reported frame rates would be much higher if typical gameresolution models were used.
Outcome	On the other hand, with the expected growth of GPU processing power, models such as these will be in wide use in a few years, and algorithms such as WPSD will be required to produce realistic deformations at this level of resolution.
Approach	Eight sample poses were created by Poser [Cur] and the joints weights and displacements of each sample were derived from these models [ Figure 5 ].
Approach	Our parallel algorithm is based on three pass GPU computation.
Approach	The fragment program for the 1st and 2nd pass, and the vertex program for the 3rd pass are implemented in the Cg language [FK03].
Approach	For accuracy the GPU computation is performed by 32bit floating point operations with 32bit floating point texture maps.
Approach	Note that the maximum required memory space for the highest resolution model is just 6.8 Mbytes; the size of the output texture T v ′ and T n ′ is the same as the size of T v and T n .
Outcome	The results of GPU-based deformation for SSD, PSD, and WPSD are shown in Figure 1 and 6, and the experiment is performed in a GeForce 6800 Ultra GPU and a 3.4Ghz Pentium 4 CPU.
Outcome	The timing results of each algorithm on the CPU and GPU are summarized in table 1 .
Outcome	On average, our GPU-based deformation shows around 20 times speed-up compared with CPU-based deformation.
Outcome	GPU-based WPSD has roughly the same speed as CPUbased SSD.
Outcome	Therefore, real-time applications using SSD can substitute WPSD running on the GPU without loosing their real-time performance.
Outcome	Since our algorithm shows speed-up for SSD and PSD as well as WPSD, applications can choose the most appropriate skinning method according to the required deformation and detail.
Outcome	In this paper, we present a parallel skinning algorithm suitable for SIMD architectures such as GPUs.
Approach	The joint weights of each vertex are automatically computed by NNLS and used in the skinning computation for SSD and WPSD.
Approach	Independent per-vertex deformation is parallelized on the GPU using three rendering passes.
Approach	In the first and second passes, per-vertex deformation is calculated by the fragment processors and the results are stored in texture maps using FBO.
Approach	In the third pass, using vertex processors, each vertex of the rest pose is changed by the deformed vertex stored in the textures generated by the first and second passes.
Outcome	Articulated body skinning using SSD, PSD, and WPSD are efficiently parallelized by our GPU-based method, and on a detailed model, we obtain around 20 times speed-up compared with CPU-based computation.
Outcome	Principal component compression of the examples and careful analysis of joint distributions can reduce the domain of computation [KJP02] and other algorithms based on the SSD, PSD, and shape interpolation may be parallelized on GPU using our approach.

Challenge	In this article, we present a semi-Lagrangian surface tracking method for use with fluid simulations.
Approach	Our method maintains an explicit polygonal mesh that defines the surface, and an octree data structure that provides both a spatial index for the mesh and a means for efficiently approximating the signed distance to the surface.
Approach	At each timestep, a new surface is constructed by extracting the zero set of an advected signed-distance function.
Approach	Semi-Lagrangian backward path tracing is used to advect the signed-distance function.
Outcome	One of the primary advantages of this formulation is that it enables tracking of surface characteristics, such as color or texture coordinates, at negligible additional cost.
Outcome	We include several examples demonstrating that the method can be effectively used as part of a fluid simulation to animate complex and interesting fluid behaviors.
Challenge	The fundamental problem of tracking a surface as it is advected by some velocity field arises frequently in applications such as surface reconstruction, image segmentation, and fluid simulation.
Challenge	Unfortunately, the na ̈ ive approach of simply advecting the vertices of a polygonal mesh, or other explicit representation of the surface, quickly encounters problems such as tangling and self-intersection.
Background	Instead, a family of methods, known as level-set methods, has been developed for surface tracking.
Background	These methods represent the surface implicitly as the zero set of a scalar field defined over the problem domain.
Background	The methods are widely used, and the texts by Sethian [1999] and Osher and Fedkiw [2003], and Osher and Sethian’s [1988] seminal article, provide an excellent introduction to the topic.
Background	One of the key issues that distinguishes various level-set and similar approaches is the representation of the scalar field, which must capture whatever surface properties are important to a given application.
Challenge	In this article we present a surface tracking method that explicitly represents the surface as a set of polygons.
Approach	A new polygonal surface is generated by contouring or extracting the zero set of ψ.
Approach	The value of ψ at a point x, at current time t, is obtained by first tracing backward through the flow field to find the previous location x at time t − t, and then returning the signed distance of x from the previous surface.
Approach	Using adaptive octree data structures, we can efficiently and reliably construct the new surface and corresponding signed-distance function.
Approach	The theoretical framework for this method comes from a series of articles by Strain [1999b, 1999c, 1999a, 2000, 2001] that described and analyzed a method for contour tracking in two dimensions.
Approach	While the semi-Lagrangian procedure for backward advection does not change significantly when going from twoto three-dimensional problems, significant surface tracking issues arise when moving to three dimensions.
Challenge	This article discusses these issues, as well as the general method, and demonstrates how semi-Lagrangian surface contouring can be useful for animating the complex and interesting behavior of fluids.
Outcome	One of the primary advantages of this method is that it enables tracking surface characteristics, such as color or texture coordinates.
Outcome	These properties can be easily stored directly on the polygonal mesh and efficiently mapped onto the new surface during semi-Lagrangian advection.
Outcome	The explicit surface representation also facilitates other common operations, such as rendering, while reconstruction from a scalar function allows operations that rely on an implicit representation.
Outcome	Finally, the method produces detailed, well-defined surfaces that are suitable for realistic animation and that do not jitter or exhibit other undesirable behaviors.
Approach	Our method pulls together solutions to a number of well-studied problems to arrive at a method for tracking surfaces.
Background	Because surface tracking arises in a variety of contexts, the topic has received a significant amount of attention.
Background	Even in the limited context of fluid animation, there has been a great deal of excellent work on simulating fluids with free surfaces, including Foster and Metaxas [1996], Foster and Fedkiw [2001], Enright et al. [2002b], Carlson et al. [2002, 2004], Losasso et al. [2004], Goktekin et al. [2004], Hong and Kim [2005], Wang et al. [2005], Guendelman et al. [2005], and Zhu and Bridson [2005].
Background	The methods available for tracking free surfaces of liquids can be roughly sorted into four categories: level-set methods, particle-based methods, particle level-set methods, and semi-Lagrangian contouring.
Background	Many of the most successful solutions to the surface tracking problem are based on level-set methods, which were originally introduced by Osher and Sethian [1988].
Background	A complete review of level-set methods is beyond the scope of this article, and we recommend the excellent surveys by Sethian [1999] and Osher and Fedkiw [2003].
Background	Level-set methods represent a surface as the zero set of a scalar function which is updated over time by solving a partial differential equation, known as the level-set equation.
Background	This equation relates change of the scalar function to an underlying velocity field.
Background	By using this implicit representation, level-set methods avoid dealing with complex topological changes.
Background	However, the scalar function is defined and maintained in the embedding three-dimensional space, rather than just on the two-dimensional surface.
Background	In practice, scalar function values need only be accurately maintained very near the surface, resulting in a cost that is roughly linear in the complexity of the surface.
Background	One difficulty with level-set methods is that they generally require very high-order conservation-law solvers, though fast semi-Lagrangian methods have been shown to work in some cases [Strain 1999b; Enright et al. 2005].
Background	The most significant drawback to using level-set methods to track liquid surfaces is their tendency to lose volume in underresolved, high-curvature regions.
Background	See Enright et al. [2002a] for an excellent discussion of the reasons for this volume loss.
Background	Bærentzen and Christensen [2002] built a sculpting system using a level-set surface representation which could be manipulated by a user with a variety of sculpting tools.
Background	Like us, they used adaptive grid structures to store the scalar field.
Background	However, they used a two-level structure rather than a full octree.
Background	They also used semi-Lagrangian methods to update their level-set function.
Background	However, when evaluating the distance function after the semi-Lagrangian path tracing, they interpolated distance values stored on a regular grid, while our explicit surface representation allows us to compute exact distances near the surface.
Background	Sussman and Puckett [2000] coupled volume-of-fluid and level-set methods to model droplet dynamics in ink-jet devices.
Background	Volume-of-fluid [Hirt and Nichols 1981] techniques represent the surface by storing, in each voxel, a volume fraction—the proportion of the voxel filled with liquid.
Background	Any cell whose fraction is not one or zero contains surface.
Background	Unfortunately, this representation does not admit accurate curvature estimates, which are essential to surface tension computations.
Background	However, accurate curvature estimates are easily computed from level-set representations.
Background	Thus, the authors combined volume-of-fluid and level-set representations to model surface tension in ink droplets.
Background	Some volume-of-fluid methods build an explicit surface representation from the volume fractions stored in each voxel.
Approach	The key difference between our method and volume-of-fluid methods is that we never compute volume fractions.
Approach	Instead, our explicit representation is generated by contouring an advected signed-distance function.
Background	A number of researchers [Terzopoulos et al. 1989; Desbrun and Gascuel 1995; Foster and Metaxas 1996; Desbrun and Cani 1996; Cani and Desbrun 1997; Stora et al. 1999; M uller  ̈ et al. 2003, 2004; Premo ze et al. 2003; Zhu and Bridson 2005; Pauly et al. 2005] have used particles to track surfaces.
Background	In many of these methods, the simulation elements are particles, which are already being tracked throughout the volume of the deforming liquid or solid.
Background	The surface can then be implicitly defined as the boundary between where the particles are and where they aren’t.
Background	The particles can be visualized directly, or can be used to define an implicit representation using blobbies or moving least-squares methods.
Background	Premo ze et al. [2003] went a step further and used particle positions and velocities to guide a level-set solution.
Background	Mueller et al. [2004] and Pauly et al. [2005] used special particles, called surfels, to represent the surface.
Background	Surfels store a surface normal as well as position and there are generally many more surfels than simulation particles.
Background	The principal drawback of these methods is that generating high-quality time-coherent surfaces can be difficult: directly visualizing the particles is insufficient for high-quality animations, methods which convert the particles to some other representation on a per-frame basis often lack temporal coherence, and methods which must run sequentially through the frames or run during the simulation are often quite costly.
Background	Additional difficulties arise when trying to ensure a good sampling of the surface.
Background	To address the volume loss of level-set methods, Enright and his colleagues [2002a, 2002b, 2005] built on the work of Foster and Fedkiw [2001] to develop particle level-set methods.
Background	These methods track the characteristics of the fluid flow with Lagrangian particles, which are then used to fix the level-set solution, essentially increasing the effective resolution of the method.
Background	Recently, these methods have been extended to work with octrees [Enright et al. 2005; Losasso et al. 2004], allowing for very high-resolution surface tracking.
Background	These methods represent the current state of the art on tracking liquid surfaces for animation, but do have some drawbacks.
Background	In particular, the published particle correction rules choose a single particle to provide the signed-distance value.
Background	Since there is no guarantee that the same particle will be chosen at subsequent timesteps, the method is extremely susceptible to high-frequency temporally incoherent perturbations of the surface.
Background	The artifacts are most noticeable when the surface thins out below the grid resolution and particles happen to be near some of the sample points, but not others.
Background	Also, the method has a large number of parameters and rules, such as the number of particles per cell and the reseeding strategy, which need to be decided, often in an application-specific way.
Background	Finally, the method tends to produce very smooth surfaces with very little detail, which is desirable in some, but not all, applications.
Background	Despite these drawbacks, the particle level-set methods have been very successful and represent a significant step forward in the area of surface tracking for liquid simulations.
Background	Recently, Strain [1999b, 1999c, 1999a, 2000, 2001] has written a series of articles building a theoretical framework culminating in the formulation of surface tracking as a contouring problem.
Background	He demonstrated his semi-Lagrangian contouring method on a variety of two-dimensional examples.
Approach	Our method is based on the method presented by Strain [2001], but with variations and extensions to deal with problems that arise in three-dimensional computer animation.
Approach	While our method bears a number of similarities to level-set methods and takes advantage of many techniques developed for those methods, we are not directly solving the level-set equation.
Approach	By formulating surface tracking as a contouring problem, we avoid many of the issues that complicate level-set methods.
Approach	In particular, we do not have the same volume loss issues which prompted the particle levelset methods: while we do not explicitly conserve volume, our semi-Lagrangian path tracing tends to conserve volume in the same way as the Lagrangian particles in the particle level-set method.
Approach	The octree structure we use to build and index the polygonal mesh is quite similar to adaptively sampled distance fields [Frisken et al. 2000].
Background	These structures adaptively sample distance fields according to local detail and store samples in a spatial hierarchy.
Approach	The key difference between adaptively sampled distance fields and our surface representation is that we store a polygon mesh in addition to distance samples.
Approach	This polygon mesh is used for exact evaluation of the distance function near the surface.
Approach	Additionally, our splitting criterion is different from that presented by Frisken et al. [2000].
Background	An alternative structure for storing narrow-band level-set functions is the dynamic tubular grid of Nielsen and Museth [2006].
Background	This structure can be combined with run-length encoding schemes [Houston et al. 2006], providing extremely compact, high-resolution representations of level-set functions.
Background	While the asymptotic times for their structure match ours, they are able to exploit cache coherence to provide extremely fast run times for most level-set operations.
FutureWork	Integrating the methods presented here with this data structure is a promising area for future work.
Approach	As our title suggests, we formulate surface tracking as a contouring problem.
Background	The contouring problem has been well studied in computer graphics and a number of approaches have been suggested.
Background	The oldest and most widely used is marching cubes, which was first presented by Wyvill et al. [1986], and later named and popularized by Lorensen and Cline [1987].
Background	Marching cubes suffers from a tendency to create ill-shaped triangles.
Background	This problem is fixed to some degree by dual contouring [Ju et al. 2002], which also provides adaptive contouring and an elegant means of preserving sharp boundaries.
Background	Dual contouring depends on normal estimates at edge crossings and is very sensitive to inaccuracies in these normal estimates.
Approach	Unfortunately, in our method we do not have accurate normal information until after the contouring step, when we have the triangle mesh.
Background	More recently, Boissonnat and Oudot [2003] presented a contouring technique which uses Delaunay triangulation methods to generate provably good triangulations.
Background	However, this method appears to be prohibitively expensive for something which must run at every timestep.
Background	Yet another alternative is marching triangles [Hilton et al. 1996], which takes a surface-based rather than volume-based approach to contouring.
Background	Marching triangles requires significantly less computation time and fewer triangles, and produces higher-quality triangles than marching cubes.
Background	Unfortunately, marching triangles is not guaranteed to produce closed, manifold meshes in the presence of sharp or thin features.
Background	Semi-Lagrangian methods have been widely used in computer graphics since they were introduced by Stam [1999] to solve the nonlinear advection term of the Navier-Stokes equations.
Approach	These methods provide the foundation for our surface tracking method.
Approach	Consequently, we briefly discuss the mathematical foundation of semi-Lagrangian methods.
Approach	Our discussion follows that of Strain [1999b].
Approach	Thus we can find φ values at any time t by finding the characteristic curve passing through (x, t), following it backward to some previous point (x 0 , t 0 ) where the value of φ is known, and setting φ(x, t) = φ(x 0 , t 0 ).
Background	This observation forms the basis of the backward characteristic or CIR scheme developed by Courant, Isaacson, and Rees [1952], which is the simplest semi-Lagrangian scheme.
Approach	Then φ(x, t n+1 ) is set equal to the interpolated value, φ(s(t n ), t n ).
Approach	For linear PDEs, such as Equation (1), the Lax-Richtmyer equivalence theorem [LeVeque 1990] guarantees that CIR will converge to the exact solution as t, x → 0 if it is stable and consistent.
Approach	The stability properties of the CIR scheme are excellent.
Approach	Each new value φ(x, t n+1 ) is a single interpolated value of φ at time t n , so unconditional stability is guaranteed in any norm where the interpolation does not increase norms.
Approach	For example, CIR with linear interpolation is unconditionally stable in the 2-norm.
Approach	In general, semi-Lagrangian schemes satisfy the CFL condition by shifting the stencil, rather than restricting the timestep.
Approach	Thus information propagates over long distances in one timestep.
Approach	Consistency (loosely speaking, the local accuracy of the method), however, is conditional.
Approach	Thus CIR is consistent to O( t) if a condition t ≥ O( x) is satisfied, contrary to the usual hyperbolic condition t ≤ C x.
Approach	This condition is extremely convenient, because t = O( x) balances time and space resolution in this first-order accurate scheme.
Approach	For nonlinear PDEs, CIR still converges when the solution is smooth.
Approach	But nonsmooth shock solutions of conservation laws move at the wrong speed because CIR is not in conservative form.
Approach	Since level-set solutions have no shocks, CIR is a natural scheme for moving interfaces.
Challenge	The surface tracking problem can be phrased as: given a surface representation and a velocity field at time t, build a representation of the surface at time t + t.
Approach	We begin with a triangle mesh and an octree annotated with signed-distance field samples.
Approach	We could try to advect the mesh points through the flow field, but would quickly encounter significant topological difficulties.
Approach	Instead, we avoid topological issues by updating the surface using an implicit representation.
Approach	The implicit representation is then used to construct a new mesh at the current timestep.
Approach	More specifically, we define a scalar-valued function which relates the surface at the current timestep to the surface at the previous timestep.
Approach	Next, we extract the zero set of this function using a contouring algorithm.
Approach	Finally, a new signed-distance field is computed through a process known as redistancing (see Figure 1 ).
Approach	One of the key differences between our method and other surface tracking methods is that we build an explicit representation of the surface at every timestep.
Approach	This explicit representation is a closed, manifold triangle mesh, which is stored as an array of vertices and an array of triangles.
Approach	The vertices are shared between triangles, allowing for easy computation of smooth vertex normals and other common mesh operations.
Approach	The distance tree (see Section 6) provides a spatial index for the mesh.
Approach	The explicit representation provides our method with several advantages.
Approach	First, it allows us to compute exact signeddistance values near the mesh.
Approach	Second, it allows us to store properties on mesh vertices, rather than at points near the mesh.
Approach	Finally, it allows us to take advantage of the many tools and algorithms which have been developed in computer graphics for manipulating and rendering triangle meshes.
Approach	To avoid the topological difficulties of directly updating an explicit surface representation, we update the surface in time through an implicit representation (see Figure 2 ).
Approach	We define a scalar-valued field function, ψ(x), which relates the surface at the current timestep to the surface at the previous timestep.
Approach	For a point x at the current timestep, the function, ψ, first uses backward path tracing, a semiLagrangian integration technique, to find the point x at the previous timestep which flows to x.
Approach	It then returns the distance from x to the surface, S n−1 , at the previous timestep.
Approach	Essentially, we are advecting the signed-distance function through the velocity field given by the fluid simulator.
Approach	In solving this advection term, our method differs from the simple CIR scheme discussed earlier in two ways.
Approach	It is important to note that, while this method traces back through the velocity field with second-order accuracy, the velocity field is frozen over the course of the timestep, leading to first-order accuracy in time.
Approach	The second difference is that, when evaluating φ at points near the surface, we do not interpolate values stored on a grid.
Approach	Instead, we compute exact distance values.
Outcome	These changes only improve the accuracy (consistency) of our method and do not affect the unconditional stability.
Approach	To compute the exact distance from a point x , we compute the distances d i to all the nearby triangles.
Approach	The distance to the surface is min i d i .
Background	Schneider and Eberly [2002] detailed a method for computing the distance from a point to a triangle.
Background	This operation is relatively expensive, but many triangles can be pruned, especially when x is very close to the surface, by using standard bounding-box techniques and our octree data structure (see Section 6).
Approach	Signing the distance values turns out to be somewhat difficult near sharp corners.
Approach	Let y and n(y) denote the closest point on the surface to x and its normal, respectively.
Approach	However, if the nearest point in the mesh lies on more than one triangle (i.e., on an edge or vertex of the mesh), the triangles do not always agree on the sign.
Approach	These situations can be resolved by computing an angle-weighted pseudonormal for each edge and vertex of the mesh and using these pseudonormals to determine the sign when the nearest point is on an edge or vertex of the mesh.
Background	Bærentzen and Aanæs [2002] provided a proof that this procedure results in accurate signing (in exact arithmetic).
Approach	The ability to compute exact distances is one of the chief advantages of having an explicit surface representation.
Approach	Interpolation can produce substantial errors (see Figure 3 ) which are compounded over time.
Approach	In fact, this interpolation error is one of the most significant drawbacks to semi-Lagrangian methods in general.
Background	When used for velocity advection, interpolation produces such significant smoothing that researchers have proposed a number of methods to add detail back to the flow [Fedkiw et al. 2001] or avoid semi-Lagrangian advection altogether [Zhu and Bridson 2005].
Outcome	In this work, we are able to leverage the advantages of semi-Lagrangian advection, without incurring the interpolation error that would otherwise undesireably smooth surface detail.
Approach	Our implementation makes heavy use of a structure we call the distance tree.
Approach	The distance tree is a balanced octree subdivision of the spatial domain.
Approach	The octree vertices are annotated with signeddistance values and each cell of the octree contains a list of the triangles with which it intersects.
Approach	(2) It provides a fast, approximate signed-distance function, which is sufficient when evaluating the signed distance far from the surface.
Approach	(3) It guides the contouring algorithm, quickly identifying cells which have vertices of different sign and, thus, contain triangles.
Approach	When computing the signed distance from a point x to a surface, S, we first find the smallest octree cell, C, containing x .
Approach	If C is at the finest level of the octree, then x may be near the surface and all the triangles in the up to 27 cells in the concentric triple 1 of C are considered when computing the minimum distance to the surface.
Approach	By storing the nearest distance seen so far and using standard bounding-box techniques, many of these triangles can be pruned before computing distances, especially when x is very near the surface.
Approach	If the computed distance is less than C’s edge length, then the distance is guaranteed to be exact.
Approach	Otherwise, the computed distance is a very good estimate but may be slightly larger than the actual distance.
Approach	Contrariwise, if C is not at the finest level of the octree or if there are no triangles in the concentric triple of C, then x is not near the surface and we do not require an exact distance.
Approach	An approximation with the correct sign is sufficient.
Approach	In this case, we use trilinear interpolation of the distance values stored at the vertices of C.
Approach	We make use of two different methods for building distance trees in this work.
Approach	Most often, we wish to build a distance tree to resolve the zero set of our field function ψ.
Approach	However, it is also useful to build a distance tree from an existing triangle mesh.
Approach	Our octrees are always built in a top-down manner where each cell is split based on some variation of the following splitting criterion:
Approach	Splitting ends when the tree reaches a predetermined maximum depth.
Approach	Criterion (11) results in a three-color octree, as described by Samet [1990], where each cell of the octree has one of three types: interior, exterior, and boundary (see Figure 4 ).
Approach	—A cell’s size is proportional to its distance to the surface.
Approach	—If φ is the signed distance to the surface at vertices and we extend φ into each cell by trilinear interpolation, then, because cells vary in size, φ will be discontinuous.
Approach	However, the jumps in φ decrease in size in cells near the surface because of the triangle inequality.
Approach	Thus the interpolated φ is nearly continuous near the surface.
Approach	—Cells coarsen very rapidly away from the surface: if there are N childless cells touching the surface, then the entire tree contains only O(N log N ) cells.
Approach	Hence the surface is resolved accurately at minimal cost.
Approach	The octree is built recursively from the root cell C 0 by the following splitting criterion:
Approach	Thus we apply Criterion (13) as if ψ n+1 were a distance function.
Approach	Thus in the limit, t = O( x) → 0, Criterion (13) reduces to (11), yielding the properties noted above.
Approach	In practice, we use the value of φ at the cell’s center to determine whether we should split the cell.
Approach	To deal with the fact that ψ n+1 is not a distance function and that the value at the cell’s center may not be the minimum over the cell, we multiply the edge length by some constant before doing the comparison.
Approach	We have found that 1/3 works well in practice—always dividing near the surface, without spuriously dividing too many cells.
Approach	Notice that we can vary this constant to achieve high-resolution bands of varying width around the surface.
Approach	When building an octree from a triangle mesh (either in initialization, or after some geometric operation has been applied to the triangle mesh) we use the following splitting criterion:
Approach	This test is efficiently implemented using Green and Hatch’s [1995] cube/triangle intersection test.
Approach	Once we have resolved ψ on our distance tree, we need to create an explicit representation of our surface at the new timestep.
Approach	Creating this explicit representation amounts to extracting the zero set of ψ and is an instance of the contouring problem, which has been well studied in computer graphics.
Approach	For its simplicity, robustness, and speed, we choose to use a marching-cubes method in our implementation.
Approach	Our implementation is based on Bloomenthal’s [1994].
Approach	Our cubes are the leaf cells in the distance tree which have vertices of differing sign.
Approach	We divide each cube into six tetrahedra to simplify the implementation.
Approach	Additionally, when finding the zero crossing along any edge (which will eventually be a vertex in the triangle mesh), we use a secant method to speed up convergence and evaluate our full composite field function, including exact evaluation of the previous signed-distance function.
Approach	Consequently, the vertices of our polygon mesh are guaranteed to lie on the implicit surface (within an tolerance).
Approach	In fact, each vertex in our polygon mesh can be mapped to some point on some triangle in the mesh at the previous timestep.
Approach	We take advantage of this fact when advecting surface properties.
Approach	The marching-cubes algorithm works well for our purposes because each triangle generated by marching cubes sits strictly inside a single cell of the distance tree, making the distance tree an especially effective spatial index.
Approach	Furthermore, we use the distance tree we have already built to guide the marching cubes, avoiding the need to build a second structure to determine the topology of the new mesh.
Approach	Near the surface, our distance tree is refined to the maximum level and looks like a uniform grid.
Approach	Consequently, we need not worry about patching the marching-cubes solution.
Outcome	Our choice of contouring algorithm does result in some limitations.
Outcome	In addition to creating poorly shaped triangles, marching cubes is nonadaptive.
Outcome	That is, the sampling is as dense in flat regions as in regions of high curvature.
Approach	Unfortunately, the nonadaptive nature of marching cubes limits the resolution we can achieve in high-curvature areas, but is necessary to ensure compatibility.
Background	To address this lack of resolution in high-curvature areas, Strain [2001] split line segments whose centers were far from the surface, yielding arbitrarily high accuracy.
Background	Unfortunately, this splitting technique is not easily extended to three dimensions as splitting a triangle either creates an incompatible triangulation or produces even more poorly shaped triangles.
Approach	It is also very difficult to guarantee that we will still have a manifold when the inserted vertices are moved to the surface.
Background	Alternatively, several adaptive contouring methods [Shu et al. 1995; Shekhar et al. 1996; Poston et al. 1998] seek to use adaptive grids and regain compatibility through various crack-patching techniques.
FutureWork	Such methods could easily be used here and we plan to explore adaptive methods in future work.
Approach	Although we did not find it necessary, after the contouring step the mesh can be processed in any way that preserves the closed-manifold invariant.
Approach	This optional processing might include smoothing the surface, improving the shape of the triangles, or any other operation that returns a closed manifold.
Approach	A new distance tree can then be built from this modified mesh using Criterion (15).
Approach	A new distance must be built only if the mesh is modified.
Approach	By taking advantage of the details of our method, we can very efficiently achieve limited smoothing in two ways.
Approach	First, we can define a second composite function to be the combination of path tracing backward in time followed by the evaluation of a high-order polynomial interpolant of the distances at the vertices of the octree.
Approach	This function is quite similar to the functions used in semi-Lagrangian level-set methods [Strain 1999b; Enright et al. 2005].
Approach	When marching cubes encounters an edge whose vertices have different signs, we find a point which evaluates to zero for each composite function.
Approach	The final mesh vertex is an average of these two points.
Approach	By constraining the mesh vertex to be on the edge of the marching-cubes grid, we still guarantee a consistent, closed, manifold triangulation.
Approach	While this smoothing technique may be quite useful in some applications, we did not use this method for any of the results in this article.
Approach	Second, repeatedly using the same grid for contouring can produce grid artifacts.
Approach	For example, a sphere of fluid falling under gravity will develop creases along the coordinate axes.
Approach	Such artifacts are a form of aliasing and can be reduced by jittering the grid each timestep.
Approach	Most of the examples in this article used grids which were slightly larger than the simulation domain.
Approach	These grids were then randomly perturbed so that grids at adjacent timesteps were slightly offset from one another.
Approach	This jittering limits the reusability of our octrees, but since we build new octrees every timestep, this limitation is not significant.
Approach	After the triangle mesh at the current timestep has been extracted, we must assign true distance values to the vertices of our octree.
Background	This problem, referred to as redistancing, has been well studied by the level-set community and a number of methods have been suggested.
Background	Strain [1999a] suggested redistancing by performing an exact evaluation at every vertex of the octree.
Background	This method is relatively efficient since the tree coarsens rapidly away from the surface and works well in two dimensions.
Approach	However, in three dimensions, we have found it to be prohibitively expensive and unnecessary.
Approach	Instead, we perform exact evaluation at all vertices of the cells that contain triangles, but then run a fast marching method [Sethian 1996; Losasso et al. 2004] over the remaining vertices.
Approach	In our method, there may be some parts of the domain where the octree was refined but did not result in any triangles, such as when the surface becomes thinner than the resolution of the tree.
Approach	Consequently, our octree, unlike those used by Losasso et al. [2004], does not necessarily coarsen away from the surface.
Approach	To address this problem, we coarsen parts of the tree which have been refined but did not generate surface.
Approach	We do this coarsening in two steps.
Approach	First, we propagate the triangle lists up the tree so that the triangle list of a cell is the union of the triangle lists of a cell’s descendants.
Approach	Second, we remove all the children of any cell whose concentric triple does not contain any triangles.
Approach	Our redistancing method comprises three steps: —coarsen the octree; —compute exact distances at vertices of cells which contain triangles; —run a fast marching method over the remaining vertices.
Outcome	One of the primary advantages of our method is the ability to track surface properties, such as color, texture coordinates, or even simulation variables, accurately at negligible additional cost.
Approach	As pointed out earlier, every vertex in a polygon mesh corresponds to some point on some triangle in the previous mesh.
Approach	Thus, semi-Lagrangian advection provides a mapping between surfaces at adjacent timesteps.
Approach	If vertex v in the current mesh maps to point p in the old mesh and some surface property was stored at p, this property can be copied to v.
Approach	In this way we can track surface properties on the actual surface as we build the surface, so we do not incur any significant additional cost.
Background	Previous methods, such as the one proposed by Rassmussen et al. [2004], have been limited to tracking properties in the volume near the surface and interpolating them to the surface.
Background	Such methods incur significant cost, introduce substantial smoothing, and blur properties between nearby surfaces.
Approach	In many cases it is sufficient to use barycentric interpolation to compute a value at p and copy this interpolated value to v.
Approach	However, for some applications this interpolation can produce unwanted smoothing.
Approach	Essentially, we are having trouble because we are resampling the surface at every timestep.
Approach	However, if we know something about the property we are tracking, we may be able to “clean up” the blurred signal.
Approach	For example, in our examples with checkerboard textures, we tracked reference coordinates which were passed to a simple function to determine color.
Approach	Since we know that the tracked value should always be a point on the initial surface we could find the point on the initial mesh which was closest to the value the tracking method supplied.
Approach	In this way, we ensured that, at every timestep, every vertex in the mesh mapped back to some point on the initial surface.
Approach	Once we had this mapping we could copy any property stored on the initial surface, whether it be the reference coordinates, texture coordinates, or color values.
Approach	Thus, if image textures were preferred over procedural textures, texture coordinates could be copied instead of reference coordinates.
Outcome	There are still plenty of open problems in the area of texturing liquid surfaces.
Outcome	In particular, it is difficult to deal with large discontinuities in surface properties, which occur when two surfaces merge, or a surface splits.
Outcome	Creating detail where a surface stretches is also an open problem.
Approach	We have tested this surface tracking method coupled with a fluid simulation on several examples such as the ones shown in Figures 5 and 6.
Approach	We also tested it in the spiraling analytical test field from Enright et al. [2002a].
Outcome	The sphere was restored to a nearly identical shape (see Figure 8 ), while the bunny exhibited a small amount of smoothing.
Approach	At each timestep, the morphogens were advected along with the surface and then allowed to react.
Approach	All of our fluid examples used a standard regular-grid Eulerian fluid simulator with the elasticity model of Goktekin et al. [2004].
Approach	The fluid simulator and the surface tracking module were only very loosely coupled: the fluid simulator provided the surface tracker with a velocity function and, in turn, the surface tracker provided the simulator with the signed-distance function.
Approach	Because our fluid simulator has a regular grid its resolution is notably coarser than the surface tracker, which uses an octree.
Background	The idea of using different resolutions for the fluid and surface is not new; Foster and Fedkiw [2001] used different timesteps for their fluid and surface calculations and Goktekin et al. [2004] found that increasing the spatial resolution of the surface tracking grid dramatically reduced volume loss.
Background	As noted by Losasso et al. [2004], using different spatial resolutions can produce artifacts.
Background	For example, pieces of surface could appear connected when the simulator thinks they are disconnected and vice versa.
Background	Additionally, surface features may be maintained when a more detailed fluid simulator would smooth them away.
Outcome	In general, we found the increased surface resolution to be worth these artifacts.
Approach	Ideally we would use a multiresolution fluid simulation, like the octree method of Losasso et al. [2004].
FutureWork	We plan to incorporate a multiresolution fluid simulator as part of our future work.
Outcome	For most of our examples the surface tracking module took roughly 1 min/timestep at an effective resolution of 512 3 .
Outcome	The fluid simulation also required about 1 min/timestep.
Outcome	Both the fluid simulator and the surface tracking module took 11 timesteps per frame.
Outcome	Thus it took about 2 days to simulate 10 s of animation, with roughly half the time spent solving for the velocity field and half the time updating the surface.
Outcome	It is important to note that, given a perfect semi-Lagrangian path tracer, the method could take arbitrarily large timesteps.
FutureWork	Decoupling the timesteps of the fluid simulator and surface tracker, so that the surface tracker runs only once per frame, is an interesting area of future work.
Approach	This surface is textured by advecting reference coordinates along with the flow and applying a procedural checkerboard texture.
Outcome	The motion of the spots on the surface occurs both from the motion of the surface and from the reactiondiffusion system seeking equilibrium on the moving surface.
Outcome	As the streams oscillate from side-to-side, they collide and produce a thin, web-like surface between them.
Outcome	The motion of the two streams causes this thin surface to form a spiral shape as the streams separate.
Outcome	Similar effects can be seen in real-world footage.
Approach	All of our images were rendered with the open-source renderer Pixie [Arikan 2005].
Approach	Many of our examples were rendered with a matte shader so that the surface detail can be seen.
Approach	A number of our examples were also rendered with a glass shader (using water’s index of refraction) for comparison to previous methods and real fluids, and to demonstrate how the method can be used to generate realistic results.
Outcome	Our colored and textured examples illustrate how easily a variety of properties may be attached to the surface.
Outcome	In practice, we believe that advected properties could be used effectively with standard shading techniques to generate a wide range of interesting effects.
Outcome	Semi-Lagrangian contouring offers an elegant and effective means for surface tracking and has a number of advantages over competing methods.
Outcome	First, we have an explicit representation.
Outcome	In addition to enabling exact evaluation, this explicit representation also allows us to leverage 30 years of computer graphics technology which has been optimized for polygonal meshes.
Outcome	Rendering, texture mapping, and a variety of other applications are all very straightforward.
Outcome	Second, we have an implicit representation.
Outcome	This implicit representation allows us to update the surface without explicitly addressing any of the difficult topological issues which plague other approaches.
Outcome	Third, semi-Lagrangian advection gives us a mapping between surfaces at adjacent timesteps.
Outcome	This mapping allows us to accurately track surface properties on the actual surface at negligible complexity and cost.
Outcome	Fourth, our method does not have any ad hoc rules or parameters to tune.
Outcome	In fact, the only parameters to our system are the upper and lower corners of the domain, the maximum depth of the octree (a resolution parameter), and some resolution tolerances.
Outcome	Finally, and most importantly, we are able to produce detailed, flicker-free animations of complex fluid motions.

Outcome	In this paper, we present a method for simulating the interaction of fluids with deformable solids.
Outcome	The method is designed for the use in interactive systems such as virtual surgery simulators where the real-time interplay of liquids and surrounding tissue is important.
Background	In computer graphics, a variety of techniques have been proposed to model liquids and deformable objects at interactive rates.
Challenge	As important as the plausible animation of these substances is the fast and stable modeling of their interaction.
Challenge	The method we describe in this paper models the exchange of momentum between Lagrangian particle-based fluid models and solids represented by polygonal meshes.
Approach	To model the solid-fluid interaction we use virtual boundary particles.
Approach	They are placed on the surface of the solid objects according to Gaussian quadrature rules allowing the computation of smooth interaction potentials that yield stable simulations.
Outcome	We demonstrate our approach in an interactive simulation environment for fluids and deformable solids.
Background	In these simulation environments, deformable objects play an important role.
Background	For the simulation of deformable solids, a variety of models have been proposed ranging from efficient mass-spring approaches to methods based on the physically more accurate Finite Element Method (FEM).
Background	Some of these methods allow the simulation of elastically and plastically deformable solids at interactive speed.
Background	More recently, there has been an increased interest in efficient methods for the realistic simulation of fluids.
Background	These approaches can be employed to represent blood or other liquids.
Background	Besides deformable models, they play an essential role in applications such as surgery simulation.
Background	So far, only a few interactive methods for the simulation of fluids with free surfaces have been proposed.
Challenge	With the ability to simulate both, deformable solids and fluids, a new problem has been introduced, namely the mod- eling of the interaction of these structures.
Challenge	An interaction model suitable for the use in interactive environments needs to be computationally efficient and the generated interaction forces must not induce any instabilities to the dynamic simulation.
Outcome	In this paper, we present a new technique to model interactions between particle based fluids and mesh based deformable solids which meets these constraints.
Approach	We present our interaction model with fluids represented by a Smoothed Particle Hydrodynamics approach (SPH) and with deformable solids represented by a Finite Element approach.
Outcome	However, the general interaction model we propose works with any type of deformation technique as long as the object surface is represented by a polygonal mesh and the fluid by Lagrangian particles.
Background	The majority of publications in the area of physically based animation focuses on physical systems of one single type.
Background	Deformable objects are interesting to study in their own right.
Background	In fluid simulation, on the other hand, boundary conditions are often considered a necessary but not a central issue.
Background	They are typically derived from simple geometric primitives.
Approach	Our method connects these two areas of research.
Background	In the field of computer graphics, a large number of mesh based methods for the physically based simulation of deformable objects have been proposed since the pioneering paper of Terzopoulos [ 1 ].
Background	Early techniques were mostly based on mass-spring systems, which are still popular for cloth simulation [ 2 , 3 ].
Background	More recent methods discretize continuous elasticity equations via the Boundary Element Method (BEM) [ 4 ] or the Finite Element Method (FEM) [ 5 , 6 , 7 ].
Background	Since T. Reeves [ 8 ] introduced particle systems as a technique for modeling fuzzy objects twenty years ago, a variety of special purpose, partice based fluid simulation techniques have been developed in the field of computer graphics.
Background	Desbrun and Cani [ 9 ] where among the first to use Smoothed Particle Hydrodynamics (SPH) [ 10 ] to derive interaction forces for particle systems.
Background	They added space-adaptivity in [ 11 ].
Background	Later, Stora et al. [ 12 ] used a similar particle based model to animate lava flows.
Background	In [ 13 ], Müller et al. derived inter particle forces from SPH and the Navier Stokes equation to simulate water with free surfaces at interactive rates.
Background	Recently, Premoze et al. [ 14 ] introduced the Moving-Particle SemiImplicit (MPS) method to computer graphics for the simulation of fluids.
Background	As a mesh-free method, it is closely related to SPH but in contrast to standard SPH, it allows the simulation of incompressible fluids.
Background	In all these papers, boundary conditions are not treated explicitly.
Background	The fluids typically interact with solid walls or the ground.
Background	Genevaux et al. [ 15 ] address the interaction problem explicitly.
Background	They propose a method to simulate the interaction between solids represented by mass-spring networks and an Eulerian fluid grid by applying spring forces to the mass-less marker particles in the fluid and the nodes of the mass-spring network.
Background	However, solids are typically represented by coarse meshes, especially in interactive simulations.
Background	Thus, the nodes of a mass-spring network are not very well suited for the application of interaction forces.
Background	Therefore, Monaghan, one of the founders of the SPH formalism, uses special boundary or ghost particles on fixed borders to model interactions [ 16 ].
Background	The idea of ghost particles was picked up in several following projects including our own.
Outcome	The key contribution of our paper is to place these ghost particles onto boundary triangles of deformable objects and to derive their locations and weights according to Gauss integration [ 17 ], which allows to model fluid-solid interactions stably at interactive rates.
Challenge	In physically based animation, we are interested in the simulation of macroscopic effects at interactive speed.
Approach	Therefore, we consider macroscopic models for both, solids and fluids.
Background	Materials, which are homogeneous at the macroscopic level, can mathematically be described as a continuum [ 18 ].
Approach	Thereby, quantities such as the density ρ, viscosity μ, deformation u or velocity v are all mathematically expressed by continuous functions over space and time.
Approach	A physical model relates these quantities to each other via partial differential equations (PDEs).
Approach	The stresses σ s are functions of the displacements u.
Approach	The equation is in Lagrangian form since the displacement vectors u follow the material points.
Approach	Similarly, mechanical properties of incompressible Newtonian fluids can be described by the following two equations in Eulerian form where fluid quantities are observed in a fixed coordinate frame
Approach	Equation (2) again states that the change of momentum equals the internal forces derived from the stresses σ f plus the externally applied body forces f .
Approach	The stress tensor σ f = 2μ (v) − pI is composed of the viscosity stress and the pressure stress.
Approach	Comparison of the right hand side of the two equations of motion (1) and (2) reveals, that the Eulerian description makes the additional convection term v · ∇v necessary.
Approach	For fluids we focus on particle based methods such as SPH for which this term can be omitted.
Background	Materials such as fluids or solids are bounded by spatial limits.
Background	The behavior of materials at these limits is defined by boundary conditions.
Approach	The boundary conditions relate the quantities of the two adjacent materials to each other at the interface.
Approach	In the case of fluid-solid interaction, the geometrical domain of the interface Γ is defined as a surface between the volumetric solid continuum and the volumetric fluid continuum (see Fig. 2(a) ).
Approach	We focus on three main types of boundary conditions.
Approach	If the solid is considered to be impermeable, no fluid element is allowed to cross the boundary, which is described in the following equation:
Approach	The equation states that the components of the velocities of the fluid and the deformable object perpendicular to Γ are equal.
Approach	The no-slip condition models friction between the fluid and the solid (see Fig. 2(c) ).
Approach	If both independent boundary conditions (4) and (5) hold, we simply have ∂t ∂ u = v at the boundary, i.e. both materials have the same velocity at the boundary.
Approach	Newton’s Third Law demands the continuity of stresses σ s and σ f throughout the boundary (see Fig. 2(d) ).
Approach	The continuous equations and boundary conditions described in the previous section need to be discretized in space and time via a numerical method before they can be used in a computer simulation.
Approach	We do not go into the details of how equation (1) for elastic objects can be solved numerically.
Background	For possible solutions using the Finite Element Method (FEM) we refer the reader to [ 19 ], [ 6 ] or [ 7 ].
Approach	All we require for our interaction method to work is • that the solid object is represented by a mesh and • that the displacements, velocities and forces are carried by the nodes of the mesh.
Background	Most of the methods used in computer graphics to simulate deformable objects meet these constraints including massspring systems, the Finite Volume Method (FVM) and the Boundary Element Method (BEM).
Approach	In this paper we concentrate on Lagrangian methods because they allow fluids with free surfaces to move freely in space while in the Eulerian case fluid computations are restricted to a spatially fixed and bounded grid.
Approach	From the fluid simulation method we require • that the fluid is represented by a set of particles and • that positions, velocities and internal forces are carried by the particles.
Approach	Interaction modeling, thus, reduces to the problem of simulating the interaction between particles and triangulated surfaces.
Background	In physics, interaction potentials of two objects always depend on the distance between them.
Approach	While the Euclidean distance between two points is uniquely defined, the distance between a point and a triangle or a point and a triangulated surface needs to be defined.
Approach	Unfortunately, concavities as well as close disconnected meshes generate discontinuous first derivatives of the distance field.
Approach	Those discontinuities lead to discontinuous derivatives in forces since the forces depend on the distance field.
Approach	A force field with discontinuous first derivatives, in turn, yields artifacts such as the so called cooking of particles in concave regions and reduced stability of the simulation.
Approach	One way to remove the problem is to replace the minimum by a weighted sum.
Approach	Let the kernel W (d, h) ∈ C 1 be a positive smooth monotonously decreasing function which is zero for d ≥ h and has a vanishing derivative at d = h.
Approach	However, as Fig. 3(b) shows, the resulting field is distorted near triangle boundaries.
Approach	Unfortunately, normalization just distributes the distortions to adjacent regions of triangle interfaces as Fig. 3(c) shows.
Approach	Another difficulty introduced by the weighted field method is the choice of the support radius h with respect to the size of the features of the boundary T .
Approach	For large supports, small features are smoothed out while small supports reduce the interaction range of T .
Background	The problems mentioned in the previous section are well known in the field of implicit surface modeling introduced by Blinn [ 23 ].
Approach	The implicit surface is defined by selecting an iso-surface of F S .
Approach	By replacing the skeleton S with the triangulated surface T we get a smooth potential field around T (see Fig. 3(d) ).
Approach	The problem with the weighted sum approach arises when when multiple triangles meet.
Approach	In this case, all triangles contribute as a whole to the sum and generate bulges.
Approach	In contrast, the convolution integral sums up infinitesimal parts of the skeleton each properly weighted (see Fig. 4 ).
Approach	When the convolution integral is used, the interaction of p with the surface T is modeled as the interaction of p with all the infinitesimal points in T .
Background	Approaches to approximate this integral were proposed by Bloomenthal [ 24 ] and Sherstyuk [ 25 ].
Background	Bloomenthal uses radial Gauss kernels which can be separated with respect to different dimensions.
Background	The separation allows post evaluation of the convolution in 3D space, only considering the distance to the triangle plane.
Background	Sherstyuk discovered a special kernel which can be analytically convoluted over a triangle domain.
Approach	Neither method is suitable for computing physical interactions because we are not free in the choice of the kernel.
Approach	The potential function is given by physical laws.
Approach	Our idea to solve the convolution integral is to use Gauss quadrature rules [ 17 ].
Approach	We use the seven point rule which has convergence order O(L 6 ) with respect to the triangle size L. (see Fig. 5(a) and Tab.
Approach	These sampling points can be interpreted as boundary particles, which are placed and weighted according to the chosen Gauss quadratur
Approach	The weighted summation of their potentials approximates the convolution of the potential over the domain of the boundary triangle in an optimal way.
Approach	Although the seven point rule yields good approximations of the convolution integral, triangles that are large in comparison to the interaction range of the surface would induce a poor sampling of the boundary field.
Approach	Therefore, we subdivide the boundary triangle until a sufficient sampling rate is provided.
Approach	We define a threshold for the maximal acceptable distance between boundary particles.
Approach	This threshold is chosen relative to the maximal interaction radius of the fluid particles and can be regulated by the user.
Approach	The boundary particles are generated by subdividing the triangle domain and by application of the Gauss quadrature rule to the resulting triangles (see Fig. 5(b) ).
Approach	This has to be done at every time step, because triangles on the boundary are moved and deformed.
Approach	Therefore, an efficient scheme is needed.
Approach	We compute the relative vectors from the triangle nodes (shown in blue) to the boundary particles (shown in red) only once because they are the same for all subdivision triangles.
Approach	These vectors are then added to the blue nodes to generate the complete set of boundary particles.
Approach	Analog to positions, the velocities of boundary particles are interpolated from the velocities of the triangle nodes.
Approach	Now that we have replaced the triangulated surface by a set of particles, the problem of triangle-particle interaction reduces to particle-particle interaction.
Approach	We can, thus, use SPH-based approaches to approximate the boundary conditions stated in Sections 3.2, 3.3 and 3.4.
Background	Monaghan [ 16 ] uses a Lennard-Jones-like force to generate repulsive forces which approximate the no-penetration condition.
Approach	We propose a Lennard-Jones-like force that models both repulsion and adhesion to the contact surface.
Approach	The traction τ ra is dependent on the distance of the surface element from the particle p and has unit force per area in order to yield a force when integrated over the triangle.
Approach	The traction has an order four repulsion term and an order two attraction term.
Approach	It is designed to be zero for r = r 0 which is the preferred distance of fluid particles from the interface.
Approach	The fact that for r = 0 the traction is finite (τ ra (0) = k) and that both, traction and first derivative vanish for r = h are important for robust real time simulations.
Approach	We use the normalized kernel W visc proposed in [ 13 ] for viscosity computations.
Approach	The kernel W visc is designed such that its Laplacian ∇ 2 W visc takes the linear form above, but satisfies the normalization criterion on the kernel itself.
Approach	The normalization warrants second order interpolation convergence.
Approach	So far, we have applied forces to fluid particles only.
Approach	However, according to Newton’s Third Law, proper reaction forces need to be applied to the deformable solid as well.
Approach	The force contributions of boundary particles have to be distributed among the boundary triangle vertices so they can be picked up by the simulator of the deformable object.
Background	Bridson et al. [ 26 ] solve a similar problem in the context of cloth simulation.
Background	To resolve vertex-triangle collisions, an impulse is applied to the colliding vertex.
Background	Then, a distribution scheme is used to compute the corresponding reaction impulses for the three vertices of the triangle.
Approach	We use the same scheme to distribute the forces to the vertices of the triangle surface.
Background	According to [ 26 ] this distribution scheme provides continuity across triangle boundaries and introduces appropriate torques for off-center interactions.
Background	However, the scheme is not completely error free.
Approach	Force magnitudes can get amplified – at most by a factor of 8/7 – at the triangle center.
Approach	However, this error did not cause any artifacts or stability problems in our simulations.
Approach	At every time step of the solid and fluid simulator, the following five steps are executed: 1.
Approach	Processing the five phases one after the other would have a negative impact on storage requirements.
Approach	Neighbor references and boundary particles for all triangles would have to be stored at the same time.
Approach	If the computations of steps three to five are grouped around single triangles, only data relevant for the current triangle has to be stored at a time ( Fig. 6 ).
Outcome	The output of step 3 is a list, containing all fluid particles within interaction range h of a triangle t.
Approach	To speed up the search for these particles we use a regular grid with spatial hashing [ 27 ].
Approach	There is a trade-off between computation time for the neighbor search and the quality of the neighbor list.
Approach	We extend the axes aligned bounding box (AABB) of t along all axes about the interaction range.
Approach	Then, we query all grid cells intersecting the extended box.
Approach	We also tested tighter queries which generate fewer neighbor candidates but their increased time complexity was not compensated by the reduced cost of interaction computations.
Approach	In step 4, boundary particles are only generated for those triangles that have fluid particle neighbors.
Approach	The boundary particles for a triangle t are kept only temporarily for the interaction computation.
Approach	After t is processed, they are discarded.
Approach	In this step, positions and velocities are interpolated from the triangle nodes for each boundary particle.
Approach	To compute interaction forces in step 5 we iterate over all the boundary particles of a triangle.
Approach	All experiments described in this section have been performed on an AMD Athlon 1.8 GHz PC with 512 MB RAM and a GeForce Ti 4400 graphics card with 128 MB RAM.
Approach	Note that most of the simulations are recorded in a real-time interactive environment.
Approach	Thus, we cannot afford several seconds or even minutes per frame for the reconstruction and rendering of the free fluid surface as in off-line simulations [ 14 , 15 ] which explains the simplistic renderings of the fluids.
Approach	To demonstrate the stability of our model in connection with concave surfaces, we filled a pool composed of 800 tetrahedral elements with 2000 fluid particles (see Fig. 7(a) ).
Approach	The simulation runs at 20 frames per second.
Approach	By pulling the pool wall, the user indirectly influences the water.
Outcome	The generated waves, in turn, deform the pool walls.
Outcome	Deformable boxes float freely on the water surface (see Fig. 7(b) ).
Approach	We dropped an additional large box into the pool (see Fig. 1 ).
Outcome	When it touches the water, it emits a wave that hits the pool boundary and causes it to fracture.
Outcome	This scene demonstrates the interplay of various physical phenomena provided by the fluid simulator, the solid simulator and the interaction model.
Outcome	An important application of our method is the simulation of bleeding during virtual operations.
Approach	Our simulation of a blood vessel is a first step into this direction.
Approach	We simulate the flow of 3000 particles through a virtual vessel, consisting of a deformable mesh composed of 560 tetrahedra.
Outcome	The simulation took about 70 ms per time step.
Approach	The velocity of the fluid particles is color coded visualizing the friction of the fluid with the boundary.
Approach	In the experiment shown in Fig. 10 , we turned on fracture of the Finite Element mesh.
Approach	Now, the vessel is torn open when the elastic stresses caused by blood pressure exceed the material threshold.
Approach	The free surface of the particle system is rendered using the Marching Cubes algorithm.
Outcome	The animation of the mesh and the particles are possible in real time at 60 ms per time step, while surface reconstruction took about half a second per frame.
Outcome	On today’s hardware only a limited number of fluid particles can be simulated in real-time which yields a relatively coarse fluid surface.
Outcome	We have presented a new method for the simulation of interactions of deformable solids with fluids.
Outcome	Our interaction model simulates repulsion, adhesion and friction near the fluid-solid interface.
Outcome	The smoothness of the force fields is important for the stability of the simulation.
Approach	The core idea to get smooth interaction fields is to place boundary particles onto the surface triangles according to Gauss quadrature rules.
Outcome	This idea might be useful in other graphic domains as well.
Outcome	We mentioned the application to modeling with implicit surfaces.
Outcome	Character skinning is another application where bulges or knees are known problems in regions where several close bones meet.
Outcome	We demonstrated the usability of our method in an interactive simulation environment with several scenes.
Outcome	A difficulty in connection with the interactive simulation of fluids is the extraction and rendering of a plausible fluid surface in real time.
FutureWork	Thus, ongoing work focusses on fast algorithms for surface reconstruction.

Challenge	This paper presents a method for animating fluid using unstructured tetrahedral meshes that change at each time step.
Outcome	We show that meshes that conform well to changing boundaries and that focus computation in the visually important parts of the domain can be generated quickly and reliably using existing techniques.
Challenge	We also describe a new approach to two-way coupling of fluid and rigid bodies that, while general, benefits from remeshing.
Outcome	Overall, the method provides a flexible environment for creating complex scenes involving fluid animation.
Challenge	Although systems for physically based fluid animation have developed rapidly in recent years and can now reliably generate production-quality results, they still have some limitations.
Challenge	Simulation domains can change substantially from step to step because of deforming boundaries, moving obstacles, and evolving fluid motion, yet current systems based on fixed grids are not ideally suited to handle these situations.
Approach	When generating the mesh, we use the position and shape of boundaries as well as criteria based on the visually important parts of the fluid and velocity field to construct a sizing field that dictates the desired edge length for tetrahedra throughout the domain.
Approach	We then use an efficient and reliable meshing algorithm adapted from [ Alliez et al., 2005 ] to produce a mesh that is refined according to this field.
Approach	We use unstructured tetrahedral meshes because they conform to curved and irregular boundaries better than axis-aligned grids with the same number of grid elements and allow for precise control of refinement throughout the domain.
Approach	We transfer the physical properties of the simulation from the old mesh to the new mesh using a generalization of the semi-Lagrangian velocity advection technique that introduces no additional smoothing.
Approach	We then perform a mass conservation step that has been extended to allow a new, single-step solution of two-way coupling between fluid and rigid bodies.
Outcome	Overall, this approach provides a flexible framework for fluid simulation that opens the door to many features.
Outcome	We have implemented the system and tested it in a variety of scenarios such as the one shown in Figure 1 .
Outcome	We have found that the combination of unstructured tetrahedral domains and dynamic remeshing creates a versatile environment for the creation of complex and visually interesting fluid animations.
Background	The animation of fluids through physical simulation has become an important tool in the visual effects industry.
Background	One approach that has been popular in recent years makes use of a spatial discretization based on regular, fixed, hexahedral grids.
Background	Some examples of this approach can be found in [Foster and Metaxas, 1996], [Foster and Metaxas, 1997], [Stam, 1999], [Yngve et al., 2000], [Fedkiw et al., 2001], [Foster and Fedkiw, 2001], [Enright et al., 2002], [Carlson et al., 2002], [Feldman et al., 2003], and [Goktekin et al., 2004].
Background	The most commonly used storage scheme for these approaches is the “staggered grid” scheme.
Background	This method offsets storage of different quantities on the grid, and was first described by [Harlow and Welch, 1965].
Background	Efforts have been made to enhance these methods to allow for better conformance to irregular boundaries such as the free surface of liquids, complex obstacles, or irregularly shaped domains.
Background	[Losasso et al., 2004] described an octree-based method that retains many of the advantages of regular grids while allowing computational effort to be focused in particular parts of the simulation domain; this enables detailed tracking of moving boundaries such as liquid surfaces.
Background	Both [Carlson et al., 2004] and [Guendelman et al., 2005] have demonstrated methods for two-way coupling of obstacles to fluid.
Background	Unstructured tetrahedra have also been used for fluid simulation within the graphics community.
Background	Two examples of this are [Feldman et al., 2005a] and [Elcott et al., 2005].
Background	The first method uses a velocity-based approach while the second uses a vorticity-based formulation.
Background	It is a blend of ideas from these two papers, along with a generalization of the semi-Lagrangian velocity advection technique for moving meshes described in [Feldman et al., 2005b] that forms the heart of our method.
Background	The idea of moving meshes independent of a fixed or particle-centric coordinate system is not a new one; arbitrary Lagrangian-Eulerian (ALE) methods were designed for just this purpose.
Background	They have proven useful in the simulation of highly deformable elastic materials.
Background	ALE was first described in [Hirt et al., 1974], where it was used with finite differences to solve compressible fluid problems.
Background	[Donea et al., 1977] went on to apply ALE in a finite element setting.
Background	An excellent survey of the development of ALE methods appears in [Donea et al., 2004].
Background	Examples within the graphics literature that feature moving meshes without remeshing include [Shah et al., 2004] and [Rasmussen et al., 2004], both of which translate the grid to follow the visually important portion of the fluid.
Background	Another approach to handling changing domains is to dispense with the mesh altogether, instead using Lagrangian particles for simulation of fluids.
Background	A few examples of this approach are [Terzopoulos et al., 1989], [Desbrun and Cani, 1996], [Cani and Desbrun, 1997], [Stora et al., 1999], [Müller et al., 2003], [Premo ze et al., 2003], and [Müller et al., 2004].
Background	These meshless methods are particularly well suited to changing domains because points can move freely without concerns about mesh quality.
Approach	Because we regenerate a new simulation mesh at each time step, the viability of our method hinges on fast, high-quality, reliable tetrahedral mesh generation.
Background	While a history of unstructured mesh generation is outside the scope of this paper, [Owen, 1998] and [Teng and Wong, 2000] provide good surveys of the field.
Approach	For our mesh generator we selected the approach described in [ Alliez et al., 2005 ].
Approach	This innovative method produces meshes which conform to domains of arbitrary topology quickly and reliably.
Approach	Also, it allows for the local edge length of the tetrahedra to be specified arbitrarily throughout space, which allows us to easily perform adaptive mesh refinement from step to step.
Approach	The meshes produced by this technique are Delaunay, which provides improved gradient estimation and allows us to significantly simplify some of the expressions that arise when interpolating velocity values stored on the mesh.
Outcome	The key contribution of our method is to demonstrate the freedom granted by remeshing at each simulation time step.
Approach	The core of our system is based on the simple, efficient methods for discretizing the inviscid Euler equations on tetrahe- dral meshes described in [Elcott et al., 2005] and [Feldman et al., 2005a].
Approach	We have made a few modifications in order to combine the best aspects of both approaches that are described below.
Approach	Once we have a good discretization, we need a way to propagate information from one mesh to the next.
Background	[Feldman et al., 2005b] details a generalization of the standard semiLagrangian velocity advection technique that allows simulation state to be transferred between deforming domains without incurring additional smoothing.
Approach	We demonstrate that their approach can easily be applied to transfer information between two arbitrary, topologically unrelated meshes, which is required to achieve more general evolution of the simulation domain from step to step.
Approach	Finally, we need to quickly and reliably generate a new tetrahedral mesh for each time step that suits the current simulation conditions, such as conformance to boundaries and obstacles as well as any desired refinement.
Background	Although methods have long existed to mesh arbitrary domains, most are relatively slow in comparison to simulation running times or don’t reliably terminate under realistic conditions.
Background	The availability of efficient, versatile meshing algorithms such as [ Alliez et al., 2005 ] has made the generation of a new mesh at each time step practical.
Challenge	Also, we describe a new, single-step method to achieve two-way coupling between obstacle and fluid motion.
Approach	We use a staggered fluid state storage scheme that stores pressures at tetrahedron circumcenters and “face-normal velocities,” the component of velocity in the direction of the face normal, at the face circumcenters.
Background	Similar schemes have been used in [Botta and Hempel, 1996], [Elcott et al., 2005] and [Feldman et al., 2005a].
Background	These methods are a generalization of the staggered grid scheme originally proposed by [Harlow and Welch, 1965].
Approach	This staggered method is used to discretize the inviscid Euler equations:
Approach	In these equations, u is the fluid velocity, t time, p pressure, ρ density, and f any external forces.
Approach	The symbol denotes T the vector of differential operators = [∂/∂x, ∂/∂y, ∂/∂z] .
Approach	We account for the changes in the mesh over a time step directly during semi-Lagrangian advection (see Section 3.2).
Approach	Divergence and gradient operators are needed as part of the mass conservation step.
Approach	We make discrete estimates of these derivatives following the formulation presented in [Losasso et al., 2004] and [Elcott et al., 2005].
Approach	The divergence of a tetrahedron is computed as an area weighted sum of the tetrahedron’s face normal velocities.
Approach	The gradient at a face circumcenter in the direction of the face’s normal is computed using finite differences.
Approach	The difference in circumcenter pressures adjacent to a face is divided by the distance between these circumcenters.
Approach	In Delaunay meshes, the line connecting adjacent tetrahedra circumcenters passes through the circumcenter of the face between them and is in the direction of that face’s normal.
Approach	This property of Delaunay meshes motivates our storage scheme at circumcenters because the gradient estimate is equivalent to the gradient of a piecewise linear function that interpolates the circumcenter values.
Approach	The staggered scheme stores only the component of velocity in the face normal direction.
Approach	For both the semi-Lagrangian step and to advect smoke particles for rendering, a full velocity vector must be found at arbitrary positions in the mesh.
Approach	We interpolate velocity vectors from face normal velocities using the two-step method developed in [Elcott et al., 2005].
Approach	First, a velocity vector, u t , is computed at each tetrahedron circumcenter, then we interpolate within Voronoi cells using u t values at the cell vertices.
Approach	Velocity u t for tetrahedron t is found by solving the small linear system N t u t = z t where N t is a matrix containing 4 rows of the face normals of t and z t is a vector of the 4 face normal velocities associated with t.
Approach	For a divergence-free field, this solution has the remarkable property that interpolating back to the face circumcenters exactly recovers the original face-normal velocities.
Approach	Thus interpolating the u t velocities also exactly interpolates the face-normal velocity components, and does not incur the error one would otherwise expect from a twostep interpolation method.
Approach	To find a velocity at an arbitrary point we interpolate within the Voronoi cell using the tetrahedra velocities associated with the cell.
Approach	This interpolation is based on the method of [Warren et al., 2004], which presents a way to interpolate within a general convex polytope.
Approach	Here, σ t is the set of polytope faces that intersect at node t.
Approach	The denominator is the product of distances from x to the faces in σ t computed using the face normals,n f , and plane offsets, d f .
Approach	|N t | is the determinant of a matrix of face normals in σ.
Approach	Weights from all nodes are normalized to sum to 1 before use in the weighted sum.
Approach	To simplify this computation we take advantage of two properties: 1) in a Delaunay mesh, edges are in the direction of the Voronoi cell’s face normals and 2) the volume of tetrahedron t is 1/6|E t | where E t is a matrix formed from the three vectors of edges emanating from a common node of t.
Approach	A similar observation appears in [Ju et al., 2005], and we find that with it the velocity interpolation is quite efficient.
Approach	All quantities appearing in Equation (4) are already stored for use in other parts of the timestep, saving the need to compute the terms in Equation (3).
Approach	When advecting large numbers of particles, velocities at nodes of tetrahedra can be first be found using Equation (4) and then quickly interpolated in a linear fasion over the tetrahedra to advect the particles.
Background	The simple and stable semi-Lagrangian method has become the standard tool for advection of the velocity field for graphical applications [Stam, 1999].
Approach	This method does not rely on velocities being stored at any particular place, as long as the velocity can be interpolated throughout space.
Approach	We can extend this technique naturally to meshes which change arbitrarily at each time step as in [Feldman et al., 2005b].
Approach	This extension does not incur any additional smoothing compared to using semi-Lagrangian advection with static meshes.
Approach	Suppose at time t velocities are stored at locations x (t) (in our case, the face circumcenters), and we want to find (t) the velocity at a particular face location x i .
Approach	We trace back (t) from x i through the velocity field of the previous time step to a point x i , which has no necessary correspondence to any feature of the old mesh.
Approach	Then, we update the velocity at (t) x i to the value interpolated from the old velocity field at x i .
Approach	Because the velocities from the previous step are stored on a different mesh, we have to trace back and interpolate using this previous mesh (see Figure 2 ).
Approach	The domain boundaries, obstacles, and smoke are free to move and change from step to step of the simulation.
Approach	By regenerating the mesh at each time step we can ensure that our domain conforms well to boundaries and is refined in visually important areas.
Approach	We accomplish this by using the variational tetrahedral meshing algorithm presented in [ Alliez et al., 2005 ].
Approach	This method allows for generation of tetrahedral meshes that conform well to an arbitrary input surface mesh, have no restrictions on topology (i.e., allow nested voids), and allow for sizing of tetrahedra throughout the domain based on arbitrary criteria.
Approach	Our implementation differs from the original algorithm in a couple of details.
Approach	As in the original method, refinement of the mesh is controlled by a sizing function μ(x) that, for any point x in the simulation domain, returns the desired local edge length of the tetrahedra.
Approach	In this equation, k 0 is an offset value that controls the minimum value of the sizing field, and hence the minimum local edge length of tetrahedra.
Approach	d(x) is the distance to the closest obstacle or boundary which demands refinement, s(x) is a function of the density of smoke particles, and ω(x) is a function of the vorticity of the velocity field.
Approach	The parameters k d , k s , and k ω respectively control the weight each of these functions has on the sizing field.
Approach	These three factors are the same as those used for octree refinement in [Losasso et al., 2004].
Approach	The overall goal of the sizing field is to focus computational effort in the most visually important parts of the scene, that is, near closed boundaries, where the velocity field varies most, and where smoke is visible.
Approach	This meshing method is iterative, so the mesh from the previous simulation time step can be used as an initial guess for the node placement in the mesh at the next simulation time step.
Approach	Because there is, in general, strong temporal coherence between steps of the simulation, the sizing field does not change too much and so the nodes from the previous step are often a good initialization.
Approach	Before the algorithm proceeds, the initial node placement is corrected to match the sizing field of the current step.
Approach	One other modification we made to the algorithm is that, when optimizing the node positions, we move nodes to the average of the barycenters of the surrounding tetrahedra instead of the circumcenters.
Approach	We have found that while this tends to slightly decrease the average quality of tetrahedra in the mesh, it often leads to substantial improvements in the quality of the worst elements of the mesh, which are of more concern for numerical simulation.
Approach	Of course, remeshing takes time, so it is important to consider the impact it has on overall simulation performance.
Outcome	The time spent generating meshes for each simulation step varies, but generally accounts for less than a quarter of the overall simulation time.
Challenge	The motion of fluid and rigid bodies that mutually effect each other can be complex and visually appealing.
Challenge	The interaction occurs as a consequence of the conditions that:          1.
Challenge	The velocities in the normal direction are the same at the interface of the fluid and the rigid body surface.
Challenge	The fluid velocity is divergence free and the rigid body velocity is rigid.
Challenge	The linear and angular momentum of the combined system is conserved.
Background	In [Carlson et al., 2004] these conditions are enforced sequentially.
Background	While for many cases this produces results that look very good, under some situations artifacts can be created because enforcing one of the conditions in general will break a previously enforced one.
Background	Examples of such artifacts might be fluid leaking through solid boundaries or poor performance in piston-like situations.
Approach	Our implementation differs from [Carlson et al., 2004] in a couple of ways, but most significantly we enforce these conditions simultaneously within the mass conservation step.
Approach	In general, the mass conservation step solves for pressures that accelerate the velocity field to be divergence free.
Background	In previous works, including those with two-way coupling, the mass conservation step treats faces to behave as fluid or explicitly prescribes their velocities.
Background	For fluid faces, the pressure accelerates the velocity proportional to the gradient of the pressure while for prescribed faces, the pressure does not effect the fluid.
Background	For a more complete discussion of fluid/prescribed-velocity mass conservation see [Fedkiw et al., 2001].
Approach	We extend mass conservation to include a dynamic, rigid body.
Approach	To do so, we solve for acceleration of the fluid and the rigid body, ignoring pressure for both.
Approach	We then solve for a pressure term that satisfies boundary and incompressibility constraints to find the final accelerations.
Approach	The rigid body accelerations can be computed by creating a matrix R that is multiplied by a vector of the pressures that surround a rigid body.
Approach	R can be formed by a series of matrix multiplications:
Approach	The rightmost matrix finds the net force-torque couple acting on a rigid body by summing up the contribution due to pressure forces acting on rigid body mesh faces.
Approach	M is a diagonal matrix with the mass of the rigid body on the diagonals and I is the inertia matrix.
Approach	The leftmost matrix in the multiplication returns the acceleration of the fluid-rigid faces in the direction of the face normal due to the linear and angular acceleration of the rigid body.
Approach	By construction, accelerations generated by this matrix behave rigidly.
Approach	Computing pressure accelerations of both the fluid and fluid-rigid faces can be expressed as a matrix A multiplied by a vector of all the pressures.
Approach	A row of A that corresponds to a face with fluid on both sides contains the same entries as the standard gradient matrix multiplied by −1/ρ.
Approach	With A built, mass conservation including two way coupling proceeds much in the same way as in the all-fluid case, with A replacing the role of the discrete gradient matrix.
Approach	For a given vector of pressures, p, the intermediate velocity field, z ∗ , is accelerated to the end-of-step velocity, z, by z = z ∗ + ∆tAp.
Approach	For the fluid faces, z ∗ is found by applying all terms of Equation (1) except the pressure term.
Approach	For the fluid-rigid faces, z ∗ is found using a rigid body simulator without pressure forces applied.
Approach	This linear system can be solved efficiently using PCG since the the matrix DA, which replaces the discrete Laplacian from the all fluid case, is also a positive-definite symmetric matrix.
Approach	Using the same machinery, we can also interact with constrained rigid bodies.
Approach	This simply requires finding an R matrix that correctly computes face accelerations due to pressure.
Approach	For example, one could easily alter R such that the body was constrained to just rotate about the origin by replacing b i in Equation (6) with b i = (r i × n i ) T and using only the I −1 block for the center matrix.
Outcome	This idea could be extended further to include even articulated bodies.
Approach	We implemented the method described above in matlab 1 and C, making use of Pyramid [Jonathan Shewchuck, personal communication] for Delaunay triangulation and pixie 2 for all renderings.
Outcome	Typical simulation times for meshes with 100,000 tetrahedra were about 1 minute per frame.
Outcome	Refinement of the simulation mesh near the paddle ensures good conformance to its curved surfaces that produce interesting vortex effects in the smoke.
Approach	The blue valves on either side of the bulb prevent backflow.
Approach	The motion of these valves is not scripted.
Approach	Instead, they are modeled as rigid bodies constrained to rotate about an axis and their motion is caused by two-way interaction with the fluid.
Outcome	On the left is a lighter bunny which is tossed about by the force of the cannons and also affects the motion of the smoke.
Outcome	On the right is a heavier bunny that drops quickly to the ground.
Outcome	Although quality of the mesh elements does not suffer at this level of refinement, the proportion of time spent meshing increases to 39.3%.
Outcome	The motion of the smoke at the higher resolution is more lively and exhibits more fine-scale detail.
FutureWork	A vorticity enhancement method, such as those in [Fedkiw et al., 2001] and [Selle et al., 2005] could be used to further enhance the fluid motion but we do not find such enhancement necessary and so have not implemented it.
Outcome	We have presented a system for performing fluid animation using unstructured tetrahedral domains that can change arbitrarily at each time step.
Outcome	Although our current implementation models completely fluid-filled domains, we believe it would be well-suited for use with surface tracking techniques for liquid simulation.

Approach	Given a corpus of motion capture data, we automatically construct a directed graph called a motion graph that encapsulates connections among the database.
Approach	The motion graph consists both of pieces of original motion and automatically generated transitions.
Approach	Motion can be generated simply by building walks on the graph.
Outcome	We present a general framework for extracting particular graph walks that meet a user’s specifications.
Outcome	We then show how this framework can be applied to the specific problem of generating different styles of locomotion along arbitrary paths.
Background	Realistic human motion is an important part of media like video games and movies.
Challenge	More lifelike characters make for more immersive environments and more believable special effects.
Challenge	At the same time, realistic animation of human motion is a challenging task, as people have proven to be adept at discerning the subtleties of human movement and identifying inaccuracies.
Background	One common solution to this problem is motion capture.
Background	However, while motion capture is a reliable way of acquiring realistic human motion, by itself it is a technique for reproducing motion.
Challenge	Motion capture data has proven to be difficult to modify, and editing techniques are reliable only for small changes to a motion.
Challenge	This limits the utility of motion capture  if the data on hand isn’t sufficiently similar to what is desired, then often there is little that can be done other than acquire more data, a time-consuming and expensive process.
Challenge	This in particular is a problem for applications that require motion to be synthesized dynamically, such as interactive environments.
Challenge	Our goal is to retain the realism of motion capture while also giving a user the ability to control and direct a character.
Challenge	For example, we would like to be able to ask a character to walk around a room without worrying about having a piece of motion data that contains the correct number of steps and travels in the right directions.
Challenge	We also need to be able to direct characters who can perform multiple actions, rather than those who are only capable of walking around.
Outcome	This paper presents a method for synthesizing streams of motions based on a corpus of captured movement while preserving the quality of the original data.
Approach	Given a set of motion capture data, we compile a structure called a motion graph that encodes how the captured clips may be re-assembled in different ways.
Approach	The motion graph is a directed graph wherein edges contain either pieces of original motion data or automatically generated transitions.
Approach	The nodes then serve as choice points where these small bits of motion join seamlessly.
Approach	Because our methods automatically detect and create transitions between motions, users needn’t capture motions specifically designed to connect to one another.
Approach	If desired, the user can tune the high-level structure of the motion graph to produce desired degrees of connectivity among different parts.
Approach	Motion graphs transform the motion synthesis problem into one of selecting sequences of nodes, or graph walks.
Approach	By drawing upon algorithms from graph theory and AI planning, we can extract graph walks that satisfy certain properties, thereby giving us control over the synthesized motions.
Approach	To demonstrate the potential of our approach, we introduce a simple example.
Approach	We were donated 78.5 seconds of motion capture, or about 2400 frames of animation, of a performer randomly walking around with both sharp and smooth turns.
Approach	Since the motion was donated, we did not carefully plan out each movement, as the literature suggests is critical to successful application of motion capture data [Washburn 2001].
Approach	From this data we constructed a motion graph and used an algorithm described later in this paper to extract motions that travelled along paths sketched on the ground.
Approach	Characteristic movements of the original data like sharp turns were automatically used when appropriate, as seen in Figure 1 .
Approach	It is possible to place additional constraints on the desired motion.
Approach	For example, we noticed that part of the motion had the character sneaking around.
Approach	By labelling these frames as special, we were able to specify that at certain points along the path the character must only use sneaking movements, and at other parts of the motion it must use normal walking motions, as is also shown in Figure 1 .
Background	Much previous work with motion capture has revolved around editing individual clips of motion.
Background	Motion warping [Witkin and Popović 1995] can be used to smoothly add small changes to a motion.
Background	Retargeting [Gleicher 1998; Lee and Shin 1999] maps the motion of a performer to a character of different proportions while retaining important constraints like footplants.
Background	Various signal processing operations [Bruderlin and Williams 1995] can be applied to motion data.
Outcome	Our work is different from these efforts in that it involves creating continuous streams of motion, rather than modifying specific clips.
Background	One strategy for motion synthesis is to perform multi-target blends among a set of examples, yielding a continuous space of parameterized motion.
Background	Wiley and Hahn [1997] used linear interpolation to create parameterizations of walking at various inclinations and reaching to various locations.
Background	Rose et al. [1998] used radial basis functions to blend among clips representing the same motion performed in different styles.
Background	These works have a focus complementary to ours: while they are mainly concerned with generating parameterizations of individual clips, we are concerned with constructing controllable sequences of clips.
Background	Another popular approach to motion synthesis is to construct statistical models.
Background	Pullen and Bregler [2000] used kernel-based probability distributions to synthesize new motion based on the statistical properties of example motion.
Background	Coherency was added to the model by explicitly accounting for correlations between parameters.
Background	Bowden [2000], Galata et al. [2001], and Brand and Hertzmann [2000] all processed motion capture data by constructing abstract “states” which each represent entire sets of poses.
Background	Transition probabilities between states were used to drive motion synthesis.
Background	Since these statistical models synthesize motion based on abstractions of data rather than actual data, they risk losing important detail.
Outcome	In our work we have tighter guarantees on the quality of generated motion.
Background	Moreover, these systems did not focus on the satisfaction of high-level constraints.
Approach	We generate motion by piecing together example motions from a database.
Background	Numerous other researchers have pursued similar strategies.
Background	Perlin [1995] and Perlin and Goldberg [1996] used a rulebased system and simple blends to attach procedurally generated motion into coherent streams.
Background	Faloutsos et al. [2001] used support vector machines to create motion sequences as compositions of actions generated from a set of physically based controllers.
Approach	Since our system involves motion capture data, rather than procedural or physically based motion, we require different approaches to identifying and generating transitions.
Background	Also, these systems were mainly concerned with appropriately generating individual transitions, whereas we address the problem of generating entire motions (with many transitions) that meet user-specified criteria.
Background	Lamouret and van de Panne [1996] developed a system that used a database to extract motion meeting high-level constraints.
Background	However, their system was applied to a simple agent with five degrees of freedom, whereas we generate motion for a far more sophisticated character.
Background	Molina-Tanco and Hilton [2000] used a state-based statistical model similar to those mentioned in the previous paragraph to rearrange segments of original motion data.
Background	These segments were attached using linear interpolation.
Background	The user could create motion by selecting keyframe poses, which were connected with a highprobability sequence of states.
Approach	Our work considers more general and sophisticated sets of constraints.
Background	Work similar to ours has been done in the gaming industry to meet the requirements of online motion generation.
Background	Many companies use move trees [Mizuguchi et al. 2001], which (like motion graphs) are graph structures representing connections in a database of motion.
Background	However, move trees are created manually — short motion clips are collected in carefully scripted capture sessions and blends are created by hand using interactive tools.
Background	Motion graphs are constructed automatically.
Background	Also, move trees are typically geared for rudimentary motion planning (“I want to turn left, so I should follow this transition”), as opposed to more complicated objectives.
Approach	The generation of transitions is an important part of our approach.
Background	Early work in this area was done by Perlin [1995], who presented a simple method for smoothly interpolating between two clips to create a blend.
Background	Lee [2000] defined orientation filters that allowed these blending operations to be performed on rotational data in a more principled fashion.
Background	Rose et al. [1996] presented a more complex method for creating transitions that preserved kinematic constraints and basic dynamic properties.
Outcome	Our main application of motion graphs is to control a character’s locomotion.
Background	This problem is important enough to have received a great deal of prior attention.
Challenge	Because a character’s path isn’t generally known in advance, synthesis is required.
Background	Procedural and physically based synthesis methods have been developed for a few activities such as walking [Multon et al. 1999; Sun and Metaxas 2001] and running [Hodgins et al. 1995; Bruderlin and Calvert 1996].
Background	While techniques such as these can generate flexible motion paths, the current range of movement styles is limited.
Background	Also, these methods do not produce the quality of motion attainable by hand animation or motion capture.
Background	While Gleicher [2001] presented a method for editing the path traversed in a clip of motion capture, it did not address the need for continuous streams of motion, nor could it choose which clip is correct to fit a path (e.g. that a turning motion is better when we have a curved path).
Approach	Our basic approach — detecting transitions, constructing a graph, and using graph search techniques to find sequences satisfying user demands — has been applied previously to other problems.
Background	Schödl et al. [2000] developed a similar method for synthesizing seamless streams of video from example footage and driving these streams according to high-level user input.
Background	Since writing this paper, we have learned of similar work done concurrently by a number of research groups.
Background	Arikan and Forsythe [2002] constructed from a motion database a hierarchical graph similar to ours and used a randomized search algorithm to extract motion that meets user constraints.
Background	Lee et al. [2002] also constructed a graph and generated motion via three user interfaces: a list of choices, a sketch-based interface similar to what we use for path fitting (Section 5), and a live video feed.
Background	Pullen and Bregler [2002] keyframed a subset of a character’s degrees of freedom and matched small segments of this keyframed animation with the lower frequency bands of motion data.
Background	This resulted in sequences of short clips forming complete motions.
Background	Li et al [2002] generated a two-level statistical model of motion.
Background	At the lower level were linear dynamic systems representing characteristic movements called “textons”, and the higher level contained transition probabilities among textons.
Background	This model was used both to generate new motion based on user keyframes and to edit existing motion.
Approach	A clip of motion is defined as a regular sampling of the character’s parameters, which consist of the position of the root joint and quaternions representing the orientations of each joint.
Approach	A motion graph is a directed graph where all edges correspond to clips of motion.
Approach	Nodes serve as choice points connecting these clips, i.e., each outgoing edge is potentially the successor to any incoming edge.
Approach	A trivial motion graph can be created by placing all the initial clips from the database as arcs in the graph.
Approach	This creates a disconnected graph with 2n nodes, one at the beginning and end of each clip.
Approach	Similarly, an initial clip can be broken into two clips by inserting a node, since the later part of the motion is a valid successor to the earlier part (see Figure 2 ).
Approach	A more interesting graph requires greater connectivity.
Approach	For a node to have multiple outgoing edges, there must be multiple clips that can follow the clip(s) leading into the node.
Approach	Since it is unlikely that two pieces of original data are sufficiently similar, we need to create clips expressly for this purpose.
Approach	Transitions are clips designed such that they can seamlessly connect two segments of original data.
Approach	By introducing nodes within the initial clips and inserting transition clips between otherwise disconnected nodes, we can create a wellconnected structure with a wide range of possible graph walks (see Figure 2 ).
Approach	Unfortunately, creating transitions is a hard animation problem.
Approach	Imagine, for example, creating a transition between a run and a backflip.
Approach	In real life this would require several seconds for an athlete to perform, and the transition motion looks little like the motions it connects.
Approach	Hence the problem of automatically creating such a transition is arguably as difficult as that of creating realistic motion in the first place.
Approach	On the other hand, if two motions are “close” to each other then simple blending techniques can reliably generate a transition.
Approach	In light of this, our strategy is to identify portions of the initial clips that are sufficiently similar that straightforward blending is almost certain to produce valid transitions.
Approach	As in our system, motion capture data is typically represented as vectors of parameters specifying the root position and joint rotations of a skeleton on each frame.
Approach	One might attempt to locate transition points by computing some vector norm to measure the difference between poses at each pair of frames.
Approach	Simple vector norms fail to account for the meanings of the parameters.
Approach	Specifically, in the joint angle representation some parameters have a much greater overall effect on the character than others (e.g., hip orientation vs. wrist orientation).
Approach	Moreover, there is no meaningful way to assign fixed weights to these parameters, as the effect of a joint rotation on the shape of the body depends on the current configuration of the body.
Approach	A motion is defined only up to a rigid 2D coordinate transformation.
Approach	That is, the motion is fundamentally unchanged if we translate it along the floor plane or rotate it about the vertical axis.
Approach	Hence comparing two motions requires identifying compatible coordinate systems.
Approach	Smooth blends require more information than can be obtained at individual frames.
Approach	A seamless transition must account not only for differences in body posture, but also in joint velocities, accelerations, and possibly higher-order derivatives.
Approach	Our similarity metric incorporates each of these considerations.
Approach	To motivate it, we note that the skeleton is only a means to an end.
Approach	In a typical animation, a polygonal mesh is deformed according to the skeleton’s pose.
Approach	This mesh is all that is seen, and hence it is a natural focus when considering how close two frames of animation are to each other.
Approach	For this reason we measure the distance between two frames of animation in terms of a point cloud driven by the skeleton.
Approach	Ideally this point cloud is a downsampling of the mesh defining the character.
Approach	To calculate the distance D( i , ¡ j ) between two frames i and ¡ j , we consider the point clouds formed over two windows of frames of user-defined length k, one bordered at the beginning by   i and the other bordered at the end by ¡ j .
Approach	That is, each point cloud is the composition of smaller point clouds representing the pose at each frame in the window.
Approach	The use of windows of frames effectively incorporates derivative information into the metric, and is similar to the approach in [Schödl et al. 2000].
Approach	The size of the   windows are the same as the length of the transitions, so D( i , ¡ j ) is affected by every pair of frames that form the transition.
Approach	To address the problem of finding coordinate systems for these point clouds (item 2 in the above list), we calculate the minimal weighted sum of squared distances given that an arbitrary rigid 2D transformation may be applied to the second point cloud:
Approach	The weights w i may be chosen both to assign more importance to certain joints (e.g., those with constraints) and to taper off towards the end of the window.
Approach	This optimization has a closed-form solution:
Approach	We compute the distance as defined above for every pair of frames in the database, forming a sampled 2D error function.
Approach	To make our transition model more compact, we find all the local minima of this error function, thereby extracting the “sweet spots” at which transitions are locally the most opportune.
Background	This tactic was also used in [Schödl et al. 2000].
Approach	These local minima are our candidate transition points.
Approach	A local minimum in the distance function does not necessarily imply a high-quality transition; it only implies a transition better than its neighbors.
Approach	We are specifically interested in local minima with small error values.
Approach	The simplest approach is to only accept local minima below an empirically determined threshold.
Approach	This can be done without user intervention.
Approach	However, often users will want to set the threshold themselves to pick an acceptable tradeoff between having good transitions (low threshold) and having high connectivity (high threshold).
Approach	Different kinds of motions have different fidelity requirements.
Approach	For example, walking motions have very exacting requirements on the transitions — people have seen others walk nearly every day since birth and consequently have a keen sense of what a walk should look like.
Challenge	On the other hand, most people are less familiar with ballet motions and would be less likely to detect inaccuracies in such motion.
Approach	As a result, we allow a user to apply different thresholds to different pairs of motions; transitions among ballet motions may have a higher acceptance threshold than transitions among walking motions.
Approach	If D( i , ¡ j ) meets the threshold requirements, we create a tran    sition by blending frames i to i+k−1 with frames ¡ j−k+1 to ¡ j , inclusive.
Approach	The first step is to apply the appropriate aligning 2D transformation to motion .
Approach	Then on frame p of the transition ¡ (0 ≤ p < k) we linearly interpolate the root positions and perform spherical linear interpolation on joint rotations:
Approach	To maintain continuity we choose the blend weights α (p) according to the conditions that α (p) = 1 for p ≤ −1, α (p) = 0 for p ≥ k, and that α (p) has C 1 continuity everywhere.
Background	Other transition schemes, such as [Rose et al. 1996], may be used in place of this one.
Approach	The use of linear blends means that constraints in the original motion may be violated.
Approach	For example, one of the character’s feet may slide when it ought to be planted.
Approach	This can be corrected by using constraint annotations in the original motions.
Approach	We treat constraints as binary signals: on a given frame a particular constraint either exists or it does not.
Approach	Blending these signals in analogy to equations 5   and 6 amounts to using the constraints from in the first half of the transition and the constraints from in the second half.
Approach	In this ¡ manner each transition is automatically annotated with constraint information, and these constraints may later be enforced as a postprocessing step when motion is extracted form the graph.
Approach	Descriptive labels attached to the motions are carried along into transitions.
Approach	Specifically, if a transition frame is a blend between a frame with a set of labels L 1 and another frame with a set of labels L 2 , then it has the union of these labels L 1 ∪ L 2 .
Approach	In its current state there are no guarantees that the graph can synthesize motion indefinitely, since there may be nodes (called dead ends) that are not part of any cycle (see Figure 4 ).
Approach	Once such a node is entered there is a bound on how much additional motion can be generated.
Approach	Other nodes (called sinks) may be part of one or more cycles but nonetheless only be able to reach a small fraction of the total number of nodes in the graph.
Approach	While arbitrarily long motion may still be generated once a sink is entered, this motion is confined to a small part of the database.
Approach	Finally, some nodes may have incoming edges such that no outgoing edges contain the same set of descriptive labels.
Approach	This is dangerous since logical discontinuities may be forced into a motion.
Approach	For example, a character currently in a “boxing” motion may have no choice but to transition to a “ballet” motion.
Approach	To address these problems, we prune the graph such that, starting from any edge, it is possible to generate arbitrarily long streams of motion of the same type such that as much of the database as possible is used.
Approach	This is done as follows.
Approach	Every frame of original data is associated with a (possibly empty) set of labels.
Approach	Say there are n unique sets.
Approach	For each set, form the subgraph consisting of all edges whose frames have exactly this set of labels.
Approach	Compute the strongly connected components (SCCs) of this subgraph, where an SCC is a maximal set of nodes such that there is a connecting graph walk for any ordered pair of nodes (u, v).
Approach	The SCCs can be computed in O(V + E) time using an algorithm due to Tarjan.
Approach	We eliminate from this subgraph (and hence the original motion graph) any edge that does not attach two nodes in the largest SCC.
Approach	Once this process is completed for all n label sets, any nodes with no edges are discarded.
Approach	A warning is given to the user if the largest SCC for a given set of labels contains below a threshold number of frames.
Approach	Also, a warning is given if for any ordered pair of SCCs there is no way to transition from the first to the second.
Approach	In either case, the user may wish to adjust the transition thresholds (Section 3.2) to give the graph greater connectivity.
Approach	By this stage we have finished constructing the motion graph.
Approach	After describing exactly how a graph walk can be converted into displayable motion, we will consider the general problem of extracting motion that satisfies user constraints.
Approach	Our algorithm involves solving an optimization problem, and so we conclude this section with some general recommendations on how to pose the optimization.
Approach	Since every edge on the motion graph is a piece of motion, a graph walk corresponds to a motion generated by placing these pieces one after another.
Approach	The only issue is to place each piece in the correct location and orientation.
Approach	In other words, each frame must be transformed by an appropriate 2D rigid transformation.
Approach	At the start of a graph walk this transformation is the identity.
Approach	Whenever we exit a transition edge, the current transformation is multiplied by the transformation that aligned the pieces of motion connected by the transition (Section 3.1).
Approach	As noted in Section 3.3, the use of linear blends to create transitions can cause artifacts, the most common of which is feet that slide when they ought to be planted.
Approach	However, every graph walk is automatically annotated with constraint information (such as that the foot must be planted).
Approach	These constraints are either specified directly in the original motions or generated as in Section 3.3, depending on whether the frame is original data or a transition.
Approach	These constraints may be satisfied using a variety of methods, such as [Gleicher 1998] or [Lee and Shin 1999].
Approach	In our work we used the method described in [Kovar et al. 2002].
Approach	We are now in a position to consider the problem of finding motion that satisfies user-specified requirements.
Approach	It is worth first noting that only very special graph walks are likely to be useful.
Approach	For example, while a random graph walk will generate a continuous stream of motion, such an algorithm has little use other than an elaborate screen saver.
Approach	As a more detailed example, consider computing an all-pairs shortest graph walk table for the graph.
Approach	That is, given a suitable metric — say, time elapsed or distance travelled — we can use standard graph algorithms like Floyd-Warshall to find for each pair of nodes u and v the connecting graph walk that minimizes the metric.
Approach	With this in hand we could, for example, generate the motion that connects one clip to another as quickly as possible.
Approach	This is less useful than it might appear at first.
Approach	First, there are no guarantees that the shortest graph walk is short in an absolute sense.
Approach	In our larger test graphs (between a few and several thousand nodes) the average shortest path between any two nodes was on the order of two seconds.
Approach	This is not because the graphs were poorly connected.
Approach	Since the transitions were about one-third of a second apiece, this means there were on average only five or six transitions separating any two of the thousands of nodes.
Approach	Second, there is no control over what happens during the graph walk — we can’t specify what direction the character travels in or where she ends up.
Approach	More generally, the sorts of motions that a user is likely to be interested in probably don’t involve minimizing metrics as simple as total elapsed time.
Approach	However, for complicated metrics there is typically no simple way of finding the globally optimal graph walk.
Approach	Hence we focus instead on local search methods that try to find a satisfactory graph walk within a reasonable amount of time.
Challenge	We now present our framework for extracting graph walks that conform to a user’s specifications.
Approach	We cast motion extraction as a search problem and use branch and bound to increase the efficiency of this search.
Approach	The user supplies a scalar function g(w, e) that evaluates the additional error accrued by appending an edge e to the existing path w, which may be the empty path 0.
Approach	We require g(w, e) to be nonnegative, which means that we can never decrease the total error by adding more edges to a graph walk.
Approach	In addition to f and g, the user must also supply a halting condition indicating when no additional edges should be added to a graph walk.
Approach	A graph walk satisfying the halting condition is called complete.
Approach	The start of the graph walk may either be specified by the user or chosen at random.
Approach	Our goal is find a complete graph walk w that minimizes f .
Approach	To give the user control over what sorts of motions should be considered in the search, we allow restrictions on what edges may be appended to a given walk w.
Approach	For example, the user may decide that within a particular window of time a graph walk may only contain “sneaking” edges.
Approach	A naıve solution is to use depth-first search to evaluate f for all complete graph walks and then select the best one.
Approach	However, the number of possible graph walks grows exponentially with the average size of a complete graph walk.
Approach	To address this we use a branch and bound strategy to cull branches of the search that are incapable of yielding a minimum.
Approach	Since g(w, e) by assumption never decreases, f (w) is a lower bound on f (w + v) for any v, where w + v is the graph walk composed of v appended to w.
Approach	Thus we can keep track of the current best complete graph walk w opt and immediately halt any branch of the search for which the graph walk’s error exceeds f (w opt ).
Approach	Also, the user may define a threshold error ε such that if f (w) < ε , then w is considered to be “good enough” and the search is halted.
Approach	Branch and bound is most successful when we can attain a tight lower bound early in the search process.
Approach	For this reason it is worthwhile to have a heuristic for ordering the edges we explore out of a particular node.
Approach	One simple heuristic is to order the children greedily — that is, given a set of unexplored children c 1 , . . . , c n , we search the one that minimizes g(w, c i ).
Approach	While branch and bound reduces the number of graph walks we have to test against f , it does not change the fact that the search process is inherently exponential — it merely lowers the effective branching factor.
Approach	For this reason we generate a graph walk incrementally.
Approach	At each step we use branch and bound to find an optimal graph walk of n frames.
Approach	We retain the first m frames of this graph walk and use the final retained node as a starting point for another search.
Approach	This process continues until a complete graph walk is generated.
Approach	In our implementation we used values of n from 80 to 120 frames (2 3 2 to 4 seconds) and m from 25 to 30 frames (about one second).
Approach	Sometimes it is useful to have a degree of randomness in the search process, such as when one is animating a crowd.
Approach	There are a couple of easy ways to add randomness to the search process without sacrificing a good result.
Approach	The first is to select a start for the search at random.
Approach	The second is retain the r best graph walks at the end of each iteration of the search and randomly pick among the ones whose error is within some tolerance of the best solution.
Approach	Since the motion extracted from the graph is determined by the function g, it is worth considering what sorts of functions are likely to produce desirable results.
Approach	To understand the issues involved, we consider a simple example.
Approach	Imagine we want to lay down two clips on the floor and create a motion that starts at the first clip and ends at the second.
Approach	Both clips must end up in the specified position and orientation.
Approach	What one will receive is a motion like in Figure 5 , where the initial clip is a walking motion and the final clip is a kick.
Outcome	The character turns around in place several times in an attempt to better line up with the target clip.
Approach	While it’s conceivable that given a larger database we would have found a better motion, the problem here is with the function we passed into the search algorithm.
Approach	First, it gives no guidance as to what should be done in the middle of the motion; all that matters is that the final clip be in the right position and orientation.
Approach	This means the character is allowed to do whatever is possible in order to make the final fit, even if the motion is nothing that a real person would do.
Approach	Second, the goal is probably more specific than necessary.
Approach	If it doesn’t matter what kick the character does, then it should be allowed to choose a kick that doesn’t require such effort to aim.
Outcome	More generally, there are two lessons we can draw from this example.
Outcome	First, g should give some sort of guidance throughout the entire motion, as arbitrary motion is almost never desirable.
Outcome	Second, g should be no more restrictive than necessary, in order to give the search algorithm more goals to seek.
Outcome	Note the tradeoff here — guiding the search toward a particular result must be balanced against unduly preventing it from considering all available options.
Approach	We have cast motion extraction as an optimization problem, and we have given some reasons why the formulation of this optimization can be difficult.
Approach	To demonstrate that it is nonetheless possible to come up with optimization criteria that allow us to solve a real problem, we apply the preceding framework to path synthesis.
Approach	This problem is simple to state: given a path P specified by the user, generate motion such that the character travels along P. In this section we present our algorithm for path synthesis, present results, and discuss applications of the technique.
Approach	Given the framework in the previous section, our only tasks are to define an error function g(w, e) and appropriate halting criteria.
Approach	A simple way to determine P is to project the root onto the floor at each frame, forming a piecewise linear curve 1 .
Approach	Let P(s) be the point on P whose arc-length distance from the start of P is s.
Approach	The i th frame of the graph walk, w i , is at some arc length s(w i ) from the start of P .
Approach	We define the corresponding point on P as the point at the same arc length, P(s(w i )).
Approach	For the j th frame of e, we calculate the squared distance between P (s(e j )) and P(s(e j )).
Approach	g(w, e) is the sum of these errors:
Approach	Note that s(e i ) depends on the total arc length of w, which is why this equation is a function of w as well as e.
Approach	First, it is efficient to compute, which is important in making the search algorithm practical.
Approach	Second, the character is given incentive to make definite progress along the path.
Approach	If we were to have required the character to merely be near the path, then it would have no reason not to alternate between travelling forwards and backwards.
Approach	Finally, this metric allows the character to travel at whatever speed is appropriate for what needs to be done.
Approach	For example, a sharp turn will not cover distance at the same rate as walking straight forward.
Approach	Since both actions are equally important for accurate path synthesis, it is important that one not be given undue preference over the other.
Approach	One potential problem with this metric is that a character who stands still will never have an incentive to move forward, as it can accrue zero error by remaining in place.
Approach	While we have not encountered this particular problem in practice, it can be countered by requiring at least a small amount of forward progress γ on each frame.
Approach	More exactly, we can replace in Equation 9 the function s(e i ) with t(e i ) = max(t(e i−1 ) + s(e i ) − s(e i−1 ),t(e i−1 ) + γ ).
Approach	Typically the user will want all generated motion to be of a single type, such as walking.
Approach	This corresponds to confining the search to the subgraph containing the appropriate set of descriptive labels.
Approach	More interestingly, one can require different types of motion on different parts of the path.
Approach	For example, one might want the character to walk along the first half of the path and sneak down the rest.
Approach	The necessary modifications to accomplish this are simple.
Approach	We will consider the case of two different motion types; the generalization to higher numbers is trivial.
Approach	We divide the original path into two smaller adjoining paths, P 1 and P 2 , based on where the transition from type T 1 to type T 2 is to occur.
Approach	If the character is currently fitting P 2 , then the algorithm is identical to the single-type case.
Approach	If the character is fitting P 1 , then we check to see if we are a threshold distance from the end of P 1 .
Approach	If not, we continue to only consider edges of type T 1 .
Approach	Otherwise we allow the search to try both edges of type T 1 and T 2 ; in the latter case we switch to fitting P 2 .
Approach	Note that we only allow this switch to occur once on any given graph walk, which prevents the resulting motion from randomly switching between the two actions.
Outcome	While the examples shown in Figure 1 suggest that our technique is viable, it perhaps isn’t surprising that we were able to find accurate fits to the given paths.
Outcome	However, our algorithm is still useful when the input database is not as rich.
Approach	We started with a single 12.8second clip of an actor sneaking along the indicated path.
Approach	To stretch this data further, we created a mirror-image motion and then built a motion graph out of the two.
Outcome	From these we were able to construct the new motions shown at the bottom of the figure, both of which are themselves approximately 13 seconds in length.
Outcome	The first example uses walking motions and the second uses martial arts motions; the latter demonstrates that our approach works even on motions that are not obviously locomotion.
Outcome	For the walking motion, the total computation time was nearly the same as the length of the generated animation (58.1 seconds of calculation for 54.9 seconds animation).
Outcome	The martial arts motion is 87.7 seconds long and required just 15.0 seconds of computation.
Outcome	In general, in our test cases the duration of a generated motion was either greater than or approximately equal to the amount of time needed to produce it.
Outcome	Both motion graphs had approximately 3000 frames (100 seconds) of animation.
Approach	In the first section of each path the character is required to walk, in the second it must sneak, and in the third it is to perform martial arts moves.
Outcome	Not only does the character follow the path well, but transitions between action types occur quite close to their specified locations.
Approach	This example used a database of approximately 6000 frames (200 seconds).
Approach	All examples were computed on a 1.3GHz Athlon.
Outcome	For our largest graph (about 6000 frames), approximately twenty-five minutes were needed to compute the locations of all candidate transitions points.
Outcome	Approximately five minutes of user time were required to select transition thresholds, and it took less than a minute to calculate blends at these transitions and prune the resulting graph.
Outcome	Directable locomotion is a general enough need that the preceding algorithm has many applications.
Outcome	We can use path synthesis techniques to give a user interactive control over a character.
Outcome	For example, when the user hits the left arrow key the character might start travelling east.
Approach	To accomplish this, we can use the path fitting algorithm to find the sequence of edges starting from our current location on the graph that best allow the character to travel east.
Approach	The first edge on the resulting graph walk is the next clip that will be played.
Approach	This process may then be repeated.
Outcome	To make this practical, we can precompute for every node in the graph a sequence of graph walks that fit straight-line paths in a sampling of directions (0 degrees, 30 degrees, .
Approach	The first edges on these paths are then stored for later use; they are the best edges to follow given the direction the character is supposed to travel in.
Approach	If we want a character to perform certain actions in a specific sequence and in specific locations, we can draw a path with subsections requiring the appropriate action types.
Outcome	This allows us to generate complex animations without the tedium of manual keyframing.
Approach	For this reason we term this process “highlevel” keyframing — the user generates an animation based on what should be happening and where.
Approach	If an AI algorithm is used to determine that a character must travel along a certain path or start performing certain actions, the motion graph may be used to “dump” motion on top of the algorithm’s result.
Outcome	Hence motion graphs may be used as a back-end for animating non-player characters in video games and interactive environments — the paths and action types can be specified by a high-level process and the motion graph would fill in the details.
Outcome	While our discussion so far has focused on a single character, there’s no reason why it couldn’t be applied to several characters in parallel.
Outcome	Motion graphs may be used as a practical tool for crowd generation.
Outcome	For example, a standard collision-avoidance algorithm could be used to generate a path for each individual, and the motion graph could then generate motion that conforms to this path.
Outcome	Moreover, we can use the techniques described at the end of Section 4.2 to add randomness to the generated motion.
Outcome	In this paper we have presented a framework for generating realistic, controllable motion through a database of motion capture.
Approach	Our approach involves automatically constructing a graph that encapsulates connections among different pieces of motion in the database and then searching this graph for motions that satisfy user constraints.
Outcome	We have applied our framework to the problem of path synthesis.
Approach	As we had limited access to data, our largest examples used a database of several thousand frames of motion.
Outcome	While we believe this was sufficient to show the potential of our method, a character with a truly diverse set of actions might require hundreds or thousands of times more data.
Outcome	Hence the scalability of our framework bears discussion.
Outcome	The principle computational bottleneck in graph construction is locating candidate transitions (Section 3.1).
Outcome	This requires comparing every pair of the F frames in the database and therefore involves O(F 2 ) operations.
Outcome	However, this calculation is trivial to parallelize, and distances between old frames needn’t be recomputed if additions are made to the database.
Outcome	It is the exception rather than the rule that two pieces of motion are sufficiently similar that a transition is possible, and hence motion graphs tend to be sparse.
Outcome	In our experience the necessary amount of storage is approximately proportional to the size of the database.
Outcome	The number of edges leaving a node in general grows with the size of the graph, meaning the branching factor in our search algorithm may grow as well.
Outcome	However, we expect that future motion graphs will be larger mainly because the character will be able to perform more actions.
Outcome	That is, for example, having increasing amounts of walking motion isn’t particularly useful once one can direct a character along nearly any path.
Outcome	Hence the branching factor in a particular subgraph will remain stationary once that subgraph is sufficiently large.
Outcome	We anticipate that typical graph searches will be restricted to one or two subgraphs, and so we expect that the search will remain practical even for larger graphs.
FutureWork	One limitation of our approach is that the transition thresholds must be specified by hand, since (as discussed in Section 3.2) different kinds of motions have different fidelity requirements.
FutureWork	Setting thresholds in databases involving many different kinds of motions may be overly laborious, and so we are investigating methods for automating this process.
FutureWork	A second area of future work is to incorporate parameterizable motions [Wiley and Hahn 1997; Rose et al. 1998] into our system, rather than having every node correspond to a static piece of motion.
FutureWork	This would add flexibility to the search process and potentially allow generated motion to better satisfy user constraints.
FutureWork	Finally, we are interested in applying motion graphs to problems other than path synthesis.

Background	Progress in cloth simulation for computer animation and apparel design has led to a multitude of deformation models, each with its own way of relating geometry, deformation, and forces.
Challenge	As simulators improve, differences between these models become more important, but it is difficult to choose a model and a set of parameters to match a given real material simply by looking at simulation results.
Outcome	This paper provides measurement and fitting methods that allow nonlinear models to be fit to the observed deformation of a particular cloth sample.
Approach	Unlike standard textile testing, our system measures complex 3D deformations of a sheet of cloth, not just one-dimensional force–displacement curves, so it works under a wider range of deformation conditions.
Approach	The fitted models are then evaluated by comparison to measured deformations with motions very different from those used for fitting.
Background	Today’s cloth simulators for animation, visual effects, games, and apparel design can mimic real cloth to a high degree of fidelity.
Challenge	But to fully exploit their capabilities, the constitutive models for cloth deformation must be tuned with great care.
Challenge	During this tuning process it is difficult to tell which models and which parameters are giving results more like the real material.
Challenge	This paper aims to solve this problem by introducing new techniques to measure complete cloth behavior under controlled conditions and to estimate cloth deformation models from these measurements.
Background	Most methods for testing cloth move the sample into a state of near-uniform strain, exercising one or at most two components of strain at once: pure stretching, pure shearing, or pure bending.
Background	One or two forces are measured to quantify the cloth’s resistance to deformation, and the resulting forcedisplacement curves are valuable in studying the differences between materials.
Challenge	However, this approach has certain limitations.
Challenge	The inevitable deviations from uniform strain create modeling error that cannot be quantified without knowing the actual strain variation; and force-displacement curves can be used directly to tune a cloth model, but do not provide any way to validate the resulting fit.
Outcome	The contributions of this paper are, first, a new, general system for observing cloth properties that measures more complete data than previous work in cloth capture or textile testing, and second, a new method for fitting parametric models to this type of data.
Outcome	Finally we show results that illustrate the performance of several widely used cloth models.
Approach	Our measurement system applies forces to a sample of cloth using actuators and force sensors that let us know the complete applied force, in 3D.
Approach	The resulting deformation is tracked by a stereo computer vision system that captures the complete deformation, also in 3D.
Outcome	Having deformation and force information makes our data well suited to model validation—the experiment measures the complete answer that should be predicted by a cloth simulator.
Approach	Also, we do not need uniform strain, and in this paper we illustrate a range of tests, some that mimic traditional tests and some with more complex deformations.
Approach	Our approach to model estimation is to numerically optimize nonlinear stress-strain curves to minimize errors in force and position compared to the measurement.
Approach	We have designed a general fitting method, suited for the vast majority of existing cloth models, that leverages equilibrium conditions to guide the iteration.
Approach	By estimating model parameters under a sequence of deformations of increasing complexity, we alleviate problems with convergence in the presence of abundant local minima.
Approach	We have used our system to fit three membrane models and two bending models from the graphics literature, each based on a different strain measure, and to evaluate the resulting models against more complex motions.
Background	Cloth simulation has a comparatively long history in computer graphics.
Background	Since the first physics-based approach by Terzopoulos et al. [ TPBF87 ] a multitude of different cloth models have emerged, ranging from simple mass-spring systems [ Pro95 , CK02 ] over general particle systems [ BHW94 , BW98 , EWS96 ] to elaborate models derived from continuum mechanics [ EKS03 , VMTF09 ] or even the discrete yarn structure [ KJM08 ].
Challenge	Considering the number of existing models, it is very hard to clearly identify or even quantify the advantages of individual approaches.
Challenge	Our goal is to define a platform for comparing cloth models to the observed behavior of real cloth.
Background	As a central component of any cloth model, material models describe the relation between deformation and resulting forces.
Background	Continuum-based approaches can accurately describe the directional variation of material properties, but regardless of the cloth model, a single set of material coefficients for the entire deformation range is not sufficient to faithfully capture the nonlinear response of typical fabrics.
Background	Bi-phasic models, typically implemented as strain limiting methods [Pro95, BFA02, Mül08, TPS09, WOR10], improve on this by splitting the material behavior into an initial, weakly elastic range and a stiff, quasi-inextensible limit.
Background	At the extreme, the elastic range can be replaced altogether by inextensibil∗ ity constraints [GHF 07, EB08].
Background	A better approximation to the true material response can be obtained by making the material parameters functions of the deformation, rather than constants, and by fitting these functions to measured data.
Background	To this end, previous work [BHW94,EWS96, VMTF09 ] has mainly relied on the Kawabata Evaluation System (KES) [Kaw80 ] and corresponding machinery.
Background	While the KES covers a comprehensive set of experiments, other devices have been used in more specific context such as the Picture Frame test [ Cul79 ] for measuring shear properties and the Cantilever test [ CPGE90 ] for measuring bending properties (see also Pabst et al. [ PKST08 ]).
Background	These measurement-based approaches establish a valuable link between simulation and real-world behavior, but they rely on experiments that isolate individual deforma∗ tion modes.
Background	As an alternative, Bhat et al. [ BTH 03 ] (and recently Kunitomo et al. [ KNM10 ]) aim at avoiding the need for controlled conditions and try to extract parameters from casually captured videos of cloth.
Background	This approach appeals through a simple and inexpensive acquisition process, but it is not possible to accurately separate internal (i.e. material-specific) and external (e.g. friction, air drag) parameters.
Background	In a similar spirit, capture technology can be used to record time-varying geometry of complex cloth mo∗ ∗ tions [WCF07,BPS 08,SGdA 10].
Background	But while capturing can provide accurate deformation data, parameter fitting remains very difficult without explicit control over boundary conditions, in particular loading forces.
Background	Closer to our work is the recent approach of Wang et al. [WRO11], who propose a data-driven piecewise linear elastic cloth model comprising 39 material parameters.
Background	These parameters are fitted to experimentally acquired data obtained from planar and bending deformations.
Outcome	Their capture setup is appealingly simple, but ours is more general and powerful: it produces a 3D surface, rather than a 2D deformation, and it measures all forces applied to the cloth as they change during a range of different deformations.
Approach	Like other cloth testing systems, we focus primarily on tensile forces, because it is hard to repeatably produce and measure compression forces in a sheet that is inclined to buckle.
Approach	Tests are performed on 100 mm square cloth samples using two kinds of plastic clips: small, rounded clips that grab a localized area, and long clips that grip one whole side of the sample.
Approach	We measure the weights of all cloth samples as well as the clips (see Table 1 ) and use these values in the optimization process.
Approach	Forces are applied to the clips by fine wire cords that are pulled to defined displacements by eight linear actuators, and the tension in the cords is monitored by miniature load cells located at the actuator ends (see Figure 2).
Approach	The location and orientation of the cords attached to the clips (which reveal the direction of the applied force) are also tracked.
Approach	The magnitudes are determined by the tension measurements, and the directions are determined by the observed directions of the cords.
Approach	Note that the actuator positions themselves are not part of the output, since they are superseded by the displacements measured at the clips.
Approach	This prevents stretching of the cord, or other factors affecting the distance between the clip and the actuator, from affecting displacement accuracy.
Approach	Our vision system recovers the space-time geometry of the deforming cloth and attached rigid clips, as well as the directions of the forces applied to the clips.
Approach	The cloth sample starts flat on a table and we capture the rest pose without applied tensile forces.
Approach	This initial frame serves to compute the geometry of the cloth without any occlusion from clips.
Approach	We then attach the clips, and the measurement process continues automatically, following a defined script of actuations, and recording images and forces.
Approach	We typically deform the cloth by moving the actuators at 0.5 mm/sec and capture a frame every 2 seconds.
Approach	The raw data for a single deformation consists of 20 to 200 individual measurement frames, with a set of camera images and simultaneous force sensor readings for each frame.
Approach	We compute the per-frame geometry using a state-ofthe-art stereo reconstruction technique [ BBH08 ], which was specifically tailored for reconstructing cloth geome∗ try [ BPS 08 ].
Approach	If the inherent texture of the cloth is not sufficiently random, it is printed with a wavelet noise pat∗ tern [ AIH 08 ] to provide texture that can be used for stereo reconstruction and tracking.
Approach	The pattern is printed with a flatbed inkjet printer and does not have a noticeable effect on the material behavior.
Approach	To represent inter-frame correspondence, we use optical flow to obtain a single triangle mesh that deforms over time, akin to the human face tracking method of Bradley et al. [BHPS10].
Approach	To start, the cloth vertices in the rest pose frame (frame 0) are projected onto the input images, where optical flow predicts the projection of each vertex at the next time step.
Approach	Back-projecting onto the reconstructed geometry for the next frame gives new position estimates for the cloth vertices.
Approach	The process is then repeated using the result from frame n to obtain frame n + 1.
Approach	As with all sequential tracking methods, very small errors can accumulate over time and cause temporal drift in the reconstruction.
Approach	To avoid drift, we subsequently match each frame independently back to the rest pose frame using the approach described in Bradley et al. [BHPS10].
Approach	The final solution is smoothed using Laplacian regularization to remove noise.
Approach	In order to measure the complete answer that a simulator should predict, we need to determine the interaction between the rigid clips, the cloth, and the cords.
Approach	The clips are produced, using rapid prototyping, with embedded codes [Fia05] that allow us to determine their identity, position, and orientation automatically.
Approach	The area of cloth occluded by the clips is used to automatically determine which cloth vertices are clamped by each clip and will therefore be constrained to it in the simulator.
Approach	The vision system also finds the cords in the images and triangulates a 3D line for each cord.
Approach	A few user scribbles on an input image indicate which cords are affecting each clip.
Approach	The forces are rendered as red vectors with lengths proportional to the force magnitudes.
Approach	The set of deformations to measure is motivated by the goals of the parameter fitting stage (Section 5): to fit model parameters for stretch, shear and bending that best describe the cloth, and to validate the parameter fits by comparing against other measurements.
Approach	To reduce the risk of falling into local minima during parameter fits, we have designed deformation sequences that produce near-isolated strains, and allow estimating stretch, shear and bending properties in a separate and incremental manner.
Approach	However, unlike standard textile evaluation practices [Kaw80], and thanks to our full 3D deformation capture solution, we relax the requirement of uniform strains.
Approach	To isolate stretching we perform a uni-axial tension experiment, with forces applied to two long bar clips attached to either side of the cloth (see Figure 4 , 2nd column).
Approach	The cloth is slowly stretched until a maximum force is reached and then slowly released back.
Approach	The process is repeated three times, in both weft and warp directions separately.
Approach	Shearing is captured using an approximate picture-frame experiment [Cul79], where four long clips fix the cloth boundaries and shear stress is applied as the cords pull on opposite corners ( Figure 4 , 3rd column).
Approach	To isolate bending deformation we slowly push the flat cloth sample off the edge of a table and measure its shape as it bends under its own weight ( Figure 4 , 4th column), for both weft and warp directions.
Approach	Thus we have a total of five measurements per cloth sample that will be used for parameter fitting (two stretch, one shear, and two bending).
Approach	We also capture two sequences with more complex deformation ( Figure 5 ) for validation after parameter fitting.
Approach	In the first test, opposite edges of the cloth are pulled in opposite directions, causing shearing and buckling ( Figure 5 , top).
Approach	The second is a four-corner pulling test, where opposite pairs of corners are pulled in alternation, resulting in diagonal wrinkles ( Figure 5 , bottom).
Outcome	To our knowledge, our method presents the first system able to record such extensive information about the behavior of a cloth sample.
Outcome	In the vision system, the camera calibration accuracy is within 0.3 pixels, or about 0.075 millimeters at the distance of the cloth.
Background	The multi-view stereo algorithm of Bradley et al. [BBH08] is among the most accurate available according to the Middlebury evaluation benchmark.
Outcome	It is difficult to quantify the accuracy of the temporal flow computation, but it can be visualized by compositing the reconstructed deformation on top of the input images (see accompanying video).
Approach	The raw repeatability of our force sensors is about 3 millinewtons (RMS).
Approach	The largest source of error in measuring the force indirectly through the cord is the internal friction in the cord as it bends around the pulleys, which introduces an artificial hysteresis of about 0.1 N.
Challenge	Our goal is to study the fidelity of constitutive models of cloth—models that predict the forces produced in the cloth in response to deformations.
Approach	The input of such a model is the positions of the vertices x 1 , . . . , x n ∈ IR 3 that define the deformation state of the sheet (analogous to strain in continuum mechanics) and the output is the forces that act between those vertices in response (analogous to stress).
Approach	Although some of the models we look at are discrete in nature, we will use the convenient terms stress and strain to describe them.
Background	Most elastic cloth models separate membrane (i.e., stretch and shear) and bending deformation energies.
Approach	In both cases, deformation energy density can be described by the product of strain (ε) and stress (σ), i.e., W = 2 1 σ · ε.
Background	Furthermore, most of these models define separable scalar stress components as linear functions of individual scalar strain metrics.
Approach	In that case, the energy density of each deformation component i can be written as W i = 1 2 k i ε 2 i , where k i ε i = σ i and k i is the stiffness coefficient corresponding to the deformation component ε i .
Background	The force density due to each ε i follows as F i = − W i = −σ i ε i = −k i ε i ε i .
Approach	We have evaluated three models for membrane deformation that fit this description (spring systems, the soft constraint model by Baraff and Witkin [BW98] and the diagonalized St.Venant-Kirchhoff (StVK) model by Volino et al. [VMTF09]), and two bending models (spring systems and the edge-based bending model in Discrete Shells [GHDS03]).
Approach	Considering possible anisotropic behavior, we distinguish six different strain components on regularly triangulated cloth: weft-stretch (ε s,u ), warp-stretch (ε s,v ), shear (ε s,uv ), weft-bend (ε b,u ), warp-bend (ε b,v ), and diagonalbend (ε b,uv ).
Approach	Next, we describe in detail the strain metrics for the individual deformation components in the selected models.
Approach	Note that not all force models define the quantities below explicitly as strains, as they often rely on the resolution of the discretization, or they differ simply by scale factors that can be embedded in the stiffness k i .
Approach	We use continuum strain definitions in all cases to fit them in a common formulation that allows us to easily compare the models.
Approach	All deformation components are modeled based on springs, with weft and warp ring-1 springs for stretch, and diagonal ring-1 springs for shear.
Approach	The membrane deformation is defined using the Green-Lagrange strain tensor, a formulation introduced to computer graphics by Terzopoulos et al. [TPBF87].
Approach	Given a per-triangle mapping function w from the undeformed 2D configuration (x a,0 , x b,0 , x c,0 ) to the deformed        3D configuration (x a , x b , x c ), the deformation gradient can be computed as −1 (w u w v ) = (x b − x a x c − x a ) x b,0 − x a,0 x c,0 − x a,0 .
Background	Volino et al. [VMTF09] approximate the standard StVK model zeroing out off-diagonal terms in the matrix that relates strain and stress, σ = Eε.
Background	Then, in the diagonalized StVK, each membrane stress component depends only on its corresponding strain component, σ s,i (ε s,i ).
Approach	Weftand warp-stretch are measured through a subtle modification of the Green-Lagrange strain tensor, defining terms that are quadratic in positions instead of quartic:
Approach	The deformation is measured based on weft and warp ring-2 springs for weftand warp-bend, and diagonal ring-2 springs for diagonal-bend.
Approach	Same as for membrane deformation, strain is measured as the relative change of edge length (1).
Background	Grinspun et al. [GHDS03] and Bridson et al. [BMF03] discovered concurrently the appropriate weighting of the angle change in order to model homogeneous bending on irregular triangle meshes with a homogeneous stiffness.
Background	Grinspun et al. define h 0 as a third of the average of the heights of the two triangles incident to the edge.
Background	This definition implies that bending energy density is integrated over edgecentered rectangles of size l 0 × h 0 .
Approach	With our separation of weft-, warpand diagonal-bending to capture anisotropy, the bending models in Discrete Shells and by Baraff and Witkin [BW98] are equivalent up to a stiffness scale factor.
Approach	The generic force density model F = −σ ε defined above assumes a linear stress-strain curve σ = kε.
Approach	However, stressstrain curves are potentially nonlinear functions.
Approach	Then, for each deformation component, we model stress as a function σ i = k i (ε i )ε i , with a strain-dependent stiffness k i encoded using Hermite splines.
Approach	We enforce non-negative constraints on the stiffness values at control points.
Approach	The resulting nonlinear force density function, F i = −k i (ε i )ε i ε i yields a conservative force field, but note that the elastic energy density can no longer be defined simply as 1 2 kε 2 , and would now require the integration of the stiffness function.
Approach	Although only Volino et al. [VMTF09] propose a general nonlinear stress-strain relationship (though many systems use some form of strain limiting instead), the same construction can easily be built on any of our selected models.
Approach	Because linear models fit the data poorly, we used the nonlinear model in all cases, resulting in a consistent set of models, parameterized by the number of spline control points, which reduces to the widely used linear models when each spline has a single control point.
Challenge	The key question of how well a given model describes a particular piece of cloth is answered by fitting the model to the measurement data: adjusting its parameters to minimize the difference between the model’s predictions and the measured behavior, both in position and force.
Approach	We do this by solving an optimization problem, leveraging that the cloth is at static equilibrium at the measured configurations.
Approach	In principle all parameters of a cloth model can be fit to a sufficiently rich single deformation sequence, but this can result in a problem fraught with local minima.
Approach	In order to achieve stable fits, we have designed an incremental optimization procedure that fits model parameters a few at a time using the isolated deformations described in Section 3.2.
Approach	For each different cloth sample, we have created a simulated replica with the same mass, uniformly distributed, and the same 100mm square geometry, discretized with a regular 25 × 25-node mesh, connected either with springs or with quadrilaterals split into triangles, depending on the model.
Approach	In each measurement sequence, a different set of nodes is fixed to rigid bodies representing the clips.
Approach	For the bending measurement sequences (see Figure 4 ), we fix all cloth nodes above the edge of the table.
Approach	The measured pulling forces of the cords are applied as point forces on the rigid bodies at known locations, with known magnitudes and orientations.
Approach	Given a set of captured static deformation frames, we wish to know the (nonlinear) stress-strain curves for the deformation components of a cloth model, such that a simulated cloth matches known positions and forces as well as possible.
Approach	Specifically, we minimize the weighted error of cloth positions and clip forces over a sequence of measurement frames, subject to the constraint of static equilibrium on all frames.
Approach	For the formulation of the objective function, we concatenate in vectors the positions, x n , and the net forces, F n , of free cloth nodes at all frames, as well as the forces, F c , applied by the cords on the clips.
Approach	Due to equilibrium, the net force on the clips, produced by cord forces, gravity, and forces from fixed cloth nodes, must be zero.
Approach	We indicate with x n and F  ̃ c , respectively, the known cloth node positions and clip forces, measured as described in Section 3.
Approach	We also concatenate in a vector k the (unknown) stiffness values at the control points of the nonlinear stress-strain curves for the deformation components of the cloth.
Approach	Since the pieces of cloth are homogeneous, we use a single curve for each deformation component for all frames and all cloth elements.
Approach	Then, the computation of model parameters based on the minimization of position and force errors subject to the static equilibrium condition can be formulated as the following nonlinear constrained least-squares problem: k = arg min μ x n (k) − x n 2 + λ F c (x n , k) − F  ̃ c 2 ,
Approach	In this optimization problem, we use the measured clip positions, x c , as known boundary conditions.
Approach	For stretch tests, the objective function is based only on clip forces, i.e., μ = 0, λ = 1, while for bend tests it is based only on cloth positions (since there are no measured forces), i.e., μ = 1, λ = 0.
Approach	For shear tests, the objective function is based only on clip forces parallel to the direction of the clips themselves.
Approach	We observed that, in situations of near-homogeneous shear, the clip-parallel forces are dominated by shear, while clip-orthogonal forces are dominated by stretch.
Approach	Then, by fitting only clip-parallel forces we reduce the sensitivity to potential errors in stretch stiffness.
Approach	The optimization problem contains two unknowns: the parameter vector k and cloth node positions x n .
Approach	We solve the optimization in an iterative manner, refining k and x n separately on two nested loops.
Approach	In an outer loop, we refine k by local minimization of the error function and, in an inner loop, we recompute x n to satisfy the equilibrium constraint.
Approach	As a result, we obtain a linear expression that relates node positions to parameter values:
Approach	We terminate the outer loop (and hence the overall optimization) when the residual is reduced by less than 1% between two consecutive iterations.
Approach	To ensure convergence of the Newton-like iterations and to enforce non-negativity constraints on the components of k, we execute a line search from k(i) to the solution of (9) if the residual grows or if the solution violates some constraint.
Approach	The solution to the linear least squares problem requires solving a system Ak = b, where the size of A is given by the number of unknown stiffness values, |k|.
Approach	In our test examples, this number was always below 10, and we solved the linear systems using LDL factorization.
Approach	The formulation of A, on the other hand, requires solving |k| linear systems of type ∂F n y = b, which ∂x n we did using the conjugate gradient method.
Approach	Once the parameter values k(i + 1) are refined, we bring the cloth to a static equilibrium position, x n (i + 1).
Approach	We do this by solving quasi-static simulations until convergence on all captured frames, starting always from the measured configuration x n and using the measured clip positions x c as boundary conditions.
Approach	We consider that a piece of cloth has converged to equilibrium when F n < 10μN.
Approach	The quasi-static simulations involve linear-system solves with the cloth stiffness matrix ∂F n .
Approach	We found that, during inter∂x n mediate iterations, the stiffness matrix may not always be well conditioned, therefore we have solved the quasi-static equilibrium problems using additive Levenberg-Marquardt, which effectively produces a modified stiffness matrix of the form ∂F n + μI.
Approach	For improved conditioning, we also use this ∂x n modified stiffness matrix in the outer loop.
Approach	The nonlinearity of cloth deformation, together with the complex interplay of various deformation components in the resulting forces and positions, make the optimization problem above extremely complex in the general case, prone to falling in local minima and sensitive to initialization values.
Approach	However, we largely alleviate these issues with the design of the five isolated deformation measurements described in Section 3.2, which allow us to separately fit stiffness curves for the six deformation components described in Section 4.1, following an incremental parameter fitting procedure.
Approach	First, we fit in parallel the weft-stretch stiffness curve, k s,u (ε s,u ), for the weft-stretch sequence, and the warp-stretch stiffness, k s,v (ε s,v ), for the warp-stretch sequence.
Approach	We ignore shear and bend parameters for stretch fits, as we have observed that they have little effect.
Approach	Second, using known stretch stiffness curves, we fit the shear stiffness k s,uv (ε s,uv ), for the shear sequence.
Approach	Third, we fit in parallel the weftbending stiffness k b,u (ε b,u ), for the weft-bending measurement sequence, and the warp-bending stiffness k b,v (ε b,v ), for the warp-bending sequence.
Approach	Finally, we fit the diagonalbending stiffness curve k b,uv (ε b,uv ), using both weftand warp-bending measurements.
Approach	To better account for crossinfluence of shear and bending, we use their estimated values as initial guesses and run another fitting iteration.
Approach	To fit each stiffness curve k i (ε i ), we iteratively subdivide the Hermite spline adding more control points until the residual error function (6) is reduced by less than 1% or a speci- fied maximum number of points, usually 4 or 5, is reached.
Approach	First, we evaluate the strain histogram for the corresponding measurement sequence, and we determine maximum and minimum strains after removing outliers.
Approach	We initialize the stiffness curve with one control point (i.e., constant stiffness), and subsequently we subdivide the strain range with equidistant control points.
Approach	We tested our system on four fabric samples, including a knit and the three common weave patterns (plain weave, twill, and satin), and three fiber types (cotton, wool, and synthetic): cotton satin (#4), rayon/spandex knit (#12), cotton denim (#14), and wool/cotton blend (#18).
Approach	Each fabric was tested with seven deformations (see Section 3.2): for fitting, stretch in X and Y, simple shear, and bending in X and Y; and for evaluation, complex shearing and corner pulling.
Outcome	The measurement shows the typical behavior of a woven fabric: a nonlinear curve with increasing stiffness for higher strain, and large hysteresis.
Approach	The test repeats three times, retracing the same loop each time after the initial extension from rest.
Approach	We worked with three cloth models built from the components described in Section 4.
Approach	The Springs model uses the spring membrane model with the spring bending model; the Soft Constraints model uses Baraff and Witkin’s membrane model with the Discrete Shells bending model; and the St. VK model uses the diagonalized St. Venant-Kirchoff membrane model with the Discrete Shells bending model.
Approach	We fit all the models in four variants: linear (constant stiffness for each deformation mode), isotropic (identical stiffness in warp and weft), linear and isotropic (the simplest variant), and nonlinear orthotropic (the most general variant).
Outcome	The results are too numerous to include in the paper; we refer the reader to the supplementary material, which illustrates the behavior of the nonlinear orthotropic variant of all three models for all four fabrics, and the behavior of the variants of the Soft Constraints model for denim, a largely nonlinear and anisotropic material.
Outcome	For each test we show a selected frame (near maximum distortion) with renderings illustrating the captured and fitted cloth geometry and forces.
Outcome	To illustrate the fitting residuals more quantitatively, we show a force-displacement plot comparing a summary of the measured forces to the predictions of the fitted model and a vector-field plot illustrating the position error over the geometry of the fitted mesh (see caption for details).
Outcome	The four selected fabrics span a large range of possible cloth behaviors.
Outcome	In a nutshell, #12 is isotropic and very compliant in stretch and bending; #4 is also isotropic, very stiff in stretch but compliant in bending; #14 is stiff and quite isotropic in stretch, but extremely anisotropic in bending (with 33/1 stiffness ratio in weft and warp); and #18 is anisotropic both in stretch (with 10/1 stiffness ratio) and in bending (with 13/1 stiffness ratio).
Outcome	The maximum stretch stiffness for #4 is 250 times higher than for #12, while #14 is 10 times stiffer in shear than any other fabric.
Outcome	All four fabrics show similar hysteresis behavior, with loading-to-unloading stretch stiffness ratios ranging from 1.4/1 to 1.8/1.
Outcome	Sample #12 is nearly linear in the test deformation range, while all other three fabrics exhibit nonlinearity.
Outcome	Interestingly, nonlinearity may arise in some deformation modes but not in others, with no clear pattern.
Outcome	For stretching, all three cloth models fit nicely to the average of the hysteresis bands, even in highly nonlinear cases.
Outcome	The fitting residual is larger for stiffer fabrics, and the nonlinear orthotropic model variants fit anisotropic fabrics best, as expected, while linear and/or isotropic variants reach a reasonable compromise but are not always able to remain inside the hysteresis band.
Outcome	For shearing, the fitting force residual is larger for #14, the stiffest fabric.
Outcome	Across models, the Soft Constraints and St. VK models fit to the average of the shearing hysteresis band, while the Springs model deviates at times.
Approach	For bending, no forces are available, and we evaluate the position residual as well as profiles of sample curves orthogonal to the support plane.
Outcome	The fitting residual is similar for all fabrics, but distinctly higher for the Springs model.
Outcome	Often, the residual is dominated by a difference in curl near the edge of the sample, while the overall shape is well fit.
Outcome	The behavior of sample #12, the most linear fabric, is predicted well in all cases, as seen in the force-displacement plots, the buckling behavior in corner pulling, and the (lower) effective shear stiffness of the sheet when allowed to buckle in the complex shear test.
Outcome	Visually, the mismatch is more apparent in the complex shear test, where models with underestimated stiffness exhibit wider folds than the real fabrics.
Approach	We have also evaluated the fitted models on new test samples of each fabric, to validate their generality.
Approach	Specifically, we have tested stretching on new samples of rayon/spandex knit (#12.2) and cotton denim (#14.2), and shearing on new samples of cotton satin (#4.2) and wool/cotton blend (#18.2).
Outcome	The force-displacement plots of the real cloth samples, shown in the supplementary document, indicate very similar behavior between fitting and test samples for #12 and #14, and a larger disparity for #4 and #18.
Outcome	The evaluation plots for the simulation models behave similar for the test and fitting cases, but the matching quality depends on the actual disparity across cloth samples.
Outcome	While overall force-displacement behavior is nicely matched, the actual folding shapes of simulated cloth may deviate largely from the captured cloth, because even a small change in material properties may lead to distant stable configurations in the L 2 sense.
Outcome	For this reason, the traditional L 2 metric is not appropriate for evaluating error in this case.
Outcome	The discontinuity of stable configurations is also the cause of flickering and twitches in some of our examples.
Outcome	The Springs model exhibits the worst fitting quality in shearing force-displacement curves, and the highest fitting residual for bending.
Outcome	This is probably due to the inherent coupling of stretch and bending deformation components in this model.
Outcome	Nevertheless, the overall deformations in complex shearing fit reasonably well.
Outcome	In contrast to continuum models, complex parameter tuning has often been regarded as a caveat of mass-spring models; but our results indicate that satisfactory parameter estimation is possible by incorporating anisotropy and nonlinearity into the model.
Outcome	The Soft Constraints and St. VK models produce results with very similar quality, which is expected as the models present only subtle differences as described in Section 4.1.
Outcome	At least three effects are missed by the tested models: hysteresis, Poisson effect (due to the diagonalization of the standard StVK model), and cross-modal stiffening (e.g., shear stiffening due to stretching).
Outcome	We indeed identified stretch stiffening in the shearing deformations, therefore we chose clip-parallel forces as objective function to minimize the effect of stretch errors on shear optimization.
Outcome	We conjecture that missing cross-modal stiffening may also be, to a large extent, the reason for stiffness underestimation in the corner pulling test for the Soft Constraints and St. VK models.
FutureWork	An extension to the nonlinear model of Wang et al. [WRO11] could help alleviate these problems.
Outcome	This paper has demonstrated a novel system for observing cloth behavior, including complete information about deformation and forces, and a new method for fitting and evaluating cloth models using the measurements.
Outcome	Our system is different from standard textile testing systems because it captures detailed geometry information; it is different from previous cloth capture systems in that it captures complete force information and measures deformations of a 3D surface.
Outcome	The combination of very complete position and force information provides an unprecedented view into the complex behavior of cloth.
Outcome	Our measurement setup offers very accurate control over membrane deformations, but the bending tests require manual intervention and are thus less precise.
Outcome	Furthermore, the bending tests are most accurate for samples with straight edges, but some cloth materials (in particular knit) tend to curl up at free boundaries.
FutureWork	In order to eliminate these problems, we would like to investigate alternative ways of controlling bending deformations in the future.
Outcome	The data from our experiments shows some of the limitations of current models.
Outcome	The most obvious of these is hysteresis—all widely used cloth models are elastic, but cloth is clearly far from elastic, resulting in quite large errors for any given point in the experiment.
FutureWork	There are many paths for future work in measurement, including more complete exploration of strain space (including compression) and capture of dynamic properties, and in fitting, where new ways of evaluating fitting error are needed that can work when the cloth’s equilibrium state is unstable or non-deterministic.

Approach	We use a bar-network (bar-net) as a deforming mechanism.
Outcome	This technique can be used similarly to a conventional skinning tool, but can also make a skin surface behave in a physically plausible manner due to the inherent physical properties of the network.
Background	A bar-net is a structure commonly used in structural engineering.
Background	Its shape depends on the structural and material properties and the forces acting upon it.
Challenge	Computing the rest shape of an arbitrary bar-net is a time-consuming non-linear problem.
Approach	In order to speed up the computation and also for such a bar-net to be used intuitively to help computer animation, we have defined a set of properties that a desirable bar-net should satisfy.
Approach	This allows a bar-net shape finding problem to be solved using linear equations.
Approach	We adopt a two-layer structure for the representation of a skin surface, including a coarse mesh and a fine mesh.
Approach	To deform a skin surface, we couple a bar-net to its coarse mesh, which in turn deforms the fine mesh when the coupled bar-net is deformed.
Approach	The fine surface mesh can be of different forms, including Nurbs, subdivision surfaces and polygons.
Background	Skin deformation resulting from the movement of characters, such as humans and animals, is one of the most interesting and challenging topics in computer animation.
Challenge	The modelling and deformation of such characters are inevitably complicated and timeconsuming, because of their structural complexity.
Challenge	While realism is important, other factors such as intuitiveness, ease of interaction and computational cost are also of great importance in animation production.
Challenge	Often a compromise among these factors has to be reached.
Background	There are two general categories of methods in animation practice: simulation and authoring.
Background	Simulation 1–3 refers to the use of a mathematical model to automatically recreate the physical reality on computers.
Background	A simulation method lets the animator easily create certain effect which could be otherwise almost an impossible mission with manual manipulations.
Background	However, the disadvantage is also obvious.
Background	Although the simulation techniques provide some parameters for the animator to control the animation, the connection between these parameters and the result is often implicit.
Background	It is usually difficult for an artist to understand the exact physical meaning of these parameters and connect them to the final outcome.
Background	Second, such methods are often computationally expensive.
Background	The authoring methods refer to those that the animator can use to manipulate the modelling or deformation directly.
Background	The animator is able to see the result immediately and has a full control over the deformed shape of the character in question.
Background	Both types of methods were around for a long time.
Background	However, animators turn to favour those tools that they feel they have a control and can evaluate the results directly.
Outcome	In this paper we present a new skinning technique for the deformation of computer-animated characters.
Outcome	A key advantage is that it combines the strengths of both prevalent categories discussed above.
Outcome	This technique is based on a physically inspired deformation model from structural engineering, known as the bar-networks (bar-nets) and can therefore deform realistically based on the physical properties leading to physically plausible outcomes.
Outcome	Meanwhile, instead of letting the mechanical model taking its full course, the animator is able to operate it as a physically based authoring tool in the same way as other conventional deformation tools.
Outcome	We call this technique the bar-net driven deformations.
Background	In animation practice, either for the film industry or games design, it is quite often for each character model to have two layers of mesh, a rough mesh (low resolution) and a fine mesh (high resolution).
Background	The high-resolution (high-res) mesh may take various forms, such as Nurbs, subdivision surfaces and polygon meshes.
Background	The detailed skin shapes including skin deformations, wrinkle, squama and feather are created on this layer.
Background	Because the mesh is very dense involving fine detail, it is inefficient to animate directly on this layer.
Background	The low-resolution (low-res) mesh thus works as an efficient intermediate layer for the modelling and deformation of the fine skin layer.
Approach	Our technique adopts this two-layered strategy.
Approach	The animator creates almost all skin deformation effects on the low-res layer.
Approach	In order to take advantage of the physics, we couple an aforementioned mechanical bar-net with the low-res mesh in areas where deformations are expected to occur.
Approach	This low-res layer gets deformed physically and in turn deforms the high-res mesh of the character’s skin model.
Approach	In order for a mechanical network to be useful in skin deformation for animated characters, we devise a set of properties for the network to satisfy.
Approach	These properties allow the behaviours of skin and anatomic tissues, e.g. muscle groups, to be mimicked intuitively in computer animation and to be computed rapidly.
Background	What needs pointing out is although there is a similarity between a bar-net and a mass–spring model, they have substantially different behaviours.
Background	A mass–spring model will not be able to satisfy the properties we define here.
Background	Most of the techniques on character deformation can be roughly categorized into two groups: authoring and simulation methods, although the boundary between them does not always seem clear.
Background	The technique of Free Form Deformations (FFDs) first introduced by Sederberg and Parry 4 remains popular and has been adopted by many animation software packages due to its simplicity and modelling speed.
Background	FFDs were later extended by several other researchers.
Background	5–8 All these techniques are purely geometric in nature and make no attempt to simulate the physical properties or behaviours of a character.
Background	Based on the FFDs, two very popular deformation tools were developed in Maya, the Lattice and Wrap deformers.
Background	An intuitive attempt to deform a character was involving a skeleton into skin deformation.
Background	This approach has a long history and it treats the skin as a shell that moves by an explicit function of the skeleton.
Background	Vertices of the skin are deformed by a weighted combination of the joint transformations of the character’s skeleton.
Background	9–13 Collectively, such methods are known as the smooth skinning.
Background	They are easy to understand and intuitive to use.
Background	A tedious part is the proper assignment of the weights.
Background	In production, the weights are painted by the animator, and thus the animator has full control over the outcomes.
Background	The smooth skinning approach suffers from some notorious drawbacks, called the candy wrapper effect or collapsing elbow effect, due to its lack of consideration of volume preservation for the soft tissues.
Background	The example-based methods were developed as an alternative in order to overcome this kind of problems 14–17 and have had some success.
Background	With this method, which is called Blend Shape in animation production, the animator can control the exact appearance of the character.
Background	In facial animation, for example, the animator often needs to dictate how a facial model deforms to achieve different expressions.
Background	On the downside, however, a large number of models have to be made in the pose space and stored for shape interpolation.
Background	This is an expensive process.
Background	The drive for realism in computer graphics has lead to some new modelling and deformation techniques.
Background	A group of techniques that have gained increasing popularity in the computer animation of characters are those based on characters anatomy.
Background	These models attempt to mimic their real life counterparts by reproducing their anatomical structures.
Background	These anatomy-based skinning methods differ on the complexity of the models and their behaviours of the underlying anatomical structures.
Background	Some use simple muscle shapes, such as abstract muscle operators, 18 meatballs, 19 some employ detailed models.
Background	20–23 The obvious advantage of this group of methods is its ability in achieving detailed visual quality during animation.
Background	One of the difficulties of these techniques, 24–28 however, is that they are indirect to use, as one has to model the anatomical structures before its appearance arrives.
Background	Achieving a particular look of the skin requires the determination of the shape, number and the layout of the muscles underneath.
Background	Until the skin mesh envelops the underlying structure, it is very hard to anticipate how the character looks like from the outside.
Background	To retain the advantage of the anatomy-based technique without losing intuitiveness, recent research has looked into the issue of estimating the muscles from the skin shape.
Background	29–30 This new technique has had a degree of success.
Background	The current limitations are that they could only use simple muscle shapes, which are sufficient in obtaining detailed deformations.
Background	Anatomy based multi-layered models have significantly improved the realism of the modelling of complex living creatures.
Challenge	Character animation based on the deformation of underlying anatomical structures, such as muscles or fat, is a very complicated process.
Challenge	Issues like mechanical forces, material properties and collision among anatomic structures all need to be properly addressed.
Challenge	The computational cost is inevitably excessive.
Challenge	Such computational costs place severe restrictions on many applications.
Challenge	Our bar-net driven skinning method endeavours to take advantage of the anatomy-based approach, the smooth skinning approach and the physically based approach.
Approach	It follows the current animation workflow, except that a bar-net is coupled with the low-res skin layer.
Approach	When the low-res mesh (or a part of it) is coupled with a bar-net, the couple mesh is called the control mesh in this paper.
Approach	Bar-nets deform according to both the external forces it is subject to and the stiffness properties of the network.
Approach	By controlling these two factors, the animator can easily create the various skin deformation effects including muscle bulge, wrinkles and creases easily.
Approach	The control mesh is bound to the character skeleton in the same way as the traditional smooth skinning method.
Approach	The bar-nets work like a deformer (a term used in many animation packages, e.g. Maya) to change the shape of the skin surface.
Approach	It is compatible with all the other deformation tools incorporated in current animation software.
Approach	They can accumulatively deform the skin shape in a certain order which can be easily changed by the animator on the fly.
Approach	The fine mesh, either in the form of Nurbs, subdivision surfaces or polygons, is deformed by the control mesh using the wrapping deformation method 8 which is available with many commercial animation packages.
Approach	Further detailed deformations including wrinkle can also be added on either by manipulating the skin surface directly or by coupling a bar-net with the fine mesh using the same mechanism.
Approach	A bar-net connects n s points, P i , in three-dimensional space with straight-line segments, called bars.
Approach	These points on the net are known as nodes.
Approach	The nodes can be either fixed or free.
Approach	Fixed nodes will not have their positions changed regardless of whether they are subjected to external forces.
Approach	Free nodes can be moved to balance the acting forces on the net.
Approach	Each bar connects two nodes.
Approach	These bars can be stretched and squashed resulting from the positioning of the end nodes, but they cannot be bent.
Approach	The network described above is in fact a graph with links connecting pairs of nodes.
Approach	A matrix C s , called the branch–node matrix can be formed, which represents in a tabular form the graph of the network.
Approach	Assuming that there are n free nodes and n f fixed nodes, the branch–node matrix can be further subdivided into two sub-matrices, C and C f , by grouping the free-node columns and fixed-node columns of the original matrix, respectively.
Approach	These matrices are used in computing the rest shape of a bar-net.
Approach	A deformable part of the low-res mesh of a character can be considered as a bar-net.
Approach	This analogy establishes a natural link between a mechanical bar-net and a surface patch.
Approach	If a bar-net is coupled with a surface, the surface can be made to behave like a piece of elastic material.
Approach	Thus many numerical methods developed in structural and mechanical engineering for the manipulation of structures and networks can be applied to control the deformation of the surfaces.
Approach	Deforming the bar-net deforms the coupled surface, hence the name bar-net driven deformation.
Approach	Bar-nets can have any arbitrary topology.
Approach	They are not restricted to a quadrilateral topology unlike most curved surface patches.
Background	Quadrilateral patches are the easiest to control and there have been many algorithms developed to implement them.
Background	But methods for controlling the deformation of a non-quadrilateral surface patch analytically remain an interesting research topic.
Background	Such a problem could be resolved by coupling a general mechanical bar-net with the control points of a surface patch of the same topology.
Approach	The principle idea of the proposed bar-net driven deformation technique is to regard the deformable area of an animated creature as a network, which deforms under an acting force.
Approach	The final shape of the surface represents the rest shape of the network and is the result of the balance of all external and internal forces.
Approach	One does not need to worry about the shape of the network itself.
Approach	This because we use a bar-net only as a control mechanism.
Approach	Changing the stiffness with other parameters unchanged has an influence on the whole network.
Approach	This is in line with the physical property of human tissues and therefore makes physical sense.
Approach	The x, y, z components of the external loads applied to the free nodes (non-fixed nodes) have independent influences on the deformation.
Approach	The x component of the displacement is only determined by the x component of the applied force, and similarly for the y and z components.
Approach	So when the animator wishes to finetune the effects on the x, y or z direction separately, the surface will deform as expected.
Approach	The deformation of the free nodes satisfies the superposition principle.
Approach	In other words, if one free node is subject to the influence of a number of forces simultaneously, the general deformation applied to the node is the same as the sum of all the deformations generated by applying these loads independently.
Approach	The benefit from this property is that several muscles, bones, fat tissues can affect the skin deformation simultaneously through summing up of their individual forces.
Background	Network form finding is always a numerically complicated problem in mechanical and structural engineering.
Background	Various numerical methods exist.
Background	As far as most mechanical networks are concerned, the relationship between the equilibrium state and the acting forces is non-linear.
Background	Shape change cannot be trivially related to the magnitude and direction of the external forces.
Background	Often numerical algorithms are deployed to determine the rest form of a network, which is inevitably time-consuming and not very useful for animation production.
Approach	In our case, the effect of stiffness of a network can be approximated by the quantity of force-length ratios of all the bars.
Background	Some researchers call this quantity the force density.
Approach	Using this stiffness parameter, we found the force density method 31 satisfies the above-defined properties.
Approach	Using a bar-net together with the force density form finding method, the prevailing advantages of this technique are its speed of computation and intuitiveness in shape control.
Approach	Coupling bar-nets with a skin surface makes it ‘mechanically deformable’.
Background	Skin deformation can happen around the joints where its surface bends and also in places where the underlying anatomic structure, such as muscles, pushes and pulling the skin surface.
Approach	Using above defined bar-net properties, deformations are achieved by applying virtual forces to the appropriate free nodes of the control mesh.
Approach	We use the force density parameter (equivalent to stiffness) and external forces to control the deformation.
Approach	Multiple bars can be grouped together to simulate the effect of muscle groups.
Approach	The user can manipulate the force on each node to tune the deformation interactively.
Approach	One can also change the force densities to make the network firmer or softer.
Approach	Forces are applied to only eight nodes of the bar-net.
Approach	In this example, the force densities are kept unchanged.
Approach	The gradually changed forces on the control mesh are bound to the elbow rotation angle, which produce both the bulge effect and compensate for the volume loss that the traditional smooth skinning method suffers.
Background	Deformed muscles always change the shape of the skin surface.
Approach	Using the model of a human arm, we illustrate how to generate the muscle effect with bar-nets.
Background	There are approximately 50 muscles in a human upper limb, most of which are large and complex.
Background	Muscles usually act in groups, some muscles act to move the joint, some to support the movement by avoiding unwanted secondary movements.
Background	The combination of these actions causes the muscles, hence the arm, to deform.
Approach	In the animated arm model, we are only concerned with the muscles producing major influence on the skin.
Approach	The deformation of the forearm is complex but relatively unnoticeable.
Approach	Therefore, in this case, only the deformations caused by biceps brachii and triceps brachii are generated.
Approach	When the arm flexes, the biceps brachii contracts and bulges.
Approach	At the same time, the triceps brachii relaxes to allow this action.
Approach	The opposite occurs during the extension of the forearm.
Approach	The biceps brachii and triceps brachii are positioned on opposite sides of the upper arm.
Approach	Accordingly only the nodes lying around the central line of the two muscles are set to free, all other nodes are fixed.
Approach	All the bars in the network are initially assigned a uniform force density.
Approach	Because of the tendon of the biceps brachii, flexing the arm deforms the biceps brachii in all three directions (x, y and z): it is shortened along the arm due to its contraction and it bulges in the other two directions to maintain its volume.
Approach	To simulate the force of the muscles, we apply some simple loads to the midpoints of the network as shown in Figure 3(b) .
Approach	These loads deform the surface to form a natural muscle bulge, as shown in Figure 3(c) .
Approach	This example demonstrates that the animator can easily shape the characters using the virtual forces as user-handles.
Approach	There are 2891 vertices and 2816 faces in the subdivision model.
Approach	While in the bar-net, there are 12 free nodes which are the only necessary resources involved in the form finding and it involves little computation cost.
Approach	Local deformations can be similarly achieved by changing the force densities.
Approach	For example, reducing the force density of the network increases the size of the bulge effect as shown in Figure 3(d) .
Background	The human shoulder is a typical area where notorious skin deformities occur using a traditional skinning method.
Outcome	Most computer-animated characters are complex both geometrically and topologically.
Outcome	The use of quadrilateral meshes to model the geometry of such characters is frequently inadequate.
Background	Computer-animated characters come in different shapes, e.g. in a form of a human, an animal or a completely imaginary figure.
Background	Branches, holes, non-manifolds and irregularities are possible geometric features of their body forms.
Outcome	Satisfying our designed properties, the network is capable of handling any connectivity (topology).
Outcome	In practice, an animated character can be initially modelled by sketching its basic shape roughly.
Outcome	This rough model is coupled with a bar-net to act as the control mesh of the character.
Outcome	The fine skin surface can be represented in various surface forms.
Outcome	Our implementation includes three major surface modelling forms: Nurbs, subdivision surfaces and polygons.
Outcome	Once the control mesh is deformed, it can deform the fine surface model using the Wrap deformer available in many animation packages.
Outcome	Bar-net driven skinning is applicable also to the modelling of wrinkle, where the bar-net is bound to the fine mesh rather than the rough mesh in order to obtain a detailed look.
Background	Character deformation in computer animation has attracted a great deal of research effort over the last two decades.
Background	The earlier models, despite being cheap, had difficulties in creating realistic character deformations.
Background	With the quest for realism, more physically based and CPU intensive computation models have emerged, notably the multi-layered anatomy-based approach.
Challenge	However, in addition to the computational cost, it is undesirable to require the animator to model many muscles before the skin shape is developed.
Outcome	In this paper, we propose a physically motivated deformation authoring technique, called the bar-net driven skinning.
Outcome	Its main strength lies in the combination of speed, intuitiveness and good realism.
Outcome	Our technique can achieve similar results to those of the anatomy-based techniques, but in an interactive manner.
Outcome	Bar-nets reach their rest shape when the acted forces equilibrate.
Outcome	Changing the forces and/or stiffness leads to a change of their shape.
Outcome	Coupling a part of surface mesh with bar-nets allows the surface deformation to be controlled by manipulating the networks and can take advantage of the physical behaviour inherent to the network.
Approach	In order to allow deformations to be produced quickly and intuitively, we have devised a set of properties that an ‘ideal’ bar-net should satisfy, which make intuitive shape control and fast computation possible.
Outcome	To deform the skin surface of a character, we couple a bar-net with a low-res mesh, called the control mesh, which links with the skin surface.
Outcome	This makes the skin mechanically deformable and achieves realistic deformation outcomes.
Outcome	We provide two types of user-handles associated with a bar-net, the virtual forces applied to the free nodes of a network and the force density values.
Outcome	They can be used individually as an interactive modelling tool or collectively to mimic the muscle forces from a muscle group.
Outcome	We have implemented this technique into prototype program in a form of a plug-in for the Autodesk Maya software ( Figure 7 ).
Outcome	It provides the animator with a new deformer which can be used both as a modelling and an animation tool.
Outcome	The animator can interactively change the fix–free status of each node, define and manipulate the forces on each free node, tune the force densities for selected bars.
Outcome	On the downside, the tools developed so far are still relatively primitive.
Outcome	The user needs to understand the basic principles of the bar-net properties before the technique can be used efficiently.
FutureWork	To remedy this problem we are currently designing higher-level tools with an interactive user interface, which will hide this complexity from the user.
Approach	The equilibrium shape of the net structure is reached when all the forces applied at each node sum up to zero.
Approach	p x ; p y ; p z are the external load vectors.
Approach	It is clear from Equation ( 4 ) that any state of equilibrium of a general network structure can be obtained by the solution of one system of linear equations, which is computationally inexpensive.

