Cloth motion gets captured by multiple video cameras which acquire a 3D point cloud of the cloth surface,  using a coloured pattern of the cloth which consists of the smallest and yet distinctive markers possible.  The 3D location of surface points is reconstructed by detecting corresponding points in multiple views. The paper presents a method to reconstruct correspondence in case of foldings (e.g. wrinkles around a knee) or occlusions (e.g. limb blocking the view of another). Three main optimisations are introduced in correspondence determination; the matching procedure gets optimised by increasing the information budget per marker and pixel, exploiting the full colour space. The information needed from neighbours is eliminated via an iterative approach to compute correspondence. Finally, strain constraints are introduced in a novel strain purning process. In order to tackle hole cases after the acquisition process, caused by occlusions, a data driven automatic hole filling approach is deployed that interpolates previously captured cloth into the mesh. Finally, the paper proposes a motion capture data approach. Proxy points for the points for knee and hip joints in each of the basis meshes are inserted to produce the final output meshes. A method of smoothing near-rigid movement without effecting flexible deformation, the flexibility preserving smoothing, is introduced as an automated calibration technique.