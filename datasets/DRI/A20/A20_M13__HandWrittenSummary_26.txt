In this paper, the authors introduce a statistical motion model for human motion analysis and generation. Their model combines the powers of physics-based motion modeling and statistical motion modeling. The incorporation of physical constraints into statistical motion models ensures generalized motions are physically plausible, thereby removing noticeable visual artifacts (e.g., unbalanced motions and motion jerkiness) in an output animation. Moreover, it enables them to create motions that react to changes in physical parameters. Meanwhile, the use of force field priors for human motion modeling not only ensures that generated motions are natural looking but also extends physically-based modeling techniques to stylized and heterogeneous human actions. The authors model the force field priors using Gaussian process models because GP can efficiently capture nonlinear properties of the force fields and its learning process involves very few manual tuning parameters. However, Gaussian process needs to retain all of the training data to make predictions and therefore its computational demands grow as the square and cube respectively of the number of training examples. Another limitation of their system is that it cannot generate a motion that is very different from motion examples because their approach is data-driven. In addition, the system is still unable to handle arbitrary external forces because the force field priors prevent the generated motion from moving away from prerecorded motion data.