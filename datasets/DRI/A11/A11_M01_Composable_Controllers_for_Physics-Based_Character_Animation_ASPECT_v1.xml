<?xml version="1.0" encoding="UTF-8" standalone="no"?>
<Document xmlns:gate="http://www.gate.ac.uk" name="A11_M01_Composable_Controllers_for_Physics-Based_Character_Animation_ASPECT_v1.xml">


  
    7eeaedc9f2ec1da80fc050225b3e2c46b86575c35a015ea71f86fa9254b15d34
    3vt5
    http://dx.doi.org/10.1145/383259.383287
  
  
    
      
        <Title>Composable Controllers for Physics-Based Character Animation</Title>
      
      
        
          Petros Faloutsos 1⁄2 Michiel van de Panne 3⁄4 1⁄2 Demetri Terzopoulos
          1
        
      
      University of Toronto, Department of Computer Science 3⁄4 Motion Playground, Inc. New York University, Courant Institute, Computer Science Department
      
        
        
        Figure 1: A dynamic “virtual stuntman” falls to the ground, rolls over, and rises to an erect position, balancing in gravity.
      
      <Abstract>
<Sentence aspectClass="NONE" inAbstract="true">An ambitious goal in the area of physics-based computer animation is the creation of virtual actors that autonomously synthesize realistic human motions and possess a broad repertoire of lifelike motor skills.</Sentence> <Sentence aspectClass="NONE" inAbstract="true">To this end, the control of dynamic, anthropomorphic figures subject to gravity and contact forces remains a difficult open problem.</Sentence> <Sentence aspectClass="NONE" inAbstract="true">We propose a framework for composing controllers in order to enhance the motor abilities of such figures.</Sentence> <Sentence aspectClass="NONE" inAbstract="true">A key contribution of our composition framework is an explicit model of the “pre-conditions” under which motor controllers are expected to function properly.</Sentence> <Sentence aspectClass="NONE" inAbstract="true">We demonstrate controller composition with pre-conditions determined not only manually, but also automatically based on Support Vector Machine (SVM) learning theory.</Sentence> <Sentence aspectClass="NONE" inAbstract="true">We evaluate our composition framework using a family of controllers capable of synthesizing basic actions such as balance, protective stepping when balance is disturbed, protective arm reactions when falling, and multiple ways of standing up after a fall.</Sentence> <Sentence aspectClass="NONE" inAbstract="true">We furthermore demonstrate these basic controllers working in conjunction with more dynamic motor skills within a prototype virtual stuntperson.</Sentence> <Sentence aspectClass="NONE" inAbstract="true">Our composition framework promises to enable the community of physics-based animation practitioners to easily exchange motor controllers and integrate them into dynamic characters.</Sentence>
</Abstract>
	Keywords: Computer Animation, Character Animation, PhysicsBased Animation Control, Physics-Based Modeling CR Categories: I.3.7 [Computer Graphics]: Three-Dimensional Graphics and Realism—Animation; I.6.8 [Simulation and Modeling]: Types of Simulation—Animation  
    
    
      0 To appear in the Proceedings of SIGGRAPH 2001 (Los Angeles, CA, August 12–17, 2001). In Computer Graphics Proceedings, Annual Conference Series, 2001, ACM SIGGRAPH, in press.
      
        <H1>1 Introduction</H1>
      
      <Sentence aspectClass="COMMON_PRACTICE" inAbstract="false">Despite the considerable history of progress in animating virtual humans <CitSpan>[ 3 , 7 ]</CitSpan>, physics-based animated characters with a large repertoire of motor skills have so far been elusive.</Sentence> <Sentence aspectClass="COMMON_PRACTICE" inAbstract="false">This may seem surprising in view of the recent successes in implementing a slew of specialist controllers capable of realistically synthesizing the complex dynamics of running, diving, and various gymnastic maneuvers <CitSpan>[ 16 ]</CitSpan>.</Sentence> <Sentence aspectClass="ADVANTAGE_DISADVANTAGE" inAbstract="false">While a divide-and-conquer strategy is clearly prudent in coping with the enormous variety of controlled motions that humans and other animals may perform, little effort has been directed at how the resulting control solutions may be integrated to yield composite controllers with significantly broader functionalities.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">For example, if researcher A creates a walking controller for a dynamic character while researcher B creates a running controller for the same articulated model, it would be beneficial if they could share their controllers (perhaps through an e-mail exchange) and easily create a composite controller enabling the character to both walk and run.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">This is a difficult problem, but its resolution would help pave the way towards controller libraries for dynamic animation which communities of practitioners could utilize and to which they could contribute.</Sentence> <Sentence aspectClass="NOVELTY" inAbstract="false">In this paper, we propose a simple yet effective framework for composing specialist controllers into more general and capable control systems for dynamic characters.</Sentence> <Sentence aspectClass="NOVELTY" inAbstract="false">In our framework, individual controllers are black boxes encapsulating control knowledge that is possibly gleaned from the biomechanics literature, derived from the robotics control literature, or developed specifically for animation control.</Sentence> <Sentence aspectClass="NOVELTY" inAbstract="false">Individual controllers must be able to determine two things: <CitSpan>(1)</CitSpan> a controller should be able to determine whether or not it can take the dynamic character from its current state to some desired goal state, and <CitSpan>(2)</CitSpan> an active controller should be able to determine whether it is operating nominally, whether it has succeeded, or whether it has failed.</Sentence> <Sentence aspectClass="NOVELTY" inAbstract="false">Any controller that can answer these queries may be added to a pool of controllers managed by a supervisor controller whose goal is to resolve more complex control tasks.</Sentence> <Sentence aspectClass="NOVELTY" inAbstract="false">An important technical contribution within our controller composition framework is an explicit model of pre-conditions.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">Preconditions characterize those regions of the dynamic figure’s state space within which an individual controller is able to successfully carry out its mission.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">Initially, we demonstrate the successful composition of controllers based on manually determined pre-conditions.</Sentence> <Sentence aspectClass="NOVELTY" inAbstract="false">We then proceed to investigate the question of whether pre-conditions can be determined automatically.</Sentence> <Sentence aspectClass="NOVELTY" inAbstract="false">We devise a promising solution which employs Support Vector Machine (SVM) learning theory.</Sentence> <Sentence aspectClass="NOVELTY" inAbstract="false">Our novel application of this technique learns appropriate pre-conditions through the repeated sampling of individual controller behavior in operation.</Sentence> <Sentence aspectClass="NOVELTY" inAbstract="false">As a testbed of our techniques, we are developing a physicallysimulated animated character capable of a large repertoire of motor skills.</Sentence> <Sentence aspectClass="ADVANTAGE" inAbstract="false">An obvious application of such a character is the creation of a virtual stuntperson: the dynamic nature of typical stunts makes them dangerous to perform, but also makes them an attractive candidate for the use of physics-based animation.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">The open challenge here lies in developing appropriate control strategies for specific actions and ways of integrating them into a coherent whole.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">In this paper, we demonstrate families of composable controllers for articulated skeletons whose physical parameters reflect anthropometric data consistent with a fully-fleshed adult male.</Sentence> <Sentence aspectClass="COMMON_PRACTICE" inAbstract="false">One family of controllers is for a 37 degree-of-freedom (DOF) 3D articulated skeleton, while a second family of controllers has been developed for a comparable 16 DOF 2D articulated skeleton.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">While the 3D skeleton illustrates the ultimate promise of the technique, the easier control associated with the 2D skeleton allows for more rapid prototyping of larger families of controllers and more careful analysis of their operation.</Sentence> <Sentence aspectClass="COMMON_PRACTICE" inAbstract="false">As has been recognized in the robotics literature, the control of broad skilled repertoires of motion remains very much an open problem even for 2D articulated figures.</Sentence> <Sentence aspectClass="COMMON_PRACTICE" inAbstract="false">Fig. 1 illustrates the 3D dynamic character autonomously performing a complex control sequence composed of individual controllers responsible for falling reactions, rolling-over, getting up, and balancing in gravity.</Sentence> <Sentence aspectClass="COMMON_PRACTICE" inAbstract="false">The upright balancing dynamic figure is pushed backwards by an external force; its arms react protectively to cushion the impact with the ground; the figure comes to rest in a supine position; it rolls over to a prone position, pushes itself up on all fours, and rises to its feet; finally it balances upright once again.</Sentence> <Sentence aspectClass="COMMON_PRACTICE" inAbstract="false">A subsequent disturbance will elicit similar though by no means identical autonomous behavior, because the initial conditions and external forces will usually not be exactly the same.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">Control sequences of such intricacy for fully dynamic articulated figures are unprecedented in the physics-based animation literature.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">After reviewing related prior work in the next section, we present the details of our control framework in Section 3.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">We then investigate the question of determining pre-conditions in Section 4.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">Section 5 describes the articulated figure models and the software system we use to implement the control framework.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">Section 6 presents the details of the example in Fig. 1 along with several other examples that demonstrate the effectiveness of our framework.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">Section 7 concludes the paper and discusses avenues for future research opened up by our work.</Sentence>
      
        <H1>2 Previous Work</H1>
        <Sentence aspectClass="COMMON_PRACTICE" inAbstract="false">The simulation and animation of human characters is a challenging problem in many respects.</Sentence> <Sentence aspectClass="COMMON_PRACTICE" inAbstract="false">Comprehensive solutions must aspire to distill and integrate knowledge from biomechanics, robotics, control, and animation.</Sentence> <Sentence aspectClass="COMMON_PRACTICE" inAbstract="false">Models for human motion must also meet a particularly high standard, given our familiarity with what the results should look like.</Sentence> <Sentence aspectClass="COMMON_PRACTICE" inAbstract="false">Not surprisingly, a divide-and-conquer strategy is evident in most approaches, focusing efforts on reproducing particular motions in order to yield a tractable problem and to allow for comparative analysis.</Sentence> <Sentence aspectClass="COMMON_PRACTICE" inAbstract="false">The biomechanics literature is a useful source of predictive models for specific motions, typically based on experimental data supplemented by careful analysis.</Sentence> <Sentence aspectClass="ADVANTAGE" inAbstract="false">These models target applications such as medical diagnosis, the understanding and treatment of motor control problems, the analysis of accidents and disabilities, and high-performance athletics.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">Computer simulation is becoming an increasingly useful tool in this domain as the motion models evolve to become more complex and comprehensive <CitSpan>[ 26 , 27 , 29 ]</CitSpan>.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">Given the challenge of achieving high-fidelity motion models for individual motions, there have been fewer efforts towards integrated solutions applicable to multiple motions.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">Reference <CitSpan>[ 26 ]</CitSpan> is one such example.</Sentence> <Sentence aspectClass="ADVANTAGE" inAbstract="false">Robotics research has made remarkable progress in the successful design of a variety of legged robots <CitSpan>[ 28 ]</CitSpan> and, more recently, bipedal robots with anthropomorphic aspirations <CitSpan>[ 23 ]</CitSpan>.</Sentence> <Sentence aspectClass="DISADVANTAGE_ADVANTAGE" inAbstract="false">Despite their limited motion repertoires and rather deliberate movements, these robotic systems are truly engineering marvels.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">The work in <CitSpan>[ 1 ]</CitSpan> provides a good summary of behavioral architectures explored in the context of robotics.</Sentence> <Sentence aspectClass="ADVANTAGE_DISADVANTAGE" inAbstract="false">A 3 DOF ball-juggling robot is described in <CitSpan>[ 6 ]</CitSpan> which uses a theory of behavior composition, although the practicality of extending the method to high-DOF dynamic models of human motions is unclear.</Sentence> <Sentence aspectClass="COMMON_PRACTICE" inAbstract="false">Computer animation is to a large extent unencumbered by the exacting fidelity requirements of biomechanical models and the mechanical limitations of robotic systems.</Sentence> <Sentence aspectClass="COMMON_PRACTICE" inAbstract="false">This has spawned a great variety of kinematic and dynamic models for character motion <CitSpan>[ 3 , 4 , 7 ]</CitSpan>.</Sentence> <Sentence aspectClass="COMMON_PRACTICE" inAbstract="false">While motion capture solutions based on blending and warping techniques may give satisfactory results for such tasks in the short term, controller based approaches reveal more about the physics, planning, and control of such motions and they therefore serve as a basis for more general solutions.</Sentence> <Sentence aspectClass="COMMON_PRACTICE" inAbstract="false">Dynamically simulated characters were first proposed over 15 years ago <CitSpan>[ 2 , 34 ]</CitSpan> and since then have progressed in sophistication in a variety of directions.</Sentence> <Sentence aspectClass="COMMON_PRACTICE" inAbstract="false">Controllers have been successfully designed for specific human motions such as walking, running, vaulting, cycling, etc. <CitSpan>[ 16 , 22 , 35 ]</CitSpan>.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">Dynamically simulated articulated characters equipped with an integrated, wide-ranging repertoire of motor skills currently remain an unachieved goal.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">Some positive steps in this direction are evident, however.</Sentence> <Sentence aspectClass="COMMON_PRACTICE" inAbstract="false">Examples include an integrated repertoire of motor controllers for biomechanically animated fish <CitSpan>[ 30 ]</CitSpan>, a methodology for controller design and integration applicable to simple figures <CitSpan>[ 32 ]</CitSpan>, a demonstration of successful integration for selected diving and gymnastic motions <CitSpan>[ 35 ]</CitSpan>, and adapting a controller designed for one character to work on another character <CitSpan>[ 17 ]</CitSpan>.</Sentence> <Sentence aspectClass="ADVANTAGE" inAbstract="false">The work of Wooten <CitSpan>[ 35 ]</CitSpan> is the most relevant as an example of a sequence of successive transitions between several controllers for human motions such as leaping, tumbling, landing, and balancing.</Sentence> <Sentence aspectClass="COMMON_PRACTICE" inAbstract="false">Transitions are realized by including the end state of some controllers in the starting states of other controllers.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">A digital biomechanics laboratory is proposed by Boston Dynamics, Inc.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">
<CitSpan>[ 20 ]</CitSpan> as a tool for simulating a wide range of human motion.</Sentence> <Sentence aspectClass="COMMON_PRACTICE" inAbstract="false">This currently remains ambitious work in progress.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">Our work is aimed at creating dynamic human characters with broadly integrated action repertoires.</Sentence> <Sentence aspectClass="NOVELTY" inAbstract="false">Unlike previous work focusing on specific athletic movements, our methodology is to begin with a core set of simple actions, including balancing, small steps, falling reactions, recovery from falls, standing up from a chair, and others.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">In the present paper, we do not cover in any appreciable detail the design of individual controllers to effect such basic actions.</Sentence> <Sentence aspectClass="ADVANTAGE" inAbstract="false">1 Rather, our contribution here is a framework for composing individual controllers, however they may be designed, into more capable control systems for dynamic characters.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">An interesting tech-
        1 Full details about the individual controllers that we have designed are presented elsewhere <CitSpan>[ 10 ]</CitSpan>.</Sentence>
        <Sentence aspectClass="NONE" inAbstract="false">nical contribution within our controller composition framework is the introduction of a learning approach for automatically determining controller pre-conditions.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">Our pre-condition learning algorithm adds to the growing body of learning algorithms that have been successfully applied in the context of computer animation in recent years <CitSpan>[ 14 , 15 ]</CitSpan>.</Sentence>
      
      
        <H1>3 Controller Composition Framework</H1>
        <Sentence aspectClass="NONE" inAbstract="false">In our controller composition framework, we consider individual controllers as black boxes which are managed by a simple supervisor controller.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">When no controller is active, the supervisor polls the pool of controllers, querying each whether it can handle the transition of the dynamic character from its current state to the desired goal state.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">Individual controllers return an integer confidence/suitability score when queried in order to bid on becoming the active controller.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">In our implementation, controllers that can perform a sensible action given the current state of the character return an integer in the range 1⁄2 1⁄21⁄4 , while those that can handle the current state as well as guarantee a transition to the desired state, return an integer in the range 1⁄21⁄4 3⁄41⁄4 .</Sentence> <Sentence aspectClass="NONE" inAbstract="false">Lastly, a value of 1⁄4 means that a controller is unsuited for the current state.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">The controller that returns the highest score becomes active.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">While this scoring scheme potentially allows for a nuanced evaluation of the controller suitability in terms of criteria such as probability of success or energy used, our current controllers resort to a simpler scheme.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">This consists of a binary success/failure evaluation multiplied by a weighting factor assigned to each controller that serves to establish a relative preference ordering.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">The power of this scheme stems from the following attributes:
        Simplicity: The composition method is straightforward and easy to implement.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">It does not appreciably burden the controller design task.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">Generality: The composition method does not restrict the design of individual controllers.</Sentence> <Sentence aspectClass="ADVANTAGE" inAbstract="false">Each controller can be as primitive or as sophisticated as its designer wishes.</Sentence>
        
          <H2>3.1 Controller Abstraction</H2>
          <Sentence aspectClass="NONE" inAbstract="false">A controller within the pool of available controllers can be as simple as a constant force, or as complex as a structured hierarchy of multiple levels of control abstraction.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">For example, as more controllers are added to the system, we may wish to group all the walking and running controllers together into a cluster that can be treated as one encapsulated controller.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">Regardless of the encapsulation, our composition method requires controllers to define pre-conditions, post-conditions and expected performance.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">Pre-conditions are a set of conditions over the state of the character and the environment.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">If these conditions are met then the controller can operate and possibly enable the character to satisfy the post-conditions.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">Assuming that the pre-conditions were met, the post-conditions define a range of states for the final state of the character after the execution of the controller.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">In other words the controller realizes a mapping between a domain of input states to a range of output states for the character.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">Because of unexpected changes in the environment, this mapping may not always succeed, which motivates the notion of expected performance.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">The controller should be able to evaluate its performance in order to detect failure at any point during its operation.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">To do this, the controller must at all times have knowledge of the current and expected state of the character or the environment.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">Defining the pre-conditions, post-conditions, and expected performance for complex characters, motions, and environments is not a straightforward task.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">However, we believe that the effort required to generate these specifications is a fair and necessary price to pay to achieve the benefits of composability.</Sentence> <Sentence aspectClass="COMMON_PRACTICE" inAbstract="false">Controllers that adhere to these specifications can form a pool of available controllers managed by the supervising controller.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">Fig. 2 presents an overview of the supervising controller’s function and its interaction with the individual controllers at every time step of the simulation.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">Before we elaborate on pre-conditions, post-conditions, and expected ing quantities performance and symbols: in subsequent The state sections, Õ let Ü Ü us 1⁄4 define of a figure the followis the vector of generalized positions Ü and velocities Ü , where the dot indicates a time derivative.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">The position and velocity of the center of mass are denoted as and respectively.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">The base of support of a figure (often called the support polygon) is denoted as Ë .</Sentence> <Sentence aspectClass="NONE" inAbstract="false">It is represented by a polygon that surrounds the foot or feet that are in contact with the ground at any given time.</Sentence>
          Supervising controller At every time step: if( no active_controller ) Controller for all controllers i =1: N if( controller[i].can_handle() == true) { Preconditions PostConditions put controller[i] into candidates end if Expected Performance end for active_controller = arbitrate(candidates) else status = active_controller.getStatus() endif
          
            Figure 2: Controller selection and arbitration during simulation.
          
        
        
          <H2>3.2 Pre-Conditions</H2>
          <Sentence aspectClass="NONE" inAbstract="false">In general, pre-conditions are relationships and constraints involving several different parameters.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">We have used the following parameters in our work:
          The initial state Õ of the figure.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">Most of our controllers can operate within a small region of the state space which we denote Ê  ́ Õ μ .</Sentence> <Sentence aspectClass="NONE" inAbstract="false">Environmental parameters.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">These include the contact points between the character and the ground, as well as the normal of the ground and the amount of friction at the contact points.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">In the following we denote conditions (generally indicated by the letter ) on the environment parameters as .</Sentence> <Sentence aspectClass="NONE" inAbstract="false">The balance of the figure.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">Usually, this is indicated by the relative position and velocity between the figure’s center of mass and the base of support.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">Typically, if the projection of along the gravity vector does not intersect the base of support Ë , the figure is considered to be unbalanced.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">We denote the balance conditions as  ́ Ë μ .</Sentence> <Sentence aspectClass="NONE" inAbstract="false">A Ê  ́ target Õ Ø μ , which state Õ can Ø , or be in provided general a by target the region user.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">of the state space
          Pre-conditions consist of unions of instances of the above conditions and are denoted
          <CitSpan>(1)</CitSpan>
          The determination of pre-conditions is crucial to the success of our composition framework and will be examined in detail in Section 4.</Sentence>
        
        
          <H2>3.3 Post-Conditions</H2>
          <Sentence aspectClass="NONE" inAbstract="false">Successful operation of a controller brings the character from an initial state, as defined by the pre-conditions, to a desired state or a desired region Ê  ́ Õ Ó μ in the state space.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">This region along with balance and possibly environmental constraints form the postconditions of a controller:
          <CitSpan>(2)</CitSpan>
          Note that the pre-conditions may reference a subset of the postconditions that is sufficient to characterize what the controller can achieve.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">In general, however, the post-conditions are different from the pre-conditions.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">For example, while a pre-condition for a falling controller requires that the center of mass be moving, the postconditions require that the center of mass be at rest.</Sentence>
        
        
          <H2>3.4 Expected Performance</H2>
          <Sentence aspectClass="ADVANTAGE" inAbstract="false">Our framework permits the automatic selection of the appropriate controller based on the information provided by the controllers themselves.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">Only the individual controllers can detect whether they are operating normally or whether failure is imminent.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">Failure in our case means that the controller cannot meet its post-conditions Ç .</Sentence> <Sentence aspectClass="NONE" inAbstract="false">The controller may fail because of a sudden change in the environment or because of badly designed pre-conditions.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">The sooner a controller can detect failure the sooner another more appropriate controller can take over.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">This is important for making a character behave naturally.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">For example, the character should not attempt to continue a walking gait if it has lost its balance and it is falling.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">In our implementation, the expected performance consists of expressions similar to those of the pre-conditions È .</Sentence> <Sentence aspectClass="NONE" inAbstract="false">In particular if the controller successfully completes its task in the time interval Ø 1⁄2 , Ø 3⁄4 , then  ́ Ø 1⁄2 μ 3⁄4È and  ́ Ø 3⁄4 μ 3⁄4Ç .</Sentence>
        
        
          <H2>3.5 Transitions</H2>
          <Sentence aspectClass="NONE" inAbstract="false">Transitions between controllers are not explicitly modeled as they would be in a finite state machine.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">They occur implicitly in response to the evolution of the motion over time, as the system state traverses the “regions-of-competency” of the various controllers.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">Nevertheless, given that most controllers are designed for specific situations, typical patterns of controller activation occur.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">Fig. 3 shows the family of controllers designed for the 3D dynamic character and their typical transition patterns.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">For example, the controllers and transitions used in achieving the motion shown in Fig. 1 is given by balance fall default rollover prone-tostanding balance.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">Fig. 4 similarly shows the family of controllers designed for the 2D dynamic character and their typical transition patterns.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">Note that not all possible transitions are shown in either of Figs. 3 and 4.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">For example, the prone-to-standing fall transition can occur if the figure is given a sufficiently strong push while rising.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">Most of the transitions which are not shown but are still practically feasible are of this nature, dealing with falling behaviors.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">Note that the fall controller always responds to the specific direction of the current fall.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">Any transition involves one controller being deactivated and another being activated.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">A controller can become deactivated (and thereby elicit a transition) for one of three reasons.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">First, it may relinquish control by declaring success upon reaching its postcondition, as is the case for a standup controller which has successfully returned the character to a standing position.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">Second, user intervention may elicit a transition.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">The controllers designed for sitting or balanced standing will retain control until intervention by a user (or by a higher level planner) forces a desired transition.</Sentence> <Sentence aspectClass="COMMON_PRACTICE" inAbstract="false">Thus, when the 2D character is balanced a user-driven process must choose among the next plausible actions, namely one of sit, walk, or dive (see Fig. 4 ).</Sentence> <Sentence aspectClass="COMMON_PRACTICE" inAbstract="false">Third, a controller may detect failure, as will be the case for unpredictable events such as a push or an unforeseen obstacle causing the character to trip.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">The transitions in Figs. 3 and 4 are labelled according to the type of controller deactivations which typically elicit the given transition patterns.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">We note that our framework is designed to work in interactive settings.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">As such, controllers typically start with slightly different initial conditions each time they are invoked, the user can interact with the character at any time, and generally there are no guarantees that the controller will reach the same end state each time it operates.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">As a result, the transition graph is dynamic in structure.</Sentence>
          
            Figure 3: Controllers and typical transitions for 3D figure
          
          
            Figure 4: Controllers and typical transitions for 2D figure
          
        
      
      
        <H1>4 Determining Pre-Conditions</H1>
        <Sentence aspectClass="NONE" inAbstract="false">For controllers associated with complex dynamic characters, determining the exact region of the state space and the general conditions that determine success or failure of the controller is in general a non-trivial matter.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">In this section, we address this problem via manual and automatic approaches.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">The manual approach allows designers to incorporate their knowledge within controllers, whereas the automatic approach is based on machine learning techniques.</Sentence>
        
          <H2>4.1 Manual Approach</H2>
          <Sentence aspectClass="COMMON_PRACTICE" inAbstract="false">For certain cases, suitable pre-conditions for specific controllers may be found in the biomechanics literature <CitSpan>[ 8 , 25 ]</CitSpan>.</Sentence> <Sentence aspectClass="COMMON_PRACTICE" inAbstract="false">For example Pai and Patton <CitSpan>[ 25 ]</CitSpan> present a comprehensive study of balance in the sagittal plane and identify the conditions under which a human can compensate for postural disturbances and maintain balance without stepping.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">For certain other cases, the pre-conditions are trivially defined by the desired motion itself.</Sentence> <Sentence aspectClass="COMMON_PRACTICE" inAbstract="false">Certain controllers function as intermediate stages between other controllers.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">If controller B is the intermediate step between A and C then the postconditions of A dictate the pre-conditions of B and similarly the pre-conditions of C define the post-conditions of B. Finally, in some cases the pre-conditions are computed by manual experimentation.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">For example a simple balance controller based on an inverted pendulum model <CitSpan>[ 12 ]</CitSpan> has intrinsic stability that can tolerate small disturbances.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">After the controller has been designed, repeated testing under disturbances of increasing magnitude can yield an approximation of the pre-conditions and the post-conditions.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">In any case, the designer of a controller presumably understands the way the controller operates, and thus is able to provide high level conditions on its success or failure.</Sentence> <Sentence aspectClass="COMMON_PRACTICE" inAbstract="false">For example, the designer of a walking controller knows if the controller can operate when the walking surface has minimal friction properties.</Sentence> <Sentence aspectClass="COMMON_PRACTICE" inAbstract="false">Also, human motion is shaped by notions such as comfort, and only the designer can take this into account.</Sentence> <Sentence aspectClass="COMMON_PRACTICE" inAbstract="false">For example, if a person is pushed while standing he/she might take a protective step because it may be more comfortable to do so instead of maintaining an inverted pendulum balancing strategy.</Sentence> <Sentence aspectClass="COMMON_PRACTICE" inAbstract="false">Similarly, the way people react to slipping and imbalance and the protective behaviors they employ are largely age dependent.</Sentence>
        
        
          <H2>4.2 Automatic, Learning Approach</H2>
          <Sentence aspectClass="NOVELTY" inAbstract="false">In this section, we introduce an automatic, machine learning approach to determining pre-conditions, which is based on systematically sampling the performance of controllers.</Sentence> <Sentence aspectClass="ADVANTAGE" inAbstract="false">Our method uses a machine learning algorithm attributed to Vapnik <CitSpan>[ 33 ]</CitSpan> known as Support Vector Machines (SVMs), which has recently attracted much attention, since in most cases the performance of SVMs matches or exceeds that of competing methods.</Sentence>
          
            <H3>4.2.1 Support vector machines (SVMs)</H3>
            <Sentence aspectClass="COMMON_PRACTICE" inAbstract="false">SVMs are a method for fitting functions to sets of labeled training data.</Sentence> <Sentence aspectClass="COMMON_PRACTICE" inAbstract="false">The functions can be general regression functions or they can be classification functions.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">In our application, we use simple classification functions with binary outputs which encode the success or failure of a controller.</Sentence> <Sentence aspectClass="COMMON_PRACTICE" inAbstract="false">Burges <CitSpan>[ 5 ]</CitSpan> provides an excellent tutorial on SVMs.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">Mathematically, we are given Ð observations, each consisting of an dimensional vector Ü 3⁄4 1⁄2 Ð and the associated “truth” Ý 3⁄4   1⁄2 1⁄2 provided by a trusted source.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">Here, Ý 1⁄2 labels a positive example—in our application, the observed success of a controller applied when the dynamic figure is in state Ü — while Ý   1⁄2 labels a negative example—the failure of the controller applied to state Ü .</Sentence> <Sentence aspectClass="NONE" inAbstract="false">The set of observations Ü Ý is called the training set.</Sentence> <Sentence aspectClass="COMMON_PRACTICE" inAbstract="false">The SVM is a machine whose task is to learn the mapping Ü Ý from a training set.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">The SVM is defined by functional mappings of the form Ü  ́ Ü « μ , where « are parameters.</Sentence> <Sentence aspectClass="COMMON_PRACTICE" inAbstract="false">A particular choice of « generates a “trained” SVM.</Sentence> <Sentence aspectClass="COMMON_PRACTICE" inAbstract="false">In a trained SVM, the sign of the decision function  ́ Ü μ represents the class assigned to a test data point Ü .</Sentence> <Sentence aspectClass="NONE" inAbstract="false">In our application, a properly trained SVM predicts if a controller will succeed (  ́ Ü μ 1⁄4 ) or fail (  ́ Ü μ 1⁄4 ) on a given state Ü of the dynamic character.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">How does one train an SVM?</Sentence> <Sentence aspectClass="NONE" inAbstract="false">In the simplest case of a linear SVM with separable training data, there exists a decision boundary separating positive from negative examples which takes the form of a “separating hyperplane” in .</Sentence> <Sentence aspectClass="NONE" inAbstract="false">The SVM training algorithm computes the separating hyperplane with the largest margin · ·   , where · (   ) is the shortest distance from the separating hyperplane to the closest positive (negative) example.</Sentence> <Sentence aspectClass="COMMON_PRACTICE" inAbstract="false">SVM training requires the solution of a quadratic programming optimization problem involving a Lagrange multiplier « for every datapoint in the training set.</Sentence> <Sentence aspectClass="COMMON_PRACTICE" inAbstract="false">Those datapoints in the solution with corresponding « 1⁄4 are called support vectors.</Sentence> <Sentence aspectClass="COMMON_PRACTICE" inAbstract="false">The support vectors are critical elements of the training set.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">They lie closest to the separating hyperplane.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">If other observations in the training set are moved (subject to certain restrictions) or removed and SVM training is repeated, the same separating hyperplane will result.</Sentence> <Sentence aspectClass="COMMON_PRACTICE" inAbstract="false">To use a trained SVM, we simply determine on which side of the decision boundary a given test data point Ü lies and assign the corresponding class label to that point.</Sentence> <Sentence aspectClass="ADVANTAGE" inAbstract="false">The linear SVM is easily generalized to nonseparable training data.</Sentence> <Sentence aspectClass="COMMON_PRACTICE" inAbstract="false">Furthermore, it is straightforward to generalize the theory to encompass nonlinear SVMs for which the decision boundaries are no longer hyperplanes (i.e., the decision function are no longer linear functions of the data).</Sentence> <Sentence aspectClass="COMMON_PRACTICE" inAbstract="false">The trick, in principle, is to map the data to some higher (possibly infinite) dimensional space in which the linear theory can be applied.</Sentence> <Sentence aspectClass="ADVANTAGE" inAbstract="false">This is easily done by introducing kernel functions Ã  ́ Ü Ü μ , such as the polynomial kernel Ã (RBF)  ́ Ü Ý kernel μ  ́ Ü Ã ¡  ́ Ü Ý · Ý μ 1⁄2μ Ô , ÜÔ ́ or the   Ü Gaussian   Ý 3⁄4 3⁄4 or 3⁄4 μ radial .</Sentence> <Sentence aspectClass="NONE" inAbstract="false">For the basis mathematfunction ical details, we refer the reader to <CitSpan>[ 5 ]</CitSpan>.</Sentence>
          
          
            <H3>4.2.2 Applying SVMs</H3>
            <Sentence aspectClass="NONE" inAbstract="false">To apply the SVM technique to the problem of determining controller pre-conditions, we train a nonlinear SVM classifier to predict the success or failure of a controller for an arbitrary starting state.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">Thus, the trained SVM demarcates the boundary of regions in the figure’s state space wherein the controller can successfully do its job.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">Training sets comprising examples Ü Ý are generated by repeatedly starting the dynamic figure at a stochasticallygenerated initial state Ü , numerically simulating the dynamics of the figure under the influence of the controller in question, and setting Ý ·1⁄2 if the controller succeeds or Ý   1⁄2 if it fails.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">The distribution of the stochastically-generated initial states is of some importance.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">The sample points should ideally be located close to the boundaries which demarcate the acceptable precondition region of state-space.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">However, these boundaries are in fact the unknowns we wish to determine and thus we must resort to a more uniform sampling strategy.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">Unfortunately, the high dimensionality of the state-space precludes regular sampling.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">We thus adopt the following stochastic process to generate a suitable distribution of initial states: First, a nominal initial state is chosen, based upon the designer’s knowledge of the controller.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">A shortduration simulation (typically 0.3s) is then carried out from this initial state while a randomized perturbation process is executed.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">This currently consists of applying an external force of random (but bounded) magnitude and random direction to the center-of-mass of the pelvis.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">Simultaneously, the character’s joints are perturbed in a stochastic fashion by setting randomized offset target angles for the joints and using the character’s PD joint controllers to drive the joints towards these perturbed positions.</Sentence> <Sentence aspectClass="ADVANTAGE" inAbstract="false">While the perturbation strategy is admittedly ad-hoc, we have found it to be effective in sampling the pre-condition space, as is validated by the online use of the learned pre-condition models.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">We employ T. Joachims’ SVM Ð Ø software which is available on the WWW <CitSpan>[ 21 ]</CitSpan>.</Sentence> <Sentence aspectClass="ADVANTAGE" inAbstract="false">The software can accommodate large training sets comprising tens of thousands of observations and it efficiently handles many thousands of support vectors.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">It includes standard kernel functions and permits the definition of new ones.</Sentence> <Sentence aspectClass="ADVANTAGE" inAbstract="false">It incorporates a fast training algorithm which proceeds by solving a sequence of optimization problems lower-bounding the solution using a form of local search.</Sentence> <Sentence aspectClass="ADVANTAGE" inAbstract="false">It includes two efficient estimation methods for error rate and precision/recall.</Sentence> <Sentence aspectClass="DISADVANTAGE_ADVANTAGE" inAbstract="false">The SVM training phase can take hours in our application, but this is done off-line.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">For example, on a 733 MHz PIII computer, the SVM training time for a training set of 8,013 observations is 2,789 seconds using the polynomial kernel, 2,109 seconds using the linear kernel, and 211 seconds using the radial kernel.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">For a training set of 11,020 observations, the training time is 8,676 seconds using the polynomial kernel, 3,593 seconds using the linear kernel, and 486 seconds using the radial kernel.</Sentence> <Sentence aspectClass="ADVANTAGE" inAbstract="false">Once trained, the SVM classifier can provide answers on-line in milliseconds.</Sentence>
          
          
            <H3>4.2.3 Pre-condition learning results</H3>
            <Sentence aspectClass="NONE" inAbstract="false">Through systematic experimentation, we have evaluated the performance of our automatic, SVM-based algorithm for learning con-
            Controller Training set size Test set size NN SVM StepToStand 8,999 9,110 80.97% 87.29% LyingOnBellyToKneel 4,200 4,223 93.27% 94.46% LyingOnBackToKneel 2,234 1,879 100.0% 100.0% BendToStand 6,926 14,272 98.05% 99.77% StandInPlace 17,317 20,393 83.63% 87.67% Walk 11,020 8,658 92.78% 97.73% StandToSit 1,100 1,286 64.15% 69.60% StandToStep 16,999 17,870 72.12% 79.18% KneelToStand 6,000 11,998 79.45% 85.06% Table 1 : Comparison between learned SVM and NN preconditions.</Sentence>
            <Sentence aspectClass="NONE" inAbstract="false">troller pre-conditions.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">We compared the performance of the SVM algorithm to that of a nearest neighbor (NN) classifier <CitSpan>[ 9 ]</CitSpan>.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">Given a training set, the nearest neighbor classifier returns for an arbitrary state Ü the same succeed/fail label as the label for that observation in the training set that is closest to Ü .</Sentence> <Sentence aspectClass="ADVANTAGE" inAbstract="false">NN classifiers should perform particularly well in cases where the feasible area in the state space is highly fragmented and localized.</Sentence> <Sentence aspectClass="ADVANTAGE_DISADVANTAGE" inAbstract="false">Note that the NN method requires zero training time, but that it provides an answer in Ç  ́ Ò μ time where Ò is size of the training set.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">Table 1 summarizes the percentage success rates (rightmost columns) of learned pre-conditions for a variety of controllers that we use later in our demonstrations.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">To compute accuracy rates, we trained the SVM and NN pre-condition learning algorithms using randomly sampled observations collected from each of the controllers.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">Then we generated test sets of novel observations and compared their true success/fail status against that predicted by the trained NN and SVM pre-conditions to obtain the accuracy percentages listed in the rightmost two columns of the table.</Sentence> <Sentence aspectClass="ADVANTAGE" inAbstract="false">The results show that the SVM algorithm consistently outperforms the NN classifier.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">For the results shown in the table, the SVM algorithm employed polynomial kernel functions.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">We ran a similar set of experiments using Gaussian RBF kernel functions, but the accuracies were consistently lower than those obtained with polynomial kernel functions.</Sentence>
          
        
      
      
        <H1>5 Implementation</H1>
        <Sentence aspectClass="NONE" inAbstract="false">Our control composition framework is implemented within DANCE , a portable, extensible object-oriented modeling and animation system <CitSpan>[ 24 ]</CitSpan>.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">2 DANCE provides a platform that researchers can use to implement animation and control techniques with minimal design and implementation overhead.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">The core of the system supports four base classes, Systems, Simulators, Actuators and Geometries which are loadable as plug-ins in accordance with simple APIs.</Sentence> <Sentence aspectClass="COMMON_PRACTICE" inAbstract="false">Articulated objects are a System subclass that support skeleton hierarchies.</Sentence> <Sentence aspectClass="COMMON_PRACTICE" inAbstract="false">They have kinematic properties and, usually, fully dynamic physical properties as well.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">Our virtual actors, which will be described shortly, are dynamic articulated objects implemented as Systems within DANCE .</Sentence> <Sentence aspectClass="COMMON_PRACTICE" inAbstract="false">An actuator is a generic concept that includes anything that can exert forces or, in general, interact in any way with systems or other actuators.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">For example, gravity, the ground, the collision mechanism, the supervisor controller and individual controllers are implemented as actuators.</Sentence> <Sentence aspectClass="ADVANTAGE" inAbstract="false">DANCE places no restrictions on the complexity of the controllers.</Sentence> <Sentence aspectClass="COMMON_PRACTICE" inAbstract="false">Simulators compute the equations of motion of all the dynamic characters and other systems in DANCE .</Sentence> <Sentence aspectClass="COMMON_PRACTICE" inAbstract="false">DANCE offers built in support for SD/FAST, a commercial system which produces optimized simulation code <CitSpan>[ 18 ]</CitSpan>.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">However, any simulator that follows a simple
        2 DANCE is freely available for non-commercial use via the URL: www.dgp.toronto.edu/software/dance.htm</Sentence>
        
          
        
        Joint Rotational DOFs Rotational DOFs 3D skeleton model 2D terminator model Head 1 1 Neck 3 1 Shoulder 2 1 Elbow 2 1 Wrist 2 Waist 3 1 Hip 3 1 Knee 1 1 Ankle 2 1
        
          Figure 5: Dynamic models and their degrees of freedom (DOFs).
        
        <Sentence aspectClass="NONE" inAbstract="false">API can be dynamically loaded into the system.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">Our simulators are automatically produced by SD/FAST from description files.</Sentence> <Sentence aspectClass="COMMON_PRACTICE" inAbstract="false">They use Kane’s method for computing articulated dynamics and a fourth order explicit Runge-Kutta time integrator for numerically simulating the motions.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">Actuators and simulators are implemented as DANCE plug-ins.</Sentence> <Sentence aspectClass="ADVANTAGE" inAbstract="false">This allows the user to dynamically load controllers and simulators at runtime.</Sentence> <Sentence aspectClass="ADVANTAGE" inAbstract="false">In addition, researchers can exchange, simulators, and controllers in the form of dynamically linked pieces of code.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">Object collisions (including self collisions) are handled by the Collision actuator.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">This actuator works on pairs of objects.</Sentence> <Sentence aspectClass="ADVANTAGE" inAbstract="false">The DANCE API allows it to work with objects that have different simulators.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">Collision detection is based on a library that uses oriented bounding boxes <CitSpan>[ 13 ]</CitSpan>.</Sentence> <Sentence aspectClass="COMMON_PRACTICE" inAbstract="false">Collision resolution uses a penalty method that corrects geometry interpenetration using spring-and-damper forces.</Sentence> <Sentence aspectClass="DISADVANTAGE_ADVANTAGE" inAbstract="false">As with all penalty methods, it can make the system stiff, but it has performed well in our experiments to date.</Sentence>
        
          <H2>5.1 Virtual Stuntman</H2>
          
            <H3>5.1.1 Dynamic model</H3>
             <Sentence aspectClass="NONE" inAbstract="false">Fig. 5 depicts our 2D and 3D articulated character models.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">The red arrows indicate the joint positions and axes of rotational degrees of freedom (DOFs) which are also presented in the table.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">The 3D skeleton model has 37 DOFs, six of which correspond to the global translation and rotation parameters.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">The table in Fig. 5 lists the DOFs for the skeleton and a 2D “terminator” model.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">The dynamic properties of both models, such as mass and moments of inertia, are taken from the biomechanics literature and correspond to a fullyfleshed adult male.</Sentence> <Sentence aspectClass="COMMON_PRACTICE" inAbstract="false">The models are equipped with natural limits both on the motion of the joints and the strength of their muscles.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">However, DANCE has no built in muscle model and does not enforce the limits automatically.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">Users can implement the model they prefer and include code to enforce the limits of the model.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">Our plug-in control scheme uses rotational spring-and-damper forces for control and enforces the limits on the joints with exponential springs.</Sentence>
          
          
            <H3>5.1.2 Pose and continuous control</H3>
            <Sentence aspectClass="COMMON_PRACTICE" inAbstract="false">Most of the controllers for our virtual stuntperson are based on pose control, which has often been used both for articulated objects <CitSpan>[ 31 ]</CitSpan> and soft objects <CitSpan>[ 11 ]</CitSpan>.</Sentence> <Sentence aspectClass="COMMON_PRACTICE" inAbstract="false">Pose control is based on cyclic or acyclic finite state machines with time transitions between the states.</Sentence> <Sentence aspectClass="COMMON_PRACTICE" inAbstract="false">Each state of the controller can be static or depend on feedback parameters.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">For some of our controllers, we use continuous control, in the sense that the control parameters are tightly coupled with some of the feedback sensors.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">The balance controllers are an example of this.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">We designed several controllers based in part on experimental studies of how humans detect loss of balance <CitSpan>[ 25 ]</CitSpan> and analysis of protective and falling behaviors <CitSpan>[ 8 ]</CitSpan>.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">The resulting parameterized controllers have been enhanced with appropriate pre-conditions, post-conditions, and expected performance and have been integrated using an arbitration-based supervising controller.</Sentence>
          
          
            <H3>5.1.3 Sensors</H3>
            <Sentence aspectClass="COMMON_PRACTICE" inAbstract="false">Each controller has full access to the internal data structures of DANCE including all the information associated with any character or object in the system.</Sentence> <Sentence aspectClass="ADVANTAGE" inAbstract="false">This allows the controllers to define arbitrary sensors that keep track of necessary information such as state parameters for feedback loops and the state of the environment.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">For efficiency, the supervisor controller calculates a number of common sensor values that are available to all the controllers.</Sentence>
          
          
            <H3>5.1.4 Command interface</H3>
            <Sentence aspectClass="COMMON_PRACTICE" inAbstract="false">Many controller transitions in the control framework happen autonomously, such as taking a protective step in response to losing balance.</Sentence> <Sentence aspectClass="COMMON_PRACTICE" inAbstract="false">However, other actions are initiated in a voluntary fashion.</Sentence> <Sentence aspectClass="COMMON_PRACTICE" inAbstract="false">For example, a standing character can do any of <CitSpan>(1)</CitSpan> remain standing using the balance controller, <CitSpan>(2)</CitSpan> sit-down, <CitSpan>(3)</CitSpan> walk, and <CitSpan>(4)</CitSpan> dive.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">Currently, the user directs these voluntary motions by interactively entering command strings to the supervisor controller which, in turn, directly increases the suitability score of the designated controller and forces the arbitration process to be invoked to select a new active controller.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">The control of voluntary motions could equivalently be delegated to a high-level planner, although this kind of planning is beyond the scope of our work at present.</Sentence>
          
        
      
      
        <H1>6 Results</H1>
        <Sentence aspectClass="NONE" inAbstract="false">At the heart of our prototype system is a composite controller that is capable of handling a large number of everyday tasks, such as walking, balancing, bending, falling, and sitting.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">In addition, we present brief descriptions of the controllers involved in producing several stunt actions.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">While the given controller descriptions are for the 3D character, the equivalent 2D controllers are very similar.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">Finally, we discuss motion sequences generated using these families of controllers 3 .</Sentence>
        3 See www.dgp.toronto.edu/ pfal/animations.html for the associated animations.
        
          <H2>6.1 Everyday Actions</H2>
          <Sentence aspectClass="NONE" inAbstract="false">We began our implementation with the simple tasks of standing, recovering balance when pushed, and falling.</Sentence> <Sentence aspectClass="COMMON_PRACTICE" inAbstract="false">An autonomous human agent should be able to balance, standing naturally in place.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">Should loss of balance occur, the character ought to react naturally either with a restoring motion or with a protective falling behavior depending on which action is appropriate in each case.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">Affording a dynamic articulated figure with natural reactions to loss of balance or impending falls is an essential step towards believable autonomous characters.</Sentence>
          
            <H3>6.1.1 Balancing</H3>
            <Sentence aspectClass="NONE" inAbstract="false">A balance controller is responsible for maintaining a natural standing posture.</Sentence> <Sentence aspectClass="COMMON_PRACTICE" inAbstract="false">This controller is based on an inverted pendulum model <CitSpan>[ 12 ]</CitSpan>, using the ankles to control the body sway.</Sentence> <Sentence aspectClass="DISADVANTAGE_ADVANTAGE" inAbstract="false">Despite the fact that the body of the character is not as rigid as the inverted pendulum hypothesis suggests, the approximation works well in practice.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">As an example of the type of manually defined pre-conditions and post-conditions used for this controller and others, these details are given in Appendix A for the balance controller.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">An animated character should attempt to maintain balance in response to external disturbances by shifting its weight, taking a step or bending at the waist.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">If the character cannot maintain balance, it must then resort to a falling behavior.</Sentence>
          
          
            <H3>6.1.2 Falling</H3>
            <Sentence aspectClass="NONE" inAbstract="false">The manner in which people fall depends on a number of factors such as their physique, their age and their training.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">For example, the work in <CitSpan>[ 19 ]</CitSpan> shows that, during a fall, the elderly are more likely to impact their hip first as compared to younger adults falling under the same conditions.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">Our fall controller is designed with the average adult in mind.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">Its main action is thus to absorb the shock of the impact using mostly the hands.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">The pre-conditions of the fall controller are defined in accordance with those of the balance controller.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">Situations that are beyond the capabilities of the latter should be handled by the fall controller.</Sentence> <Sentence aspectClass="ADVANTAGE" inAbstract="false">Our implementation of the fall controller can handle falls in any direction, responding in different ways to falls in different directions.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">Fig. 6 depicts frames from falls in a variety of directions.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">The second frame in Fig. 1 also demonstrates the action of the fall controller within a fall-and-recover sequence.</Sentence>
          
          
            <H3>6.1.3 Sitting</H3>
            <Sentence aspectClass="NONE" inAbstract="false">Sitting down in a chair and rising from a chair are common everyday tasks.</Sentence> <Sentence aspectClass="ADVANTAGE" inAbstract="false">We have implemented a controller that can do both depending on the instructions of the animator.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">Apart from the command string supplied by the user, the pre-conditions are either a balanced upright posture or a balanced sitting posture.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">The postconditions are similarly defined.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">The resulting action is illustrated in Fig. 7 .</Sentence>
          
          
            <H3>6.1.4 Rising from a supine position</H3>
            <Sentence aspectClass="NONE" inAbstract="false">Getting up off the ground is a surprisingly difficult motion to simulate.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">It involves rapid changes of the contact points and significant shifting of the figure’s weight.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">In addition, the frictional properties of the ground model can influence the motion.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">The pre-conditions for this controller are straightforward.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">The character must be lying with its back flat on the ground, within some tolerance.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">The post-conditions are that the character should be on its feet with its center of mass within the support polygon.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">Then it would be up to another controller to take over and bring the character from a crouching position to a standing one.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">A snapshot of a resulting motion is shown in Fig. 8 .</Sentence>
            
              
              Figure 6: Falling in different directions
            
          
          
            <H3>6.1.5 Rolling over</H3>
            <Sentence aspectClass="NONE" inAbstract="false">When lying on their back, some people may choose to roll-over to a prone position before attempting to stand.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">We have implemented a roll-over controller that can emulate this action.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">The fourth frame in Fig. 1 demonstrates the action of the roll-over controller.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">The pre-conditions of the roll-over controller require a supine posture, and no movement of the center of mass.</Sentence> <Sentence aspectClass="ADVANTAGE" inAbstract="false">The postconditions of the roll controller are fairly simple and they include any prone position for which the character is extended and fairly straight; i.e., no crossing of legs or arms, etc.</Sentence>
          
          
            <H3>6.1.6 Rising from a prone position</H3>
            <Sentence aspectClass="NONE" inAbstract="false">Frames 5–9 in Fig. 1 demonstrate the action of a controller that enables the virtual stuntperson to rise from the prone position.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">When lying face-down, the pre-conditions can be fairly relaxed.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">Our controller assumes that is has the time to change the state of the character to one from which it knows how to rise.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">As long as the figure is not lying on its arms and the ground is relatively flat it will attempt to get up.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">The post-conditions are chosen such that they satisfy the pre-conditions of the balance controller.</Sentence>
          
        
        
          <H2>6.2 Stunts</H2>
          <Sentence aspectClass="NONE" inAbstract="false">Apart from everyday actions, we want our dynamic character to be able to do a variety of other voluntary actions dictated by the animator.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">Such actions can potentially include vigorous and/or physically dangerous actions.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">It is our hope that if a large number of researchers contribute controllers the character can eventually be used as a virtual stuntperson.</Sentence>
          
            <H3>6.2.1 Kip move</H3>
            <Sentence aspectClass="NONE" inAbstract="false">The kip is an athletic motion often seen in martial arts films and is depicted in Fig. 9 .</Sentence> <Sentence aspectClass="NONE" inAbstract="false">The controller is based on a pose controller whose pre-conditions include a variation of supine positions.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">As before, the first part of the controller makes sure that the character assumes a position suitable for performing the kip.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">The larger part of the motion is ballistic, which focuses the control mainly at the kick off and landing phases.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">The last part of the controller applies continuous control to bring the stuntman to an erect position from which the balance controller can take over.</Sentence>
          
          
            <H3>6.2.2 Plunge and roll</H3>
             <Sentence aspectClass="NONE" inAbstract="false">Fig. 10 shows the stuntman performing a suicidal dive down stairs.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">The character can be instructed to lunge forward and upward at a takeoff angle controlled by the user.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">When the hands contact the ground a front-roll is attempted.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">The pre-conditions of this controller are defined be an upright position and little movement of the center of mass.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">We have also experimented with a multiple character scenario, with one character tackling another, Fig. 11 .</Sentence> <Sentence aspectClass="NONE" inAbstract="false">While the timing of the tackle is scripted, it illustrates the capability of the system to cope with a pair of interacting characters, each equipped with its own supervisory controller.</Sentence>
            
              
              Figure 11: Two interacting virtual characters.
            
          
        
        
          <H2>6.3 Animation Sequences</H2>
          <Sentence aspectClass="NONE" inAbstract="false">We have produced two relatively long animation sequences that demonstrate the potential of the our framework.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">The sequence for the 3D skeleton model presented in Fig. 1 involves controllers whose pre-conditions are provided analytically by the designer.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">Such conditions tend to define square regions within the space defined by the parameters involved.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">Despite their simple form, such pre-conditions can generally work well as is demonstrated by the intricacy of the animation produced.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">We expect to investigate the application of SVM-learned pre-conditions to the 3D model in the future.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">A second animation sequence with the 2D terminator model (see Fig. 12 ) makes use of a set of controllers having a mix of analytic and learned pre-conditions.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">The sequence of controllers that generated the animation was: balance sit lean-forward rise balance walk step-to-stand balance dive default kneel kneel to stand balance step-forward step-tostand balance step-back step-to-stand balance fall default.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">The analytical pre-conditions prune large parts of the state space and the svm-classifier provides a more accurate success/failure prediction within the remaining region.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">During the animation sequence, the svm-classifier correctly refined the analytical answer in several cases.</Sentence>
        
        
          <H2>6.4 Performance Issues</H2>
          <Sentence aspectClass="NONE" inAbstract="false">Most of the computational burden in our approach lies in the numerical simulation of the equations of motion.</Sentence> <Sentence aspectClass="ADVANTAGE" inAbstract="false">The computations associated with the controllers and our composition framework are negligible in comparison.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">In general, the 2D model simulates in real time, while the 3D model runs between 5 and 9 times slower than real time on a 733 MHz Pentium III system.</Sentence>
          
            
            Figure 7: Sitting and rising from a chair
          
          
            
            Figure 8: Rising from a supine position on the ground and balancing erect in gravity.
          
          
            
            Figure 9: Kip move: A more vigorous way of getting up from the supine position as in the first frame of Fig. 8 .
          
          
            
            Figure 10: Ouch!
          
        
      
      
        <H1>7 Conclusion</H1>
        <Sentence aspectClass="COMMON_PRACTICE" inAbstract="false">The challenges of physics-based controller design plus the technical obstacles that researchers face when attempting to share their algorithms has hindered progress in the important area of physicsbased character animation.</Sentence> <Sentence aspectClass="NOVELTY" inAbstract="false">This paper has presented a methodology for ameliorating the problem with a framework which facilitates the exchange and composition of controllers.</Sentence> <Sentence aspectClass="ADVANTAGE" inAbstract="false">Our framework has been implemented within a freely available system for modeling and animating articulated characters.</Sentence> <Sentence aspectClass="ADVANTAGE" inAbstract="false">To our knowledge, our system is the first to demonstrate a dynamic anthoropomorphic character with controlled reactions to disturbances or falls in any direction, as well as the ability to pick itself up off the ground in several ways, among other controlled motions.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">We hope that our system will foster collective efforts among numerous practitioners that will eventually result in complex composite controllers capable of synthesizing a full spectrum of human-like motor behaviors.</Sentence> <Sentence aspectClass="LIMITATION" inAbstract="false">Given the enormous challenge of building controllers capable of large repertoires of dynamic human-like motion, it is inevitable that the work presented in this paper is incomplete in many ways.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">Published control methods for 3D walking, running, and stair climbing make obvious candidates for integration into our system.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">Coping with variable terrain and dynamic environments are dimensions of added complexity that should provide work for years to come.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">Automatic parameterization of controllers to variations in character dimensions and mass is a necessary step for having solutions adaptable to a variety of characters.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">Deriving controllers from motion-capture data is an exciting but difficult prospect, although some progress is already being made in this area.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">Other methods of “teaching” skills to a dynamic character also warrant investigation.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">Finally, intelligently integrating controllers which affect only subsets of DOFs needs to be addressed in order to allow for the parallel execution of controllers.</Sentence>
      
      
        <H1>Acknowledgements</H1>
        <Sentence aspectClass="NONE" inAbstract="false">We wish to thank Joe Laszlo for his help with the video editing equipment and for useful discussions.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">We would also like to thank Symbolic Dynamics Inc.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">for allowings us to distribute the equations of motion of the 3D human model.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">This work was supported by grants from NSERC and CITO.</Sentence>
      
      
        <H1>A Balance controller</H1>
        <Sentence aspectClass="COMMON_PRACTICE" inAbstract="false">The articulated body must be in a balanced upright position, the velocity and acceleration of the center of mass should not exceed certain threshold values as explained in <CitSpan>[ 25 ]</CitSpan>, and both feet must maintain contact with the ground at all times.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">The controller can tolerate small perturbations of the posture and the velocity/acceleration of the center of mass by stiffening the ankle joints.</Sentence> <Sentence aspectClass="COMMON_PRACTICE" inAbstract="false">For larger accelerations of the center of mass, the controller actively actuates the ankle joint to reduce the acceleration of the center of mass.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">The post-conditions are similar to the pre-conditions.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">In mathematical form using the notation defined in Section 3:</Sentence>
        
          
          Figure 12: A still image from the terminator sequence.
        
        <Sentence aspectClass="NONE" inAbstract="false">The dynamic terminator model has been knocked backward by the force of a collision to the head by the red ball.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">The terminator maintains balance by taking a protective step.</Sentence>
        <Sentence aspectClass="NONE" inAbstract="false">: Acceleration: 1⁄4 1⁄2 m sec 3⁄4 .</Sentence> <Sentence aspectClass="NONE" inAbstract="false">Velocity: Balance: Posture:  ́1⁄2 projection Ò 1⁄4 μ ¿ È m  ́ Õ sec.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">μ 3⁄4Ë   .</Sentence> <Sentence aspectClass="NONE" inAbstract="false">Õ 1⁄4 1⁄4 1⁄2 rad, where  ́ thigh knee waist μ and Ò is a normalization parameter.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">Acceleration: : 1⁄4 1⁄41⁄2 m sec 3⁄4 .</Sentence> <Sentence aspectClass="NONE" inAbstract="false">Balance: Posture: Velocity:  ́1⁄2 projection Ò 1⁄4 μ 1⁄4 È m  ́ Õ μ sec.</Sentence> 3⁄4Ë   . <Sentence aspectClass="NONE" inAbstract="false">Õ 1⁄4 1⁄4 1⁄2 rad, where  ́ thigh knee waist μ and Ò is a normalization parameter.</Sentence>
      
      
        <H1>References</H1>
        
          [1] Ronald C. Arkin. Behavioral Robotics. MIT Press, 1998.
          [2] W. W. Armstrong and M. Green. The dynamics of articulated rigid bodies for purposes of animation. Proceedings of Graphics Interface ’85, pages 407–415, 1985.
          [3] N. Badler, C. Phillips, and B. Webber. Simulating Humans: Computer Graphics, Animation, and Control. Oxford University Press, 1993.
          [4] N. I. Badler, B. Barsky, and D. Zeltzer. Making Them Move. Morgan Kaufmann Publishers Inc., 1991.
          [5] C. Burges. A tutorial on support vector machines for pattern recognition. Data Mining and Knowledge Discovery, 2(2):955–974, 1998.
          [6] R. R Burridge, A. A. Rizzi, and D. E Koditschek. Sequential composition of dynamically dexterous robot behaviors. The International Journal of Robotics Research, 18(6):534–555, June 1999.
          [7] Tolga Capin, Igor Pandzic, Nadia Magnenat Thalmann, and Daniel Thalmann. Avatars in Networked Virtual Environments. John Wiley &amp; Sons, 1999.
          [8] M. C. Do, Y. Breniere, and P. Brenguier. A biomechanical study of balance recovery during the fall forward. Journal of Biomechanics, 15(12):933–939, 1982.
          [9] R. O. Duda and P. E Hart. Pattern Classification and Scene Analysis. Wiley, 1973.
          [10] Petros Faloutsos. Composable Controller for Physics-based Character Animation. PhD thesis, Univeristy of Toronto, DCS, Toronto,Canada, 2001. To be awarded.
          [11] Petros Faloutsos, Michiel van de Panne, and Demetri Terzopoulos. Dynamic free-form deformations for animation synthesis. IEEE Transactions on Visualization and Computer Graphics, 3(3):201–214, 1997.
          [12] R. C Fitzpatrick, J. L. Taylor, and D. I. McCloskey. Ankle stiffness of standing humans in response to imperceptible perturbation: reflex and task-dependent components. Journal of Physiology, 454:533–547, 1992.
          [13] Stefan Gottschalk, Ming Lin, and Dinesh Manocha. OBB-Tree: A hierarchical structure for rapid interference detection. In Computer Graphics (SIGGRAPH 96 Proceedings), pages 171–180, 1996.
          [14] R. Grzeszczuk and D. Terzopoulos. Automated learning of muscle-based locomotion through control abstraction. Proceedings of ACM SIGGRAPH: Computer Graphics, pages 63–70, August 1995.
          [15] R. Grzeszczuk, D. Terzopoulos, and G. Hinton. Neuroanimator: Fast neural network emulation and control of physics-based models. Proceedings of ACM SIGGRAPH: Computer Graphics, pages 9–20, July 1998.
          [16] J. K. Hodgins, W. L. Wooten, D. C. Brogan, and J. F. O’Brien. Animating human athletics. Proceedings of SIGGRAPH 95, ACM Computer Graphics, pages 71– 78, 1995.
          [17] Jessica K. Hodgins and Nancy S. Pollard. Adapting simulated behaviors for new characters. Proceedings of SIGGRAPH 97, pages 153–162, August 1997.
          [18] Michael G. Hollars, Dan E. Rosenthal, and Michael A. Sherman. Sd/fast. Symbolic Dynamics, Inc., 1991.
          [19] E. T Hsiao and S. N Robinovitch. Common protective movements govern unexpected falls from standing height. Journal of biomechanics, 31:1–9, 1998.
          [20] Boston Dynamics Inc. The digital biomechanics laboratory. www.bdi.com, 1998.
          [21] T. Joachims. Making large-scale svm learning practical. advances in kernel methods. In B. Schölhopf, C. Burges, and A. Smola, editors, Support Vector Learning. MIT-Press, 1999. http://www-ai.cs.uni dortmund.de/DOKUMENTE/joachims 99a.pdf.
          [22] Joseph F. Laszlo, Michiel van de Panne, and Eugene Fiume. Limit cycle control and its application to the animation of balancing and walking. Proceedings of SIGGRAPH 96, pages 155–162, August 1996.
          [23] Honda Motor Co. Ltd. www.honda.co.jp/english/technology/robot/.
          [24] Victor Ng and Petros Faloutsos. Dance: Dynamic animation and control environment. Software system, www.dgp.toronto.edu/DGP/DGPSoftware.html.
          [25] Yi-Chung Pai and James Patton. Center of mass velocity-position predictions for balance control. Journal of biomechanics, 30(4):347–354, 1997.
          [26] Marcus G. Pandy and Frank C. Anderson. Three-dimensional computer simulation of jumping and walking using the same model. In Proceedings of the VIIth International Symposium on Computer Simulation in Biomechanics, August 1999.
          [27] Marcus G. Pandy, Felix E. Zajac, Eunsup Sim, and William S. Levine. An optimal control model for maximum-height human jumping. Journal of Biomechanics, 23(12):1185–1198, 1990.
          [28] M. H. Raibert. Legged Robots that Balance. MIT Press, 1986.
          [29] Cecile Smeesters, Wilson C. Hayes, and Thomas A. McMahon. Determining fall direction and impact location for various disturbances and gait speeds using the articulated total body model. In Proceedings of the VIIth International Symposium on Computer Simulation in Biomechanics, August 1999.
          [30] Xiaoyuan Tu and Demetri Terzopoulos. Artificial fishes: Physics, locomotion, perception, behavior. Proceedings of SIGGRAPH 94, pages 43–50, 1994.
          [31] M. van de Panne. Parameterized gait synthesis. IEEE Computer Graphics and Applications, pages 40–49, March 1996.
          [32] Michiel van de Panne, Eugene Fiume, and Zvonko Vranesic. Reusable motion synthesis using state-space controllers. Computer Graphics (SIGGRAPH 90 Proceedings), 24(4):225–234, August 1990. ISBN 0-201-50933-4. Held in Dallas, Texas.
          [33] V. Vapnik. Estimation of Dependecies Based on Empirical Data (in Russian). Nauka, Moscow, 1979. English translation Springer Verlag, New York, 1982.
          [34] Jane Wilhelms and Brian A. Barsky. Using dynamic analysis to animate articulated bodies such as humans and robots. In Graphics Interface ’85, pages 97–104, May 1985.
          [35] Wayne Wooten. Simulation of Leaping, Tumbling, Landing, and Balancing Humans. PhD thesis, Georgia Institute of Technology, March 1998.
        
      
    
  

</Document>
