<?xml version="1.0" encoding="UTF-8" standalone="no"?>
<Document xmlns:gate="http://www.gate.ac.uk" name="A11_M01_Composable_Controllers_for_Physics-Based_Character_Animation_SUMMARY_v1.xml">


  
    7eeaedc9f2ec1da80fc050225b3e2c46b86575c35a015ea71f86fa9254b15d34
    3vt5
    http://dx.doi.org/10.1145/383259.383287
  
  
    
      
        <Title>Composable Controllers for Physics-Based Character Animation</Title>
      
      
        
          Petros Faloutsos 1⁄2 Michiel van de Panne 3⁄4 1⁄2 Demetri Terzopoulos
          1
        
      
      University of Toronto, Department of Computer Science 3⁄4 Motion Playground, Inc. New York University, Courant Institute, Computer Science Department
      
        
        
        Figure 1: A dynamic “virtual stuntman” falls to the ground, rolls over, and rises to an erect position, balancing in gravity.
      
      <Abstract>
<Sentence inAbstract="true">An ambitious goal in the area of physics-based computer animation is the creation of virtual actors that autonomously synthesize realistic human motions and possess a broad repertoire of lifelike motor skills.</Sentence> <Sentence inAbstract="true">To this end, the control of dynamic, anthropomorphic figures subject to gravity and contact forces remains a difficult open problem.</Sentence> <Sentence inAbstract="true">We propose a framework for composing controllers in order to enhance the motor abilities of such figures.</Sentence> <Sentence inAbstract="true">A key contribution of our composition framework is an explicit model of the “pre-conditions” under which motor controllers are expected to function properly.</Sentence> <Sentence inAbstract="true">We demonstrate controller composition with pre-conditions determined not only manually, but also automatically based on Support Vector Machine (SVM) learning theory.</Sentence> <Sentence inAbstract="true">We evaluate our composition framework using a family of controllers capable of synthesizing basic actions such as balance, protective stepping when balance is disturbed, protective arm reactions when falling, and multiple ways of standing up after a fall.</Sentence> <Sentence inAbstract="true">We furthermore demonstrate these basic controllers working in conjunction with more dynamic motor skills within a prototype virtual stuntperson.</Sentence> <Sentence inAbstract="true">Our composition framework promises to enable the community of physics-based animation practitioners to easily exchange motor controllers and integrate them into dynamic characters.</Sentence>
</Abstract>
	Keywords: Computer Animation, Character Animation, PhysicsBased Animation Control, Physics-Based Modeling CR Categories: I.3.7 [Computer Graphics]: Three-Dimensional Graphics and Realism—Animation; I.6.8 [Simulation and Modeling]: Types of Simulation—Animation  
    
    
      0 To appear in the Proceedings of SIGGRAPH 2001 (Los Angeles, CA, August 12–17, 2001). In Computer Graphics Proceedings, Annual Conference Series, 2001, ACM SIGGRAPH, in press.
      
        <H1>1 Introduction</H1>
      
      <Sentence inAbstract="false" summaryRelevanceScore="1.67">Despite the considerable history of progress in animating virtual humans <CitSpan>[ 3 , 7 ]</CitSpan>, physics-based animated characters with a large repertoire of motor skills have so far been elusive.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="1.67">This may seem surprising in view of the recent successes in implementing a slew of specialist controllers capable of realistically synthesizing the complex dynamics of running, diving, and various gymnastic maneuvers <CitSpan>[ 16 ]</CitSpan>.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.33">While a divide-and-conquer strategy is clearly prudent in coping with the enormous variety of controlled motions that humans and other animals may perform, little effort has been directed at how the resulting control solutions may be integrated to yield composite controllers with significantly broader functionalities.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="1.67">For example, if researcher A creates a walking controller for a dynamic character while researcher B creates a running controller for the same articulated model, it would be beneficial if they could share their controllers (perhaps through an e-mail exchange) and easily create a composite controller enabling the character to both walk and run.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.00">This is a difficult problem, but its resolution would help pave the way towards controller libraries for dynamic animation which communities of practitioners could utilize and to which they could contribute.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="5.00">In this paper, we propose a simple yet effective framework for composing specialist controllers into more general and capable control systems for dynamic characters.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="5.00">In our framework, individual controllers are black boxes encapsulating control knowledge that is possibly gleaned from the biomechanics literature, derived from the robotics control literature, or developed specifically for animation control.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="3.67">Individual controllers must be able to determine two things: <CitSpan>(1)</CitSpan> a controller should be able to determine whether or not it can take the dynamic character from its current state to some desired goal state, and <CitSpan>(2)</CitSpan> an active controller should be able to determine whether it is operating nominally, whether it has succeeded, or whether it has failed.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="3.33">Any controller that can answer these queries may be added to a pool of controllers managed by a supervisor controller whose goal is to resolve more complex control tasks.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="4.33">An important technical contribution within our controller composition framework is an explicit model of pre-conditions.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="3.67">Preconditions characterize those regions of the dynamic figure’s state space within which an individual controller is able to successfully carry out its mission.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="4.00">Initially, we demonstrate the successful composition of controllers based on manually determined pre-conditions.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="3.00">We then proceed to investigate the question of whether pre-conditions can be determined automatically.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="4.33">We devise a promising solution which employs Support Vector Machine (SVM) learning theory.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="4.00">Our novel application of this technique learns appropriate pre-conditions through the repeated sampling of individual controller behavior in operation.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="4.00">As a testbed of our techniques, we are developing a physicallysimulated animated character capable of a large repertoire of motor skills.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.67">An obvious application of such a character is the creation of a virtual stuntperson: the dynamic nature of typical stunts makes them dangerous to perform, but also makes them an attractive candidate for the use of physics-based animation.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="3.33">The open challenge here lies in developing appropriate control strategies for specific actions and ways of integrating them into a coherent whole.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="4.33">In this paper, we demonstrate families of composable controllers for articulated skeletons whose physical parameters reflect anthropometric data consistent with a fully-fleshed adult male.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="3.00">One family of controllers is for a 37 degree-of-freedom (DOF) 3D articulated skeleton, while a second family of controllers has been developed for a comparable 16 DOF 2D articulated skeleton.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.33">While the 3D skeleton illustrates the ultimate promise of the technique, the easier control associated with the 2D skeleton allows for more rapid prototyping of larger families of controllers and more careful analysis of their operation.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="1.33">As has been recognized in the robotics literature, the control of broad skilled repertoires of motion remains very much an open problem even for 2D articulated figures.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="1.0">Fig. 1 illustrates the 3D dynamic character autonomously performing a complex control sequence composed of individual controllers responsible for falling reactions, rolling-over, getting up, and balancing in gravity.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="1.67">The upright balancing dynamic figure is pushed backwards by an external force; its arms react protectively to cushion the impact with the ground; the figure comes to rest in a supine position; it rolls over to a prone position, pushes itself up on all fours, and rises to its feet; finally it balances upright once again.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="1.67">A subsequent disturbance will elicit similar though by no means identical autonomous behavior, because the initial conditions and external forces will usually not be exactly the same.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.33">Control sequences of such intricacy for fully dynamic articulated figures are unprecedented in the physics-based animation literature.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="1.0">After reviewing related prior work in the next section, we present the details of our control framework in Section 3.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="1.0">We then investigate the question of determining pre-conditions in Section 4.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="1.0">Section 5 describes the articulated figure models and the software system we use to implement the control framework.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="1.0">Section 6 presents the details of the example in Fig. 1 along with several other examples that demonstrate the effectiveness of our framework.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="1.0">Section 7 concludes the paper and discusses avenues for future research opened up by our work.</Sentence>
      
        <H1>2 Previous Work</H1>
        <Sentence inAbstract="false" summaryRelevanceScore="2.00">The simulation and animation of human characters is a challenging problem in many respects.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="1.67">Comprehensive solutions must aspire to distill and integrate knowledge from biomechanics, robotics, control, and animation.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="1.33">Models for human motion must also meet a particularly high standard, given our familiarity with what the results should look like.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.00">Not surprisingly, a divide-and-conquer strategy is evident in most approaches, focusing efforts on reproducing particular motions in order to yield a tractable problem and to allow for comparative analysis.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.00">The biomechanics literature is a useful source of predictive models for specific motions, typically based on experimental data supplemented by careful analysis.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.33">These models target applications such as medical diagnosis, the understanding and treatment of motor control problems, the analysis of accidents and disabilities, and high-performance athletics.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="1.33">Computer simulation is becoming an increasingly useful tool in this domain as the motion models evolve to become more complex and comprehensive <CitSpan>[ 26 , 27 , 29 ]</CitSpan>.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.00">Given the challenge of achieving high-fidelity motion models for individual motions, there have been fewer efforts towards integrated solutions applicable to multiple motions.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="1.0">Reference <CitSpan>[ 26 ]</CitSpan> is one such example.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="1.67">Robotics research has made remarkable progress in the successful design of a variety of legged robots <CitSpan>[ 28 ]</CitSpan> and, more recently, bipedal robots with anthropomorphic aspirations <CitSpan>[ 23 ]</CitSpan>.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="1.67">Despite their limited motion repertoires and rather deliberate movements, these robotic systems are truly engineering marvels.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="1.0">The work in <CitSpan>[ 1 ]</CitSpan> provides a good summary of behavioral architectures explored in the context of robotics.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="1.67">A 3 DOF ball-juggling robot is described in <CitSpan>[ 6 ]</CitSpan> which uses a theory of behavior composition, although the practicality of extending the method to high-DOF dynamic models of human motions is unclear.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="1.0">Computer animation is to a large extent unencumbered by the exacting fidelity requirements of biomechanical models and the mechanical limitations of robotic systems.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="1.33">This has spawned a great variety of kinematic and dynamic models for character motion <CitSpan>[ 3 , 4 , 7 ]</CitSpan>.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.00">While motion capture solutions based on blending and warping techniques may give satisfactory results for such tasks in the short term, controller based approaches reveal more about the physics, planning, and control of such motions and they therefore serve as a basis for more general solutions.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="1.67">Dynamically simulated characters were first proposed over 15 years ago <CitSpan>[ 2 , 34 ]</CitSpan> and since then have progressed in sophistication in a variety of directions.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.00">Controllers have been successfully designed for specific human motions such as walking, running, vaulting, cycling, etc. <CitSpan>[ 16 , 22 , 35 ]</CitSpan>.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.33">Dynamically simulated articulated characters equipped with an integrated, wide-ranging repertoire of motor skills currently remain an unachieved goal.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.00">Some positive steps in this direction are evident, however.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.00">Examples include an integrated repertoire of motor controllers for biomechanically animated fish <CitSpan>[ 30 ]</CitSpan>, a methodology for controller design and integration applicable to simple figures <CitSpan>[ 32 ]</CitSpan>, a demonstration of successful integration for selected diving and gymnastic motions <CitSpan>[ 35 ]</CitSpan>, and adapting a controller designed for one character to work on another character <CitSpan>[ 17 ]</CitSpan>.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.00">The work of Wooten <CitSpan>[ 35 ]</CitSpan> is the most relevant as an example of a sequence of successive transitions between several controllers for human motions such as leaping, tumbling, landing, and balancing.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.00">Transitions are realized by including the end state of some controllers in the starting states of other controllers.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="1.0">A digital biomechanics laboratory is proposed by Boston Dynamics, Inc.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="1.0">
<CitSpan>[ 20 ]</CitSpan> as a tool for simulating a wide range of human motion.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.00">This currently remains ambitious work in progress.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="3.00">Our work is aimed at creating dynamic human characters with broadly integrated action repertoires.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="4.67">Unlike previous work focusing on specific athletic movements, our methodology is to begin with a core set of simple actions, including balancing, small steps, falling reactions, recovery from falls, standing up from a chair, and others.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.67">In the present paper, we do not cover in any appreciable detail the design of individual controllers to effect such basic actions.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="4.33">1 Rather, our contribution here is a framework for composing individual controllers, however they may be designed, into more capable control systems for dynamic characters.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="1.0">An interesting tech-
        1 Full details about the individual controllers that we have designed are presented elsewhere <CitSpan>[ 10 ]</CitSpan>.</Sentence>
        <Sentence inAbstract="false" summaryRelevanceScore="1.0">nical contribution within our controller composition framework is the introduction of a learning approach for automatically determining controller pre-conditions.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="3.67">Our pre-condition learning algorithm adds to the growing body of learning algorithms that have been successfully applied in the context of computer animation in recent years <CitSpan>[ 14 , 15 ]</CitSpan>.</Sentence>
      
      
        <H1>3 Controller Composition Framework</H1>
        <Sentence inAbstract="false" summaryRelevanceScore="4.00">In our controller composition framework, we consider individual controllers as black boxes which are managed by a simple supervisor controller.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="3.33">When no controller is active, the supervisor polls the pool of controllers, querying each whether it can handle the transition of the dynamic character from its current state to the desired goal state.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="3.33">Individual controllers return an integer confidence/suitability score when queried in order to bid on becoming the active controller.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="3.33">In our implementation, controllers that can perform a sensible action given the current state of the character return an integer in the range 1⁄2 1⁄21⁄4 , while those that can handle the current state as well as guarantee a transition to the desired state, return an integer in the range 1⁄21⁄4 3⁄41⁄4 .</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="1.67">Lastly, a value of 1⁄4 means that a controller is unsuited for the current state.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="1.67">The controller that returns the highest score becomes active.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.67">While this scoring scheme potentially allows for a nuanced evaluation of the controller suitability in terms of criteria such as probability of success or energy used, our current controllers resort to a simpler scheme.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="1.67">This consists of a binary success/failure evaluation multiplied by a weighting factor assigned to each controller that serves to establish a relative preference ordering.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="1.0">The power of this scheme stems from the following attributes:
        Simplicity: The composition method is straightforward and easy to implement.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="3.67">It does not appreciably burden the controller design task.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="1.0">Generality: The composition method does not restrict the design of individual controllers.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="3.67">Each controller can be as primitive or as sophisticated as its designer wishes.</Sentence>
        
          <H2>3.1 Controller Abstraction</H2>
          <Sentence inAbstract="false" summaryRelevanceScore="3.67">A controller within the pool of available controllers can be as simple as a constant force, or as complex as a structured hierarchy of multiple levels of control abstraction.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.00">For example, as more controllers are added to the system, we may wish to group all the walking and running controllers together into a cluster that can be treated as one encapsulated controller.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.33">Regardless of the encapsulation, our composition method requires controllers to define pre-conditions, post-conditions and expected performance.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.00">Pre-conditions are a set of conditions over the state of the character and the environment.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.00">If these conditions are met then the controller can operate and possibly enable the character to satisfy the post-conditions.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="1.67">Assuming that the pre-conditions were met, the post-conditions define a range of states for the final state of the character after the execution of the controller.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.00">In other words the controller realizes a mapping between a domain of input states to a range of output states for the character.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.67">Because of unexpected changes in the environment, this mapping may not always succeed, which motivates the notion of expected performance.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.33">The controller should be able to evaluate its performance in order to detect failure at any point during its operation.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.00">To do this, the controller must at all times have knowledge of the current and expected state of the character or the environment.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.33">Defining the pre-conditions, post-conditions, and expected performance for complex characters, motions, and environments is not a straightforward task.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.00">However, we believe that the effort required to generate these specifications is a fair and necessary price to pay to achieve the benefits of composability.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.33">Controllers that adhere to these specifications can form a pool of available controllers managed by the supervising controller.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="1.67">Fig. 2 presents an overview of the supervising controller’s function and its interaction with the individual controllers at every time step of the simulation.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="1.0">Before we elaborate on pre-conditions, post-conditions, and expected ing quantities performance and symbols: in subsequent The state sections, Õ let Ü Ü us 1⁄4 define of a figure the followis the vector of generalized positions Ü and velocities Ü , where the dot indicates a time derivative.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="1.33">The position and velocity of the center of mass are denoted as and respectively.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="1.33">The base of support of a figure (often called the support polygon) is denoted as Ë .</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="1.33">It is represented by a polygon that surrounds the foot or feet that are in contact with the ground at any given time.</Sentence>
          Supervising controller At every time step: if( no active_controller ) Controller for all controllers i =1: N if( controller[i].can_handle() == true) { Preconditions PostConditions put controller[i] into candidates end if Expected Performance end for active_controller = arbitrate(candidates) else status = active_controller.getStatus() endif
          
            Figure 2: Controller selection and arbitration during simulation.
          
        
        
          <H2>3.2 Pre-Conditions</H2>
          <Sentence inAbstract="false" summaryRelevanceScore="2.67">In general, pre-conditions are relationships and constraints involving several different parameters.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="1.0">We have used the following parameters in our work:
          The initial state Õ of the figure.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.33">Most of our controllers can operate within a small region of the state space which we denote Ê  ́ Õ μ .</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="1.33">Environmental parameters.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="1.33">These include the contact points between the character and the ground, as well as the normal of the ground and the amount of friction at the contact points.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="1.0">In the following we denote conditions (generally indicated by the letter ) on the environment parameters as .</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="1.33">The balance of the figure.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="1.33">Usually, this is indicated by the relative position and velocity between the figure’s center of mass and the base of support.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="1.33">Typically, if the projection of along the gravity vector does not intersect the base of support Ë , the figure is considered to be unbalanced.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="1.67">We denote the balance conditions as  ́ Ë μ .</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="1.0">A Ê  ́ target Õ Ø μ , which state Õ can Ø , or be in provided general a by target the region user.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="1.0">of the state space
          Pre-conditions consist of unions of instances of the above conditions and are denoted
          <CitSpan>(1)</CitSpan>
          The determination of pre-conditions is crucial to the success of our composition framework and will be examined in detail in Section 4.</Sentence>
        
        
          <H2>3.3 Post-Conditions</H2>
          <Sentence inAbstract="false" summaryRelevanceScore="2.33">Successful operation of a controller brings the character from an initial state, as defined by the pre-conditions, to a desired state or a desired region Ê  ́ Õ Ó μ in the state space.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="1.0">This region along with balance and possibly environmental constraints form the postconditions of a controller:
          <CitSpan>(2)</CitSpan>
          Note that the pre-conditions may reference a subset of the postconditions that is sufficient to characterize what the controller can achieve.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.00">In general, however, the post-conditions are different from the pre-conditions.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="1.33">For example, while a pre-condition for a falling controller requires that the center of mass be moving, the postconditions require that the center of mass be at rest.</Sentence>
        
        
          <H2>3.4 Expected Performance</H2>
          <Sentence inAbstract="false" summaryRelevanceScore="3.67">Our framework permits the automatic selection of the appropriate controller based on the information provided by the controllers themselves.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.67">Only the individual controllers can detect whether they are operating normally or whether failure is imminent.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.33">Failure in our case means that the controller cannot meet its post-conditions Ç .</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.67">The controller may fail because of a sudden change in the environment or because of badly designed pre-conditions.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.67">The sooner a controller can detect failure the sooner another more appropriate controller can take over.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.33">This is important for making a character behave naturally.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="1.33">For example, the character should not attempt to continue a walking gait if it has lost its balance and it is falling.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.00">In our implementation, the expected performance consists of expressions similar to those of the pre-conditions È .</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.00">In particular if the controller successfully completes its task in the time interval Ø 1⁄2 , Ø 3⁄4 , then  ́ Ø 1⁄2 μ 3⁄4È and  ́ Ø 3⁄4 μ 3⁄4Ç .</Sentence>
        
        
          <H2>3.5 Transitions</H2>
          <Sentence inAbstract="false" summaryRelevanceScore="2.00">Transitions between controllers are not explicitly modeled as they would be in a finite state machine.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="1.67">They occur implicitly in response to the evolution of the motion over time, as the system state traverses the “regions-of-competency” of the various controllers.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="1.67">Nevertheless, given that most controllers are designed for specific situations, typical patterns of controller activation occur.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="1.33">Fig. 3 shows the family of controllers designed for the 3D dynamic character and their typical transition patterns.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="1.0">For example, the controllers and transitions used in achieving the motion shown in Fig. 1 is given by balance fall default rollover prone-tostanding balance.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="1.33">Fig. 4 similarly shows the family of controllers designed for the 2D dynamic character and their typical transition patterns.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="1.0">Note that not all possible transitions are shown in either of Figs. 3 and 4.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="1.33">For example, the prone-to-standing fall transition can occur if the figure is given a sufficiently strong push while rising.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="1.33">Most of the transitions which are not shown but are still practically feasible are of this nature, dealing with falling behaviors.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="1.33">Note that the fall controller always responds to the specific direction of the current fall.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="1.33">Any transition involves one controller being deactivated and another being activated.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.33">A controller can become deactivated (and thereby elicit a transition) for one of three reasons.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="1.67">First, it may relinquish control by declaring success upon reaching its postcondition, as is the case for a standup controller which has successfully returned the character to a standing position.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.00">Second, user intervention may elicit a transition.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.00">The controllers designed for sitting or balanced standing will retain control until intervention by a user (or by a higher level planner) forces a desired transition.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.00">Thus, when the 2D character is balanced a user-driven process must choose among the next plausible actions, namely one of sit, walk, or dive (see Fig. 4 ).</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.00">Third, a controller may detect failure, as will be the case for unpredictable events such as a push or an unforeseen obstacle causing the character to trip.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="1.67">The transitions in Figs. 3 and 4 are labelled according to the type of controller deactivations which typically elicit the given transition patterns.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.00">We note that our framework is designed to work in interactive settings.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.33">As such, controllers typically start with slightly different initial conditions each time they are invoked, the user can interact with the character at any time, and generally there are no guarantees that the controller will reach the same end state each time it operates.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.33">As a result, the transition graph is dynamic in structure.</Sentence>
          
            Figure 3: Controllers and typical transitions for 3D figure
          
          
            Figure 4: Controllers and typical transitions for 2D figure
          
        
      
      
        <H1>4 Determining Pre-Conditions</H1>
        <Sentence inAbstract="false" summaryRelevanceScore="2.33">For controllers associated with complex dynamic characters, determining the exact region of the state space and the general conditions that determine success or failure of the controller is in general a non-trivial matter.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.33">In this section, we address this problem via manual and automatic approaches.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="3.33">The manual approach allows designers to incorporate their knowledge within controllers, whereas the automatic approach is based on machine learning techniques.</Sentence>
        
          <H2>4.1 Manual Approach</H2>
          <Sentence inAbstract="false" summaryRelevanceScore="1.67">For certain cases, suitable pre-conditions for specific controllers may be found in the biomechanics literature <CitSpan>[ 8 , 25 ]</CitSpan>.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="1.67">For example Pai and Patton <CitSpan>[ 25 ]</CitSpan> present a comprehensive study of balance in the sagittal plane and identify the conditions under which a human can compensate for postural disturbances and maintain balance without stepping.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="1.67">For certain other cases, the pre-conditions are trivially defined by the desired motion itself.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="1.67">Certain controllers function as intermediate stages between other controllers.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="1.0">If controller B is the intermediate step between A and C then the postconditions of A dictate the pre-conditions of B and similarly the pre-conditions of C define the post-conditions of B. Finally, in some cases the pre-conditions are computed by manual experimentation.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="1.0">For example a simple balance controller based on an inverted pendulum model <CitSpan>[ 12 ]</CitSpan> has intrinsic stability that can tolerate small disturbances.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="1.0">After the controller has been designed, repeated testing under disturbances of increasing magnitude can yield an approximation of the pre-conditions and the post-conditions.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.00">In any case, the designer of a controller presumably understands the way the controller operates, and thus is able to provide high level conditions on its success or failure.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="1.67">For example, the designer of a walking controller knows if the controller can operate when the walking surface has minimal friction properties.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="1.67">Also, human motion is shaped by notions such as comfort, and only the designer can take this into account.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="1.67">For example, if a person is pushed while standing he/she might take a protective step because it may be more comfortable to do so instead of maintaining an inverted pendulum balancing strategy.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="1.67">Similarly, the way people react to slipping and imbalance and the protective behaviors they employ are largely age dependent.</Sentence>
        
        
          <H2>4.2 Automatic, Learning Approach</H2>
          <Sentence inAbstract="false" summaryRelevanceScore="4.00">In this section, we introduce an automatic, machine learning approach to determining pre-conditions, which is based on systematically sampling the performance of controllers.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="4.33">Our method uses a machine learning algorithm attributed to Vapnik <CitSpan>[ 33 ]</CitSpan> known as Support Vector Machines (SVMs), which has recently attracted much attention, since in most cases the performance of SVMs matches or exceeds that of competing methods.</Sentence>
          
            <H3>4.2.1 Support vector machines (SVMs)</H3>
            <Sentence inAbstract="false" summaryRelevanceScore="2.00">SVMs are a method for fitting functions to sets of labeled training data.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.00">The functions can be general regression functions or they can be classification functions.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.33">In our application, we use simple classification functions with binary outputs which encode the success or failure of a controller.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="1.0">Burges <CitSpan>[ 5 ]</CitSpan> provides an excellent tutorial on SVMs.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.00">Mathematically, we are given Ð observations, each consisting of an dimensional vector Ü 3⁄4 1⁄2 Ð and the associated “truth” Ý 3⁄4   1⁄2 1⁄2 provided by a trusted source.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.00">Here, Ý 1⁄2 labels a positive example—in our application, the observed success of a controller applied when the dynamic figure is in state Ü — while Ý   1⁄2 labels a negative example—the failure of the controller applied to state Ü .</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="1.67">The set of observations Ü Ý is called the training set.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="1.67">The SVM is a machine whose task is to learn the mapping Ü Ý from a training set.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="1.67">The SVM is defined by functional mappings of the form Ü  ́ Ü « μ , where « are parameters.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="1.67">A particular choice of « generates a “trained” SVM.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="1.67">In a trained SVM, the sign of the decision function  ́ Ü μ represents the class assigned to a test data point Ü .</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.33">In our application, a properly trained SVM predicts if a controller will succeed (  ́ Ü μ 1⁄4 ) or fail (  ́ Ü μ 1⁄4 ) on a given state Ü of the dynamic character.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="1.0">How does one train an SVM?</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.00">In the simplest case of a linear SVM with separable training data, there exists a decision boundary separating positive from negative examples which takes the form of a “separating hyperplane” in .</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="1.67">The SVM training algorithm computes the separating hyperplane with the largest margin · ·   , where · (   ) is the shortest distance from the separating hyperplane to the closest positive (negative) example.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="1.67">SVM training requires the solution of a quadratic programming optimization problem involving a Lagrange multiplier « for every datapoint in the training set.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="1.67">Those datapoints in the solution with corresponding « 1⁄4 are called support vectors.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.00">The support vectors are critical elements of the training set.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="1.33">They lie closest to the separating hyperplane.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="1.33">If other observations in the training set are moved (subject to certain restrictions) or removed and SVM training is repeated, the same separating hyperplane will result.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.00">To use a trained SVM, we simply determine on which side of the decision boundary a given test data point Ü lies and assign the corresponding class label to that point.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.00">The linear SVM is easily generalized to nonseparable training data.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.00">Furthermore, it is straightforward to generalize the theory to encompass nonlinear SVMs for which the decision boundaries are no longer hyperplanes (i.e., the decision function are no longer linear functions of the data).</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.00">The trick, in principle, is to map the data to some higher (possibly infinite) dimensional space in which the linear theory can be applied.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.00">This is easily done by introducing kernel functions Ã  ́ Ü Ü μ , such as the polynomial kernel Ã (RBF)  ́ Ü Ý kernel μ  ́ Ü Ã ¡  ́ Ü Ý · Ý μ 1⁄2μ Ô , ÜÔ ́ or the   Ü Gaussian   Ý 3⁄4 3⁄4 or 3⁄4 μ radial .</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="1.67">For the basis mathematfunction ical details, we refer the reader to <CitSpan>[ 5 ]</CitSpan>.</Sentence>
          
          
            <H3>4.2.2 Applying SVMs</H3>
            <Sentence inAbstract="false" summaryRelevanceScore="3.00">To apply the SVM technique to the problem of determining controller pre-conditions, we train a nonlinear SVM classifier to predict the success or failure of a controller for an arbitrary starting state.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.67">Thus, the trained SVM demarcates the boundary of regions in the figure’s state space wherein the controller can successfully do its job.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.33">Training sets comprising examples Ü Ý are generated by repeatedly starting the dynamic figure at a stochasticallygenerated initial state Ü , numerically simulating the dynamics of the figure under the influence of the controller in question, and setting Ý ·1⁄2 if the controller succeeds or Ý   1⁄2 if it fails.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.33">The distribution of the stochastically-generated initial states is of some importance.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.33">The sample points should ideally be located close to the boundaries which demarcate the acceptable precondition region of state-space.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.33">However, these boundaries are in fact the unknowns we wish to determine and thus we must resort to a more uniform sampling strategy.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.33">Unfortunately, the high dimensionality of the state-space precludes regular sampling.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="1.0">We thus adopt the following stochastic process to generate a suitable distribution of initial states: First, a nominal initial state is chosen, based upon the designer’s knowledge of the controller.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.00">A shortduration simulation (typically 0.3s) is then carried out from this initial state while a randomized perturbation process is executed.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.00">This currently consists of applying an external force of random (but bounded) magnitude and random direction to the center-of-mass of the pelvis.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.67">Simultaneously, the character’s joints are perturbed in a stochastic fashion by setting randomized offset target angles for the joints and using the character’s PD joint controllers to drive the joints towards these perturbed positions.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="3.00">While the perturbation strategy is admittedly ad-hoc, we have found it to be effective in sampling the pre-condition space, as is validated by the online use of the learned pre-condition models.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.67">We employ T. Joachims’ SVM Ð Ø software which is available on the WWW <CitSpan>[ 21 ]</CitSpan>.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.67">The software can accommodate large training sets comprising tens of thousands of observations and it efficiently handles many thousands of support vectors.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.33">It includes standard kernel functions and permits the definition of new ones.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.67">It incorporates a fast training algorithm which proceeds by solving a sequence of optimization problems lower-bounding the solution using a form of local search.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.67">It includes two efficient estimation methods for error rate and precision/recall.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="3.33">The SVM training phase can take hours in our application, but this is done off-line.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.00">For example, on a 733 MHz PIII computer, the SVM training time for a training set of 8,013 observations is 2,789 seconds using the polynomial kernel, 2,109 seconds using the linear kernel, and 211 seconds using the radial kernel.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.33">For a training set of 11,020 observations, the training time is 8,676 seconds using the polynomial kernel, 3,593 seconds using the linear kernel, and 486 seconds using the radial kernel.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="3.00">Once trained, the SVM classifier can provide answers on-line in milliseconds.</Sentence>
          
          
            <H3>4.2.3 Pre-condition learning results</H3>
            <Sentence inAbstract="false" summaryRelevanceScore="1.0">Through systematic experimentation, we have evaluated the performance of our automatic, SVM-based algorithm for learning con-
            Controller Training set size Test set size NN SVM StepToStand 8,999 9,110 80.97% 87.29% LyingOnBellyToKneel 4,200 4,223 93.27% 94.46% LyingOnBackToKneel 2,234 1,879 100.0% 100.0% BendToStand 6,926 14,272 98.05% 99.77% StandInPlace 17,317 20,393 83.63% 87.67% Walk 11,020 8,658 92.78% 97.73% StandToSit 1,100 1,286 64.15% 69.60% StandToStep 16,999 17,870 72.12% 79.18% KneelToStand 6,000 11,998 79.45% 85.06% Table 1 : Comparison between learned SVM and NN preconditions.</Sentence>
            <Sentence inAbstract="false" summaryRelevanceScore="1.0">troller pre-conditions.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.33">We compared the performance of the SVM algorithm to that of a nearest neighbor (NN) classifier <CitSpan>[ 9 ]</CitSpan>.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="1.67">Given a training set, the nearest neighbor classifier returns for an arbitrary state Ü the same succeed/fail label as the label for that observation in the training set that is closest to Ü .</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.00">NN classifiers should perform particularly well in cases where the feasible area in the state space is highly fragmented and localized.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.00">Note that the NN method requires zero training time, but that it provides an answer in Ç  ́ Ò μ time where Ò is size of the training set.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.33">Table 1 summarizes the percentage success rates (rightmost columns) of learned pre-conditions for a variety of controllers that we use later in our demonstrations.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.00">To compute accuracy rates, we trained the SVM and NN pre-condition learning algorithms using randomly sampled observations collected from each of the controllers.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.00">Then we generated test sets of novel observations and compared their true success/fail status against that predicted by the trained NN and SVM pre-conditions to obtain the accuracy percentages listed in the rightmost two columns of the table.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="3.33">The results show that the SVM algorithm consistently outperforms the NN classifier.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="3.00">For the results shown in the table, the SVM algorithm employed polynomial kernel functions.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.33">We ran a similar set of experiments using Gaussian RBF kernel functions, but the accuracies were consistently lower than those obtained with polynomial kernel functions.</Sentence>
          
        
      
      
        <H1>5 Implementation</H1>
        <Sentence inAbstract="false" summaryRelevanceScore="3.00">Our control composition framework is implemented within DANCE , a portable, extensible object-oriented modeling and animation system <CitSpan>[ 24 ]</CitSpan>.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.33">2 DANCE provides a platform that researchers can use to implement animation and control techniques with minimal design and implementation overhead.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.33">The core of the system supports four base classes, Systems, Simulators, Actuators and Geometries which are loadable as plug-ins in accordance with simple APIs.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.33">Articulated objects are a System subclass that support skeleton hierarchies.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.33">They have kinematic properties and, usually, fully dynamic physical properties as well.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.33">Our virtual actors, which will be described shortly, are dynamic articulated objects implemented as Systems within DANCE .</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.00">An actuator is a generic concept that includes anything that can exert forces or, in general, interact in any way with systems or other actuators.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="1.67">For example, gravity, the ground, the collision mechanism, the supervisor controller and individual controllers are implemented as actuators.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.00">DANCE places no restrictions on the complexity of the controllers.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.00">Simulators compute the equations of motion of all the dynamic characters and other systems in DANCE .</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.00">DANCE offers built in support for SD/FAST, a commercial system which produces optimized simulation code <CitSpan>[ 18 ]</CitSpan>.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="1.0">However, any simulator that follows a simple
        2 DANCE is freely available for non-commercial use via the URL: www.dgp.toronto.edu/software/dance.htm</Sentence>
        
          
        
        Joint Rotational DOFs Rotational DOFs 3D skeleton model 2D terminator model Head 1 1 Neck 3 1 Shoulder 2 1 Elbow 2 1 Wrist 2 Waist 3 1 Hip 3 1 Knee 1 1 Ankle 2 1
        
          Figure 5: Dynamic models and their degrees of freedom (DOFs).
        
        <Sentence inAbstract="false" summaryRelevanceScore="1.0">API can be dynamically loaded into the system.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="3.00">Our simulators are automatically produced by SD/FAST from description files.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.33">They use Kane’s method for computing articulated dynamics and a fourth order explicit Runge-Kutta time integrator for numerically simulating the motions.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.33">Actuators and simulators are implemented as DANCE plug-ins.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="3.00">This allows the user to dynamically load controllers and simulators at runtime.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.67">In addition, researchers can exchange, simulators, and controllers in the form of dynamically linked pieces of code.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.33">Object collisions (including self collisions) are handled by the Collision actuator.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.33">This actuator works on pairs of objects.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.00">The DANCE API allows it to work with objects that have different simulators.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.33">Collision detection is based on a library that uses oriented bounding boxes <CitSpan>[ 13 ]</CitSpan>.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.33">Collision resolution uses a penalty method that corrects geometry interpenetration using spring-and-damper forces.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="3.00">As with all penalty methods, it can make the system stiff, but it has performed well in our experiments to date.</Sentence>
        
          <H2>5.1 Virtual Stuntman</H2>
          
            <H3>5.1.1 Dynamic model</H3>
             <Sentence inAbstract="false" summaryRelevanceScore="2.00">Fig. 5 depicts our 2D and 3D articulated character models.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.00">The red arrows indicate the joint positions and axes of rotational degrees of freedom (DOFs) which are also presented in the table.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="1.67">The 3D skeleton model has 37 DOFs, six of which correspond to the global translation and rotation parameters.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.00">The table in Fig. 5 lists the DOFs for the skeleton and a 2D “terminator” model.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.00">The dynamic properties of both models, such as mass and moments of inertia, are taken from the biomechanics literature and correspond to a fullyfleshed adult male.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.00">The models are equipped with natural limits both on the motion of the joints and the strength of their muscles.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="1.33">However, DANCE has no built in muscle model and does not enforce the limits automatically.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.00">Users can implement the model they prefer and include code to enforce the limits of the model.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.33">Our plug-in control scheme uses rotational spring-and-damper forces for control and enforces the limits on the joints with exponential springs.</Sentence>
          
          
            <H3>5.1.2 Pose and continuous control</H3>
            <Sentence inAbstract="false" summaryRelevanceScore="2.67">Most of the controllers for our virtual stuntperson are based on pose control, which has often been used both for articulated objects <CitSpan>[ 31 ]</CitSpan> and soft objects <CitSpan>[ 11 ]</CitSpan>.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.67">Pose control is based on cyclic or acyclic finite state machines with time transitions between the states.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.00">Each state of the controller can be static or depend on feedback parameters.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.67">For some of our controllers, we use continuous control, in the sense that the control parameters are tightly coupled with some of the feedback sensors.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.00">The balance controllers are an example of this.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="3.00">We designed several controllers based in part on experimental studies of how humans detect loss of balance <CitSpan>[ 25 ]</CitSpan> and analysis of protective and falling behaviors <CitSpan>[ 8 ]</CitSpan>.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="3.00">The resulting parameterized controllers have been enhanced with appropriate pre-conditions, post-conditions, and expected performance and have been integrated using an arbitration-based supervising controller.</Sentence>
          
          
            <H3>5.1.3 Sensors</H3>
            <Sentence inAbstract="false" summaryRelevanceScore="2.67">Each controller has full access to the internal data structures of DANCE including all the information associated with any character or object in the system.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.67">This allows the controllers to define arbitrary sensors that keep track of necessary information such as state parameters for feedback loops and the state of the environment.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.33">For efficiency, the supervisor controller calculates a number of common sensor values that are available to all the controllers.</Sentence>
          
          
            <H3>5.1.4 Command interface</H3>
            <Sentence inAbstract="false" summaryRelevanceScore="2.33">Many controller transitions in the control framework happen autonomously, such as taking a protective step in response to losing balance.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.33">However, other actions are initiated in a voluntary fashion.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.00">For example, a standing character can do any of <CitSpan>(1)</CitSpan> remain standing using the balance controller, <CitSpan>(2)</CitSpan> sit-down, <CitSpan>(3)</CitSpan> walk, and <CitSpan>(4)</CitSpan> dive.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.33">Currently, the user directs these voluntary motions by interactively entering command strings to the supervisor controller which, in turn, directly increases the suitability score of the designated controller and forces the arbitration process to be invoked to select a new active controller.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.33">The control of voluntary motions could equivalently be delegated to a high-level planner, although this kind of planning is beyond the scope of our work at present.</Sentence>
          
        
      
      
        <H1>6 Results</H1>
        <Sentence inAbstract="false" summaryRelevanceScore="4.67">At the heart of our prototype system is a composite controller that is capable of handling a large number of everyday tasks, such as walking, balancing, bending, falling, and sitting.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="3.67">In addition, we present brief descriptions of the controllers involved in producing several stunt actions.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.67">While the given controller descriptions are for the 3D character, the equivalent 2D controllers are very similar.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="3.00">Finally, we discuss motion sequences generated using these families of controllers 3 .</Sentence>
        3 See www.dgp.toronto.edu/ pfal/animations.html for the associated animations.
        
          <H2>6.1 Everyday Actions</H2>
          <Sentence inAbstract="false" summaryRelevanceScore="1.67">We began our implementation with the simple tasks of standing, recovering balance when pushed, and falling.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="1.67">An autonomous human agent should be able to balance, standing naturally in place.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.00">Should loss of balance occur, the character ought to react naturally either with a restoring motion or with a protective falling behavior depending on which action is appropriate in each case.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.33">Affording a dynamic articulated figure with natural reactions to loss of balance or impending falls is an essential step towards believable autonomous characters.</Sentence>
          
            <H3>6.1.1 Balancing</H3>
            <Sentence inAbstract="false" summaryRelevanceScore="2.00">A balance controller is responsible for maintaining a natural standing posture.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.00">This controller is based on an inverted pendulum model <CitSpan>[ 12 ]</CitSpan>, using the ankles to control the body sway.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.67">Despite the fact that the body of the character is not as rigid as the inverted pendulum hypothesis suggests, the approximation works well in practice.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="1.0">As an example of the type of manually defined pre-conditions and post-conditions used for this controller and others, these details are given in Appendix A for the balance controller.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="1.67">An animated character should attempt to maintain balance in response to external disturbances by shifting its weight, taking a step or bending at the waist.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="1.67">If the character cannot maintain balance, it must then resort to a falling behavior.</Sentence>
          
          
            <H3>6.1.2 Falling</H3>
            <Sentence inAbstract="false" summaryRelevanceScore="2.00">The manner in which people fall depends on a number of factors such as their physique, their age and their training.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="1.33">For example, the work in <CitSpan>[ 19 ]</CitSpan> shows that, during a fall, the elderly are more likely to impact their hip first as compared to younger adults falling under the same conditions.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.33">Our fall controller is designed with the average adult in mind.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.33">Its main action is thus to absorb the shock of the impact using mostly the hands.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.33">The pre-conditions of the fall controller are defined in accordance with those of the balance controller.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.33">Situations that are beyond the capabilities of the latter should be handled by the fall controller.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="3.00">Our implementation of the fall controller can handle falls in any direction, responding in different ways to falls in different directions.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="1.67">Fig. 6 depicts frames from falls in a variety of directions.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="1.67">The second frame in Fig. 1 also demonstrates the action of the fall controller within a fall-and-recover sequence.</Sentence>
          
          
            <H3>6.1.3 Sitting</H3>
            <Sentence inAbstract="false" summaryRelevanceScore="1.67">Sitting down in a chair and rising from a chair are common everyday tasks.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="3.00">We have implemented a controller that can do both depending on the instructions of the animator.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.33">Apart from the command string supplied by the user, the pre-conditions are either a balanced upright posture or a balanced sitting posture.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.00">The postconditions are similarly defined.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="1.67">The resulting action is illustrated in Fig. 7 .</Sentence>
          
          
            <H3>6.1.4 Rising from a supine position</H3>
            <Sentence inAbstract="false" summaryRelevanceScore="1.67">Getting up off the ground is a surprisingly difficult motion to simulate.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.33">It involves rapid changes of the contact points and significant shifting of the figure’s weight.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.00">In addition, the frictional properties of the ground model can influence the motion.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.33">The pre-conditions for this controller are straightforward.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.00">The character must be lying with its back flat on the ground, within some tolerance.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.00">The post-conditions are that the character should be on its feet with its center of mass within the support polygon.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.00">Then it would be up to another controller to take over and bring the character from a crouching position to a standing one.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="1.67">A snapshot of a resulting motion is shown in Fig. 8 .</Sentence>
            
              
              Figure 6: Falling in different directions
            
          
          
            <H3>6.1.5 Rolling over</H3>
            <Sentence inAbstract="false" summaryRelevanceScore="2.00">When lying on their back, some people may choose to roll-over to a prone position before attempting to stand.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="3.00">We have implemented a roll-over controller that can emulate this action.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.00">The fourth frame in Fig. 1 demonstrates the action of the roll-over controller.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.33">The pre-conditions of the roll-over controller require a supine posture, and no movement of the center of mass.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.67">The postconditions of the roll controller are fairly simple and they include any prone position for which the character is extended and fairly straight; i.e., no crossing of legs or arms, etc.</Sentence>
          
          
            <H3>6.1.6 Rising from a prone position</H3>
            <Sentence inAbstract="false" summaryRelevanceScore="2.00">Frames 5–9 in Fig. 1 demonstrate the action of a controller that enables the virtual stuntperson to rise from the prone position.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.00">When lying face-down, the pre-conditions can be fairly relaxed.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.33">Our controller assumes that is has the time to change the state of the character to one from which it knows how to rise.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.00">As long as the figure is not lying on its arms and the ground is relatively flat it will attempt to get up.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.00">The post-conditions are chosen such that they satisfy the pre-conditions of the balance controller.</Sentence>
          
        
        
          <H2>6.2 Stunts</H2>
          <Sentence inAbstract="false" summaryRelevanceScore="2.67">Apart from everyday actions, we want our dynamic character to be able to do a variety of other voluntary actions dictated by the animator.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.33">Such actions can potentially include vigorous and/or physically dangerous actions.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.33">It is our hope that if a large number of researchers contribute controllers the character can eventually be used as a virtual stuntperson.</Sentence>
          
            <H3>6.2.1 Kip move</H3>
            <Sentence inAbstract="false" summaryRelevanceScore="2.00">The kip is an athletic motion often seen in martial arts films and is depicted in Fig. 9 .</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.67">The controller is based on a pose controller whose pre-conditions include a variation of supine positions.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.33">As before, the first part of the controller makes sure that the character assumes a position suitable for performing the kip.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.00">The larger part of the motion is ballistic, which focuses the control mainly at the kick off and landing phases.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.33">The last part of the controller applies continuous control to bring the stuntman to an erect position from which the balance controller can take over.</Sentence>
          
          
            <H3>6.2.2 Plunge and roll</H3>
             <Sentence inAbstract="false" summaryRelevanceScore="2.00">Fig. 10 shows the stuntman performing a suicidal dive down stairs.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.33">The character can be instructed to lunge forward and upward at a takeoff angle controlled by the user.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.00">When the hands contact the ground a front-roll is attempted.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.67">The pre-conditions of this controller are defined be an upright position and little movement of the center of mass.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.67">We have also experimented with a multiple character scenario, with one character tackling another, Fig. 11 .</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.67">While the timing of the tackle is scripted, it illustrates the capability of the system to cope with a pair of interacting characters, each equipped with its own supervisory controller.</Sentence>
            
              
              Figure 11: Two interacting virtual characters.
            
          
        
        
          <H2>6.3 Animation Sequences</H2>
          <Sentence inAbstract="false" summaryRelevanceScore="2.67">We have produced two relatively long animation sequences that demonstrate the potential of the our framework.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.00">The sequence for the 3D skeleton model presented in Fig. 1 involves controllers whose pre-conditions are provided analytically by the designer.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="1.67">Such conditions tend to define square regions within the space defined by the parameters involved.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.00">Despite their simple form, such pre-conditions can generally work well as is demonstrated by the intricacy of the animation produced.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="1.67">We expect to investigate the application of SVM-learned pre-conditions to the 3D model in the future.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.67">A second animation sequence with the 2D terminator model (see Fig. 12 ) makes use of a set of controllers having a mix of analytic and learned pre-conditions.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.33">The sequence of controllers that generated the animation was: balance sit lean-forward rise balance walk step-to-stand balance dive default kneel kneel to stand balance step-forward step-tostand balance step-back step-to-stand balance fall default.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.67">The analytical pre-conditions prune large parts of the state space and the svm-classifier provides a more accurate success/failure prediction within the remaining region.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.67">During the animation sequence, the svm-classifier correctly refined the analytical answer in several cases.</Sentence>
        
        
          <H2>6.4 Performance Issues</H2>
          <Sentence inAbstract="false" summaryRelevanceScore="2.67">Most of the computational burden in our approach lies in the numerical simulation of the equations of motion.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="3.00">The computations associated with the controllers and our composition framework are negligible in comparison.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="4.00">In general, the 2D model simulates in real time, while the 3D model runs between 5 and 9 times slower than real time on a 733 MHz Pentium III system.</Sentence>
          
            
            Figure 7: Sitting and rising from a chair
          
          
            
            Figure 8: Rising from a supine position on the ground and balancing erect in gravity.
          
          
            
            Figure 9: Kip move: A more vigorous way of getting up from the supine position as in the first frame of Fig. 8 .
          
          
            
            Figure 10: Ouch!
          
        
      
      
        <H1>7 Conclusion</H1>
        <Sentence inAbstract="false" summaryRelevanceScore="3.67">The challenges of physics-based controller design plus the technical obstacles that researchers face when attempting to share their algorithms has hindered progress in the important area of physicsbased character animation.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="4.33">This paper has presented a methodology for ameliorating the problem with a framework which facilitates the exchange and composition of controllers.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="3.67">Our framework has been implemented within a freely available system for modeling and animating articulated characters.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="4.33">To our knowledge, our system is the first to demonstrate a dynamic anthoropomorphic character with controlled reactions to disturbances or falls in any direction, as well as the ability to pick itself up off the ground in several ways, among other controlled motions.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="3.33">We hope that our system will foster collective efforts among numerous practitioners that will eventually result in complex composite controllers capable of synthesizing a full spectrum of human-like motor behaviors.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="4.00">Given the enormous challenge of building controllers capable of large repertoires of dynamic human-like motion, it is inevitable that the work presented in this paper is incomplete in many ways.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="3.67">Published control methods for 3D walking, running, and stair climbing make obvious candidates for integration into our system.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.67">Coping with variable terrain and dynamic environments are dimensions of added complexity that should provide work for years to come.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.67">Automatic parameterization of controllers to variations in character dimensions and mass is a necessary step for having solutions adaptable to a variety of characters.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.67">Deriving controllers from motion-capture data is an exciting but difficult prospect, although some progress is already being made in this area.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.67">Other methods of “teaching” skills to a dynamic character also warrant investigation.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="3.00">Finally, intelligently integrating controllers which affect only subsets of DOFs needs to be addressed in order to allow for the parallel execution of controllers.</Sentence>
      
      
        <H1>Acknowledgements</H1>
        <Sentence inAbstract="false" summaryRelevanceScore="1.0">We wish to thank Joe Laszlo for his help with the video editing equipment and for useful discussions.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="1.0">We would also like to thank Symbolic Dynamics Inc.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="1.0">for allowings us to distribute the equations of motion of the 3D human model.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="1.0">This work was supported by grants from NSERC and CITO.</Sentence>
      
      
        <H1>A Balance controller</H1>
        <Sentence inAbstract="false" summaryRelevanceScore="2.33">The articulated body must be in a balanced upright position, the velocity and acceleration of the center of mass should not exceed certain threshold values as explained in <CitSpan>[ 25 ]</CitSpan>, and both feet must maintain contact with the ground at all times.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.00">The controller can tolerate small perturbations of the posture and the velocity/acceleration of the center of mass by stiffening the ankle joints.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.00">For larger accelerations of the center of mass, the controller actively actuates the ankle joint to reduce the acceleration of the center of mass.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="2.00">The post-conditions are similar to the pre-conditions.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="1.0">In mathematical form using the notation defined in Section 3:</Sentence>
        
          
          Figure 12: A still image from the terminator sequence.
        
        <Sentence inAbstract="false" summaryRelevanceScore="2.00">The dynamic terminator model has been knocked backward by the force of a collision to the head by the red ball.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="1.67">The terminator maintains balance by taking a protective step.</Sentence>
        <Sentence inAbstract="false" summaryRelevanceScore="1.0">: Acceleration: 1⁄4 1⁄2 m sec 3⁄4 .</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="1.0">Velocity: Balance: Posture:  ́1⁄2 projection Ò 1⁄4 μ ¿ È m  ́ Õ sec.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="1.0">μ 3⁄4Ë   .</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="1.0">Õ 1⁄4 1⁄4 1⁄2 rad, where  ́ thigh knee waist μ and Ò is a normalization parameter.</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="1.0">Acceleration: : 1⁄4 1⁄41⁄2 m sec 3⁄4 .</Sentence> <Sentence inAbstract="false" summaryRelevanceScore="1.0">Balance: Posture: Velocity:  ́1⁄2 projection Ò 1⁄4 μ 1⁄4 È m  ́ Õ μ sec.</Sentence> 3⁄4Ë   . <Sentence inAbstract="false" summaryRelevanceScore="1.0">Õ 1⁄4 1⁄4 1⁄2 rad, where  ́ thigh knee waist μ and Ò is a normalization parameter.</Sentence>
      
      
        <H1>References</H1>
        
          [1] Ronald C. Arkin. Behavioral Robotics. MIT Press, 1998.
          [2] W. W. Armstrong and M. Green. The dynamics of articulated rigid bodies for purposes of animation. Proceedings of Graphics Interface ’85, pages 407–415, 1985.
          [3] N. Badler, C. Phillips, and B. Webber. Simulating Humans: Computer Graphics, Animation, and Control. Oxford University Press, 1993.
          [4] N. I. Badler, B. Barsky, and D. Zeltzer. Making Them Move. Morgan Kaufmann Publishers Inc., 1991.
          [5] C. Burges. A tutorial on support vector machines for pattern recognition. Data Mining and Knowledge Discovery, 2(2):955–974, 1998.
          [6] R. R Burridge, A. A. Rizzi, and D. E Koditschek. Sequential composition of dynamically dexterous robot behaviors. The International Journal of Robotics Research, 18(6):534–555, June 1999.
          [7] Tolga Capin, Igor Pandzic, Nadia Magnenat Thalmann, and Daniel Thalmann. Avatars in Networked Virtual Environments. John Wiley &amp; Sons, 1999.
          [8] M. C. Do, Y. Breniere, and P. Brenguier. A biomechanical study of balance recovery during the fall forward. Journal of Biomechanics, 15(12):933–939, 1982.
          [9] R. O. Duda and P. E Hart. Pattern Classification and Scene Analysis. Wiley, 1973.
          [10] Petros Faloutsos. Composable Controller for Physics-based Character Animation. PhD thesis, Univeristy of Toronto, DCS, Toronto,Canada, 2001. To be awarded.
          [11] Petros Faloutsos, Michiel van de Panne, and Demetri Terzopoulos. Dynamic free-form deformations for animation synthesis. IEEE Transactions on Visualization and Computer Graphics, 3(3):201–214, 1997.
          [12] R. C Fitzpatrick, J. L. Taylor, and D. I. McCloskey. Ankle stiffness of standing humans in response to imperceptible perturbation: reflex and task-dependent components. Journal of Physiology, 454:533–547, 1992.
          [13] Stefan Gottschalk, Ming Lin, and Dinesh Manocha. OBB-Tree: A hierarchical structure for rapid interference detection. In Computer Graphics (SIGGRAPH 96 Proceedings), pages 171–180, 1996.
          [14] R. Grzeszczuk and D. Terzopoulos. Automated learning of muscle-based locomotion through control abstraction. Proceedings of ACM SIGGRAPH: Computer Graphics, pages 63–70, August 1995.
          [15] R. Grzeszczuk, D. Terzopoulos, and G. Hinton. Neuroanimator: Fast neural network emulation and control of physics-based models. Proceedings of ACM SIGGRAPH: Computer Graphics, pages 9–20, July 1998.
          [16] J. K. Hodgins, W. L. Wooten, D. C. Brogan, and J. F. O’Brien. Animating human athletics. Proceedings of SIGGRAPH 95, ACM Computer Graphics, pages 71– 78, 1995.
          [17] Jessica K. Hodgins and Nancy S. Pollard. Adapting simulated behaviors for new characters. Proceedings of SIGGRAPH 97, pages 153–162, August 1997.
          [18] Michael G. Hollars, Dan E. Rosenthal, and Michael A. Sherman. Sd/fast. Symbolic Dynamics, Inc., 1991.
          [19] E. T Hsiao and S. N Robinovitch. Common protective movements govern unexpected falls from standing height. Journal of biomechanics, 31:1–9, 1998.
          [20] Boston Dynamics Inc. The digital biomechanics laboratory. www.bdi.com, 1998.
          [21] T. Joachims. Making large-scale svm learning practical. advances in kernel methods. In B. Schölhopf, C. Burges, and A. Smola, editors, Support Vector Learning. MIT-Press, 1999. http://www-ai.cs.uni dortmund.de/DOKUMENTE/joachims 99a.pdf.
          [22] Joseph F. Laszlo, Michiel van de Panne, and Eugene Fiume. Limit cycle control and its application to the animation of balancing and walking. Proceedings of SIGGRAPH 96, pages 155–162, August 1996.
          [23] Honda Motor Co. Ltd. www.honda.co.jp/english/technology/robot/.
          [24] Victor Ng and Petros Faloutsos. Dance: Dynamic animation and control environment. Software system, www.dgp.toronto.edu/DGP/DGPSoftware.html.
          [25] Yi-Chung Pai and James Patton. Center of mass velocity-position predictions for balance control. Journal of biomechanics, 30(4):347–354, 1997.
          [26] Marcus G. Pandy and Frank C. Anderson. Three-dimensional computer simulation of jumping and walking using the same model. In Proceedings of the VIIth International Symposium on Computer Simulation in Biomechanics, August 1999.
          [27] Marcus G. Pandy, Felix E. Zajac, Eunsup Sim, and William S. Levine. An optimal control model for maximum-height human jumping. Journal of Biomechanics, 23(12):1185–1198, 1990.
          [28] M. H. Raibert. Legged Robots that Balance. MIT Press, 1986.
          [29] Cecile Smeesters, Wilson C. Hayes, and Thomas A. McMahon. Determining fall direction and impact location for various disturbances and gait speeds using the articulated total body model. In Proceedings of the VIIth International Symposium on Computer Simulation in Biomechanics, August 1999.
          [30] Xiaoyuan Tu and Demetri Terzopoulos. Artificial fishes: Physics, locomotion, perception, behavior. Proceedings of SIGGRAPH 94, pages 43–50, 1994.
          [31] M. van de Panne. Parameterized gait synthesis. IEEE Computer Graphics and Applications, pages 40–49, March 1996.
          [32] Michiel van de Panne, Eugene Fiume, and Zvonko Vranesic. Reusable motion synthesis using state-space controllers. Computer Graphics (SIGGRAPH 90 Proceedings), 24(4):225–234, August 1990. ISBN 0-201-50933-4. Held in Dallas, Texas.
          [33] V. Vapnik. Estimation of Dependecies Based on Empirical Data (in Russian). Nauka, Moscow, 1979. English translation Springer Verlag, New York, 1982.
          [34] Jane Wilhelms and Brian A. Barsky. Using dynamic analysis to animate articulated bodies such as humans and robots. In Graphics Interface ’85, pages 97–104, May 1985.
          [35] Wayne Wooten. Simulation of Leaping, Tumbling, Landing, and Balancing Humans. PhD thesis, Georgia Institute of Technology, March 1998.
        
      
    
  

</Document>
