The dream of animating complex living creatures with pure computation (such as inverse kinematics, or dynamic control) proved impractical. Even though creatures are not free from physics, their motion is not a direct consequence of physics. The problem we try to solve in this paper can be summarized as: ( 1 ) finding in real-time the motion retargetted to a new character that has different anthropometric proportions, and ( 2 ) at the same time, preserving the features of the original motion during the retargetting. 

On-line motion retargetting presented in this paper is based on inverse rate control [17] (or resolved motion rate control), which is a way to implement inverse kinematics based on Jacobian.  It computes the changes in joint angles corresponding to the changes in end-effector position. While tracking the multiple end-effector trajectories of the original subject or character, our on-line motion retargetting imitates the joint motion of the original character by exploiting the kinematic redundancies of the animated model.

The method is an improvement over the off-line retargetting based on spacetime constraints since real-time performances can be retargetted without degradation of retargetting quality. The OMR technique greatly helps to get more satisfactory results in motion capturing with fewer trials by giving the real-time feedback to the performer. Furthermore, the captured data are enhanced in both end-effector positions and joint angles by going through our OMR filter.

One minor unsolved problem is that there is no easy way to guarantee full-proof stability of the system due to the non-linearity.