This paper describes the momentum-based motion editing technique. Momentum constraints effectively record the aggregate effect of the natural torque usage and energy storage/release in a specific momentum pattern. In contrast to the existing methods, the proposed framework is particularly robust to large-scale motion modifications. The system is based on an optimization algorithm that can transform the captured motion to satisfy high-level user constraints while preserving physical realism. The algorithm is composed of three separate components: Motion pre-fitting, optimization, and interpolation. The pre-fitting optimizes a set of coefficients used to model momentum curves so that they are constrained to the similar shapes of the original motion. The system then formulates a spacetime optimization that solves for a new motion, where both high-level physical constraints and the user specification are met. With a family of such optimized motions that parameterize certain dynamic space, a simple linear interpolation is applied to generate arbitrary new motion within the dynamic space in real-time. Since this method does not compute internal torques for joints, scaling and convergence issues are less critical in the optimization framework. This simplification also speeds up the performance. However, this framework is limited to high-dynamic motions with ballistic stages, and does not handle less energetic motions such as walking. Furthermore, the number of samples required is exponentially proportional to the number of dimensions, thus the current framework is hindered by the offline computation of a large dataset.