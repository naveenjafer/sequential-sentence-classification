<?xml version="1.0" encoding="UTF-8" standalone="no"?>
<Document xmlns:gate="http://www.gate.ac.uk" name="A05_S06_Building_Effcient,_Accurate_Character_Skins_from_Examples_ASPECT_v1.xml">


  
    4d7508619e6c2edec7350f85a067113fef474375b28592cf953cecd2f37b95ff
    3wx9
    http://dx.doi.org/10.1145/1201775.882308
  
  
    
      To appear at SIGGRAPH 2003
      
        <Title>Building Efficient, Accurate Character Skins from Examples</Title>
      
      
        
          Alex Mohr ∗ Michael Gleicher University of Wisconsin
        
        
          Madison
        
      
      
        
        Figure 1: Several still frames of our character from Figure 9 in a new animation sequence.
      
      <Abstract>
<Sentence aspectClass="NONE" inAbstract="true">Good character animation requires convincing skin deformations including subtleties and details like muscle bulges.</Sentence> <Sentence aspectClass="NONE" inAbstract="true">Such effects are typically created in commercial animation packages which provide very general and powerful tools.</Sentence> <Sentence aspectClass="NONE" inAbstract="true">While these systems are convenient and flexible for artists, the generality often leads to characters that are slow to compute or that require a substantial amount of memory and thus cannot be used in interactive systems.</Sentence> <Sentence aspectClass="NONE" inAbstract="true">Instead, interactive systems restrict artists to a specific character deformation model which is fast and memory efficient but is notoriously difficult to author and can suffer from many deformation artifacts.</Sentence> <Sentence aspectClass="NONE" inAbstract="true">This paper presents an automated framework that allows character artists to use the full complement of tools in high-end systems to create characters for interactive systems.</Sentence> <Sentence aspectClass="NONE" inAbstract="true">Our method starts with an arbitrarily rigged character in an animation system.</Sentence> <Sentence aspectClass="NONE" inAbstract="true">A set of examples is exported, consisting of skeleton configurations paired with the deformed geometry as static meshes.</Sentence> <Sentence aspectClass="NONE" inAbstract="true">Using these examples, we fit the parameters of a deformation model that best approximates the original data yet remains fast to compute and compact in memory.</Sentence>
</Abstract>
	<H2>Keywords: </H2>Interactive, Skin, Approximation
    
    
      
        <H1>1 Introduction</H1>
      
      <Sentence aspectClass="NONE" inAbstract="false">To be believable, animated characters must deform in plausible ways as they move.</Sentence> <Sentence aspectClass="DISADVANTAGE" inAbstract="false">It is possible to accomplish this by having an artist sculpt an entire character mesh by hand for every frame of an animation sequence, but this is impractical.</Sentence> <Sentence aspectClass="COMMON_PRACTICE" inAbstract="false">Instead, animators typi- cally manipulate an underlying hierarchical skeleton.</Sentence> <Sentence aspectClass="COMMON_PRACTICE" inAbstract="false">The character mesh geometry must then be attached to the underlying skeleton so that as the skeleton deforms, the mesh also deforms appropriately.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">This attachment of model geometry to an underlying skeleton is called a “skin” and can be viewed as a function that maps from the skeletal parameters to a deformation field.</Sentence> <Sentence aspectClass="COMMON_PRACTICE" inAbstract="false">There are two fundamental aspects of skin creation—authoring and computation.</Sentence> <Sentence aspectClass="COMMON_PRACTICE" inAbstract="false">Skin authoring refers to how artists use tool sets to describe the behavior of skin geometry as the skeleton moves.</Sentence> <Sentence aspectClass="COMMON_PRACTICE" inAbstract="false">Skin computation refers to the method by which the deformed mesh geometry is evaluated for display at some skeleton configuration.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">For high-end applications, the authoring methods drive skin creation while for interactive systems, computation methods dominate.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">For high-end applications such as film, the visual fidelity of characters is paramount, so artists require flexibility and control in skin authoring.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">Hence, there are many different ways to create characters using commercial tools.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">One technique involves modeling skin substructure such as muscles and tendons to drive the skin geometry <CitSpan>[Wilhelms and Gelder 1997; Scheepers et al. 1997]</CitSpan>.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">Many deformers which drive skins by linking their control points to the skeletal parameters with custom expressions or scripts are also available.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">Some examples include FFD lattices <CitSpan>[Sederberg and Parry 1986]</CitSpan> or Wires <CitSpan>[Singh and Fiume 1998]</CitSpan>.</Sentence> <Sentence aspectClass="COMMON_PRACTICE" inAbstract="false">High-end characters often use a combination of these techniques—different tools are appropriate for different parts of the character.</Sentence> <Sentence aspectClass="ADVANTAGE" inAbstract="false">This generality and control means that the computation aspect of high-end characters is highly customizable, tightly coupled to authoring, and potentially unbounded.</Sentence> <Sentence aspectClass="ADVANTAGE" inAbstract="false">In fact, high-end tools allow authors to continually develop new skin computation models through custom scripts, expressions and complex deformers.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">In contrast, interactive systems require fast computation and small memory size for characters.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">Thus, the character computation model is fixed and artists must restrict their tool set to author characters in direct support of it.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">The most common skin computation model in games and interactive systems goes by many names including SSD, enveloping, smooth skinning, and linear blend skinning.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">This technique assigns a set of influencing joints and blending weights to each vertex in the character.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">The skin is computed by transforming each vertex by a weighted combination of the joints’ local coordinate frames.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">This technique is discussed in more detail in Section 3.</Sentence> <Sentence aspectClass="ADVANTAGE_DISADVANTAGE" inAbstract="false">While fast to evaluate and compact in memory, this method is notorious not only for its authoring difficulty, but also for its undesirable deformation artifacts.</Sentence> <Sentence aspectClass="ADVANTAGE" inAbstract="false">However, this method is widely used since these characters can be used with arbitrary amounts of animation data and can be posed at runtime.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">A different character computation mechanism previously used in interactive systems is called mesh animation.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">Mesh animation works by storing a large number of deformed models as static meshes—one for each frame of animation.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">These static models are then either displayed directly or are linearly interpolated at runtime.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">Mesh animation is interesting since it decouples skin authoring from runtime skin computation, allowing artists to use any tools they want to author characters.</Sentence> <Sentence aspectClass="DISADVANTAGE" inAbstract="false">Unfortunately mesh animation is only appropriate when the required animation sequences are short and are known a priori.</Sentence> <Sentence aspectClass="DISADVANTAGE" inAbstract="false">As games and interactive applications use larger amounts of animation, storing every frame becomes prohibitive.</Sentence> <Sentence aspectClass="DISADVANTAGE" inAbstract="false">This technique is also incapable of generating new poses at runtime; for example, to place the character’s hand exactly on a door knob or to make footfalls land precisely on stairs.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">Due to these limitations, mesh animation is losing popularity.</Sentence> <Sentence aspectClass="NOVELTY" inAbstract="false">In this paper, we present an automated method to build character skins that are fast to compute and compactly represented from a set of examples.</Sentence> <Sentence aspectClass="ADVANTAGE" inAbstract="false">This technique allows artists to use any skin authoring tools they like while producing characters that meet the performance demands and work with the computation models used in interactive systems.</Sentence> <Sentence aspectClass="NOVELTY" inAbstract="false">We present a framework for extending linear blend skinning that allows us to capture these detailed skin deformations.</Sentence> <Sentence aspectClass="NOVELTY" inAbstract="false">We show how we can fit the parameters of our skinning model using a sampling of an arbitrarily rigged character’s deformations.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">The rest of this paper is organized as follows.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">After a review of related work, we describe the simple linear blend skinning model and its strengths and weaknesses.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">The limitations of this approach lead us to a discussion of our framework for extending this skinning model.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">Next we describe how we fit the parameters of our skinning model using a sampling of the original character deformations.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">Finally we present results and applications of our technique.</Sentence>
      ∗ {amohr, gleicher}@cs.wisc.edu , http://www.cs.wisc.edu/graphics
      ∗
      1
      To appear at SIGGRAPH 2003
      
        <H2>1.1 System Overview</H2>
        <Sentence aspectClass="NONE" inAbstract="false">Building a skin with our system involves two major steps.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">We begin with a character rigged in an animation package such as Maya.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">We then sample this character’s skin deformations by exporting the character’s geometry in several poses.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">Next we fit the parameters of our underlying skinning model using this sampled data.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">We wish to obtain a good sampling of the character’s skin deformations to fit our underlying model with.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">To do this, we pose the character to exercise all the joints fully and include its extreme poses.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">This step does not require a trained animator since these poses are only intended to exercise the degrees of freedom of the character and need not correspond to a realistic motion.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">Once this is done, the poses are sampled regularly at k times.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">This sampling can be very simple to obtain from the user’s perspective—in our case, users must simply invoke a script we have implemented in Maya.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">Each sample consists of the skeleton configuration and the corresponding deformed skin geometry as a static mesh.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">We call a paired skeleton configuration and static mesh an example.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">Using this set of examples, our system first determines the set of joints that should influence each vertex, and then solves a bilinear least-squares problem to fit the parameters of the underlying skinning model.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">As mentioned earlier, the skinning model we use is an extension of the standard linear blend skinning model.</Sentence> <Sentence aspectClass="NOVELTY" inAbstract="false">Our extension adds extra joints to the character that are simply related to the existing joints.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">These new joints are designed in such a way to capture richer deformations than the standard linear blend skinning model.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">Our system is configured to add these extra joints automatically to characters, but we allow users to fine tune the specific set of extra joints if they wish.</Sentence>
      
      
        <H1>2 Related Work</H1>
        <Sentence aspectClass="COMMON_PRACTICE" inAbstract="false">Character skin deformations are fundamental to character animation and have been addressed for some time in the literature.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">
<CitSpan>Catmull [1972]</CitSpan> introduced one of the first skeleton-driven techniques—rigid skinning to a hierarchically structured articulated figure.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">A 2D skeletal bilinear deformation method was presented by <CitSpan>Burtnyk and Wein [1976]</CitSpan>.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">An early 3D skeleton-driven technique that went beyond rigid skinning was presented by MagnenatThalmann, et al. [1988].</Sentence> <Sentence aspectClass="NONE" inAbstract="false">Their technique used custom programmed algorithms to deform character meshes based on the nature of particular joints.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">More recently, novel skinning methods that start with a simple skin and use sparse data interpolation to correct errors between it and a set of examples have been introduced.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">Three examples, Pose Space Deformation, Shape by Example, and EigenSkin <CitSpan>[Lewis et al. 2000; Sloan et al. 2001; Kry et al. 2002]</CitSpan> use radial basis interpolation of corrections to linear blend skins.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">Another recent work applies these techniques to range scan data <CitSpan>[Allen et al. 2002]</CitSpan>.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">These techniques are similar to ours in that they take examples as input.</Sentence> <Sentence aspectClass="LIMITATION" inAbstract="false">The results of these approaches are quite good, and unlike our technique, they can handle skin deformations that depend on abstract parameters rather than only skeleton configurations.</Sentence> <Sentence aspectClass="DISADVANTAGE" inAbstract="false">However, these methods are not appropriate for interactive characters since they require storing potentially large amounts of example data for runtime interpolation.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">In contrast, our method discards all example data after the fitting process so the size of our runtime structures does not scale with the number of inputs.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">Other authors have used physical simulation for interactive deformations, especially secondary animation <CitSpan>[James and Pai 2002; Capell et al. 2002]</CitSpan>.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">Our method cannot capture these secondary deformations directly; however, a technique such as DyRT <CitSpan>[James and Pai 2002]</CitSpan> can be applied to the characters we generate to add secondary animation.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">There has been some recent work on fitting skinning models.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">One method solves for joint centers and vertex weights for a scanned arm <CitSpan>[Nebel and Sibiryakov 2002]</CitSpan> but the Multi-Weight Enveloping technique <CitSpan>[Wang and Phillips 2002]</CitSpan>, or MWE, is most similar to our approach.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">MWE extends linear blend skinning by giving each vertex one weight to each coefficient of each influencing joint’s transformation matrix instead of one weight per influencing joint.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">They then find these weights by solving a linear leastsquares problem using a set of examples as input.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">While on the surface Multi-Weight Enveloping and our technique seem very similar, they are in fact different in a fundamental way.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">Both MWE and our technique use an extension of linear blend skinning as an underlying deformation model.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">However, MWE extends linear blend skinning by adding more vertex weights to the model while in contrast, our method adds more joints.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">MWE uses a large number of weights per vertex (12 per influencing joint).</Sentence> <Sentence aspectClass="DISADVANTAGE" inAbstract="false">This introduces the possibility of rank deficient matrices in the least-squares solutions <CitSpan>[Wang and Phillips 2002]</CitSpan>, especially since the matrix coefficients are usually highly correlated.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">This can lead to overfitting, which MWE must take measures to avoid.</Sentence> <Sentence aspectClass="ADVANTAGE" inAbstract="false">In contrast, since the number of weights per vertex in one of our skins remains relatively small (1 per influencing joint) and our extra joints are explicitly designed to be very different from existing joints, our technique requires no special provisions to avoid overfitting.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">Even so, our method can detect and handle small amounts of overfitting if it occurs as explained in Section 5.2.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">Another consequence of having one weight per entry in the joint transformation matrices is that MWE skins are not as easily accelerated by graphics hardware as skins created using our method.</Sentence> <Sentence aspectClass="ADVANTAGE" inAbstract="false">Finally, since our skins are computed in the same manner as linear blend skins, existing software infrastructure can make use of them with little or no changes.</Sentence>
        2
        To appear at SIGGRAPH 2003
      
      
        <H1>3 Linear Blend Skinning</H1>
        <Sentence aspectClass="NONE" inAbstract="false">The traditional interactive skinning model goes by many names.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">Lewis et. al call it Skeleton Subspace Deformation or SSD, Maya calls it “smooth skinning” and we call it linear blend skinning.</Sentence> <Sentence aspectClass="COMMON_PRACTICE" inAbstract="false">This technique is widely used for interactive applications.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">An excellent description of this method is found in <CitSpan>Lewis et al. [2000]</CitSpan>.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">The linear blend skinning algorithm works by first placing a hierarchical skeleton inside a static model of a character, typically in some neutral pose.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">This initial character pose is referred to as “dress pose”.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">Then, each vertex is assigned a set of influencing joints and a blending weight for each influence.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">Computing the deformation in some pose involves rigidly transforming each dress pose vertex by all of its influencing joints.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">Then the blending weights are used to combine these rigidly transformed positions.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">The deformed vertex position at some skeletal configuration c, v c is computed as</Sentence>
        
          1
          n v c = ∑ w i M i,c M i,d −1 v d i=1
        
        <Sentence aspectClass="NONE" inAbstract="false">where w i are the weights (usually affine or convex), v d is the dresspose location of some vertex v, M i,c is the transformation matrix associated with the ith joint in configuration c and M i,d −1 is the inverse of the dress-pose matrix associated with the ith influence.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">(Taken together, M i,d −1 v d represents the location of v d in the local coordinate frame of the ith influence.) Note that a deformed vertex position in the dress pose configuration c = d is the same as the provided dress pose vertex ( v d = v d ) if the weights are affine.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">This skinning algorithm is notorious for its failings.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">It cannot represent complex deformations and suffers from characteristic artifacts such as the “candy-wrapper” collapse effect on wrists and collapsing around bending joints as shown in Figure 2 .</Sentence> <Sentence aspectClass="NONE" inAbstract="false">The artifacts occur because vertices are transformed by linearly interpolated matrices.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">If the interpolated matrices are dissimilar as in a rotation of nearly 180 degrees, the interpolated transformation is degenerate, so the geometry must collapse.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">In addition to these deformation problems, linear blend skins are very difficult to author <CitSpan>[Lewis et al. 2000]</CitSpan>.</Sentence> <Sentence aspectClass="DISADVANTAGE_ADVANTAGE" inAbstract="false">Despite its failings, this skinning algorithm is very fast and widely supported by commercial applications so it remains popular especially in games and virtual environments.</Sentence>
      
      
        <H1>4 Extending Linear Blend Skinning</H1>
        <Sentence aspectClass="NONE" inAbstract="false">The linear blend skinning model is not sufficient to capture deformations well as shown in Figure 3 .</Sentence> <Sentence aspectClass="NONE" inAbstract="false">The problem in this particular case is that as the twist approaches 180 degrees, the linearly blended matrix becomes degenerate and collapses the skin geometry.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">Linearly blended transformations tend to collapse the more different they are.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">The resulting loss of volume can also be observed around hinge joints such as the knee and elbow as shown in Figure 2 .</Sentence> <Sentence aspectClass="NONE" inAbstract="false">We observe that we can help avoid the collapse problem by avoiding blending transformations that are so dissimilar.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">We can accomplish this by adding extra transformations that properly interpolates without collapsing.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">In the case of the twisting wrists, we can add an extra joint that interpolates the rotation angle correctly and does not collapse.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">In fact, artists sometimes do this by hand to help avoid wrist collapses.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">More generally, we observe that any deformation effect could be obtained by adding joints that deform appropriately to capture that deformation effect.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">For example, to capture muscle bulges, we can add joints that scale up when the muscle should bulge, and scale down when the muscle relaxes.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">For wrinkles, we could add several joints that move and scale in concert to capture the wrinkles.</Sentence> In
        
          
          Figure 2: Common problems with linear blend skinning: the bent arm on the left demonstrates shrinkage around bent joints such as the elbow and knee while the twisted wrist on the right demonstrates the “candy-wrapper” collapse effect. These artifacts are caused by blending dissimilar transformations.
        
        
          
          Figure 3: Top Row: Three examples of a twisting box driven by a nonlinear de-
        
        former. <Sentence aspectClass="NONE" inAbstract="false">Middle Row: Solved linear blend skin using one joint.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">Bottom Row: Our result with just one additional joint that half interpolates the twist rotation.</Sentence>
        <Sentence aspectClass="NONE" inAbstract="false">fact, in the limit we could add as many transformations as vertices and capture all deformations exactly.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">Unfortunately, adding so many extra joints is impractical.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">First, adding such a large number of joints would severely impact the performance of our resulting skins.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">Worse, even if we could find these transformations for the input examples, it is unclear how to determine the general relationships of these transformations to the skeletal parameters in all poses.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">Without knowledge of this relationship, our scheme would only be able to reproduce the input frames and would not work well in new poses.</Sentence> <Sentence aspectClass="NOVELTY" inAbstract="false">Instead, we extend the traditional linear blend skinning model by adding a relatively small number of joints that are simply related to the original skeletal parameters and fit using them.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">We choose these extra joints by both examining the places where the standard linear blend model fails and by examining extra character deformations that we would like to capture.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">We then add joints that we believe will help resolve these artifacts.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">Finally, we fit the parameters of our skinning model using this extended skeleton.</Sentence> <Sentence aspectClass="NOVELTY" inAbstract="false">The key to our success is that since vertices choose weighted sums of transformations, if any linear scaling of an added joint is beneficial it may be used.</Sentence> <Sentence aspectClass="ADVANTAGE" inAbstract="false">Thus the additional joints need not be exact.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">We emphasize that this is a framework for obtaining better deformations and the joints we choose to add are based on our observations of characters.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">Different characters with different deformations may require a different set of additional joints.</Sentence> <Sentence aspectClass="ADVANTAGE" inAbstract="false">However, once some set of these joints is determined, the skin may be solved using our fitting algorithm without change.</Sentence>
        3
        To appear at SIGGRAPH 2003
        
          
        
        blend skin approximation. Bottom Row: Our result using one additional joint.
        
          Figure 4: Top Row: Original examples of a twisting wrist. Middle Row: Linear
          
        
        
          Figure 5: Linear blend skinning alone is incapable of capturing correct creasing
        
        <Sentence aspectClass="NONE" inAbstract="false">around elbows.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">At the left is an example of a bent elbow.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">In the middle is the linear blend skin approximation.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">notice the interpenetration.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">In contrast, our method avoids the interpenetration.</Sentence>
      
      
        <H2>4.1 Additional Joints</H2>
        <Sentence aspectClass="NOVELTY" inAbstract="false">To help solve the collapsing geometry problem, our system can automatically add joints that properly interpolate rotations without collapsing.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">This is done by examining the rotation of a joint relative to the dress pose and computing the new joint as the halfway spherical linear interpolation <CitSpan>[Shoemake 1985]</CitSpan> of this rotation, located at the same position in space.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">More joints with evenly distributed interpolation parameters could be added to sample this rotation space even better; however, in our experience just a single interpolated rotation is sufficient.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">Figure 4 demonstrates the improvements gained by simply adding a single interpolated rotation joint in the twisting case.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">Figure 5 shows the improvements for the bent elbow case.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">Another type of effect not easily captured by the simple linear blend model is bulging and denting of skins caused by muscles, tendons, or other substructure.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">These particular effects cannot be captured since the joints employed in animating a character do not typically scale up and down as would be necessary to approximate these effects.</Sentence> <Sentence aspectClass="NOVELTY" inAbstract="false">We have observed that for many characters, the substructure deformation effects from muscles and tendons are often simply related to the angles between joints.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">For example, a bicep bulge is small when the elbow is near full extension while the bugle is large when the elbow is near full flexion.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">The effect is similar for other muscles in the body.</Sentence> <Sentence aspectClass="NOVELTY" inAbstract="false">To capture these effects, our system can add several joints that scale up and down based on the angle between particular joints.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">We add these scaling joints as follows.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">First we choose a joint in the original skeleton that will drive the scaling parameters of the new joints.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">Once this driver is chosen, there are two sets of joints that we add.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">The first set is “upstream” of the driver and lies in the middle of the bone connecting the driver to its parent, the second set is “downstream” and lies in the middle of the bones connecting the driver to its children.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">All upstream joints are oriented in the same way, with one axis aligned with the bone as shown in Figure 6 .</Sentence> <Sentence aspectClass="NONE" inAbstract="false">We use four upstream joints.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">Two of them scale up about two axes orthogonal to the bone and a corresponding pair scale down about the two axes orthogonal to the bone.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">The scale parameters of these joints are set based on the angle of the bone connecting the driver to its parent and the bone connecting the driver to its child.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">If the driver has multiple children, a vector that is the sum of the bones connecting the driver to its children is used to measure the angle.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">Downstream joints are similar.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">We use four downstream joints on each bone connecting the driver to its children that scale just as the upstream joints do.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">The scale parameters are computed as follows.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">For joints that scale up, the scale parameter s is s = 1 + k b 1 · b 2 + 1 2 b 1 b 2 where b 1 and b 2 are the bone vectors used to measure the angle at the driver joint and k is the maximum scale factor when the angle between b 1 and b 2 is zero.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">For joints that scale down, the scale parameter is simply s −1 .</Sentence> <Sentence aspectClass="NONE" inAbstract="false">The value for k may be chosen by the user but in our experience, we have found that 8 works well for our examples.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">Again, since vertices may take any scaling of these new joints, a conservative large value is fine.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">For example, if a vertex in fact needed a joint that scaled by 2 instead of 8, it could be assigned a weight of 4 1 .</Sentence>
        J1 v1 θ v2 J3 J4-J7 J2 Driver
        
          Figure 6: Our method adds extra joints to characters to help better approximate deformations. Here J4 through J7 are automatically added upstream joints that scale depending on the angle θ. As θ decreases, J4 scales up in the direction v1 which is orthogonal to the bone connecting J1 and J2. Meanwhile, J5 scales up in the direction v2, orthogonal to both the bone and v1. J6 and J7 operate similarly, but scale down as θ increases rather than up. Downstream joints are very similar except that these joints are positioned on the bone from J2 to J3.
        
      
      
        <H1>5 Fitting the Skinning Model</H1>
        <Sentence aspectClass="NONE" inAbstract="false">Once our system has augmented the input skeleton, we use a fitting procedure to set the parameters of the underlying skinning model to match the example data well.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">As mentioned earlier, the input to the fitting process is a set of examples.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">An example is simply a static character mesh paired with a skeleton.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">This static mesh is deformed according to the skeleton configuration, but it is not attached to the skeleton in any way.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">For our results, our examples were generated by exporting rigged objects from Maya, but they could have been sculpted by hand or come from another program.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">A linear blend skin computes a deformed vertex as described earlier in Equation 1.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">Examining this skinning model, only the M i are predetermined.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">These are the coordinate frames associated with all the joints in the character.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">That means for each vertex, we are able to choose the set of influencing joints, influence weights (w i ) and the dress pose vertex position (v d ).</Sentence> <Sentence aspectClass="NONE" inAbstract="false">We would like to choose the influence sets, weights and dress pose vertex positions that best approximate the examples and generalize well to new poses.</Sentence>
        4
        To appear at SIGGRAPH 2003
        Examples Compactness of Local Coordinate Point Clouds Upper Arm Lower Arm
        
          Figure 7: Top: A set of three examples of a deforming arm mesh with a bulging
        
        bicep. <Sentence aspectClass="NONE" inAbstract="false">A particular point on the arm mesh is highlighted in each example.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">Bottom Left: Each example rotated and aligned so that the upper arm bones coincide.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">The highlighted points form a cloud in the local coordinate frame of the upper arm.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">Even though the bicep bulges significantly, this cloud is compact.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">Lower Right: A similar point cloud but relative to the forearm.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">This cloud is far less compact than the former, making the forearm a poorer choice for an influence.</Sentence>
      
      
        <H2>5.1 Finding Influence Sets</H2>
        <Sentence aspectClass="NONE" inAbstract="false">We determine influence sets first for several reasons.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">Ideally, the influence sets would fall out naturally from the weight solving procedure (irrelevant joints would have a weight of zero) but this does not happen in practice because our samplings are necessarily not exhaustive.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">Also, the more joints that a vertex depends on, the slower the skin can be to compute and current hardware only supports a limited number of influences per vertex.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">Thus, we would like to select a small set of good influences.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">Also, choosing the influence sets appropriately lets us bound the size of the problems we must solve to determine the weights as discussed in Section 5.2.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">This makes the solving process faster.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">In most recent research, influence set determination has been left to users <CitSpan>[Lewis et al. 2000; Wang and Phillips 2002; Sloan et al. 2001]</CitSpan>.</Sentence> <Sentence aspectClass="COMMON_PRACTICE" inAbstract="false">The task is typically accomplished by “painting” the regions of influence for each joint over the mesh.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">While less difficult than painting the weights themselves <CitSpan>[Lewis et al. 2000]</CitSpan>, it is a tedious process.</Sentence> <Sentence aspectClass="NOVELTY" inAbstract="false">In contrast, our system automatically determines the influence sets for each vertex using a heuristic algorithm.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">We observe that vertices in a character skin typically transform nearly rigidly with respect to some joint.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">For instance, vertices on the forearm roughly follow the forearm.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">We believe that for most characters, their skin is most heavily influenced by those joints that they are bound to.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">Even though a point on the bicep is not truly rigid as an arm moves (due to muscle bulge), we believe that these points remain mostly rigidly attached to the upper arm, and therefore should be influenced by it.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">Using this observation, we measure how rigidly a vertex transforms with every joint over all examples and use the most rigidly transforming joints for the influence set.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">For a single vertex, a rigidity score for a joint is computed as follows.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">For each example, the local coordinate position of the vertex is computed as M i,e −1 v e where M i,e is the coordinate frame associated with the ith joint in the eth example and v e is the global coordinate position of the vertex on the eth example.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">The collection of these local coordinate positions over all examples forms a point cloud as shown in Figure 7 .</Sentence> <Sentence aspectClass="NONE" inAbstract="false">The more compact this point cloud, the more rigid we believe the vertex-joint relationship to be.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">We measure the compactness of this point cloud by taking its diameter (the maximum distance between any two points in the cloud).</Sentence> <Sentence aspectClass="NONE" inAbstract="false">We have found that the simple O(n 2 ) algorithm that compares each point to every other to be fast enough for our purposes but this diameter may be computed more quickly.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">An O(n log n) time algorithm is possible.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">See <CitSpan>[Malandain and Boissonnat 2002]</CitSpan> for faster methods.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">Once the compactness measures for all joints are computed for a vertex, the smallest k are chosen as the influence set for that vertex.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">It may be tempting to use a threshold scheme to choose influence sets but we have found this problematic.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">It is unclear how to pick a good threshold because as the rigidity scores get larger, they become less meaningful.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">For instance, it may happen as an artifact of the particular input examples that points on the left shoulder move much more rigidly relative to the right leg rather than the left leg but both choices make no sense for influences.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">Since larger rigidity scores are not particularly meaningful, it is nearly impossible to pick a meaningful threshold value.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">As in other linear blend skinning systems, influence sets need only be determined conservatively <CitSpan>[Wang and Phillips 2002]</CitSpan> so we allow users to choose k if desired.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">In our experience, we have found that between three and eight influences works well, depending on the complexity of the character.</Sentence>
      
      
        <H2>5.2 Solving for Weights and Vertices</H2>
        <Sentence aspectClass="NONE" inAbstract="false">Once the influence sets have been determined, only the weights and dress pose vertex positions remain (w i and v d ).</Sentence> <Sentence aspectClass="NONE" inAbstract="false">We would like to find the best vertices and weights that minimize the least-squares difference between the skin and the examples at all the example skeleton configurations.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">That is
        n 2 min ∑ v e i − v e i i=1
        for all examples where v e i is the input vertex position from the ith example and v e i is the deformed vertex computed by the skinning model at the ith example configuration.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">n v e = ∑ w i M i,e M i,d −1 v d i=1 This problem is bilinear in the weights and vertices.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">We use an alternation technique to solve the optimization.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">This works by first fixing the first variable and solving a linear least-squares problem to find the second, then fixing the second and solving a linear leastsquares problem for the first.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">This process is then repeated until it converges.</Sentence> <Sentence aspectClass="COMMON_PRACTICE" inAbstract="false">This technique is commonly used and is described in <CitSpan>[Freeman and Tenenbaum 1997]</CitSpan>.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">We start by solving for weights since we have no good guess for them but we know that the initial dress pose vertices are ideal.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">Next we hold the weights fixed and solve for vertex positions.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">This process typically converges after one or two iterations.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">As mentioned in Section 2, we have found that since we are solving for a small numbers of weights using large numbers of examples, our systems are often well conditioned and do not suffer from overfitting if the input data is well sampled.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">Thus we do not have to take special precautions to avoid overfitting as in <CitSpan>[Wang and Phillips 2002]</CitSpan>, although we include tests for robustness.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">For clarity, we present the matrices we solve via least-squares in block form.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">First we introduce some notation: T i,e = M i,e M i,d −1 .</Sentence> <Sentence aspectClass="NONE" inAbstract="false">In order to ensure that the resulting weights are affine, we set w 1 = 1 − ∑ i=2 n w i , and solve for w 2 through w n .</Sentence>
        <Sentence aspectClass="NONE" inAbstract="false">   (T (T 2,e 2,e 1 k − − .</Sentence> . . <Sentence aspectClass="NONE" inAbstract="false">T T 1,e 1,e k 1 )v )v d d ··· ··· ..</Sentence> . <Sentence aspectClass="NONE" inAbstract="false">(T (T n,e n,e 1 k − − .</Sentence> . . <Sentence aspectClass="NONE" inAbstract="false">T T 1,e 1,e k 1 )v )v d d        w w w .</Sentence> . . <Sentence aspectClass="NONE" inAbstract="false">2 n 3     =    v v e e 1 k − − T T .</Sentence> . . <Sentence aspectClass="NONE" inAbstract="false">1,e 1,e 1 k v v d d</Sentence>
          
        5
        To appear at SIGGRAPH 2003
        The matrix used to solve for vertex positions is as follows. <Sentence aspectClass="NONE" inAbstract="false">   ∑ ∑ i=1 n i=1 n w w . . . i i T T i,e i,e 1 k    v d =    v v . . . e e 1 k    To handle homogeneous coordinates, the translation parts of the ∑ i=1 n w i T i,e k matrices are subtracted from the v e on the right hand side.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">We solve these least-squares problems using the singular value decomposition.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">This lets us detect when our matrices are rank deficient, leading to overfitting.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">We detect this by comparing the ratio of the largest singular value to the smallest, and issuing a warning if there are any singular values below some fraction of this ratio.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">To recover, we zero these singular values and continue with the fitting process.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">If overfitting is a problem, provisions such as those taken in <CitSpan>[Wang and Phillips 2002]</CitSpan> could also be used.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">However, in all the examples in this paper, no singular values were zeroed.</Sentence>
      
      
        <H2>5.3 Handling Normals</H2>
        <Sentence aspectClass="NONE" inAbstract="false">It is not only important for the geometry in a skin approximation to be accurate, but also important for normals to be well approximated.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">If they are not, lighting calculations will not produce good results.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">We assume that normals are specified per vertex.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">It may seem that just transforming a dress pose normal by the inverse transpose of the corresponding vertex’s transformation matrix would be correct.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">To be more explicit, n  ̄ c = ( ∑ w i M i,c M i,d −1 ) −T n d ( ∑ w i M i,c M i,d −1 ) −T n d While this is technically valid for local neighborhoods of smooth surfaces <CitSpan>[Turkowski 1990]</CitSpan>, we do not have a smooth surface.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">Instead we have single points that are computed independently.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">Computing the normals in this manner can give undesirable results when the blended transformations are not pure rotations.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">Interactive systems typically approximate normal calculations as</Sentence>
        
          2
          n  ̄ c = ∑ w i M i,c −T M i,d T n d ∑ w i M i,c −T M i,d T n d
        
        <Sentence aspectClass="NONE" inAbstract="false">since it is often faster to calculate the joint matrices and their inverses incrementally by composition because at each step, rotations and scales have special inverse forms.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">This alleviates the need for a general inversion operation.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">In EigenSkin <CitSpan>[Kry et al. 2002]</CitSpan>, normals are treated as second skinning problem and are computed independently.</Sentence> <Sentence aspectClass="NOVELTY" inAbstract="false">In our system, we take the model used in existing systems as in Equation 2 and include normals in our optimization process.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">To do this, we simply add more terms to the objective function to include the differences between normal vectors.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">We allow users to scale normals if they wish to change their relative influence on the least-squares solution.</Sentence>
      
      
        <H1>6 Results</H1>
        <Sentence aspectClass="NONE" inAbstract="false">The simple linear blend skinning model commonly used in video games and other interactive applications is very fast and compact but cannot capture the high quality deformations that make convincing characters.</Sentence> <Sentence aspectClass="NOVELTY" inAbstract="false">Our framework for extending the linear blend model allows us to capture much more interesting deformations while retaining its efficiency.</Sentence> <Sentence aspectClass="NOVELTY" inAbstract="false">The most egregious deformation problems of linear blend skinning are solved by our approach.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">Figures 3 and 4 show how our system can fix collapsing twists by adding just a single extra joint.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">Collapsing and interpenetrations around hinge joints are also fixed using our method as shown in Figure 5 .</Sentence> <Sentence aspectClass="ADVANTAGE" inAbstract="false">In addition to solving these problems with linear blend skinning, our extension framework can capture other more subtle and detailed deformations required for convincing characters.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">Figure 8 demonstrates how our method can capture the bulges in the biceps and triceps of a character’s arm.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">While the particular extra joints we have chosen to add to our characters may not be capable of capturing the full deformation for any character, different extra joints that do capture the desired deformations may be added and solved using our technique.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">To demonstrate that our technique can be used on more than just simple arms and legs, Figure 9 shows a rigged upper body and its approximation by our system.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">This figure also shows this character in new poses from an animation sequence, demonstrating that our resulting skins generalize well to new poses.</Sentence> <Sentence aspectClass="ADVANTAGE" inAbstract="false">Our solution procedure is generally very fast.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">None of the examples shown here took more than five minutes to solve on a modern personal computer.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">The slowest was the upper body model which has more than 6000 vertices, 50 examples, and 5 influences per vertex.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">The computation time for each vertex depends on the number of influences and the number of examples.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">Also, since each vertex is solved independently, our algorithm is trivial to parallelize.</Sentence>
        
          
          Figure 8: Top: Examples of a muscular arm flexing. Middle: Linear blend skin approximation. Note the lack of bicep bulge. Bottom: Results using our method.
        
      
      
        <H2>6.1 Applications</H2>
        <Sentence aspectClass="NONE" inAbstract="false">The ability to generate compactly represented, fast to evaluate, high quality skin approximations from a set of examples is very useful.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">Applications range from building characters for video games and virtual environments to high-end animation previewing.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">Many current interactive systems such as video games only support linear blend skinned characters.</Sentence> <Sentence aspectClass="DISADVANTAGE" inAbstract="false">Aside from the deformation problems associated with using this model, authoring these skins is notoriously difficult.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">Determining the blending weights and influence sets is left to the skin author to set directly.</Sentence> <Sentence aspectClass="DISADVANTAGE" inAbstract="false">None of the more intuitive or useful deformer primitives provided by animation systems may be used.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">Using our method, character authors may use any tools they like to author characters.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">All our system requires is a set of examples which is used to compute the appropriate influence sets and blending weights automatically.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">This frees the author from setting them manually.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">It is important to note that since our characters are a straightforward extension to linear blend skinning, many existing interactive systems already have the software infrastructure to sup- port them.</Sentence> <Sentence aspectClass="ADVANTAGE" inAbstract="false">In addition, since our skins are computed in the same manner as existing linear blend skins, they are already accelerated by current graphics hardware.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">Another application of our system is to map a character originally attached to one skeleton onto a different underlying skeleton.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">We call this process skin retargeting.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">Skin retargeting is useful if a particular interactive system requires characters to have a specific skeleton.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">For instance, a video game may have an optimized engine for characters with a particular skeleton topology.</Sentence> <Sentence aspectClass="COMMON_PRACTICE" inAbstract="false">Ordinarily, if a character was created for a different skeleton, the character would have to be re-rigged manually to work on the new skeleton topology.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">However, this can be accomplished much more easily with our system.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">One just exports a set of example meshes deformed by the original skeleton but paired with corresponding poses of the new skeleton.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">Our system sees this as any other set of data and solves for the proper influence sets and blending weights.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">Another application of our technique is targeted at high-end animation.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">High-end characters often have such complex deformations that they cannot be computed interactively.</Sentence> <Sentence aspectClass="COMMON_PRACTICE" inAbstract="false">Thus, animators typically work with low fidelity versions that only roughly suggest the actual shape of the character.</Sentence> <Sentence aspectClass="ADVANTAGE" inAbstract="false">Using our method, interactive characters could be built that allow animators to interact with much better approximations of the deformed characters.</Sentence>
        6
        To appear at SIGGRAPH 2003
        
          
          
          
          Figure 9: Top Row: Examples of an upper body rigged in Maya. Middle Row: Best linear blend skin. Note the circled problem areas. Bottom Row: Our results.
        
      
      
        <H2>6.2 Discussion</H2>
        <Sentence aspectClass="NOVELTY" inAbstract="false">In this paper, we have presented a method for building fast to evaluate, compact representations that produce accurate approximations of deforming characters.</Sentence> <Sentence aspectClass="ADVANTAGE" inAbstract="false">The characters may be rigged using any available tool since our system only requires static deformed meshes paired with skeletal configurations as input.</Sentence> <Sentence aspectClass="LIMITATION" inAbstract="false">While our technique works well for a wide variety of character skins, it has limitations.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">For instance, character deformations in our model are only driven by the skeleton’s joint parameters.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">Our method cannot capture deformations that are driven by abstract parameters such as “happiness” as in <CitSpan>[Lewis et al. 2000; Sloan et al. 2001]</CitSpan>.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">Our system also cannot accurately reproduce deformations that are not representable as linear combinations of the transformations expressed in our skeletons.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">For instance, the scaling joints presented in this paper can only fully capture deformations that are well approximated by a scaling that is linearly related to the cosine of the angle between two bones.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">This assumption may be violated by a character whose muscle bulges only when its arm is fully bent.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">The scaling joints also assume that only the angle between joints is important, so bending the shoulder forward is treated the same as bending it up.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">Even though not all deformations can be captured using the extra joints presented here, new joints may be added to capture any important deformation, and our influence set and vertex weight solving framework may be applied without change.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">Despite these limitations, our method produces high-quality yet fast and compact skinned characters that work with existing game engines, graphics hardware and other runtime systems.</Sentence>
      
      
        <H1>Acknowledgments</H1>
        <Sentence aspectClass="NONE" inAbstract="false">We would like to thank Luke Tokheim for help with rigging and J. P. Lewis and Karan Singh for their generosity with characters.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">We would also like to thank the UW Graphics Group, especially Andrew Selle and Hyun Joon Shin for their help with video production.</Sentence> <Sentence aspectClass="NONE" inAbstract="false">This research is supported by NSF grants CCR-9984506 and CCR-0204372, and equipment donations from Intel.</Sentence>
      
      
        <H1>References</H1>
        
          A LLEN , B., C URLESS , B., AND P OPOVI Ć , Z. 2002. Articulated body deformation from range scan data. ACM Transactions on Graphics 21, 3 (July), 612–619.
          B URTNYK , N., AND W EIN , M. 1976. Interactive skeleton techniques for enhancing motion dynamics in key frame animation. CACM 19, 10, 564–569.
          C APELL , S., G REEN , S., C URLESS , B., D UCHAMP , T., AND P OPOVI Ć , Z. 2002. Interactive skeleton-driven dynamic deformations. ACM Transactions on Graphics 21, 3, 586–593.
          C ATMULL , E. E. 1972. A system for computer generated movies. In Proc. ACM Annual Conf. August, 422–431.
          F REEMAN , W. T., AND T ENENBAUM , J. B. 1997. Learning bilinear models for two-factor problems in vision. In IEEE Computer Vision and Pattern Recognition.
          J AMES , D. L., AND P AI , D. K. 2002. DyRT: Dynamic response textures for real time deformation simulation with graphics hardware. ACM Transactions on Graphics 21, 3, 582–585.
          K RY , P. G., J AMES , D. L., AND P AI , D. K. 2002. Eigenskin: Real time large deformation character skinning in hardware. In ACM SIGGRAPH Symposium on Computer Animation, 153–160.
          L EWIS , J. P., C ORDNER , M., AND F ONG , N. 2000. Pose space deformations: A unified approach to shape interpolation and skeleton-driven deformation. In Proceedings of ACM SIGGRAPH 2000, Annual Conference Series, ACM SIGGRAPH.
          M AGNENAT -T HALMANN , N., L APERRIRE , R., AND T HALMANN , D. 1988. Jointdependent local deformations for hand animation and object grasping. In Proceedings of Graphics Interface ’88, 26–33.
          M ALANDAIN , G., AND B OISSONNAT , J.-D. 2002. Computing the diameter of a point set. In Discrete Geometry for Computer Imagery (DGCI 2002), A. Braquelaire, J.O. Lachaud, and A. Vialard, Eds., vol. 2301.
          N EBEL , J.-C., AND S IBIRYAKOV , A. 2002. Range flow from stereo-temporal matching: application to skinning. In IASTED International Conference on Visualization, Imaging, and Image Processing.
          S CHEEPERS , F., P ARENT , R. E., C ARLSON , W. E., AND M AY , S. F. 1997. Anatomybased modeling of the human musculature. In Proceedings of SIGGRAPH 97, Annual Conference Series, ACM SIGGRAPH, 163–172.
          S EDERBERG , T. W., AND P ARRY , S. R. 1986. Free-form deformation of solid geometric models. In Proceedings of SIGGRAPH 86, Annual Conference Series, ACM SIGGRAPH, 151–160.
          S HOEMAKE , K. 1985. Animating rotation with quaternion curves. In Proceedings of SIGGRAPH 85, Annual Conference Series, ACM SIGGRAPH, 245–254.
          S INGH , K., AND F IUME , E. L. 1998. Wires: A geometric deformation technique. In Proceedings of SIGGRAPH 98, Annual Conference Series, ACM SIGGRAPH, 405–414.
          S LOAN , P.-P. J., C HARLES F. R OSE , I., AND C OHEN , M. F. 2001. Shape by example. In Proceedings of the 2001 symposium on Interactive 3D graphics, 135–143.
          T URKOWSKI , K. 1990. Transformations of surface normal vectors. Tech. Rep. 22, Apple Computer, July.
          W ANG , X. C., AND P HILLIPS , C. 2002. Multi-weight enveloping: Least-squares approximation techniques for skin animation. In ACM SIGGRAPH Symposium on Computer Animation, 129–138.
          W ILHELMS , J., AND G ELDER , A. V. 1997. Anatomically based modeling. In Proceedings of SIGGRAPH 97, Annual Conference Series, ACM SIGGRAPH, 173– 180.
        
        7
      
    
  

</Document>
